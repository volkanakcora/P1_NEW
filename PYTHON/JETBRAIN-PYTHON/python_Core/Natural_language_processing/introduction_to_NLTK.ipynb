{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) NLTK,\n",
    "\n",
    " short for Natural Language Toolkit, is a Python library for NLP. It provides modules for various language-related tasks, including part-of-speech tagging, syntactic parsing, text classification, named-entity recognition, etc. The library includes a lot of datasets and pre-trained models available for free. It is designed to support NLP researchers and learners. Besides its practical application, NLTK is suitable for beginners in computational linguistics methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have installed the library, you may also want to download external datasets and models. The datasets include, for instance, collections of classic literary works, samples of web conversations, movie reviews, as well as various lexical resources like sets of synonyms. As for the models, NLTK provides several models, for example, the pre-trained word2vec. It allows you to find out the relations between words. NLTK also has a couple of pre-trained models for sentiment analysis and so forth. The whole list is available on the official NLTK site â€” NLTK Data. Use download() to get to the resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nltk.download()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method without arguments opens the NLTK Downloader window. You can select the required data there. Choose all in the Collections tab to obtain the entire collection. Alternatively, you can type all as the function argument. It will get you the entire set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('all')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Advantages and disadvantages\n",
    "\n",
    "\n",
    "We have mentioned that nltk is a great starting point for studying NLP due to its academic nature. The documentation is clear, easy to comprehend, and includes numerous examples. Additionally, we would like to highlight some other benefits:\n",
    "\n",
    "- NLTK proves to be highly suitable for carrying out NLP tasks.;\n",
    "- It is convenient to access external resources, and all the models have been trained on dependable datasets.;\n",
    "- Texts are often supplied with annotations.\n",
    "\n",
    "However, there are some restrictions:\n",
    "\n",
    "- NLTK may not be the optimal solution for certain tasks, as it can be slow when dealing with large datasets or real-time processing;\n",
    "- Although built-in models may not be the most advanced, they still serve as a valuable starting point.;\n",
    "- Although the library offers various conventional machine learning techniques, it lacks resources for neural network training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) NLTK applications\n",
    "\n",
    "\n",
    "Let's start with pre-processing. Before processing any data, specific steps should be taken. Firstly, tokenization is necessary, breaking raw textual data into smaller units like words, phrases, or other entities. Secondly, lemmatization or stemming is performed where different word forms are normalized and reduced. NLTK has special modules for these procedures: nltk.tokenize and nltk.stem.\n",
    "\n",
    "You may require additional pre-processing to remove high-frequency words; these words have little value. nltk contains wordlists of common words for several languages. Such words are called stopwords; they can be found in nltk.corpus.stopwords. With the help of the same corpus module, you can get access to other corpora of nltk.\n",
    "\n",
    "The library is also good for other tasks, such as collocation discovery. Collocations are two or more words that frequently appear together (best friend, make breakfast, save time). Such phrases can be extracted with the help of nltk.collocations.\n",
    "\n",
    "Another task is part-of-speech tagging. Annotation is done using the pre-trained model included in nltk. It also has tools for chunking, a procedure related to part-of-speech tagging. Through chunking, the tool can recognize groups of sentences that are syntactically related, including noun phrases. However, while chunking is helpful in some regards, it cannot provide a comprehensive understanding of a text's syntactic structure. Parsing is necessary for a more in-depth analysis of a text's syntactic organization. Additionally, NLTK includes a module for generating tree representations of the inner sentence structures.\n",
    "\n",
    "Another thing that NLTK can do is text classification and clustering for fundamental machine learning. To evaluate the performance of your NLP tasks, use the evaluation metrics provided in NLTK.\n",
    "\n",
    "Last but not least, NLTK has ways of statistical counting. Most of them are included in the FreqDist class of the nltk.probabilitymodule. For example, you can learn about word frequency distributions in your text.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
