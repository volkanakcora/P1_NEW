{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support', 'marketing', 'technical', 'hr', 'support', 'sales', 'hr', 'support', 'technical', 'technical']\n",
      "10909\n",
      "[[0.94, 0.93], [0.87, 0.72], [0.56, 0.36]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# scroll down to the bottom to implement your solution\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists('../Data'):\n",
    "        os.mkdir('../Data')\n",
    "\n",
    "    # Download data if it is unavailable.\n",
    "    if ('A_office_data.xml' not in os.listdir('.') and\n",
    "        'B_office_data.xml' not in os.listdir('.') and\n",
    "        'hr_data.xml' not in os.listdir('../Data')):\n",
    "        print('A_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/jpeknyzx57c4jb2/A_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/A_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('B_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/hea0tbhir64u9t5/B_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/B_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('hr_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/u6jzqqg1byajy0s/hr_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/hr_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        # All data in now loaded to the Data folder.\n",
    "\n",
    "    # write your code here\n",
    "    a_office_data = pd.read_xml('A_office_data.xml')\n",
    "    b_office_data = pd.read_xml('B_office_data.xml')\n",
    "    hr_data = pd.read_xml('hr_data.xml')\n",
    "\n",
    "    #A office data\n",
    "    a_office_data['a_new_column'] = a_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('A', x))\n",
    "    a_office_data.index=a_office_data['a_new_column']\n",
    "    a_office_data.drop('a_new_column', axis=1)\n",
    "    a_office_data.index.name = None \n",
    "\n",
    "    # B office data\n",
    "    b_office_data['a_new_column'] = b_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('B', x))\n",
    "    b_office_data.index=b_office_data['a_new_column']\n",
    "    b_office_data.drop('a_new_column', axis=1)\n",
    "    b_office_data.index.name = None \n",
    "\n",
    "    # HR Data\n",
    "    hr_data=hr_data.set_index('employee_id')\n",
    "\n",
    "    unified_team_data = pd.concat([a_office_data, b_office_data])\n",
    "    final_data = unified_team_data.merge(hr_data, right_index=True, left_index=True, how='left', indicator=True)\n",
    "    final_data=final_data[final_data['_merge']=='both']\n",
    "    final_data.drop(columns=[\"_merge\", \"employee_office_id\", \"a_new_column\"], inplace=True)\n",
    "    final_data=final_data.sort_index()\n",
    "\n",
    "\n",
    "    #First question:\n",
    "    # What are the departments of the top ten employees in terms of working hours?\n",
    "    first_question = final_data.sort_values('average_monthly_hours', ascending=False).head(10)\n",
    "    print(first_question['Department'].tolist())\n",
    "\n",
    "    #Second question:\n",
    "    # What is the total number of projects on which IT department employees with low salaries have worked?\n",
    "    second_question = final_data[final_data['salary'] == 'low']\n",
    "    second_question = second_question[['Department',\"salary\",\"number_project\"]].sum()['number_project']\n",
    "    print(second_question)\n",
    "\n",
    "    #Third question:\n",
    "    #What are the last evaluation scores and the satisfaction levels of the employees A4, B7064, and A3033?\n",
    "    third_question = final_data[['last_evaluation', 'satisfaction_level']]\n",
    "    employees = third_question[(third_question.index == 'A4') | (third_question.index == 'B7064') | (third_question.index == 'A3033')]\n",
    "    selected_columns = ['last_evaluation', 'satisfaction_level']\n",
    "    data_subset = employees[selected_columns]\n",
    "\n",
    "    num_rows = len(data_subset)\n",
    "\n",
    "    formatted_rows = []\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        row = data_subset.iloc[i]\n",
    "        formatted_row = list(row)\n",
    "        formatted_rows.append(formatted_row)\n",
    "\n",
    "    print(formatted_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_860/1237317333.py:37: FutureWarning: Passing literal xml to 'read_xml' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  a_office_data = pd.read_xml('../Data/A_office_data.xml')\n"
     ]
    },
    {
     "ename": "XMLSyntaxError",
     "evalue": "Start tag expected, '<' not found, line 1, column 1 (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[6], line 37\u001b[0m\n    a_office_data = pd.read_xml('../Data/A_office_data.xml')\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/xml.py:1132\u001b[0m in \u001b[1;35mread_xml\u001b[0m\n    return _parse(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/xml.py:852\u001b[0m in \u001b[1;35m_parse\u001b[0m\n    data_dicts = p.parse_data()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/xml.py:556\u001b[0m in \u001b[1;35mparse_data\u001b[0m\n    self.xml_doc = self._parse_doc(self.path_or_buffer)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/xml.py:647\u001b[0m in \u001b[1;35m_parse_doc\u001b[0m\n    document = fromstring(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/etree.pyx:3257\u001b[0m in \u001b[1;35mlxml.etree.fromstring\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/parser.pxi:1916\u001b[0m in \u001b[1;35mlxml.etree._parseMemoryDocument\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/parser.pxi:1803\u001b[0m in \u001b[1;35mlxml.etree._parseDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/parser.pxi:1144\u001b[0m in \u001b[1;35mlxml.etree._BaseParser._parseDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/parser.pxi:618\u001b[0m in \u001b[1;35mlxml.etree._ParserContext._handleParseResultDoc\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32msrc/lxml/parser.pxi:728\u001b[0m in \u001b[1;35mlxml.etree._handleParseResult\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32msrc/lxml/parser.pxi:657\u001b[0;36m in \u001b[0;35mlxml.etree._raiseParseError\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Start tag expected, '<' not found, line 1, column 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# scroll down to the bottom to implement your solution\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists('../Data'):\n",
    "        os.mkdir('../Data')\n",
    "\n",
    "    # Download data if it is unavailable.\n",
    "    if ('A_office_data.xml' not in os.listdir('.') and\n",
    "            'B_office_data.xml' not in os.listdir('.') and\n",
    "            'hr_data.xml' not in os.listdir('../Data')):\n",
    "        print('A_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/jpeknyzx57c4jb2/A_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/A_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('B_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/hea0tbhir64u9t5/B_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/B_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('hr_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/u6jzqqg1byajy0s/hr_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('../Data/hr_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        # All data in now loaded to the Data folder.\n",
    "\n",
    "    # write your code here\n",
    "    a_office_data = pd.read_xml('../Data/A_office_data.xml')\n",
    "    b_office_data = pd.read_xml('../Data/B_office_data.xml')\n",
    "    hr_data = pd.read_xml('../Data/hr_data.xml')\n",
    "\n",
    "    # A office data\n",
    "    a_office_data['a_new_column'] = a_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('A', x))\n",
    "    a_office_data.index = a_office_data['a_new_column']\n",
    "    a_office_data.drop('a_new_column', axis=1)\n",
    "    a_office_data.index.name = None\n",
    "\n",
    "    # B office data\n",
    "    b_office_data['a_new_column'] = b_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('B', x))\n",
    "    b_office_data.index = b_office_data['a_new_column']\n",
    "    b_office_data.drop('a_new_column', axis=1)\n",
    "    b_office_data.index.name = None\n",
    "\n",
    "    # HR Data\n",
    "    hr_data = hr_data.set_index('employee_id')\n",
    "\n",
    "    unified_team_data = pd.concat([a_office_data, b_office_data])\n",
    "    final_data = unified_team_data.merge(hr_data, right_index=True, left_index=True, how='left', indicator=True)\n",
    "    final_data = final_data[final_data['_merge'] == 'both']\n",
    "    final_data.drop(columns=[\"_merge\", \"employee_office_id\", \"a_new_column\"], inplace=True)\n",
    "    final_data = final_data.sort_index()\n",
    "\n",
    "    df = final_data.copy()\n",
    "\n",
    "\n",
    "    def count_bigger_5(data):\n",
    "        return (data > 5).sum()\n",
    "\n",
    "    result = df.groupby('left').agg({\n",
    "        'number_project': [('median', 'median'), ('count_bigger_5', count_bigger_5)],\n",
    "        'time_spend_company': ['mean', 'median'],\n",
    "        'Work_accident': ['mean'],\n",
    "        'last_evaluation': ['mean', 'std']\n",
    "    })\n",
    "\n",
    "    result = result.round(2)\n",
    "    print(result.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Departments:\n",
      "{(0.0, 'high'): {'IT': 193.0, 'management': 196.0, 'marketing': 173.0, 'product_mng': 172.0, 'sales': 190.0, 'support': 214.0, 'technical': 193.0}, (0.0, 'low'): {'IT': 198.5, 'management': 208.0, 'marketing': 199.5, 'product_mng': 198.5, 'sales': 198.0, 'support': 194.5, 'technical': 197.0}, (0.0, 'medium'): {'IT': 199.0, 'management': 201.0, 'marketing': 185.0, 'product_mng': 202.0, 'sales': 198.0, 'support': 196.0, 'technical': 202.0}, (1.0, 'high'): {'IT': 155.0, 'management': 259.0, 'marketing': 148.5, 'product_mng': 149.0, 'sales': 241.5, 'support': 237.0, 'technical': 157.5}, (1.0, 'low'): {'IT': 235.0, 'management': 230.5, 'marketing': 155.0, 'product_mng': 218.0, 'sales': 224.5, 'support': 219.0, 'technical': 244.0}, (1.0, 'medium'): {'IT': 198.0, 'management': 235.0, 'marketing': 157.0, 'product_mng': 154.5, 'sales': 225.0, 'support': 221.0, 'technical': 232.0}}\n",
      "Second Pivot Table:\n",
      "{('last_evaluation', 'max', 0): {2: 0.97, 3: 0.99, 4: 0.97, 5: 0.99, 6: 0.99, 7: 0.9, 8: 0.85, 10: 0.85}, ('last_evaluation', 'mean', 0): {2: 0.62, 3: 0.59, 4: 0.67, 5: 0.74, 6: 0.67, 7: 0.58, 8: 0.62, 10: 0.62}, ('last_evaluation', 'min', 0): {2: 0.37, 3: 0.36, 4: 0.36, 5: 0.38, 6: 0.37, 7: 0.38, 8: 0.4, 10: 0.37}, ('satisfaction_level', 'mean', 0): {2: 0.69, 3: 0.61, 4: 0.49, 5: 0.57, 6: 0.56, 7: 0.71, 8: 0.66, 10: 0.68}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# scroll down to the bottom to implement your solution\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists('../Data'):\n",
    "        os.mkdir('../Data')\n",
    "\n",
    "    # Download data if it is unavailable.\n",
    "    if ('A_office_data.xml' not in os.listdir('.') and\n",
    "        'B_office_data.xml' not in os.listdir('.') and\n",
    "        'hr_data.xml' not in os.listdir('../Data')):\n",
    "        print('A_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/jpeknyzx57c4jb2/A_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('A_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('B_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/hea0tbhir64u9t5/B_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('B_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('hr_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/u6jzqqg1byajy0s/hr_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('hr_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        # All data in now loaded to the Data folder.\n",
    "\n",
    "    # write your code here\n",
    "    a_office_data = pd.read_xml('A_office_data.xml')\n",
    "    b_office_data = pd.read_xml('B_office_data.xml')\n",
    "    hr_data = pd.read_xml('hr_data.xml')\n",
    "\n",
    "    # A office data\n",
    "    a_office_data['a_new_column'] = a_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('A', x))\n",
    "    a_office_data.index = a_office_data['a_new_column']\n",
    "    a_office_data.drop('a_new_column', axis=1)\n",
    "    a_office_data.index.name = None\n",
    "\n",
    "    # B office data\n",
    "    b_office_data['a_new_column'] = b_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('B', x))\n",
    "    b_office_data.index = b_office_data['a_new_column']\n",
    "    b_office_data.drop('a_new_column', axis=1)\n",
    "    b_office_data.index.name = None\n",
    "\n",
    "    # HR Data\n",
    "    hr_data = hr_data.set_index('employee_id')\n",
    "\n",
    "    unified_team_data = pd.concat([a_office_data, b_office_data])\n",
    "    final_data = unified_team_data.merge(hr_data, right_index=True, left_index=True, how='left', indicator=True)\n",
    "    final_data = final_data[final_data['_merge'] == 'both']\n",
    "    final_data.drop(columns=[\"_merge\", \"employee_office_id\", \"a_new_column\"], inplace=True)\n",
    "    final_data = final_data.sort_index()\n",
    "\n",
    "    df = final_data.copy()\n",
    "    #Firs question part 5 \n",
    "    # Generate the first pivot table\n",
    "    first_pivot_table = df.pivot_table(index='Department', columns=['left', 'salary'], values='average_monthly_hours', aggfunc='median')\n",
    "\n",
    "    # Filter the pivot table based on the given conditions\n",
    "    filtered_departments = first_pivot_table[((first_pivot_table[0.0]['high'] < first_pivot_table[0.0]['medium']) & (first_pivot_table.index.isin(df[df['left'] == 0]['Department']))) |\n",
    "                                            ((first_pivot_table[1.0]['low'] < first_pivot_table[1.0]['high']) & (first_pivot_table.index.isin(df[df['left'] == 1]['Department'])))]\n",
    "\n",
    "    print(filtered_departments.to_dict())\n",
    " \n",
    "    \n",
    "    #Second question:\n",
    "    # Calculate the previous mean evaluation score for each employee\n",
    "    df['previous_mean_evaluation_score'] = df.groupby('time_spend_company')['last_evaluation'].shift()\n",
    "\n",
    "    # Filter the data based on the condition\n",
    "    filtered_df = df[df['promotion_last_5years'] == 0]  # Select rows without promotion\n",
    "    filtered_df = filtered_df[filtered_df['previous_mean_evaluation_score'] > filtered_df.groupby('time_spend_company')['previous_mean_evaluation_score'].shift(-1)]\n",
    "\n",
    "    # Generate the second pivot table\n",
    "    second_pivot_table = filtered_df.pivot_table(index='time_spend_company', columns='promotion_last_5years',\n",
    "                                                values=['last_evaluation', 'satisfaction_level'],\n",
    "                                                aggfunc={'last_evaluation': ['min', 'max', 'mean'], 'satisfaction_level': 'mean'})\n",
    "\n",
    "    # Round all the numbers to two decimals\n",
    "    second_pivot_table = second_pivot_table.round(2)\n",
    "\n",
    "    # Convert the resulting DataFrame to Python dictionaries\n",
    "    second_pivot_dict = second_pivot_table.to_dict()\n",
    "\n",
    "    print(second_pivot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Pivot Table as Dictionary:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean evaluation scores for employees with and without promotions\n",
    "mean_eval_promoted = df[df['promotion_last_5years'] == 1].groupby('time_spend_company')['last_evaluation'].mean()\n",
    "mean_eval_not_promoted = df[df['promotion_last_5years'] == 0].groupby('time_spend_company')['last_evaluation'].mean()\n",
    "\n",
    "# Filter the DataFrame to include only rows where mean evaluation score for not promoted employees is higher\n",
    "filtered_index = mean_eval_not_promoted[mean_eval_not_promoted > mean_eval_promoted].index\n",
    "filtered_df = df[df.index.get_level_values(0).isin(filtered_index)]\n",
    "\n",
    "# Generate the second pivot table\n",
    "second_pivot_table = filtered_df.pivot_table(index='time_spend_company', columns='promotion_last_5years',\n",
    "                                             values=['last_evaluation', 'satisfaction_level'],\n",
    "                                             aggfunc={'last_evaluation': ['min', 'max', 'mean'],\n",
    "                                                      'satisfaction_level': 'mean'})\n",
    "\n",
    "# Convert to Python dictionary\n",
    "second_pivot_table_dict = second_pivot_table.to_dict()\n",
    "\n",
    "print(\"Second Pivot Table as Dictionary:\")\n",
    "print(second_pivot_table_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Pivot Table as Dictionary:\n",
      "{('last_evaluation', 'max', 0): {2: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 10: 1.0}, ('last_evaluation', 'max', 1): {2: 0.99, 4: 0.9, 5: 0.91, 6: 0.71, 10: 0.94}, ('last_evaluation', 'mean', 0): {2: 0.7162919594067135, 4: 0.7653705583756345, 5: 0.8199675324675325, 6: 0.7656206896551724, 10: 0.7206578947368422}, ('last_evaluation', 'mean', 1): {2: 0.69125, 4: 0.7475, 5: 0.6075, 6: 0.515, 10: 0.63}, ('last_evaluation', 'min', 0): {2: 0.37, 4: 0.36, 5: 0.38, 6: 0.37, 10: 0.37}, ('last_evaluation', 'min', 1): {2: 0.52, 4: 0.42, 5: 0.37, 6: 0.38, 10: 0.48}, ('satisfaction_level', 'max', 0): {2: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 10: 0.99}, ('satisfaction_level', 'max', 1): {2: 0.94, 4: 0.94, 5: 0.82, 6: 0.81, 10: 0.85}, ('satisfaction_level', 'mean', 0): {2: 0.7008743169398908, 4: 0.4772994923857868, 5: 0.6164448051948053, 6: 0.587448275862069, 10: 0.6576315789473683}, ('satisfaction_level', 'mean', 1): {2: 0.646875, 4: 0.6016666666666667, 5: 0.66, 6: 0.623, 10: 0.50875}, ('satisfaction_level', 'min', 0): {2: 0.09, 4: 0.09, 5: 0.09, 6: 0.12, 10: 0.14}, ('satisfaction_level', 'min', 1): {2: 0.29, 4: 0.15, 5: 0.23, 6: 0.48, 10: 0.22}, ('max', 'last_evaluation', 0): {2: None, 4: None, 5: None, 6: None, 10: None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_860/4289274918.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_second_pivot_table[('max', 'last_evaluation', 0)] = None\n"
     ]
    }
   ],
   "source": [
    "# Generate the second pivot table\n",
    "second_pivot_table = df.pivot_table(index='time_spend_company', columns='promotion_last_5years',\n",
    "                                    values=['last_evaluation', 'satisfaction_level'],\n",
    "                                    aggfunc={'last_evaluation': ['min', 'max', 'mean'],\n",
    "                                             'satisfaction_level': ['min', 'max', 'mean']})\n",
    "\n",
    "# Filter the pivot table based on the given condition\n",
    "filtered_second_pivot_table = second_pivot_table[\n",
    "    second_pivot_table[('last_evaluation', 'mean', 0)] >\n",
    "    second_pivot_table[('last_evaluation', 'mean', 1)]]\n",
    "\n",
    "# Check if the missing key exists in the filtered pivot table and add it if not present\n",
    "if ('max', 'last_evaluation', 0) not in filtered_second_pivot_table:\n",
    "    filtered_second_pivot_table[('max', 'last_evaluation', 0)] = None\n",
    "\n",
    "# Convert the filtered pivot table to dictionary\n",
    "filtered_second_pivot_dict = filtered_second_pivot_table.to_dict()\n",
    "\n",
    "print(\"Second Pivot Table as Dictionary:\")\n",
    "print(filtered_second_pivot_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Pivot Table as Dictionary:\n",
      "{('max', 'last_evaluation', 0): {2: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 10: 1.0}, ('max', 'last_evaluation', 1): {2: 0.99, 4: 0.9, 5: 0.91, 6: 0.71, 10: 0.94}, ('max', 'satisfaction_level', 0): {2: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 10: 0.99}, ('max', 'satisfaction_level', 1): {2: 0.94, 4: 0.94, 5: 0.82, 6: 0.81, 10: 0.85}, ('mean', 'last_evaluation', 0): {2: 0.7162919594067135, 4: 0.7653705583756345, 5: 0.8199675324675325, 6: 0.7656206896551724, 10: 0.7206578947368422}, ('mean', 'last_evaluation', 1): {2: 0.69125, 4: 0.7475, 5: 0.6075, 6: 0.515, 10: 0.63}, ('mean', 'satisfaction_level', 0): {2: 0.7008743169398908, 4: 0.4772994923857868, 5: 0.6164448051948053, 6: 0.587448275862069, 10: 0.6576315789473683}, ('mean', 'satisfaction_level', 1): {2: 0.646875, 4: 0.6016666666666667, 5: 0.66, 6: 0.623, 10: 0.50875}, ('min', 'last_evaluation', 0): {2: 0.37, 4: 0.36, 5: 0.38, 6: 0.37, 10: 0.37}, ('min', 'last_evaluation', 1): {2: 0.52, 4: 0.42, 5: 0.37, 6: 0.38, 10: 0.48}, ('min', 'satisfaction_level', 0): {2: 0.09, 4: 0.09, 5: 0.09, 6: 0.12, 10: 0.14}, ('min', 'satisfaction_level', 1): {2: 0.29, 4: 0.15, 5: 0.23, 6: 0.48, 10: 0.22}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# scroll down to the bottom to implement your solution\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists('../Data'):\n",
    "        os.mkdir('../Data')\n",
    "\n",
    "    # Download data if it is unavailable.\n",
    "    if ('A_office_data.xml' not in os.listdir('.') and\n",
    "            'B_office_data.xml' not in os.listdir('.') and\n",
    "            'hr_data.xml' not in os.listdir('../Data')):\n",
    "        print('A_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/jpeknyzx57c4jb2/A_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('A_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('B_office_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/hea0tbhir64u9t5/B_office_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('B_office_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('hr_data loading.')\n",
    "        url = \"https://www.dropbox.com/s/u6jzqqg1byajy0s/hr_data.xml?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open('hr_data.xml', 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        # All data in now loaded to the Data folder.\n",
    "\n",
    "    # write your code here\n",
    "    a_office_data = pd.read_xml('../Data/A_office_data.xml')\n",
    "    b_office_data = pd.read_xml('../Data/B_office_data.xml')\n",
    "    hr_data = pd.read_xml('../Data/hr_data.xml')\n",
    "\n",
    "    # A office data\n",
    "    a_office_data['a_new_column'] = a_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('A', x))\n",
    "    a_office_data.index = a_office_data['a_new_column']\n",
    "    a_office_data.drop('a_new_column', axis=1)\n",
    "    a_office_data.index.name = None\n",
    "\n",
    "    # B office data\n",
    "    b_office_data['a_new_column'] = b_office_data['employee_office_id'].apply(lambda x: \"{}{}\".format('B', x))\n",
    "    b_office_data.index = b_office_data['a_new_column']\n",
    "    b_office_data.drop('a_new_column', axis=1)\n",
    "    b_office_data.index.name = None\n",
    "\n",
    "    # HR Data\n",
    "    hr_data = hr_data.set_index('employee_id')\n",
    "\n",
    "    unified_team_data = pd.concat([a_office_data, b_office_data])\n",
    "    final_data = unified_team_data.merge(hr_data, right_index=True, left_index=True, how='left', indicator=True)\n",
    "    final_data = final_data[final_data['_merge'] == 'both']\n",
    "    final_data.drop(columns=[\"_merge\", \"employee_office_id\", \"a_new_column\"], inplace=True)\n",
    "    final_data = final_data.sort_index()\n",
    "\n",
    "    df = final_data.copy()\n",
    "    # Firs question part 5\n",
    "    # Generate the first pivot table\n",
    "    first_pivot_table = df.pivot_table(index='Department', columns=['left', 'salary'], values='average_monthly_hours',\n",
    "                                       aggfunc='median')\n",
    "\n",
    "    # Filter the pivot table based on the given conditions\n",
    "    filtered_departments = first_pivot_table[((first_pivot_table[0.0]['high'] < first_pivot_table[0.0]['medium']) & (\n",
    "        first_pivot_table.index.isin(df[df['left'] == 0]['Department']))) |\n",
    "                                             ((first_pivot_table[1.0]['low'] < first_pivot_table[1.0]['high']) & (\n",
    "                                                 first_pivot_table.index.isin(df[df['left'] == 1]['Department'])))]\n",
    "\n",
    "    print(filtered_departments.to_dict())\n",
    "\n",
    "    # Second question:\n",
    "    # Filter the data based on the condition\n",
    "    # Calculate mean evaluation scores for employees with and without promotions\n",
    "    # Generate the second pivot table\n",
    "    # Generate the second pivot table\n",
    "    # Generate the second pivot table\n",
    "    # Generate the second pivot table\n",
    "    second_pivot_table = df.pivot_table(index='time_spend_company', columns='promotion_last_5years',\n",
    "                                        values=['last_evaluation', 'satisfaction_level'],\n",
    "                                        aggfunc={'last_evaluation': ['min', 'max', 'mean'],\n",
    "                                                 'satisfaction_level': ['min', 'max', 'mean']})\n",
    "\n",
    "    # Filter the pivot table based on the given condition\n",
    "    filtered_second_pivot_table = second_pivot_table[\n",
    "        second_pivot_table[('last_evaluation', 'mean', 0)] >\n",
    "        second_pivot_table[('last_evaluation', 'mean', 1)]]\n",
    "\n",
    "    # Extract necessary elements from the filtered pivot table\n",
    "    filtered_second_pivot_dict = {\n",
    "        ('max', 'last_evaluation', 0): filtered_second_pivot_table[('last_evaluation', 'max', 0)].to_dict(),\n",
    "        ('max', 'last_evaluation', 1): filtered_second_pivot_table[('last_evaluation', 'max', 1)].to_dict(),\n",
    "        ('max', 'satisfaction_level', 0): filtered_second_pivot_table[('satisfaction_level', 'max', 0)].to_dict(),\n",
    "        ('max', 'satisfaction_level', 1): filtered_second_pivot_table[('satisfaction_level', 'max', 1)].to_dict(),\n",
    "        ('mean', 'last_evaluation', 0): filtered_second_pivot_table[('last_evaluation', 'mean', 0)].to_dict(),\n",
    "        ('mean', 'last_evaluation', 1): filtered_second_pivot_table[('last_evaluation', 'mean', 1)].to_dict(),\n",
    "        ('mean', 'satisfaction_level', 0): filtered_second_pivot_table[('satisfaction_level', 'mean', 0)].to_dict(),\n",
    "        ('mean', 'satisfaction_level', 1): filtered_second_pivot_table[('satisfaction_level', 'mean', 1)].to_dict(),\n",
    "        ('min', 'last_evaluation', 0): filtered_second_pivot_table[('last_evaluation', 'min', 0)].to_dict(),\n",
    "        ('min', 'last_evaluation', 1): filtered_second_pivot_table[('last_evaluation', 'min', 1)].to_dict(),\n",
    "        ('min', 'satisfaction_level', 0): filtered_second_pivot_table[('satisfaction_level', 'min', 0)].to_dict(),\n",
    "        ('min', 'satisfaction_level', 1): filtered_second_pivot_table[('satisfaction_level', 'min', 1)].to_dict()\n",
    "    }\n",
    "\n",
    "    print(filtered_second_pivot_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
