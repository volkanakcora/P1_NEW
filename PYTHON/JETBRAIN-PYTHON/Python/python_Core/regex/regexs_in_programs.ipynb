{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regexs in programs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are very versatile. They can be used to automate many tedious text-related tasks, such as input text validation or data collection. In this topic, we will have a look at two examples of simple yet powerful programs that employ regular expressions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email validation program\n",
    "\n",
    "Let's have a look at a basic program that checks whether the text contains email addresses and, if it does, returns them in sequential order:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_emails(string):\n",
    "    # Here we compile our simple pattern that will match email addresses\n",
    "    pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "\n",
    "    # Remember that re.findall() returns a list of all matched email strings\n",
    "    emails = re.findall(pattern, string) \n",
    "\n",
    "    # To print the matched strings one by one\n",
    "    for email in emails:\n",
    "        print(email)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program above carries out a rather simple check. It checks if the @ character is preceded and followed by alphanumeric characters, an underscore, and a dot. Mind that \\w is equal to [A-Za-z0-9_].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billy123@something.com\n",
      "alice_2000@website.com\n",
      "johnnY.b@blahblahblah.com\n"
     ]
    }
   ],
   "source": [
    "'Lets test our program:'\n",
    "\n",
    "# Suppose we have a text with various email addresses\n",
    "string = '''cat billy123@something.com, dog 456 \n",
    "          alice_2000@website.com johnnY.b@blahblahblah.com'''\n",
    "find_emails(string)\n",
    "# billy123@something.com\n",
    "# alice_2000@website.com\n",
    "# johnnY.b@blahblahblah.com\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside is that our program will also match strings like _@._. They obviously cannot be considered email addresses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email validation 2.0\n",
    "If usernames and domain names are too short, it may lead to rather bad scenarios. We can set some restrictions when compiling our pattern to avoid this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want the username to be at least 5 characters long \n",
    "# and the domain name of 2 to 4 characters \n",
    "pattern = re.compile(r'[\\w\\.-]{5,}@[\\w-]+\\.\\w{2,4}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break it down piece by piece:\n",
    "\n",
    "- [\\w\\.-]{5,} matches alphanumeric characters, underscores, a dot, or a dash that appear at least 5 times;\n",
    "- @ matches the @ sign;\n",
    "- [\\w-]+\\. matches alphanumeric characters, underscores, or a dash followed by a dot;\n",
    "- \\w{2,4} matches alphanumeric characters and underscores that appear 2-4 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's our final program:\n",
    "\n",
    "def find_emails(string):\n",
    "    # Here we compile our simple pattern that will match email addresses\n",
    "    pattern = re.compile(r'[\\w\\.-]{5,}@[\\w-]+\\.[\\w]{2,4}')\n",
    "\n",
    "    # Remember that re.findall() returns a list of all matched email strings\n",
    "    emails = re.findall(pattern, string) \n",
    "\n",
    "    # To print the matched strings one by one\n",
    "    for email in emails:\n",
    "        print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billy123@something.com\n",
      "alice_2000@website.com\n",
      "johnnY.b@blahblahblah.com\n"
     ]
    }
   ],
   "source": [
    "string = '''_@._ mary_liu@abc._ billy123@something.com, dog 456 \n",
    "            alice_2000@website.com johnnY.b@blahblahblah.com one@one.one'''\n",
    "find_emails(string)\n",
    "# billy123@something.com\n",
    "# alice_2000@website.com\n",
    "# johnnY.b@blahblahblah.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "As you may already know, text preprocessing plays a crucial role with textual data. Tokenization or splitting text into smaller units (usually words) is the first step in text processing. Text tokenization can go smoother with regular expressions if you don't want to use other special tools.\n",
    "\n",
    "The most straightforward approach to tokenization is to split a text by whitespaces. Let's see how it works:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(string):\n",
    "    tokens = re.split('\\s+', string)\n",
    "    return tokens\n",
    "\n",
    "string = \"This is a sample string. (And here's another one!!)\"\n",
    "tokenize(string)\n",
    "# ['This', 'is', 'a', 'sample', 'string.', '(And', \"here's\", 'another', 'one!!)']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After giving it a thorough look, you can spot the elephant in the room â€” punctuation marks. Let's get rid of them before we split our sentence:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_@_ mary_liu@abc_ billy123@somethingcom dog 456 \n",
      "            alice_2000@websitecom johnnYb@blahblahblahcom one@oneone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_@_',\n",
       " 'mary_liu@abc_',\n",
       " 'billy123@somethingcom',\n",
       " 'dog',\n",
       " '456',\n",
       " 'alice_2000@websitecom',\n",
       " 'johnnYb@blahblahblahcom',\n",
       " 'one@oneone']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(string):\n",
    "    # Let's create a pattern that contains punctuation marks\n",
    "    punctuation = re.compile(r'[\\.,\\?!\\*:;()]')\n",
    "\n",
    "    # Substitute the punctuations with empty strings\n",
    "    no_punct = re.sub(punctuation, '', string)\n",
    "    print(no_punct)\n",
    "    # This is a sample string And here's another one\n",
    "\n",
    "    # Split sentences by whitespaces\n",
    "    tokens = re.split('\\s+', no_punct)\n",
    "    return tokens\n",
    "\n",
    "tokenize(string)\n",
    "# ['This', 'is', 'a', 'sample', 'string', 'And', \"here's\", 'another', 'one']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not omitted the apostrophe ' in the punctuation mark list. This is quite important as we do not want to split words like Let's, here's, or Mary's into two different tokens and change their meaning.\n",
    "\n",
    "As you can see, tokenization can be a bit tricky, but regex can help you with it. Of course, there are a lot of ways to tokenize a text depending on the text type you are dealing with. We have presented you with one of the simplest ways to do it.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which of the following patterns can be used to check whether a given vehicle license plate number is valid? Let's assume that a standard plate is of the following format: ABC-1234.\n",
    "\n",
    "\n",
    "### re.compile(r'[A-Z]{3}-\\d{4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
