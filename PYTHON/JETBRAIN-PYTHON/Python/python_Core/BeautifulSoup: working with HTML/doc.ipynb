{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the content formatted for a Jupyter notebook in Markdown:\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install BeautifulSoup, you need a Python package manager, `pip`.\n",
    "\n",
    "```sh\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "Also, you need the `requests` library to send HTTP requests. It can also be installed using `pip`.\n",
    "\n",
    "```sh\n",
    "pip install requests\n",
    "```\n",
    "\n",
    "Do not forget to import these libraries before starting your work.\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "```\n",
    "\n",
    "## Getting Started with Web Scraping\n",
    "\n",
    "First, we need to create a variable that will store the content of the page. To do so, use `requests.get()` with a link as an attribute.\n",
    "\n",
    "```python\n",
    "r = requests.get('https://www.newsinlevels.com/products/albino-tortoise-level-1/')\n",
    "```\n",
    "\n",
    "To check whether the page was downloaded successfully, you can use `status_code`. If the returned code is 200, there are no errors. If your code is 400 or 500, there are some difficulties with getting the page.\n",
    "\n",
    "```python\n",
    "print(r.status_code)  # 200\n",
    "```\n",
    "\n",
    "Then we use `BeautifulSoup()` class to create a parse tree of our page.\n",
    "\n",
    "```python\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "```\n",
    "\n",
    "There are two parameters: `r.content` is the data of the page, and `html.parser` is a parser included in the standard Python library. You can install additional parsers like `lxml` via pip and use them instead of the `html.parser`. The `lxml` parser is used for swift processing.\n",
    "\n",
    "The result of the procedure is a tree. You can use the `prettify()` method to turn your tree into a nicely formatted string.\n",
    "\n",
    "```python\n",
    "print(soup.prettify())\n",
    "```\n",
    "\n",
    "```html\n",
    "# <!DOCTYPE html>\n",
    "# <html lang=\"en-US\">\n",
    "#  <head>\n",
    "#   <script data-cfasync=\"false\" data-ezscrex=\"false\" data-pagespeed-no-defer=\"\">\n",
    "# ...\n",
    "```\n",
    "\n",
    "## Searching for Tags\n",
    "\n",
    "As far as you can see, the content stored in the variable `soup` is hard to follow, plus it contains a lot of unnecessary information that we do not need. Important data like texts or titles are often stored with particular tags. So, once you have decided which tags you need, there are two useful methods for finding these tags in your tree.\n",
    "\n",
    "### `find()` Method\n",
    "\n",
    "The `find()` method returns the first occurrence of the tag in the tree. This method is suitable if you are sure that your document has only one specific tag you need.\n",
    "\n",
    "```python\n",
    "p1 = soup.find('title')  \n",
    "print(p1)  # <title>Albino tortoise – level 1 - News in Levels</title>\n",
    "```\n",
    "\n",
    "### `find_all()` Method\n",
    "\n",
    "The `find_all()` method returns the list of all the results with the tag you are searching for.\n",
    "\n",
    "```python\n",
    "p2 = soup.find_all('p')\n",
    "print(p2)\n",
    "\n",
    "# [<p>09-06-2022 07:00</p>, <p>Albinism means that a person or animal has no pigment. Pigment is a thing which makes the color in our hair and skin. <strong>Albino</strong> people usually have white hair and skin.</p>, ...]\n",
    "```\n",
    "\n",
    "If the specified tags have not been found, the `find()` method returns `None` and `find_all()` returns an empty list.\n",
    "\n",
    "We can also specify our tag using supplementary attributes: class, style, and so on. The typical structure of such specification is shown below.\n",
    "\n",
    "```python\n",
    "p3 = soup.find_all('p', {'style': 'text-align: center;'})\n",
    "print(p3)\n",
    "\n",
    "# [<p style=\"text-align: center;\"><strong><span style=\"color:#006699;\"><span style=\"font-size: 18px;\"><span style=\"line-height: 21px;\">Get the App</span></span></span></strong></p>, <p style=\"text-align: center;\">© 2022, All rights reserved.</p>, ...]\n",
    "```\n",
    "\n",
    "We have changed our variable a little bit by adding the second parameter, a dictionary specifying the text style of elements. The keys of this dictionary are attributes of tags.\n",
    "\n",
    "Another method connected with tag searching is `soup.<tag>` where `<tag>` is any tag you may need to find. This structure returns all the content between an opening tag and a closing tag. In the next example, the result is the content between `<head>` and `</head>`:\n",
    "\n",
    "```python\n",
    "print(soup.head)\n",
    "# <head><script data-cfasync=\"false\" ...\n",
    "```\n",
    "\n",
    "If there are several tags with the same name, the method will return only the first occurrence.\n",
    "\n",
    "## Text and Link Extraction\n",
    "\n",
    "Now we know some basics of HTML and BeautifulSoup, it is time to extract all the necessary data. Earlier, we have learned to create a variable with lists of `<p>` tags.\n",
    "\n",
    "```python\n",
    "paragraphs = soup.find_all('p', {'style': 'text-align: center;'})\n",
    "```\n",
    "\n",
    "Now, to process all tags in this list, you can use a `for` loop for iteration and the `text` method helps to get text data.\n",
    "\n",
    "```python\n",
    "for p in paragraphs:\n",
    "    print(p.text + '\\n')\n",
    "```\n",
    "\n",
    "Each `p.text` returns a text paragraph from the page.\n",
    "\n",
    "There is another helpful method that can be used to get tag attributes. Let's get hyperlinks while working with link tags. After collecting hyperlinks, we can use them for further requests and collecting related data. The developers of BeautifulSoup also allow users to extract links using the `get()` method. Just write down a quoted attribute of the tag you need to extract in round brackets.\n",
    "\n",
    "```python\n",
    "a = soup.find_all('a')\n",
    "for i in a:\n",
    "    print(i.get('href'))  # https://www.newsinlevels.com ...\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "By following these steps, you can effectively use BeautifulSoup for web scraping, allowing you to extract and process data from web pages efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "This Markdown should look clear and beautiful when rendered in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
