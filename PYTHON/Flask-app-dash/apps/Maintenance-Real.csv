Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Component/s,Due Date,Labels,Labels,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Log Work,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Cloners),Outward issue link (Cloners),Outward issue link (Copied),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Issue split),Outward issue link (Issue split),Outward issue link (Issue split),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (ACM Type),Custom field (Acceptance Criteria),Custom field (Actual End Time),Custom field (Actual Start  Time),Custom field (Affected Areas),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (Business Justification),Custom field (Change Type),Custom field (Change completion date),Custom field (Change description),Custom field (Change description),Custom field (Change description),Custom field (Change description),Custom field (Change reason),Custom field (Change risk),Custom field (Change start date),Custom field (Contact Number),Custom field (Critical Business Process),Customer Request Type,Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (Database & Journal cleanup),Custom field (Days Since Last Comment),Custom field (Delivery Due Date),Custom field (Deployment Environments),Custom field (Deployment Environments),Custom field (Deployment Environments),Custom field (Deployment Environments),Custom field (Deployment Environments),Custom field (Deployment Success),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (EPEX Project),Custom field (End Time),Custom field (Epic Link),Custom field (Estimate),Custom field (Fix Description),Custom field (Flagged),Custom field (HUPX Project),Custom field (Hosting Services Coordinator),Custom field (ICCC Invitation),Custom field (Impact),Custom field (Impact),Custom field (Impact Assessment),Custom field (Implementation Steps),Custom field (Introduction Factor),Custom field (Investigation reason),Custom field (Issue Detection Factor),Custom field (Issue Time),Custom field (M7 User),Custom field (M7A Change Description),Custom field (Merge Request Config),Custom field (Merge Request SQL),Custom field (Mitigation),Custom field (Onboarding details),Custom field (Operational categorization),Custom field (Owner),Custom field (PIR (Post Implementation Review)),Custom field (PO / ACM Approvers),Custom field (Pending reason),Custom field (Period),Custom field (Phase),Custom field (Price (excl. VAT)),Custom field (Probability),Custom field (Product),Custom field (Product),Custom field (Product Categorization),Custom field (Project Impact),Custom field (Purchasing Type),Custom field (RAID Response),Custom field (RAID type),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Reason for failed deployment),Custom field (Release Notes),Custom field (Release Notes),Custom field (Release Notes),Custom field (Release Notes),Custom field (Reproducible),Custom field (Request Category),Custom field (Request participants),Custom field (Requirement ID),Custom field (Rollback Plan),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root cause),Custom field (SAP Change),Custom field (SAP Record),Satisfaction score (out of 5),Custom field (Severity),Custom field (Shift Start Date),Custom field (Shift Type),Custom field (Source),Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Custom field (Start Time),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Story Points),Custom field (Story Points),Custom field (Story Points),Custom field (Story Points),Custom field (Team),Custom field (TechOps Customer),Custom field (TechOps Service Catalogue),Custom field (Test Coverage),Custom field (Test Instructions),Custom field (Test Result),Time Spent in Progress,Time Spent in Progress simplified,Time to approve normal change,Time to approve normal change simplified,Time to close after resolution,Time to close after resolution simplified,Time to first response,Time to first response simplified,Time to resolution,Time to resolution simplified,Custom field (Urgency),Custom field (Urgency),Custom field (Waiting on),Custom field (Workaround),Custom field (XBID Environment),Custom field (XSOP Project),Custom field (Zephyr Teststep),Custom field ([Environment]),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitCommitsReferenced),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
SLOTH - multiple errors when ingesting larger load to timescale,XP-4582,106853,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,17/Feb/21 09:21,19/Feb/21 12:30,22/Feb/21 13:26,19/Feb/21 12:30,,,,,,,,,,,,,,"Run some load on XBID and observe TimescaleDB ingestion. The agent crashes with following errors:

{code}
2021-02-17 09:13:10.843  INFO 11968 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 986 events, rate: 98.6 event(s)/sec 
2021-02-17 09:13:18.170 ERROR 11968 --- [     parallel-2] c.d.e.x.s.agent.MetricsIngestionService  : Ingestion error

reactor.core.Exceptions$OverflowException: Could not emit buffer due to lack of requests
	at reactor.core.Exceptions.failWithOverflow(Exceptions.java:233) ~[reactor-core-3.4.1.jar:3.4.1]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Assembly trace from producer [reactor.core.publisher.FluxBufferTimeout] :
	reactor.core.publisher.Flux.bufferTimeout
	com.deutscheboerse.energy.xbid.sloth.agent.MetricsIngestionService.start(MetricsIngestionService.kt:44)
Error has been observed at the following site(s):
	|_ Flux.bufferTimeout ⇢ at com.deutscheboerse.energy.xbid.sloth.agent.MetricsIngestionService.start(MetricsIngestionService.kt:44)
	|_     Flux.concatMap ⇢ at com.deutscheboerse.energy.xbid.sloth.agent.MetricsIngestionService.start(MetricsIngestionService.kt:45)
Stack trace:
		at reactor.core.Exceptions.failWithOverflow(Exceptions.java:233) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.flushCallback(FluxBufferTimeout.java:227) [reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.lambda$new$0(FluxBufferTimeout.java:158) [reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.1.jar:3.4.1]
		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_181]
		at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_181]
{code}

{code}
2021-02-17 09:13:18.172  WARN 11968 --- [tor-tcp-epoll-1] reactor.core.publisher.FluxUsingWhen     : Async resource cleanup failed after cancel

org.springframework.dao.TransientDataAccessResourceException: R2DBC rollback; Cannot exchange messages because the request queue limit is exceeded; nested exception is io.r2dbc.postgresql.client.ReactorNettyClient$RequestQueueException: Cannot exchange messages because the request queue limit is exceeded
	at org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:215) ~[spring-r2dbc-5.3.2.jar:5.3.2]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Assembly trace from producer [reactor.core.publisher.MonoOnErrorResume] :
	reactor.core.publisher.Mono.onErrorMap
	org.springframework.r2dbc.connection.R2dbcTransactionManager.doRollback(R2dbcTransactionManager.java:292)
Error has been observed at the following site(s):
	|_    Mono.onErrorMap ⇢ at org.springframework.r2dbc.connection.R2dbcTransactionManager.doRollback(R2dbcTransactionManager.java:292)
	|_                    ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.lambda$processRollback$27(AbstractReactiveTransactionManager.java:516)
	|_         Mono.defer ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:511)
	|_          Mono.then ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:511)
	|_          Mono.then ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.lambda$processRollback$28(AbstractReactiveTransactionManager.java:534)
	|_ Mono.onErrorResume ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:532)
	|_          Mono.then ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:535)
	|_          Mono.then ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.lambda$processRollback$30(AbstractReactiveTransactionManager.java:536)
	|_ Mono.onErrorResume ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:536)
	|_          Mono.then ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.processRollback(AbstractReactiveTransactionManager.java:537)
	|_                    ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.lambda$rollback$26(AbstractReactiveTransactionManager.java:497)
	|_       Mono.flatMap ⇢ at org.springframework.transaction.reactive.AbstractReactiveTransactionManager.rollback(AbstractReactiveTransactionManager.java:495)
Stack trace:
		at org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:215) ~[spring-r2dbc-5.3.2.jar:5.3.2]
		at org.springframework.r2dbc.connection.R2dbcTransactionManager.translateException(R2dbcTransactionManager.java:439) ~[spring-r2dbc-5.3.2.jar:5.3.2]
		at org.springframework.r2dbc.connection.R2dbcTransactionManager.lambda$doRollback$10(R2dbcTransactionManager.java:292) ~[spring-r2dbc-5.3.2.jar:5.3.2]
		at reactor.core.publisher.Mono.lambda$onErrorMap$29(Mono.java:3370) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Mono.lambda$onErrorResume$31(Mono.java:3460) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxPeekFuseable$PeekFuseableSubscriber.onError(FluxPeekFuseable.java:234) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onError(MonoIgnoreElements.java:83) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onError(FluxDiscardOnCancel.java:92) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onError(FluxDiscardOnCancel.java:92) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:219) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$BaseSink.error(FluxCreate.java:453) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:781) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.error(FluxCreate.java:726) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.drainLoop(FluxCreate.java:230) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.drain(FluxCreate.java:206) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.error(FluxCreate.java:182) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.lambda$addConversation$2(ReactorNettyClient.java:809) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.FluxCreate.subscribe(FluxCreate.java:94) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel.subscribe(FluxDiscardOnCancel.java:49) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel.subscribe(FluxDiscardOnCancel.java:49) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:154) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Mono.subscribe(Mono.java:4046) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:173) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Mono.subscribe(Mono.java:4046) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:173) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:157) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:127) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2346) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:169) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:54) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxFromMonoOperator.subscribe(FluxFromMonoOperator.java:83) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.cancel(FluxUsingWhen.java:342) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators.terminate(Operators.java:1222) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyMain.cancel(MonoFlatMapMany.java:131) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators.terminate(Operators.java:1222) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyMain.cancel(MonoFlatMapMany.java:131) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.cancel(FluxContextWrite.java:141) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.cancel(FluxContextWrite.java:141) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoReduceSeed$ReduceSeedSubscriber.cancel(MonoReduceSeed.java:95) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onError(FluxConcatMap.java:257) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.SerializedSubscriber.onError(SerializedSubscriber.java:124) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.flushCallback(FluxBufferTimeout.java:227) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.lambda$new$0(FluxBufferTimeout.java:158) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.1.jar:3.4.1]
		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_181]
		at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]
Caused by: io.r2dbc.postgresql.client.ReactorNettyClient$RequestQueueException: Cannot exchange messages because the request queue limit is exceeded
	at io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.lambda$addConversation$2(ReactorNettyClient.java:809) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Assembly trace from producer [reactor.core.publisher.FluxCreate] :
	reactor.core.publisher.Flux.create
	io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.addConversation(ReactorNettyClient.java:786)
Error has been observed at the following site(s):
	|_        Flux.create ⇢ at io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.addConversation(ReactorNettyClient.java:786)
	|_                    ⇢ at io.r2dbc.postgresql.client.ReactorNettyClient.exchange(ReactorNettyClient.java:222)
	|_                    ⇢ at io.r2dbc.postgresql.client.Client.exchange(Client.java:76)
	|_        Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlConnection.exchange(PostgresqlConnection.java:348)
	|_                    ⇢ at io.r2dbc.postgresql.util.Operators.discardOnCancel(Operators.java:43)
	|_         Flux.defer ⇢ at io.r2dbc.postgresql.PostgresqlConnection.useTransactionStatus(PostgresqlConnection.java:335)
	|_                    ⇢ at io.r2dbc.postgresql.util.Operators.discardOnCancel(Operators.java:43)
	|_          Flux.then ⇢ at io.r2dbc.postgresql.PostgresqlConnection.useTransactionStatus(PostgresqlConnection.java:337)
	|_                    ⇢ at io.r2dbc.postgresql.PostgresqlConnection.rollbackTransaction(PostgresqlConnection.java:218)
	|_          Mono.from ⇢ at io.r2dbc.pool.PooledConnection.rollbackTransaction(PooledConnection.java:131)
	|_ Mono.doOnSubscribe ⇢ at io.r2dbc.pool.PooledConnection.rollbackTransaction(PooledConnection.java:131)
	|_          Mono.from ⇢ at org.springframework.r2dbc.connection.R2dbcTransactionManager.doRollback(R2dbcTransactionManager.java:291)
Stack trace:
		at io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.lambda$addConversation$2(ReactorNettyClient.java:809) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.FluxCreate.subscribe(FluxCreate.java:94) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel.subscribe(FluxDiscardOnCancel.java:49) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxDefer.subscribe(FluxDefer.java:54) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalFluxOperator.subscribe(InternalFluxOperator.java:62) ~[reactor-core-3.4.1.jar:3.4.1]
		at io.r2dbc.postgresql.util.FluxDiscardOnCancel.subscribe(FluxDiscardOnCancel.java:49) ~[r2dbc-postgresql-0.8.6.RELEASE.jar:0.8.6.RELEASE]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:52) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:154) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Mono.subscribe(Mono.java:4046) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:173) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Mono.subscribe(Mono.java:4046) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.drain(MonoIgnoreThen.java:173) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoIgnoreThen.subscribe(MonoIgnoreThen.java:56) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:157) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:127) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2346) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:169) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:54) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:64) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxFromMonoOperator.subscribe(FluxFromMonoOperator.java:83) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.cancel(FluxUsingWhen.java:342) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators.terminate(Operators.java:1222) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyMain.cancel(MonoFlatMapMany.java:131) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators.terminate(Operators.java:1222) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyMain.cancel(MonoFlatMapMany.java:131) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.cancel(FluxContextWrite.java:141) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.cancel(FluxContextWrite.java:141) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.MonoReduceSeed$ReduceSeedSubscriber.cancel(MonoReduceSeed.java:95) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drainLoop(Operators.java:2211) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.drain(Operators.java:2180) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.cancel(Operators.java:1992) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onError(FluxConcatMap.java:257) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.SerializedSubscriber.onError(SerializedSubscriber.java:124) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.flushCallback(FluxBufferTimeout.java:227) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.publisher.FluxBufferTimeout$BufferTimeoutSubscriber.lambda$new$0(FluxBufferTimeout.java:158) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.1.jar:3.4.1]
		at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.1.jar:3.4.1]
		at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_181]
		at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181]
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_181]
		at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]
{code}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,259200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:9zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,Alpha Sprint 28 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/21 12:30;ll664;Again, this was problem with reactor buffering operators not respecting demand properly. In the end, I've resorted to implement simple buffer on Chronicle consumer level, which works well and servers purpose.

Also, SLOTH AWS bandwidth requirements were estimated within this tasks: https://confluence.energy.svc.dbgcloud.io/display/XBID/SLOTH+Architecture#SLOTHArchitecture-Bandwidth",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Patroni/postgresql instance failed to start after clean service stop,XP-4552,106666,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,11/Feb/21 12:23,19/Feb/21 10:26,22/Feb/21 13:26,17/Feb/21 12:02,,,,,,,,,,Patroni,TechOps,,,"During XBID 3.1 UAT Failover test scenario 1.3 - Failure DB node, we experienced issues when I stopped patroni service of async cluster on two nodes.
They failed to start and I had to run reinit on them.

I have to consult it with Cybertek and Steffen if they know why it is happening and how to fix/prevent it.",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,We will do one more test on SIMU env in the next open maintenance window.,,,,,,,,,,,,,,345600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cmps:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Feb/21 20:17;hw120;As discussed with Cybertek...
{quote}Hello, We had problem with xbid simu async instances when I stopped and then started patroni service, they got stuck in ""starting"" state and I had to reinit those nodes.
In logs, postgres was complaining about missing wal files.
Is it known problem? (PostgreSQL 12.4, Patroni 1.6.5)
16:50
Julian Markwort The primary regularly discards old WAL files that it no longer needs...
Patroni can use replication slots to let the primary know that a replica still needs some WAL to catch up, but this might not be enabled in your environment.
16:51
Kaarel Moppel Yes, sounds like the most common replication problem at all :slightly_smiling_face: https://stackoverflow.com/questions/47645487/postgres-streaming-replication-error-requested-wal-segment-has-already-been-rem
16:51
by default Postgres doesn't reserve any extra WAL for replication purposes
16:51
Julian Markwort could it simply be that the replica was already lagging quite a bit behind or that the stop and start took quite a while?
16:53
I think most of your patroni clusters are configured with no replication slots and only a few hundred wal_keep_segments...
wal_keep_segments tells the primary to keep at least that many WAL files, even if it does not need them any more.
17:13
Peter Pruchnerovic:house_with_garden: no, before the stop operation, it was all in sync, 0 lag
17:14
We did more extensive test where we were stopping and starting multiple instances of 4 node xbid simu cluster. End state was only one node running.
17:14
No problem on sync cluster, only on async one.
17:24
Peter Pruchnerovic:house_with_garden: We have set wall_keep_segments = '8'
17:26
What parameters should I configure and on which nodes? Should Leader have something different in the config? What if Leader goes to another server?
17:27
Julian Markwort it really only makes sense to define wal_keep_segments for all hosts, i.e. in ""dynamic config"", using patronictl edit-config (or appropriate http requests)
17:28
wal_keep_segments = '8' is way too low, I would say. depending on your settings, 8 WAL switches are very quickly reached even with almost IDLE load on the database
17:28
one WAL segment is 16MB...so it is usually no issue to keep 100 or 200 of them around
17:45
Julian Markwort another possible solution that I've brought up a few times already is to use a proper WAL archive that can be accessible to all cluster members...
This would mean that the primary does not need to keep any more WAL than it really needs or that the replication slots dictate that it must.
If the replicas fall far behind, they can simply ask the WAL archive to give them the necessary files and catch up.Additionally, a WAL archive usually goes hand-in-hand with backups and you can have PITR (point in time recovery) to any point in between backups, as long as you have the WAL segments that where produced in the meantime between backups
17:55
Peter Pruchnerovic:house_with_garden: Interesting, but it would mean to have large and fast NAS storage and mounted single filesystem to all nodes, right?
18:06
Andriy Nazarenko fast and NAS - oxymoron
18:06
Julian Markwort The WAL archive only needs to be able to keep up with WAL creation on average...
A high latency e.g. Is not a big issue when dealing with WAL archive
18:24
Andriy Nazarenko but what happens when network connection breaks between wal archive and real wal / actual DB host?
18:24
if we are discussing NAS (shared storage) option for WAL archive
18:25
or worse, NFS is known to ""lock up"" entire IO on the NFS client, if the NFS server unexpectedly goes away.
18:38
Julian Markwort when wal archiving is properly configured, files are only deleted if
- they are no longer needed by the primary for crash recovery
- they are no longer needed to satify replication slots (if those are enabled)
- the archive command ran successfully (usually a test ""is the file already archived?"" and the copying of the file itself)

that means an indefinitely broken connection to the archive will lead to the primary never deleting WAL and filling its disk, unless the archive_command is temporarily changed to something like /bin/true, which of course renders the archive unusable for catching up or doing PITR but at least allows the primary to continue running.
18:39
any temporary issues are handled by archive_command simply through retrying until the command returns success
18:42
instead of NFS directly mounted into all cluster members, I would rather suggest to use a proper tool for this purpose, like pgBackRest.
That can take care of validating the chain of WAL on the replica for completeness and it can validate the checksum of the WAL files before returning to the caller.
Additionally, it's very easy to setup pgBackRest so that it can only be pushed to and pulled from, not deleted from the outside. And further, pgBackRest does not allow overwriting of existing WAL files...
18:47
Julian Markwort if you'd like to we can discuss this more in-depth at some point...
We could probably replace the backup system that is breaking more often than we'd all like to in the same sweep :)
19:10
Peter Pruchnerovic:house_with_garden: Thanks @Julian Markwort for your help, I will increase wal_keep_segments to 200.{quote}

I updated patroni deployment to set *wal_keep_segments: 200*

And applied this change to syt1, syt3, perf and simu clusters online.
{code}
ssh xbtestpdb1
sudo su -
patronictl -c /etc/patroni_xbsyt1async/config.yml edit-config
patronictl -c /etc/patroni_xbsyt1sync/config.yml edit-config
patronictl -c /etc/patroni_xbsyt3async/config.yml edit-config
patronictl -c /etc/patroni_xbsyt3sync/config.yml edit-config
ssh xbperfpdb1
sudo su -
patronictl -c /etc/patroni_xbperfasync/config.yml edit-config
patronictl -c /etc/patroni_xbperfsync/config.yml edit-config
ssh xbsimupdb1
sudo su -
patronictl -c /etc/patroni_xbsimuasync/config.yml edit-config
patronictl -c /etc/patroni_xbsimusync/config.yml edit-config
{code}

I will check the logs for a day or two to see if it's not causing any issues.

Tomorrow I will test db failovers again on syt1/3, to see if it works reliably.

On wednesday I will apply it to production.","17/Feb/21 12:01;hw120;Applied on prod also. Added wal_keep_segments: 200 to patroni config online and checked if it was applied.
{code}
ssh xbprodpdb1
sudo su -
patronictl -c /etc/patroni_xbprodasync/config.yml edit-config
patronictl -c /etc/patroni_xbprodsync/config.yml edit-config
su - postgres
psql -p 25101
postgres=# SELECT * FROM pg_settings WHERE name = 'wal_keep_segments';
       name        | setting | unit |           category            |                       short_desc                       | extra_desc | context | vartype |       source       | min_val |  max_val   | enumvals | boot_val | reset_val |                           sourcefile                           | sourceline | pending_restart
-------------------+---------+------+-------------------------------+--------------------------------------------------------+------------+---------+---------+--------------------+---------+------------+----------+----------+-----------+----------------------------------------------------------------+------------+-----------------
 wal_keep_segments | 200     |      | Replication / Sending Servers | Sets the number of WAL files held for standby servers. |            | sighup  | integer | configuration file | 0       | 2147483647 |          | 0        | 200       | /var/lib/pgsql_prod_25101/data/9.5/xbprodasync/postgresql.conf |         34 | f
(1 row)

psql -p 25201
postgres=# SELECT * FROM pg_settings WHERE name = 'wal_keep_segments';
       name        | setting | unit |           category            |                       short_desc                       | extra_desc | context | vartype |       source       | min_val |  max_val   | enumvals | boot_val | reset_val |                          sourcefile                           | sourceline | pending_restart
-------------------+---------+------+-------------------------------+--------------------------------------------------------+------------+---------+---------+--------------------+---------+------------+----------+----------+-----------+---------------------------------------------------------------+------------+-----------------
 wal_keep_segments | 200     |      | Replication / Sending Servers | Sets the number of WAL files held for standby servers. |            | sighup  | integer | configuration file | 0       | 2147483647 |          | 0        | 200       | /var/lib/pgsql_prod_25201/data/9.5/xbprodsync/postgresql.conf |         35 | f
(1 row)
{code}
","17/Feb/21 14:53;hw120;Tested on XBID PERF patroni cluster, all failovers and switchovers went well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID PROD GlusterFS hosts are overloaded,XP-4550,106662,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,11/Feb/21 11:58,15/Feb/21 11:12,22/Feb/21 13:26,15/Feb/21 11:12,,,,,,,,,,glusterfs,TechOps,,,"xbprodglfs1/2 servers are overloaded, load is 6-8. Most resources are consumed by glusterfs and s1-agent (sentinel) processes.
We should investigate if we can optimize it (glusterdfs) or add more vCPU cores +4.",,hw120,yn731,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-388,M7P-7696,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"Issue was that the Antivirus daemon (clamav) was started as a user, which has not enough permissions to scan the uploaded files, it must run as root. It is fixed now, by Tuan/Lambert.",,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cmow:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/21 14:17;hw120;Tunning of glusterfs to allow caching.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Database LIPB ECP Backup Storage Hits Threshold at xbcutsedb,XP-4547,106563,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,10/Feb/21 14:30,11/Feb/21 15:00,22/Feb/21 13:26,11/Feb/21 15:00,,,,,,,,,,toilwork,,,,"Alert in CUTS environment: (shared edb1)
{quote}WARNING on xbcutsedb1 | Mount: /var/lib/pgsql_lipbecp_25517 - used: 86% - 17 GB/21 GB Used/Total
{quote}

Similar to: XP-4339 Database LIPB ECP Backup Storage Hits Threshold at xbcutsedb",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cmeo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/21 14:59;zs244;Resolved during maintenance today in XP-4477:

{quote}/dev/mapper/rootvg-lv_pgsql_ctsoecp_25524_data
                       69G  534M   65G   1% /var/lib/pgsql_ctsoecp_25524
/dev/mapper/rootvg-lv_pgsql_ctsoecp_25524_log
                      4.8G   45M  4.6G   1% /var/lib/pgsql_ctsoecp_25524/log
/dev/mapper/rootvg-lv_pgsql_ctsoecp_25524_backup
                       20G  556M   19G   3% /var/lib/pgsql_ctsoecp_25524/backup
/dev/mapper/rootvg-lv_pgsql_cuteecp_25503_data
                       20G  525M   19G   3% /var/lib/pgsql_cuteecp_25503
/dev/mapper/rootvg-lv_pgsql_cuteecp_25503_log
                      4.8G   52M  4.5G   2% /var/lib/pgsql_cuteecp_25503/log
/dev/mapper/rootvg-lv_pgsql_cuteecp_25503_backup
                       16G  860M   14G   6% /var/lib/pgsql_cuteecp_25503/backup
/dev/mapper/rootvg-lv_pgsql_lipaecp_25516_data
                       99G  868M   93G   1% /var/lib/pgsql_lipaecp_25516
/dev/mapper/rootvg-lv_pgsql_lipaecp_25516_log
                      4.8G  605M  4.0G  13% /var/lib/pgsql_lipaecp_25516/log
/dev/mapper/rootvg-lv_pgsql_lipaecp_25516_backup
                       35G 1023M   32G   4% /var/lib/pgsql_lipaecp_25516/backup
/dev/mapper/rootvg-lv_pgsql_lipbecp_25517_data
                       20G  623M   18G   4% /var/lib/pgsql_lipbecp_25517
/dev/mapper/rootvg-lv_pgsql_lipbecp_25517_log
                      4.8G   48M  4.6G   2% /var/lib/pgsql_lipbecp_25517/log
/dev/mapper/rootvg-lv_pgsql_lipbecp_25517_backup
                       48G  993M   44G   3% /var/lib/pgsql_lipbecp_25517/backup
{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application Log Hits Threshold on xbctpjamq1,XP-4544,106554,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,10/Feb/21 13:33,11/Feb/21 14:38,22/Feb/21 13:26,11/Feb/21 14:38,,,,,,,,,,toilwork,,,,"Altert in CTPJ environment:
	{quote}WARNING on xbctpjamq1 | Mount: /xbid/logs - used: 86% - 810 MB/1.0 GB Used/Total{quote}

Check on system: (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20XBID%20Storage%20Operation%20Procedures/65/)

{quote}xbctpjamq1 | FAILED | rc=127 >>
/dev/mapper/rootvg-lv_xbid_logs  976M  775M  135M  86% /xbid/logs{quote}",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cmco:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe J,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/21 14:28;zs244;Made the option to (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20XBID%20Storage%20Operation%20Procedures/):

{quote} find /xbid/logs -type f -mtime +120 -atime -120 -exec rm {} \;{quote}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application Log Hits Threshold on xbctpldow1,XP-4543,106553,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,10/Feb/21 13:27,11/Feb/21 13:17,22/Feb/21 13:26,11/Feb/21 13:17,,,,,,,,,,toilwork,,,,"Alert in CTPL environment:
|WARNING on xbctpldow1 \| Mount: /xbid/logs - used: 86% - 5.1 GB/6.3 GB Used/Total|

Check on system: (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20XBID%20Storage%20Operation%20Procedures/64/console)
{quote}/dev/mapper/rootvg-lv_xbid_logs  5.9G  4.8G  852M  86% /xbid/logs{quote}

",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,950400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cmcg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe L,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/21 13:17;zs244;System cleaned-up and there is now the option in Jenkins Job ""Storage Operation Procedures"" to find files bigger than 10M or 100M in /xbid/logs: (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20XBID%20Storage%20Operation%20Procedures/)
{quote}
{quote}find /xbid/logs -type f -size +100M -exec ls -hl {} \;
find /xbid/logs -type f -size +10M -exec ls -hl {} \;{quote}
{quote}
Further, it is tested to remove files which are older than 180 days and not accessed within the last 180 days:
{quote}find /xbid/logs -type f -size +10M -mtime +180 -atime -180 -exec rm {} \; {quote}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLOTH - some handlers wait time for processing are negative,XP-4538,106486,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,09/Feb/21 16:43,16/Feb/21 16:22,22/Feb/21 13:26,16/Feb/21 16:22,,,,,,,,,,,,,,"I've put some load to XBID locally and I can see that some handler metrics have negative values.

It looks like it's only {{handler_*_wait_time_processing}} field, but check thoroughly and fix. See attached CSV for the actual SLOTH DB table {{xbid_event}}.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Feb/21 16:43;ll664;xbid_events_negative_handlers.csv;https://jira.deutsche-boerse.com/secure/attachment/92545/xbid_events_negative_handlers.csv",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1036800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,09/Feb/21 16:43,,,,,,,,,,,,,None,,,,,,,,,,"1|y0clxk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLOTH - merge to XBID develop,XP-4536,106477,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,09/Feb/21 15:04,15/Feb/21 16:41,22/Feb/21 13:26,15/Feb/21 16:41,,,3.2.x,,,,,,,,,,,"Merge SLOTH code from branch [XP-4250-develop|https://github.deutsche-boerse.de/dev/xbid/tree/XP-4250-develop] to {{develop}}.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1036800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ckbp:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4536,XP-4530,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create info end-point for Report tool applications,XP-4521,106415,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,08/Feb/21 14:51,12/Feb/21 11:19,22/Feb/21 13:26,12/Feb/21 11:19,,,3.1.x,,AM Indicators Reporting,SLA Report Tool,,,,,,,,"h2. Current situation
An info end-point showing a current application version is missing in all report tool applicaions. It is needed for XP-4494

h2. Acceptance criteria
* AMR, ACR and Report tool expose an info end-point showing a current version of the running instance",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0clj4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Feb/21 09:35;qo794;* Report tool: https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/372
{code}
curl http://localhost:8080/actuator/info
{""build"":{""version"":""2.52-SNAPSHOT-""}}
{code}
* AM reporting tool: https://github.deutsche-boerse.de/dev/xbid.am-reporting/pull/35
{code}
curl http://localhost:8080/actuator/info
{""build"":{""version"":""1.0.11-SNAPSHOT-""}}
{code}
* Acer reporting tool: https://github.deutsche-boerse.de/dev/xbid.acer-reporting/pull/13
{code}
curl http://localhost:8080/actuator/info
{""build"":{""version"":""1.0.3-SNAPSHOT-""}}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create info end-point for AMS,XP-4520,106413,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,08/Feb/21 14:49,19/Feb/21 15:05,22/Feb/21 13:26,19/Feb/21 15:05,,,3.2.x,,AMS,,,,,,,,,"h2. Current situation
An info end-point showing a current application version is missing in AMS. It is needed for XP-4494

h2. Acceptance criteria
* AMS exposes an info end-point showing a current version of the running instance",,ek176,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1123200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0clio:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 28,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Statistic Loader Stopped Working - Fix pg_hba Configuration for xbprodcor,XP-4517,106299,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zs244,zs244,zs244,04/Feb/21 16:22,05/Feb/21 19:15,22/Feb/21 13:26,05/Feb/21 19:15,,,,,,,,,,,,,," 
 In [https://dbg-devops.slack.com/archives/C65N02RMW/p1612277116144200,] there is the remark that the xbid production statistic loader stopped working. 

Here is a simple fix https://jira.deutsche-boerse.com/browse/XP-3237 (how it was fixed in the past)FYI: I can see the error here (at the end) [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Statistics-Generator/375/console]
 Caused by: org.postgresql.util.PSQLException: FATAL: no pg_hba.conf entry for host ""10.139.54.203"", user ""uapp01xbprodcor"", database ""xbprodcor"", SSL off

 
h2. TODOs (draft)
 * check if it is reading from master or replica host (should be replica) ? xbproddbr1
 * (optional) check the patroni config if it is still generous on the replica one
{quote}pg_hba: # Add following lines to pg_hba.conf after running 'initdb'
* host replication replicator 0.0.0.0/0 md5
* host all all 0.0.0.0/0 md5{quote}
* add mentioned entry to pg_hba.conf like in https://jira.deutsche-boerse.com/browse/XP-3237 and find a proper way to reload config



",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1382400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cktk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Feb/21 15:52;zs244;- job is reading from replica
 - checked patroni config of replicas and it is generous but specific user was missing
 - added entry as in XP-3237 to patroni config yaml (manually) and reloaded dbr1 dbr2

{quote}vim /etc/patroni_xbprodasync/config.yml
 patronictl -c /etc/patroni_xbprodasync/config.yml reload xbprodasync xbproddbr1
 patronictl -c /etc/patroni_xbprodasync/config.yml reload xbprodasync xbproddbr2
{quote} 

- started XBID-Statistics-Generator ([https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Statistics-Generator/] #379)

 - entered database to check if connection is open - and it is - seems to work","05/Feb/21 19:15;zs244;- XBID-Statistics-Generator ([https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Statistics-Generator/] #379)
{quote}Finished: SUCCESS{quote}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update DB Cleanup job to use ansible,XP-4512,106261,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,iv732,yo218,yo218,04/Feb/21 07:35,15/Feb/21 12:23,22/Feb/21 13:26,15/Feb/21 12:23,,,,,,,,,,,,,,"h2. Current situation 

There is a jenkins job which deletes old history data from the database of each environment. It is still using the old deployment config and need to be migrated to the usage of ansible. Simu is already failing since a few days, it is just a matter of time until prod would fail, too which would result in an uncontrolled increase of the database. Here is the link to the job:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/All-XBID-Cleanup-DBs/] 

 

Job is failing when it's not running for preset number of days. 
h2. Proposed solution 

todo: 
 * migrate the job to Ansible (xbid_cleanup_dbs_select)
 * please also check if m7 solution does fit our needs 

Hint: 

pay attention to PROD which is still on the old DB and deployed with old Perl script. 
h2. Acceptance criteria
 * db cleanup job runs without failure 

 ",,ek176,hw120,iv732,yn731,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,604800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cklc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Feb/21 11:26;hw120;That one is triggering this one https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID-Cleanup-DBs-Select/
We should create separate new job for ansible deployed environments and update this one to run only on 8 remaining perl managed environments - including prod.","12/Feb/21 12:32;iv732;My solution should be to create a completely new Jenkins job where we connect to each db host and execute the sql script directly from there. 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID%20-%20DB%20clean%20up/

For cuties env: it is straightforward because we do not have patroni cluster
For Simu and Prod: we need to run the patroni command to get the leader and execute the sql script only from that node (because on other node the db is is recovery mode and data cannot be deleted)

Modified the script touse the datetime function of postgresql, instead the date time function of shell

On each db host, create the 3 scripts and put under /opt/data/db_clean_scripts","12/Feb/21 14:22;iv732;Stopped the old Jenkins job
Scheduled the new Jenkins job and continue to monitor.","15/Feb/21 12:23;iv732;The new jenkins job is running well.
Removed the old jenkins jobs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(split 2) Dataset generator - fixing, refactoring, etc.",XP-4511,106224,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,03/Feb/21 13:13,17/Feb/21 10:35,22/Feb/21 13:26,17/Feb/21 10:34,,,,,,,,,,,,,,"After several separate additions, the {{m7.dataset-generator}} no longer works with any known input, contains unused or unclear temporary code, README is outdated and the whole project is a mess in general.

Also, standard for the input format does not exist anymore, there is no concise information about that anywhere and the whole process is unclear (or undefined).

Steps:
- decide on the input format for datasets
- introduce proper tests enforcing some clarity when adding/changing functionality
- adjust dataset generator for the input format
- describe dataset creation/update processes in confluence or wiki with link from confluence",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4584,XP-4583,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,432000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zo09",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/21 10:34;lt112;See follow-up tickets (causes)

Definition has changes 
- new format not agreed upon yet
- see https://github.deutsche-boerse.de/dev/m7.dataset-generator/pull/49",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fix metrics error, split into 3 separate paths",XP-4510,106221,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ll664,eh941,03/Feb/21 12:55,16/Feb/21 10:50,22/Feb/21 13:26,16/Feb/21 10:50,,,3.2.x,,,,,,,,,,,"The code related to performance meauserement of event handlers is quite messy and hard to grasp. Cleanup/refactor.

 

Analyze and prepare the solution and discuss it with other devs to confirm your assumption. ",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:6c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Wait for the Firewall request, check connections",XP-4509,106218,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,qm925,iv732,03/Feb/21 12:25,19/Feb/21 08:51,22/Feb/21 13:26,19/Feb/21 08:51,,,3.2.x,,,,,,01/Feb/21 00:00,TechOps,,,,"Information from clients
 * *+Individual CuTe for OKTE+*

 * 
 ** As you know OKTE is a new NEMO to SIDC cooperation.
 ** OKTE intends to start initial implementation activities as of February 2021
 ** Therefore we would like to ask you to deliver Individual Cute environment for OKTE (4th Wave) until *01 February 2021*

*There is a HOWTO [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Setup+new+environment*]

*Hint: get inspired by Henex ticket: XP-2583.* 

*Acceptance criteria* 
 * analyse of what needs to be done and how long it will take (do we need to order something or is there anything special to be done specifically?)
 * align with syseng team so they also include their input 
 * create follow up ticket(s) with details for creating new environment for OKTE
 ** e.g. devs to create inventories and update deployment scripts
 * record estimated effort needed in the ticket so we can better prepare for the future planning. 
 * update [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Setup+new+environment] with latest procedue

 ",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,345600,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i000000000000000ac",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,Xbops Sprint 28,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 11:17;iv732;Escalated the FW request, resubmitted.","17/Feb/21 14:09;iv732;Firewall was done.
The issue with missing java default folder was fixed.
[~ab039] will do some further checks.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Persister metrics - add rows by DB task,XP-4508,106217,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,03/Feb/21 12:25,03/Feb/21 12:25,22/Feb/21 13:26,03/Feb/21 12:25,,,,,,,,,,,,,,"We collect metrics and we report sum of all rows affected.

Add another level of detail so each task contain number of rows affected by DB task. ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0cbsz:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Prefill events identification,XP-4507,106216,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,03/Feb/21 12:24,03/Feb/21 12:25,22/Feb/21 13:26,03/Feb/21 12:25,,,,,,,,,,,,,,"h2. Current situation

Prefilled orders will corrupt performance statistics as prefilled orders are done fast in batch . 
h2. Proposed solution

For performance reports, we want to exclude prefill orders.

Think of the ways how to identify them, currently perftest client sends order with specific text prefix.
h3. Ideas:

- introduce tags for events ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i000000000000000e001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix HP Fortify errors (nightly pipelines),XP-4505,106210,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ek176,ek176,03/Feb/21 10:51,19/Feb/21 10:56,22/Feb/21 13:26,17/Feb/21 11:10,,,3.1.x,3.2.x,,,,,,,,,,"DoD pipelines started failing due to HP Fortify: No change in project code resulted in quality assessment drop.

TBD:
 * Check if this is related to HP Fortify upgrade (review also XP-4291 if this can help)
 * Fix the HP Fortify findings (suppress)
 * Try to suppress in code, rather in web (create follow-up tickets if needed/complicated)
 * In case it still display different stuff for dev/acceptance, consult with [~ek615]",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,777600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4527,XP-4505_xbid_hpfortify_upgrade,XP-4530,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Feb/21 14:14;ek176;See the #energy_development channel (Fri, Jan 29 and Wed, Feb 03): 
[Vladimir Klimes|https://app.slack.com/team/U3MPSU7EH]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-small%2F1f3e1.png!  [10:24|https://dbg-devops.slack.com/archives/G5CS694JV/p1611825896006300]

On Tuesday there was an update of the production Fortify server. Unfortunately the version there is not backwards compatible. I have updated the pipeline library ([https://github.deutsche-boerse.de/dev/m7.pipeline-library]) so that the fortify jobs still work. Please, update the pipeline library version in your pipelines to 1.37. If you are brave (or crazy) enough to use the version from master, it should just work for you.
 
 
!https://ca.slack-edge.com/T12FM9C21-U5ASTGTV3-d0a7de19d7d9-48!
[Pavel Popelka|https://app.slack.com/team/U5ASTGTV3]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-small%2F1f3e1.png!  [09:52|https://dbg-devops.slack.com/archives/G5CS694JV/p1611910337007400?thread_ts=1611825896.006300&cid=G5CS694JV]

replied to a thread:[On Tuesday there was an update of the production Fortify server. Unfortunately the version there is not backwards compatible. I have updated the pipeline library (https://github.deutsche-boerse.de/dev/m7.pipeline-library) so that the fortify jobs still work. Please, update the pipeline library version in your pipelines to 1.37. If you are brave (or crazy) enough to use the version from master, it should just work for you.|https://dbg-devops.slack.com/archives/G5CS694JV/p1611910337007400?thread_ts=1611825896.006300&cid=G5CS694JV]
thanks Vladimir for mentioning, the main message related to HP fortify sounds like this: * We observe several warnings and errors in our Software Security Center (SSC) Web GUI log which are related to different causes, therefore
 *  => Please check all your *_automated logins_*with your technical users for any warnings and errors
 *  => Please check all your *_“cloudscan” and “scancentral” command calls_* for any warnings and errors
 *  => Please check all your *_automated Fortify calls_* from your scripts and tools (e.g. Continuous Integration) for any warnings and errors
 *  => Please check all you *_automated REST-API calls_* for any warnings and errors
 *  => Please check for *_automated scripts_* that are *_no longer needed_* and can be stopped or removed completely
 *  => Please check if *_all used tokens are still valid_* and have not been expired
 * Do not reuse any tokens which have been created before the update of the Test- and Production-Environment as we observed in some rare cases permission issues
 *  => Please *_re-create all required tokens_* as the encapsulated permissions have slightly changed
 * In you are facing SSC Web GUI errors or strange display behaviors
 *  => Please *_delete the browser history/cache_*completely as old GUI fragments taken from the browser’s cache lead to such situations 
 
 
 
 
 
!https://ca.slack-edge.com/T12FM9C21-U3MPSU7EH-18656e339f99-48!
[Vladimir Klimes|https://app.slack.com/team/U3MPSU7EH]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-small%2F1f3e1.png!  [14:03|https://dbg-devops.slack.com/archives/G5CS694JV/p1612357436015700]

Together with Steffen we have installed the 20.2.0 version of Fortify client to all englobwrk workers and updated the pipeline library to reflect the needed changes (see previous message from Pavel). If you want to use the most recent version of Fortify, please update your pipelines: * Use the 1.38 (or later) version of pipeline library (not needed if you use master).
 * Change the Fortify path to {{/sw/cmqa/tools/HPEFortify/20.2.0}} (you need to use the same version for both requesting tokens and scanning).
 * Change the sca-maven-plugin version to 20.2.0.

Please note, that with the version increase the ruleset also changed, so you will probably have more unresolved security issues after you use the newer version. Plan some time to also mitigate these issues.
Also note, that when you upload a scan artifact to SSC using the new version, you can no longer upload any artifact there using some older version.
 
 
 
 
 ","12/Feb/21 14:19;eg288;* all pipelines upgraded to HPFortify 20.2.0
* pipelines were failing due to timeouts, in other words the jobs did not finish in time -> timeouts increased",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implemenet Ansible role for Sloth ingestion agent,XP-4504,106209,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,ll664,03/Feb/21 10:30,11/Feb/21 08:54,22/Feb/21 13:26,11/Feb/21 08:54,,,3.2.x,,,,,,,,,,,"Idea:

-The agent just shuts down on error, make it restartable via systemd as it is with Patroni agent?- Agreed to deploy it as a normal java application first, if we encounter a lot of shut downs due to external dependencies not available, we'll change it to a systemd service.

AC:

* Sloth agent deployable to XBID Perf",,ll664,qo794,,,,,,,,,,,,,,,,,,,XP-4493,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1036800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Feb/21 15:29;qo794;* xbsloth role created:
** https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1372
* perf configured:
** https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2536
* successfully deployed on {{xbidperfcor1}} - can be checked there

h3. TODO once timescale and elastic is available (XP-4224)
* replace vault entries:
{code}
- secret/xb/xbid/perf/elastic/xbperfsloth: password, username
- secret/xb/xbid/perf/db/xbperfsloth: password, username
{code}
* fill into {{default.yml}} in {{xbsloth}} role:
{code}
spring_data_elasticsearch_client_reactive_endpoints: ""not_defined_yet""
timescale_host: ""not_defined_yet""
timescale_port: ""not_defined_yet""
{code}
* start sloth

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order modification executes database task which might be slow,XP-4501,106202,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,eh941,eh941,03/Feb/21 09:41,09/Feb/21 12:13,22/Feb/21 13:26,09/Feb/21 12:13,,,3.2.x,,,,,,,Performance_Issue,,,,"When perf tests are executed we noticed there are many database tasks executed. It turned out it's actually caused by order modification for which a database task is always used. If the task is in persistence context it always cut the batch and a transaction is executed. This might be slow.

Change it so that ModifyOrdrReq doesn't use database task but rather standard entity update.",,eh941,hj444,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1123200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cjlj:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Feb/21 16:24;ll664;Fixed and merged to \{develop}. Two improvements has been implemented:

 
 * database tasks are no longer cutting Persister batches transaction (removed force persistence flag), resulting in longer and more performant transactions in peaks
 * bulk order hibernation/inactivation of small size (configurable), are persisted directly via hibernate insted of bulk update via DbTask - this should help utilizing JDBC batches in persister

 

Both improvements should show performance improvements in higher percentile (peaks) as they improve batching capabilities of Persiter. Note that no performance tests has been executed as part of this task as we'll do performance testing with CPM  implementation anyway.

 

The configuration threshold to use DbTask based hibernate is {{ordersThresholdToTriggerDbTaskPersistence}}, by default set to 10. Configurable via database.

 

For testing I suggest to do a shakedown around order modification/inactivation features.

 ","09/Feb/21 12:09;hj444;Retest :
Env Docker : Version R3.2.6-SNAPSHOT (Build 0d0a5c47a158a17ca633a90c0c841c3bb98269ba)
 SOB - Trading status
 CMM - publish capacity+Allocation
Login into Test client
 Orders 
* Add orders
-- 'O' orders hourly contracts
-- 'B' orders 'hourly' block 
* Modify : change price
-- 'O' orders
-- 'B' orders
* Deactivate - selected
-- 'O' orders
-- 'B' orders
* Deactivate All
* Activate  - selected
-- 'O' orders
-- 'B' orders
* Delete order
-- 'O' orders
-- 'B' orders
* Set SOB set service HALT : action=""AHIB""
-- Orders are deactivated
* Set SOB set service TRADING 
-- Orders stay deactivated


Works ok. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add more comments to sloth tables and columns,XP-4496,106164,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eh941,eh941,02/Feb/21 13:51,15/Feb/21 10:20,22/Feb/21 13:26,15/Feb/21 10:20,,,3.2.x,,,,,,,,,,,"Add explementary comments to sloths' database entities like columns and tables. It can be done as follows:

{code:sql}
COMMENT ON TABLE xbid_event IS 'Events that starts from Front dirsuptor like messages, system tasks and journal redo';
{code}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cjlg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move scheduler of On-call support to OpsGenie,XP-4478,106057,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,01/Feb/21 09:53,17/Feb/21 11:03,22/Feb/21 13:26,17/Feb/21 11:03,,,3.1.x,,,,,,,,,,,"h1. {color:#00875a}Value: Reliable solution for primary on-call support selection{color}
h2. Current situation 

There is a phone with Android app to reschedule dev1 vs dev2 as a primary number for development on-call support. This phone is getting old, his battery got bigger and backpanel got disassembled from it. App is also hard to manage remotely. 

We also have paid OpsGenie where we can have similar functionality and it can be managed remotely.
h2. Proposed solution 

Switch scheduling from the Android App solution to OpsGenie. 

Schelude: https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+on-call+support#XBIDon-callsupport-On-Callschedule
h2. Acceptance Critera
 * Dev1 vs Dev2 as a primary number switching done in OpsGenie. 
 * Still track names who is responsible
 * present on Scrum event how the switching is done so Ops know how to reach devs

 ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4514,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"Implemented by @Jiriiik mainly.
checked in OpsGenie: Works
Ops to share knowledge",,,,,,,,,,,,,,1814400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cjlj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix kapacitor handlers error when tag is missing,XP-4425,105888,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,27/Jan/21 22:44,20/Feb/21 12:33,22/Feb/21 13:26,02/Feb/21 14:40,,,,,,,,,,Monitoring,TechOps,,,"Some instance-specific alerts don't have an instance tag defined in group_by condition and all system-specific alerts don't have it also, because their metrics are server-specific only.

But the issue is, that email handlers for prod have instance condition specified to avoid call alerting for flapping service like h2h4u on m7 and ams on xbid.

It is affecting the ability to send alerts to alarmtilt for alerts that are missing instance tag.

* I must add an instance tag to all service-specific alerts
* Create separate handlers for system-specific alerts
* Update deployment to make it work
",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cic0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Feb/21 14:40;hw120;Tested and deployed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prefill events identification,XP-4414,105832,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,27/Jan/21 09:28,11/Feb/21 09:02,22/Feb/21 13:26,11/Feb/21 09:02,,,,,,,,,,,,,,"h2. Current situation

Prefilled orders will corrupt performance statistics as prefilled orders are done fast in batch . 
h2. Proposed solution

For performance reports, we want to exclude prefill orders.

Think of the ways how to identify them, currently perftest client sends order with specific text prefix.
h3. Ideas:

- introduce tags for events ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4507,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Replace XbidEvent name with requestType, requestSize",XP-4413,105831,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ll664,ll664,27/Jan/21 09:27,09/Feb/21 09:49,22/Feb/21 13:26,09/Feb/21 09:49,,,,,,,,,,,,,,"h1. {color:#00875a}Value: Clarity on data {color}
h2. Current situation 

We have event name that contains unstructured data, i,e. requestName and concatenated client order ids.

(eg.. field contains order modify + concatenated number of ids) 
h2. Proposed solution 

In internal API between xbid and Sloth.  

Replace field _name_ with:
 * requestType - a class name of the request
 * bulkSize - size of items in requests (ie. orders on OrdrModify, allocations, delivery intervals etc.)",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e0006",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - CMI - deploy of double side component does not always pick external dataset,XP-4411,105809,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ll664,ll664,26/Jan/21 15:56,19/Feb/21 16:39,22/Feb/21 13:26,11/Feb/21 11:00,,,3.1.x,,,,,,,,,,," 

The external dataset if put to just node 1:
{code:java}
{% if instance_num | int == 1 %}
    <Resources>
        <JarResources className=""org.apache.catalina.webresources.DirResourceSet""
                      base=""${catalina.home}/{{ plugins_dir }}""
                      webAppMount=""/WEB-INF/lib""/>
    </Resources>
{% endif %}
{code}
But Ansible starts both nodes at once, so if node2 is started first, the dataset population is skipped.

Happened on syt3.

[https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy%2Fxbid-full-ansible-deploy/detail/xbid-full-ansible-deploy/462/pipeline/165]

 

Hint:
 * what about having this jar on both nodes? 
 * This happens only during the deployment of clean dataset.",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cjlj:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4530,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Operations Log Hits Threshold on xbsimucom3,XP-4401,105720,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,25/Jan/21 11:28,02/Feb/21 16:05,22/Feb/21 13:26,02/Feb/21 16:05,,,,,,,,,,toilwork,,,,"On simulation, there was the GlusterFS log running full:
{quote}CRITICAL on xbsimucom3 | Mount: /var/log - used: 97% - 914 MB/1.0 GB Used/Total
{quote}
Then df -h also showed:
{quote}df: ‘/opt/data01/xbid_amreports_simu/OUT/am’: Transport endpoint is not connected
 df: ‘/opt/data01/xbid_reporttool_simu/OUT/am’: Transport endpoint is not connected
{quote}
{{which was resolved by simple unmount and mount.}}
{quote}{{[root@xbsimucom3 ~]# ls -sh /var/log/glusterfs/glusterfs.log}}

{{674M /var/log/glusterfs/glusterfs.log}}
{quote}
Easy solution: mv log to /tmp/ and then transferring it to our m7shrdebsm1
{quote}{color:#7a869a}scp glusterfs.log logmover@m7shrdebsm1:/tmp{color}
{quote}
As mount problems reoccured, a reboot was triggered: (/xbid/remount.sh)
{quote}grep -q ""_simu"" /etc/mtab; [ $? -ne 0 ] && while read p; do mount --bind /opt/data01/pmi_archiver/OUT/pmi /opt/data01/""$p""/OUT/pmi; mount --bind /opt/data01/xbid_reporttool_simu/OUT/am /opt/data01/xbid_amreports_simu/OUT/am; done </opt/data01/sftp_mover/userlist >/dev/null 2>&1
{quote}
Nice to have: Find out how to trigger glusterfs log rotation manually to have an easy solution as it does compression.

There was no address for issuing the downsizing - unclear and out of scope for the moment.",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2419200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0chco:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/21 11:51;zs244;[~iv732], thanks for resolving - please feel free to add some further details if you have any.","25/Jan/21 12:00;zs244;Further: vgs showed that it is quite full - only 100mb left. Lets talk in the daily what we can do about it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update customer monitoring - CuTes & Lip envs - false positive alarms - 27.01.2021,XP-4400,105709,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,zi174,zi174,25/Jan/21 10:19,28/Jan/21 11:25,22/Feb/21 13:26,28/Jan/21 11:25,,,,,,,,,27/Jan/21 00:00,,,,,"We need to avoid the false-positive AT alarms for *ALL* *CuTes & LIP environments* 

1) it looks like the problem is somewhere in the ""middle layer"" on the apache servers, network,... or we should do the same as was done for PROD issue XP-3434
 _the monitoring script is adjusted to run still every 5s but if the first attempt returns the faulted state then we will wait 10s and check again. updated only on prod, we have to update it on all envs_

2) introduce some multiple checks before these AT are triggered",,iv732,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cha8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jan/21 13:12;iv732;[~zi174]
rabbitmq check is updated for both lipa and lipb
on cute we do not have rabbitmq check, so no change.","26/Jan/21 15:34;zi174;[~iv732],

ok I'm going to let them know tomorrow. Regarding cute, does it mean on these envs, the situation with false positive alarms cannot happen, right? ","26/Jan/21 15:37;iv732;Right, we are mentioning here the false positive alarms for rabbitmq, due to its special conditions. On Cute we do not monitor rabbitmq status, so false positive alarm for rabbitmq cannot happen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"module CORE, AMQP connection factory respConnFactory recreates AMQP channels",XP-4396,105592,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eg288,eg288,21/Jan/21 14:33,16/Feb/21 13:13,22/Feb/21 13:26,16/Feb/21 13:13,,,3.1.x,,,,,,,,,,,"Investigate why AMQP connection factory respConnFactory recreates AMQP channels sometimes. The recreation can lead to scenario where messages are published in a wrong order. See XP-4380 for details.

Investigate why the channel creation takes place on a regular basis. In production it is roughly 8 times per day. The channel creation should not happen at all ideally when the AMQP connection is used within a single thread only.

The connection/spring template is used also in ShutdownBroadcastSender, but it is not used at all during normal operation. So it should not trigger any channel recreation.

Already investigated by Franta Odehnal under XP-3177, also read his question on stack-overflow:
 [https://stackoverflow.com/questions/62592526/rabbitmq-topic-exchange-message-ordering]

 

Hint: It might be enough just to change properties. 

 
h2. Acceptance criteria: 
 - This is extremely sensitive topic: do a deep review, discuss also in broader audience, check for potential flaws or impacts 
 - verify it during the higher load (at least 6M+ OTs per day)",,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4580,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,518400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cjli:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/21 16:06;eg288;Probable root cause is org/springframework/boot/actuate/amqp/*RabbitHealthIndicator*.java, it concurrently access every rabitmq spring template to obtain connection status.

Solution proposal is to disable this checker.

We should try to reporduce it first. And verify that it is not happening when the checker is disabled.","16/Feb/21 13:13;eh941;Issue split into:
|XP-4580|(split 1) module CORE, AMQP connection factory respConnFactory recreates AMQP channels|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate and deploy telegraf config for capacity management,XP-4392,105563,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,21/Jan/21 10:57,03/Feb/21 11:17,22/Feb/21 13:26,03/Feb/21 10:56,,,,,,,,,,Monitoring,TechOps,,,"SYSENG (Kaan and Goekay) asked me to help them to integrate telegraf changes to collect metrics for capacity management report.

Goekay prepared repository with changes

[https://github.deutsche-boerse.de/dev/CapandPerfMgmt/blob/dev/ansible/main.yml]

and I have to sync it with telegraf ansible role, test it and deploy on all physical hosts.

I also have to add condition to deploy changes only on physical hosts.
Something like ""ansible_virtualization_role"" != ""guest"",

List of hosts:
{code:bash} 
xbsimupdb1
xbsimupdb2
xbsimupdb3
xbsimupdb4
m7testpdb1
m7testpdb2
xbidperfcor1
m7ppg2
m7ppg1
xbperfpdb1
xbidprodcor2
xbidprodcor1
m7simupdb2
m7simupdb3
m7simupdb1
xbperfpdb2
m7simupdb4
xbidsimucor2
xbidsimucor1
m7prodpdb3
m7prodpdb2
m7prodpdb1
m7prodpdb4
m7spg2
xbprodpdb4
m7spg1
xbprodpdb1
xbprodpdb3
xbprodpdb2
xbtestpdb2
xbtestpdb1
{code}

 ",,hw120,kw089,ox626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cge8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Jan/21 15:48;hw120;Waiting for Goekay to approve, if they can than use our influxdb databases to extract the data for capacity reports.","25/Jan/21 10:21;ox626;Hi Peter, metrics from M7 and XBID physicals hosts can be forwarded to Energy Influx in AWS. Please proceed with deployment","25/Jan/21 10:40;hw120;* I have to create new database for Capacity management: metrics_energy_capacity_management
* Define new data output in telegraf config and use namepass/namedrop to distinguish where should metrics go, test if it works
{code}
[[outputs.influxdb]]
  urls = [""https://influxdb.energy.svc.dbgcloud.io""] # required
  ## The target database for metrics (telegraf will create it if not exists).
  database = ""metrics_energy"" # required
  ## Retention policy to write to. Empty string writes to the default rp.
  retention_policy = """"
  ## Write consistency (clusters only), can be: ""any"", ""one"", ""quorum"", ""all""
  write_consistency = ""any""
  timeout = ""25s""
  insecure_skip_verify = true
  namedrop = [""bmhostdisk*""]
[[outputs.influxdb]]
  urls = [""https://influxdb.energy.svc.dbgcloud.io""] # required
  ## The target database for metrics (telegraf will create it if not exists).
  database = ""metrics_energy_capacity_management"" # required
  ## Retention policy to write to. Empty string writes to the default rp.
  retention_policy = """"
  ## Write consistency (clusters only), can be: ""any"", ""one"", ""quorum"", ""all""
  write_consistency = ""any""
  timeout = ""25s""
  insecure_skip_verify = true
  namepass = [""bmhostdisk*""]
{code}
* Deploy it on all physical servers","25/Jan/21 22:55;hw120;3h later, after fixing many bugs in ansible inventory, tuning deployment and fighting with old rhel 6, deployed on all hosts with exception of m7(s|p)pg[12].

[~kw089] On old RHEL 6 hosts, provided bash script doesn't work
{code}
[root@m7spg1 ~]# /bin/sh /etc/telegraf/scripts/bmhostdisk.sh
df: unrecognized option '--output=source,size,avail'
Try `df --help' for more information.
bmhostdisk,host=m7spg1,type=lvm,pname=rootvg total=278.88,free=91.84,used=187.03,used_percent=67.07
awk: cmd. line:6: (FILENAME=- FNR=2) fatal: division by zero attempted
{code}

Deployed using this jenkins job
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/

host patterns:
{code}
~m7t.*-shrd-(prod|simu|syt1)-pdb.*async.* 
~xb.*(syt1|perf|simu|prod)-.*pdb.*async.*
~xb.*(perf|simu|prod)-.*cor.*
&veritas
{code}","26/Jan/21 09:59;kw089;Hi [~hw120]

It is known issue that  this version of script is not compatible with RHEL6(I commented inside a script). [~wm282] fix the script and it should be running for both RHEL6 and RHEL7. But it is a matter of test. After test the script on some systems, I will push it to the repo.

 

 

 ","03/Feb/21 10:56;hw120;As all problematic RHEL 6 hosts were discarded recently, m7(s|p)pg[12], I am closing it as done.","03/Feb/21 11:17;kw089;[~hw120]  We do not have any RHEL6 Physical servers anymore. So, We do not need to update the script. If something changes, I will update you with the RHEL6  and RHEL7 compliant script. Thank you so much for your support so far.

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Comtrader: Introduce TLS TrustManager (Fix Critical HP Fortify finding),XP-4391,105562,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,21/Jan/21 10:44,21/Jan/21 13:45,22/Feb/21 13:26,21/Jan/21 13:45,,,,,ComTrader,,,,,Security,TLS,,,"Critical HP Fortify finding exists in CT Acceptance (weirdly not reported in Develop, but should be):

The SSL Trust has overly broad configuration:
{code:java}
@Override
public X509Certificate[] getAcceptedIssuers() {
    return null;
}
{code}
Solution: Provided in M7 ComTrader solution: SecureConnectionHelper.java class

 ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2742,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,False ticket. Resolved in XP-2742,,,,,,,,,,,,,,2764800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cge0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security Test: Finalize XLS (Split 1),XP-4385,105500,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,20/Jan/21 14:06,20/Jan/21 14:08,22/Feb/21 13:26,20/Jan/21 14:08,,,,,,,,,,,,,,"Current status, regarding XP-3469 (Security Testing Epic) there are:
 * DBAG Standards (Sec SW Dev, Vuln. Mgmt, ...)
 * XLS file (XP-3965), test part prepared by Duc

 

To be done:
 * Check what are we expected to comply with from the point of the standards
 * Finalize the XLS file to be expedited to GIS
 * Finalize/close as much as possible in XP-3469 Epic",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Done within Alpha Sprint 25,,,,,,,,,,,,,,2764800,,,,,,,,,,,,,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0cfzg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security Test: Finalize XLS (Split 2),XP-4384,105495,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,20/Jan/21 13:34,17/Feb/21 11:58,22/Feb/21 13:26,17/Feb/21 11:06,,,,,,,,,,,,,,"Current status, regarding XP-3469 (Security Testing Epic) there are:
 * DBAG Standards (Sec SW Dev, Vuln. Mgmt, ...)
 * XLS file (XP-3965), test part prepared by Duc

 

To be done:
 * Check what are we expected to comply with from the point of the standards
 * Finalize the XLS file to be expedited to GIS
 * Finalize/close as much as possible in XP-3469 Epic",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4385,,,,,,,,,,,,,,"17/Feb/21 10:34;ek176;XBID_Security_tests_analysis_v3.xlsx;https://jira.deutsche-boerse.com/secure/attachment/92990/XBID_Security_tests_analysis_v3.xlsx","16/Feb/21 13:11;ek176;xbid-security-check-list-mb-v11_final_internal_dev.xls;https://jira.deutsche-boerse.com/secure/attachment/92956/xbid-security-check-list-mb-v11_final_internal_dev.xls","17/Feb/21 11:56;zi174;xbid-security-check-list-mb-v12.xls;https://jira.deutsche-boerse.com/secure/attachment/92996/xbid-security-check-list-mb-v12.xls",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"XLS available, about 0.5 stp to do (discussion in progress) -- less effort than splitting
",,,,,,,,,,,,,,432000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000ec",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/21 13:57;ek176;Based on [security-check-list-duc-v8_20201110.xlsx​|https://jira.deutsche-boerse.com/secure/attachment/89817/security-check-list-duc-v8_20201110.xlsx​] (See XP-3965)","16/Feb/21 13:37;ek176;The following files are ready:
 * v11_final_out.xls – for VMT ticket
 * v11_final_internal_dev.xls – more comments, notes and internal info (incl. theory)","17/Feb/21 10:35;ek176;For completeness, added overview of XBID security - related tests.","17/Feb/21 11:58;ek176;xbid-security-check-list-mb-v12.xls replaces _final_out version -- to be sent out",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Refactor EventLog/AbstractEventHandler,XP-4383,105492,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ll664,eh941,20/Jan/21 13:23,03/Feb/21 12:55,22/Feb/21 13:26,03/Feb/21 12:55,,,3.2.x,,,,,,,,,,,"The code related to performance meauserement of event handlers is quite messy and hard to grasp. Cleanup/refactor.

 

Analyze and prepare the solution and discuss it with other devs to confirm your assumption. ",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4510,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2851200,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:69",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: VMAX Storage in Hausen 2021,XP-4382,105490,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,20/Jan/21 13:10,23/Jan/21 22:23,22/Feb/21 13:26,23/Jan/21 22:23,,,,,,,,,,TechOps,toilwork,,,"+*Before Task*+
||ID           ||Date &              Time||Responsible        ||Env                              ||Task||Comment||
|XB_BE1|18.01. - 20.01.|Peter Pruchnerovic ,Tuan Nguyen|ALL|Check the startup playbook/procedures, if a single sided startup is possible (e.g. if something happens during the Maintenance window, we need to start the application just on IXE side and it should not fail, because HAU is not available)| |
|XB_BE2|20.01. 14:30 PM|Peter Pruchnerovic ,Tuan Nguyen|PROD, SIMU|Check, if master core, database, SPM, Gluster, Consul are running in IXE (if not, failover with maintenance window on Friday)| |
|XB_BE3|20.01. 15:00PM|Peter Pruchnerovic ,Tuan Nguyen|PROD, SIMU|Check, if customers are connected to IXE (MPLS mainly). If not, send another reminder to affected customer for the Maintenance window on Friday.| |

+*Friday 22.01.2021 (A day before implementation)*
 +
||ID         ||Date & Time        ||Responsible||Env                                   ||Task||Comment||
|XB_FR1|10:00|Peter Pruchnerovic ,Tuan Nguyen|PROD|Final check, if master nodes are running in IXE as input for next step (maintenance window)| |
|XB_FR2|13:00 - 14:00|Peter Pruchnerovic ,Tuan Nguyen,Ana Kovacevic |PROD|""Pre-arranged maintenance window:
 - Failover of XBID solution to the primary data center Equinix, if needed
 - XBID members/clients reconnect all their connections to primary data center Equinix
 - Shakedown test""| |

+*Saturday Task 23.01.2021 - Official start for Saturday: 7:00am*+
||ID                ||Date & Time               ||Responsible||Env                                     ||Task||Comment||
|XB_SA1|07:00 - 07:05|Peter Pruchnerovic ,Tuan Nguyen|PROD|""Check, if Shipping Module didn't failover during night from Equinix to Hausen
 (its seamless on XBID) if its in Hausen we should failover back to Equinix""| |
| XB_SA2| 07:00 - 07:10| Peter Pruchnerovic| ALL| Snooze CheckMK/OpsGenie| |
| XB_SA3| 07:05 - 07:10| Peter Pruchnerovic| ALL| Snooze AlarmTilt| |
| XB_SA4| 07:10 - 07:45| Peter Pruchnerovic ,Tuan Nguyen ,Roman Krewer,| SIMU| ""Shutdown/failover all services on HAU side:
 - Application slave instances
 - Application components on HAU side running ACTI/ACTI
 - GlusterFS - NO touch !(taken care by Lambert)
 - LDAP
 - also stop core service""| GlusterFS is handled by Lambert.(Snaptshot + shutdown)|
| XB_SA6| 08:00 - 08:30| Peter Pruchnerovic ,Tuan Nguyen ,Roman Krewer| PROD| ""Shutdown/failover all services on HAU side:
 - Application slave instances
 - Application components on HAU side running ACTI/ACTI
 - GlusterFS - NO touch !(taken care by Lambert)
 - LDAP
 - stop core service""| GlusterFS is handled by Lambert.(Snaptshot + shutdown)|
| XB_SA12| 09:30 - 09:45| Peter Pruchnerovic ,Tuan Nguyen| ALL| Shutdown Consul HAU VMs| |
| XB_SA13| 09:45| Peter Pruchnerovic| ALL| Activate AlarmTilt| |
| XB_SA14| 09:45| Peter Pruchnerovic| ALL| Activate CheckMK/OpsGenie| |
|{color:#de350b} {color}|{color:#de350b} {color}|*{color:#de350b}TASK AFTER 18:00{color}* |{color:#de350b} {color}|{color:#de350b} {color}|
| XB_SA18| 18:15| Peter Pruchnerovic,Tuan Nguyen| ALL|Startup Consul HAU VMs, as soon as the phsical hosts have been started by CloudAdmins| |
| XB_SA24| 19:15 - 19:30| Peter Pruchnerovic,Tuan Nguyen, Roman,Lambert|PROD|""Startup all services on HAU side:
 - Application slave instances
 - Application components on HAU side running ACTI/ACTI
 - GlusterFS - check the network disks availability on """"xbprodrep2"""", xbprodcbn2"""", """"xbprodcbn2"""", """"xbprodcom[246]"""" VM hosts
 - LDAP
 - core service""| |
| XB_SA27| 20:00 - 20:30| Peter Pruchnerovic,Tuan Nguyen, Roman,lambert| SIMU| ""Startup all services on HAU side:
 - Application slave instances
 - Application components on HAU side running ACTI/ACTI
 - GlusterFS - check the network disks availability on """"xbsimurep2"""", xbsimucbn2"""", """"xbsimucbn2"""", """"xbsimucom[246]"""" VM hosts
 - LDAP
 - core service""| |
|XB_SA28| 20:30 - 21:00| All| All| Check hosts & services| |",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9494,,,,,,,,,,,,SERVICE-9494,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfyg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) product entity refactoring vol3,XP-4381,105486,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,uv683,tr866,20/Jan/21 12:37,05/Feb/21 14:51,22/Feb/21 13:26,05/Feb/21 14:51,,,3.2.x,,,,,,,,,,,Finish all the TODO JH items related to Product entity refactoring.,,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/21 13:09;tr866;R3.1.12-screenshot-10.136.142.21_60900-2021.01.25-11_46_52.png;https://jira.deutsche-boerse.com/secure/attachment/92020/R3.1.12-screenshot-10.136.142.21_60900-2021.01.25-11_46_52.png","25/Jan/21 13:09;tr866;R3.2.5-SNAPSHOT-screenshot-localhost_24081-2021.01.25-11_51_46.png;https://jira.deutsche-boerse.com/secure/attachment/92021/R3.2.5-SNAPSHOT-screenshot-localhost_24081-2021.01.25-11_51_46.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1382400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zo0y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,Alpha Sprint 26 (S),Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,minor-fixups,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Jan/21 14:38;tr866;Testing on docker with version XB 3.2.5-SNAPSHOT-1547082ca2582d5167ada7d4f80cab06743df566

h2. Found defect:
# h4. Navigation between the tabs during product Creation/Modification doesn't work:
** Description:
During Creation of Modification of a product navigation by pressing on *Previous/Next* buttons(Create process) or on *tab headers(Details, Attribute* etc.; both *Create* or *Modify* process) leads to *blank page* with no possibility to continue even on page Refresh. URL has to be cut to get to main page.
** Steps to Reproduce
### Navigate to View->Reference Data Management->Product Setup->Product Management
### Press Create
### Fill in the fields in Details tab
### Press Next or Previous button
** Observed behaviur: Blank screen is displayed
_Note: verified on Syt1 with version XB Syt1 R3.2.4-fad912d6a0f8988766558c3939737894fe94084b. Last version from the day before was still working correctly._","25/Jan/21 13:14;tr866;Testing on docker with version XB R3.2.5-SNAPSHOT-ff309bd692d83be83185e7f2076f0d33a35f0b34
h2. Found defect (x):
Items missing in the list of *date*/time based attributes used for defining the *Long and Short Contract Name Format Template* in the right-hand side panels:

h3. Description:
following items are missing in the list of attributes for contract name templates:
|StartOfDelivery_Day|EndOfDelivery_Day|
|StartOfDelivery_Month|EndOfDelivery_Month|
|StartOfDelivery_MonthYear|EndOfDelivery_MonthYear|
|StartOfDelivery_Half Year|EndOfDelivery_Half Year|
|StartOfDelivery_Semester|EndOfDelivery_Semester|
|StartOfDelivery_Year Quarter|EndOfDelivery_Year Quarter|
|StartOfDelivery_Year (4 digits)|EndOfDelivery_Year (4 digits)|
|StartOfDelivery_Year (2 digits)|EndOfDelivery_Year (2 digits)|
|StartOfDelivery_Year Date|EndOfDelivery_Year Date|
|StartOfDelivery_Year DateTime|EndOfDelivery_Year DateTime|

 h3. Steps to Reproduce:
 # Navigate to View->Reference Data Management->Product Setup->Product Management
 # Press Create
 # Fill in all the mandatory the fields in Details tab
 # Click on the ""Contract Names"" tab header
 # Check the contents of the lists

 _Note: \\First I thought it might be caused by the dataset, but then I verified on Syt3 with version R3.1.12-545158fedd3ce3e4293d64025afcc1de62abd199, that the list was complete before. On Syt2 with version R3.2.4-fad912d6a0f8988766558c3939737894fe94084b the items are missing already._
  ||Then||Now||
| !R3.1.12-screenshot-10.136.142.21_60900-2021.01.25-11_46_52.png|height=100%,width=100%! | !R3.2.5-SNAPSHOT-screenshot-localhost_24081-2021.01.25-11_51_46.png|height=100%,width=100%! |","05/Feb/21 14:50;tr866;Successfully tested on docker with version R3.2.5-SNAPSHOT-3ce0a794382429a4cf1310d2e821671f30573555
Previous issues were fixed and no other suspicious behaviour compared to older versions was found.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) Implement data ingestion for current production,XP-4379,105480,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,qo794,20/Jan/21 11:36,20/Jan/21 11:38,22/Feb/21 13:26,20/Jan/21 11:38,,,,,,,,,,,,,,"We want current production metrics. Design a solution how to push it to target databases.

TODO:
* kotlin application (create task for VM)
* poll periodically ElasticSearch
* write metrics extractor from ElasticSearch
* design a data model - drafted in Epic

",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2851200,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zo0k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix Comtrader Acceptance nightly pipelines,XP-4378,105471,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ei349,ei349,20/Jan/21 10:26,29/Jan/21 15:50,22/Feb/21 13:26,29/Jan/21 15:50,,,3.1.x,,,,,,,,,,,"Comtrader, xbid having more than 100 issues found in HP fortify which needs to be resolved similar as on develop branch. 

Please check them and align it with develop. 
h2. Acceptance criteria 

- Nigthly acceptance branch pipeline fails no more",,ei349,ek176,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4391,,,,,,,"29/Jan/21 15:18;tr866;Tuplak Energy 01292021-15.14.51.png;https://jira.deutsche-boerse.com/secure/attachment/92176/Tuplak+Energy+01292021-15.14.51.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1987200,,,,,,,,,,,,,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0cbsy:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/21 13:54;ek176; 
 Branches diff overview: *{color:#0747a6}{{git rev-list --oneline ^acceptance develop}}{color}*
||MR (Develop, missing in Acceptance)||XP related||Status||
|#15: Version Bump 3.1 -> 3.2|XP-3345|Not in ticket scope|
|#11: Enable CN check on PROD|XP-3205|Not in ticket scope|
|#16, 17, 18, 33: Upgrade new certs|XP-3514|Not in ticket scope|
|#19: Owasp (kotlin)|XP-1261|Merge|
|#24: Deployment via AWS|XP-3458|Not in ticket scope|
|#31, #37: CT Deploy Internal test|XP-3458|Not in ticket scope|
|#30: HP Fortify|XP-2742|Merge|
|Release 3.2.1| |Not in ticket scope|
|#34, #35: HP Fortify|XP-2742|Merge|
|#36, #37, #38, #41: Support all SYT, dst, perf env|XP-4111|Not in ticket scope|
|Release 3.2.2, 3.2.3, 3.2.4, 3.2.5, 3.2.6| |Not in ticket scope|
|#44: Shared OWASP file|XP-3555|Merge|
|#42, #43, #45, #46/other, #47: OWASP fixes|XP-1261|Merge|
|#46/profile-storage upgrade to 1.8.3|XP-1261|Merge (v1.8.3 deployed to SIMU on 2021-01-21)|

 ","21/Jan/21 14:43;ek176;The following log errors are already in acceptance, no action taken:
{code:java}
2021-01-21T14:42:27.427+0100 [rader-Worker-17] ERROR c.d.c.c.j.ComtraderBase - Comtrader-Worker-17

java.lang.IllegalStateException: Not on FX application thread; currentThread = Comtrader-Worker-17

        at com.sun.javafx.tk.Toolkit.checkFxUserThread(Toolkit.java:236)

        at com.sun.javafx.tk.quantum.QuantumToolkit.checkFxUserThread(QuantumToolkit.java:423)

        at javafx.scene.Parent$2.onProposedChange(Parent.java:367)

        at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:113)

        at com.sun.javafx.collections.VetoableListDecorator.setAll(VetoableListDecorator.java:108)

        at com.sun.javafx.scene.control.skin.LabeledSkinBase.updateChildren(LabeledSkinBase.java:575)

        at com.sun.javafx.scene.control.skin.LabeledSkinBase.handleControlPropertyChanged(LabeledSkinBase.java:204)

        at com.sun.javafx.scene.control.skin.LabelSkin.handleControlPropertyChanged(LabelSkin.java:49)

        at com.sun.javafx.scene.control.skin.BehaviorSkinBase.lambda$registerChangeListener$61(BehaviorSkinBase.java:197)

        at com.sun.javafx.scene.control.MultiplePropertyChangeListenerHandler$1.changed(MultiplePropertyChangeListenerHandler.java:55)

        at javafx.beans.value.WeakChangeListener.changed(WeakChangeListener.java:89)

        at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:361)

        at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)

        at javafx.beans.property.StringPropertyBase.fireValueChangedEvent(StringPropertyBase.java:103)

        at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:110)

        at javafx.beans.property.StringPropertyBase.access$000(StringPropertyBase.java:49)

        at javafx.beans.property.StringPropertyBase$Listener.invalidated(StringPropertyBase.java:230)

        at com.sun.javafx.binding.ExpressionHelper$SingleInvalidation.fireValueChangedEvent(ExpressionHelper.java:137)

        at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)

        at com.deutscheboerse.ui.jfx.util.binding.SafeObjectBinding.invalidate(SafeObjectBinding.java:98)

        at com.deutscheboerse.ui.jfx.util.binding.SafeObjectBinding$SafeBindingHelperObserver.invalidated(SafeObjectBinding.java:132)

        at com.sun.javafx.binding.ExpressionHelper$SingleInvalidation.fireValueChangedEvent(ExpressionHelper.java:137)

        at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)

        at javafx.beans.property.ObjectPropertyBase.fireValueChangedEvent(ObjectPropertyBase.java:105)

        at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112)

        at javafx.beans.property.ObjectPropertyBase.access$000(ObjectPropertyBase.java:51)

        at javafx.beans.property.ObjectPropertyBase$Listener.invalidated(ObjectPropertyBase.java:233)

        at com.sun.javafx.binding.ExpressionHelper$SingleInvalidation.fireValueChangedEvent(ExpressionHelper.java:137)

        at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)

        at com.deutscheboerse.ui.jfx.util.binding.SafeObjectBinding.invalidate(SafeObjectBinding.java:98)

        at com.deutscheboerse.ui.jfx.util.binding.SafeObjectBinding$SafeBindingHelperObserver.invalidated(SafeObjectBinding.java:132)

        at com.sun.javafx.collections.ListListenerHelper$Generic.fireValueChangedEvent(ListListenerHelper.java:321)

        at com.sun.javafx.collections.ListListenerHelper.fireValueChangedEvent(ListListenerHelper.java:73)

        at javafx.collections.ObservableListBase.fireChange(ObservableListBase.java:233)

        at javafx.collections.ListChangeBuilder.commit(ListChangeBuilder.java:482)

        at javafx.collections.ListChangeBuilder.endChange(ListChangeBuilder.java:541)

        at javafx.collections.ObservableListBase.endChange(ObservableListBase.java:205)

        at javafx.collections.ModifiableObservableListBase.add(ModifiableObservableListBase.java:155)

        at com.deutscheboerse.comxerv.comtrader.jfx.components.filter.SortingTableItemsAppender.addToCorrectPosition(SortingTableItemsAppender.java:34)

        at com.deutscheboerse.comxerv.comtrader.jfx.components.filter.SortingTableItemsAppender.accept(SortingTableItemsAppender.java:26)



{code}","21/Jan/21 16:06;ek176;ComTrader 3.1.2-SNAPSHOT successfully started with XBID 3.2.5-SNAPSHOT (order was placed)","25/Jan/21 10:52;ek176;Merged to acceptance. A quick smoke test might be performed.

No function added. Only cherry-picks from development branch.

Nightly run ok: https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-comtrader-acceptance-nightly-pipeline/182","25/Jan/21 12:53;ek176;Unclosed stream fixes added (strangely not reported in develop). Fixed in both develop and acceptance branch: [https://github.deutsche-boerse.de/dev/xbid.comtrader/pull/52]

To be tested:
 * Gzipped AMQP API Message (AmqpUtil.java, i.e.: AbstractComXervAmqpBackend#processBroadcast)
 * Import orders from file (ImportExportServiceImpl#parseOrders)","29/Jan/21 15:27;tr866;Smoke test successful on docker with version ComTraderComTrader V. 3.2.7-SNAPSHOT 2021-01-28T13:29:08Z, XB R3.2.5-SNAPSHOT (Build e6b3d8bad0da7ff0b4a397a5edabe3cc45d63936)

Limited basic functionality of admin user is working fine, i.e. Recall processing, Cancelation of trades. GUI seems to work fine too, working filters, selections, order/trades , Order Book Details etc. 

!Tuplak Energy 01292021-15.14.51.png|width=50%,height=50%!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix XBID Acceptance nightly pipelines,XP-4377,105470,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,pg759,ei349,ei349,20/Jan/21 10:20,29/Jan/21 15:33,22/Feb/21 13:26,29/Jan/21 15:33,,,3.1.x,,,,,,,,,,,"Comtrader, xbid having more than 100 issues found in HP fortify which needs to be resolved similar as on develop branch. 

Please check them and align it with develop. 
h2. Acceptance criteria 

- Nigthly acceptance branch pipeline fails no more",,ei349,pg759,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4378,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,1987200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/21 15:11;pg759;14 issues remain after sync with develop suppressions","29/Jan/21 15:33;pg759;The only issue that was worth was in CMM code that is only called from test units and is removed in develop. After consultation with Kamil we decided to NOT cleanup the code in this late phase of release cycle.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tomcat Out of Memory Alert on xbctsoecp1,XP-4374,105465,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,zs244,zs244,20/Jan/21 10:14,20/Jan/21 12:01,22/Feb/21 13:26,20/Jan/21 12:01,,,,,,,,,,toilwork,,,,"We had two notifications xbid_alerts_cute (https://dbg-devops.slack.com/archives/G01EDS77VK4)
{quote}xbctsoecp1 - xb - xbid - ctso - ecp1 is not sending health status data.
xbctsoecp1 - xb - xbid - ctso - ecp1 is sending health status data.
{quote}

Followed by 
{quote}Tomcat out of memory alert
Encountered 1 Tomcat error(s) in the last 5 minutes. 
xbctsoecp1 - 2021-01-20T08:38:15.859Z 
Unexpected error during checking message status. Error ID : 15705c65-cdb8-4af3-8c8a-2d7a75cec19c Error code : UNEXPECTED_ERROR
eu.entso_e.ecp.v1.endpoint.messaging.exceptions.ECPMessagingException: Unexpected error during checking message status. Error ID : 15705c65-cdb8-4af3-8c8a-2d7a75cec19c Error code : UNEXPECTED_ERROR
    at eu.entso_e.ecp.v1.endpoint.ws.messaging.ECPEndpointServiceSkeleton.SendMessage(ECPEndpointServiceSkeleton.java:314)
...{quote}",,hw120,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gq",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe TSOs,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/21 10:21;zs244;Same as https://dbg-devops.slack.com/archives/G01EDS77VK4/p1610560325191800?","20/Jan/21 11:35;hw120;Increased memory for java process to 2g
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/746/files
we need to redeploy it now.","20/Jan/21 12:01;hw120;Restarted instance with new settings.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update customer monitoring - SIMU - false positive alarms,XP-4373,105448,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,zi174,zi174,19/Jan/21 16:18,21/Jan/21 10:07,22/Feb/21 13:26,20/Jan/21 17:07,,,3.1.6,,,,,,21/Jan/21 00:00,,,,,"We need to avoid the false-positive AT alarms for *SIMU*

1) it looks like the problem is somewhere in the ""middle layer"" on the apache servers, network,... or we should do the same as was done for PROD issue XP-3434
_the monitoring script is adjusted to run still every 5s but if the first attempt returns the faulted state then we will wait 10s and check again. updated only on prod, we have to update it on all envs_

2) introduce some multiple checks before these AT are triggered",,iv732,zi174,,,,,,,,,,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2764800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfqw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/21 17:07;iv732;Implemented the change.
Tested OK

{code:java}
2021-01-20 17:06:22 INFO: Checking ext app on xbsimuxmq1
2021-01-20 17:06:24 INFO: Response of check for ext on xbsimuxmq1: 1
2021-01-20 17:06:24 INFO: Checking ext app on xbsimuxmq3
2021-01-20 17:06:25 INFO: Response of check for ext on xbsimuxmq3: 1
2021-01-20 17:06:25 INFO: Checking ext app on xbsimuxmq5
2021-01-20 17:06:27 INFO: Response of check for ext on xbsimuxmq5: 1
2021-01-20 17:06:27 INFO: Checking ext app on xbsimuxmq2
2021-01-20 17:06:28 INFO: Response of check for ext on xbsimuxmq2: 1
2021-01-20 17:06:28 INFO: Checking ext app on xbsimuxmq4
2021-01-20 17:06:30 INFO: Response of check for ext on xbsimuxmq4: 1
2021-01-20 17:06:30 INFO: Checking ext app on xbsimuxmq6
2021-01-20 17:06:32 INFO: Response of check for ext on xbsimuxmq6: 1
2021-01-20 17:06:32 INFO: XBID simu - At least one server of the rabbitmq cluster ext is up and running or alert already sent

{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid profile-storage - fix failing acceptance nighly pipeline,XP-4372,105437,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,19/Jan/21 14:56,20/Jan/21 10:52,22/Feb/21 13:26,19/Jan/21 15:22,,,,,,,,,,,,,,,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zoh",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jan/21 15:22;eg288;nightly acceptance pipeline is green again -> https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-acceptance-nightly-pipeline/71/ ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM: Latest version not compatible with tosca-fake dataset,XP-4371,105431,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,MG726,tr866,tr866,19/Jan/21 11:49,29/Jan/21 16:11,22/Feb/21 13:26,29/Jan/21 16:11,,,3.2.x,,Shipping,,,,,,,,,"Last version version 3.2.0-SNAPSHOT-0dd3d6752bacb7b2ddc401df62f7c3ffe2622639 can't be run on docker.
SMI module fails to start.",,jy268,MG726,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,1987200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,fixing-hp-fortify-acceptance-2021-02-15,acceptance,XP-4371_upgrade_dataset_version,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Jan/21 16:26;tr866;Docker failed to start with smi 3.2.1-SNAPSHOT-6db0002c59f8f223bd106b8c9993f6178f65b121 as well.","20/Jan/21 09:42;tr866;SPM 3.2.0.1 was tho successfully deployed(without DB Clean) on Syt1 and looks working.","22/Jan/21 16:02;jy268;Tested with dataset 3.2.2 and works fine. Please retest and close the ticket. Please remember that both xbid and sm have to be deployed with db cleanup when using different dataset.","29/Jan/21 16:11;MG726;Tested successfully in docker with tosca-fake dataset and shipping module version 3.2.0 (core version 3.2.5-SNAPSHOT)

Docker was successfully started and SPM and SOB worked without any problems.

Test {color:green}OK{color}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PMI-archiving - fix failing acceptance nighly pipeline,XP-4370,105428,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,19/Jan/21 10:55,20/Jan/21 10:52,22/Feb/21 13:26,19/Jan/21 15:16,,,,,,,,,,,,,,,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zog",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-4370_acceptance_hp_fortify_issues,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Jan/21 15:15;eg288;nightly acceptance pipeline is green again -> https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-pmi-archiving-acceptance-nightly-pipeline/157/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve timescaleDB ingestion performance,XP-4366,105421,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ll664,ll664,19/Jan/21 10:21,15/Feb/21 08:46,22/Feb/21 13:26,15/Feb/21 08:46,,,3.2.x,,,,,,,,,,,"Currently we're able to insert 300 rows/s, which is rather slow.

Couple of optimization comes in mind:

* a batch of event does not form a single transaction - postgres starts a new one for every insert
* no batch statements - r2dbc currently does not support batch statements with parameters, watch till this is implemented - https://github.com/r2dbc/r2dbc-spi/issues/99 
* but we're batching on the statement level (multiple parameter sets) so maybe we're doing it right - check

{code}
2021-01-19 10:14:29.156  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3923 events, rate: 392.3 event(s)/sec 
2021-01-19 10:14:39.156  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3877 events, rate: 387.7 event(s)/sec 
2021-01-19 10:14:49.161  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3667 events, rate: 366.7 event(s)/sec 
2021-01-19 10:14:59.156  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3768 events, rate: 376.8 event(s)/sec 
2021-01-19 10:15:09.156  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3974 events, rate: 397.4 event(s)/sec 
2021-01-19 10:15:19.157  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 3956 events, rate: 395.6 event(s)/sec 
2021-01-19 10:15:29.156  INFO 23381 --- [     parallel-1] c.d.e.x.s.agent.MetricsIngestionService  : Inserted 2900 events, rate: 290.0 event(s)/sec
{code}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2937600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"HP fortify, pmi logger report - references files from AMS project",XP-4362,105407,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,18/Jan/21 17:02,28/Jan/21 15:11,22/Feb/21 13:26,28/Jan/21 12:29,,,3.1.x,,,,,,,,,,,"HP fortify report AID292_XBID_PMI_LOGGER, both versions (DEVELOP, ACCEPTANCE) shows issues from AMS project

The links to the PM-Ilogger reports:
 [https://hpfortify.dwain.infra/ssc/html/ssc/version/12588/fix/null/?filterSet=dbd63fcc-432f-4066-8388-1b008de27dc1]
 [https://hpfortify.dwain.infra/ssc/html/ssc/version/12589/fix/null/?filterSet=dbd63fcc-432f-4066-8388-1b008de27dc1]

All the settngs in pipeline definition seems right. Please doublecheck/investigate and fix.

 

*Hint:* 

- contact HP fortify team as it looks that on xbid side it's all correctly configured. ",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2160000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/21 12:29;eg288;The problem was in HP fortify. The AID292_XBID_PMI_LOGGER report generation was blocked because the source code had changed by more then 10% in size. It happend at some point in October 2020. The report was not generated since then. For pmi-logger application the HP fortify showed report from another project as the AID292_XBID_PMI_LOGGER was not available (not a nice behaviour indeed)

To unblock the report processing someone has to confirm manually that the change in size is valid.

To confirm it, open the report AID292_XBID_PMI_LOGGER. Go to tab ARTIFACTS, it lists uploaded artifacts (i.e. sourcecode which needs to be analyzed by HP fortify). Here each artifact has processing status and it is possible to confirm the change in size here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Operations Log Hits Threshold on xbsimucbn2,XP-4361,105403,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,18/Jan/21 15:48,02/Feb/21 15:45,22/Feb/21 13:26,02/Feb/21 15:45,,,,,,,,,,TechOps,,,,"Following is resolved by extending the file system:

WARNING on xbsimucbn2 | Mount: /var/log - used: 91% - 17 GB/20 GB Used/Total

Please find reasonable size, why it went full and search for unnecessary files occupying space.
",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:fhc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Feb/21 15:45;zs244;Not possible to reproduce anymore and for the moment, no a problem anymore.

/dev/mapper/rootvg-lv_varlog 20G 4.2G 15G 22% /var/log

(vgs: rootvg 1 7 0 wz--n- <59.51g <7.84g)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[SPM] Problem with boot upgrade to 2.3.8.RELEASE - Replace H2 with testcontainers,XP-4358,105382,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,18/Jan/21 10:53,01/Feb/21 11:06,22/Feb/21 13:26,01/Feb/21 11:06,,,,,Shipping,,,,,,,,,"After attempt to upgrade spring-boot-starter-parent from 2.3.6.RELEASE to 2.3.8.RELEASE integration tests started to behave in a weird way. Currently shipping is using H2 for testing and during persist we got following exception:
{code}
Value too long for column ""CREATED_DATE VARBINARY(255)"": ""X'aced0005737200166f72672e6a6f64612e74696d652e4461746554696d65b83c78646a5bddf90200007872001f6f72672e6a6f64612e74696d652e62617365... (273)""; SQL statement:
insert into PARTY (ID, CREATED_BY, CREATED_DATE, LAST_MODIFIED_BY, LAST_MODIFIED_DATE, DELETED, EMAIL_1, EMAIL_1_CERTIFICATE, EMAIL_1_CERTIFICATE_NAME, EMAIL_2, EMAIL_2_CERTIFICATE, EMAIL_2_CERTIFICATE_NAME, LONG_NAME, PARTY_EIC, SHORT_NAME, status, VERSION, ECP_ENDPOINT_ID, PARTY_TYPE) values (null, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'TSO') [22001-200]
{code}

My understanding is that H2 with the newest spring-boot version started to interpret joda DateTime as binary array which is nonsense. What is more we are not using flyway during integration test which is another drawback.
As a solution I suggest getting rid of H2 and using postgres from testcontainers instead.

Steps:
* Remove h2 dependency
* Replace with testcontainers postgres
* Replace AbstractCtxTest logic which uses H2 methods to one reflecting postgres
* Alter config entries in application.properties in shipping-services project",,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,3024000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,fixing-owasp-issues-2021-02-16,fixing-hp-fortify-develop-2021-02-15,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Persister metrics - add rows by DB task,XP-4357,105374,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,18/Jan/21 09:43,08/Feb/21 09:43,22/Feb/21 13:26,08/Feb/21 09:43,,,,,,,,,,,,,,"We collect metrics and we report sum of all rows affected.

Add another level of detail so each task contain number of rows affected by DB task. ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cbsz:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/Jan/21 08:29;ll664;PRs ready, will merge it after XP-4383 is done.","03/Feb/21 12:25;ll664;Issue split into:
|XP-4508|(Split 1) Persister metrics - add rows by DB task|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Persister metrics - add CMM DB entities,XP-4356,105373,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,18/Jan/21 09:43,19/Jan/21 10:24,22/Feb/21 13:26,19/Jan/21 10:24,,,,,,,,,,,,,,,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,N/A,,,,,,,,,,,,,,2937600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfb4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Jan/21 10:23;ll664;Done, XBID code merged to {{XP-4250-develop}}, Sloth changes in {{develop}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Memory Dump Hits Storage Size Threshold on xbctsoecp,XP-4352,105208,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,14/Jan/21 11:49,02/Feb/21 15:40,22/Feb/21 13:26,02/Feb/21 15:40,,,,,,,,,,toilwork,,,,"System hits warning and 5 minutes later the notification:
{quote}CRITICAL on xbctsoecp1 | Mount: /xbid - used: 97% - 2.8 GB/3.1 GB Used/Total
{quote}
Later it further notifies with Tomcat out of memory alert:
{quote}Encountered 3 Tomcat error(s) in the last 5 minutes. 
 xbctsoecp1 - 2021-01-13T17:50:26.021Z 
 Unexpected error during checking message status. Error ID : 3fa7795f-d495-4094-ae1a-cf2058d36375 Error code : UNEXPECTED_ERROR
 eu.entso_e.ecp.v1.endpoint.messaging.exceptions.ECPMessagingException: Unexpected error during checking message status. Error ID : 3fa7795f-d495-4094-ae1a-cf2058d36375 Error code : UNEXPECTED_ERROR
 at eu.entso_e.ecp.v1.endpoint.ws.messaging.ECPEndpointServiceSkeleton.SendMessage(ECPEndpointServiceSkeleton.java:314)
 at eu.entso_e.ecp.v1.endpoint.ws.messaging.ECPEndpointServiceMessageReceiverInOut.invokeBusinessLogic(ECPEndpointServiceMessageReceiverInOut.java:120)
{quote}
- check the reason

 ",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2073600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gk",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/21 11:51;zs244;Extended filesystem +1GB regarding CRITICAL on xbctsoecp1 | Mount: /xbid - used: 97% - 2.8 GB/3.1 GB Used/Total. ","22/Jan/21 13:57;zs244;Checked again [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20Storage%20Operation%20Procedures/20/console]

/dev/mapper/rootvg-lv_xbid 3.9G 2.7G 1.1G 72% /xbid","28/Jan/21 11:32;zs244;Checked again: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20Storage%20Operation%20Procedures/28/console]

/dev/mapper/rootvg-lv_xbid 5.9G 1.9G 3.8G 33% /xbid","28/Jan/21 15:04;zs244;Added some options to the Storage Operation Procedure Jenkins Job like ""find /xbid -size +100M -ls"" which shows that there is a current instance of a heapdump:

/xbid/xbid-ctso-ecp1/log/java_pid53519.hprof

And history shows that there were others.

rm /xbid/xbid-ctso-ecp1/log/java_pid28487.hprof
 rm /xbid/xbid-ctso-ecp1/log/java_pid8307.hprof","29/Jan/21 09:23;zs244;Standard procedure is here to move it to a place where it is accessible by a dev who will use Eclipse Memory Analyzer Open Source Project [https://www.eclipse.org/mat/] to analyze the problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare ad-hoc jenkins job for tasks like extending filesystem,XP-4351,105205,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,14/Jan/21 11:06,25/Jan/21 11:52,22/Feb/21 13:26,19/Jan/21 22:34,,,,,,,,,,jenkins,reducingtoil,TechOps,,"We are spending too much time on tedious toil work like
 * extending filesystems
 * cleaning up space
 * ...

I will prepare simple jenkins job allowing to run ansible ad-hoc command to do it.",,hw120,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4401,XP-4361,XP-4352,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:fh",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/21 12:08;zs244;*Ideas*

Options

- one option to have: df -h functionality to check
- one option to check if there is free space: vgs
- one option to extend /xbid or /var to either 4, 6, 8 or 10 GB
- one option to do a yum clean all
- one option to show recent memory dumps
- one option to move the memory dump to a place where devs can analyse it
- one option to see current iostat´s

Naming

- ""XBID Storage Operation Procedures"" - if its get useful then we can push it in technical operations to be more like ""Energy IT Storage Operation Procedures""?","19/Jan/21 22:30;hw120;Created two jenkins jobs:

* one for ad hoc storage operations
 [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20Storage%20Operation%20Procedures/]
* and generic ad hoc command
 [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy%20IT%20Ansible%20Ad-Hoc%20single%20command%20job/]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix HP Fortify issues in reporting-engine acceptance,XP-4349,105198,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,MG726,eg288,eg288,14/Jan/21 09:51,17/Feb/21 13:13,22/Feb/21 13:26,17/Feb/21 13:13,,,,,,,,,,,,,,Fix HP fortify issues in xbid-reporting nightly acceptance build,,eg288,MG726,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/21 13:13;MG726;Test_client_entry.txt;https://jira.deutsche-boerse.com/secure/attachment/93004/Test_client_entry.txt","17/Feb/21 13:13;MG726;sob_TC540_20210216_ADMIN.xml;https://jira.deutsche-boerse.com/secure/attachment/93005/sob_TC540_20210216_ADMIN.xml","17/Feb/21 13:13;MG726;sob_TC810_20210216_ADMIN.xml;https://jira.deutsche-boerse.com/secure/attachment/93006/sob_TC810_20210216_ADMIN.xml",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,432000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zofo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3394_flyway_standard_implementation,acceptance,XP-3394_remove_schema_version,XP-3394_acceptance_flyway_standard_implementation,XP-4354,XP-4349_acceptance_fix_hp_fortify_issues,develop,XP-4349_set_default_page,XP-3394_acceptance_remove_unused_maven_properties,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Jan/21 15:40;eg288;DONE -> the xbid-reporting-engine-acceptance-nightly-pipeline is green -> https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-reporting-engine-acceptance-nightly-pipeline/156/ 

To Test:
* deploy xbid-reporting-engine 5.0.57 along with latest xbid 3.1.x
* generate a few orders and trades in xbid
* next day verify all the scheduled reports are generated and they all have expected content","17/Feb/21 13:12;MG726;Reporting engine version 5.0.57 tested successfully on SYT1 with xbid version 3.1.12.

Entered orders and trades via test Client saved in Test_client_entry.txt in the attachment together with the generated reports TC540 and TC810.

Test {color:green}OK{color}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deletion Concept 2021,XP-4348,105163,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,13/Jan/21 13:53,20/Jan/21 10:52,22/Feb/21 13:26,20/Jan/21 09:34,,,,,,,,,,,,,,TBD (once I know what I should do :)) ,,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jan/21 14:23;zi174;DeletionConcept_RoPA446_XBID_v02.docx;https://jira.deutsche-boerse.com/secure/attachment/91830/DeletionConcept_RoPA446_XBID_v02.docx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3369600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1665,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cabi:2a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update deployment verifier for SOB on internal test environment using Ansible,XP-4345,105136,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,pg759,ei349,ei349,13/Jan/21 09:40,17/Feb/21 17:08,22/Feb/21 13:26,17/Feb/21 17:08,,,3.1.x,,,,,,,,,,,"h2. Current situation

Current deployment verifier uses energy-mkt-shared and after migration to Ansible we have to update it to be able to load needed values from ansible scripts. 
https://github.deutsche-boerse.de/dev/xbid-deploy-verifier
h2. Proposed solution 
 * update deployment verifier for SOB to be able to run on at least one internal test env. 

tip: there might be an output from ansible with needed data (you can pick a format as you wish) ",,ei349,ek176,pg759,qo794,,,,,,,,,,,,,,,,,,,,,,,,,XP-4593,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,345600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4343,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cabi:2b",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/21 09:48;ek176;[https://github.deutsche-boerse.de/dev/energy.datalake/blob/master/Makefile]

To get variables, try {{--syntax-check --vv }}

 

Also we might re-use (dry-run): {{energy.automation.deployments/jenkins/Jenkinsfile_deploy_xbid_full }}as the core command is actually:
{code:java}
sh """"""
    ansible-playbook \
    playbooks/${playbook} \
    --limit ~'${ansibleLimit}' \
    --inventory ${ansibleInventory} \
    --tags ${tags} \
    ${ansibleParameters} ${additionalParameters}
""""""
{code}","17/Feb/21 17:07;pg759;Issue split into:
|XP-4593|(split1) Update deployment verifier for SOB on internal test environment using Ansible|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Internet connection timeouts on Jenkins,XP-4340,105084,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Resolved,,pg759,pg759,12/Jan/21 12:44,19/Jan/21 14:56,22/Feb/21 13:26,19/Jan/21 14:56,,,3.2.x,,Shipping,,,,,TechOps,,,,"Build process of shipping changed after igration to webpack (XP-761). The build now uses its ""own"" node/npm to avoid dependency on versions that are installed on Jenkins servers. The downside is that the node/npm and packages required by shipping-ui-react module are now downloaded from Internet using procy configured on Jenkins servers ({{proxy.shrd.dbgcloud.io:3128}}) and sometimes the downloads time out and the build fails. Due the amount of JS packages downloaded the chances of failed buid are quite high.

The cause can be seen in nmp log. npm tries to downolad JS packace - the connection takes 60s (timeout) and following extraction fails - as the package is not downloaded.

Examples of failed build [xbid-shipping-pulls #252|https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-shipping-pulls/252/]

 
h2. Acceptance Criteria 
 * Check if there is a problem with a timeout or it's different problem (like inaccessible resources or something similar). 
 * Resolve the issue causing timeout. ",,jy268,pg759,,,,,,,,,,,,,,,,,,,XP-4330,,,,,,,,,,,,,,,XP-4283,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e01",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jan/21 14:55;jy268;Not required anymore, we have used `yarn` instead of `npm` which retries broken downloads. Build is green now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Database LIPB ECP Backup Storage Hits Threshold at xbcutsedb,XP-4339,105083,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,12/Jan/21 12:22,02/Feb/21 15:42,22/Feb/21 13:26,02/Feb/21 15:42,,,,,,,,,,,,,,"A small extend done as of CRITICAL on xbcutsedb1 fast-fixed the issue:
{quote}Mount: /var/lib/pgsql_lipbecp_25517/backup - used: 96% - 28 GB/32 GB Used/Total{quote}

After performing a full backup manually, the filesystem is back to 1% 

{quote}/dev/mapper/rootvg-lv_pgsql_lipbecp_25517_backup 48G  449M   45G   1% /var/lib/pgsql_lipbecp_25517/backup{quote}

The resize is open and we need to check if this issue reoccurs.",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2073600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gj",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/21 17:28;zs244;Further, the job in [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/] is still red. This needs to be fixed if we don´t want to have this issue reoccurring.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tomcat app start fails due to occupied HTTP port,XP-4333,105020,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,eg288,eg288,11/Jan/21 12:22,17/Feb/21 15:45,22/Feb/21 13:26,17/Feb/21 11:16,,,3.1.x,,,,,,,Monitoring,TechOps,,,"*Info: there is a workaround for this topic. We can wait until Peter is back.* 
 * WKA: stop telegraf, stop core, start core, start telegraf

------

 

The tomcat fails to start fully and it reports that the HTTP port is ocupied, There is no other instance of the same app running. What always helps is the telegraf restart. So it seems that telegraf itself somehow blocks the port.

Example of failed deployments due to this error:
 * [https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FXBID%20Ansible%20Jobs%2FXBID%20Ansible%20deploy%20full/detail/XBID%20Ansible%20deploy%20full/436/pipeline]
 * [https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FXBID%20Ansible%20Jobs%2FXBID%20Ansible%20deploy%20full/detail/XBID%20Ansible%20deploy%20full/438/pipeline]

Tomcat log:
{code:java}
11-Jan-2021 11:30:32.857 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [""http-nio-60328""]
11-Jan-2021 11:30:32.863 SEVERE [main] org.apache.catalina.core.StandardService.initInternal Failed to initialize connector [Connector[HTTP/1.1-60328]]
        org.apache.catalina.LifecycleException: Protocol handler initialization failed
                at org.apache.catalina.connector.Connector.initInternal(Connector.java:1077)
                at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:136)
                at org.apache.catalina.core.StandardService.initInternal(StandardService.java:552)
                at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:136)
                at org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:848)
                at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:136)
                at org.apache.catalina.startup.Catalina.load(Catalina.java:639)
                at org.apache.catalina.startup.Catalina.load(Catalina.java:662)
                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:302)
                at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:472)
        Caused by: java.net.BindException: Address already in use
                at sun.nio.ch.Net.bind0(Native Method)
                at sun.nio.ch.Net.bind(Net.java:433)
                at sun.nio.ch.Net.bind(Net.java:425)
                at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
                at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
                at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:221)
                at org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:1118)
                at org.apache.tomcat.util.net.AbstractJsseEndpoint.init(AbstractJsseEndpoint.java:222)
                at org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:587)
                at org.apache.coyote.http11.AbstractHttp11Protocol.init(AbstractHttp11Protocol.java:74)
                at org.apache.catalina.connector.Connector.initInternal(Connector.java:1075)
                ... 13 more
11-Jan-2021 11:30:32.864 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [""ajp-nio-0.0.0.0-61328""]
{code}
Notes:
 * solution could be restart of telegraf before each tomcat start, but firs I think we should troubleshoot it and try to figure out what is wrong
 * outcome of this ticket could be list of troubleshooting steps which should be executed when it happens again, so anybody can collect infomation when he stumbles accross the issue",,eg288,ei349,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,432000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e09",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Jan/21 13:13;ei349;There is a workaround in place but it's unpleasant to resolve this issue regularly. ","15/Feb/21 21:14;hw120;https://everything.curl.dev/usingcurl/timeouts

Configured timeout and max-time limits for curl command which is getting health endpoint data.

I will test it on a couple of environments.","17/Feb/21 11:11;hw120;Tested on syt1/3 cor instances, looks fine. I will redeploy it on all xbid ansible-deployed envs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upload Acer reports 2020 H2 to Sftp,XP-4332,105019,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,tr866,tr866,11/Jan/21 12:13,14/Jan/21 13:04,22/Feb/21 13:26,12/Jan/21 16:08,,,,,,,,,,TechOps,toilwork,,,"Please upload the attached ACER reports [^acer_2020_h2.zip] to SFTP for customers the same way it was done for the first half of the year XP-3209.",,hw120,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2542,,,,,,,"11/Jan/21 11:55;tr866;acer_2020_h2.zip;https://jira.deutsche-boerse.com/secure/attachment/91592/acer_2020_h2.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3456000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:fgi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jan/21 15:55;hw120;As discussed, I uploaded reports to following PXs: *cropex epex gme hupx np omie opcom ote tge bsp*

NOTE: BSP and IBEX were missing from the list, we added only BSP because IBEX doesn't have account created

* Connected to *35 PS Support PROD FFM Citrix* desktop from CyberArk
* Copied over attached file to xbprodcbn1 server using winscp
* Copied over file to all mentioned ftp directiories
{code:bash}
# Checked if it is empty
[root@xbprodcbn1 data01]# for px in cropex epex gme hupx np omie opcom ote tge bsp; do ls -la /opt/data01/xbid_${px}_prod/OUT/acer; done
total 8
drwxr-xr-x 2 101022 101022 4096 Jan 11 16:44 .
drwxr-xr-x 4 101022 101022 4096 Jan 11 16:44 ..
total 8
drwxr-xr-x 2 101012 101012 4096 Aug 12 10:56 .
drwxr-xr-x 7 101012 101012 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101013 101013 4096 Aug 12 10:56 .
drwxr-xr-x 7 101013 101013 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101027 101027 4096 Aug 12 10:56 .
drwxr-xr-x 7 101027 101027 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101014 101014 4096 Aug 12 10:56 .
drwxr-xr-x 7 101014 101014 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101015 101015 4096 Aug 12 10:56 .
drwxr-xr-x 7 101015 101015 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101029 101029 4096 Aug 12 10:56 .
drwxr-xr-x 7 101029 101029 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101024 101024 4096 Aug 12 10:56 .
drwxr-xr-x 7 101024 101024 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101026 101026 4096 Aug 12 10:56 .
drwxr-xr-x 7 101026 101026 4096 Jul 13  2020 ..
total 8
drwxr-xr-x 2 101018 101018 4096 Jan 12 15:42 .
drwxr-xr-x 7 101018 101018 4096 Jan 12 15:42 ..

# Copied report file over to all directories
[root@xbprodcbn1 data01]# for px in cropex epex gme hupx np omie opcom ote tge bsp; do cp /home/hw120/acer_2020_h2.zip /opt/data01/xbid_${px}_prod/OUT/acer; done                                                          

# Checked it is there
[root@xbprodcbn1 data01]# for px in cropex epex gme hupx np omie opcom ote tge bsp; do ls -la /opt/data01/xbid_${px}_prod/OUT/acer; done
total 12319
drwxr-xr-x 2 101022 101022     4096 Jan 12 15:48 .
drwxr-xr-x 4 101022 101022     4096 Jan 11 16:44 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101012 101012     4096 Jan 12 15:48 .
drwxr-xr-x 7 101012 101012     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101013 101013     4096 Jan 12 15:48 .
drwxr-xr-x 7 101013 101013     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101027 101027     4096 Jan 12 15:48 .
drwxr-xr-x 7 101027 101027     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101014 101014     4096 Jan 12 15:48 .
drwxr-xr-x 7 101014 101014     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101015 101015     4096 Jan 12 15:48 .
drwxr-xr-x 7 101015 101015     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101029 101029     4096 Jan 12 15:48 .
drwxr-xr-x 7 101029 101029     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101024 101024     4096 Jan 12 15:48 .
drwxr-xr-x 7 101024 101024     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101026 101026     4096 Jan 12 15:48 .
drwxr-xr-x 7 101026 101026     4096 Jul 13  2020 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
total 12319
drwxr-xr-x 2 101018 101018     4096 Jan 12 15:48 .
drwxr-xr-x 7 101018 101018     4096 Jan 12 15:42 ..
-rw-r--r-- 1 root   root   12606240 Jan 12 15:48 acer_2020_h2.zip
{code}
","12/Jan/21 16:08;hw120;Also uploaded on xbprodsla1 to /xbid/reports
* Connected to 35 PS Support PROD FFM Citrix desktop from CyberArk
* Copied over attached file to xbprodsla1 server using winscp
Copied over file to mentioned directiory, extracted and fixed permissions
{code:bash}
ssh xbprodsla1
sudo su -
cp /home/hw120/acer_2020_h2.zip /xbid/reports/
cd /xbid/reports
unzip acer_2020_h2.zip
chown tomcat:tomcat *

[root@xbprodsla1 reports]# ls -tla /xbid/reports
total 1271716
drwxr-xr-x  4 tomcat tomcat    20480 Jan 12 16:04 .
-rw-r--r--  1 tomcat tomcat 12606240 Jan 12 15:59 acer_2020_h2.zip
-rw-r--r--  1 tomcat tomcat  4961767 Jan  1 09:45 2020-12_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2021-01-01-084500.xml
-rw-r--r--  1 tomcat tomcat  8883590 Jan  1 09:30 2020-12_WEIGHTED_AVERAGE_PRICE_2021-01-01-083000.xml
-rw-r--r--  1 tomcat tomcat 13372573 Jan  1 09:15 2020-12_TRADE_VOLUME_HOUR_TO_DELIVERY_2021-01-01-081500.xml
-rw-r--r--  1 tomcat tomcat 26143646 Jan  1 08:00 2020-12_INTRADAY_TRADE_VOLUME_2021-01-01-070000.xml
-rw-r--r--  1 tomcat tomcat 10879778 Jan  1 06:30 2020-12_BID_ASK_SPREAD_2021-01-01-053000.xml
-rw-r--r--  1 tomcat tomcat  4594374 Dec  1 09:45 2020-11_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-12-01-084500.xml
-rw-r--r--  1 tomcat tomcat  7464966 Dec  1 09:30 2020-11_WEIGHTED_AVERAGE_PRICE_2020-12-01-083000.xml
-rw-r--r--  1 tomcat tomcat 11142425 Dec  1 09:15 2020-11_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-12-01-081500.xml
-rw-r--r--  1 tomcat tomcat 21925496 Dec  1 08:00 2020-11_INTRADAY_TRADE_VOLUME_2020-12-01-070000.xml
-rw-r--r--  1 tomcat tomcat  9410115 Dec  1 06:30 2020-11_BID_ASK_SPREAD_2020-12-01-053000.xml
-rw-r--r--  1 tomcat tomcat  4828649 Nov  1 09:45 2020-10_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-11-01-084500.xml
-rw-r--r--  1 tomcat tomcat  7764748 Nov  1 09:30 2020-10_WEIGHTED_AVERAGE_PRICE_2020-11-01-083000.xml
-rw-r--r--  1 tomcat tomcat 11990206 Nov  1 09:15 2020-10_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-11-01-081500.xml
-rw-r--r--  1 tomcat tomcat 24531403 Nov  1 08:00 2020-10_INTRADAY_TRADE_VOLUME_2020-11-01-070000.xml
-rw-r--r--  1 tomcat tomcat  9553692 Nov  1 06:30 2020-10_BID_ASK_SPREAD_2020-11-01-053000.xml
-rw-r--r--  1 tomcat tomcat  4632467 Oct  1 09:45 2020-09_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-10-01-084500.xml
-rw-r--r--  1 tomcat tomcat  7480068 Oct  1 09:30 2020-09_WEIGHTED_AVERAGE_PRICE_2020-10-01-083000.xml
-rw-r--r--  1 tomcat tomcat 11838421 Oct  1 09:15 2020-09_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-10-01-081500.xml
-rw-r--r--  1 tomcat tomcat 24554885 Oct  1 08:00 2020-09_INTRADAY_TRADE_VOLUME_2020-10-01-070000.xml
-rw-r--r--  1 tomcat tomcat  9548684 Oct  1 06:30 2020-09_BID_ASK_SPREAD_2020-10-01-053000.xml
-rw-r--r--  1 tomcat tomcat  4711144 Sep  1 09:45 2020-08_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-09-01-084500.xml
-rw-r--r--  1 tomcat tomcat  7544123 Sep  1 09:30 2020-08_WEIGHTED_AVERAGE_PRICE_2020-09-01-083000.xml
-rw-r--r--  1 tomcat tomcat 11120341 Sep  1 09:15 2020-08_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-09-01-081500.xml
-rw-r--r--  1 tomcat tomcat 24442156 Sep  1 08:00 2020-08_INTRADAY_TRADE_VOLUME_2020-09-01-070000.xml
-rw-r--r--  1 tomcat tomcat  9487280 Sep  1 06:30 2020-08_BID_ASK_SPREAD_2020-09-01-053000.xml
-rw-r--r--  1 tomcat tomcat  4760060 Aug  1 09:45 2020-07_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-08-01-084500.xml
-rw-r--r--  1 tomcat tomcat  7718111 Aug  1 09:30 2020-07_WEIGHTED_AVERAGE_PRICE_2020-08-01-083000.xml
-rw-r--r--  1 tomcat tomcat 11090490 Aug  1 09:15 2020-07_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-08-01-081500.xml
-rw-r--r--  1 tomcat tomcat 22926975 Aug  1 08:00 2020-07_INTRADAY_TRADE_VOLUME_2020-08-01-070000.xml
-rw-r--r--  1 tomcat tomcat  9351242 Aug  1 06:30 2020-07_BID_ASK_SPREAD_2020-08-01-053000.xml
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM: Make logout work in devel mode,XP-4330,104977,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,MG726,pg759,pg759,08/Jan/21 15:13,22/Jan/21 13:55,22/Feb/21 13:26,22/Jan/21 13:55,,,3.2.x,,Shipping,,,,,,,,,"When developing frontend it's useful to run frontend localy and have them refreshed imediatelly without need to rebuild it and restart shipping-integration in order for changes to take effect. Only REST API methods are actually sent to shipping-integration module.

After migration to webpack -XP-761- it is not possible to test logout, because it is bound to renderion of `logout.html` page and webpack devserver won't proxy the request because this page is generated by frontend.",,jy268,MG726,pg759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2678400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ccy0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Jan/21 15:43;pg759;{{CustomLogoutFilter}} triggered by access to {{/logout.html}} was replaced with {{CustomLogoutHandler}} which is triggered by Spring Security logout bound to URL {{/ajaxLogout}}. The handler performs same actions as the filter did.

 Response from logout depends on caller. When invoked from frontend {{302 Found}} with redirect to {{/logout.html}} is returned and the GUI then renders logout page as usual. When invoked as REST API {{204 No Content}} is returned. This is Spring Security feature.

Note: When testing make sure that XP-4196 is already deployed at target environment so you won't get repeated login window when re-authentication after logout.","12/Jan/21 13:33;pg759;Builds done by Jenkins fail randomly due to Internet timeouts. After migration to webpack, build downloads node, npm and shipping-ui-react dependencies from Internet. This is lots of data and the chances of failure on Jenkisn are now very high.

The connectivity might change in time, but all attempts failed at Friday 4th and Tuesday 12th.","19/Jan/21 14:56;jy268;Hi [~pg759] I have migrated npm to yarn, you can try now, it should not fail. Please remember to rebase.","20/Jan/21 10:39;jy268;Please test logout functionality on any of systemtest envs.","22/Jan/21 12:17;MG726;Tested on SYT1 with shipping module version 3.2.1 

*Test steps:*
 1. login with user SPMADM02 -> login successful
 2. click on the user name in right corner and choose Log Out -> user was logged out
 3. again log in with user SPMADM02 -> login pop-up window appeared successfully and after the full-filling of credentials user was successfully logged in again

 Test {color:#008000}OK{color}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auditd Failed User Login cor -> amq (XBID),XP-4327,104950,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zs244,zs244,zs244,08/Jan/21 12:01,12/Jan/21 14:34,22/Feb/21 13:26,08/Jan/21 16:26,,,,,,,,,,TechOps,,,,"From emails regarding:
_FW: [Ticket#2020120839001361] Action required. Auditd – successful login after brute force attempts by user RABBITMQ_

- we have failed login attempts on amq from cor sources like xbctpgcor1 and xbctpgcor1
- it is unlikely that there was a malicious brute force attack

Please investigate the cause of the failed attempts. Most likely .pem
",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3801600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gf",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jan/21 14:03;zs244;1. ) fix > 5 Jan 2021 06:47:02 CET	USER_LOGIN|failed	xbctpgcor1	10.139.41.39	xbctpgamq1	10.139.41.36	RABBITMQ

- check: `[root@xbctpgcor1 ~]# su -c 'ssh -v rabbitmq@xbctpgamq1' tomcat`
- for working system the authentication (publickey) succeeds using the `/home/tomcat/.ssh/id_rsa`
- check if this file exists: `ls -all /home/tomcat/.ssh`
- if not then create one `ssh-keygen -t rsa`
- copy to addressed system `xbctpgamq1` authorized keys
- then check if file is in `/home/tomcat/.ssh/config` as `IdentityFile ~/.ssh/id_rsa`
- check again: `[root@xbctpgcor1 ~]# su -c 'ssh -v rabbitmq@xbctpgamq1' tomcat`

{color:#00875A}done - works again{color}

2.) fix > 5 Jan 2021 06:12:40 CET	USER_LOGIN|failed	xbctpfcor1	10.139.41.45	xbctpfamq1	10.139.41.42	RABBITMQ

- check: `[root@xbctpgcor1 ~]# su -c 'ssh -v rabbitmq@xbctpfamq1' tomcat`
- for working system the authentication (publickey) succeeds using the `/home/tomcat/.ssh/id_rsa`
- check if this file exists: `ls -all /home/tomcat/.shh/`
- id_rsa.pub exists
- copy to addressed system `xbctpfamq1` authorized keys
- then check if file is in `/home/tomcat/.ssh/config` as `IdentityFile ~/.ssh/id_rsa`
- check again: `[root@xbctpgcor1 ~]# su -c 'ssh -v rabbitmq@xbctpgamq1' tomcat`

{color:#00875A}done - works again{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CORE module never stops gracefully in time, it must be killed",XP-4321,104864,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,MG726,eg288,eg288,07/Jan/21 18:11,20/Jan/21 16:13,22/Feb/21 13:26,20/Jan/21 16:13,,,3.1.6,,,,,,,,,,,"Tomcat stop.sh script never ends gracefully, instead the tomcat instance must be killed.

Example from syt2 environment:
{code}
[tomcat@xbsyt2cor1 tomcat]$ bin/stop.sh 
Using CATALINA_BASE:   /xbid/xbid-syt2-cor1/tomcat
Using CATALINA_HOME:   /xbid/xbid-syt2-cor1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-syt2-cor1/tomcat/temp
Using JRE_HOME:        /
Using CLASSPATH:       /xbid/xbid-syt2-cor1/tomcat/bin/bootstrap.jar:/xbid/xbid-syt2-cor1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-syt2-cor1/tomcat/pid
Tomcat did not stop in time.
To aid diagnostics a thread dump has been written to standard out.
Killing Tomcat with the PID: 9227
The Tomcat process has been killed.
{code}

The catalina.out log contains warnings that a thread has been started by the application, but it was not stopped.
{code}
2020-06-10T16:59:29.097+0200 WARNING org.apache.catalina.loader.WebappClassLoaderBase - The web application [m7core] registered the JDBC driver [org.postgresql.Driver] but failed to unregister it when the web application was stopped. To p
revent a memory leak, the JDBC Driver has been forcibly unregistered. 
2020-06-10T16:59:29.098+0200 WARNING org.apache.catalina.loader.WebappClassLoaderBase - The web application [m7core] appears to have started a thread named [pool-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
 java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
 java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
 java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748) 
{code}",,eg288,MG726,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2764800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zof",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-2478-tobago-upgrade-clean01,XP-4152-acceptance,develop,XP-2400,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Jan/21 19:00;eg288;MultiNodeDataSourceResolver has not been closing auxiliary datasources created to find database master node -> fixed. 

After the fix the tomcat stop.sh script finishes gracefully.
{code}
[tomcat@xbsyt2cor1 tomcat]$ bin/stop.sh 
Using CATALINA_BASE:   /xbid/xbid-syt2-cor1/tomcat
Using CATALINA_HOME:   /xbid/xbid-syt2-cor1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-syt2-cor1/tomcat/temp
Using JRE_HOME:        /
Using CLASSPATH:       /xbid/xbid-syt2-cor1/tomcat/bin/bootstrap.jar:/xbid/xbid-syt2-cor1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-syt2-cor1/tomcat/pid
Tomcat stopped.
{code}

And catalina.out log contains no warnings
{code}
2021-01-07T18:55:59.999+0100 INFO org.apache.catalina.core.StandardServer - A valid shutdown command was received via the shutdown port. Stopping the Server instance. 
2021-01-07T18:55:59.999+0100 INFO org.apache.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler [""http-nio-60808""] 
2021-01-07T18:56:00.005+0100 INFO org.apache.coyote.ajp.AjpNioProtocol - Pausing ProtocolHandler [""ajp-nio-0.0.0.0-61808""] 
2021-01-07T18:56:00.011+0100 INFO org.apache.catalina.core.StandardService - Stopping service [Catalina] 
2021-01-07T18:56:01.035+0100 INFO org.apache.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler [""http-nio-60808""] 
2021-01-07T18:56:01.038+0100 INFO org.apache.coyote.ajp.AjpNioProtocol - Stopping ProtocolHandler [""ajp-nio-0.0.0.0-61808""] 
2021-01-07T18:56:01.041+0100 INFO org.apache.coyote.http11.Http11NioProtocol - Destroying ProtocolHandler [""http-nio-60808""] 
2021-01-07T18:56:01.042+0100 INFO org.apache.coyote.ajp.AjpNioProtocol - Destroying ProtocolHandler [""ajp-nio-0.0.0.0-61808""] 
{code}
","08/Jan/21 11:51;eg288;Test proposal: 
* deploy it
* execute a few tests like order add, create trade, some reference data change
* stop the core and verify it was stopped gracefully
* start core and verify all the previous changes are still in the place
* verify logs there are no errors","20/Jan/21 16:13;MG726;Tested on SYT3 with xbid core version 3.1.12 (tomcat@xbsyt3cor1):
{code:java}
$ cd /xbid/xbid-syt3-cor1/tomcat/

$ ./stop.sh
Using CATALINA_BASE: /xbid/xbid-syt3-cor1/tomcat
Using CATALINA_HOME: /xbid/xbid-syt3-cor1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-syt3-cor1/tomcat/temp
Using JRE_HOME: /
Using CLASSPATH: /xbid/xbid-syt3-cor1/tomcat/bin/bootstrap.jar:/xbid/xbid-syt3-cor1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID: /xbid/xbid-syt3-cor1/tomcat/pid
Tomcat stopped.
There are no matching processes by xbid-syt3-cor1. Returning.
{code}
Core stopped gracefully.

Changes made via SOB persist the stopping the core. 

Test {color:#008000}OK{color}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Operations Data Space Hits Threshold on SIMU/PROD Systems,XP-4318,104850,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zs244,zs244,zs244,07/Jan/21 14:34,21/Jan/21 10:47,22/Feb/21 13:26,15/Jan/21 10:17,,,,,,,,,,TechOps,toilwork,,,"Several occurrences on simu/prod like

{quote}CRITICAL on xbsimupdb1 | Mount: /var - used: 98% - 4.1 GB/4.2 GB Used/Total{quote}

- solution is to clear operations data by yum clean all
- full /var/cache is most likely related to migration to premium rhel subscription, and there were left behind metadata from old subscription - please clarify

Please clarify the cause of this.",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4351,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3283200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,07/Jan/21 14:34,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/21 14:57;zs244;Hi [~cv524], [~kw089], could you have a look if its related to your current activities regarding rhel subscription or similar?","07/Jan/21 14:59;zs244;Fix done for these system by [~cs687] and me: _yum clean all_
- xbsimupdb4 done
- xbsimupdb3 done
- xbsimupdb2 done
- xbsimupdb1 done
- xbprodpdb1 done
- xbprodpdb2 done
- xbprodpdb3 done
- xbprodpdb4 done","07/Jan/21 16:00;zs244;Consulted with Lambert:

- patching and OS upgrade operations fills the ""/var/cache/yum/"" (in our very general case ""/var/cache/yum/x86_64/7Server/"") with cached metadata.
- besides yum clean all also do _rm -rf /var/cache/yum/*_ and _yum repolist_.
- If even after this set of commands the ""/var"" filesystem has more then 80% utilization, it is reasonable to extend this filesystem by suitable size like
{quote}lvextend -r -L +<desired added size in gigabytes>G /dev/rootvg/lv_var{quote}

The size of ""/var"" filesystem should be 4GB as minimal accepted size.","07/Jan/21 16:06;zs244;Still open question: Was there any specific patching or OS upgrade or similar activity?","12/Jan/21 11:43;zs244;Scope of this issue is now to extend the filesystem on the occasions and do the suggested clean up:

{quote}yum clean all
rm -rf /var/cache/yum/*
yum repolist
{quote}
","13/Jan/21 17:27;zs244;Today again, will do the 3 mentioned steps for these systems: 

kapacitorAPP  4:28 PM
WARNING on xbprodpdb3 | Mount: /var - used: 86% - 3.6 GB/4.2 GB Used/Total
WARNING on xbprodpdb1 | Mount: /var - used: 86% - 3.6 GB/4.2 GB Used/Total
WARNING on xbprodpdb4 | Mount: /var - used: 86% - 3.6 GB/4.2 GB Used/Total
WARNING on xbprodpdb2 | Mount: /var - used: 86% - 3.6 GB/4.2 GB Used/Total","13/Jan/21 17:36;zs244;Fixed for the moment, extension still open.","14/Jan/21 10:46;zs244;Extended the xbsimupdb1-4 /var to 8GB and did the mentioned three steps again.","15/Jan/21 10:17;zs244;Extended xbprodpdb1-4 /var to 8GB and did the three clean-up steps again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unicorn's request - ECP's database and Application health check.,XP-4314,104808,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yn731,yn731,yn731,06/Jan/21 15:03,21/Jan/21 13:38,15/Feb/21 13:46,21/Jan/21 13:36,,,3.1.x,,,,,,,,,,,"From Unicorn's email:

_In order to prevent any further issues, we would like to check archivation/performance status after some time period. Could you please gather the following information:_
 * archivation logs from the active node (currently http://xbprodecp1:8080/ECP_MODULE_XBID/ADMIN/monitoringPage.seam?cid=2)
 * ECP DB tables sizing and count of messages",,hw120,qo794,yn731,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SMXBID-2325,,,,,,,"07/Jan/21 11:09;qo794;ecp-archive-logs.tgz;https://jira.deutsche-boerse.com/secure/attachment/91496/ecp-archive-logs.tgz",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2678400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gm",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/21 11:10;qo794;Logs from the archive job attached  [^ecp-archive-logs.tgz] ","20/Jan/21 14:29;zs244;xbprodecp=# \dt+
 List of relations
 Schema | Name | Type | Owner | Size | Description
-----------+------------------------------+-------+-----------+------------+-------------
 xbprodecp | auditlog | table | xbprodecp | 305 MB |
 xbprodecp | auth_token | table | xbprodecp | 8712 kB |
 xbprodecp | certificate | table | xbprodecp | 120 kB |
 xbprodecp | certificate_authority | table | xbprodecp | 8192 bytes |
 xbprodecp | certificate_record | table | xbprodecp | 40 kB |
 xbprodecp | component_info | table | xbprodecp | 56 kB |
 xbprodecp | connection_validation | table | xbprodecp | 40 kB |
 xbprodecp | control_ecp | table | xbprodecp | 0 bytes |
 xbprodecp | ds_content_version | table | xbprodecp | 0 bytes |
 xbprodecp | ecp_configuration | table | xbprodecp | 48 kB |
 xbprodecp | endpoint | table | xbprodecp | 48 kB |
 xbprodecp | event | table | xbprodecp | 160 kB |
 xbprodecp | failover_lock | table | xbprodecp | 72 kB |
 xbprodecp | gateway | table | xbprodecp | 0 bytes |
 xbprodecp | information_message | table | xbprodecp | 8192 bytes |
 xbprodecp | message | table | xbprodecp | 456 kB |
 xbprodecp | message_arch | table | xbprodecp | 1220 MB |
 xbprodecp | message_content | table | xbprodecp | 2312 kB |
 xbprodecp | message_content_arch | table | xbprodecp | 6904 MB |
 xbprodecp | message_content_storage | table | xbprodecp | 1560 kB |
 xbprodecp | message_content_storage_arch | table | xbprodecp | 3128 MB |
 xbprodecp | messagebox_edc | table | xbprodecp | 280 kB |
 xbprodecp | messagebox_edc_arch | table | xbprodecp | 668 MB |
 xbprodecp | messagebox_mn | table | xbprodecp | 0 bytes |
 xbprodecp | messagebox_mn_arch | table | xbprodecp | 0 bytes |
 xbprodecp | messageregister_edc | table | xbprodecp | 448 MB |
 xbprodecp | messageregister_mn | table | xbprodecp | 0 bytes |
 xbprodecp | messaging_component | table | xbprodecp | 144 kB |
 xbprodecp | node | table | xbprodecp | 48 kB |
 xbprodecp | private_key | table | xbprodecp | 48 kB |
 xbprodecp | registration_request | table | xbprodecp | 8192 bytes |
 xbprodecp | registrations | table | xbprodecp | 96 kB |
 xbprodecp | sent_message_register | table | xbprodecp | 8192 bytes |
 xbprodecp | unreachable_component | table | xbprodecp | 0 bytes |
(34 rows)","20/Jan/21 14:30;zs244;xbprodecp=# select count\(*\) from message;
 count
 -------
 204
 (1 row)","20/Jan/21 14:32;zs244;[~yn731] I provided the information here in the comments, is this everything you asked for?","21/Jan/21 09:52;yn731;Thanks, [~zs244] I believe that should be it. I guess we can close this as soon as Unicorn finishes the analysis. I will take it with me for now","21/Jan/21 13:36;yn731;From Unicorn:
{quote}_Hello Ramiro,_

_Thank you for the output, it looks alright. Messages are correctly processed, there are no hanging messages in ""live"" message table. Also, archivation task is finished within a few seconds._

_*Could we agree to repeat this check after a month again? To double-check the situation, and eventually reconsider preventive truncate of ""non-live"" tables (_arch) to keep the system smooth-running.""*_
{quote}
We will close this ticket and continue in XP-4393 for the 2nd round of checks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: XBID external test - VM power cycle - CUTE TSO & shared services,XP-4313,104803,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,06/Jan/21 14:39,07/Jan/21 22:32,22/Feb/21 13:26,07/Jan/21 16:13,,,,,,,,,,TechOps,toilwork,,,"Perform VM power cycling on the below-listed environments

CUTE TSO + shared services VMs

 

Customer communication - inform that all *CUTEs/LIPs* will not be available during this maintenance

 

For each shared services VM
 * TO : shutdown environment-specific VMs (list below)
 * Syseng: startup VM 
 * Syseng: perform VM check

|Name|Host|Compatibility|EVC Mode|
|xbcutsctp1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbcutsedb1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsidm1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsntp1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutspmi1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsrep1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbmplsssl1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbmplsweb1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbtestdbr1|fresxegy1008.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbtinfclt1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|

 

For each environment Env in

(CUTE TSO)
 * stop the environment Env
 * for all Env environment-specific VM (see list below)
 ** TO : shutdown environment-specific VMs (list below)
 ** Syseng: startup VM 
 ** Syseng: perform VM check
 * start environment Env
 * product team sanity check the environment Env

 

LIST OF VMs
  
|xbctsoamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctsocor1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctsodow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctsoecp1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctsoenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9197,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,yn731,,,,,,,,,,,,,Internal Deployment Request,eg288,,,,No,3888000,,CTSO,,,,,,dm700,lw641,ox626,rehapav,sw455,,07/Jan/21 17:00,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy0i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Jan/21 16:02;hw120; 
{code:bash}
ssh entestauto1

git clone git@github.deutsche-boerse.de:dev/energy.powermaintenance.git
cd energy.powermaintenance
cat <<EOF > pm_hosts
xbctsoamq1
xbctsocor1
xbctsodow1
xbctsoecp1
xbctsoenq1
xbcutspmi1
xbcutsrep1
xbmplsssl1
xbmplsweb1
EOF

# check if all hosts are responding
./ping_all.sh

# detect and fill in instance list inventory
./detect_tomcat.sh
./detect_rabbitmq.sh
./detect_apache.sh
./detect_haproxy.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh
./check_apache.sh
./check_haproxy.sh


# stop tomcat instances and check if they are down
./stop_tomcat.sh
./check_tomcat.sh

# stop rabbitmq instances and check if they are down
./stop_rabbitmq.sh
./check_rabbitmq.sh 

# stop apache instances and check if they are down
./stop_apache.sh
./check_apache.sh 

# stop haproxy instances and check if they are down
./stop_haproxy.sh
./check_haproxy.sh 

# haproxy scripts weren't working, had to stop them manually

# Hand them over to Lambert

# Start them afterwards

# check if all hosts are responding
./ping_all.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh
./check_apache.sh
./check_haproxy.sh

# start rabbitmq instances and check if they are down
./start_rabbitmq.sh
./check_rabbitmq.sh 
# start script doesn't work for old perl deployed rabbits, had to start it manually from the instances
./check_rabbitmq.sh 

# start tomcat instances and check if they are down
./start_tomcat.sh
./check_tomcat.sh

# start apache instances and check if they are down
./start_apache.sh
./check_apache.sh 

# start haproxy instances and check if they are down
./start_haproxy.sh
./check_haproxy.sh 

# haproxy scripts weren't working, had to stop them manually

# start scripts doesn't work for old perl deployed tomcats, had to start them manually fomr the instances
# ctso cor didn't started, again the same issue with missing journal file which never existed
# cleaning journal in db
[root@xbtestpdb1 ~]# su - postgres
Last login: Thu Jan  7 11:42:53 CET 2021
-bash-4.2$ ll /var/lib/|grep ctso
drwxr-xr-x   5 postgres postgres   43 Mar 19  2019 pgsql_ctso_25024
-bash-4.2$ psql -p 25024 -d xbctsocor -c ""delete from m7_999_revision_index;""
DELETE 1
-bash-4.2$ psql -p 25024 -d xbctsocor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
INSERT 0 1
# and starting cor and other tomcat instances manuall

# About half of the instances on xbcutspmi1 host were not starting by script, had to start them manually
# Instances running on xbcutsrep1, only ansible deployed instances started fine, others had to be started by hand

# 


===============================================================

ssh to xbcutsctp1 and stop instance manually

#ssh to xb cute, ctso, lipa, lipb ecp1 hosts and stop instances there

ssh xbcutsedb1 and stop all dbs
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_cuteecp_25503/data/9.5 stop
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_ctsoecp_25524/data/9.5 stop
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_lipaecp_25516/data/9.5 stop
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_lipbecp_25517/data/9.5 stop

# Hand them over to Lambert

# Start them afterwards

/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_cuteecp_25503/data/9.5 start
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_ctsoecp_25524/data/9.5 start
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_lipaecp_25516/data/9.5 start
/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_lipbecp_25517/data/9.5 start

#ssh to xb cute, ctso, lipa, lipb ecp1 hosts and start instances there

#ssh to xbcutsctp1 and start instance manually
{code}



 ","07/Jan/21 16:10;hw120;I also had to update powermaintenance scripts with missing apache instances handling script
[https://github.deutsche-boerse.de/dev/energy.powermaintenance/pull/3/files]
","07/Jan/21 22:32;hw120;There were many issues during stop/start process, namely
* some of the tomcat instances were not possible to stop with stop script, they had to be killed
* some of the running tomcat/java instances were missing instance directory, leftover from cleanup
* core instances were failing after vm reboot, investigation still in progress
* there were instances missing from the inventory, they were still only in perl xml configs
* Still missing monitoring for a couple of instance types like apache, slapd, edb postgres, ntp servers, clt gluster

Unfortunately, power maintenance scripts are still far from ideal and require a bit of tuning
* They can't start rabbitmq instances deployed by perl
* They can't start all tomcat instances deployed by perl
* They can't start all haproxy instances deployed by perl
We should focus on tuning them before the next power maintenance, it can save us a lot of problems.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XIBD CORE instance fails to start on missing journal file,XP-4309,104773,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eg288,hw120,hw120,06/Jan/21 10:56,18/Jan/21 11:55,22/Feb/21 13:26,18/Jan/21 11:55,,,3.1.x,,,,,,,,,,,"Tested on CTPK, but it happened on most of the CUTE envs during power cycling operation described in XP-4284, XP-4287 and XP-4304.

 

Considering problems in previous power cycling, I investigated start/stop scripts and they all seem fine.

This time, I will try to rule out the possible influence of SYSENG changes and our automation scripts by
 * stopping rabbitmq and tomcat instances manually on one perl and one ansible env - ctpm/ctpk
 * restarting VMs
 * starting rabbitmq and tomcat instances manually on one perl and one ansible env - ctpm/ctpk
 * check the status

What I did exactly is described in https://jira.deutsche-boerse.com/browse/XP-4304

On environment CTPK we got this problem after reboot of VM, when I tried to start the cor.

I got error
{code:java}
# start failed, error in the cor standard log is the same, seems like application issue
vim /xbid/logs/xbid-ctpk-cor1/xb_xbid_ctpk_cor-1_standard_ixe.log

2021-01-06T09:03:17.221Z [overScheduler-1][][] ERROR o.s.s.s.TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210106/data-51610-1 at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:478) at com.deutscheboerse.energy.m7.core.in.journal.Replayer.<init>(Replayer.java:28) at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.createReplayer(AbstractChronicleQJournaler.java:122) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.getInitialDateTime(M7LifecycleManagerImpl.java:322) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.createStartupTask(M7LifecycleManagerImpl.java:422) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.startMaster(M7LifecycleManagerImpl.java:176) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.tryLock(M7LifecycleManagerImpl.java:233) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$null$0(M7LifecycleManagerImpl.java:160) at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42) at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$startFailoverTimer$1(M7LifecycleManagerImpl.java:160) at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210106/data-51610-1 at net.openhft.chronicle.VanillaChronicleUtils.mkFiles(VanillaChronicleUtils.java:42) at net.openhft.chronicle.VanillaDataCache.dataFor(VanillaDataCache.java:69) at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:454) ... 17 common frames omitted
{code}
But such file didn't existed before I stopped the instance.

To fix it, I had to do journal cleanup in the database
{code:java}
[hw120@entestauto1 ~]$ ssh xbtestpdb1
[hw120@xbtestpdb1 ~]$ sudo su -
[root@xbtestpdb1 ~]# su - postgres
-bash-4.2$ ll /var/lib/|grep ctp
drwxr-xr-x   6 postgres postgres   56 Jun 22  2020 pgsql_ctpa_25020
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpb_25021
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpc_25022
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpd_25023
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpe_25026
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpf_25027
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctpg_25028
drwxr-xr-x   5 postgres postgres   43 Mar  4  2019 pgsql_ctph_25029
drwxr-xr-x   5 postgres postgres   43 Mar  5  2019 pgsql_ctpi_25030
drwxr-xr-x   5 postgres postgres   43 Mar  5  2019 pgsql_ctpj_25031
drwxr-xr-x   5 postgres postgres   43 Mar  5  2019 pgsql_ctpk_25032
drwxr-xr-x   5 postgres postgres   43 Mar 20  2019 pgsql_ctpl_25033
drwx--x--x   6 postgres postgres   56 Mar  6  2020 pgsql_ctpm_25034
-bash-4.2$ psql -p 25032 -d xbctpkcor -c ""delete from m7_999_revision_index;""
DELETE 1
-bash-4.2$ psql -p 25032 -d xbctpkcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
INSERT 0 1
{code}
and then cor started successfully.

 

I also did the test with CTPM which is still deployed by perl, there I tested only rebooting cor VM.

There it started without problem after I rebooted the host.

 ",,eg288,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4321,,,,,,,XP-4304,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3024000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,06/Jan/21 10:56,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zo1",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/21 11:55;eg288;Unable to reproduce on syt2 env, even after VM (machine xbsyt2cor1) restart -> closing the issue as not reproducable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Implement data ingestion for current production,XP-4308,104772,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,qo794,06/Jan/21 10:46,06/Jan/21 10:46,22/Feb/21 13:26,06/Jan/21 10:46,,,,,,,,,,,,,,"We want current production metrics. Design a solution how to push it to target databases.

TODO:
* kotlin application (create task for VM)
* poll periodically ElasticSearch
* write metrics extractor from ElasticSearch
* design a data model - drafted in Epic

",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,,,,,,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zoi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) CMI should fetch files from ECP one by one (fetch-process-acknowledge),XP-4306,104764,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,jy268,hj444,06/Jan/21 09:54,27/Jan/21 15:26,22/Feb/21 13:26,27/Jan/21 15:26,,,3.1.x,,CMM,,,,,Tech-Debt,,,,"Currently CMI uses old deprecated methods for fetching files from ECP resulting in downloading all files as a list and then processing them. In details it downloads files one by one and add them to the list, when download of one file fails, whole list is rejected. It results in another download attempt during next ECP files check. Another approach should be used, which is currently implemented in SMI:
1. download file
2. process file
3. acknowledge file
It can be achieved by using ConfirmAfterProcessingEcpMessageReceiver interface in commons-transport.",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2160000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:9i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/21 09:55;hj444;Actual date 5.1.2021
SYT3 : Version R3.2.3 (Build f8ed207ffd3066b56f11d298d662e63e4fbe80f9)
APG TSO endpoint for ECP set.
CMI - Inbound - Outbound files created with Sender/Receiver APG TSO, and ECP
DE-AT,PT-ES, FR-DE
File configurations valid from 6.1.2021. Test continue 6.1.","27/Jan/21 15:26;hj444;Tested -  ECP :
Receiving outbound files from XBID
 - Outbound files generated based on distribution event and sent via ECP.
Sending Inbound files to XBID - publishing files.
 - Inbound files (NTC, CAS) where sent from User Endpoint 
Sending/Receiving ACK file . Ack was received by XBID and sent from User endpoint
Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) SM: replace grunt with webpack,XP-4305,104753,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,ll664,jy268,06/Jan/21 08:57,27/Jan/21 09:11,22/Feb/21 13:26,27/Jan/21 09:11,,,3.2.x,,Shipping,,,,,,,,,"{color:#00875a}*[ Cleaner and easier future development on SPM ]*{color}

Current frontend development experience is not very pleasant. It requires running jetty, grunt, disabling CORS, grunt watch is very slow, etc.

Replace the JS build with webpack and introduce webpack-dev-server for local development.

 

Use webpack with as much same code we have right now as possible ",,hj444,jy268,qo794,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4371,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2246400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i000000000000000eo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,HOT Sprint 25 (S),Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_reporting_tools_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Jan/21 15:09;jy268;[~qo794] as a part of review, could you please do a clean build and check if FE works fine?
{code}
mvn clean install
{code}
only","08/Jan/21 09:38;qo794;Build works fine, FE is reachable, but only when using maven 3.6.3 to build the project. Jenkins has maven 3.6.2, which should be fine as well, but shipping release job and pipeline have 3.6.0 configured.","08/Jan/21 12:13;jy268;Please do a smoke test if shipping ui works fine.","19/Jan/21 10:38;tr866;Note: Latest version 3.2.0-SNAPSHOT-0dd3d6752bacb7b2ddc401df62f7c3ffe2622639 is {color:#de350b}not compatible{color} with {color:#de350b}tosca-fake dataset{color}. At least smi couldn't be started on docker.","21/Jan/21 11:35;hj444;Retest : SYT1 : SPM version : 3.2.0.1
","21/Jan/21 15:22;hj444;Retest : SYT1 :
* SPM version : 3.2.1
* XBID : Version R3.2.4 (Build fad912d6a0f8988766558c3939737894fe94084b)

 GUI check :
Login and check pages : Users with different roles.
1. SPMADM02 - Super Admin
    SPMADM03 - Super Admin
2. AMPTSOAD - TSO Admin role
3. CCPADMIN - CCP Admin
4. CCPOPERA - CCP Operations
5. EPEXAD02 -  CCP Operations + SA Oper + SA Admin + CCP Admin
6. RTESAOP1 - SA Operations
7. AMPCENAD - Central Admin -> Download report for IC
8. RTESAOPR - SA Oper Read Only","25/Jan/21 16:29;hj444;9. SPMADM02 - Create User 
                           Create User Group
                           Create CCP","27/Jan/21 09:11;hj444;GUI works ok.
Jira will  be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SERVICE CLONE: XBID external test - VM power cycle - CUTE K,L,M, CUTE PX",XP-4304,104747,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,05/Jan/21 22:25,06/Jan/21 16:03,22/Feb/21 13:26,06/Jan/21 16:03,,,,,,,,,,TechOps,toilwork,,,"Perform VM power cycling on the below-listed environments

CUTE K, CUTE L, CUTE M and CUTE PX

 

Customer communication - inform that above-listed environments will not be available during this maintenance

 

For each environment Env in

(CUTE K, CUTE L, CUTE M, CUTE PX)
 * stop the environment Env
 * for all Env environment-specific VM (see list below)
 ** TO : shutdown environment-specific VMs (list below)
 ** Syseng: startup VM 
 ** Syseng: perform VM check
 * start environment Env
 * product team sanity check the environment Env

 

LIST OF VMs
|xbctpkamq1|fresxegy2007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpkcor1|fresxegy2010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Broadwell"" Generation|
|xbctpkdow1|fresxegy2008.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpkenq1|fresxegy2007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplamq1|fresxegy1010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplcor1|fresxegy1007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpldow1|fresxegy1008.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpmcor1|fresxegy2007.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbctpmenq1|fresxegy2009.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|

|xbcuteamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutecor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbcutedow1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcuteecp1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcuteenq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9194,,,,,,,,,,,,SERVICE-9194,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,yn731,,,,,,,,,,,,,Internal Deployment Request,eg288,,,,No,3974400,,CTPK,CTPL,CTPM,CUTE,,,dm700,lw641,ox626,rehapav,sw455,,06/Jan/21 17:00,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 22:33;hw120;Considering problems in previous power cycling, I investigated start/stop scripts and they all seem fine.

This time, I will try to rule out the possible influence of SYSENG changes and our automation scripts by
 * stopping rabbitmq and tomcat instances manually on one perl and one ansible env - ctpm/ctpk
 * restarting VMs
 * starting rabbitmq and tomcat instances manually on one perl and one ansible env - ctpm/ctpk
 * check the status

Continue with the rest depending on the result.","06/Jan/21 11:17;hw120;As we have environments being deployed by perl and ansible in the list, I will use scripts for power maintenance to execute it.

[https://github.deutsche-boerse.de/dev/energy.powermaintenance]

 
{code:java}
# from entestauto1 or enprodauto1
git clone git@github.deutsche-boerse.de:dev/energy.powermaintenance.git
cd energy.powermaintenance
cat <<EOF > pm_hosts
xbctpkamq1
xbctpkcor1
xbctpkdow1
xbctpkenq1
xbctplamq1
xbctplcor1
xbctpldow1
xbctplenq1
xbctpmcor1
xbctpmenq1
xbcuteamq1
xbcutecor1
xbcutedow1
xbcuteecp1
xbcuteenq1
EOF

# check if all hosts are responding
./ping_all.sh

# detect and fill in instance list inventory
./detect_tomcat.sh
./detect_rabbitmq.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh

# Stopping xb ctpk cor1 instance
ssh xbctpkcor1
sudo su -
su - tomcat
cd /xbid/xbid-ctpk-cor1/tomcat/bin
./stop.sh
ps aux |grep cor1
[root@xbctpkcor1 ~]# ll /xbid/journal/m7-msgs/20210106/
total 668
-rw-r----- 1 tomcat tomcat 67108864 Jan  6 03:02 data-25805-0
-rw-r----- 1 tomcat tomcat 67108864 Jan  6 09:48 data-25805-1
-rw-r----- 1 tomcat tomcat 16777216 Jan  6 09:48 index-0
reboot

# Stopping xb ctpk sob and cmm instances
ssh xbctpkenq1
sudo su -
su - tomcat
tomcat@xbctpkenq1:[/xbid]$ cd xbid-ctpk-cmm1/tomcat/bin/
tomcat@xbctpkenq1:[/xbid/xbid-ctpk-cmm1/tomcat/bin]$ ./stop.sh
Using CATALINA_BASE:   /xbid/xbid-ctpk-cmm1/tomcat
Using CATALINA_HOME:   /xbid/xbid-ctpk-cmm1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-ctpk-cmm1/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /xbid/xbid-ctpk-cmm1/tomcat/bin/bootstrap.jar:/xbid/xbid-ctpk-cmm1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-ctpk-cmm1/tomcat/pid
Tomcat stopped.
tomcat@xbctpkenq1:[/xbid/xbid-ctpk-cmm1/tomcat/bin]$ cd ../../..
tomcat@xbctpkenq1:[/xbid]$ cd xbid-ctpk-sob1/tomcat/bin/
tomcat@xbctpkenq1:[/xbid/xbid-ctpk-sob1/tomcat/bin]$ ./stop.sh 
Using CATALINA_BASE:   /xbid/xbid-ctpk-sob1/tomcat
Using CATALINA_HOME:   /xbid/xbid-ctpk-sob1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-ctpk-sob1/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /xbid/xbid-ctpk-sob1/tomcat/bin/bootstrap.jar:/xbid/xbid-ctpk-sob1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-ctpk-sob1/tomcat/pid
Tomcat stopped.
tomcat@xbctpkenq1:[/xbid/xbid-ctpk-sob1/tomcat/bin]$ ps aux |grep java
tomcat   64241  0.0  0.0 112704   984 pts/1    S+   09:53   0:00 grep --color=auto java
logout
reboot

# Stopping xb ctpk cmi, smc, smi instances
ssh xbctpkdow1
sudo su -
su - tomcat
tomcat@xbctpkdow1:[/xbid]$ cd xbid-ctpk-smi1/tomcat/bin/
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-smi1/tomcat/bin]$ ./stop.sh 
Using CATALINA_BASE:   /xbid/xbid-ctpk-smi1/tomcat
Using CATALINA_HOME:   /xbid/xbid-ctpk-smi1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-ctpk-smi1/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /xbid/xbid-ctpk-smi1/tomcat/bin/bootstrap.jar:/xbid/xbid-ctpk-smi1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-ctpk-smi1/tomcat/pid
Tomcat stopped.
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-smi1/tomcat/bin]$ cd ../../../xbid-ctpk-smc1/tomcat/bin/
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-smc1/tomcat/bin]$ ./stop.sh 
Using CATALINA_BASE:   /xbid/xbid-ctpk-smc1/tomcat
Using CATALINA_HOME:   /xbid/xbid-ctpk-smc1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-ctpk-smc1/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /xbid/xbid-ctpk-smc1/tomcat/bin/bootstrap.jar:/xbid/xbid-ctpk-smc1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-ctpk-smc1/tomcat/pid
Tomcat did not stop in time.
To aid diagnostics a thread dump has been written to standard out.
Killing Tomcat with the PID: 54867
The Tomcat process has been killed.
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-smc1/tomcat/bin]$ cd ../../../xbid-ctpk-cmi1/tomcat/bin/
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-cmi1/tomcat/bin]$ ./stop.sh 
Using CATALINA_BASE:   /xbid/xbid-ctpk-cmi1/tomcat
Using CATALINA_HOME:   /xbid/xbid-ctpk-cmi1/tomcat
Using CATALINA_TMPDIR: /xbid/xbid-ctpk-cmi1/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /xbid/xbid-ctpk-cmi1/tomcat/bin/bootstrap.jar:/xbid/xbid-ctpk-cmi1/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /xbid/xbid-ctpk-cmi1/tomcat/pid
Tomcat stopped.
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-cmi1/tomcat/bin]$ ps aux |grep java
tomcat   42800  0.0  0.0 112704   984 pts/1    S+   09:57   0:00 grep --color=auto java
tomcat@xbctpkdow1:[/xbid/xbid-ctpk-cmi1/tomcat/bin]$ logout
[root@xbctpkdow1 ~]# reboot

# Stopping xb ctpk amq1 instances
ssh xbctpkamq1
sudo su -
su - rabbitmq
rabbitmq@xbctpkamq1:[/xbid]$ ps aux |grep rabbitmq-server
rabbitmq 49828  0.0  0.0 113172  1476 ?        S     2020   0:00 /bin/sh /xbid/xbid-ctpk-int-amq1/sbin/rabbitmq-server
rabbitmq 49829  0.0  0.0 113172  1480 ?        S     2020   0:00 /bin/sh /xbid/xbid-ctpk-ext-amq1/sbin/rabbitmq-server
rabbitmq@xbctpkamq1:[/xbid]$ cd xbid-ctpk-int-amq1/
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-int-amq1]$ ./stop.sh
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-int-amq1]$ cd ../xbid-ctpk-ext-amq1
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-ext-amq1]$ ./stop.sh 
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-ext-amq1]$ ps aux |grep rabbit-server
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-ext-amq1]$ logout
[root@xbctpkamq1 ~]# reboot

# Started xb ctpk amq1 instance manually
ssh xbctpkamq1
sudo su - su - rabbitmq
rabbitmq@xbctpkamq1:[/xbid]$ cd xbid-ctpk-int-amq1/
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-int-amq1]$ ./start.sh 
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-int-amq1]$ cd ../xbid-ctpk-ext-amq1
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-ext-amq1]$ ./start.sh 
rabbitmq@xbctpkamq1:[/xbid/xbid-ctpk-ext-amq1]$ ps aux |grep rabbitmq-server
rabbitmq   1956  0.0  0.0 113172  1484 pts/0    S    10:01   0:00 /bin/sh /xbid/xbid-ctpk-int-amq1/sbin/rabbitmq-server
rabbitmq   2222  0.0  0.0 113172  1488 pts/0    S    10:02   0:00 /bin/sh /xbid/xbid-ctpk-ext-amq1/sbin/rabbitmq-server
rabbitmq   2479  0.0  0.0 112708   988 pts/0    S+   10:02   0:00 grep --color=auto rabbitmq-server

# Starting xb ctpk cor1 instance
ssh xbctpkcor1
sudo su -
su - tomcat
[root@xbctpkcor1 ~]# ll /xbid/journal/m7-msgs/20210106/
total 668
-rw-r----- 1 tomcat tomcat 67108864 Jan  6 03:02 data-25805-0
-rw-r----- 1 tomcat tomcat 67108864 Jan  6 09:48 data-25805-1
-rw-r----- 1 tomcat tomcat 16777216 Jan  6 09:48 index-0
[root@xbctpkcor1 ~]# ps aux |grep cor1
bbrother   1443  0.0  0.0   4428   648 ?        Ss   09:53   0:00 /home/bbrother/hobbit/client/./bin/xymonlaunch --config=/home/bbrother/hobbit/client/./etc/clientlaunch.cfg --log=/home/bbrother/hobbit/client/./logs/clientlaunch.log --pidfile=/home/bbrother/hobbit/client/./logs/clientlaunch.xbctpkcor1.pid
bbrother   2307  0.0  0.0   9556  1164 ?        S    09:57   0:00 sh -c vmstat 300 2 1>/home/bbrother/hobbit/client/./tmp/xymon_vmstat.xbctpkcor1.2206 2>&1; mv /home/bbrother/hobbit/client/./tmp/xymon_vmstat.xbctpkcor1.2206 /home/bbrother/hobbit/client/./tmp/xymon_vmstat.xbctpkcor1
root       2882  0.0  0.0 112704   980 pts/0    R+   10:02   0:00 grep --color=auto cor1
[root@xbctpkcor1 ~]# su - tomcat
Last login: Wed Jan  6 09:46:20 CET 2021 on pts/1
tomcat@xbctpkcor1:[/xbid]$ cd xbid-ctpk-cor1/tomcat/bin/
tomcat@xbctpkcor1:[/xbid/xbid-ctpk-cor1/tomcat/bin]$ ./start.sh

# start failed, error in the cor standard log is the same, seems like application issue
vim /xbid/logs/xbid-ctpk-cor1/xb_xbid_ctpk_cor-1_standard_ixe.log

2021-01-06T09:03:17.221Z [overScheduler-1][][] ERROR o.s.s.s.TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task
java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210106/data-51610-1
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:478)
        at com.deutscheboerse.energy.m7.core.in.journal.Replayer.<init>(Replayer.java:28)
        at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.createReplayer(AbstractChronicleQJournaler.java:122)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.getInitialDateTime(M7LifecycleManagerImpl.java:322)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.createStartupTask(M7LifecycleManagerImpl.java:422)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.startMaster(M7LifecycleManagerImpl.java:176)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.tryLock(M7LifecycleManagerImpl.java:233)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$null$0(M7LifecycleManagerImpl.java:160)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$startFailoverTimer$1(M7LifecycleManagerImpl.java:160)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210106/data-51610-1
        at net.openhft.chronicle.VanillaChronicleUtils.mkFiles(VanillaChronicleUtils.java:42)
        at net.openhft.chronicle.VanillaDataCache.dataFor(VanillaDataCache.java:69)
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:454)
        ... 17 common frames omitted


# Did the same test with ctpm, but only with cor1 instance, this one is running old xbid deployed with perl
# Stopped instance manually with stop.sh script
# rebooted server
# Started instance manually with start.sh script
# All went well

# Continue with stoppin it all to hand over to syseng

# stop tomcat instances and check if they are down
./stop_tomcat.sh
./check_tomcat.sh

# stop rabbitmq instances and check if they are down
./stop_rabbitmq.sh
./check_rabbitmq.sh {code}
Contacted Lambert to do the trick.

 

In a process I identified problem of missing ecp instance in those scripts and had to fix them in XP-4285.

 

When Lambert finished his part, I continued to start instances

 

Starting all instances 
{code:java}
# check if all hosts are responding
./ping_all.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh 

# start rabbitmq instances and check if they are down
./start_rabbitmq.sh
./check_rabbitmq.sh 

# start tomcat instances and check if they are down
./start_tomcat.sh
./check_tomcat.sh
 {code}
 * Start script doesn't work for rabbitmq instances deployed by perl/on environment which are not migrated to ansible yet, had to start them manually
 * Starting tomcat instances failed for cor instances, had to start them manually and then identified the issue with missing journal file, the example from one of the env

 
{code:java}
2021-01-05T09:18:44.703Z [overScheduler-1][][] ERROR o.s.s.s.TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task.
java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:412)
        at com.deutscheboerse.energy.m7.core.in.journal.Replayer.<init>(Replayer.java:28)
        at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.createReplayer(AbstractChronicleQJournaler.java:122)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.getInitialDateTime(M7LifecycleManagerImpl.java:322)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.createStartupTask(M7LifecycleManagerImpl.java:422)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.startMaster(M7LifecycleManagerImpl.java:176)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.tryLock(M7LifecycleManagerImpl.java:233)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$null$0(M7LifecycleManagerImpl.java:160)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$startFailoverTimer$1(M7LifecycleManagerImpl.java:160)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicleUtils.mkFiles(VanillaChronicleUtils.java:42)
        at net.openhft.chronicle.VanillaDataCache.dataFor(VanillaDataCache.java:70)
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:388)
        ... 17 common frames omitted
{code}
 
 * I had to go to database server and clean journal as advised by developers

{code:java}
ssh xbtestpdb1
sudo su -
su - postgres
psql -p 25032 -d xbctpkcor -c ""delete from m7_999_revision_index;""
psql -p 25032 -d xbctpkcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25033 -d xbctplcor -c ""delete from m7_999_revision_index;""
psql -p 25033 -d xbctplcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
# CTPM was not necessary to clean, on problem with missing journal file message
#psql -p 25034 -d xbctpmcor -c ""delete from m7_999_revision_index;""
#psql -p 25034 -d xbctpmcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25003 -d xbcutecor -c ""delete from m7_999_revision_index;""
psql -p 25003 -d xbcutecor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
{code}
 * Then I started cor instances manually and checked all remaining tomcat services, some of them I had to also start
 * Requested check of the environment/application by bizops

 

 ","06/Jan/21 14:05;hw120;{color:#1d1c1d}But we have issue with xbid cute ecp1 instance, as server refused to boot and SYSENG is still investigating.{color}","06/Jan/21 16:03;hw120;{color:#1d1c1d}XBID CUTE ECP node is up, Lambert fixed it and I started the instance.{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Chronicle queue retention policy,XP-4300,104736,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ll664,ll664,05/Jan/21 16:18,08/Feb/21 17:49,22/Feb/21 13:26,02/Feb/21 11:03,,,3.2.x,,,,,,,,,,,"How long we want to store event in Chronicle before we delete?

It would be good to have it for at least 30 days?

Try to estimate size of the Chronicle files.

 

Acceptance criteria
 * propose a solution and discuss with other devs your assumption. 
 * record the decision in the ticket. ",,eg288,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4493,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1728000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/Jan/21 16:24;eg288;h3. ChronicleQueue files
 * when a message does not fit in, the queue file is extended with 80MB
 * rolling policy is driven by [RollCycles|https://github.com/OpenHFT/Chronicle-Queue/blob/master/src/main/java/net/openhft/chronicle/queue/RollCycles.java], it is driven by time only, not by size, i.e. queue file size is limited only by disk size

h3. Correlation between XbidEvents count and queue file size

Test executions produced the following numbers:
||XbidEvents||ChronicleQueue file size||
|6_000_000|3GB|
|2_800_000|2GB|

Based on this we can say that 1000 XbidEvents roughly consumes 600kB of disk space
 * If there is no load XBID core produces in 1 hour roughly 4500 XbidEvents (ReconsiliationBroadcast, H2HMatrix, SYSTEM_TASKs like ContractMaintenance or OrderExpiration)
 * An OrderEntry produces two XbidEvents (SENDER, ORDERBOOK)

h3. Estimated data size produced in one day
||Order transactions per day||XbidEvents||Estimated Queue Size||Note||
|10_000_000|20_000_000|12GB|Prediction of order transactions within one year|
|2_500_000|5_000_000|3GB|Current production load|
 * other events like system tasks are negligible and are not included

h3. Notes
 * RollCycle cannot be changed later easily (without data removal)
{code}
2021-02-01 10:52:46.652 [main][] WARN - n.o.c.q.i.s.SCQMeta - Overriding roll length from existing metadata, was 300000, overriding to 1200000
2021-02-01 10:52:46.653 [main][] WARN - n.o.c.q.i.s.SingleChronicleQueueBuilder - Overriding roll cycle from FIVE_MINUTELY to TWENTY_MINUTELY
{code}
* on xbidprodcor1 
** /xbid - Size: 2G, Avail: 1.2G
** /xbid/log - Size: 50G, Avail: 33G","29/Jan/21 16:41;eg288;h2. Proposal for team discussion
* how many days to keep the queue data?
** remove the queue files when data processed by sloth ingestion agent
** 1 day minimum or even less, what is the point to keep the data around?
* cleanup done by external app/sloth itself
** cleanup done by sloth as it knows if the data has been processed (i.e. stored into downstream systems)
* rollCycle policy?
** Recommended RollPolicy.FAST_HOURLY
||Order transactions per day||XbidEvents||Estimated Total Queue Size In One Day (24 files)||Estimated Single File Size||Note||
|10_000_000|20_000_000|12GB|500MB|Prediction of order transactions within one year|
|2_500_000|5_000_000|3GB|125MB|Current production load|
** File size heavily depends on how busy the hour is, so it could be much bigger for busy hours while small for quiet hours
** There is no minimum file size, the minimum size 80MB is applied for the currently active file (i.e. one where the new mesages are written to), when the file is rolled over, the size is shrinked to the ""normal"" size","02/Feb/21 10:26;eg288;h2. Team discussion outcome
see XP-4493",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sloth agent failover/event replay,XP-4299,104735,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ll664,ll664,05/Jan/21 16:17,04/Feb/21 13:04,22/Feb/21 13:26,02/Feb/21 14:18,,,3.2.x,,,,,,,,,,,"If we want to connect SLA Reports to SLOTH, we cannot lose messages.

We need to implement a replay mechanism for events not yet inserted to target DB.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4415,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cbsz:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,minor-fixups,XP-4250-develop,XP-4530,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup grafana dashboard for performance reports,XP-4298,104734,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,05/Jan/21 16:14,27/Jan/21 15:33,22/Feb/21 13:26,27/Jan/21 15:31,,,3.2.x,,,,,,,,,,,"Create dashboard in grafana that would replace Excel performance reports.

Commit as a docker-compose into the xbid.sloth.

Same dashboard could be part of our standalone Grafana once we have DB infrastrcuture in place (VMs etc.)",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4419,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2160000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/21 15:27;ll664;Dashboards created and commited as docker-compose. The Orderbook stats are missing, since it's not really possible to calculate them now (not without complicated window functions). After XP-4383 is done, it could be implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor EventLog/AbstractEventHandler,XP-4297,104733,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ll664,ll664,05/Jan/21 16:13,05/Feb/21 09:24,22/Feb/21 13:26,20/Jan/21 13:23,,,3.2.x,,,,,,,,,,,"The code related to performance meauserement of event handlers is quite messy and hard to grasp. Cleanup/refactor.

 

Analyze and prepare the solution and discuss it with other devs to confirm your assumption. ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4383,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove bid-ask spread/analytics handler from Sloth metrics,XP-4296,104732,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ll664,ll664,05/Jan/21 16:11,12/Jan/21 10:00,22/Feb/21 13:26,12/Jan/21 10:00,,,3.2.x,,,,,,,,,,,Those are off the processing path and the numbers are meanigless.,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:9r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Chronicle metrics consumer - implement backpressure,XP-4295,104731,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,pg759,ll664,ll664,05/Jan/21 16:09,16/Feb/21 16:25,22/Feb/21 13:26,16/Feb/21 16:25,,,3.2.x,,,,,,,,,,,"The consumer just pushes the events as fast as it can and does respect demand from downstream - i.e. if timescale inserts are slower than the rate of events flowing in, it may crash.

Implement proper backpressure - currenlty it's hacked by buffering of signals with {{onBackpressureBuffer()}} operator.",,ll664,pg759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zo6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/21 00:26;pg759;* The events are now pulled rather than pushed => chronicle log is read only as fast as the consumer demands.
 * Buffering on consumer now uses {{bufferTimeout}} adn is sliced per 100 events or 1 second
 * There is prefetch buffer for 1000 items to smooth the reading
 * Logging stats every 10 seconds does not use buffers => avoids list allocation/growing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sloth - exploratory/automated testing,XP-4294,104730,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,05/Jan/21 16:06,18/Jan/21 10:24,22/Feb/21 13:26,18/Jan/21 10:24,,,3.2.x,,,,,,,,,,,"We need to do some manual exploratory tests to check the collected metrics as well as write couple of integration/unit tests for the new code the collects the metrics in XBID Core.

Fix the issues discovered along the way.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3024000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:8i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-4250-develop,XP-4530,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Jan/21 10:24;ll664;I've discovered couple of issues, fixed them and written integration tests for that. All commited to {{XP-4250-develop}} branch in XBID and {{develop}} in xbid.sloth.

Exploratory testing done on the TimescaleDB as target, closing as no more issues discovered.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data ingestion to Elasticsearch,XP-4293,104729,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,05/Jan/21 16:03,13/Jan/21 15:41,22/Feb/21 13:26,13/Jan/21 15:41,,,3.2.x,,,,,,,,,,,"Finish data ingestion into Elasticsearch in the sloth-ingestion-agent. 

Scaffolding already done - see [ElasticsearchXbidEventDao|https://github.deutsche-boerse.de/dev/xbid.sloth/blob/develop/sloth-ingestion-agent/src/main/kotlin/com/deutscheboerse/energy/xbid/sloth/agent/elasticsearch/ElasticsearchXbidEventDao.kt]",,jy268,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3456000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,05/Jan/21 16:03,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zo4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/21 13:02;jy268;Please review [~ll664]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SERVICE CLONE: XBID external test - VM power cycle - CUTE F,G,H,I,J",XP-4287,104697,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,04/Jan/21 16:10,05/Jan/21 22:28,22/Feb/21 13:26,05/Jan/21 22:26,,,,,,,,,,TechOps,toilwork,,,"Perform VM power cycling on the below-listed environments

CUTE F, CUTE G, CUTE H, CUTE I, CUTE J

 

Customer communication - inform that above-listed environments will not be available during this maintenance

 

For each environment Env in

(CUTE F, CUTE G, CUTE H, CUTE I, CUTE J)
 * stop the environment Env
 * for all Env environment-specific VM (see list below)
 ** TO : shutdown environment-specific VMs (list below)
 ** Syseng: startup VM 
 ** Syseng: perform VM check
 * start environment Env
 * product team sanity check the environment Env

 

LIST OF VMs
|xbctpfamq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfcor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfdow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgamq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgcor1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpgdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphamq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphcor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphdow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpiamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpicor1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpidow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpienq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjcor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpjenq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9193,,,,,,,,,,,,SERVICE-9193,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,yn731,,,,,,,,,,,,,Internal Deployment Request,eg288,,,,No,4060800,,CTPF,CTPG,CTPH,CTPI,CTPJ,,dm700,lw641,ox626,rehapav,sw455,,05/Jan/21 17:00,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy8",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 22:24;hw120;As we have environments being deployed by perl and ansible in the list, I will use scripts for power maintenance to execute it.

[https://github.deutsche-boerse.de/dev/energy.powermaintenance]

 
{code:java}
# from entestauto1 or enprodauto1
git clone git@github.deutsche-boerse.de:dev/energy.powermaintenance.git
cd energy.powermaintenance
cat <<EOF > pm_hosts
xbctpfamq1
xbctpfcor1
xbctpfdow1
xbctpfenq1
xbctpgamq1
xbctpgcor1
xbctpgdow1
xbctpgenq1
xbctphamq1
xbctphcor1
xbctphdow1
xbctphenq1
xbctpiamq1
xbctpicor1
xbctpidow1
xbctpienq1
xbctpjamq1
xbctpjcor1
xbctpjdow1
xbctpjenq1
EOF

# check if all hosts are responding
./ping_all.sh

# detect and fill in instance list inventory
./detect_tomcat.sh
./detect_rabbitmq.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh

# stop tomcat instances and check if they are down
./stop_tomcat.sh
./check_tomcat.sh

# stop rabbitmq instances and check if they are down
./stop_rabbitmq.sh
./check_rabbitmq.sh {code}
Contacted Lambert to do the trick.

 

In a process I identified problems in those scripts and had to fix them in XP-4285.

 

When Lambert finished his part, I continued to start instances

 

 
{code:java}
# check if all hosts are responding
./ping_all.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh 

# start rabbitmq instances and check if they are down
./start_rabbitmq.sh
./check_rabbitmq.sh 

# start tomcat instances and check if they are down
./start_tomcat.sh
./check_tomcat.sh

{code}
 

 
 * Start script doesn't work for rabbitmq instances deployed by perl/on environment which are not migrated to ansible yet, had to start them manually
 * Starting tomcat instances failed for cor instances, had to start them manually and then identified the issue with missing journal file, the example from one of the env

 
{code:java}
2021-01-05T09:18:44.703Z [overScheduler-1][][] ERROR o.s.s.s.TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task.
java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:412)
        at com.deutscheboerse.energy.m7.core.in.journal.Replayer.<init>(Replayer.java:28)
        at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.createReplayer(AbstractChronicleQJournaler.java:122)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.getInitialDateTime(M7LifecycleManagerImpl.java:322)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.createStartupTask(M7LifecycleManagerImpl.java:422)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.startMaster(M7LifecycleManagerImpl.java:176)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.tryLock(M7LifecycleManagerImpl.java:233)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$null$0(M7LifecycleManagerImpl.java:160)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$startFailoverTimer$1(M7LifecycleManagerImpl.java:160)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicleUtils.mkFiles(VanillaChronicleUtils.java:42)
        at net.openhft.chronicle.VanillaDataCache.dataFor(VanillaDataCache.java:70)
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:388)
        ... 17 common frames omitted
{code}
 
 * I had to go to database server and clean journal as advised by developers

{code:java}
ssh xbtestpdb1
sudo su -
su - postgres
psql -p 25028 -d xbctpgcor -c ""delete from m7_999_revision_index;""
psql -p 25028 -d xbctpgcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25030 -d xbctpicor -c ""delete from m7_999_revision_index;""
psql -p 25030 -d xbctpicor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25031 -d xbctpjcor -c ""delete from m7_999_revision_index;""
psql -p 25031 -d xbctpjcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25029 -d xbctphcor -c ""delete from m7_999_revision_index;""
psql -p 25029 -d xbctphcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25027 -d xbctpfcor -c ""delete from m7_999_revision_index;""
psql -p 25027 -d xbctpfcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""{code}
 * Then I started cor instances manually and checked all remaining tomcat services, some of them I had to also start
 * Requested check of the environment/application by bizops

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix power maintenance scripts,XP-4285,104670,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,04/Jan/21 11:22,07/Jan/21 22:34,22/Feb/21 13:26,05/Jan/21 14:08,,,,,,,,,,reducingtoil,TechOps,,,"I discovered problems in those scripts on xbid part, as we need them to be reliable, I have to fix them.

They are also useful when doing power cycling maintenance of larger number of hosts.",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9197,SERVICE-9192,SERVICE-9194,SERVICE-9193,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3888000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 14:07;hw120;Updated, fixed and tested in...
https://github.deutsche-boerse.de/dev/energy.powermaintenance/pull/1/files
https://github.deutsche-boerse.de/dev/energy.powermaintenance/pull/2/files
https://github.deutsche-boerse.de/dev/energy.powermaintenance/pull/3/files
","07/Jan/21 22:33;hw120;Unfortunately, power maintenance scripts are still far from ideal and require a bit of tuning
* They can't start rabbitmq instances deployed by perl
* They can't start all tomcat instances deployed by perl
* They can't start all haproxy instances deployed by perl
We should focus on tuning them before the next power maintenance, it can save us a lot of problems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SERVICE CLONE: XBID external test - VM power cycle - CUTE A,B,C,D,E",XP-4284,104664,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,04/Jan/21 09:46,05/Jan/21 22:28,22/Feb/21 13:26,05/Jan/21 22:26,,,,,,,,,,TechOps,toilwork,,,"Perform VM power cycling on the below-listed environments

CUTE A, CUTE B, CUTE C, CUTE D, CUTE E

 

Customer communication - inform that above-listed environments will not be available during this maintenance

 

For each environment Env in

(CUTE A, CUTE B, CUTE C, CUTE D, CUTE E)
 * Syseng: fix booting script with necessary ""selinux"" and ""audit"" parameters
 * Syseng: Switch on ""CPU HotADD"" and ""Memory Hot Plug"" features for VM in ESX infrastructure  (ca. 30 Min)
 * stop the environment Env
 * for all Env environment-specific VM (see list below)
 ** TO : shutdown environment-specific VMs (list below)
 ** Syseng: startup VM 
 ** Syseng: perform VM check
 * start environment Env
 * product team sanity check the environment Env

 

LIST OF VMs
|Name|Host|Compatibility|EVC Mode|
|xbctpaamq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpacor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpadow1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpaenq1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpbamq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpbcor1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpbdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpbenq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpcamq1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpccor1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpcdow1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpcenq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpdamq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpdcor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpddow1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpdenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpeamq1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpecor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpedow1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpeenq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9192,,,,,,,,,,,,SERVICE-9192,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,yn731,,,,,,,,,,,,,Internal Deployment Request,eg288,,,,No,4060800,,CTPA,CTPB,CTPC,CTPD,CTPE,,dm700,lw641,ox626,rehapav,sw455,,04/Jan/21 17:00,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 22:21;hw120;As we have environments being deployed by perl and ansible in the list, I will use scripts for power maintenance to execute it.

[https://github.deutsche-boerse.de/dev/energy.powermaintenance]

 
{code:java}
# from entestauto1 or enprodauto1
git clone git@github.deutsche-boerse.de:dev/energy.powermaintenance.git
cd energy.powermaintenance
cat <<EOF > pm_hosts
xbctpaamq1
xbctpacor1
xbctpadow1
xbctpaenq1
xbctpbamq1
xbctpbcor1
xbctpbdow1
xbctpbenq1
xbctpcamq1
xbctpccor1
xbctpcdow1
xbctpcenq1
xbctpdamq1
xbctpdcor1
xbctpddow1
xbctpdenq1
xbctpeamq1
xbctpecor1
xbctpedow1
xbctpeenq1
EOF

# check if all hosts are responding
./ping_all.sh

# detect and fill in instance list inventory
./detect_tomcat.sh
./detect_rabbitmq.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh

# stop tomcat instances and check if they are down
./stop_tomcat.sh
./check_tomcat.sh

# stop rabbitmq instances and check if they are down
./stop_rabbitmq.sh
./check_rabbitmq.sh {code}
Contacted Lambert to do the trick.

 

In a process I identified problems in those scripts and had to fix them in XP-4285.

 

When Lambert finished his part, I continued to start instances

 

 
{code:java}
# check if all hosts are responding
./ping_all.sh

# check if services/instances are running
./check_tomcat.sh
./check_rabbitmq.sh 

# start rabbitmq instances and check if they are down
./start_rabbitmq.sh
./check_rabbitmq.sh 

# start tomcat instances and check if they are down
./start_tomcat.sh
./check_tomcat.sh

{code}
 

 
 * Start script doesn't work for rabbitmq instances deployed by perl/on environment which are not migrated to ansible yet, had to start them manually
 * Starting tomcat instances failed for cor instances, had to start them manually and then identified issue with missing journal file, example from one of the env

 
{code:java}
2021-01-05T09:18:44.703Z [overScheduler-1][][] ERROR o.s.s.s.TaskUtils$LoggingErrorHandler - Unexpected error occurred in scheduled task.
java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:412)
        at com.deutscheboerse.energy.m7.core.in.journal.Replayer.<init>(Replayer.java:28)
        at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.createReplayer(AbstractChronicleQJournaler.java:122)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.getInitialDateTime(M7LifecycleManagerImpl.java:322)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.createStartupTask(M7LifecycleManagerImpl.java:422)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.startMaster(M7LifecycleManagerImpl.java:176)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.tryLock(M7LifecycleManagerImpl.java:233)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$null$0(M7LifecycleManagerImpl.java:160)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.lambda$startFailoverTimer$1(M7LifecycleManagerImpl.java:160)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20210105/data-86028-1
        at net.openhft.chronicle.VanillaChronicleUtils.mkFiles(VanillaChronicleUtils.java:42)
        at net.openhft.chronicle.VanillaDataCache.dataFor(VanillaDataCache.java:70)
        at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:388)
        ... 17 common frames omitted
{code}
 
 * I had to go to database server and clean journal as advised by developers

{code:java}
ssh xbtestpdb1
sudo su -
su - postgres
psql -p 25020 -d xbctpacor -c ""delete from m7_999_revision_index;""
psql -p 25020 -d xbctpacor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25021 -d xbctpbcor -c ""delete from m7_999_revision_index;""
psql -p 25021 -d xbctpbcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25022 -d xbctpccor -c ""delete from m7_999_revision_index;""
psql -p 25022 -d xbctpccor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25023 -d xbctpdcor -c ""delete from m7_999_revision_index;""
psql -p 25023 -d xbctpdcor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
psql -p 25026 -d xbctpecor -c ""delete from m7_999_revision_index;""
psql -p 25026 -d xbctpecor -c ""insert into m7_999_revision_index (static_id, index, timestamp) values (1, 0, 0);""
{code}
 * Then I started cor instances manually and checked all remaining tomcat services, some of them I had to also start
 * Requested check of the environment/application by bizops

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"XBID Core Down on CTP[A, C, E, F, H, J, K, L, M], CTSO, LIPA",XP-4281,104627,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,28/Dec/20 13:57,05/Jan/21 12:26,22/Feb/21 13:26,29/Dec/20 10:17,,,,,,,,,,Postgresql,TechOps,,,"CPTA/C and CTSO Cor went down 24.12. at 11:12

All the rest 26.12. in between 3:12 and 4:16

They all seems to be related to the same issue
{quote}org.postgresql.util.PSQLException: ERROR: out of memory
{quote}
In Cor1 instances logs:

[https://kibana.energy.svc.dbgcloud.io/goto/498f4e81657a28784860ac0c80b99279]

In postgresql log:

[https://kibana.energy.svc.dbgcloud.io/goto/2c90f2b89e614985dd226e080f63d717]

 ",,ek176,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4752000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Dec/20 17:34;hw120;Identified problem in xbsyt3sync patroni/postgresql cluster configuration, too high shared_buffers setting.
Fixed and restarted cluster nodes.

Also added work_mem and maintenance_work_mem into all single instance postgres instances.

Started all stopped cor instances.

{code:bash}
# fix patroni config
patronictl -c /etc/patroni_xbsyt3sync/config.yml edit-config
# and added correct config as in /etc/patroni_xbsyt3sync/config.yml

# restarted cluster members one by one
patronictl -c /etc/patroni_xbsyt3sync/config.yml restart xbsyt3sync xbtestpdb1
patronictl -c /etc/patroni_xbsyt3sync/config.yml restart xbsyt3sync xbtestpdb2

cat /root/pg_conf_change 
maintenance_work_mem = 320MB
work_mem = 32MB

# Update postgres config
for i in `ls /var/lib/pgsql_*/data/12/postgresql.conf`;do sed -i '/shared_buffers = 2GB/r /root/pg_conf_change' $i;done
for i in `ls /var/lib/pgsql_*/data/9.5/postgresql.conf`;do sed -i '/shared_buffers = 2GB/r /root/pg_conf_change' $i;done

# check if change was added
grep ""work_mem = 32MB""  pgsql_*/data/12/postgresql.conf
grep ""maintenance_work_mem = 320MB""  pgsql_*/data/12/postgresql.conf

# reloaded instances to apply change
for i in `ls -d /var/lib/pgsql_*/data/12/ |grep -v syt1 |grep -v syt3`;do /usr/pgsql-12/bin/pg_ctl -D $i reload;done
for i in `ls -d /var/lib/pgsql_*/data/9.5/ |grep -v syt1 |grep -v syt3`;do /usr/pgsql-9.5/bin/pg_ctl -D $i reload;done

#checked if config change was applied, example for one instance
psql -p 25020 -c ""select * from pg_settings""
{code}

then started
","29/Dec/20 10:17;hw120;All impacted envs are up with exception of CTPE/J/K, where cor started, but failed to report health status.

There I had to stop telegraf service, stop cor application, start cor application and start telegraf service.
This worked for ctpj, but for ctpe/k I had to stop/start application 3 times till it started to work.

Maybe because curl telegraf health check might be conflicting with that port use.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"XBID Core Down on SIMU, LIPB, CUTE",XP-4278,104597,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,23/Dec/20 15:59,20/Jan/21 13:54,22/Feb/21 13:26,23/Dec/20 16:09,,,,,,,,,,,,,,"Monitoring reported Core Down on SIMU, LIPB, CUTE.

David Siro investigated the problem and recommended to clean journal and start it again.
 * [https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=29919747]
 * start core instances",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4277,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5184000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-4275-acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Dec/20 16:07;hw120;Created xbid simu core db dump and uploaded to ebsm
{code:java}
su - postgres
pg_dump -Fc -p 25102 -d xbsimucor > /var/lib/pgsql_simu_25102/backup/xbsimucor_2020-12-23_db.Fcdump
scp /var/lib/pgsql_simu_25102/backup/xbsimucor_2020-12-23_db.Fcdump hw120@m7shrdebsm1:/tmp/xbsimucor_2020-12-23_db.Fcdump
{code}
 

Cleaned journal on all 3 core databases and filesystems.

Started all cors.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Core Down - CMM user deletion fails,XP-4277,104595,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,tr866,ll664,ll664,23/Dec/20 15:10,18/Jan/21 13:40,22/Feb/21 13:26,11/Jan/21 17:50,,,3.1.6,,,,,,,,,,,"Happened in SIMU, LIPB and CUTE:

[https://kibana.energy.svc.dbgcloud.io/goto/03be339bb7708ad17e3fb92e9092030c]

From the very first look it looks like {{cmm_281_user_preferencies}} is not deleted with user. Actually that table is not even part of XBID Core at all, it is just use directly from CMM UI.
{code:java}
Exception while executing a batch.
org.postgresql.util.PSQLException: ERROR: update or delete on table ""cmm_280_user"" violates foreign key constraint ""fk_66bqwlxu7hx9vxk00gxnc1j6m"" on table ""cmm_281_user_preferencies""
  Detail: Key (racf_id)=(HOPS01ZV) is still referenced from table ""cmm_281_user_preferencies"".
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2505)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2241)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:310)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:447)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:368)
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:158)
	at org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:124)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeUpdate(ProxyPreparedStatement.java:61)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeUpdate(HikariProxyPreparedStatement.java)
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:197)
	at org.hibernate.engine.jdbc.batch.internal.NonBatchingBatch.addToBatch(NonBatchingBatch.java:45)
	at org.hibernate.persister.entity.AbstractEntityPersister.delete(AbstractEntityPersister.java:3570)
	at org.hibernate.persister.entity.AbstractEntityPersister.delete(AbstractEntityPersister.java:3829)
	at org.hibernate.internal.StatelessSessionImpl.delete(StatelessSessionImpl.java:136)
	at org.hibernate.internal.StatelessSessionImpl.delete(StatelessSessionImpl.java:127)
	at com.deutscheboerse.energy.m7.core.persistance.executor.SequencePersistenceExecutor.lambda$new$2(SequencePersistenceExecutor.java:45)
	at com.deutscheboerse.energy.m7.core.persistance.executor.SequencePersistenceExecutor.persistInTransaction(SequencePersistenceExecutor.java:60)
	at com.deutscheboerse.energy.m7.core.persistance.executor.BatchPersistenceExecutor.persistInTransaction(BatchPersistenceExecutor.java:77)
	at com.deutscheboerse.energy.m7.core.persistance.HibernatePersistService.save(HibernatePersistService.java:18)
	at com.deutscheboerse.energy.m7.core.out.Persister.persistContextData(Persister.java:80)
	at com.deutscheboerse.energy.m7.core.out.Persister.doOnEvent(Persister.java:61)
	at com.deutscheboerse.energy.m7.core.out.Persister.doOnEvent(Persister.java:25)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}
DB dump os EBMS:
{code:java}
[hw120@m7shrdebsm1 ~]$ ll /tmp/xbsimucor_2020-12-23_db.Fcdump
-rw-r--r-- 1 hw120 users 54756325 Dec 23 15:18 /tmp/xbsimucor_2020-12-23_db.Fcdump
{code}
Acceptance Criteria 
 * Short term solution as part of this ticket:  
 ** -Option 1 (hard to test, hard to write integration test for that):- 
 *** -CASCADE DELETE orphan removal on the DB level-
 ** *Option 2 (preferred):* 
 *** drop the foreign key 
 *** delete data by CMM before the message to delete user is sent to core. 
 * Analyze the proper solution
 ** get rid of the table from the core - analyze it and prepare ticket for the next release to the backlog. ",,ek176,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4320,,,,,,,"08/Jan/21 11:20;tr866;m7-app-xbidCore1.log;https://jira.deutsche-boerse.com/secure/attachment/91561/m7-app-xbidCore1.log","08/Jan/21 11:20;tr866;screenshot-localhost_24082-2021.01.07-14_33_00.png;https://jira.deutsche-boerse.com/secure/attachment/91562/screenshot-localhost_24082-2021.01.07-14_33_00.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3542400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,23/Dec/20 15:10,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:8",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4277-develop-sonar-test,acceptance,XP-2478-tobago-upgrade-clean01,develop,XP-4152-acceptance,XP-2400,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Jan/21 10:42;ll664;The trader preferences feature does not really work at the moment. They're save into the DB, but when user logs out and logs in again, the loading of preferences does not work and defaults are used. Confirmed with [~ei349] that this should be also fixed.","08/Jan/21 09:25;ll664;Fixed and merged to both {{acceptance}} and {{develop}} branches. Pls note the bug with preferences loading (comment above) was fixed as well. Ready to test.","08/Jan/21 11:21;tr866;Issue successfully reproduced on Docker with version from SIMU = XB R3.1.11 (Build 708b8af0b2d56e50a7e3f39817206c54d444e804)
h4. Prerequisite for testing on docker:

Older version of xbid-test without OWASP ZAP needed!
 Issue successfully reproduced with commit version of xbid-test ae9e99354e2abc0c54de178bc64d1a75cf28c0f5 from 6th of November 2020.
 With latest version of xbid-test the issue wasn't possible to get reproduced as after restart of Docker the table in question cmm_281_user_preferencies was getting deleted!
h4. Steps to reproduce:
 # Start Docker with default testing time (year 2018) or some date at least 60 days before the current time
 # Login to CMM as TSO Admin or Explicit Participant(having Preferences option in the menu). e.g. users from tosca fake dataset: TSUSER01, TSUSER02, TSUSER03, TSUSER07, TSUSER08, XB50H010
 # Change preferences for the logged in user, e.g. in *Menu>Preferences* check some additional option like ""Allocation On Behalf"" or ""Show Contract UTC Time""
 -- Make sure in DB that in the table *cmm_281_user_preferencies* a new record was added for the recent changes(normally the table is empty first after first startd of Docker)
 # Login to CMM as Reference Data Admin (SADMIN02)
 # Suspend the above used user, i.e. Modify user and enable the Suspended checkbox
 # Stop docker
 # Start docker with current time (60 days later than the previous time)
 # Verify in DB that record for the changed preferences remained in the cmm_281_user_preferencies table
 # Login to CMM as Reference Data Admin (SADMIN02)
 # Delete the CMM user for which the preferences were previously changed

h4. Observed behaviour:

Core is down
 !screenshot-localhost_24082-2021.01.07-14_33_00.png!

Exception thrown in the [^m7-app-xbidCore1.log]:
{code}
Unable to find source-code formatter for language: java. Available languages are: actionscript, ada, applescript, bash, c, c#, c++, cpp, css, erlang, go, groovy, haskell, html, java, javascript, js, json, lua, none, nyan, objc, perl, php, python, r, rainbow, ruby, scala, sh, sql, swift, visualbasic, xml, yamlCaused by: java.sql.BatchUpdateException: Batch entry 0 delete from public.CMM_280_USER where RACF_ID='TSUSER01' was aborted: ERROR: update or del
ete on table ""cmm_280_user"" violates foreign key constraint ""fk_66bqwlxu7hx9vxk00gxnc1j6m"" on table ""cmm_281_user_preferencies""
{code}","11/Jan/21 15:05;tr866;Second issue also confirmed in version XB R3.1.11 (Build 708b8af0b2d56e50a7e3f39817206c54d444e804)
Changed preferences are being saved in DB in cmm_281_user_preferencies table but not loaded on next login.","11/Jan/21 15:55;tr866;Successfully tested the fix on docker with version XB R3.2.4-SNAPSHOT (Build 125325ef14aa2fad0a1ab6371aebc38a476fa529)
# (/) Loading of modified preferences if now working correctly after logout and relogin. Even after time-travelling and restart of docker. Btw the name of the table in DB is bit odd as it's having the same number 281 as user_history and name is ""preferencies"" rather than ""preferences"". I could be related to the previous problems.
# (/) Users with modified preferences could be successfully deleted without putting the Core down:
TSUSER01(roles: File Management Admin, Reference Data Admin, TSO Admin), TSUSER02(role: Explicit Participant), TSUSER03 (role: TSO Admin), TSUSER07 (role: Read-Only TSO Admin), TSUSER08 (role: Explicit Participant)
together with users without preferences TSUSER05 (role: Reference Data Admin), TSUSER06 (role: File Management Admin)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(split 1) Dataset generator - fixing, refactoring, etc.",XP-4276,104591,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,23/Dec/20 10:32,17/Feb/21 09:32,22/Feb/21 13:26,03/Feb/21 13:13,,,,,,,,,,,,,,"After several separate additions, the {{m7.dataset-generator}} no longer works with any known input, contains unused or unclear temporary code, README is outdated and the whole project is a mess in general.

Also, standard for the input format does not exist anymore, there is no concise information about that anywhere and the whole process is unclear (or undefined).

Steps:
- decide on the input format for datasets
- introduce proper tests enforcing some clarity when adding/changing functionality
- adjust dataset generator for the input format
- describe dataset creation/update processes in confluence or wiki with link from confluence",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4511,,,XP-4584,XP-4583,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5270400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 25 (S),HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4276-split-io,XP-4276-new-format,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Maintenance of xbid syt3 ecp to add more resources for database host,XP-4272,104579,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,22/Dec/20 16:21,05/Jan/21 12:26,22/Feb/21 13:26,22/Dec/20 16:21,,,,,,,,,,TechOps,,,,"xbinteedb1 hosts is overloaded, we have to add more cpus, but hot plug is not enabled, so we have to do it offline.

I schedule maintenance of ECP syt3 instances, request change with SYSENG.
 * Create SYSENG ticket
 * Schedule syt3 ecp instances downtime with xbid team
 * Schedule change with syseng team
 * execute it by stopping ecp instances, stopping ecp database, powering off db server
 * and then start it all again after syseng did the job",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-224,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5270400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hy1",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comtrader, TestClient -> Connection not working properly after switch DC1->DC2",XP-4262,104449,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,17/Dec/20 10:07,18/Jan/21 09:02,22/Feb/21 13:26,18/Jan/21 09:02,,,,,,,,,,,,,,"1. After Switching from DC1 to DC2 - connection to Comtrader and Test client is not working properly. We need more attempts for successful login

Comtrader log added.

2.  User disconnected - without any reasons
SYT1 env :
time : 10:08  USER:XBEPEXX1 
",,eh941,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4194,,,,,,,"17/Dec/20 10:05;hj444;2020-12-17_09-28-56-728_comtrader_logfile.0.log;https://jira.deutsche-boerse.com/secure/attachment/91176/2020-12-17_09-28-56-728_comtrader_logfile.0.log",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3024000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:8l",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Christmas Sprint (S),Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Dec/20 12:33;eh941;Everything seems to be configured properly. I've checked all 10 HA proxies, the both trading inquiry modules and the core module (that's all I had to check) and everything looks exactly as it should. 

I've checked the time 10:08 and user XBEPEXX1. I found a LogoutRequest in the trading inquiry log so it looks like the client itself logged out. The real question is why and how. I tried to log in with different user XBOMIEX2 and there are no problems. I was logged in for about 10 minutes and no disconnection happened.

I didn't have chance to check the comtrader log. It might be helpful.","06/Jan/21 12:54;eh941;There was an unrelated problem with stopping HA proxies - the proxies weren't stopped properly and there were multiple instances running on the same ports. That caused the weird behavior because the cliant was routed randomly to a HA proxy and only one of them (there were 3 in total) was valid on a particular VM.","14/Jan/21 15:25;hj444;retest : SYT1: Version R3.2.3 (Build f8ed207ffd3066b56f11d298d662e63e4fbe80f9)
TestClient login  DC1, DC2 after switch : OK
Comtrader : Logs only to DC1.
 - investigation in - XP-3454


 ","18/Jan/21 08:24;hj444;I'll close this ticket. 
XP-3454 is open I'll retest whole DC switch again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Self-service password reset job is not working,XP-4259,104406,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ab039,ab039,16/Dec/20 11:14,08/Jan/21 15:21,22/Feb/21 13:26,08/Jan/21 15:21,,,,,,,,,,TechOps,,,,"Could you please fix the following job:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID%20LDAP%20syt_perf/]",,ab039,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3801600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,16/Dec/20 11:14,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gl",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 24,Xbops Christmas Sprint,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/21 16:31;iv732;There are several issue:
1. Reading the wrong vault field (should be ""password"", not ""value"")
2. The default password is violating the new password policy (min 12 characters)

To do:
- modify the vault read
- set another default password to ""xbidTest01!1"" 
","08/Jan/21 15:20;iv732;Done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - on double-sided environments only rabbits in one DC should be started,XP-4258,104405,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eh941,eh941,16/Dec/20 11:02,05/Jan/21 11:09,22/Feb/21 13:26,05/Jan/21 11:09,,,3.1.x,,,,,,,RabbitMQ,,,,"In current setup when the environment is double-sided only rabbits in one DC are used. We currently start all rabbits which is a potential issue if the application somehow connects to them. The rabbits in the other DC are switched on manually in case of  the primary DC failure.

DoD:
* When the deployment and start of rabbits is done via [deploy job|https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-full-ansible-deploy/] only rabbits in DC 1 (IXE) are up and running.
* After the first step is done verify [job for DC switch|https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-dc-switch/] if it isn't over-complicated in respect of the changes done in the rabbit deployment",,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4147200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c927:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Jan/21 11:09;eg288;updated ansible role xbrabbitmq-instance and jenkins pipeline Jenkinsfile_xbid_dc_switch",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CheckMK hosts grouping and labeling. ,XP-4255,104359,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,zq813,zq813,15/Dec/20 11:21,18/Jan/21 12:28,22/Feb/21 13:26,18/Jan/21 12:25,,,,,,,,,,check_mk,TechOps,,,"Hello. 

As you know we have new instances of checkmk - [https://globmon.srv.energy/]

For migrating existing hosts from englobmon2 to new nodes I would like to ask you to provide a list of virtual machines with proper host groups and labels.

Based on host groups and labels we can setup notifications and views. 

Virtual machines will be boarded via this playbook: [https://github.deutsche-boerse.de/dev/energy.infra.hw/blob/master/ansible/roles/checkmk_vm/tasks/main.yml]

 

Example of command: 

 
{code:java}
ansible-playbook playbooks/add_checkmk_vm.yml -e ""site_name=simumon1 product=m7 envi=test criticality=test"" -i inventory -k -K -v
{code}
Where:
 * criticality (critical, prod, simu, test)
 * envi - environment (TEST, SIMU PROD) 
 * product - hosts grouped in one product name
 * site_name - where hosts will be monitored. Prod hosts must be monitored from prod node. Same for rest environments. 

Due to limitations of checkmk webapi it's better to add new hosts instead of modifying existing ones.

Host lists even can be in excel sheet, just mention proper tags for them. Except listed tags you can define any new tags for segregation, I will create new tags in checkmk and assign them to listed hosts.

 

Additional info: 
 * we have 3 new groups - syt, cute, prod. 
 * we might be able to get information from the inventory

 ",,ei349,iv732,yo218,zq813,,,,,,,,,,,,,,,,,SYSENGINT-57,,,,,,,,,,,,,,,,,,,,,,"15/Jan/21 12:08;zq813;m7t_host_groups_with_shared.csv;https://jira.deutsche-boerse.com/secure/attachment/91740/m7t_host_groups_with_shared.csv","15/Jan/21 16:49;iv732;xbid_host.csv;https://jira.deutsche-boerse.com/secure/attachment/91767/xbid_host.csv",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3024000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 08:17;ei349;Comment from Niklas: This topic is preventing us since more than a month from the finalization of the CheckMK migration (the ticket has just been created a week before Christmas, but mutual discussions and email exchange started way earlier)","05/Jan/21 13:14;ei349;Dear [~iv732], can you please align with [~zq813] and fill in the estimate based on the feedback? ","15/Jan/21 12:11;zq813;Hello [~iv732] . Steffen provided list for M7 hosts: [^m7t_host_groups_with_shared.csv]

Something similar for XBID hosts will be enough. In case some other, additional tags are not required from your side. ","15/Jan/21 16:49;iv732;[~zq813] I attached the list of host in XBID
","15/Jan/21 16:52;zq813;Thank you [~iv732]. One question regarding list. XB is product and XBID is customer, right? ","18/Jan/21 12:25;iv732;[~zq813] yes. the columns are: 

{{ ansible_hostname }}','{{ product }}','{{ customer }}','{{ environment_tag }}","18/Jan/21 12:26;zq813;Great. Thanks a lot :) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare new consul enterprise prod cluster - deployment on prod env and migration of M7 PROD patroni clusters,XP-4246,104245,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,hw120,hw120,11/Dec/20 10:36,15/Dec/20 07:29,22/Feb/21 13:26,15/Dec/20 07:29,,,,,,,,,,Consul,Patroni,TechOps,,"We need to deploy new Consul Enterprise cluster for PROD environments, which would be shared by all energy products.

We have new servers prepared prodcons[1-5].srv.energy where it should be deployed.

As we have to migrate existing/connected m7proddbr1/2 hosts to a new network, we will have to stop patroni and postgres services running on them first.

*NOTE: We must make sure, all needed ports are open in every needed direction as described here:*

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Consul#Consul-Networkports-FWrules]

Using nc or telnet we can easily test it: [https://ubidots.com/blog/how-to-simulate-a-tcpudp-client-using-netcat/]

Patroni preparation steps:
 * Connect to *m7proddbr1/2* hosts and stop patroni services
 ** Notify Lambert to start their migration to new networks and ips
 ** Also so he adds second network interface for the old network with proper routing so ebsm connection would still work
 * Pause all patroni clusters running on *m7prodpdb[1-4]* hosts and check if they are in maintenance mode

{code:java}
ssh m7prodpdb1
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause;done
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done
# to check it from enprodauto1
ansible all -m shell -a 'for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done' --limit 'm7*-elts*prod*pdb*async1' -b -K{code}

 * Make a backup of patroni configuration in */etc/patroni_/config.yml*
{code:java}
ansible all -m shell -a 'mkdir /root/systemctl_backup/ && cp -a /usr/lib/systemd/system/patroni_* /root/systemctl_backup/' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'mkdir /root/patroni_backup && cp -a /etc/patroni_*/ /root/patroni_backup/' --limit 'm7*-elts*prod*async*' -b -K
{code}

 * Update all systemctl patroni config files to
 ** Comment out lines starting with *ExecStartPre=* and *ExecStopPost=*
 ** Change *KillMode=control-group* to *KillMode=process*
 ** To apply the changes, run *systemctl daemon-reload*
{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStartPre/#ExecStartPre/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStopPost/#ExecStopPost/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=control-group/KillMode=process/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*prod*async*' -b -K
{code}

Consul preparation steps:
 * Enable RHEL 7.8 repository so consul deployment would have python3 selinux dependency available
 * Stop consul clients on all *m7prodpdb[1-4]* and *m7proddbr1/2* hosts
 * Make a backup of consul configuration in */etc/consul/* and binary in */usr/local/bin/consul*
 * Clean up old consul config and binary

{code:java}
ansible all -m shell -a 'subscription-manager release --set 7.8' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'yum clean all' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'yum repolist' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'systemctl stop consul' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'cp -a /etc/consul /root/consul_backup' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'cp -a /usr/local/bin/consul /root/consul_backup/consul_binary' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /etc/consul/ -rf' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /var/consul -rf' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /usr/local/bin/consul' --limit 'm7*-elts*prod*async*' -b -K
{code}
Consul deployment steps:
 * Create keys and certificates for the cluster:
 ** Make sure vault path for this new cluster is empty {{vault list secret/global/consul/energy-shrd-prod}}
 *** If old keys exist there, backup them and then delete them from vault
 *** 
{code:java}
for i in `vault list secret/global/consul/energy-shrd-prod/ |grep -v Keys |grep -v '\-\-\-\-'`;do vault delete secret/global/consul/energy-shrd-prod/$i ;done
{code}

 * 
 ** Export variables to define cluster name, consul binary path and run script to generate certs with 10y validity
 ** 
{code:java}
export CONSUL_DC=energy-shrd-prod && \
export CONSUL_BINARY=/usr/local/bin/consul && \
roles/consul_instance/create-consul-cluster.sh{code}

 * 
 ** this will save them in vault folder {{secret/global/consul/<dc_name>/}} - make sure they are there afterward {{vault list secret/global/consul/energy-shrd-prod}}
 * Deploy consul servers

{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K --limit 'energy-shrd-prod-cons*'
{code}
 * 
 ** be careful to set a correct limit and group name - do you want to deploy all instances in the group?
 ** you may append \{{ -e consul_install_upgrade=True}} if you wish to upgrade the consul binary in case it already exists
 ** you may also append other parameters from the upstream role, they are documented here: [https://github.com/brianshumate/ansible-consul/blob/master/README.md]
 * this will deploy cluster with TLS, gossip encrypt and ACL security enabled
 * Now you save bootstrap token which you can find on any provisioned node in {{/etc/consul/config.json}} to vault {{secret/global/consul/<dc_name>/bootstrap_token}}
 * Save tokens to vault
 ** {{vault write secret/global/consul/energy-shrd-prod/bootstrap_token value=XXXX-XXX-XXXX-XXXX}}
 ** {{vault write secret/global/consul/energy-shrd-prod/acl_replication_token value=XXXX-XXX-XXXX-XXXX}}
 ** {{vault write secret/global/consul/energy-shrd-prod/acl_agent_token value=XXXX-XXX-XXXX-XXXX}}
 * Deploy consul on all nodes of consul cluster including clients

{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K
{code}
Patroni migration to new consul cluster steps:
 * Update patroni config with new consul token - Either re-deploy patroni clusters with ansible or update token by awk/sed
 * Restart all patroni services to pick up consul token change
 * Try resuming one patroni cluster if it would work correctly with new consul
 * If all tests will pass, the application is still running and logs of patroni, consul and postgres are clean, we can resume all remaining patroni clusters
 * Revert back systemctl patroni config files to
 ** Uncomment lines starting with *ExecStartPre=* and *ExecStopPost=***
 ** To apply the changes, run *systemctl daemon-reload*

{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStartPre/ExecStartPre/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStopPost/ExecStopPost/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=process/KillMode=control-group/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*prod*async*' -b -K
{code}",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-206,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"* consul deployed with new version on new consul hosts
* dbr hosts are in the proper VLAN
* workaround, connection from EBSM to old interface of dbr hosts are still possible 
* monitoring deployed
* certificates of consul new created",,,,,,,,,,,,,,5961600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c8ls:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 24,,,,,,,,,,,,,,,,,,,,,see my last comments,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Dec/20 11:27;cs687;+*checking the firewall-implementation #505346 & #505361*+
*Direction* {color:red}m7prodpdbX{color} -> {color:red}enprodcnslX{color} with Port *8301, 8330, 8501,8333* are working fine
*m7proddbrX can be checked after the proper interface/IP is enabled*
{code:java}
[cs687@m7prodpdb1 ~]$ telnet 10.139.132.241 8301   
Trying 10.139.132.241...                           
Connected to 10.139.132.241.                       
Escape character is '^]'.                          
^C^CConnection closed by foreign host.             

[root@prodcons1.srv.energy ~]# nc -v -l -4 8301
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Listening on 0.0.0.0:8301
{code}

*Direction* {color:red}enprodcnslX{color} -> {color:red}m7prodpdbX{color} with Port *8301 8302*
*m7proddbrX can be checked after the proper interface/IP is enabled*
{code:java}
[root@prodcons1.srv.energy ~]# telnet m7prodpdb1 8301
Trying 10.139.53.176...
Connected to m7prodpdb1.
Escape character is '^]'.
Connection closed by foreign host.
{code}

The following rules can not be checked, because *m7proddbrX* are still running in the wrong network!
* m7prodpdbX -> m7proddbrX with Port 8301
* m7proddbrX -> m7prodpdbX with Port 8301 
* m7proddbrX -> englobldap1/2 with Port 389
* same for the whole firewall-request *#505361*

{color:red}*IMPORTANT check all the ports 2 firewall-implementations like consul-firewall-request and patroni/postgres firewall-request*{color}","11/Dec/20 13:22;cs687;Created Vault backup 
*secrets/secret/global/consul/energy-shrd-prod_backup*","14/Dec/20 08:50;cs687;1.) paused the cluster and stopped dbr-patorni services 

# m7proddbr1/2
* for i in `ls /etc/ |grep patroni_`;do echo $i; systemctl stop $i;done
# shutdown the old interface 
{code:java}
ifdown eth1
{code}
* for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause;done
* for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done
{code:java}
[root@m7prodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprprodsync | m7prodpdb1 | 10.139.53.176:20016 | Sync standby | running |  3 |           |
| m7aamprprodsync | m7prodpdb3 | 10.139.53.172:20016 |    Leader    | running |  3 |         0 |
| m7aamprprodsync | m7prodpdb4 | 10.139.53.171:20016 |              | running |  3 |           |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerprodsync | m7prodpdb1 | 10.139.53.176:20018 |    Leader    | running |  2 |         0 |
| m7axeerprodsync | m7prodpdb2 | 10.139.53.173:20018 |              | running |  2 |         0 |
| m7axeerprodsync | m7prodpdb3 | 10.139.53.172:20018 | Sync standby | running |  2 |         0 |
| m7axeerprodsync | m7prodpdb4 | 10.139.53.171:20018 |              | running |  2 |           |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsprodasync | m7prodpdb1 | 10.139.53.176:20002 | Leader | running | 10 |         0 |
| m7teltsprodasync | m7prodpdb2 | 10.139.53.173:20002 |        | running | 10 |         1 |
| m7teltsprodasync | m7prodpdb3 | 10.139.53.172:20002 |        | running | 10 |         1 |
| m7teltsprodasync | m7prodpdb4 | 10.139.53.171:20002 |        | running | 10 |         1 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexprodasync | m7prodpdb1 | 10.139.53.176:20006 | Leader | running |  6 |         0 |
| m7tflexprodasync | m7prodpdb3 | 10.139.53.172:20006 |        | running |  6 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxprodasync | m7prodpdb1 | 10.139.53.176:20008 | Leader | running | 11 |         0 |
| m7thupxprodasync | m7prodpdb2 | 10.139.53.173:20008 |        | running | 11 |         0 |
| m7thupxprodasync | m7prodpdb3 | 10.139.53.172:20008 |        | running | 11 |         0 |
| m7thupxprodasync | m7prodpdb4 | 10.139.53.171:20008 |        | running | 11 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxprodasync | m7prodpdb1 | 10.139.53.176:20010 | Leader | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb2 | 10.139.53.173:20010 |        | running |  5 |           |
| m7tplpxprodasync | m7prodpdb3 | 10.139.53.172:20010 |        | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb4 | 10.139.53.171:20010 |        | running |  5 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdprodasync | m7prodpdb1 | 10.139.53.176:20000 | Leader | running |  4 |         0 |
| m7tshrdprodasync | m7prodpdb2 | 10.139.53.173:20000 |        | running |  4 |           |
| m7tshrdprodasync | m7prodpdb3 | 10.139.53.172:20000 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmprodasync | m7prodpdb1 | 10.139.53.176:20014 | Leader | running |  5 |         0 |
| m7txrpmprodasync | m7prodpdb2 | 10.139.53.173:20014 |        | running |  5 |         0 |
| m7txrpmprodasync | m7prodpdb3 | 10.139.53.172:20014 |        | running |  5 |         0 |
| m7txrpmprodasync | m7prodpdb4 | 10.139.53.171:20014 |        | running |  5 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopprodasync | m7prodpdb1 | 10.139.53.176:20012 | Leader | running |  7 |         0 |
| m7txsopprodasync | m7prodpdb2 | 10.139.53.173:20012 |        | running |  7 |         0 |
| m7txsopprodasync | m7prodpdb3 | 10.139.53.172:20012 |        | running |  7 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on

{code}
","14/Dec/20 09:01;cs687;2.) backup the patroni files
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'cp -a /usr/lib/systemd/system/patroni_* /root/systemctl_backup/' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>

[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'cp -a /etc/patroni_*/ /root/patroni_backup/' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>
{code}

","14/Dec/20 11:09;cs687;3.) Update all systemctl patroni config files to
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStartPre/#ExecStartPre/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>

[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStopPost/#ExecStopPost/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>

[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=control-group/KillMode=process/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>

[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>
{code}
","14/Dec/20 11:20;cs687;4.) Consul preparation steps:
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'subscription-manager release --set 7.8' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
Release set to: 7.8
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
Release set to: 7.8
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
Release set to: 7.8
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>
Release set to: 7.8
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
Release set to: 7.8
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>
Release set to: 7.8
{code}

{code:java}
ansible all -m shell -a 'yum clean all' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'yum repolist' --limit 'm7*-elts*prod*async*' -b -K
{code}

{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'systemctl stop consul' --limit 'm7*-elts*prod*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-prod-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-prod-dbr-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-prod-pdb-async1 | SUCCESS | rc=0 >>

[root@m7prodpdb1 ~]# systemctl status consul.service
● consul.service - Consul agent
   Loaded: loaded (/usr/lib/systemd/system/consul.service; enabled; vendor preset: disabled)
   Active: inactive (dead) since Mon 2020-12-14 11:16:34 CET; 53s ago
  Process: 14495 ExecStart=/usr/local/bin/consul agent -config-file=/etc/consul/config.json -config-dir=/etc/consul/consul.d -pid-file=/var/run/consul/consul.pid (code=exited, status=0/SUCCESS)
 Main PID: 14495 (code=exited, status=0/SUCCESS)

Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: consul client down
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: shutdown complete
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Stopping DNS server 0.0.0.0:8600 (tcp)
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Stopping DNS server 0.0.0.0:8600 (udp)
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Stopping HTTP server 127.0.0.1:8500 (tcp)
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Stopping HTTPS server 0.0.0.0:8501 (tcp)
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Waiting for endpoints to shut down
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Endpoints down
Dec 14 11:16:34 m7prodpdb1 consul[14495]: 2020/12/14 11:16:34 [INFO] agent: Exit code: 0
Dec 14 11:16:34 m7prodpdb1 systemd[1]: Stopped Consul agent.
{code}

{code:java}
ansible all -m shell -a 'cp -a /etc/consul /root/consul_backup' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'cp -a /usr/local/bin/consul /root/consul_backup/consul_binary' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /etc/consul/ -rf' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /var/consul -rf' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'rm /usr/local/bin/consul' --limit 'm7*-elts*prod*async*' -b -K
{code}


","14/Dec/20 11:22;cs687;5.) deleting vault secrets and backuped it before
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ for i in `vault list secret/global/consul/energy-shrd-prod/ |grep -v Keys |grep -v '\-\-\-\-'`;do vault delete secret/global/consul/energy-shrd-prod/$i ;done
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/acl_agent_token
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/acl_replication_token
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/bootstrap_token
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/ca_cert
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/ca_key
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/client_cert
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/client_key
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/encrypt_key
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/server_cert
Success! Data deleted (if it existed) at: secret/global/consul/energy-shrd-prod/server_key
{code}

6.) generate new keys
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ export CONSUL_DC=energy-shrd-prod && \
> export CONSUL_BINARY=/usr/local/bin/consul && \
> roles/consul_instance/create-consul-cluster.sh
I'm about to create certificates and keys for consul datacenter 'energy-shrd-prod' and write them to vault.
Do you want to continue? [y/N] y
As you wish...
==> Saved consul-agent-ca.pem
==> Saved consul-agent-ca-key.pem
No value found at secret/global/consul/energy-shrd-prod/ca_key
Success! Data written to: secret/global/consul/energy-shrd-prod/ca_key
No value found at secret/global/consul/energy-shrd-prod/ca_cert
Success! Data written to: secret/global/consul/energy-shrd-prod/ca_cert
==> WARNING: Server Certificates grants authority to become a
    server and access all state in the cluster including root keys
    and all ACL tokens. Do not distribute them to production hosts
    that are not server nodes. Store them as securely as CA keys.
==> Using consul-agent-ca.pem and consul-agent-ca-key.pem
==> Saved energy-shrd-prod-server-consul-0.pem
==> Saved energy-shrd-prod-server-consul-0-key.pem
No value found at secret/global/consul/energy-shrd-prod/server_key
Success! Data written to: secret/global/consul/energy-shrd-prod/server_key
No value found at secret/global/consul/energy-shrd-prod/server_cert
Success! Data written to: secret/global/consul/energy-shrd-prod/server_cert
==> Using consul-agent-ca.pem and consul-agent-ca-key.pem
==> Saved energy-shrd-prod-client-consul-0.pem
==> Saved energy-shrd-prod-client-consul-0-key.pem
No value found at secret/global/consul/energy-shrd-prod/client_key
Success! Data written to: secret/global/consul/energy-shrd-prod/client_key
No value found at secret/global/consul/energy-shrd-prod/client_cert
Success! Data written to: secret/global/consul/energy-shrd-prod/client_cert
No value found at secret/global/consul/energy-shrd-prod/encrypt_key
Success! Data written to: secret/global/consul/energy-shrd-prod/encrypt_key
{code}

","14/Dec/20 11:25;cs687;7.) deploy consul server
{code:java}
[cs687@enprodauto1 {master L | ?6} ~/ansible/energy.automation.deployments]$ ansible-playbook -e consul_group_name=consul_energy_shrd_prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K -k --limit 'energy-shrd-prod-cons*' --list-hosts

playbook: playbooks/deploy_consul_instances.yml

  play #1 (consul_energy_shrd_prod): Assemble Consul cluster    TAGS: []
    pattern: ['consul_energy_shrd_prod']
    hosts (5):
      energy-shrd-prod-cons2
      energy-shrd-prod-cons4
      energy-shrd-prod-cons1
      energy-shrd-prod-cons5
      energy-shrd-prod-cons3

  play #2 (consul_energy_shrd_prod): Configure consul server network segments   TAGS: []
    pattern: ['consul_energy_shrd_prod']
    hosts (5):
      energy-shrd-prod-cons2
      energy-shrd-prod-cons4
      energy-shrd-prod-cons1
      energy-shrd-prod-cons5
      energy-shrd-prod-cons3
{code}

{code:java}
[root@prodcons1.srv.energy ~]# export CONSUL_HTTP_TOKEN=XXX
[root@prodcons1.srv.energy ~]# consul members
Node                    Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-prod-cons1  10.139.132.241:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons2  10.139.132.242:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons3  10.139.132.243:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons4  10.139.132.244:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons5  10.139.132.245:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
{code}


{code:java}
[cs687@enprodauto1 {master L | ?6} ~/ansible/energy.automation.deployments]$ vault write secret/global/consul/energy-shrd-prod/bootstrap_token value=XXX
Success! Data written to: secret/global/consul/energy-shrd-prod/bootstrap_token
[cs687@enprodauto1 {master L | ?6} ~/ansible/energy.automation.deployments]$ vault write secret/global/consul/energy-shrd-prod/acl_replication_token value=XXX
Success! Data written to: secret/global/consul/energy-shrd-prod/acl_replication_token
[cs687@enprodauto1 {master L | ?6} ~/ansible/energy.automation.deployments]$ vault write secret/global/consul/energy-shrd-prod/acl_agent_token value=XXX
Success! Data written to: secret/global/consul/energy-shrd-prod/acl_agent_token
{code}

","14/Dec/20 11:34;cs687;8.) deploy consul instances

{code:java}
[cs687@enprodauto1 {master L | ?6} ~/ansible/energy.automation.deployments]$ ansible-playbook -e consul_group_name=consul_energy_shrd_prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K -k --list-hosts

playbook: playbooks/deploy_consul_instances.yml

  play #1 (consul_energy_shrd_prod): Assemble Consul cluster    TAGS: []
    pattern: ['consul_energy_shrd_prod']
    hosts (11):
      energy-shrd-prod-cons2
      m7t-shrd-prod-consul-pdb4
      m7t-shrd-prod-consul-pdb3
      m7t-shrd-prod-consul-dbr1
      energy-shrd-prod-cons1
      energy-shrd-prod-cons3
      m7t-shrd-prod-consul-pdb2
      m7t-shrd-prod-consul-pdb1
      energy-shrd-prod-cons4
      energy-shrd-prod-cons5
      m7t-shrd-prod-consul-dbr2

  play #2 (consul_energy_shrd_prod): Configure consul server network segments   TAGS: []
    pattern: ['consul_energy_shrd_prod']
    hosts (11):
      energy-shrd-prod-cons2
      m7t-shrd-prod-consul-pdb4
      m7t-shrd-prod-consul-pdb3
      m7t-shrd-prod-consul-dbr1
      energy-shrd-prod-cons1
      energy-shrd-prod-cons3
      m7t-shrd-prod-consul-pdb2
      m7t-shrd-prod-consul-pdb1
      energy-shrd-prod-cons4
      energy-shrd-prod-cons5
      m7t-shrd-prod-consul-dbr2
{code}

{color:red}*Ended up with that issue, Lambert will fix it and rerun the deployment*{color}
{code:java}
Failure talking to yum: failure: repodata/repomd.xml from rhel-7-server-eus-rpms: [Errno 256] No more mirrors to try.
https://englobsat1.deutsche-boerse.de/pulp/repos/DBG_Energy_Global/Energy_Production/RHEL-7_POSTGRESQL-11/content/eus/rhel/server/7/7.8/x86_64/os/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found
{code}

{code:java}
[root@prodcons1.srv.energy ~]# consul members
Node                       Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-prod-cons1     10.139.132.241:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons2     10.139.132.242:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons3     10.139.132.243:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons4     10.139.132.244:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
energy-shrd-prod-cons5     10.139.132.245:8301  alive   server  1.8.6+ent  2         energy-shrd-prod  <all>
m7t-shrd-prod-consul-dbr1  10.139.135.221:8301  alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
m7t-shrd-prod-consul-dbr2  10.139.135.222:8301  alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
m7t-shrd-prod-consul-pdb1  10.139.53.176:8301   alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
m7t-shrd-prod-consul-pdb2  10.139.53.173:8301   alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
m7t-shrd-prod-consul-pdb3  10.139.53.172:8301   alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
m7t-shrd-prod-consul-pdb4  10.139.53.171:8301   alive   client  1.8.6+ent  2         energy-shrd-prod  m7-prod-patroni-cluster
{code}

","14/Dec/20 12:57;cs687;9.) change bootstrap token on patroni instances:
{code:java}
ansible all -m shell -a 'for i in `ls /etc/patroni_*/config.yml`;do sed -i ""s/XXX_old/XXX_new/g"" $i;done' --limit 'm7*-elts*prod*async*' -b -K -k
{code}

{code:java}
# check on all nodes 
ansible all -m shell -a 'for i in `ls /etc/patroni_*/config.yml`;do grep -i token $i;done' --limit 'm7*-elts*prod*async*' -b -K -k
{code}



FLEXPROD
{code:java}
[root@m7prodpdb1 ~]# patronictl -c /etc/patroni_m7tflexprodasync/config.yml list
+---------+--------+------+------+-------+----+-----------+
| Cluster | Member | Host | Role | State | TL | Lag in MB |
+---------+--------+------+------+-------+----+-----------+
+---------+--------+------+------+-------+----+-----------+
{code}


#after restart patroni nodes, everything is working 
{code:java}
ansible all -m shell -a 'systemctl restart patroni_m7tflexprodasync.service'  --limit 'm7*-flex*prod*pdb-async1:m7*-flex*prod*pdb-async3' -b -K -k --list-hosts
{code}


{code:java}
patronictl -c /etc/patroni_m7tflexprodasync/config.yml resume
{code}


{code:java}
[root@m7prodpdb1 ~]# patronictl -c /etc/patroni_m7tflexprodasync/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexprodasync | m7prodpdb1 | 10.139.53.176:20006 | Leader | running |  6 |         0 |
| m7tflexprodasync | m7prodpdb3 | 10.139.53.172:20006 |        | running |  6 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
{code}

{color:red}*these steps has to be done for all the env´s*{color}","14/Dec/20 13:45;cs687;10.) rolledback all the service files 
{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStartPre/ExecStartPre/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStopPost/ExecStopPost/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=process/KillMode=control-group/g"" $i; done' --limit 'm7*-elts*prod*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*prod*async*' -b -K
{code}
","14/Dec/20 14:13;cs687;11.) deployment of replica-hosts
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7*-prod*dbr*:playbooks/deploy_patroni.yml --limit ""m7*-prod*dbr*"" -k -K -b --tags replicaicsc-prod*:playbooks/deploy_patroni.yml --limit ""m7*-prod*dbr*"" -k -K -b --tags replicaflex-prod*"" -k -K -b  --tags replica
{code}

#bring old interface up and running 
{code:java}
[root@m7proddbr1 ~]# ifup eth1
[root@m7proddbr1 ~]# ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 10.139.135.221  netmask 255.255.255.0  broadcast 10.139.135.255
        ether 00:50:56:be:e7:97  txqueuelen 1000  (Ethernet)
        RX packets 6364103  bytes 32082503263 (29.8 GiB)
        RX errors 0  dropped 2628  overruns 0  frame 0
        TX packets 3103740  bytes 254834423 (243.0 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

eth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 10.136.161.253  netmask 255.255.255.128  broadcast 10.136.161.255
        ether 00:50:56:be:63:d9  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 5  bytes 210 (210.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 103084  bytes 19269192 (18.3 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 103084  bytes 19269192 (18.3 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
{code}

#added static routes for ebsm connection 
{code:java}
* ip route add 10.139.54.216/32 via 10.136.161.129 
* ip route add 10.139.54.216/32  via 10.136.33.129

[cs687@m7shrdebsm1 ~]$ telnet 10.136.161.253 20012           
Trying 10.136.161.253...                                     
Connected to 10.136.161.253.                                 
Escape character is '^]'.                                    
^CConnection closed by foreign host.                         
                                   
[cs687@m7shrdebsm1 ~]$ telnet 10.136.33.253 20012            
Trying 10.136.33.253...                                      
Connected to 10.136.33.253.                                  
Escape character is '^]'.                                    
^CConnection closed by foreign host.                         
[cs687@m7shrdebsm1 ~]$ ^C                                    
{code}


","14/Dec/20 16:20;hw120; - Deployed OS monitoring on new prodcons[1-5].srv.energy hosts and checked if we can see data in graphs

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1510/console|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1503/console]

 - Updated certificate monitoring config

[https://github.deutsche-boerse.de/dev/energy.automation.certificate/commit/adb8d3fa66798ffc1179af80f23a811b5396891a|https://github.deutsche-boerse.de/dev/energy.automation.certificate/commit/9b78fa6c3ad269f6ff3f530e425b170dfa305d60]

 - Run certificate monitoring update jenkins job

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Scheduled-tasks/job/Certificate%20info%20update/247/console]

 - Checking if cert table is updated

[https://github.deutsche-boerse.de/pages/dev/energy.automation.certificate/#sort=expiry&order=asc]

 - Updated patroni deployment to exclude backup volume creation on replica hosts - dbrX

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1273/files]

 ","15/Dec/20 07:29;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
(split 2) Add option to disable several input channels in CMI,XP-4238,104181,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,eh941,lt112,09/Dec/20 13:42,11/Dec/20 15:22,22/Feb/21 13:26,11/Dec/20 15:22,,,3.2.x,,,,,,,,,,,"If the ECP is not configured the log is full of following exceptions:
{noformat}
2020-08-07T11:47:54.001Z [TaskScheduler-6][][] ERROR c.d.e.c.t.e.w.c.ECPMessagingClientDefault - Unknown exception occured when calling ECP WS. .
java.lang.NullPointerException: null
        at org.springframework.ws.transport.http.AbstractHttpWebServiceMessageSender.supports(AbstractHttpWebServiceMessageSender.java:63)
        at org.springframework.ws.client.support.WebServiceAccessor.createConnection(WebServiceAccessor.java:107)
        at org.springframework.ws.client.core.WebServiceTemplate.sendAndReceive(WebServiceTemplate.java:551)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:390)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:383)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:373)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.lambda$marshalSendAndReceive$4(MultiNodeWsTemplate.java:54)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.doWithFallback(MultiNodeWsTemplate.java:110)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.marshalSendAndReceive(MultiNodeWsTemplate.java:54)
        at com.deutscheboerse.energy.commons.transport.ecp.ws.client.ECPMessagingClientDefault.doReceiveMessage(ECPMessagingClientDefault.java:153)
        at com.deutscheboerse.energy.commons.transport.ecp.ws.client.ECPMessagingClientDefault.receiveMessage(ECPMessagingClientDefault.java:75)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessage(EcpTransport.java:106)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessages(EcpTransport.java:79)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1556)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessages(EcpTransport.java:63)
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.receive(EcpHandler.java:59)
        at sun.reflect.GeneratedMethodAccessor147.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)
        at com.deutscheboerse.energy.failover.aop.SkipExecutionIfNotMasterAspect.aroundHandler(SkipExecutionIfNotMasterAspect.java:41)
        at sun.reflect.GeneratedMethodAccessor145.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)

{noformat}
But it doesn't mean the application has a bug inside. Add switch to enable/disable SFTP, ECP, Mail, SCP input channels in CMI, SPM.
 
Acceptance criteria: 
 * possibility to turn on/off input channels in CMI, SPM for all channels (document how it's done and inform developers!)
 ** e.g. property like EcpChannelEnabled=false in the inventory
 * always log information about skipped channel because it's disabled. ",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6393600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zk",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,HOT Sprint 24 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Strange values on 12/11 in Performance and SM SLA Report, and Credit Points Report",XP-4237,104174,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Resolved,yn731,yn731,yn731,09/Dec/20 12:42,05/Jan/21 12:27,22/Feb/21 13:26,21/Dec/20 09:23,,,,,,,,,,SLA,,,,"h3. +*Performance and SM SLA Report*+ 

*Order Execution time:*
|2020-11-11|53|73|
|2020-11-12|100|135|

*Public Orderbooks Reports Resp:*
|2020-11-11|50|64|
|2020-11-12|86|109|
----
h3.  +*Credit Points Report*+

*Order Execution Time*
|2020-11-11 16:00:00|2020-11-11 17:00:00|26|32|
|2020-11-11 17:00:00|2020-11-11 18:00:00|36|49|
|2020-11-11 18:00:00|2020-11-11 19:00:00|43|66|
|2020-11-11 19:00:00|2020-11-11 20:00:00|54|80|
|2020-11-11 20:00:00|2020-11-11 21:00:00|88|144|
|2020-11-11 21:00:00|2020-11-11 22:00:00|93|134|
|2020-11-11 22:00:00|2020-11-11 23:00:00|97|128|
|2020-11-11 23:00:00|2020-11-12 00:00:00|102|138|
|2020-11-12 00:00:00|2020-11-12 01:00:00|142|188|
|2020-11-12 01:00:00|2020-11-12 02:00:00|131|188|
|2020-11-12 02:00:00|2020-11-12 03:00:00|126|185|
|2020-11-12 03:00:00|2020-11-12 04:00:00|121|170|
|2020-11-12 04:00:00|2020-11-12 05:00:00|119|159|
|2020-11-12 05:00:00|2020-11-12 06:00:00|131|169|
|2020-11-12 06:00:00|2020-11-12 07:00:00|100|134|
|2020-11-12 11:00:00|2020-11-12 12:00:00|19|24|
|2020-11-12 12:00:00|2020-11-12 13:00:00|25|30|
|2020-11-12 13:00:00|2020-11-12 14:00:00|34|42|
|2020-11-12 14:00:00|2020-11-12 15:00:00|44|55|
|2020-11-12 15:00:00|2020-11-12 16:00:00|53|71|
|2020-11-12 16:00:00|2020-11-12 17:00:00|54|67|
|2020-11-12 17:00:00|2020-11-12 18:00:00|71|91|
|2020-11-12 18:00:00|2020-11-12 19:00:00|75|94|
|2020-11-12 19:00:00|2020-11-12 20:00:00|88|122|
|2020-11-12 20:00:00|2020-11-12 21:00:00|103|143|
|2020-11-12 21:00:00|2020-11-12 22:00:00|131|171|
|2020-11-12 22:00:00|2020-11-12 23:00:00|148|201|
|2020-11-12 23:00:00|2020-11-13 00:00:00|179|331|
|2020-11-13 00:00:00|2020-11-13 01:00:00|82|123|

 *Publix orderbook Reports resp*
|2020-11-11 19:00:00|2020-11-11 20:00:00|53|64|
|2020-11-11 20:00:00|2020-11-11 21:00:00|64|81|
|2020-11-11 21:00:00|2020-11-11 22:00:00|83|103|
|2020-11-11 22:00:00|2020-11-11 23:00:00|91|111|
|2020-11-11 23:00:00|2020-11-12 00:00:00|92|111|
|2020-11-12 00:00:00|2020-11-12 01:00:00|110|141|
|2020-11-12 01:00:00|2020-11-12 02:00:00|111|137|
|2020-11-12 02:00:00|2020-11-12 03:00:00|111|135|
|2020-11-12 03:00:00|2020-11-12 04:00:00|113|134|
|2020-11-12 04:00:00|2020-11-12 05:00:00|107|129|
|2020-11-12 05:00:00|2020-11-12 06:00:00|127|146|
|2020-11-12 06:00:00|2020-11-12 07:00:00|92|115|
|2020-11-12 07:00:00|2020-11-12 08:00:00|31|41|
|2020-11-12 08:00:00|2020-11-12 09:00:00|28|38|
|2020-11-12 09:00:00|2020-11-12 10:00:00|31|40|
|2020-11-12 10:00:00|2020-11-12 11:00:00|28|39|
|2020-11-12 11:00:00|2020-11-12 12:00:00|29|38|
|2020-11-12 12:00:00|2020-11-12 13:00:00|32|40|
|2020-11-12 13:00:00|2020-11-12 14:00:00|45|54|
|2020-11-12 14:00:00|2020-11-12 15:00:00|52|60|
|2020-11-12 15:00:00|2020-11-12 16:00:00|58|68|
|2020-11-12 16:00:00|2020-11-12 17:00:00|58|68|
|2020-11-12 17:00:00|2020-11-12 18:00:00|69|83|
|2020-11-12 18:00:00|2020-11-12 19:00:00|74|88|
|2020-11-12 19:00:00|2020-11-12 20:00:00|81|95|
|2020-11-12 20:00:00|2020-11-12 21:00:00|90|106|
|2020-11-12 21:00:00|2020-11-12 22:00:00|115|141|
|2020-11-12 22:00:00|2020-11-12 23:00:00|127|157|
|2020-11-12 23:00:00|2020-11-13 00:00:00|124|156|
|2020-11-13 00:00:00|2020-11-13 01:00:00|67|88|

*Rabbit MQ queing time{color:#de350b} (Out of SLAs){color}*
|2020-11-12 09:00:00|2020-11-12 10:00:00|759|
|2020-11-12 10:00:00|2020-11-12 11:00:00|5|
|2020-11-12 11:00:00|2020-11-12 12:00:00|5|
|2020-11-12 12:00:00|2020-11-12 13:00:00|5|
|2020-11-12 13:00:00|2020-11-12 14:00:00|3|
|2020-11-12 14:00:00|2020-11-12 15:00:00|3|
|2020-11-12 15:00:00|2020-11-12 16:00:00|2|

 ",,yn731,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/20 16:56;yn731;XBID Credit Points Report November 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/90994/XBID+Credit+Points+Report+November+2020.xlsx","09/Dec/20 12:41;yn731;XBID Performance and SM SLA Reporting November 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/90961/XBID+Performance+and+SM+SLA+Reporting+November+2020.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5443200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,09/Dec/20 12:42,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:fi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 24,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Production,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/20 10:46;zi174;From my point of view, the values are slightly higher than usual. However, this happened only between 11.12 - 12.12 and we're still safely within SLA. I am not able provide a reason why these values are higher (it would investigate someone from Dev), but I don't think it's necessary. This situation doesn't happen on regular basis, just in the particular day(s). Thus, from my point of view we should monitor if these high values will appear more often and then investigate it. 

As I mentioned above, we are still safely within SLA and the values are not on the top border of SLA, I wouldn't invest more time to investigate why the values are higher as from my point of view it does not indicate any potential issues for the future. 

I would investigate more only in case the customer will request it.

 

Jakub","18/Dec/20 16:24;yn731;Hi [~zi174]

Those numbers below looked biiiiig. that is why I wanted to check it with you.

*Rabbit MQ queing time{color:#de350b} (Out of SLAs){color}*
|2020-11-12 09:00:00|2020-11-12 10:00:00|759|

Clarified it is. Thanks!","21/Dec/20 09:18;zi174;Hi [~yn731],

Yes, I saw it, but as I mentioned above, it's ""one-number show"" without any consequences. So, it can be caused by e.g. some update etc. but nothing what concern me.

 

Jakub",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
product entity refactoring vol2,XP-4234,104147,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,09/Dec/20 08:54,19/Jan/21 10:12,22/Feb/21 13:26,13/Jan/21 10:49,,,3.2.x,,,,,,,,,,,"There are unused pieces of code on xbid entitities, go through it and consider removing.
 * Product#assetName
 * Product#assetExchangeId
 * Product#assetType
 * ProductType

There can be more, take a peek into prod db and see what is not set and try to determine from code if it is indeed needed.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6480000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:7",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Christmas Sprint (S),Alpha Sprint 25,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3394_flyway_standard_implementation,XP-3394_remove_schema_version,XP-4354,develop,XP-4349_set_default_page,XP-2400,XP-4234,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement data ingestion - XBID core,XP-4229,104112,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ll664,ll664,08/Dec/20 14:26,06/Jan/21 11:20,22/Feb/21 13:26,06/Jan/21 11:20,,,,,,,,,,demo,,,,"* Implement data ingestion into current {{develop}} branch.
 * Collect enhanced metrics as defined in the epic
 * Remove ElasticDisruptor - decide what do do with SLA
 * Design maintainable solution, couple of requirements:
 ** we do rare deploys to PROD, hence it would make sense to deocouple code that pushes to timescale/elastic to separate application, in order to deploy more often
 ** in core push metrics effectively (should not slowdown the core as logback does), chronicle with some binary format comes in mind

Suggestions:
 * use Chronicle to decouple XBID core from Analytical platform/ingestion agent
 * agent runs on the same host as core
 * we should be able deploy the agent anytime even if it is on the sam host as core (verify with someone?)

AC: 

- present the outcome on the scrum event",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c78s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 24,Alpha Christmas Sprint (S),,,,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Jan/21 11:20;ll664;Closing, followup tasks are created.

For Sloth - a new repository has been created - https://github.deutsche-boerse.de/dev/xbid.sloth
XBID - code not yet merged to develop, still in branch - https://github.deutsche-boerse.de/dev/xbid/tree/XP-4250-develop",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement data ingestion for current production,XP-4223,104063,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,ll664,08/Dec/20 12:44,15/Feb/21 12:03,22/Feb/21 13:26,15/Feb/21 12:03,,,,,,,,,,,,,,"We want current production metrics. Design a solution how to push it to target databases.

TODO:
* kotlin application (create task for VM)
* poll periodically ElasticSearch
* write metrics extractor from ElasticSearch
* design a data model - drafted in Epic

",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4379,XP-4308,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zofu",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 24 (S),HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Alarm Tilt checks for web UIs and RabbitMQs,XP-4222,104055,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,lw641,lw641,08/Dec/20 11:21,08/Dec/20 13:49,22/Feb/21 13:26,08/Dec/20 13:49,,,,,,,,,,,,,,"Alarm Tilt checks for web UIs and Rabbits were written by techops in the past and were part of the pearl deployment.
 
My question was how are these checks deployed (I can't find anything in the ansible project) and how are maintained and if they work.
 
There was a rumour that Peter P. did some changes in rabbitmq checks but I can't see any changes in the energy-mkt-shared.
 
Thank you.",,ei349,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4227,XP-4226,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6480000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c7go:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Dec/20 13:48;ei349;This is still in Perl. There is a follow up in tickets XP-4226, XP-4227. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare new consul enterprise simu cluster - deployment on simu env and migration of M7 SIMU patroni clusters,XP-4208,103873,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,hw120,hw120,03/Dec/20 22:25,11/Dec/20 10:28,22/Feb/21 13:26,08/Dec/20 12:01,,,,,,,,,,Consul,Patroni,TechOps,,"We need to deploy new Consul Enterprise cluster for simu environments, which would be shared by all energy products.

We have new servers prepared simucons[1-5].srv.energy where it should be deployed.

As we have to migrate existing/connected m7simudbr1/2 hosts to a new network, we will have to stop patroni and postgres services running on them first.

 

*NOTE: We must make sure, all needed ports are open in every needed direction as described here:*

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Consul#Consul-Networkports-FWrules]

Using nc or telnet we can easily test it: [https://ubidots.com/blog/how-to-simulate-a-tcpudp-client-using-netcat/]

 

Patroni preparation steps:
 * Connect to *m7simudbr1/2* hosts and stop patroni services
 ** Notify Lambert to start their migration to new networks and ips
 ** Also so he adds second network interface for the old network with proper routing so ebsm connection would still work
 * Pause all patroni clusters running on *m7simupdb[1-4]* hosts and check if they are in maintenance mode

 
{code:java}
ssh m7simupdb1
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause;done
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done
# to check it from enprodauto1
ansible all -m shell -a 'for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done' --limit 'm7*-elts*simu*async1' -b -{code}
 
 * Update all systemctl patroni config files to
 ** Comment out lines starting with *ExecStartPre=* and *ExecStopPost=*
 ** Change *KillMode=control-group* to *KillMode=process*
 ** To apply the changes, run *systemctl daemon-reload*

{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStartPre/#ExecStartPre/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStopPost/#ExecStopPost/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=control-group/KillMode=process/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*simu*async*' -b -K
{code}
 * Make a backup of patroni configuration in */etc/patroni_/config.yml*

{code:java}
ansible all -m shell -a 'mkdir /root/patroni_backup && cp -a /etc/patroni_*/ /root/patroni_backup/' --limit 'm7*-elts*simu*async*' -b -K
{code}
Consul preparation steps:
 * Enable RHEL 7.8 repository so consul deployment would have python3 selinux dependency available
 * Stop consul clients on all *m7simupdb[1-4]* and *m7simudbr1/2* hosts
 * Make a backup of consul configuration in */etc/consul/* and binary in */usr/local/bin/consul*
 * Clean up old consul config and binary

{code:java}
ansible all -m shell -a 'subscription-manager release --set 7.8' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'systemctl stop consul' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'cp -a /etc/consul /root/consul_backup' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'cp -a /usr/local/bin/consul /root/consul_backup/consul_binary' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'rm /etc/consul/ -rf' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'rm /var/consul -rf' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'rm /usr/local/bin/consul' --limit 'm7*-elts*simu*async*' -b -K
{code}
Consul deployment steps: 
 * Create keys and certificates for the cluster:
 ** Make sure vault path for this new cluster is empty {{vault list secret/global/consul/energy-shrd-simu}}
 *** If old keys exists there, delete them
 *** 
{code:java}
for i in `vault list secret/global/consul/energy-shrd-simu/ |grep -v Keys |grep -v '\-\-\-\-'`;do vault delete secret/global/consul/energy-shrd-simu/$i ;done
{code}

 * 
 ** Export variables to define cluster name, consul binary path and run script to generate certs with 10y validity
 ** 
{code:java}
export CONSUL_DC=energy-shrd-simu && \
export CONSUL_BINARY=/usr/local/bin/consul && \
roles/consul_instance/create-consul-cluster.sh{code}

 * 
 ** this will save them in vault folder {{secret/global/consul/<dc_name>/}} - make sure they are there afterward {{vault list secret/global/consul/energy-shrd-simu}}
 * Deploy consul servers 

{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K --limit 'energy-shrd-simu-cons*'
{code}
 * 
 ** be carefull to set correct limit and group name - do you want to deploy all instances in the group?
 ** you may append \{{ -e consul_install_upgrade=True}} if you wish to upgrade the consul binary in case it already exists
 ** you may also append other parameters from the upstream role, they are documented here: [https://github.com/brianshumate/ansible-consul/blob/master/README.md]
 * this will deploy cluster with TLS, gossip encrypt and ACL security enabled
 * Now you save bootstrap token which you can find on any provisioned node in {{/etc/consul/config.json}} to vault {{secret/global/consul/<dc_name>/bootstrap_token}}
 * Save tokens to vault
 ** {{vault write secret/global/consul/energy-shrd-simu/bootstrap_token value=XXXX-XXX-XXXX-XXXX}}
 ** {{vault write secret/global/consul/energy-shrd-simu/acl_replication_token value=XXXX-XXX-XXXX-XXXX}}
 ** {{vault write secret/global/consul/energy-shrd-simu/acl_agent_token value=XXXX-XXX-XXXX-XXXX}}
 * Deploy consul on all nodes of consul cluster including clients

{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K
{code}
Patroni migration to new consul cluster steps:
 * Update patroni config with new consul token - Either re-deploy patroni clusters with ansible or update token by awk/sed
 * Restart all patroni services to pick up consul token change
 * Try resuming one patroni cluster if it would work correctly with new consul
 * If all tests will pass, the application is still running and logs of patroni, consul and postgres are clean, we can resume all remaining patroni clusters
 * Revert back systemctl patroni config files to
 ** Uncomment lines starting with *ExecStartPre=* and *ExecStopPost=***
 ** To apply the changes, run *systemctl daemon-reload*

{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStartPre/ExecStartPre/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStopPost/ExecStopPost/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=process/KillMode=control-group/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*simu*async*' -b -K
{code}",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"all steps are described in the last comment!
",,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hzo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,.,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/20 09:03;cs687;Network-Switch: https://jira.deutsche-boerse.com/browse/SYSENGINT-193","07/Dec/20 15:11;cs687;related to the replica hosts changes:
epex-asim reporting engine is still pointing to the replica-hosts and should be changed for this maintenance to the pdb hosts.
 
https://jira.deutsche-boerse.com/browse/SERVICE-9247
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2421","08/Dec/20 08:05;cs687;1.) paused simu patroni cluster on m7simupdb1-4 - and verified that this is the case 
{code:java}
[root@m7simupdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
{code}

2.) stopped the patroni service on the hosts *m7simudbr1* and *m7simudbr2*
{code:java}
[root@m7simudbr1 ~]# systemctl stop patroni_m7teltsctpbasync.service
[root@m7simudbr1 ~]# systemctl stop patroni_m7teltssimuasync.service
[root@m7simudbr1 ~]# systemctl stop patroni_m7tepexasimasync.service
[root@m7simudbr1 ~]# systemctl stop patroni_m7thupxasimasync.service
{code}

3.) Updating all systemctl patroni config files for each cluster
{code:java}
[cs687@enprodauto1 {epex-asim L | ✔} ~/ansible/energy.automation.deployments]$ ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStartPre/#ExecStartPre/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K -k
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-simu-dbr-async1 | SUCCESS | rc=0 >>
m7t-elts-simu-pdb-async2 | SUCCESS | rc=0 >>
m7t-elts-simu-pdb-async1 | SUCCESS | rc=0 >>
m7t-elts-simu-pdb-async3 | SUCCESS | rc=0 >>
m7t-elts-simu-pdb-async4 | SUCCESS | rc=0 >>
m7t-elts-simu-dbr-async2 | SUCCESS | rc=0 >>

and also... 

ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/ExecStopPost/#ExecStopPost/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K -k

ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=control-group/KillMode=process/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K -k

ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*simu*async*' -b -K -k
{code}

4.) Make a backup of patroni configuration in /etc/patroni_/config.yml
{code:java}
ansible all -m shell -a 'mkdir /root/patroni_backup && cp -a /etc/patroni_*/ /root/patroni_backup/' --limit 'm7*-elts*simu*async*' -b -K -k

drwxr-xr-x  31 root root  4096 Dec  8 08:52 patroni_backup
{code}

5.) 

{code:java}
ansible all -m shell -a 'subscription-manager release --set 7.8' --limit 'm7*-elts*simu*async*' -b -K -k
ansible all -m shell -a 'systemctl stop consul' --limit 'm7*-elts*simu*async*' -b -K -k
ansible all -m shell -a 'cp -a /etc/consul /root/consul_backup' --limit 'm7*-elts*simu*async*' -b -K -k
ansible all -m shell -a 'rm /etc/consul/ -rf' --limit 'm7*-elts*simu*async*' -b -K
{code}

6.) backup-ed vault ""energy-shrd-simu-backup""
 /secrets/secret/global/consul/energy-shrd-simu
deleted the current vault setting
{code:java}
for i in `vault list secret/global/consul/energy-shrd-simu/ |grep -v Keys |grep -v '\-\-\-\-'`;do vault delete secret/global/consul/energy-shrd-simu/$i ;done
{code}

7.) Export variables to define cluster name, consul binary path and run script to generate certs with 10y validity
{code:java}
export CONSUL_DC=energy-shrd-simu && \
export CONSUL_BINARY=/usr/local/bin/consul && \
roles/consul_instance/create-consul-cluster.sh

[cs687@enprodauto1 {epex-asim L | ?6} ~/ansible/energy.automation.deployments]$ vault list secret/global/consul/energy-shrd-simu
Keys
----
ca_cert
ca_key
client_cert
client_key
encrypt_key
server_cert
server_key
{code}

8.) consul server deployment 
{code:java}
[cs687@enprodauto1 {epex-asim L | ?6} ~/ansible/energy.automation.deployments]$ ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -k -K --limit 'energy-shrd-simu-cons*' --list-hosts

playbook: playbooks/deploy_consul_instances.yml
  play #1 (consul_energy_shrd_simu): Assemble Consul cluster    TAGS: []
    pattern: ['consul_energy_shrd_simu']
    hosts (5):
      energy-shrd-simu-cons4
      energy-shrd-simu-cons3
      energy-shrd-simu-cons2
      energy-shrd-simu-cons5
      energy-shrd-simu-cons1

  play #2 (consul_energy_shrd_simu): Configure consul server network segments   TAGS: []
    pattern: ['consul_energy_shrd_simu']
    hosts (5):
      energy-shrd-simu-cons4
      energy-shrd-simu-cons3
      energy-shrd-simu-cons2
      energy-shrd-simu-cons5
      energy-shrd-simu-cons1

ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -k -K --limit 'energy-shrd-simu-cons*'

[root@simucons1.srv.energy ~]# export CONSUL_HTTP_TOKEN=XXX
[root@simucons1.srv.energy ~]# systemctl status consul.service
● consul.service - Consul agent
   Loaded: loaded (/usr/lib/systemd/system/consul.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2020-12-08 10:25:02 CET; 2min 7s ago
  Process: 37547 ExecStartPre=/bin/chown -R consul:bin /run/consul (code=exited, status=0/SUCCESS)
  Process: 37545 ExecStartPre=/bin/mkdir -m 0750 -p /run/consul (code=exited, status=0/SUCCESS)
 Main PID: 37550 (consul)
   CGroup: /system.slice/consul.service
           └─37550 /usr/local/bin/consul agent -config-file=/etc/consul/config.json -config-dir=/etc/consul/consul.d -pid-file=/run/consul/consul.pid

Dec 08 10:25:02 simucons1.srv.energy systemd[1]: consul.service: main process exited, code=exited, status=1/FAILURE
Dec 08 10:25:02 simucons1.srv.energy systemd[1]: Stopped Consul agent.
Dec 08 10:25:02 simucons1.srv.energy systemd[1]: Unit consul.service entered failed state.
Dec 08 10:25:02 simucons1.srv.energy systemd[1]: consul.service failed.
Dec 08 10:25:02 simucons1.srv.energy systemd[1]: Starting Consul agent...
Dec 08 10:25:02 simucons1.srv.energy systemd[1]: Started Consul agent.
[root@simucons1.srv.energy ~]# consul members
Node                    Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-simu-cons1  10.139.131.241:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons2  10.139.131.242:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons3  10.139.131.243:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons4  10.139.131.244:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons5  10.139.131.245:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
{code}

Save tokens to vault:
{code:java}
vault write secret/global/consul/energy-shrd-simu/bootstrap_token value=XXXX-XXX-XXXX-XXXX
vault write secret/global/consul/energy-shrd-simu/acl_replication_token value=XXXX-XXX-XXXX-XXXX
vault write secret/global/consul/energy-shrd-simu/acl_agent_token value=XXXX-XXX-XXXX-XXXX
{code}

9.) deploy consul instances 
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K -k


[root@simucons1.srv.energy ~]# consul members
Node                       Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-simu-cons1     10.139.131.241:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons2     10.139.131.242:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons3     10.139.131.243:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons4     10.139.131.244:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons5     10.139.131.245:8301  alive   server  1.8.6+ent  2         energy-shrd-simu  <all>
m7t-shrd-simu-consul-dbr1  10.139.134.221:8301  alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-dbr2  10.139.134.222:8301  alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb1  10.139.58.176:8301   alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb2  10.139.58.175:8301   alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb3  10.139.58.174:8301   alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb4  10.139.58.173:8301   alive   client  1.8.6+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
{code}



","08/Dec/20 11:03;cs687;10.) resume cluster maintenance mode
change bootstrap token:
{code:java}
ansible all -m shell -a 'sed -i ""s/e43039e8-c03a-529d-9a7e-9d36cd4fda61/0bee408b-408e-522e-ae37-b51dc9d6b296/g"" /etc/patroni_enshrdebsmasync/config.yml'  --limit 'm7*-elts*simu*async*' -b -K -k
{code}

restart patroni service:
{code:java}
ansible all -m shell -a 'systemctl restart patroni_enshrdebsmasync.service'  --limit 'm7*-elts*simu*async*' -b -K -k
{code}

resume the maintenance mode:
{code:java}
patronictl -c /etc/patroni_enshrdebsmasync/config.yml resume
Success: cluster management is resumed
[root@m7simupdb1 patroni_backup]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml list
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  5 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  5 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  5 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  5 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
{code}

and did it for all instances:
{code:java}
ansible all -m shell -a 'for i in `ls /etc/patroni_*/config.yml`;do sed -i ""s/e43039e8-c03a-529d-9a7e-9d36cd4fda61/0bee408b-408e-522e-ae37-b51dc9d6b296/g"" $i;done' --limit 'm7*-elts*simu*async*' -b -K -k

ansible all -m shell -a 'for i in `ls /etc/ |grep patroni_`;do systemctl restart $i;done' --limit 'm7*-elts*simu*async*' -b -K -k

for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume; done
{code}



","08/Dec/20 11:42;cs687;11.) rollback patroni service file 
{code:java}
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStartPre/ExecStartPre/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/#ExecStopPost/ExecStopPost/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'for i in `ls /usr/lib/systemd/system/patroni_*`;do sed -i ""s/KillMode=process/KillMode=control-group/g"" $i; done' --limit 'm7*-elts*simu*async*' -b -K
ansible all -m shell -a 'systemctl daemon-reload' --limit 'm7*-elts*simu*async*' -b -K
{code}

and redeploy replica-hosts, pointing still to the old ip-address
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+   
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |   
+------------------+------------+----------------------+--------+---------+----+-----------+   
| m7thupxasimasync | m7simudbr1 | 10.136.161.121:24018 |        | running |  6 |         0 |   
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018  | Leader | running |  6 |         0 |   
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018  |        | running |  6 |         0 |   
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018  |        | running |  6 |         0 |   
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018  |        | running |  6 |         0 |   
+------------------+------------+----------------------+--------+---------+----+-----------+   
{code}
","08/Dec/20 11:56;cs687;12.) bring up the interface again and add as a workaround two static routes on hosts m7simudbr1/2
{code:java}
[root@m7simudbr1 network-scripts]# ifup eth1    
#dbr1:
ip route add 10.139.54.216/32 via 10.136.161.1
[root@m7shrdebsm1 ~]# telnet 10.136.161.121 24004      
Trying 10.136.161.121...                               
Connected to 10.136.161.121.                           
Escape character is '^]'.                              
^CConnection closed by foreign host.                   
   
#dbr2:
ip route add 10.139.54.216/32 via 10.136.33.1
[root@m7shrdebsm1 ~]# telnet 10.136.33.123 24004     
Trying 10.136.33.123...                              
Connected to 10.136.33.123.                          
Escape character is '^]'.                            
^CConnection closed by foreign host.                 
{code}


FYI: [~dp007]

","08/Dec/20 12:01;cs687;done. 
PROD planned on monday/tuesday next week. 
Ticket will be created by [~hw120] and we will make a WALKTHROUGH meeting. ","08/Dec/20 13:02;hw120; - Deployed OS monitoring on new simucons[1-5].srv.energy hosts

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1503/console]

 - Updated certificate monitoring config

[https://github.deutsche-boerse.de/dev/energy.automation.certificate/commit/9b78fa6c3ad269f6ff3f530e425b170dfa305d60]

 - Run certificate monitoring update jenkins job

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Scheduled-tasks/job/Certificate%20info%20update/240/console]

 - Checking if cert table is updated

[https://github.deutsche-boerse.de/pages/dev/energy.automation.certificate/#sort=expiry&order=asc]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pentest finding - Info Disclosure Header ,XP-4207,103856,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,pd122,ei349,ei349,03/Dec/20 12:41,11/Dec/20 09:38,22/Feb/21 13:26,11/Dec/20 09:38,,,3.1.5,,,,,,31/Dec/20 00:00,TechOps,,,,"Some information in email headers seems unnecessary:
 * internal IP addresses (e.g., 10.136.140.250)
 * mail server name (Postfix)
 * mail sender software in Message-ID (JavaMail.tomcat)
 * spam-filtering software (bounces of inbound messages)

This problem is for outgoing messages from M7T and M7C (e.g., password reset), and also for inbound messages bounces (M7C).

*Pen test report references:*

Security assessment report of M7 EPEX V7 (6.1)
Security assessment report of M7C V17 (6.1.2)
Security assessment report of the M7 ICS XML file import using email V4 (5.2)",,ei349,pd122,,,,,,,,,,,,,,,,,,,XP-2486,M7P-5556,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6307200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4088,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c6kw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/20 12:56;pd122;Change to be made to both XBID production mail servers:
{code:java}
[pd122@enprodauto1 {master L | ✔} ~/Sources/energy-app-mail]$ ansible-playbook postfix.yml -e cluster=xb --check --diff  --ask-pass --ask-become-pass
.
.
.
TASK [postfix : update header checks] ***************************************************************************************************************************************************************************************************************************************************************************************
--- before: /etc/postfix/header_checks
+++ after: /home/pd122/Sources/energy-app-mail/roles/postfix/files/header_checks
@@ -494,3 +494,9 @@
 # Yorktown Heights, NY 10598, USA
 #
 # HEADER_CHECKS(5)
+
+# removes IP address and MTA from ""Received"" header
+/(.*) \[[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\](.*) \(Postfix\) (.*)/ REPLACE ${1}${2} ${3}
+
+# removes app server from ""Message-ID"" header (replaces with ""energy"")
+/(.*)tomcat(.*)/ REPLACE ${1}energy${2}
.
.
.{code}","11/Dec/20 09:38;pd122;Actioned on 8/12/202, no issues reported since.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve telegraf deployment to handle empty tomcat context,XP-4204,103824,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,02/Dec/20 14:18,08/Dec/20 12:55,22/Feb/21 13:26,02/Dec/20 15:05,,,,,,,,,,Monitoring,TechOps,,,"When telegraf_tomcats variable is specified with empty context: """", we are getting extra / in health_check.sh script.

We can fix it similarly as for jolokia where it is handled correctly.

 

We got this request from M7A team.",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6998400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hzc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/20 15:04;hw120;Investigated that we can't easily modify it in case of context variable is missing. Telegraf template needs this variable for tomcat tag and it would break grafana templating.

To modify health_status.sh script to make it work, we would have to switch from bash positional arguments to flags and add if/else conditions.","02/Dec/20 15:05;hw120;Right now it is not needed, there is no case where it would be needed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PoC cleanup of ecp database ,XP-4201,103778,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,cs687,cs687,01/Dec/20 15:26,08/Dec/20 13:03,22/Feb/21 13:26,02/Dec/20 11:02,,,,,,,,,02/Dec/20 00:00,Database,ECP,xbid_ops,,"Unicorn came back to us with some introductions to cleanup the ecp database. 
For that we will test it on the systemtest3 ecp-database ""xbinteecp1 25508""

Plan looks like that:
{code:java}
Unicorn needs to provide DBAG a list of tables that need to be persisted.
•	The following tables will be dumped and restored:
•	event
•	auditlog
•	auth_token
•	messaging_component
•	certificate
•	failover_lock
•	registrations
•	component_info
•	ecp_configuration
•	private_key
•	node
•	endpoint
•	certificate_record
•	connection_validation
•	unreachable_component
•	sent_message_register
•	ds_content_version
•	registration_request
•	information_message
•	certificate_authority
•	gateway
•	control_ecp
Exact steps to be followed by DBAG staff during the maintenance.
•	Prepare new schema with the same structure and empty tables
o	installation script for the database can be found in the ECP installation (ECP_Linux_3.0.6_BUILD-346.zip), notes attached. We are not allowed to send you the scripts, because we are not the owner of the software.
•	Dump the tables that have to be persisted (above)
•	Find timeframe where all outgoing messages are processed, stop ECP Endpoint
•	Reconfigure ECP Endpoint to the new database
•	Start ECP Endpoint and wait for all tables to be created and ECP Endpoint correctly launched
•	Stop ECP  Endpoint again
•	Restore the dump
•	Start ECP Endpoint
{code}

*We have till tomorrow 02.12.2020 EOD to provide Impact analysis and maintenance details*

From Dev side [~qo794] will participate from xbops [~yn731], [~hw120] and [~cs687]",,cs687,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,all the steps and changes are described in the comment and in the confluence page https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=29932832,,,,,,,,,,,,,,7084800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hz",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/20 16:22;qo794;Use *xbsyt3ecp* database schema for the test, I've configured a regular file sending in CMI on syt3 every minute","01/Dec/20 16:51;cs687;1.) *database table backup from original database and backup of the whole database specially when it goes to production*:
{code:java}
# backup proper tables 
pg_dump --port=25508 -d xbsyt3ecp -n xbsyt3ecp -t event -t auditlog -t auth_token -t messaging_component -t certificate -t failover_lock -t registrations -t component_info -t ecp_configuration -t private_key -t node -t endpoint -t certificate_record -t connection_validation -t unreachable_component -t sent_message_register -t ts_content_version -t registration_request -t information_message -t certificate_authority -t gateway -t control_ecp -a | gzip > /tmpppas/02122020/xbsyt3ecp_data.sql.gz

# backup the whole database-schema
pg_dump --port=25508 -d xbsyt3ecp -n xbsyt3ecp | gzip > /tmpppas/02122020/xbsyt3ecp.sql.gz
{code}

2.) *Find timeframe where all outgoing messages are processed and stop ECP Endpoints on hosts xbsyt3ecp1 & xbsyt3ecp2 by executing these scripts as tomcat user*
{code:java}
/xbid/ECPPackage-TSO1/batches/shutdown_tomcat.sh
/xbid/ECPPackage-TSO1/batches/shutdown_tomcat.sh
{code}

* *check if the database connections of user ""uapp01xbsyt3ecp"" are gone*
{code:java}
-bash-4.1$ psql -p 25508
psql (12.4)
Type ""help"" for help.

postgres=# \c xbsyt3ecp
You are now connected to database ""xbsyt3ecp"" as user ""postgres"".
xbsyt3ecp=# select * from pg_stat_activity;
{code}

* *Rename old database*
{code:java}
ALTER DATABASE xbsyt3ecp RENAME TO xbsyt3ecp_backup;
{code}

* *Create new Database with the original name by executing the DB-Shell Scripts in /var/lib/pgsql_syt3ecp_25508/ADMIN/INSTALL as postgres user*
{code:java}
./010_CREATE_DATABASE.sh
./020_CREATE_SCHEMA.sh
./030_ALTER_ROLE.sh
./034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sh
{code}

* *list the database schemas afterwards if everything has the proper shape*
{code:java}
-bash-4.1$ psql -p 25508
psql (12.4)
Type ""help"" for help.

postgres=# \l
                                       List of databases
       Name       |   Owner   | Encoding | Collate |    Ctype    |      Access privileges
------------------+-----------+----------+---------+-------------+-----------------------------
 xbsyt3ecp        | xbsyt3ecp | UTF8     | C       | en_US.UTF-8 | =Tc/xbsyt3ecp              +
                  |           |          |         |             | xbsyt3ecp=CTc/xbsyt3ecp    +
                  |           |          |         |             | uapp01xbsyt3ecp=c/xbsyt3ecp+
                  |           |          |         |             | udev01xbsyt3ecp=c/xbsyt3ecp+
                  |           |          |         |             | umon01xbsyt3ecp=c/xbsyt3ecp
 xbsyt3ecp_backup | xbsyt3ecp | UTF8     | C       | en_US.UTF-8 | xbsyt3ecp=CTc/xbsyt3ecp    +
                  |           |          |         |             | =Tc/xbsyt3ecp              +
                  |           |          |         |             | uapp01xbsyt3ecp=c/xbsyt3ecp+
                  |           |          |         |             | udev01xbsyt3ecp=c/xbsyt3ecp+
                  |           |          |         |             | umon01xbsyt3ecp=c/xbsyt3ecp
{code}

* *Before starting up Endpoint we have to execute the install.sql script*
We need to copy the script from one of the ECP Endpoint hosts to the database host located in  
*/xbid/ECPPackage-TSO1/db-sql/sql/PostgreSql/install.sql* and rename the variable in file @USER@ to our uapp-database user 
{code:java}
:%s/@USER@/uapp01xbsyt3ecp/g
{code}

{code:java}
# execute the script
postgres=# \c xbsyt3ecp
You are now connected to database ""xbsyt3ecp"" as user ""postgres"".
xbsyt3ecp=# \i /tmp/install.sql
{code}

* *Start the ECP Endpoints again as tomcat user*
{code:java}
xbsyt3ecp1:/xbid/ECPPackage-TSO1/batches/startup_tomcat.sh
xbsyt3ecp2:/xbid/ECPPackage-TSO1/batches/startup_tomcat.sh
{code}

4.) *Wait until all tables are created and ECP Endpoint is correctly launched, check for that UI, once everything is prepared stop ECP Endpoint again as tomcat user*

UI for production:
* http://xbprodecp1:8080/ECP_MODULE_XBID/ADMIN/monitoringPage.seam?cid=2
* http://xbprodecp2:8080/ECP_MODULE_XBID/ADMIN/monitoringPage.seam?cid=2
{code:java}
/xbid/ECPPackage-TSO1/batches/shutdown_tomcat.sh
/xbid/ECPPackage-TSO1/batches/shutdown_tomcat.sh
{code}

5.) *Restore the tables-backup as postgres user which were saved before and check table message afterwards:*
{code:java}
for i in ecp; do zcat /tmpppas/02122020/xbsyt3${i}_data.sql.gz | /usr/pgsql-12/bin/psql -p 25508 -d xbsyt3${i}; done
{code}

* *{color:red}Table message must be empty!{color}*
{code:java}
xbsyt3ecp=# select * from message;    
{code}

6.) *Start ECP Endpoint as tomcat user again:*
{code:java}
/xbid/ECPPackage-TSO1/batches/startup_tomcat.sh
/xbid/ECPPackage-TSO1/batches/startup_tomcat.sh
{code}

7.) *Once everything is save, we can drop the old database:*
{code:java}
DROP DATABASE xbsyt3ecp_backup;
{code}","02/Dec/20 06:50;qo794;The ecp db installation script for our syt3 end-point is this one /xbid/ECPPackage-TSO1/db-sql/sql/PostgreSql/install.sql, but {{@USER@}} must be replaced by {{uapp01xbsyt3ecp}}. Or there is also a bash script for a database creation {{/xbid/ECPPackage-TSO1/db-sql/build-PostgreSql-db-tso1.sh}} which creates an application user, cleans an existing database if needed and creates a new one.","02/Dec/20 11:02;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DC switchover Jenkins job to be amended for Ansible (Devops),XP-4200,103742,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,tm431,tm431,01/Dec/20 08:32,07/Dec/20 15:37,22/Feb/21 13:26,07/Dec/20 15:37,,,,,,,,,,DEVOPS,TechOps,,,"In order to test Failovers on SYT1,3 we need to amend following job
 [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-DC-Switchover/]

Exit criteria: JOB works and can start Rabbits and all components in other DC.

Feel free to add DEVs for this task, if rights will be granted to them.

Next step would be to amend the SIMU DC switchover job

 

Complexity: 
 * TOs = 3 
 * Devs = 3 (including new ansible Rabbitmq role which is already in place)",,cs687,ek176,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"all is working fine.
changed the job to use the proper rabbitmq and haproxy playbook
and also deleted the old perl part and replaced it with ansible.  ",,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i0000000000000009",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,see comments. ,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/20 13:27;tm431;Grant DEVs rights for that job.","02/Dec/20 14:01;cs687;like we discussed in the meeting Failover 3.1 Kick-off, we (@oliver.heinsohn and me) going to check the 
jenkins job https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-DC-Switchover/ related to ticket XP-4200

we figured out already during the DRT, we saw that the job is using the global/common rabbitmq playbook and is failing with AnsibleUndefinedVariable 

playbook which is currently used in the job,
{code:java}
ansible-playbook playbooks/deploy_rabbitmq_instances.yml --limit ""${rabbitInstancesAcive}:&*-syt*"" --tags deploy
{code}

{code:java}
AnsibleUndefinedVariable: 'PORT_CUST_DIGIT' is undefined

failed: [xb-xbid-syt1-int-amq4] (item={'source': '3.5.x/rabbitmq-env.conf.j2', 'target': 'rabbitmq-env.conf'}) => {
    ""changed"": false,
    ""item"": {
        ""source"": ""3.5.x/rabbitmq-env.conf.j2"",
        ""target"": ""rabbitmq-env.conf""
    }
}
{code}

we would recommend to change all ansible commands to the new rabbitmq role playbooks/deploy_xbrabbitmq-instance.yml and test the job on systemtest1. Who can participate form dev-side

the same for HAProxy we have to use the new role ""xbhaproxy"" as well
instead of
{code:java}
ansible-playbook playbooks/deploy_haproxy.yml --limit ""xb-xbid-${environment}-*haprox*"" --tags stop
{code}
","04/Dec/20 16:36;cs687;changed the job ""XBID-DC-Switchover"" for Systemtest1 and ran it to switch to DC2

[root@xbsyt1cor2 xbid-syt1-cor2]# curl http://localhost:60708/m7core/health/m7
{""status"":""UP"",""details"":{""master"":true}}[root@xbsyt1cor2 xbid-syt1-cor2]#

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-DC-Switchover/

basically what we are doing:
* stopping cor, enq, cmm, cmi, smc, smi, rep, ctp, amq, haproxy and ecp
* deploy, start the rabbitmq cluster of the DC where we want to switch
* deploy, start haproxy´s
* start instances in specific DC
* start the rest","07/Dec/20 08:05;cs687;these playbooks will be triggered:
{code:java}
# stop all instances 
ansible-playbook playbooks/deploy_xbcor.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbenq.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbcmm.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbcmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbsmc.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbsmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbrep.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbctp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbecp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
{code}

{code:java}
# stop all instances 
ansible-playbook playbooks/deploy_xbcor.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbenq.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbcmm.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbcmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbsmc.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbsmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbrep.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbctp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
ansible-playbook playbooks/deploy_xbecp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags stop
{code}

{code:java}
# stop haproxy instances
ansible-playbook playbooks/deploy_xbhaproxy.yml --limit ""xb-xbid-${environment}-*haprox*"" --tags stop
{code}

{code:java}
# set parameters
if [ ${switchTo} -eq 2 ]
then
	export rabbitInstancesAcive=""xb-xbid-${environment}-*mq2:xb-xbid-${environment}-*mq4:xb-xbid-${environment}-*mq6""
	export rabbitInstancesMaster=""xb-xbid-${environment}-*mq2""
	export rabbitInstancesRest=""xb-xbid-${environment}-*mq4:xb-xbid-${environment}-*mq6""
    export tomcatStartFirst=2
    export tomcatStartSecond=1
    export AMQP_SERVERS_EXT=""{{ AMQP_SERVERS_EXT_DC2 }}""
    export AMQP_SERVERS_INT=""{{ AMQP_SERVERS_INT_DC2 }}""
else
	export rabbitInstancesAcive=""xb-xbid-${environment}-*mq1:xb-xbid-${environment}-*mq3:xb-xbid-${environment}-*mq5""
	export rabbitInstancesMaster=""xb-xbid-${environment}-*mq1""
	export rabbitInstancesRest=""xb-xbid-${environment}-*mq3:xb-xbid-${environment}-*mq5""
    export tomcatStartFirst=1
    export tomcatStartSecond=2
    export AMQP_SERVERS_EXT=""{{ AMQP_SERVERS_EXT_DC1 }}""
    export AMQP_SERVERS_INT=""{{ AMQP_SERVERS_INT_DC1 }}""
fi

# deploy and start secondary rabbitmq cluster
ansible-playbook playbooks/deploy_xbrabbitmq-instance.yml --limit ""${rabbitInstancesAcive}:&*-syt*"" --tags deploy
ansible-playbook playbooks/deploy_xbrabbitmq-instance.yml --limit ""${rabbitInstancesMaster}:&*-syt*"" --tags start
ansible-playbook playbooks/deploy_xbrabbitmq-instance.yml --limit ""${rabbitInstancesRest}:&*-syt*"" --tags start
{code}

{code:java}
# set parameters
if [ ${switchTo} -eq 2 ]
then
	export rabbitInstancesAcive=""xb-xbid-${environment}-*mq2:xb-xbid-${environment}-*mq4:xb-xbid-${environment}-*mq6""
	export rabbitInstancesMaster=""xb-xbid-${environment}-*mq2""
	export rabbitInstancesRest=""xb-xbid-${environment}-*mq4:xb-xbid-${environment}-*mq6""
    export tomcatStartFirst=2
    export tomcatStartSecond=1
    export AMQP_SERVERS_EXT=""{{ AMQP_SERVERS_EXT_DC2 }}""
    export AMQP_SERVERS_INT=""{{ AMQP_SERVERS_INT_DC2 }}""
else
	export rabbitInstancesAcive=""xb-xbid-${environment}-*mq1:xb-xbid-${environment}-*mq3:xb-xbid-${environment}-*mq5""
	export rabbitInstancesMaster=""xb-xbid-${environment}-*mq1""
	export rabbitInstancesRest=""xb-xbid-${environment}-*mq3:xb-xbid-${environment}-*mq5""
    export tomcatStartFirst=1
    export tomcatStartSecond=2
    export AMQP_SERVERS_EXT=""{{ AMQP_SERVERS_EXT_DC1 }}""
    export AMQP_SERVERS_INT=""{{ AMQP_SERVERS_INT_DC1 }}""
fi

# deploy and start haproxy cluster with modified backends
# AMQP_SERVERS_EXT: ""{{ AMQP_SERVERS_EXT_DC2 }}""
# AMQP_SERVERS_INT: ""{{ AMQP_SERVERS_INT_DC2 }}""
ansible-playbook playbooks/deploy_xbhaproxy.yml --limit ""xb-xbid-${environment}-*haprox*"" --tags deploy,start -e ""AMQP_SERVERS_EXT=${AMQP_SERVERS_EXT}"" -e ""AMQP_SERVERS_INT=${AMQP_SERVERS_INT}""
{code}

{code:java}
# start instances on the switched DC
ansible-playbook playbooks/deploy_xbcor.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbenq.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbcmm.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbcmi.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbsmc.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbsmi.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbrep.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbctp.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbecp.yml --limit ""*${switchTo}"" --inventory xb/xbid/${environment} --tags start
{code}

{code:java}
# start instances of other DC
ansible-playbook playbooks/deploy_xbcor.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbenq.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbcmm.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbcmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbsmc.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbsmi.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbrep.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbctp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
ansible-playbook playbooks/deploy_xbecp.yml --limit '~.*' --inventory xb/xbid/${environment} --tags start
{code}

","07/Dec/20 15:37;cs687;closing the ticket and create a new one, to proper improve the job handled by [~eh941]
https://dbg-devops.slack.com/archives/C65N02RMW/p1607339961071900",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SOB - Delivery Area Management - View - validation message improvement,XP-4198,103724,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,hj444,hj444,hj444,30/Nov/20 15:46,18/Dec/20 15:26,22/Feb/21 13:26,18/Dec/20 15:26,,,,,,,,,,,,,,"# Login into SOB Ref data admin
# Navigate at Delivery Area management 
*DO not select Any DA*
# Click View btn
_Expected : Please select Delivery Area/DA,..._
_Actual : Please select a tso !_
 
Validation message improvement for DA selection.

tested Docker : Version R3.2.3-SNAPSHOT (Build 8b45901ff11ee3267b96c14811a0b3c81242bbb7)",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/20 16:22;hj444;ValidationMessage_DA_selectTSO.png;https://jira.deutsche-boerse.com/secure/attachment/90701/ValidationMessage_DA_selectTSO.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5616000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c927:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade,XP-4277-develop-sonar-test,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,develop,XP-2400,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Dec/20 15:25;hj444;Tested : Docker: Version R3.2.4-SNAPSHOT-9c2b34b0f61e6227533606e3b5a2fcd16b2c7c72
Validation message : Please select a Delivery Area from the list!
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide list of all expiring certificates in 2021,XP-4197,103717,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ei349,ei349,30/Nov/20 15:28,29/Jan/21 16:46,22/Feb/21 13:26,03/Dec/20 16:15,,,3.1.x,,,,,,31/Dec/20 00:00,BizOps,TechOps,,,"h1. {color:#00875a}Certificates maintenance overview 2021{color}
h2. Current Situation 

There is a monitoring of expiring certificates in place. 
 * [https://github.deutsche-boerse.de/pages/dev/energy.automation.certificate/#sort=expiry&order=asc&details=true]

There might be still some certificates which are not covered in this list and expiring next year. 

We don't have that many releases or deployments on XBID and it would be good to prepare a plan to renew them all at once or via planned batches. 

There is also a list of XBID related certificates here: 
 * https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Certificates+overview

h2. Proposed Solution 

Discuss among all parties involved in certificates usage and management (dev, ops, syseng) and provide list of all *expiring certificates in 2021* with detailed information. 
h2. Acceptance Criteria
 * list of all expiring certificates in 2021 which affect XBID in any way. 
 * each row contains date of expiration 
 * each row contains impact assessment
 ** if downtime is needed or we have seamless renewal
 ** customer impact in general ",,cs687,ei349,iv732,yy377,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/20 12:39;cs687;xbid_exp_certs_2021.txt;https://jira.deutsche-boerse.com/secure/attachment/90715/xbid_exp_certs_2021.txt",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/20 13:06;yy377;* Check the time for reminder (how long ahead it will inform us)","02/Dec/20 12:39;cs687;I triggered with [~iv732] the following Job 
*Project Expired Server Certs check*

and changed in the bash-script the following to provide the proper output:
* alertTime=""-400 days""
* for env in xb; do

and comment out this part to avoid alarmtilt notifications!
{code:java}
if test -f ""/tmp/global_expiration-report.txt""; then
  cat ""/tmp/global_expiration-report.txt"" | mailx -s ""The following certificate(s) will be expired soon. Please request new ones asap!"" niklas.albers@deutsche-boerse.com 7tops@deutsche-boerse.com peter.pruchnerovic@deutsche-boerse.com boris.gabel@deutsche-boerse.com  tuan.nguyen@deutsche-boerse.com

fi
if test -f ""/tmp/expiration-report.txt""; then
  cat ""/tmp/expiration-report.txt"" | mailx -s ""The following certificate(s) will be expired soon. Please request new ones asap!"" -- tuan.nguyen@deutsche-boerse.com
  while IFS= read -r line
  do
      cn=$(cut -d';' -f1 <<<$line)
	  exp=$(cut -d';' -f2 <<<$line)
	  path=$(cut -d';' -f3 <<<$line)
      product=$(cut -d'/' -f2 <<<$path)
      customer=$(cut -d'/' -f3 <<<$path)
      env=$(cut -d'/' -f4 <<<$path)
      JSON_STRING='{""message"":""This cert will expire soon: '$cn'"", ""details"":{""EXPDATE"":""'$exp'"",""PRODUCT"":""'$product'"",""CUS"":""'$customer'"",""ENV"":""'$env'""}}'
      curl -X POST -H ""Content-Type: application/json"" -H ""Authorization: GenieKey 44f2ae42-d89a-4978-8aff-4af71eed0398"" --data ""$JSON_STRING"" https://api.eu.opsgenie.com/v2/alerts
  done < ""/tmp/expiration-report.txt""
fi
{code}
","02/Dec/20 12:39;cs687;[~iv732] please double-check. thanks","02/Dec/20 15:02;iv732;According to the list, we only have some expired certs for system test or perf, and some SMIME certs for ctpx and simu. 
The client cert and wildcard cert are still valid until 2022. All good!
   ","03/Dec/20 15:47;iv732;The list after removing the system test and perf environments:
{code:java}
 --- SMIME cert ---

CN=xbctpa-cmi/emailAddress=xbctpa-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:19:26 2021 GMT
CN=xbctpa-cor/emailAddress=xbctpa-cor@xbid-test.deutsche-boerse.com;Jul 12 15:19:00 2021 GMT
CN=xbctpa-spm/emailAddress=xbctpa-spm@xbid-test.deutsche-boerse.com;Jul 12 15:19:14 2021 GMT
CN=xbctpb-cmi/emailAddress=xbctpb-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:20:06 2021 GMT
CN=xbctpb-cor/emailAddress=xbctpb-cor@xbid-test.deutsche-boerse.com;Jul 12 15:19:40 2021 GMT
CN=xbctpb-spm/emailAddress=xbctpb-spm@xbid-test.deutsche-boerse.com;Jul 12 15:19:52 2021 GMT
CN=xbctpc-cmi/emailAddress=xbctpc-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:20:44 2021 GMT
CN=xbctpc-cor/emailAddress=xbctpc-cor@xbid-test.deutsche-boerse.com;Jul 12 15:20:18 2021 GMT
CN=xbctpc-spm/emailAddress=xbctpc-spm@xbid-test.deutsche-boerse.com;Jul 12 15:20:30 2021 GMT
CN=xbctpd-cmi/emailAddress=xbctpd-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:21:22 2021 GMT
CN=xbctpd-cor/emailAddress=xbctpd-cor@xbid-test.deutsche-boerse.com;Jul 12 15:20:56 2021 GMT
CN=xbctpd-spm/emailAddress=xbctpd-spm@xbid-test.deutsche-boerse.com;Jul 12 15:21:10 2021 GMT
CN=xbctpe-cmi/emailAddress=xbctpe-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:22:02 2021 GMT
CN=xbctpe-cor/emailAddress=xbctpe-cor@xbid-test.deutsche-boerse.com;Jul 12 15:21:36 2021 GMT
CN=xbctpe-spm/emailAddress=xbctpe-spm@xbid-test.deutsche-boerse.com;Jul 12 15:21:48 2021 GMT
CN=xbctpf-cmi/emailAddress=xbctpf-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:22:40 2021 GMT
CN=xbctpf-cor/emailAddress=xbctpf-cor@xbid-test.deutsche-boerse.com;Jul 12 15:22:14 2021 GMT
CN=xbctpf-spm/emailAddress=xbctpf-spm@xbid-test.deutsche-boerse.com;Jul 12 15:22:26 2021 GMT
CN=xbctpg-cmi/emailAddress=xbctpg-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:23:18 2021 GMT
CN=xbctpg-cor/emailAddress=xbctpg-cor@xbid-test.deutsche-boerse.com;Jul 12 15:22:52 2021 GMT
CN=xbctpg-spm/emailAddress=xbctpg-spm@xbid-test.deutsche-boerse.com;Jul 12 15:23:06 2021 GMT
CN=xbctph-cmi/emailAddress=xbctph-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:23:56 2021 GMT
CN=xbctph-cor/emailAddress=xbctph-cor@xbid-test.deutsche-boerse.com;Jul 12 15:23:30 2021 GMT
CN=xbctph-spm/emailAddress=xbctph-spm@xbid-test.deutsche-boerse.com;Jul 12 15:23:44 2021 GMT
CN=xbctpi-cmi/emailAddress=xbctpi-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:24:36 2021 GMT
CN=xbctpi-cor/emailAddress=xbctpi-cor@xbid-test.deutsche-boerse.com;Jul 12 15:24:10 2021 GMT
CN=xbctpi-spm/emailAddress=xbctpi-spm@xbid-test.deutsche-boerse.com;Jul 12 15:24:22 2021 GMT
CN=xbctpj-cmi/emailAddress=xbctpj-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:25:14 2021 GMT
CN=xbctpj-cor/emailAddress=xbctpj-cor@xbid-test.deutsche-boerse.com;Jul 12 15:24:48 2021 GMT
CN=xbctpj-spm/emailAddress=xbctpj-spm@xbid-test.deutsche-boerse.com;Jul 12 15:25:00 2021 GMT
CN=xbctso-cmi/emailAddress=xbctso-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:18:09 2021 GMT
CN=xbctso-cor/emailAddress=xbctso-cor@xbid-test.deutsche-boerse.com;Jul 12 15:17:44 2021 GMT
CN=xbctso-spm/emailAddress=xbctso-spm@xbid-test.deutsche-boerse.com;Jul 12 15:17:56 2021 GMT
CN=xbcute-cmi/emailAddress=xbcute-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:18:48 2021 GMT
CN=xbcute-cor/emailAddress=xbcute-cor@xbid-test.deutsche-boerse.com;Jul 12 15:18:22 2021 GMT
CN=xbcute-spm/emailAddress=xbcute-spm@xbid-test.deutsche-boerse.com;Jul 12 15:18:36 2021 GMT
CN=xblipa-cmi/emailAddress=xblipa-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:25:52 2021 GMT
CN=xblipa-cor/emailAddress=xblipa-cor@xbid-test.deutsche-boerse.com;Jul 12 15:25:26 2021 GMT
CN=xblipa-spm/emailAddress=xblipa-spm@xbid-test.deutsche-boerse.com;Jul 12 15:25:38 2021 GMT
CN=xblipb-cmi/emailAddress=xblipb-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:26:30 2021 GMT
CN=xblipb-cor/emailAddress=xblipb-cor@xbid-test.deutsche-boerse.com;Jul 12 15:26:04 2021 GMT
CN=xblipb-spm/emailAddress=xblipb-spm@xbid-test.deutsche-boerse.com;Jul 12 15:26:18 2021 GMT
CN=xbsimu-cmi/emailAddress=xbsimu-cmi@xbid-test.deutsche-boerse.com;Jul 12 15:27:10 2021 GMT
CN=xbsimu-cor/emailAddress=xbsimu-cor@xbid-test.deutsche-boerse.com;Jul 12 15:26:44 2021 GMT
CN=xbsimu-spm/emailAddress=xbsimu-spm@xbid-test.deutsche-boerse.com;Jul 12 15:26:56 2021 GMT

--- SSL Cert ---
CN=dst.xbid.m7.deutsche-boerse.com;Feb 11 23:59:59 2021 GMT

--- Consul cert ---

CN=server.xb-xbid-simu.consul;Apr  2 09:15:45 2021 GMT{code}","08/Dec/20 13:10;ei349;CN=server.xb-xbid-simu.consul;Apr 2 09:15:45 2021 GMT

will not be updated as new Consul should be in place and it's certificate validity should be 10 years. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible: Perform dry runs on LIP A ,XP-4176,103534,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,25/Nov/20 15:09,08/Dec/20 10:34,22/Feb/21 13:26,08/Dec/20 10:34,,,3.1.5,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7603200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analytical Platform - evaluate InfluxDB ,XP-4174,103527,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,25/Nov/20 13:31,08/Dec/20 14:21,22/Feb/21 13:26,08/Dec/20 14:21,,,,,,,,,,,,,,"Try out locally in Docker:
 * load events
 * try Influx Data Explorer for data exploration/analytical queries",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,XP-4173,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w3:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/20 16:22;ll664;h1. InfluxDB

Below are the main points discovered during the evaluating. I assumed we want to store structured data as in drafted epic, i.e. we'd like to model 1:n relationship somehow.

* no SQL-like query lang, just Flux (scripting)
* very powerful and comprehensive standard library - contains tons of analytical functions - https://docs.influxdata.com/influxdb/v2.0/query-data/flux/
* data model built around fields (actual metrics - count/time etc.) and tags - labels that describe data - order type, username etc. - https://docs.influxdata.com/influxdb/v2.0/reference/key-concepts/
* storing eventId as a tag would not make sense as tags due to its uniquenes - see series cardinality - https://docs.influxdata.com/influxdb/v2.0/write-data/best-practices/resolve-high-cardinality/ - but how to built secondary indexes and do effective joins?
* cannot really store structures - the way around is to create separate metrics, but only joining option is then {{_time}} key only - but this might be good enough if we look at aggreates i.e. per minute/hour
* browser based data explorer comes with syntax highlighting/intellisense, but still feels weird (might be just personal preference)
* comes with couple of visualization types - this is sufficient as our primary use case in not to build dashboards
* heavily convention based - `_time`, `_value` columns has special meaning for visualization/default function parameters etc.
* data visualizations perform their own transformations - not explicitly stated anywhere
* dockerized version somehow slow - both queries/ingestion (125 points/sec)

h2. Flux examples

h3. Event counts per time window

{code}
from(bucket: ""xbid"")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r[""_measurement""] == ""events"")
  |> filter(fn: (r) => r[""_field""] == ""core_service_time"")
  |> group(columns: [""_field""])
  |> aggregateWindow(every: 10m, fn: count, createEmpty: false)
  |> yield(name: ""count"")
{code}


h3. Event counts per time window, per order type

{code}
from(bucket: ""xbid"")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r[""_measurement""] == ""events"")
  |> filter(fn: (r) => r[""_field""] == ""core_service_time"")
  |> group(columns: [""_field""])
  |> aggregateWindow(every: 10m, fn: count, createEmpty: false)
  |> yield(name: ""count"")
{code}

h3. Mean time per order type

{code}
from(bucket: ""xbid"")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r[""_measurement""] == ""events"")
  |> filter(fn: (r) => r[""_field""] == ""core_service_time"" or r[""_field""] == ""persister_time"")
  |> filter(fn: (r) => r[""type""] != ""OTHER"")
  |> group(columns: [""_field"", ""type""])
  |> aggregateWindow(every: 5s, fn: mean, createEmpty: false)
  |> yield(name: ""mean"")
{code}

h3. Percentiles counts per time window, per order type

{code}
q90 = from(bucket: ""xbid"")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r[""_measurement""] == ""events"")
  |> group(columns: [""_field"", ""type""])
  |> toFloat()
  |> quantile(q: 0.9)
  |> rename(columns: {_value: ""q90""})
  |> drop(columns: [""_start"", ""_stop""])

q95 = from(bucket: ""xbid"")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r[""_measurement""] == ""events"")
  |> group(columns: [""_field"", ""type""])
  |> toFloat()
  |> quantile(q: 0.95)
  |> rename(columns: {_value: ""q95""})
  |> drop(columns: [""_start"", ""_stop""])

join(
   tables: {d1: q90, d2: q95},
  on: [""_field"", ""type""]
)
{code}


","07/Dec/20 16:29;ll664;h1. TimescaleDB

I also had a bit of time to look at https://www.timescale.com/, which is an Postgres extensions for timeseries data.

* solves insert performace-degrade with growing amount of data
* timescale considers themselves as more performant than Influx (might be biased)  - https://blog.timescale.com/blog/timescaledb-vs-influxdb-for-time-series-data-timescale-influx-sql-nosql-36489299877/
* SQL - joins, secondary indexes
* postgres builtin analytical features are somehow worse compared to Inlfux
* query performance with millions on records questionable, but with enough memory should be fine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analytical Platform - evaluate Elastic ,XP-4173,103526,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,ll664,25/Nov/20 13:30,08/Dec/20 12:39,22/Feb/21 13:26,08/Dec/20 12:39,,,,,,,,,,,,,,"Try out locally in Docker:
 * load events
 * try Kibana for data exploration/analytical queries",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/20 13:10;qo794;Screenshot_20201207_130149.png;https://jira.deutsche-boerse.com/secure/attachment/90847/Screenshot_20201207_130149.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6652800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/20 09:05;ll664;I recommend Elastic Cloud - see 'Try it yourself' section in [https://www.elastic.co/what-is/elasticsearch-business-analytics]

as the Kibana/Elastic we have is not the latest one.

 

I've already setup a 14 day trial, works out-of-the box with some predefined datasets, but we can also push our own data there.

 ","26/Nov/20 14:51;qo794;Kibana Platinum features can also be activated on Docker Kibana, it also provides sample data importing, working fine on local machine.","07/Dec/20 13:12;qo794;h2. Evaluation outcome
 * supports percentiles calculation out of the box [https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-percentile-aggregation.html]
 * easy to visualize percentiles via tables
  !Screenshot_20201207_130149.png! 
 * scripted fields for creating additional fields on the fly based on existing fields [https://www.elastic.co/guide/en/kibana/current/scripted-fields.html]
 * nested field data type for fields containing array of objects [https://www.elastic.co/guide/en/elasticsearch/reference/7.6/nested.html]
 * querying over nested fields [https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html]
 * nested queries supported directly in KQL in Kibana UI [https://www.elastic.co/guide/en/kibana/7.6/kuery-query.html#kuery-query-nested-field]
 * aggregation of nested fields [https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-nested-aggregation.html]
 * nanoseconds supported https://www.elastic.co/guide/en/elasticsearch/reference/current/date_nanos.html
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) CMI - retrying to send file doesn't work if EcpSender fails due to missing V-Code - testing,XP-4170,103522,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ll664,od044,25/Nov/20 12:41,26/Nov/20 11:53,22/Feb/21 13:26,26/Nov/20 11:53,,,3.1.x,,,,,,,,,,,"If an attempt to send file via Ecp fails because there's no V-Code, the subsequent retry and notification event fails on precondition. It expect the file to be in DB, which is not the case.

{code}
2020-11-17T17:25:00.113Z [executor-7][][] ERROR c.d.e.c.t.FileSenderProxy - Failed to send file ExportFileDescriptor{fileHeaderId=43842467, requireAcknowledgement=true} File: 20201118_ATC_EE-FI_196.xml (SENT, ECP, com.deutscheboerse
.energy.cmminteg.filetype.cim.ATC) for 11XNPSPOT-ELBASW
com.deutscheboerse.energy.cmminteg.api.transport.TransportException: TSO 11XNPSPOT-ELBASW does not have defined the V-code
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.getReceiverCode(EcpHandler.java:167)
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.sendFile(EcpHandler.java:148)
        at sun.reflect.GeneratedMethodAccessor349.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
        at com.sun.proxy.$Proxy171.sendFile(Unknown Source)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.sendFile(FileSenderProxy.java:63)
        at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper$HandlerMethod.invoke(MessagingMethodInvokerHelper.java:1102)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.invokeHandlerMethod(MessagingMethodInvokerHelper.java:581)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:477)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:355)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:108)
        at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:95)
        at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:127)
        at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:177)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:224)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.access$000(BroadcastingDispatcher.java:56)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher$1.run(BroadcastingDispatcher.java:204)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor.lambda$execute$0(ErrorHandlingTaskExecutor.java:57)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
2020-11-17T17:25:00.118Z [executor-7][][] ERROR o.s.i.h.LoggingHandler - org.springframework.messaging.MessageHandlingException: error occurred during processing message in 'MethodInvokingMessageProcessor' [org.springframework.integration.handler.MethodInvokingMessageProcessor@19ee2d4c]; nested exception is java.lang.IllegalStateException, failedMessage=GenericMessage [payload=ExportFileDescriptor{fileHeaderId=43842467, requireAcknowledgement=true} File: 20201118_ATC_EE-FI_196.xml (SENT, ECP, com.deutscheboerse.energy.cmminteg.filetype.cim.ATC) for 11XNPSPOT-ELBASW, headers={id=3d51805a-7791-1f61-1cdb-0ddc641dadcf, timestamp=1605633900110}]
        at org.springframework.integration.support.utils.IntegrationUtils.wrapInHandlingExceptionIfNecessary(IntegrationUtils.java:191)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:111)
        at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:95)
        at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:127)
        at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:177)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:224)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.access$000(BroadcastingDispatcher.java:56)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher$1.run(BroadcastingDispatcher.java:204)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor.lambda$execute$0(ErrorHandlingTaskExecutor.java:57)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException
        at com.google.common.base.Preconditions.checkState(Preconditions.java:492)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.notifyTransportFailed(FileSenderProxy.java:87)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.retryAndNotifyTransportFailure(FileSenderProxy.java:78)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.sendFile(FileSenderProxy.java:67)
        at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper$HandlerMethod.invoke(MessagingMethodInvokerHelper.java:1102)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.invokeHandlerMethod(MessagingMethodInvokerHelper.java:581)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:477)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:355)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:108)
        ... 10 more
{code}

- fix : we can just add warning when this occurs and ignore it. ",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7603200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i00000000000006",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/20 11:53;od044;Test passed on docker R3.2.2-SNAPSHOT (Build 12b0288eb1cd0e67476a6ad182824bef1918609a)
- WARN messages are logged 
{code}
2020-11-26T10:25:00.054Z [executor-1][][] WARN  c.d.e.c.t.e.EcpHandler - Sending of file ExportFileDescriptor{fileHeaderId=9, requireAcknowledgement=true} File: 20201126_TAR_ES-PT_003.xml (SENT, ECP, 
com.deutscheboerse.energy.cmminteg.filetype.cim.TAR) for TS-TSO1--------0 skipped, no ECP V-code defined for [TS-TSO1--------0]
2020-11-26T10:25:00.134Z [executor-3][][] WARN  c.d.e.c.t.s.SftpHandler - Sending of file ExportFileDescriptor{fileHeaderId=12, requireAcknowledgement=true} File: 20201126_NetPI_10YPT-REN------W_003.xml (SENT, SFTP, com.deutscheboerse.energy.cmminteg.filetype.cim.NetPI) for TS-TSO1--------0 skipped, no SFTP user defined for [TS-TSO1--------0]
2020-11-26T10:25:00.116Z [executor-1][][] WARN  c.d.e.c.t.s.ScpHandler - Sending of file ExportFileDescriptor{fileHeaderId=11, requireAcknowledgement=true} File: 20201126_NSF_ES-PT_003.xml (SENT, SCP, com.deutscheboerse.energy.cmminteg.filetype.cim.NSF) for TS-TSO2--------R skipped, no SCP host defined for [TS-TSO2--------R]
{code}

StR 
1. Configure outbound file with receivers which do not have configured SFTP, SCP, V-Code of ECP and their distribution schedules
2. Check a CMI log - WARN messages are logged, no retry attempts occur 
3. Configure SFTP and SCP and V-Code for those receivers
4. Check that files are sent",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test and implement jenkins selfservice alerting change to allow slack alerts for test/cute/prod,XP-4168,103489,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,24/Nov/20 14:32,25/Nov/20 09:39,22/Feb/21 13:26,25/Nov/20 09:39,,,,,,,,,,jenkins,Monitoring,TechOps,," 
 * We need to update all jenkins selfhealing jobs to be able send xbid alerts to new slack channels

 

Consulted with Roman about jenkins selfhealing alerts:

think i set them up here: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Selfhealing/]
 the actual slack might be sent in the end by some script that is executed via ansible
 at least it corresponds to this folder structure: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/jenkins/selfhealing]
 the second one in the end is here: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/rabbitmq_instance/templates/prodscripts/rabbitmq/rabbitmq_include#L86]
 yes and the first one directly from jenkins: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/selfhealing/Jenkinsfile_slave-slave#L46]
 probably you could also just search github for the error text... i think in an ideal world, you will find the exact point of implementation....",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2892,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4dk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Nov/20 09:39;hw120;It seems that both jenkins self-healing jobs are used only for M7, closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Collect consul monitoring metrics,XP-4165,103483,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,24/Nov/20 13:23,17/Feb/21 09:59,22/Feb/21 13:26,17/Feb/21 09:58,,,,,,,,,,Consul,Monitoring,TechOps,,"Story
 * We are missing monitoring of consul service instances
 * We need to pick metrics we want to collect from this service

Definition of Done
 * Having in influxdb all necessary metrics related to this service
 * Deployed telegraf to all environments which are running consul service

Acceptance criteria
 * consul Metrics are being collected from all environments where consul service is running

Documentation:

[https://learn.hashicorp.com/tutorials/consul/monitor-datacenter-health]

[https://learn.hashicorp.com/tutorials/consul/monitor-health-telegraf]

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2764800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000003",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/21 13:50;hw120;Modified telegraf templates and deployed on all new test, simu and prod consul clusters. Now we are collecting all the consul metrics.

Looking for Grafana/Chronograf dashboard we can use, but most of them are designed for prometheus datasource, so we might need to create one from scratch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID PROD ECP performance problems investigation,XP-4161,103447,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,23/Nov/20 13:55,23/Nov/20 13:56,22/Feb/21 13:26,23/Nov/20 13:56,,,,,,,,,,TechOps,,,,"* Investigate resource usage of ecp db and app hosts
 * Organize increase of memory on xprodedb1 server and reconfiguration of postgres instance
 * Redeploy ecp instance with increased Xmx config
 * Provide information for unicorn support related to ecp database
 * Call with unicorn
 * Provide them files and config they requested",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7776000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c44g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Request access to energy internal systems from new Azure Citrix Virtual Desktops,XP-4159,103437,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,23/Nov/20 11:33,30/Dec/20 15:30,22/Feb/21 13:26,30/Dec/20 14:37,,,,,,,,,,Citrix,TechOps,,,"Azure VDIs are a replacement for old VMware based Citrix VDIs, as those are being decommissioned by the end of the year. We have new options to have Ubuntu/CentOS/Windows in RDEV network or Windows in OA network, all running in Azure cloud.

 

Because Citrix VDI is my primary remote desktop for work and FW requests can take up to 30 days to implement, I have to request access till the end of November, so they have time to implement it by the end of the year.

 

I made a list of all internal tools/services we are using in Energy.

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Energy+internal+tools+and+services]

Now I have to test if they are accessible from new Citrix Azure VDIs and request access for those we can get it.

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4579200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hu",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,Xbops Sprint 23,Xbops Sprint 24,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Nov/20 20:41;hw120;Created all needed FW requests.

[https://jiradbg.deutsche-boerse.de/browse/DEVENV-39?focusedCommentId=951668&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-951668]
FW requests:
506516
506551
506552
 ","30/Nov/20 21:27;hw120;Created ticket to fix CyberArk access from Citrix Azure Windows OA [https://jiradbg.deutsche-boerse.de/browse/DEVENV-53]","30/Dec/20 14:37;hw120;Urged CCI team to implement them before the end of the year, when old Citrix VDIs will be decommissioned. Requests already breached 30days SLA.
They done it day after.
Tested and all seems to be fine, one exception is access to https://artifactory.dbgcloud.io/ and CyberArk from Azure Windows OA.
I will escalate it through project manager Zeina.","30/Dec/20 15:29;hw120;Created FW request for access to artifactory from OA network.
FW request 506815",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test and implement kapacitor handlers change to allow slack alerts for test/cute/prod,XP-4158,103435,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,23/Nov/20 11:13,24/Nov/20 12:08,22/Feb/21 13:26,24/Nov/20 12:08,,,,,,,,,,Monitoring,TechOps,,,,,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2892,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7776000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c428:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Nov/20 12:08;hw120;More info in linked ticked, just to log my work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) Security tests run automatically - DEADLINE 31.12.2020,XP-4157,103407,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,20/Nov/20 17:08,20/Nov/20 17:09,22/Feb/21 13:26,20/Nov/20 17:09,,,,,,,,,,,,,,"We have no security test cases. These should be run automatically, see XP-2987

Tests to be used: Cucumber GUI tests

Security tool: OWASP ZAProxy/BUrpSuit in headless mode

AC: 
 * Security tests run automatically",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Split burn,,,,,,,,,,,,,,8035200,,,,,,,,,,,,,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i0000000000000r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix NPE in ResourceManagement,XP-4155,103405,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ek176,ek176,20/Nov/20 16:45,11/Dec/20 10:50,22/Feb/21 13:26,11/Dec/20 10:50,,,,,Other,,,,,,,,,"Fix the NPE in com.deutscheboerse.energy.resourcemanagement.resource.ResourceInterceptor.postStateChange(ResourceInterceptor.java:48

Log (SOB):
{noformat}
2020-09-27T12:11:11.805Z [ost-startStop-1][][] WARN  o.s.s.s.AbstractStateMachine - Interceptors threw exception in post state change2020-09-27T12:11:11.805Z [ost-startStop-1][][] WARN  o.s.s.s.AbstractStateMachine - Interceptors threw exception in post state changejava.lang.NullPointerException: null at com.deutscheboerse.energy.resourcemanagement.resource.ResourceInterceptor.postStateChange(ResourceInterceptor.java:48) at org.springframework.statemachine.support.StateMachineInterceptorList.postStateChange(StateMachineInterceptorList.java:120) at org.springframework.statemachine.support.AbstractStateMachine.callPostStateChangeInterceptors(AbstractStateMachine.java:890) at org.springframework.statemachine.support.AbstractStateMachine.entryToState(AbstractStateMachine.java:1273) at org.springframework.statemachine.support.AbstractStateMachine.entryToState(AbstractStateMachine.java:1263) at org.springframework.statemachine.support.AbstractStateMachine.setCurrentStateInternal(AbstractStateMachine.java:1059) at org.springframework.statemachine.support.AbstractStateMachine.setCurrentState(AbstractStateMachine.java:1033) at org.springframework.statemachine.support.AbstractStateMachine.switchToState(AbstractStateMachine.java:926) at org.springframework.statemachine.support.AbstractStateMachine.access$500(AbstractStateMachine.java:82) at org.springframework.statemachine.support.AbstractStateMachine$3.transit(AbstractStateMachine.java:334) at org.springframework.statemachine.support.DefaultStateMachineExecutor.handleInitialTrans(DefaultStateMachineExecutor.java:302) at org.springframework.statemachine.support.DefaultStateMachineExecutor.processTriggerQueue(DefaultStateMachineExecutor.java:398) at org.springframework.statemachine.support.DefaultStateMachineExecutor.access$200(DefaultStateMachineExecutor.java:64) at org.springframework.statemachine.support.DefaultStateMachineExecutor$1.run(DefaultStateMachineExecutor.java:330) at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) at org.springframework.statemachine.support.DefaultStateMachineExecutor.scheduleEventQueueProcessing(DefaultStateMachineExecutor.java:353) at org.springframework.statemachine.support.DefaultStateMachineExecutor.execute(DefaultStateMachineExecutor.java:162) at org.springframework.statemachine.support.DefaultStateMachineExecutor.doStart(DefaultStateMachineExecutor.java:174) at org.springframework.statemachine.support.LifecycleObjectSupport.start(LifecycleObjectSupport.java:120) at org.springframework.statemachine.support.AbstractStateMachine.doStart(AbstractStateMachine.java:418) at org.springframework.statemachine.support.LifecycleObjectSupport.start(LifecycleObjectSupport.java:120) at com.deutscheboerse.energy.resourcemanagement.rabbit.RabbitResource.start(RabbitResource.java:71) at com.google.common.collect.ImmutableList.forEach(ImmutableList.java:405) at com.deutscheboerse.energy.resourcemanagement.resource.manager.ResourceManager.start(ResourceManager.java:56) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.context.event.ApplicationListenerMethodAdapter.doInvoke(ApplicationListenerMethodAdapter.java:261) at org.springframework.context.event.ApplicationListenerMethodAdapter.processEvent(ApplicationListenerMethodAdapter.java:179) at org.springframework.context.event.ApplicationListenerMethodAdapter.onApplicationEvent(ApplicationListenerMethodAdapter.java:142) at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:402) at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:359) at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:896) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552) at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:401) at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:292){noformat}",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w3:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),Alpha Sprint 24,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,XP-4250-develop,develop,XP-2400,master,XP-4250-metrics-integration-test-2,XP-4155-resourcemanagment-upgrade,XP-4250-metrics-integration-test,XP-2478-tobago-upgrade,XP-4277-develop-sonar-test,XP-4211-perf-analysis-develop,XP-4155-npe-fix,XP-4211-perf-analysis-develop-jh,XP-4250-develop-jh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Dec/20 14:16;ek176;Found the NPE in logs when investigating XP-3845",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMI should fetch files from ECP one by one (fetch-process-acknowledge),XP-4150,103394,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,jy268,jy268,20/Nov/20 14:41,06/Jan/21 09:56,22/Feb/21 13:26,06/Jan/21 09:56,,,3.1.x,,CMM,,,,,Tech-Debt,,,,"Currently CMI uses old deprecated methods for fetching files from ECP resulting in downloading all files as a list and then processing them. In details it downloads files one by one and add them to the list, when download of one file fails, whole list is rejected. It results in another download attempt during next ECP files check. Another approach should be used, which is currently implemented in SMI:
1. download file
2. process file
3. acknowledge file
It can be achieved by using ConfirmAfterProcessingEcpMessageReceiver interface in commons-transport.",,hj444,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4306,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w3:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),Alpha Sprint 24,Alpha Christmas Sprint (S),,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Dec/20 12:57;hj444;ECP - actually not possible to test. Communication going on with Unicorn. 
Status : Waiting","05/Jan/21 16:06;hj444;Actual date 5.1.2021
SYT3 : Version R3.2.3 (Build f8ed207ffd3066b56f11d298d662e63e4fbe80f9)
APG TSO endpoint for ECP set.
CMI - Inbound - Outbound files created with Sender/Receiver APG TSO, and ECP
DE-AT,PT-ES, FR-DE
File configurations valid from 6.1.2021. Test continue 6.1.","06/Jan/21 09:54;hj444;Issue split into:
|XP-4306|(Split 1) CMI should fetch files from ECP one by one (fetch-process-acknowledge)|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) CMI - retrying to send file doesn't work if EcpSender fails due to missing V-Code,XP-4139,103322,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ll664,ll664,19/Nov/20 09:15,25/Nov/20 14:00,22/Feb/21 13:26,25/Nov/20 14:00,,,3.1.x,,,,,,,,,,,"If an attempt to send file via Ecp fails because there's no V-Code, the subsequent retry and notification event fails on precondition. It expect the file to be in DB, which is not the case.

{code}
2020-11-17T17:25:00.113Z [executor-7][][] ERROR c.d.e.c.t.FileSenderProxy - Failed to send file ExportFileDescriptor{fileHeaderId=43842467, requireAcknowledgement=true} File: 20201118_ATC_EE-FI_196.xml (SENT, ECP, com.deutscheboerse
.energy.cmminteg.filetype.cim.ATC) for 11XNPSPOT-ELBASW
com.deutscheboerse.energy.cmminteg.api.transport.TransportException: TSO 11XNPSPOT-ELBASW does not have defined the V-code
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.getReceiverCode(EcpHandler.java:167)
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.sendFile(EcpHandler.java:148)
        at sun.reflect.GeneratedMethodAccessor349.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
        at com.sun.proxy.$Proxy171.sendFile(Unknown Source)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.sendFile(FileSenderProxy.java:63)
        at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper$HandlerMethod.invoke(MessagingMethodInvokerHelper.java:1102)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.invokeHandlerMethod(MessagingMethodInvokerHelper.java:581)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:477)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:355)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:108)
        at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:95)
        at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:127)
        at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:177)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:224)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.access$000(BroadcastingDispatcher.java:56)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher$1.run(BroadcastingDispatcher.java:204)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor.lambda$execute$0(ErrorHandlingTaskExecutor.java:57)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
2020-11-17T17:25:00.118Z [executor-7][][] ERROR o.s.i.h.LoggingHandler - org.springframework.messaging.MessageHandlingException: error occurred during processing message in 'MethodInvokingMessageProcessor' [org.springframework.integration.handler.MethodInvokingMessageProcessor@19ee2d4c]; nested exception is java.lang.IllegalStateException, failedMessage=GenericMessage [payload=ExportFileDescriptor{fileHeaderId=43842467, requireAcknowledgement=true} File: 20201118_ATC_EE-FI_196.xml (SENT, ECP, com.deutscheboerse.energy.cmminteg.filetype.cim.ATC) for 11XNPSPOT-ELBASW, headers={id=3d51805a-7791-1f61-1cdb-0ddc641dadcf, timestamp=1605633900110}]
        at org.springframework.integration.support.utils.IntegrationUtils.wrapInHandlingExceptionIfNecessary(IntegrationUtils.java:191)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:111)
        at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:95)
        at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:127)
        at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:177)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:224)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher.access$000(BroadcastingDispatcher.java:56)
        at org.springframework.integration.dispatcher.BroadcastingDispatcher$1.run(BroadcastingDispatcher.java:204)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor.lambda$execute$0(ErrorHandlingTaskExecutor.java:57)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalStateException
        at com.google.common.base.Preconditions.checkState(Preconditions.java:492)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.notifyTransportFailed(FileSenderProxy.java:87)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.retryAndNotifyTransportFailure(FileSenderProxy.java:78)
        at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.sendFile(FileSenderProxy.java:67)
        at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
        at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper$HandlerMethod.invoke(MessagingMethodInvokerHelper.java:1102)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.invokeHandlerMethod(MessagingMethodInvokerHelper.java:581)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:477)
        at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:355)
        at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:108)
        ... 10 more
{code}

- fix : we can just add warning when this occurs and ignore it. ",,ei349,ll664,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,XP-4170,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,19/Nov/20 09:15,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i00000000000002",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-4152-acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Nov/20 15:22;ei349;Hint: 

- we can just add warning when this occurs and ignore it. ","23/Nov/20 14:17;qo794;When a channel for a receiver is not properly configured, file sending is skipped and a warning is written into a log file:
* sftp - no sftp user in a database - already implemented (/)
* scp - no scp host in a database
* ecp - no V-code defined","24/Nov/20 13:13;qo794;Implemented in develop and acceptance branch","25/Nov/20 12:41;od044;Issue split into:
|XP-4170|(Split 2) CMI - retrying to send file doesn't work if EcpSender fails due to missing V-Code - testing|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide proper ssh key for pmi_archiver sftp user ,XP-4137,103251,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,od044,od044,18/Nov/20 12:35,24/Nov/20 16:07,22/Feb/21 13:26,24/Nov/20 16:07,,,,,,,,,,TechOps,,,,"SSH key id_rsa_sftp does not work for user pmi_archiver.

Please provide and upload new ssh key for pmi_archiver user to access SFTP server:
- xbintecbn1 
- xbintecbn2 

Issue: 
Cannot connect to sftp with the actual ssh key:
{code}
sftp -v  -i id_rsa_sftp -P 40300 pmi_archiver@xbintecbn1
debug1: SSH2_MSG_SERVICE_ACCEPT received
debug1: Authentications that can continue: password,publickey
debug1: Next authentication method: publickey
debug1: Trying private key: id_rsa_sftp
debug1: Authentications that can continue: password,publickey
debug1: Next authentication method: password
pmi_archiver@xbintecbn1's password:
{code}
Verified on pmi host xbintepmi1
",,cs687,od044,,,,,,,,,,,,,,,,,,,XP-3566,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"added the proper key to vault and redeployed 
*xb/xbid/test/sftp/id_rsa_sftp*",,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c2yw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/20 12:02;cs687;Updated vault with the proper key - used ""id_ras_pmi""
{code:java}
[root@xbintepmi1 xbid-syt1-pmi-archiver1]# ls -all /home/pmi/key/
total 28
-rw-------  1 pmi pmi 1675 Mar 28  2018 id_rsa_pmi
{code}

*xb/xbid/test/sftp/id_rsa_sftp* and saved the old one as a backup with the name *value_old_241120*

merged pull-request to fix the sftp users:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2399/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1244/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1246/files

Working again!
{code:java}
[root@xbintepmi1 xbid-syt1-pmi-archiver1]# sftp -P 40300 -i /xbid/xbid-syt1-pmi-archiver1/config/id_rsa_sftp pmi_archiver@xbintecbn1
Connected to xbintecbn1.
sftp>
{code}
","24/Nov/20 16:07;cs687;cronjob were executed successfully! Ticket can be closed. 

tested with xb-xbid-syt1-pmi-archiver
{code:java}
'/xbid/logs/xbid-syt1-pmi-logger1/internal-archived-messages'.                                                                                                                                                                    [1820/1820]
2020-11-24 15:05:13.274  INFO 10136 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : Uploading file '/xbid/logs/xbid-syt1-pmi-logger1/archived-messages/SOBPMI_log_20200705T160000_1500-1600.log.gz' to SFTP.
2020-11-24 15:05:13.279  INFO 10136 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : Moving file '/xbid/logs/xbid-syt1-pmi-logger1/archived-messages/SOBPMI_log_20200705T160000_1500-1600.log.gz' to internal archive directory
'/xbid/logs/xbid-syt1-pmi-logger1/internal-archived-messages'.
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve commons-transport MultiNodeWsTemplate to log which ECP node is used,XP-4135,103243,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,jy268,jy268,18/Nov/20 10:43,24/Nov/20 09:35,22/Feb/21 13:26,24/Nov/20 09:35,,,3.1.x,,CMM,Shipping,,,,Tech-Debt,,,,"Currently ECP toggling works that way:
{code}
boolean usePrimary = usePrimaryTemplate.get();
        try {
            WebServiceOperations template = usePrimary ? primaryTemplate : secondaryTemplate;
            return templateAction.executeOnTemplate(template);
        } catch (WebServiceClientException e) {
            usePrimaryTemplate.compareAndSet(usePrimary, !usePrimary);
            WebServiceOperations template = usePrimary ? secondaryTemplate : primaryTemplate;
            LOG.error(""Action failed on primary WS node."", e);
            LOG.info(""Trying secondary node"");
            T result = templateAction.executeOnTemplate(template);
            LOG.info(""Attempt on secondary WS node successful"");
            return result;
        }
{code}

which flips primary with secondary node, during runtime, from logs, we don't know which node is used exactly as after failure secondary becomes primary etc. It should log ECP address or something which lets us identify which node was used.",,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8294400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c3vg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AMR net position collector failing,XP-4134,103233,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qo794,qo794,qo794,18/Nov/20 09:09,18/Nov/20 11:01,22/Feb/21 13:26,18/Nov/20 11:01,,,,,AM Indicators Reporting,,,,,,,,,"{{am-collect-net-positions}} is failing, log from simu:
{code:java}
2020-11-18T01:00:07.677Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [extract-and-load-net-positions]
2020-11-18T01:00:07.678Z [h-jobs-thread-1][][] INFO  c.d.e.x.a.c.IntervalLoggingListener - Importing data from '2020-10-13T00:00:00Z' to '2020-11-18T00:00:00Z'
2020-11-18T01:00:07.725Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step extract-and-load-net-positions in job am-collect-net-positions
org.springframework.dao.DuplicateKeyException: PreparedStatementCallback; SQL [INSERT INTO am_net_position
                                    (delivery_start_date, delivery_end_date, area, import, export, canonical_time_duration)
                                    VALUES (?, ?, ?, ?, ?, ?)]; ERROR: duplicate key value violates unique constraint ""am_net_position_delivery_start_end_date_area_duration_key""
  Detail: Key (delivery_start_date, delivery_end_date, area, canonical_time_duration)=(2020-10-13 15:00:00, 2020-10-13 16:00:00, 10Y1001A1001A82H, PT15M) already exists.; nested exception is org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""am_net_position_delivery_start_end_date_area_duration_key""
  Detail: Key (delivery_start_date, delivery_end_date, area, canonical_time_duration)=(2020-10-13 15:00:00, 2020-10-13 16:00:00, 10Y1001A1001A82H, PT15M) already exists.
        at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:247)
        at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
        at org.springframework.jdbc.core.JdbcTemplate.translateException(JdbcTemplate.java:1443)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:633)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:647)
        at org.springframework.jdbc.core.JdbcTemplate.batchUpdate(JdbcTemplate.java:936)
        at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.batchUpdate(NamedParameterJdbcTemplate.java:366)
        at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.batchUpdate(NamedParameterJdbcTemplate.java:354)
        at org.springframework.batch.item.database.JdbcBatchItemWriter.write(JdbcBatchItemWriter.java:175)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.writeItems(SimpleChunkProcessor.java:193)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.doWrite(SimpleChunkProcessor.java:159)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.write(SimpleChunkProcessor.java:294)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.process(SimpleChunkProcessor.java:217)
        at org.springframework.batch.core.step.item.ChunkOrientedTasklet.execute(ChunkOrientedTasklet.java:77)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:145)
        at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:258)
        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:208)
        at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
        at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:68)
        at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:68)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:169)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)
        at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:137)
        at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:319)
        at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:147)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""am_net_position_delivery_start_end_date_area_duration_key""
  Detail: Key (delivery_start_date, delivery_end_date, area, canonical_time_duration)=(2020-10-13 15:00:00, 2020-10-13 16:00:00, 10Y1001A1001A82H, PT15M) already exists.
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2532)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2267)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:510)
        at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:851)
        at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:874)
        at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1563)
        at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
        at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
        at org.springframework.jdbc.core.JdbcTemplate.lambda$batchUpdate$2(JdbcTemplate.java:950)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:617)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:647)
        at org.springframework.jdbc.core.JdbcTemplate.batchUpdate(JdbcTemplate.java:936)
        at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.batchUpdate(NamedParameterJdbcTemplate.java:366)
        at org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.batchUpdate(NamedParameterJdbcTemplate.java:354)
        at org.springframework.batch.item.database.JdbcBatchItemWriter.write(JdbcBatchItemWriter.java:175)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.writeItems(SimpleChunkProcessor.java:193)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.doWrite(SimpleChunkProcessor.java:159)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.write(SimpleChunkProcessor.java:294)
        at org.springframework.batch.core.step.item.SimpleChunkProcessor.process(SimpleChunkProcessor.java:217)
        at org.springframework.batch.core.step.item.ChunkOrientedTasklet.execute(ChunkOrientedTasklet.java:77)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:145)
        at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:258)
        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:208)
        at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
        at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:68)
        at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:68)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:169)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)
        at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:137)
        at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:319)
        at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:147)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
2020-11-18T01:00:07.726Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [extract-and-load-net-positions] executed in 49ms
2020-11-18T01:00:07.729Z [h-jobs-thread-1][][] INFO  o.s.b.c.l.s.SimpleJobLauncher - Job: [FlowJob: [name=am-collect-net-positions]] completed with the following parameters: [{RUN_TIME=1605661207645, YEAR=2020, MONTH=NOVEMBER}] and the following status: [FAILED] in 70ms
{code}",,qo794,,,,,,,,,,";18/Nov/20 11:01;qo794;7200",,,,7200,,,,7200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8294400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c2uw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Nov/20 10:48;qo794;h3. Root cause
Missing key (canonical_time_duration) in an sql data collect query when joining import and export data into one table.","18/Nov/20 10:48;qo794;Fixed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add access to xbsimurts1 and xbsimurts2,XP-4133,103174,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cv179,od044,od044,16/Nov/20 11:07,28/Jan/21 08:44,22/Feb/21 13:26,28/Jan/21 08:44,,,,,,,,,,TechOps,,,,"Please add access to
 - xbsimurts1
 - xbsimurts2

for users:
 - od044 (Manh Duc Nguyen)
 - rx089 (Alexandr Radecky)
 - tr866 (Tomas Bendasek)
 - hj444 (Janette Novysedlakova)
 - mg726 (Sona Fornbaumova)

Reason
 To execute performance against SIMU",,cv179,dm700,ei349,od044,wm282,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2160000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c2i8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Nov/20 13:48;ei349;Contacted [~wm282] about this question. 
> Hi Andrei, can you please estimate how long it will take to some of syseng people to perform such a change and if it's even possible? https://jira.deutsche-boerse.com/browse/XP-4133","24/Nov/20 14:07;ei349;[~od044] please define what ""access"" means. What level of permissions you need?","24/Nov/20 14:51;od044;Hi, [~ei349] [~wm282]

Access meant to able to connect to the host with our credentials and switch to tomcat user. Permission should be read / write. ","25/Nov/20 08:26;wm282;These hosts are part of XBID SIMU environment.

Access to SIMU (and PROD) hosts is always possible via the so-called ""self-service"" Jenkins job that gives temporary access.

Are you aware of that?","25/Nov/20 11:41;od044;[~wm282] I am aware of that, just we don't know that host is part of SIMU env. I thought it was the host that was whitelisted to access to SIMU env, because we could access it in past without the any ""self-service"".

Anyway, I just try self-service, but it does not work for me, the job failed.

This access is required for performance execution, where we need to upload a new performance app and its configuration to execute performance from it. 

","25/Nov/20 11:56;wm282;> we don't know that host is part of SIMU env

really? :) so the xb*simu*rts1 does not give a hint?

can I get more details / error message / output for the failed self-service job so we can troubleshoot this?","25/Nov/20 12:14;wm282;Ok.. one step ahead of you

I've already found and checked your Jenkins job and it does look strange (this never happened before to anybody).

We made some changes now, so please try again.","25/Nov/20 16:07;wm282;Access to the hosts is working now, but we realised that the permissions to control the running services via sudo mechanism are currently not allowed.

This requires discussion how to proceed (making exceptions / making new standards / other options)","30/Nov/20 13:03;ei349;We agreed with [~wm282] that he will discuss it internally and come back to us with proposal how to achieve that. 

I confirmed that it's fine for us to have it on ""need to know basis"" where we can request the access for a limited time (in matter of days, weeks, ..) via some kind of automation (e.g. Jenkins job)","27/Jan/21 16:08;cv179;[~dm700] please approve following 2 exceptions:
 # adding mentioned users of the description to the ldap group of ""product application support"" (sudo_app_support) which allows users to switch to the application user and run interactive commands (e.g. as tomcat). This group membership will be permanent or until revocation and valid on any accessible host.
 # access to mentioned simu hosts until 19.02.2021 (so no need to trigger hours blocks in the self service for those hosts)

 ","28/Jan/21 08:22;dm700;[~dm700] approved both 2 mentioned exceptions",,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM - TSO Admin - Service/Direction HALT message in menu bar doesn't get updated,XP-4132,103172,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,hj444,tr866,tr866,16/Nov/20 10:45,09/Dec/20 11:36,22/Feb/21 13:26,09/Dec/20 11:36,,,,,CMM,,,,,,,,,"h2. Description: 
# When 2 sessions of CMM are opened and in one of the sessions Service is in HALT and then one direction is set to ALLOCATION the message in the menu bar doesn't get updated. Message should get updated in all sessions from ""SERVICE HALT"" to ""DIRECTION Halt [direction]"".
# Same problem for scenario when one direction is in HALT already and the other direction is set to HALT as well. Message should get updated from ""DIRECTION Halt [direction]"" to ""SERVICE HALT"" in all sessions.

h2. Steps to reproduce:
# Login to CMM in two independent sessions with TSO Admin rights
# Navigate to Capacity Management in both sessions
# Select an Interconnector (e.g. RTE-AMP) in both sessions
# In one session select the Service Halt panel and set service to HALT.
# Check in both sessions of CMM if the message in menu bar got updated to ""SERVICE HALT"" !screenshot-service_halt_24082-2020.11.16-10_28_11.png|height=30%,width=30%!
# In the same session select the Direction Halt panel and set on of the directions to ALLOCATION (e.g. RTE->AMP)
# Open the 2nd session of CMM and wait for couple of automatic refreshes of the GUI and check if HALT message got updated to ""DIRECTION HALT AMP->RTE""
# In 2nd session press the ""Reload"" button to get the GUI refreshed manually and check the message again
# Back in the 1st session put the direction RTE->AMP back to HALT
# IN the 2nd session of CMM and wait for couple of automatic refreshes of the GUI and check if HALT message got updated to ""SERVICE HALT""

h2. Expected result:
# When setting one of the directions to ALLOCATION while service being in HALT the message in the menu bar should be updated in all sessions to ""DIRECTION HALT AMP->RTE"" !screenshot-direction_halt_24082-2020.11.16-10_29_07.png|height=30%,width=30%!
# When one direction is in HALT already and the remaining one is set to HALT too the message in menu bar should get updated in all sessions to ""SERVICE HALT"" !screenshot-service_halt_24082-2020.11.16-10_28_11.png|height=30%,width=30%!

h2. Current behaviour:
# In the other session of CMM than the one were the direction was set to ALLOCATION the message should get updated automatically same as in the active one. The message stays in that session on ""SERVICE HALT"" till manual refresh of the screen.
# In the other session of CMM than the one where the remaining direction was set to HALT the message in menu bar should get updated automatically same as in the active one to ""SERVICE HALT"". The messages stays on ""DIRECTION HALT AMP->RTE"" till manual refresh of the screen.",,ei349,hj444,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/20 10:46;tr866;screenshot-direction_halt_24082-2020.11.16-10_29_07.png;https://jira.deutsche-boerse.com/secure/attachment/89971/screenshot-direction_halt_24082-2020.11.16-10_29_07.png","16/Nov/20 10:47;tr866;screenshot-service_halt_24082-2020.11.16-10_28_11.png;https://jira.deutsche-boerse.com/secure/attachment/89973/screenshot-service_halt_24082-2020.11.16-10_28_11.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6480000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,16/Nov/20 10:45,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,XP-4250-develop,develop,XP-2400,XP-4250-metrics-integration-test-2,master,XP-2478-tobago-upgrade,XP-4250-metrics-integration-test,XP-4277-develop-sonar-test,XP-4211-perf-analysis-develop,XP-4211-perf-analysis-develop-jh,XP-4250-develop-jh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Nov/20 11:11;tr866;This misbehaviour was noticed when testing this linked ticket.","02/Dec/20 09:52;ei349;this might be fixed by another bugfix, can you please confirm [~hj444]? ","03/Dec/20 13:25;hj444;tested docker : Version R3.2.3-SNAPSHOT (Build a64608fdf3abed1e6931d281e55de4475b755fcd)

CMM TSO Admin :
 Open 3 sessions S1, S2, S3
Scenarios:
1. Service in Allocation - no message at main menu.
		-- S1 : Direction Halt tab : Set AMP -> RTE Direction Halt
                --- Message appears : DIRECTION HALT AMP-RTE
		-- S2, S3 automatic update and Message DIRECTION HALT AMP-RTE appears
		=== OK
	(/)	
2. Actual Status Direction AMP-RTE is in halt Message is present in S1, S2, S3  : DIRECTION HALT AMP-RTE
		-- S1 in Service Halt tab set Service Halt - {color:blue}Automatic Update of message to SERVICE HALT{color}
		-- S2, S3 expected also an automatic update of message to SERVICE HALT
                            --- {color:red} Actual: Message : DIRECTION HALT AMP-RTE {color}
                            --- After waiting few minutes manual reload done and the message is updated( also changing to any tab at page (Capacity overview today, tomorrow tab, or in Administration panel switching tabs) will trigger message update)
(x)
3. Actual Status SERVICE HALT
		-- S2 set RTE-AMP Direction Allocation : {color:blue}Automatic Update of message to DIRECTION HALT AMP-RTE{color}
		-- S1, S3  expected also an automatic update of message to  DIRECTION HALT AMP-RTE
                            --- {color:red} Actual: Message :SERVICE HALT {color}
                            --- After waiting few minutes manual reload done and message is updated ( also changing to any tab at page (Capacity overview today, tomorrow tab, or in Administration panel switching tabs) will trigger message update)

(x)		
4. Actual Status : DIRECTION HALT AMP-RTE
		-- S3 - set Service to Allocation - message is updated/removed automatically, no message is present
		-- S1, S2 - automatic update and message is updated/removed automatically, no message is present
		
		== OK 
(/)","09/Dec/20 11:36;hj444;retest done Docker : 
Version R3.2.4-SNAPSHOT (Build bb571568d1ebd80863ece7861a9679a884a4da24)
SC1: (/)
SC2: (/)
SC3 : (/)
SC4: (/)

+ SC5: (/)
 Service in Allocation - no message at main menu.
– S1 : Direction Halt tab : Set AMP -> RTE Direction Halt
— Message appears  : DIRECTION HALT AMP-RTE
– S2, S3 automatic update and Message DIRECTION HALT AMP-RTE appears
=== OK
– S3 : Direction Halt tab : Set RTE-> AMP Direction Halt
— Message appears  : SERVICE HALT
– S2, S1 automatic update and Message SERVICE HALT appears
=== OK
+ SC6: (/)
 Service in Hat -  SERVICE HALT in S1, S2, S3
– S1 : Direction Allocation tab : Set AMP -> RTE Direction Allocation
— Message appears  : DIRECTION HALT RTE-AMP
– S2, S3 automatic update and Message DIRECTION HALT RTE-AMP appears
=== OK
– S3 : Direction Allocation tab : Set RTE-> AMP Direction Allocation
(Service is in Allocation)
No message is present after update
– S2, S1 automatic update and No Message is present
=== OK
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID performance - analytical platform,XP-4126,103117,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,12/Nov/20 15:29,02/Dec/20 10:06,22/Feb/21 13:26,02/Dec/20 10:06,,,,,,,,,,,,,,"We are struggling to analyse XBID performance, currently we have limited options like Grafana metrics, or raw performance logs/xbid-perfstart index in Kibana. 

Grafana unfortunately offers 30s aggregates (copuple of percentile, min/max, mean) of data - StatsD. Detailed performance profile is missing.

It turns out to be really tough to perform any analysis - typically performance data are imported to local Postgres where any slightly complex runs forever. 

Therefore we'd like to tackle the problem in more elaborate fashion. The idea is to have a 'platform' that would allows us quickly and efficiently analyse performance data.

h2. Use cases

* production incident investigation
* performance data analysis for change requests like Cross Product Matching 

h2. Data

* every XBID event is measured within every processing stage (Unmarshaller, Core Service, Persister etc.).
* currently we push those to Elastic and logfiles
* adapter need to extract-and-load from Elastic to new platform until XBID is pushing the events directly

h2. Requirements

* have ability to run complex queries on the data - compute statistics (percentiles, mean, etc.) within certain time window - from minutes to months.
* performance - should be reasonably fast
* data retention - the longer, the better - sometimes we investigate problems couple of months back
* scalability - XBID generates ~3 mil. events per day

h2. Technologies

* what datastore - Influx seems like natural choice for timeseries data
* if Influx is used, we can correlate with other metrics we have - CPU, 
* UI visualization - Grafana does not seem to be a good fit for adhoc query tool, Chronograf?
* something else?



",,ei349,ek176,hw120,ll664,qm925,radeale,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7084800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4172,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c260:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/20 22:26;hw120;Seems like perfect timing for [https://www.influxdata.com/blog/influxdb-2-0-open-source-is-generally-available/]

unfortunately, it is still not available in the Enterprise version. I expect it will be soon.

 

Also, elastic stack provides nice possibilities to work with metrics and analytics, huge benefit is that it can centralize them all - Logs, Metrics, APM, Uptime, SIEM, and machine learning - Anomaly detection & on-demand forecasting.

[https://www.elastic.co/observability]

[https://www.elastic.co/what-is/elasticsearch-business-analytics]

[https://www.elastic.co/what-is/elasticsearch-machine-learning]

 

But to use any of those for heavy analytics, it might be a good idea to consider performance impact and possibly deploy a separate stack for it.

 ","16/Nov/20 16:26;ll664;Notes from call on 16th of November, how do we move forward;

h2. Consolidate use cases

Write down use-cases and data that would enhance current metrics. Evaluate possibility to store this in the cloud from contractual perspective.

h2. Research technologies

Focus on end-user perspective - nice querying interface, graphs, vizualization etc. Performance.

Some candidates, compare:

* InfluxDB/Chronograf
* Elastic/Kibana
* cloud native tech? which one?","16/Nov/20 21:42;hw120;Cloud-native options are:
 * [https://aws.amazon.com/timestream/] - not available in Frankfurt region yet, only in Ireland
 * GCP Bigtable - can apparently be used for time-series [https://cloud.google.com/bigtable/docs/schema-design-time-series]
 * [https://docs.microsoft.com/en-us/azure/time-series-insights/time-series-insights-overview]

If we consider time-series use-case, seem like InfluxDB is the leader [https://db-engines.com/en/ranking/time+series+dbms]

 ","20/Nov/20 11:09;ll664;h2. Metrics data
h3. Current
 * username
 * request type (OrdrEntry, OrdrModify)
 * total processing time
 * wait/processing times for every stage
 * success/failure flag
 * end of batch flag for Persister/Ordebook

Logline example:
{code:java}
2020-11-20 09:33:11.888,XBEPEXX1,OrdrModify[11107587273],9,1605861191888,RMQ:1,J:[0,6],U:[0,1],V:[0,0],A:[0,0],C:[0,0(IDBC:0)],RT:[0,0],P:[0,2],R:[0,0],O:[null,null],S:[0,0],P:Y,O:N,S
{code}
h3. Enhancement
 * change precision from millis to nanos
 * unique event id for every event
 * total time spent in Persister/Orderbook even in case of not end-of-batch - currently we have typically 0 if event is not end-of-batch
 * order count within the OrdrEntry/OrdrModify event
 * contract delivery dates
 * order sides
 * matching - every match*
 ** total - start/end/duration
 ** validation - start/end/duration
 ** matching - start/end/duration
 ** routing - start/end/duration
 ** capacity constraints - unsuccessful routing attempts
 ** trades count
 ** trade flows count
 ** allocation count
 ** trade allocations count
 * auction - every round*
 ** total - start/end/duration
 ** matching - start/end/duration
 ** capacity constraints - unsuccessful routing attempts
 ** contracts count
 ** buy orders count
 ** sell orders count
 ** trades count
 ** trade flows count
 ** allocation count
 ** trade allocations count
 * orderbook
 ** time spent waiting for execution
 ** calculation time
 ** orders count
 * persister
 ** start/end/duration
 ** inserted orders/trades/trade flows/allocations count
 ** updated orders/trades/trade flows/allocations count
 ** total statements executed
 ** batch updates size (i.e. hibernate all orders)

{{*}} for matching/auction consider cardinality 1:N (metrics for every order/auction round in event) in context of target datastore - for instance for InfluxDB this is not suitable","02/Dec/20 09:58;ei349;Dear [~ll664], update the epic with gathered information from this ticket and close this one please. ","02/Dec/20 10:05;ll664;Extracted relevant info to epic XP-4172, closing this one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve performance of OrderInactivationByExpirationStrategy,XP-4125,103100,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Fixed,eg288,eh941,eh941,12/Nov/20 11:22,18/Jan/21 13:39,22/Feb/21 13:26,09/Dec/20 14:01,,,3.1.6,,,,,,,,,,,"In production it's very typical for this task to take more than 500 ms even though there are just a few records to be updated. The query can be found in {{OrderInactivationByExpirationStrategy}}

Investigate why it takes so long.

Here are links that proves that. They might be dead soon though :(

[https://kibana.energy.svc.dbgcloud.io/goto/f0489a117e7c49796c825aa3e97def4a]

[https://kibana.energy.svc.dbgcloud.io/goto/17cf80fa4a7eacc92db9234bca41db1e]

 

Check how many items are updated so we have a data for analysis. 

Optimistic scenario: 

- It will probably be some missing index (optimistic scenario)

 

Pessimistic scenario: 

- change the strategy how orders are deleted. ",,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,XP-4250-develop,develop,XP-2400,master,XP-4250-metrics-integration-test-2,master-acceptance,XP-4250-metrics-integration-test,XP-2478-tobago-upgrade,XP-4277-develop-sonar-test,acceptance,XP-4211-perf-analysis-develop,XP-4211-perf-analysis-develop-jh,XP-4152-acceptance,XP-4250-develop-jh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"04/Dec/20 18:13;eg288;Incident took place on 12. November 2020, there were 152 OrderExpirationSystemTask which took longer then 1s and many of them were close to 10s. Nowadays there is barely one OrderExpirationSystemTask breaching 1s.

Query:
{code}
explain select o.user_id, o.expiration_date, o.ex_gdt from cx_100_order o
WHERE ((o.expiration_date IS NOT NULL AND o.expiration_date <= now() at time zone 'UTC') 
OR (o.ex_gdt IS NOT NULL AND o.ex_gdt <= now() at time zone 'UTC')) 
AND o.mod_type_code IN ('ACTI', 'HIBE')
{code}

{code}
Index Scan using idx100_003 on cx_100_order o  (cost=0.56..21127.12 rows=11132 width=20)
  Index Cond: ((mod_type_code)::text = ANY ('{ACTI,HIBE}'::text[]))
  Filter: (((expiration_date IS NOT NULL) AND (expiration_date <= timezone('UTC'::text, now()))) OR ((ex_gdt IS NOT NULL) AND (ex_gdt <= timezone('UTC'::text, now()))))
{code}

grep cmd to find long running OrderExpirationSystemTask:
{code}
grep perf-sender xb_xbid_prod_cor-1_standard_ixe_* | grep OrderExpi | egrep ""P:\[[0-9]*,[0-9]{4,}""
{code}","07/Dec/20 18:20;eg288;Possible solution:

Introduce new index:
{code}
create index if not exists idx100_007
    on xbprodcor.cx_100_order (mod_type_code, expiration_date, ex_gdt);
{code}
It is not enough, the execution plan looks still the same. Index condition includes only mod_type_code and the expired orders are filtered in a separate step. This is probably due to OR condition.

A solution would be to issue 2 updates instead of one update with OR in condition. Then the index condition includes also a timestamp column.

*Query 1:*
{code}
explain analyze select * from xbprodcor.cx_100_order o
WHERE o.mod_type_code IN ('ACTI', 'HIBE') AND o.expiration_date IS NOT NULL AND o.expiration_date <= TO_TIMESTAMP('2020-12-06 22:15:00', 'YYYY-MM-DD HH24:MI:SS')
{code}
{code}
Index Scan using idx100_007 on cx_100_order o  (cost=0.56..20617.79 rows=11558 width=359) (actual time=0.049..0.130 rows=168 loops=1)
  Index Cond: (((mod_type_code)::text = ANY ('{ACTI,HIBE}'::text[])) AND (expiration_date IS NOT NULL) AND (expiration_date <= to_timestamp('2020-12-06 22:15:00'::text, 'YYYY-MM-DD HH24:MI:SS'::text)))
Planning Time: 0.161 ms
Execution Time: 0.154 ms
{code}

*Query 2:*
{code}
explain analyze select * from cx_100_order o
WHERE o.mod_type_code IN ('ACTI', 'HIBE') AND o.ex_gdt IS NOT NULL AND o.ex_gdt <= TO_TIMESTAMP('2020-12-06 22:15:00', 'YYYY-MM-DD HH24:MI:SS')
{code}
{code}
Index Scan using idx100_007 on cx_100_order o  (cost=0.56..14700.29 rows=8107 width=359) (actual time=0.063..1.867 rows=69 loops=1)
  Index Cond: (((mod_type_code)::text = ANY ('{ACTI,HIBE}'::text[])) AND (ex_gdt IS NOT NULL) AND (ex_gdt <= to_timestamp('2020-12-06 22:15:00'::text, 'YYYY-MM-DD HH24:MI:SS'::text)))
Planning Time: 0.157 ms
Execution Time: 1.897 ms
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Fork m7.profile-storage to xbid.profile-storage,XP-4116,103056,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,jy268,lt112,11/Nov/20 10:40,11/Nov/20 10:41,22/Feb/21 13:26,11/Nov/20 10:41,,,3.2.x,,ComTrader,,,,,Tech-Debt,,,,"Fork m7.profile-storage to xbid.profile-storage. Currently all builds are set for develop branch which is used by m7 project, due to that any fixes in 1.8 branch result in failing unit tests on jenkins (1.8 branch does not contain docker project which is explicitly set in mvn execution params)
 # Acceptance criteria:
 # Fork m7.profile-storage to xbid.profile-storage
 # Copy all jenkins builds related to m7.profile-storage and switch them to xbid.profile-storage
 # Check if xbid developers have access to new fork
 # Set 1.8 branch as new develop
 # Create jenkins job for releasing, because currently it has to be done manually
 # Create new HP fortify application (needs to be discussed with ESO to assign AID first, then follow https://confluence.energy.svc.dbgcloud.io/display/M7T/HP+Fortify) 
 # Create jenkins nightly pipelines (including OWASP, HP Fortify and similar)
 # Based on Sonar/HP Fortify findings, re-estimate XP-4097",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btrs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) Failover event took place message sent with the same id during startup - testing,XP-4115,103051,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,jy268,od044,11/Nov/20 10:38,11/Nov/20 13:55,22/Feb/21 13:26,11/Nov/20 13:55,,,3.2.x,,Trading,,,,,,,,,"During https://jira.deutsche-boerse.com/browse/SMXBID-2173 analysis we have found that StartupTask resulting in StartupResult does not persist entities.
{code}
    private boolean isToPersist(ResponseEvent event) {
        Result result = event.getResult();
        return !(result instanceof StartupResult) || ((StartupResult) result).isToPersist();
    }
{code}

Due to that two messages were sent with the same id.
Please analyze and fix if following field should be persisted:
{code}
private StatusMessage failoverMessage;
{code}",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8812800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btja:9i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/20 13:54;od044;Test passed on XBID 3.2.0 on SYT1 

- Failover messsages are persited 
- Smoke test passed

Step to reproduce:

1. prerquisites: have double-sided env
2. Stop cor1 
3. Stop cor2
4. Start both cor1 and cor2
5. Check pmi-message and look for message ""Failover event took place."" - error there are 2 message with the same  msgId with different timestamp

{code}
./xbid-syt1-pmi-logger1/pmi-messages.log:2020-11-11 10:17:52.070: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""16"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T10:17:52.013Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605089872060}, timestamp=Wed Nov 11 11:17:52 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=5759, messageCount=0, consumerTag=amq.ctag-Em1lGsH0xOqy8qkfFPv8Xg, consumerQueue=xbid.monitoring.1]
./xbid-syt1-pmi-logger1/pmi-messages.log:2020-11-11 10:21:28.938: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""16"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T10:21:28.855Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605090088925}, timestamp=Wed Nov 11 11:21:28 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=5835, messageCount=0, consumerTag=amq.ctag-Em1lGsH0xOqy8qkfFPv8Xg, consumerQueue=xbid.monitoring.1]


./xbid-syt1-pmi-logger5/pmi-messages.log:2020-11-11 10:17:52.070: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""16"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T10:17:52.013Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605089872060}, timestamp=Wed Nov 11 11:17:52 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=5621, messageCount=0, consumerTag=amq.ctag--9OPEqxFLJ6h8b_bjakv-g, consumerQueue=xbid.monitoring.3]
./xbid-syt1-pmi-logger5/pmi-messages.log:2020-11-11 10:21:28.938: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""16"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T10:21:28.855Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605090088925}, timestamp=Wed Nov 11 11:21:28 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=5697, messageCount=0, consumerTag=amq.ctag--9OPEqxFLJ6h8b_bjakv-g, consumerQueue=xbid.monitoring.3]
{code}

After fix
{code}
./pmi-messages.log:2020-11-11 12:23:24.003: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""6"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T12:23:23.954Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605097403998}, timestamp=Wed Nov 11 13:23:23 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=10560, messageCount=0, consumerTag=amq.ctag-Em1lGsH0xOqy8qkfFPv8Xg, consumerQueue=xbid.monitoring.1]
./pmi-messages.log:2020-11-11 12:30:33.337: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><MsgRprt xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><MsgList><Msg msgId=""9"" type=""PUBLIC"" messageCode=""146"" timestmp=""2020-11-11T12:30:33.268Z"" svrty=""HIG"" txt=""Failover event took place."" mktSupervisionMsg=""false""/></MsgList></MsgRprt>. MessageProperties [headers={x-m7-group-sequence=1, x-m7-group-id=1.public, server-timestamp=1605097833323}, timestamp=Wed Nov 11 13:30:33 CET 2020, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=MsgRprt, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.public, receivedDelay=null, deliveryTag=10738, messageCount=0, consumerTag=amq.ctag-Em1lGsH0xOqy8qkfFPv8Xg, consumerQueue=xbid.monitoring.1]
grep: ./rolled-over-dead-lettered-messages: Is a directory
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Two SFTP nodes support in pmi archiving,XP-4114,103050,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,uv683,qo794,11/Nov/20 10:22,11/Nov/20 10:22,22/Feb/21 13:26,11/Nov/20 10:22,,,3.2.x,,,,,,,,,,,"It was discovered that pmi archiving was always working only with one sftp node. This could lead to issues when given node will be down and there are two nodes. Enhance shipping module to work with multiple nodes.

See https://jira.deutsche-boerse.com/browse/XP-3552

 

Hint: 
 * there is an library used for this one. 
 * -assumption: it should require only bump of versions and update a template - Incorrect assumption, PMI archiver uses some low level library to connect to sftp, the whole sftp related code must be rewritten to use our multi node sftp class.",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btja:bi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Create separate slack channel for alerts from SYT,XP-4113,103044,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eg288,qo794,eg288,11/Nov/20 09:55,11/Nov/20 09:56,22/Feb/21 13:26,11/Nov/20 09:56,,,3.2.x,,,,,,,,,,,"Currently all alerts from non-prod environments are reported to one slack channel: {{xbid_alerts}}. This way the channel is flooded with notifications from our internal SYT envs so the customers facing env alerts can be easily missed, moreover it's hard to even monitor this channel. It would be great to report all notifications from SYT envs to a different channel, maybe also renaming the current one to be more self-explanatory (it's not clear at the first glance what alerts are reported there).",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040000604",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible deployment - improve maintainability of dev and techops full deployment pipelines,XP-4111,103022,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eg288,eg288,eg288,10/Nov/20 17:12,15/Dec/20 15:02,22/Feb/21 13:26,15/Dec/20 13:29,,,3.1.x,,,,,,,,,,,"There are two very similar jenkins pipelines to deploy full env, first for dev, second for techops they differ only in agent,s so the techops one can access also customer facing envs including prod.

https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/selfservice/Jenkinsfile_deploy_xbid_full
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/Jenkinsfile_deploy_xbid_full

Another differences is in supported envs, All the other differences should not be there.

Come up with a solution where we do not duplicate the whole pipeline, instead have the most of the pipeline code only once, so if there is any change required it does not need to be done twice.",,eg288,ll664,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5875200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:zq",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,HOT Sprint 24 (S),,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4111,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Nov/20 13:48;ll664;So, sharing common template pipeline code is not an easy task at all. Jenkins supports extracting declarative pipeline code into commons library: [https://www.jenkins.io/doc/book/pipeline/shared-libraries/#defining-declarative-pipelines]

But, the shared library has to reside in the separate git repository. For now, it cannot be a file in the same folder, which is sad. Extracting it separate git repo is quite hard bullet to bite:
 * maintenance cost - having deploy pipeline in two repos would the setup a lot more complex, outweighing the benefits of DRY/common code extraction.
 * artificial restriction - missing Jenkins feature forcing us to needlessly complex solutions
 * the shared lib config is hidden to normal user - only an Jenkins admin know from which git repo is the code loaded

I've tried different hacks people are using to overcome this (hacking with temporary git repo in local folder):
 [https://code-held.com/2020/01/22/jenkins-local-shared-library/]
 [https://stackoverflow.com/questions/46213913/load-jenkins-pipeline-shared-library-from-same-repository]

but unfortunately, it doesn't work due access rights issues.

Also, there's a demand for this by the community, but not yet implemented:
 [https://github.com/jenkinsci/workflow-cps-global-lib-plugin/pull/37]
 [https://github.com/jenkinsci/workflow-cps-global-lib-plugin/pull/40]

I've also taken a look how other projects (m7t,m7a) are doing this. They have duplications, but also extract some common functions to a separate groovy file (see [example|https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/deploy_lib_m7t.groovy]).

*I decide to give up.*

The experience with Jenkins pipelines is too frustrating, time consuming and leads nowhere.

There's also a new way of pipeline management, which looks promising and tackles those issues right from the start. We might give it a try:
 [https://www.jenkins.io/blog/2019/05/09/templating-engine/]","30/Nov/20 08:58;eg288;Possible solution:
Use built-in property $env.JOB_BASE_NAME. It returns _Energy/xbid-full-ansible-deploy_ for dev instance, while for ops instance it returns _Energy-operation/XBID Ansible Jobs/XBID Ansible deploy full_. Inside the pipeline we can test the property and based on the value populate the two variables agent and environments.

It is brittle and definitively not a best practice to change behaviour of the pipeline based on its name. Still I think it is better then to duplicate all the code in the pipeline.
All built-in properties are described [here|https://opensource.triology.de/jenkins/pipeline-syntax/globals].","15/Dec/20 13:29;eg288;*  implemented in energy.automation.deployments/jenkins/Jenkinsfile_deploy_xbid_full, 
*  the original development pipeline energy.automation.deployments/jenkins/selfservice/Jenkinsfile_deploy_xbid_full has been deleted",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Comtrader compatibility with syt2, syt3, perf, dst and docker",XP-4110,103015,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,10/Nov/20 15:55,18/Nov/20 11:07,22/Feb/21 13:26,18/Nov/20 11:07,,,3.1.4,,,,,,,,,,,"Comtrader doesn't work with  syt2, syt3, perf, dst and docker at the moment. It works for syt1. 

 

We need to update our properties and build uber package for syt2, syt3, perf, dst and docker as well. ",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/20 12:56;od044;ComTrader-localhost-xsob-docker-2.5.1.25.jnlp;https://jira.deutsche-boerse.com/secure/attachment/89989/ComTrader-localhost-xsob-docker-2.5.1.25.jnlp",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8294400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/20 11:06;eg288;DONE

all CT flavors for internal test envs can be found on [XBID ComTrader links|https://confluence.energy.svc.dbgcloud.io/display/XBID/ComTrader+Links]
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Try to estimate work needed for JDK11 upgrade on LMAX Disruptor,XP-4109,103011,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,10/Nov/20 15:19,20/Nov/20 10:46,22/Feb/21 13:26,20/Nov/20 10:46,,,3.2.x,,,,,,,,,,,"Before going to XP-4105 we need to evaluate if our investment into JDK11 upgrade for this 3rd party library is worthy. 
 * Check disruptor code
 * try to test it with JDK11

 

Check also [https://github.com/LMAX-Exchange/disruptor/issues/298]

 
h2.  
h2. Acceptance criteria
 * brief overview about what needs to be done to allow us to use JDK11 on LMAX Disruptors. 
 * present the outcome on the Review so we can decide how to process further. ",,ei349,ek176,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8208000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w7:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,XP-4109-jdk11-upgrade,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Nov/20 12:09;ll664;h3. Running on JDK 11

*We cannot upgrade to JDK11 because we're stuck with Chronicle 3.*

Long story short, as long as we use GlusterFS (or any network filesystem) we're stuck with Chronicle 3 which does not run on JDK11. 

Journal writes fails as JDK internals changed:

{code}
java.lang.IllegalStateException: java.lang.ClassCastException: class [B cannot be cast to class [C ([B and [C are in module java.base of loader 'bootstrap')
	at net.openhft.lang.io.AbstractBytes.writeObject(AbstractBytes.java:2433) ~[lang-6.8.2.jar:na]
	at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.doOnEvent(AbstractChronicleQJournaler.java:88) ~[classes/:na]
	at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQJournaler.doOnEvent(ChronicleQJournaler.java:70) ~[classes/:na]
	at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQJournaler.doOnEvent(ChronicleQJournaler.java:28) ~[classes/:na]
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75) ~[classes/:na]
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32) ~[classes/:na]
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128) ~[disruptor-3.3.2.jar:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
Caused by: java.lang.ClassCastException: class [B cannot be cast to class [C ([B and [C are in module java.base of loader 'bootstrap')
	at net.openhft.lang.io.AbstractBytes$FastStringOperations17.extractChars(AbstractBytes.java:3215) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.AbstractBytes$FastStringOperations17.getUtf8EncodedStringLength(AbstractBytes.java:3223) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.AbstractBytes.findUTFLength(AbstractBytes.java:303) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.AbstractBytes.findUTFLength(AbstractBytes.java:267) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.AbstractBytes.writeUTFΔ(AbstractBytes.java:1186) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.impl.ClassMarshaller.write(ClassMarshaller.java:67) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.impl.ClassMarshaller.write(ClassMarshaller.java:36) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.BytesMarshallableSerializer.writeSerializable2(BytesMarshallableSerializer.java:101) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.BytesMarshallableSerializer.writeSerializable(BytesMarshallableSerializer.java:89) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.BytesMarshallableSerializer.writeSerializable2(BytesMarshallableSerializer.java:105) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.serialization.BytesMarshallableSerializer.writeSerializable(BytesMarshallableSerializer.java:89) ~[lang-6.8.2.jar:na]
	at net.openhft.lang.io.AbstractBytes.writeObject(AbstractBytes.java:2431) ~[lang-6.8.2.jar:na]
	... 9 common frames omitted
{code}

More details in XP-1250 and XP-759.

We should seriously think what are our plans with journal longterm.

With some dependency tweaks, XBID Core is able to run with Zulu JDK11, with Disruptor 3.x - {{sun.misc.Unsafe}} is still present. WIP branch [XP-4109-jdk11-upgrade|https://github.deutsche-boerse.de/dev/xbid/tree/XP-4109-jdk11-upgrade].

h3. Efforts to get rid of Unsafe in Disruptor

Actually, the Unsafe is already replaced in {{master}} branch on [Disruptor's Github|https://github.com/LMAX-Exchange/disruptor]. There's also quite live development, commits coming everyday, hence it seems like version 4.x is not far from release. However, developers aren't actually very responsive about this - see discusion in [google groups|https://groups.google.com/g/lmax-disruptor/c/qDqpmNlXTjI].

Nevertheless, given the fact that Disruptor 3.x runs on JDK11, there are no implementation efforts on the library itself needed. We could go with current 3.x, or upgrade to 4.x once released.
","19/Nov/20 12:18;ll664;I also notice we're running old versions of Disruptor/Chronicle, will upgrade within this ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove Exchange entity,XP-4108,102991,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,10/Nov/20 14:19,08/Dec/20 16:02,22/Feb/21 13:26,20/Nov/20 10:44,,,3.2.x,,,,,,,,,,,"There is an exchange entity in XBID core. It is used in Product, TradingSchedule and MarketArea. It is always populated to XSOB and other value doesn't make sense because XBID is not routing orders to different exchanges. It is comxerv relict. There is also a lot of references in trading module.

Please discuss what to do with it in customer visible views like trading and PMI. One option is to always fill XSOB so that customers will not know anything. The other is to omit it - delete in trading and leave blank in PMI.

 

Hints: 
 * several references from trading
 * used in API",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w7:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,XP-4250-develop,develop,XP-2400,XP-4250-metrics-integration-test-2,master,XP-2478-tobago-upgrade,XP-4250-metrics-integration-test,XP-4277-develop-sonar-test,XP-4211-perf-analysis-develop,XP-4211-perf-analysis-develop-jh,XP-4250-develop-jh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate on-call production support planning to OpsGenie,XP-4102,102928,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,09/Nov/20 14:59,10/Nov/20 16:26,22/Feb/21 13:26,10/Nov/20 16:26,,,,,,,,,,,,,,Move all current plannings from gCal to OpsGenie. ,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8985600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2649,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bwzz:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Resolve findings from xbid.profile-storage in HP Fortify, Sonar and Owasp",XP-4097,102793,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,06/Nov/20 14:58,23/Nov/20 10:39,22/Feb/21 13:26,23/Nov/20 10:39,,,,,,,,,,,,,,Resolve all 2 top level severity findings in HP fortify and Sonar for xbid.profile-storage,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9244800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bwzz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleanup Product entity,XP-4082,102542,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,04/Nov/20 14:16,26/Nov/20 14:49,22/Feb/21 13:26,11/Nov/20 14:15,,,,,,,,,,,,,,"There are a couple of old comxerv features on Product entity. Investigate and cleanup all the related code if necessary.
 * leg1product
 * leg2product
 * isVolatilityInterruption
 * isFutureProduct
 * isCommodityProduct
 * isAutoOrderMatcher

ProductPoolImpl
 * isLocal(), isRemote() doesnt have sense for XBID",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9417600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0byf8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fix CacheConfiguration in SM, currently it is disabled as Guava was deprecated in spring",XP-4076,102450,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,jy268,jy268,03/Nov/20 14:11,18/Nov/20 11:27,22/Feb/21 13:26,18/Nov/20 11:27,,,3.2.x,,Shipping,,,,,,,,,"Shipping was meant to cache users by user name, unfortunately this logic was disabled in 2017 during migration to spring boot 2 and not fixed afterwards :) . Please fix CacheConfiguration class according to
{code}
        // Guava no longer supported
        // https://jira.spring.io/browse/SPR-13797
{code}
in a nutshell, Caffeine supersede Guava and should be configured in SPM as a replacement.",,jy268,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8294400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i00000001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4076,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Nov/20 17:03;jy268;h1. Change description

Guava cache was replaced with Caffeine cache. Guava one was removed from spring 5.0 so the code was commented out. Now caching should work fine with TTL set to 10 seconds.

h1. Testing

Please do a smoke test of SPM UI focusing on user management operations like adding user, removing, updating, resetting passwords etc.","18/Nov/20 11:27;od044;Test passed on SM 3.2.0.1
- Smoke test passed ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 2) Fork m7.profile-storage to xbid.profile-storage,XP-4075,102438,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,jy268,jy268,03/Nov/20 13:32,18/Nov/20 08:43,22/Feb/21 13:26,18/Nov/20 08:43,,,3.2.x,,ComTrader,,,,,Tech-Debt,,,,"Fork m7.profile-storage to xbid.profile-storage. Currently all builds are set for develop branch which is used by m7 project, due to that any fixes in 1.8 branch result in failing unit tests on jenkins (1.8 branch does not contain docker project which is explicitly set in mvn execution params)
 # Acceptance criteria:
 # Fork m7.profile-storage to xbid.profile-storage
 # Copy all jenkins builds related to m7.profile-storage and switch them to xbid.profile-storage
 # Check if xbid developers have access to new fork
 # Set 1.8 branch as new develop
 # Create jenkins job for releasing, because currently it has to be done manually
 # Create new HP fortify application (needs to be discussed with ESO to assign AID first, then follow https://confluence.energy.svc.dbgcloud.io/display/M7T/HP+Fortify) 
 # Create jenkins nightly pipelines (including OWASP, HP Fortify and similar)
 # Based on Sonar/HP Fortify findings, re-estimate XP-4097",,jy268,lt112,,,,,,,,,,,,,,,,,,,XP-4097,,,,,,,,XP-4116,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bwzy:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Nov/20 14:51;lt112;# Fork m7.profile-storage to xbid.profile-storage
** https://github.deutsche-boerse.de/dev/xbid.profile-storage
# Copy all jenkins builds related to m7.profile-storage and switch them to xbid.profile-storage
** https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-pulls-cucumber/
** https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-pulls-integration/
** https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-pulls-sonar/
** https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-pulls-unit/
** NOTE: 1.8 version does not have the necessary profiles as 1.9 does, jobs will be adjusted accordingly 
# Check if xbid developers have access to new fork
** done
# Set 1.8 branch as new develop
** done
# Create jenkins job for releasing, because currently it has to be done manually
** https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-profile-storage-release/
# Create new HP fortify application (needs to be discussed with ESO to assign AID first, then follow https://confluence.energy.svc.dbgcloud.io/display/M7T/HP+Fortify)
** done
# Create jenkins nightly pipelines (including OWASP, HP Fortify and similar)
** https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-profile-storage-develop-nightly-pipeline/
** https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-profile-storage-acceptance-nightly-pipeline/
# Based on Sonar/HP Fortify findings, re-estimate XP-4097
** reestimated","11/Nov/20 10:40;lt112;Issue split into:
|XP-4116|(split 1) Fork m7.profile-storage to xbid.profile-storage|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID SIMU DRT 07/11/2020 - review plan and prepare for test,XP-4072,102397,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,lw641,lw641,02/Nov/20 14:38,06/Nov/20 15:06,22/Feb/21 13:26,06/Nov/20 15:06,,,,,,,,,,,,,,On Nov 4th 11:00 a call is scheduled to review the upcoming DRT and ensure everything is clear.,,ei349,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9244800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxsw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Nov/20 15:06;ei349;call happened. closing the ticket. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Review the updated concept in Attachment 5A.2,XP-4071,102394,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,qm925,qm925,02/Nov/20 14:00,06/Nov/20 09:04,22/Feb/21 13:26,02/Nov/20 14:54,,,3.1.4,,,,,,03/Nov/20 00:00,,,,,"With the implementation of Patroni with R2.0, the concept needs to be reflected also in the contractual documents - Attachment 5A.2",,cs687,iv732,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,changed the xbid contract - database setup ,,,,,,,,,,,,,,9590400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxs8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/20 14:07;iv732;I found one typo:  (should be ""one of them"")
{code:java}
On of them contains the database for the XBID Core module and is replicat-ing all the hosts in an asynchronous way. 

{code}
Moreover if possible I dont want to mention the databases there, because besides of cor and reporting, we have  other DBs such as AMS and ctp (and maybe more in the future)

","02/Nov/20 14:53;cs687;Thank you [~iv732] for the hint 

I changed it now to the following: 
{code:java}
On each host are two PostgreSQL instances installed which are managed by two (2) pat-roni-clusters. One of them contains the database for the XBID Core module and is replicat-ing all the hosts in an asynchronous way. The second cluster is replicating the data synchronously between all databases hosts.
{code}

Changed the following: 
chapter 7.9 
{code:java}
The basic components of the database’s HA architecture are four (4) dedicated and physi-cally separated servers, consul agent for election and detection of the master node, and clustering software ‘patroni’. Two (2) servers are running on each data center. All hosts are equipped with local NVMe SSD devices which will be used by the databases and by the journal files for the XBID Core module. One of these four (4) servers is considered the master node and the others are running as slave nodes. A consul-agent on each host is connecting to one node of a five (5) node Consul-cluster which is used for the election and detection of the master node. The cluster software and consul is responsible for monitor-ing the health of the cluster and taking action when a failure is detected. 
On each host are two PostgreSQL instances installed which are managed by two (2) pat-roni-clusters. One of them contains the database for the XBID Core module and is replicat-ing all the hosts in an asynchronous way. The second cluster is replicating the data syn-chronously between all databases hosts.
This setup prevents loss of committed data as all nodes are equipped with two (2) fast lo-cal NVMe SSD devices, two (2) hosts are spread across both data centers and uses host based synchronous/asynchronous mirroring to replicate data. This way failure of storage in one data center does not cause data loss and does not impact operations.
{code}

deleted chapter *7.11, 7.11.1*


","02/Nov/20 14:54;cs687;reviewed by [~iv732], [~hw120]
forwarded the updated version to [~qm925]
Ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resetting a password leads to an error,XP-4065,102318,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,ab039,ab039,30/Oct/20 11:47,02/Nov/20 13:06,22/Feb/21 13:26,30/Oct/20 13:24,,,3.1.3,,CMM,,,,,,,,,"When trying to reset a password from User Management I receive an error message.

*System Error. Unable to find user""..*

It seems there is some LDAP problem:
2020-10-30T10:24:56.230Z [.0-61391-exec-9][][] ERROR c.d.e.c.c.a.ErrorHandlerAspect - Unexpected exception.
com.deutscheboerse.passwd.service.PasswordException: Unable to find user
        at com.deutscheboerse.passwd.service.impl.PasswdServiceLdapImpl.userExists(PasswdServiceLdapImpl.java:114)
        at com.deutscheboerse.passwd.service.impl.PasswdServiceLdapImpl.resetPasswordOrCreateNewEntryIfDoesNotExist(PasswdServiceLdapImpl.java:341)
        at com.deutscheboerse.energy.cmm.refdata.service.UpdateRefDataServiceImpl.resetPassword(UpdateRefDataServiceImpl.java:107)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",,ab039,cs687,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,connected to ldap xbdtldap1 and changed the password of the user xbid-lipb-adm to the proper one. ,,,,,,,,,,,,,,9936000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,30/Oct/20 11:47,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxc0:",9223372036854775807,,,,,,,,,,,password was not matching in ldap ,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,,,,LIP-B,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/20 13:01;tm431;The technical user in both XBID and SPM tree should have correct password, the technical user is {color:#1d1c1d}xbid-lipb-adm{color}

I am not sure but the default could be Test01 or smth similar","30/Oct/20 13:19;cs687;[~tm431] [~ab039]
Test01 was not the proper password. 
I changed the password for user xbid-lipb-adm, check it with ""Test01"" for me its working out. 

Cheers.","30/Oct/20 13:24;cs687;done, ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AM Reporting - lots of JSCH clutter in the logs,XP-4055,102252,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,28/Oct/20 15:41,02/Nov/20 13:06,22/Feb/21 13:26,29/Oct/20 11:00,,,3.1.3,,,,,,,,,,,"JSCH logs tons of info when connecting to SFTP on INFO level, which pollutes the logs. Fix logback conf.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10022400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09ibi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,icsc-db,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application Network Mapping Jenkins Job,XP-4052,102205,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zs244,zs244,zs244,27/Oct/20 14:47,20/Jan/21 10:52,22/Feb/21 13:26,14/Jan/21 16:50,,,,,,,,,,goodForTraining,TechOps,,,"h1. Application Network Mapping Automation
h2. Current Situation
 - group security requires network map to be aware of potential leaks/losses

h2. Proposed Solution
 - create a Jenkins job ""XBID Map Application Network"" which accesses hosts and performs netstat/nmap/.. tools to receive application network information
 - push the Jenkins output into the Confluence page in XP-2988 manually (?)

h2. Acceptance Criteria
 - the Jenkins job gives open port information about targeted host",,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3283200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000gp",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/21 13:10;zs244;Basic functionality to fire command like netstat: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Map%20Application%20Network/","14/Jan/21 16:49;zs244;The Jenkins job is quite ""raw"" but it gives the acceptance criteria: ""the Jenkins job gives open port information about targeted host"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID_SLA_Reports email alias not working from production,XP-4051,102201,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,uv683,uv683,27/Oct/20 14:35,06/Nov/20 10:55,22/Feb/21 13:26,06/Nov/20 10:55,,,,,,,,,,,,,,"We have this email alias in outloook.  {{XBID_SLA_Reports}} you can see it in there and when you sent email from outlook to it, it works. However we have set this alias into report tool application on production (xbprodsla1 and xbprodsla2) and it is not working. Emails are simply sent via SMTP server xbprodmail1 and xbprodmail2. Non alias recipients works fine.

Please investigate what needs to be done in order for this to work. Thanks

 

-  [~cs687] will try to investigate with [~pd122]. ",,cs687,ei349,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"like cci provided in the email, in case we would have a valid mail-box created for *XBID_SLA_Reports@deutsche-boerse.com*, then it should have been received all the emails. 

For that we have to request the IT-SREVICE Request:
IT-SERVICE Request -> 05. Access Authorization Notes/Exchange -> Exchange - Create new shared mailbox 

and for the users which have access to the mailbox we have to create an additional request:
IT-SERVICE Request -> 05. Access Authorization Notes/Exchange -> Exchange - ACCESS TO SHARED MAILBOX

Jakub and me decided on it to just add the 3-5 users directly to the list in xbprodsla1/2 

I will try to figure out any contact of exchange admin´s and ask them if the described plan above will help us for this purpose. ",,,,,,,,,,,,,,9331200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxyw:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/20 15:21;ei349;(flag) Flag added

waiting for a feedback from Steffen and Urban.","04/Nov/20 11:00;cs687;Had a look at the email hosts *xbprodmail1* and *xbprodmail2*
it seems like the message/email was accepted from mail-gateway mail5.deutsche-boerse.de

In that case i will send CCI-Team an email to provide us more trace details to investigate further!

{code:java}
[root@xbprodmail1 ~]# grep -i ""XBID_SLA_Reports"" /var/log/maillog
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 35482230: to=<XBID_SLA_Reports@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 6F357E5: to=<XBID_SLA_Reports@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.09, delays=0.04/0/0.01/0.05, dsn=2.0.0, status=sent (250 ok:  Message 9504728 accepted)

[root@xbprodmail1 ~]# grep -i ""35482230"" /var/log/maillog
Nov  1 13:00:00 xbprodmail1 postfix/smtpd[43671]: 35482230: client=xbprodsla2.deutsche-boerse.de[10.139.95.215]
Nov  1 13:00:00 xbprodmail1 postfix/cleanup[46037]: 35482230: message-id=<97952303.4.1604232000183.JavaMail.tomcat@xbprodsla2.deutsche-boerse.de>
Nov  1 13:00:00 xbprodmail1 postfix/qmgr[60866]: 35482230: from=<xbprod-rpt@xbid.deutsche-boerse.com>, size=631681, nrcpt=2 (queue active)
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 35482230: to=<XBID_SLA_Reports@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 35482230: to=<jakub.hesoun.ext@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
Nov  1 13:00:00 xbprodmail1 postfix/qmgr[60866]: 35482230: removed
{code}
","04/Nov/20 11:13;cs687;EMAIL to CCI: 
{code:java}
Hey CCI-Team, 

I would like to ask you, to provide us the Mail-Trace for the following timestamp
Nov  1 13:00:00

The Email were send out with an Alias “XBID_SLA_Reports” 
client=xbprodsla2.deutsche-boerse.de[10.139.95.215]
from=<xbprod-rpt@xbid.deutsche-boerse.com>, size=631681, nrcpt=2 (queue active)
to=<XBID_SLA_Reports@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
to=<jakub.hesoun.ext@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)

Emails are simply sent via SMTP with our server *xbprodmail1* and *xbprodmail2* and non-alias recipients works fine. 
Is there any rule behind it, that any alias-recipients are not working out? 

The whole output: 
Nov  1 13:00:00 xbprodmail1 postfix/smtpd[43671]: 35482230: client=xbprodsla2.deutsche-boerse.de[10.139.95.215]
Nov  1 13:00:00 xbprodmail1 postfix/cleanup[46037]: 35482230: message-id=<97952303.4.1604232000183.JavaMail.tomcat@xbprodsla2.deutsche-boerse.de>
Nov  1 13:00:00 xbprodmail1 postfix/qmgr[60866]: 35482230: from=<xbprod-rpt@xbid.deutsche-boerse.com>, size=631681, nrcpt=2 (queue active)
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 35482230: to=<XBID_SLA_Reports@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
Nov  1 13:00:00 xbprodmail1 postfix/smtp[46038]: 35482230: to=<jakub.hesoun.ext@deutsche-boerse.com>, relay=mail5.deutsche-boerse.de[10.230.194.254]:25, delay=0.1, delays=0.04/0.01/0.01/0.04, dsn=2.0.0, status=sent (250 ok:  Message 9504718 accepted)
Nov  1 13:00:00 xbprodmail1 postfix/qmgr[60866]: 35482230: removed

Please provide us the trace for further troubleshooting. 

Thanks in Advance!

Cheers, 
Steffen
{code}
","06/Nov/20 08:17;cs687;Feedback from CCI:
[~uv683] can we specially double check this part ? 
*The logs indicate the message was delivered to the DBAG Exchange  If there is a valid e-mail box created for XBID_SLA_Reports@deutsche-boerse.com, then it should have been received.*

{code:java}
Greetings,
CCI manages the External e-mail Gateways that use the SMTP envelope headers to process and transport the messages .  If the Aliases are part of Outlook or Exchange embedded coding, it is transparent to CCI. If the Alias “XBID_SLA_Reports” is defined on the Mail server to associate with XBID_SLA_Reports@deutsche-boerse.com, the verified the address was created as  SMTP recipient.

The logs indicate the message was delivered to the DBAG Exchange  If there is a valid e-mail box created for XBID_SLA_Reports@deutsche-boerse.com, then it should have been received.

These are the logs from the Mail Gateways:
01 Nov 2020 13:00:00 (GMT +01:00)        Protocol SMTP interface Data 1 (IP 10.230.194.254) on incoming connection (ICID 8942132) from sender IP 10.136.140.249. 
01 Nov 2020 13:00:00 (GMT +01:00)        (ICID 8942132) RELAY sender group RELAYLIST match 10.136.140.249 SBRS rfc1918 country not applicable
01 Nov 2020 13:00:00 (GMT +01:00)        Start message 9504718 on incoming connection (ICID 8942132).
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 enqueued on incoming connection (ICID 8942132) from xbprod-rpt@xbid.deutsche-boerse.com.
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 on incoming connection (ICID 8942132) added recipient (XBID_SLA_Reports@deutsche-boerse.com).
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 on incoming connection (ICID 8942132) added recipient (jakub.hesoun.ext@deutsche-boerse.com).
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 contains message ID header '<97952303.4.1604232000183.JavaMail.tomcat@xbprodsla2.deutsche-boerse.de>'.
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 original subject on injection: prod SLA reports for 2020-10
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 (631833 bytes) from xbprod-rpt@xbid.deutsche-boerse.com ready.
01 Nov 2020 13:00:00 (GMT +01:00)        Message 9504718 queued for delivery.
01 Nov 2020 13:00:00 (GMT +01:00)        SMTP delivery connection (DCID 3873837) opened from Cisco IronPort interface 10.230.194.254 to IP address 193.29.81.254 on port 25.
01 Nov 2020 13:00:00 (GMT +01:00)        Delivery connection (DCID 3873837) successfully accepted TLS protocol TLSv1.2 cipher ECDHE-RSA-AES256-GCM-SHA384 .
01 Nov 2020 13:00:00 (GMT +01:00)        (DCID 3873837) Delivery started for message 9504718 to XBID_SLA_Reports@deutsche-boerse.com, jakub.hesoun.ext@deutsche-boerse.com.
01 Nov 2020 13:00:01 (GMT +01:00)        (DCID 3873837) Delivery details: Message 9504718 sent to XBID_SLA_Reports@deutsche-boerse.com, jakub.hesoun.ext@deutsche-boerse.com

 


Best Regards,

Connectivity Control & Internet (CCI)
IT Infrastructure
Deutsche Boerse Group
{code}
","06/Nov/20 08:46;cs687;Just talked to [~qm925] and she confirmed there is no valid real Mailbox existing!
She showed me her outlook and it shows just a distribution list with the ""*Display-Name*"": ""XBID_SLA_Reports""
and the proper ""*Alias*"": ""&XBIDSLAs""
[~uv683]: Does it make sense to change the alias and try if the emails will be received? ","06/Nov/20 10:55;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CLONE - XBID LIPB new version of R3.1.3, SIMU->LIPB DB restore 27-30/10/2020",XP-4049,102185,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,tm431,hw120,27/Oct/20 11:14,03/Nov/20 09:00,22/Feb/21 13:26,03/Nov/20 09:00,,,,,,,,,,xbid_ops,,,,"We have 5 days (27/10-02/11/2020) for LIPB deployment and SIMU->LIPB DB restoration according to ASR015

*Date:* 27-02nd november

 

*Maximum end time:* 2/11/2020 9:00

*Target environment:* LIPB

*Software version:*

PACKAGE R3.1.3
||Component||Version||Comment||
|xbid|3.1.8|New|
|spm|3.1.3|New|
|comtrader|3.1.2|*NEW WITH CERTIFICATES in SERVICE-8276 so no need to deploy any*|
|pmilogger|1.1.0|No change|
|pmiarchiving|1.0.19|New version|
|m7-xbid-report-tool|2.46|No change|
|alarmtilt-client|1.0.8|No change|
|h3. AMS|1.0.0|No change|
|h3. xbid-am-reporting|1.0.4|New XP-3541 is done|
|rep-engine|5.0.56|No change|

 
h2. Execution steps
 * Stop environment*
 * PostgreSQL 12.4*  upgrade ([~iv732] and [~cs687])
 * Perform Ansible deployment - as part of the deployment:*
 * Apache *Tomcat 8.5.57* upgrade (automatic via Ansible)
 * Deploy new versions of RabbitMQ and Erlang
 *Rabbit MQ* - by ansible deployment

{color:#1d1c1d} 3.8.5  -> new version{color}
 {color:#1d1c1d}   {color}*Erlang* - by ansible adhoc command
 {color:#1d1c1d} 22.1 -> new version TOs to prepare{color}
{code:java}
ansible all --limit 'xb*-lipb-*amq*' -m shell -a ""yum update XBID-erlang -y"" -b -K
{code}
 * 
 ** TLS Ciphers updated (XBID-5191) ([~ek176]) - Apache restart/reload of conf. needed 
 * *HA proxy TLS Ciphers* - re-deploy via old HA Proxy playbook

 * Apply new LDAP Policies to both XBID and SPM LDAP tree. 

|ssword minimum length to 12 characters
 +
 _“Future user passwords will have to be at least 12 characters long.” -->_ Passwords which are valid in the moment of deployment (i.e. passwords with previous security policies) remain valid.|1 uppercase letter, 1 lowercase letter + 1 digit and a special character is enforced|Users will not be allowed to reuse the last *six* passwords|
 * 
 ** More info:
 *** –
 *** XP-2473 (XBID-5195) COR SPM min pwd lenght = 12
 *** XP-2231 (XBID-5197) COR SPM history of pwd = 6

 

{color:#de350b}*After the DEPLOYMENT IS FINISHED, PLEASE PERFORM DB COPY FROM ideally   SIMU->LIPB env.*
 
 *Set the password expiration date for all users to x+90 days and reset passwords to default value xbidTest01!1*{color}

 ",,ab039,hw120,iv732,tm431,,,,,,,,,,,,,,,,,,,,SERVICE-8411,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,tm431,,,,,,,,,,,,,,Internal Deployment Request,eg288,eh941,jy268,qo794,No,9590400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,02/Nov/20 10:00,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ax42:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,LIP-B,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/Oct/20 11:12;iv732;Cor is not running due to running out of memory
{code:java}
tomcat@xblipbcor1:[/xbid/xbid-lipb-cor1/tomcat]$ less hs_err_pid23114.log
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (mmap) failed to map 5744558080 bytes for committing reserved memory.
{code}
--> the inventory is wrongly configured

--> run the PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2322]

Rabbitmq was not running after deployment. There were a bunch of erlang processes running:
{code:java}
rabbitmq@xblipbamq1:[/xbid/logs/xbid-lipb-int-amq1]$ netstat -tulpn
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7738            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:51390           0.0.0.0:*               LISTEN      13040/beam.smp      
tcp        0      0 0.0.0.0:5600            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:52390           0.0.0.0:*               LISTEN      13040/beam.smp      
tcp        0      0 0.0.0.0:54310           0.0.0.0:*               LISTEN      7536/epmd           
tcp        0      0 0.0.0.0:54311           0.0.0.0:*               LISTEN      1803/epmd           
tcp        0      0 0.0.0.0:53390           0.0.0.0:*               LISTEN      13040/beam.smp      
tcp        0      0 0.0.0.0:4369            0.0.0.0:*               LISTEN      11556/epmd          
tcp        0      0 0.0.0.0:54390           0.0.0.0:*               LISTEN      32528/epmd          
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:54391           0.0.0.0:*               LISTEN      17863/epmd          
udp        0      0 0.0.0.0:41615           0.0.0.0:*                           -                   
udp        0      0 10.139.41.242:123       0.0.0.0:*                           -                   
udp        0      0 127.0.0.1:123           0.0.0.0:*                           -                   
udp        0      0 0.0.0.0:123             0.0.0.0:*         
{code}
After killing all of them, redeployment of rabbitmq raised another error:
{code:java}
TASK [xbrabbitmq-instance : Delete old instance directory] *********************fatal: [xb-xbid-lipb-int-amq1]: FAILED! => {    ""changed"": false}MSG:rmtree failed: [Errno 13] Permission denied: '/xbid/xbid-lipb-int-amq1/var/lib/rabbitmq/mnesia/xbid-lipb-int-amq1@xblipbamq1-plugins-expand/cowlib-2.7.0/include/cow_inline.hrl'changed: [xb-xbid-lipb-ext-amq1]
{code}
--> delete all logs and xbid-lipb* directories

Afterwards, redeployment of rabbitmq, and then all other components.

Everything looks good.

[https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FXBID%20Ansible%20Jobs%2FXBID%20Ansible%20deploy%20full/detail/XBID%20Ansible%20deploy%20full/242/pipeline]

 

 ","28/Oct/20 16:21;iv732;Performed the DB copy, got error:

 
{code:java}
ERROR: Found non-empty schema ""xblipbcor"" without metadata table! Use init() or set initOnMigrate to true to initialize the metadata table.
ERROR: Caused by: com.googlecode.flyway.core.api.FlywayException: Found non-empty schema ""xblipbcor"" without metadata table! Use init() or set initOnMigrate to true to initialize the metadata table.
ERROR: Occured in com.googlecode.flyway.core.Flyway$1.execute() at line 848
ERROR : Can NOT execute the DB migration
{code}","28/Oct/20 16:45;iv732;It seems that the job used the old perl script to stop and redeploy all tomcat components!

I created a copy of this job and remove all the above steps. 

Stopped tomcat modules manually with the new ansible playbook.

Executed the new Jenkins job: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Copy%20DB/1/console]

After that start all tomcat: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID%20Ansible%20deploy%20full/245/]

 ","29/Oct/20 09:00;iv732;The Jenkins job run but I checked, there is no changes of password on LDAP.
Sawthe error:
{code:java}
ldap_start_tls: Operations error (1) additional info: SSL connection already established.
{code}

Modified the script to only use either start_tls or ssl, not both:


{code:java}
# export LDAP tree from source and modify it
if [[ ""$reset_passwords"" =~ ^(xbidtest01|xbidTest01!)$  ]]; then
  echo setting the passwords to ${reset_passwords}
  LDAPTLS_REQCERT=never ldapsearch -LLL -x -H ldap://$source_ldap_server.deutsche-boerse.de -Z -D uid=xbid-adm,dc=energy,dc=$source_dc_value -y $source_pwd_file -b ou=$source,o=xbid,dc=energy,dc=$source_dc_value dn sn cn objectClass uid pwdpolicysubentry aci > /tmp/xbid_$source.ldif
  LDAPTLS_REQCERT=never ldapsearch -LLL -x -H ldap://$source_ldap_server.deutsche-boerse.de -Z -D uid=xbid-adm,dc=energy,dc=$source_dc_value -y $source_pwd_file -b ou=$source,o=sm,dc=energy,dc=$source_dc_value dn sn cn objectClass uid pwdpolicysubentry aci > /tmp/sm_$source.ldif
  sed 's/'$source'/'$target'/g;s/objectClass: top/objectClass: top\nuserPassword: ${reset_passwords}/g;s/sn: trader/changetype: add\nsn: trader/g;1 a\changetype: add' /tmp/xbid_$source.ldif > /tmp/xbid_$target.ldif
  sed 's/'$source'/'$target'/g;s/objectClass: top/objectClass: top\nuserPassword: ${reset_passwords}/g;s/sn: trader/changetype: add\nsn: trader/g;1 a\changetype: add' /tmp/sm_$source.ldif > /tmp/sm_$target.ldif
elif [[ ""$reset_passwords"" =~ ^(no)$  ]]; then
  echo using the original passwords
  echo source_dc_value is $source_dc_value
  LDAPTLS_REQCERT=never ldapsearch -LLL -x -H ldap://$source_ldap_server.deutsche-boerse.de -Z -D uid=xbid-adm,dc=energy,dc=$source_dc_value -y $source_pwd_file -b ou=$source,o=xbid,dc=energy,dc=$source_dc_value dn sn cn objectClass uid pwdpolicysubentry aci userPassword > /tmp/xbid_$source.ldif
  LDAPTLS_REQCERT=never ldapsearch -LLL -x -H ldap://$source_ldap_server.deutsche-boerse.de -Z -D uid=xbid-adm,dc=energy,dc=$source_dc_value -y $source_pwd_file -b ou=$source,o=sm,dc=energy,dc=$source_dc_value dn sn cn objectClass uid pwdpolicysubentry aci userPassword > /tmp/sm_$source.ldif
  sed 's/'$source'/'$target'/g;s/sn: trader/changetype: add\nsn: trader/g;1 a\changetype: add' /tmp/xbid_$source.ldif > /tmp/xbid_$target.ldif
  sed 's/'$source'/'$target'/g;s/sn: trader/changetype: add\nsn: trader/g;1 a\changetype: add' /tmp/sm_$source.ldif > /tmp/sm_$target.ldif
fi
 remove old tree and import ldif file
echo pwd file is $target_pwd_file
LDAPTLS_REQCERT=never ldapdelete -x -H ldaps://$target_ldap_server.deutsche-boerse.de -D uid=xbid-adm,dc=energy,dc=test -y $target_pwd_file ""ou=$target,o=xbid,dc=energy,dc=test"" -r
LDAPTLS_REQCERT=never ldapdelete -x -H ldaps://$target_ldap_server.deutsche-boerse.de -D uid=xbid-adm,dc=energy,dc=test -y $target_pwd_file ""ou=$target,o=sm,dc=energy,dc=test"" -r
LDAPTLS_REQCERT=never ldapmodify -x -H ldaps://$target_ldap_server.deutsche-boerse.de -D uid=xbid-adm,dc=energy,dc=test -y $target_pwd_file -f /tmp/xbid_$target.ldif
LDAPTLS_REQCERT=never ldapmodify -x -H ldaps://$target_ldap_server.deutsche-boerse.de -D uid=xbid-adm,dc=energy,dc=test -y $target_pwd_file -f /tmp/sm_$target.ldif
{code}
","29/Oct/20 10:35;iv732;Modified the script on the Jenkins job, now the LDAP users are created with correct passwords.
Will ask BizOps to test.
","29/Oct/20 10:58;tm431;[~iv732] 

SFTP is not working please check the emergency chanell, somethins with invalid private key

and also ECP is not working can you please



1.stop ECP Endpoint on XBID LIPB

2. clean all messages in ECP database,not all tables must be present in the DB

truncate table auditlog;
truncate table event;
truncate table messagebox_mn;
truncate table messagebox_mc;
truncate table messagebox_edc;
truncate table messagebox_mn_arch;
truncate table messagebox_mc_arch;
truncate table messagebox_edc_arch;
truncate table message;
truncate table message_arch;
truncate table message_content;
truncate table message_content_arch;
truncate table message_content_storage;
truncate table message_content_storage_arch;
truncate table messageregister_edc;
truncate table messageregister_mc;
truncate table messageregister_mn;

3. start ECP Endpoint on XBID LIPB


thanx","29/Oct/20 11:30;iv732;1. log in to xbcutsedb1
2. truncated the tables

{code:java}
xblipbecp=# truncate table auditlog;
TRUNCATE TABLE
xblipbecp=# truncate table event;
TRUNCATE TABLE
xblipbecp=# truncate table messagebox_mn;
TRUNCATE TABLE
xblipbecp=# truncate table messagebox_mc;
ERROR:  relation ""messagebox_mc"" does not exist
xblipbecp=# truncate table messagebox_edc;
TRUNCATE TABLE
xblipbecp=# truncate table messagebox_mn_arch;
TRUNCATE TABLE
xblipbecp=# truncate table messagebox_mc_arch;
ERROR:  relation ""messagebox_mc_arch"" does not exist
xblipbecp=# truncate table messagebox_edc_arch;
TRUNCATE TABLE
xblipbecp=# truncate table message;
TRUNCATE TABLE
xblipbecp=# truncate table message_arch;
TRUNCATE TABLE
xblipbecp=# truncate table message_content;
TRUNCATE TABLE
xblipbecp=# truncate table message_content_arch;
TRUNCATE TABLE
xblipbecp=# truncate table message_content_storage;
TRUNCATE TABLE
xblipbecp=# truncate table message_content_storage_arch;
TRUNCATE TABLE
xblipbecp=# truncate table messageregister_edc;
TRUNCATE TABLE
xblipbecp=# truncate table messageregister_mc;
ERROR:  relation ""messageregister_mc"" does not exist
xblipbecp=# truncate table messageregister_mn;
TRUNCATE TABLE

{code}
3. Started ECP ","29/Oct/20 11:47;iv732;Regarding SFTP:
1. the key file is there:

{code:java}
tomcat@xblipbdow1:[/xbid/xbid-lipb-cmi1/tomcat/conf]$ ls -al
total 244
drwx------  3 tomcat tomcat   4096 Oct 28 16:14 .
drwxr-xr-x 10 tomcat tomcat   4096 Oct 29 10:35 ..
drwxr-x---  3 tomcat tomcat   4096 Oct 28 16:14 Catalina
-rw-------  1 tomcat tomcat  13446 Jun 30 23:53 catalina.policy
-rw-------  1 tomcat tomcat   7661 Jun 30 23:53 catalina.properties
-rw-r--r--  1 tomcat tomcat   2348 Oct 28 16:13 context.xml
-rw-------  1 tomcat tomcat   4324 Oct 28 16:13 id_rsa_sftp
-rw-------  1 tomcat tomcat   1149 Jun 30 23:53 jaspic-providers.xml
-rw-------  1 tomcat tomcat   2313 Jun 30 23:53 jaspic-providers.xsd
-rw-r--r--  1 tomcat tomcat   4087 Oct 28 16:13 logging.properties
-rw-r--r--  1 tomcat tomcat   6692 Oct 28 16:13 server.xml
-rw-------  1 tomcat tomcat   2164 Jun 30 23:53 tomcat-users.xml
-rw-------  1 tomcat tomcat   2558 Jun 30 23:53 tomcat-users.xsd
-rw-------  1 tomcat tomcat 171879 Jun 30 23:53 web.xml
{code}

2. But the content of that key file is not correct:

{code:java}
LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS1FJQkFBS0NBZ0VBMGVOT3dhTVdXTG56QXVLWnRIRURad3M4b2FSVmpRZ0NBZ2huYWJXRHNZY084Y1pKCkdMdGNXV29EeDU0d1NmbWR0ZTA2eTFxNmVTOFRTQ1JncTdLcnhMQ3RhaWthWDNRSVlnWDh3MUVET1RRUitONnoKdm81d2ZjUndyMUhZY1NOWStHMDdwNjJyc3JITjBkVkxkazRkQ1FlYnFaeEd5bEtLejdUaDJld0VORGQ1bzdEYQppbllVems2TksvL3A1Vk8yYVFXc2NqaVlDSkJiYmR4ZkFub2hWU0hhdnpWLS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS1FJQkFBS0NBZ0VBMGVOT3dhTVdXTG56QXVLWnRIRURad3M4b2FSVmpRZ0NBZ2huYWJXRHNZ
Y084Y1pKCkdMdGNXV29EeDU0d1NmbWR0ZTA2eTFxNmVTOFRTQ1JncTdLcnhMQ3RhaWthWDNRSVlnWDh3MUVET1RRUitONnoKdm81d2ZjUndyMUhZY1NOWStH
MDdwNjJyc3JITjBkVkxkazRkQ1FlYnFaeEd5bEtLejdUaDJld0VORGQ1bzdEYQppbllVems2TksvL3A1Vk8yYVFXc2NqaVlDSkJiYmR4ZkFub2hWU0hhdnpW
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
{code}
3. Replaced with the correct keys (updated vault: xb/xbid/test/sftp/id_rsa_sftp)

{code:java}
-----BEGIN RSA PRIVATE KEY-----
MIIJKQIBAAKCAgEA0eNOwaMWWLnzAuKZtHEDZws8oaRVjQgCAghnabWDsYcO8cZJ
GLtcWWoDx54wSfmdte06y1q6eS8TSCRgq7KrxLCtaikaX3QIYgX8w1EDOTQR+N6z
vo5wfcRwr1HYcSNY+G07p62rsrHN0dVLdk4dCQebqZxGylKKz7Th2ewENDd5o7Da
inYUzk6NK//p5VO2aQWscjiYCJBbbdxfAnohVSHavzVyIdWA5Vw0ogs54i5Amz7M
PA3QsTigxuys4ye0A7EGjW3fQQwchoVjwJ47McdU8r/DjqirpYW/z46G9GJtglto
UMxGHjypd5SZn9Cxbw5WXHq/EDYmsQpMZRXzdikywr9jAk5+cMmCqze2jUzniYQH
Adt+PlL/Xe8p6bJIGha9/hNHmva/sB6uSjJzkp1809BIkEdoHdt1Rx2Kz48OOVpW
CvcHP1pb4cGzZVBWqF9nCBTj0n+7GP2KrUJkco5WB1UkMsnenkdc4YdD6rj3lkz7
lXVfB5u5OEh1E88APaKFqmupWVSlXvixnhN4Wt2YIWXGleEqAAMu46Gt0jGB/uzK
Nu/7xETwgcZ/lrMCxKk9Wg878/cBq7qy9KBq9VB1PEnWPHF+p57BJXgrS4YIgoHw
+Bh7jETO1C4hcuTyfSrNYtP7FxjKL//cbDSABttrsZazkg0sgYHScPf9X6sCAwEA
AQKCAgBLMLloGTrKMmNiZzdVMx9a7OWdqreTPIkrnUMe1Y4GLTInXzeUipp81cPg
4US/W5MqN4BWlXw0Ka8oqw+OswViA0E8xNjT1Uejhi2U8xLKjWLa2z1dSL338EXG
KPX3IgifhtJWMZtO+u+W+mh8S2OPdpBHZNrfZE6iNlSqsyiWZEFJaPQBome1uOJO
HvH129V/Li8nBCtC9iQq6UWIJ6SFUQmCcm0evdPdVvjsDEWCR7uRYh/ca76VnonK
ecM95V1R7TtBs1jFfsdBUcv4lzbxkE1YYWZ3VumW9KFQg+jI5/H/PyvRtjxwXJ8B
XdTjMeo+tM4vdzG3Zw7ZYa0YkZKT3cfO/zVl9pHfGfluUfCUySCXskoq3U6Q4fDH
QuHB+AXcX1f1RXVbT2wFo1mBBpP+D4vO4f7rJEgSrgIe7WBGVvDHsdjxtoyoJfrh
hyYsAQIl+aHJb8mh7vQcvFDHeUG6sFTqweB6j9BSg7LPtcXVC5Kw75xV0+144iFW
lAgu5zoO3neWi3hYo3TkrmVixQxGWgPesBVZF6n18YNIdCd8kr32+BfYdRl8O7eb
l1p0CuES4DKirceUHzq2vPXjsXC4RdxlaLbJqWd+XVsRyad5xbRBHZW/PlBcINYL
pxKPb6G7tAwOSPnhhuYSSzF1HCU09f0Huho0REBMPGmYxFBR4QKCAQEA87ebyCGM
71pNQucGyrS45l9aAelg0iOPduG0OXNSal/607mcMskrB0iK342BMddqbqlckIyX
nK+gbX5Hrk4adkxSC/8r64YSODsBd1moCPvUib+zvcwxKqa8+e8yqUXScnHKUd2X
IG8SkpRr079HwbIdVnhSe0BNlU+nP2/QvHMTQ83/VSYL7pBOvMqdqGZ7jHalb5fz
KouryfWAs38iKEnaE+ugHy+Rosu3ErZKloLe+K/VuE1z90nCuAkwH5IrulPTQBcj
cCtsPH/aE2F0jxxIWrHgzo1iCGslv2UC+ZRs+TJ2UmBZBeUZ2AaB51WjsaTE25Be
orPWIpIAiuV8swKCAQEA3Hc9e2fe68fPC268tF+ukUKLdiUTHjr5ABST7XxxRcV8
vPCpWNJYPmqYM5nmmC8RcUwUSblt5EeUznR4A7ZahCtyFUMCYPyObp5RsJwhjyps
8tAkR+F2ihJVr2nNqb7piN5hyyxNoYKJX16tZECWegLYNyiXb2jBOdUXo5AlDL13
6Yo7YKvGse80LkWXK3eiJK80WIjGjdk2xGMgbFcccHkAxtNfvbHchg6kjNvzDmC8
nKtn2rDOpnjuGFrcQldzDB/ZHgaDfWXm3rIXz4t/dZplWyOl3dWKEUYVQ+dOM+MN
tcixyfBJ1J3ZidHxZKu3ajgAIKGM40H+CYGAFcN9KQKCAQAgjs+1zZ2ZQBQAMwK6
Q6hLxkMs7DNt/ygkNoSwBBLneQj2Dd6q/irMX0mGEc5HjUJ/pApkmROL7/5bgjor
M+3fDdUMGzuPzCpU7rUEb6q+AH5lJIHrggKzcvDd5rF64YP6m+7uPs74mz387Oz2
rZ/1ZUj8CzjhlDaJEsoB9HsLIchaD4PjqSCA7zBFkj+7hm1M13DEVqU6cswxP6XA
1OQIQ81pSdnrMJyhBdvgGRAfyT3mNP81DsvGJkln8npGTW2gB6C5+B1Y18Qu1Nma
KzO6Boo363lfvo1xGHdDeUgLdWOVasNZv9tEqVVpgX0LHWqvyZYuyruJusKJfb2q
0Ht3AoIBAQDP1zoHFS17aqsuQ/9yrKGOIAYKI3majk4gXUX4JdFDzaKDHP8J1YOL
lEJYo0ZZQkZXYTnfJwkKpNEMsZBTL561659pm/qqJG7Cqk6pCQg6R+zeHIuXmF6A
XDibXkudM3ZGqh/XwrSNBtsrJb6hPKKf8/6SQZpCVaeUNehLMqE7GYPqj37a7BYt
uSygUsrpF6esnd/jd054e8a97hWrDZSqE+k/iBZCZ2NWnodSpCjH7TrjGFSYPwcS
uf78xuvPP1IepAez3sAnf+HfIFaCOyi2XhAfk8PTFnVLQ57YnT+EexF5xvKVRgrU
ftuOqnXASoJniNPV73c66APuQj/WRK3BAoIBAQDOzv0fkOKQQz0iGVu2xZOO0Qo9
3hNx4s9YRpgp8RdJTXX9Moy8dXx0ewoYN1Md/SikEyJEdr+H+wTQNnmxPRFL3bb9
/oUXu+XGFyBLAINi38UNiNUHlDjxRIgr+WksW9FgvG4xW1qxRkajHXgIy6fTXW+N
O9GSQNZV4jH15GmyWONUOrLKWf2i+quYUqQLSuD21Zt0/yxnqcBwe8/Z0qjWWgLx
IsmKZ2cP5he4hR3++MSDBlOi9ugI+hIZsWrDdr6lkUCrmUVm1rufj5oP1boh6U3g
JkNaZx9yHdwghM+YSQ+JJZqhNNSsGaRP/mv2Tc+nYmYBNwEf+7XqVQQn/tme
-----END RSA PRIVATE KEY-----

{code}

4. Restarted SPM module","29/Oct/20 11:51;tm431;Restart please also CMI and CMM module they also use SFTP","29/Oct/20 15:35;iv732;Applied some further PRs:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2327
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2329
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2330
","02/Nov/20 08:42;iv732;telegraf will be deployed by [~hw120] this week","02/Nov/20 22:52;hw120;Telegraf was redeployed already on Wednesday, but there were a couple of problems. Especially with ecp and rabbitmq.

All should be fixed now.","03/Nov/20 08:59;iv732;Thanks [~hw120]
This ticket is closed now.",,,,,,,,,,,,,,,,,,,,,,,,,
Remove TSO dispute,XP-4046,102146,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,26/Oct/20 16:44,02/Nov/20 13:06,22/Feb/21 13:26,28/Oct/20 17:06,,,3.1.3,,,,,,,,,,,"There is a class TsoDispute and a lot of related code code along with DB tables (which are empty on production). TSO disputed were driven by trading property `tsoDisputesEnabled` which is also turned off. If turned on, it is not working anyway.

I suggest removing all related code along with UI tso dispute which can be found it tsoConfig.xhtml",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10195200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09ib",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbacr/xbamr logs to Kibana and ebsm,XP-4045,102134,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,ll664,ll664,26/Oct/20 13:42,10/Nov/20 13:21,22/Feb/21 13:26,10/Nov/20 13:21,,,,,,,,,,,,,,"Those service were extracted from Report Tool, which has a special index {{xbid-sla}} in Kibana.

Let's drop that index and move it to {{xbid-tomcat}} and have there instances there (Kibana {{instance}} field):
 * sla - original Report Tool
 * acr - ACER Reporting
 * amr - AM Reporting

Adjust ebsm copy jobs as well.

 

hint: format should be same as everywhere else. If not - contact devs to correct it. ",,cs687,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"deployed filebeat instances on xbsimusla1/2 hosts
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/
 and confirmed that the logs are in kibana 

[root@xbsimusla1 filebeat.d]# ll                                        
total 12                                                                
-rw-r--r-- 1 beat beat 579 Nov 10 12:37 xb-xbid-simu-acr1.yml           
-rw-r--r-- 1 beat beat 579 Nov 10 12:55 xb-xbid-simu-amr1.yml           
-rw-r--r-- 1 beat beat 603 Nov 10 12:47 xb-xbid-simu-report-tool1.yml   
[root@xbsimusla2 filebeat.d]# ll
total 12
-rw-r--r-- 1 beat beat 578 Nov 10 12:37 xb-xbid-simu-acr2.yml
-rw-r--r-- 1 beat beat 578 Nov 10 12:55 xb-xbid-simu-amr2.yml
-rw-r--r-- 1 beat beat 602 Nov 10 12:47 xb-xbid-simu-report-tool2.yml",,,,,,,,,,,,,,8985600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxyw:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,.,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Nov/20 11:57;cs687;just checked the transfer scripts of *xbidprodcor1* and *xbidsimucor1*
and it seems all is added to transfer the logs to ebsm 

SIMU:
{code:java}
/xbid/logs/xbid-simu-acr1/xb_xbid_simu_acr-1_standard_ixe.log is successfully transferred
/xbid/logs/xbid-simu-acr1/rollover/xb_xbid_simu_acr-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-simu-ams1/.xb_xbid_simu_xbams-1_standard_ixe.log.swp is successfully transferred
/xbid/logs/xbid-simu-ams1/xb_xbid_simu_xbams-1_standard_ixe.log is successfully transferred
/xbid/logs/xbid-simu-report-tool1/rollover/xb_xbid_simu_report-tool-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-simu-report-tool1/xb_xbid_simu_rpt-1_standard_ixe.log is successfully transferred
/xbid/logs/xbid-simu-report-tool1/xb_xbid_simu_report-tool-1_standard_ixe.log is successfully transferred
xbsimusla1 is completed

/xbid/logs/xbid-simu-acr2/rollover/xb_xbid_simu_acr-2_standard_hau_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-simu-acr2/xb_xbid_simu_acr-2_standard_hau.log is successfully transferred
/xbid/logs/xbid-simu-amr1/rollover/xb_xbid_simu_amr-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-simu-amr1/xb_xbid_simu_amr-1_standard_ixe.log is successfully transferred
/xbid/logs/xbid-simu-ams2/xb_xbid_simu_ams-2_standard_hau.log is successfully transferred
/xbid/logs/xbid-simu-ams2/xb_xbid_simu_xbams-2_standard_ixe.log is successfully transferred
/xbid/logs/xbid-simu-report-tool2/xb_xbid_simu_rpt-2_standard_hau.log is successfully transferred
/xbid/logs/xbid-simu-report-tool2/rollover/xb_xbid_simu_report-tool-2_standard_hau_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-simu-report-tool2/xb_xbid_simu_report-tool-2_standard_hau.log is successfully transferred
xbsimusla2 is completed
{code}

PROD:
{code:java}
/xbid/logs/xbid-prod-acr1/rollover/xb_xbid_prod_acr-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-prod-acr1/xb_xbid_prod_acr-1_standard_ixe.log is successfully transferred
/xbid/logs/xbid-prod-report-tool1/rollover/xb_xbid_prod_rpt-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-prod-report-tool1/xb_xbid_prod_rpt-1_standard_ixe.log is successfully transferred
xbprodsla1 is completed
/xbid/logs/xbid-prod-acr2/xb_xbid_prod_acr-2_standard_hau.log is successfully transferred
/xbid/logs/xbid-prod-acr2/rollover/xb_xbid_prod_acr-2_standard_hau_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-prod-report-tool2/xb_xbid_prod_rpt-2_standard_hau.log is successfully transferred
/xbid/logs/xbid-prod-report-tool2/rollover/xb_xbid_prod_rpt-2_standard_hau_0_2020-11-08.log.gz already transferred
xbprodsla2 is completed
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-prod-ams1/xb_xbid_prod_xbams-1_standard_ixe.log is successfully transferred
xbprodams1 is completed
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-08.log.gz already transferred
/xbid/logs/xbid-prod-ams2/xb_xbid_prod_xbams-2_standard_hau.log is successfully transferred
xbprodams2 is completed
{code}

will investigate to put the missing logs to kibana as well.","10/Nov/20 12:11;cs687;added the components to ams, acr, amr to */opt/ebsm/properties/Logfile.properties*","10/Nov/20 12:48;cs687;deployed filebeat for acr1/2 and report-tool1/2 on both hosts xbsimusla1/2
{code:java}
[root@xbsimusla1 filebeat.d]# ll                                        
total 12                                                                
-rw-r--r-- 1 beat beat 579 Nov 10 12:37 xb-xbid-simu-acr1.yml           
-rw-r--r-- 1 beat beat 579 Nov 10 12:55 xb-xbid-simu-amr1.yml           
-rw-r--r-- 1 beat beat 603 Nov 10 12:47 xb-xbid-simu-report-tool1.yml   

[root@xbsimusla2 filebeat.d]# ll
total 12
-rw-r--r-- 1 beat beat 578 Nov 10 12:37 xb-xbid-simu-acr2.yml
-rw-r--r-- 1 beat beat 578 Nov 10 12:55 xb-xbid-simu-amr2.yml
-rw-r--r-- 1 beat beat 602 Nov 10 12:47 xb-xbid-simu-report-tool2.yml
{code}


","10/Nov/20 13:21;cs687;done

also stopped amr1 on xbsimusla2 and corrected it in the inventory 
that on xbsimusla2 amr2 is running! 

later on xbsimusla1 has an instance amr1 im-place",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBAMS monitoring - no calls in the middle of the night?,XP-4044,102124,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ll664,ll664,26/Oct/20 13:24,08/Dec/20 12:54,22/Feb/21 13:26,07/Dec/20 23:34,,,,,,,,,,goodForTraining,Monitoring,TechOps,,"There was a discussion in #xbid_emergency that AMS uses Vault, which is not HA and would report DOWN if Vault is not accessible.

Subsequently, alert would be triggered and call ops. This might not be necessary, as AMS problems could be solved during business hours and not necessarily during night for instance.

Should we do something about it?

Hints: 
 * *AMS instanced are already being monitored*
 * Do not trigger alert as a call 
 * Slack alert in xbid_alerts_prod  is the way
 * steps needed: 
 ** check the inventory
 ** check the deployment of service (what ports are needed)
 ** check the monitoring deployment client if it will work as it is or needs to be modified
 ** deploy it and test it",,hw120,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Deployed.,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Dec/20 23:34;hw120;Added exclude for ams instances to kapacitor xbid handler for alerting via alarmtilt.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM GUI - TSO Admin Capacity Overview Page - Contracts status verification methods,XP-4039,102066,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,hj444,hj444,23/Oct/20 13:55,21/Dec/20 15:09,22/Feb/21 13:26,21/Dec/20 09:42,,,,,,,,,,GUI,TestAutomation,,,"Prepare methods for verification of contracts status at CmmCapacityOverview page

1. Visibility for allocation
2. img - Active, Halt, ...
3. Verify Today contracts
4. Verify tomorrow contracts
5. Verify contracts status at OBH tab. - for TSO
6. Verify contracts status for Explicit Participant
",,hj444,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6307200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c3vc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),HOT Sprint 23,HOT Sprint 24 (S),HOT Christmas Sprint,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-4526-resource-managment-fix,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Dec/20 12:09;od044;I have added new method to check TSO Capacity overview.
 * class CmmCapacityOverviewPage

added new test  to demonstration 
* CmmSmokeTest 
** checkTsoAdminCapacityOverviewPageInHalt
** checkTsoAdminCapacityOverviewPageInAllocation

Note this method and test was created only for TSO Admin Capacity overview. Create new ticket for Explicit participant (XP-4248)m because the page has different element id ect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid test sytX patroni clusters are running out of connections,XP-4031,101956,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,21/Oct/20 18:10,02/Nov/20 12:57,22/Feb/21 13:26,21/Oct/20 18:55,,,3.1.2,,,,,,,Patroni,Postgresql,,,"I have noticed flapping alert in xbid_alerts channel
{quote}kapacitorAPP

xbtestpdb2 - xb - xbid - syt1 - pdb-async2 is sending postgres data.
 17:00
 xbtestpdb2 - xb - xbid - syt1 - pdb-async2 is not sending postgres data.
 17:24
 kapacitorAPP 
 xbtestpdb2 - xb - xbid - syt1 - pdb-async2 is sending postgres data.
 17:28
 xbtestpdb2 - xb - xbid - syt1 - pdb-async2 is not sending postgres data.
{quote}
I checked logs
{quote}[root@xbtestpdb2 ~]# vim /var/lib/pgsql_syt1_25106/log/postgresql-Wed.log

2020-10-21 17:58:52.794 CEST [9501] WARNING: archiving write-ahead log file ""00000004.history"" failed too many times, will try again later
 2020-10-21 17:58:55.446 CEST [46821] uapp01xbsyt1cor@xbsyt1cor (10.139.41.85) FATAL: remaining connection slots are reserved for non-replication superuser connections
 2020-10-21 17:59:05.450 CEST [46839] uapp01xbsyt1cor@xbsyt1cor (10.139.41.85) FATAL: remaining connection slots are reserved for non-replication superuser connections
 2020-10-21 17:59:15.454 CEST [46863] uapp01xbsyt1cor@xbsyt1cor (10.139.41.85) FATAL: remaining connection slots are reserved for non-replication superuser connections
 2020-10-21 17:59:25.458 CEST [46886] uapp01xbsyt1cor@xbsyt1cor (10.139.41.85) FATAL: remaining connection slots are reserved for non-replication superuser connections
{quote}
and noticed problem about not enough connections left.

I checked status on existing syt1 and syt3 patroni clusters
{code:java}
-bash-4.2$ for i in 106 206 007 108 208; do psql -p 25$i -c ""select current_setting('max_connections');"";done
 current_setting
-----------------
 300
(1 row) current_setting
-----------------
 300
(1 row) current_setting
-----------------
 250
(1 row) current_setting
-----------------
 300
(1 row) current_setting
-----------------
 300
(1 row)
{code}
Then I decided to increase max_connections it to 300
{code:java}
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1async/config.yml edit-config xbsyt1async --pg max_connections=300
---
+++
@@ -16,6 +16,7 @@
     log_min_duration_statement: 5000
     log_temp_files: 10000
     maintenance_work_mem: 320MB
+    max_connections: 300
     max_wal_size: 2GB
     pg_stat_statements.track: all
     shared_buffers: 1001MBApply these changes? [y/N]: y
Configuration changed
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml edit-config xbsyt1sync --pg max_connections=300
---
+++
@@ -16,6 +16,7 @@
     log_min_duration_statement: 5000
     log_temp_files: 10000
     maintenance_work_mem: 320MB
+    max_connections: 300
     max_wal_size: 2GB
     pg_stat_statements.track: all
     shared_buffers: 1001MBApply these changes? [y/N]: y
Configuration changed

[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt3async/config.yml edit-config xbsyt3async --pg max_connections=300
---
+++
@@ -16,6 +16,7 @@
     log_min_duration_statement: 5000
     log_temp_files: 10000
     maintenance_work_mem: 320MB
+    max_connections: 300
     max_wal_size: 2GB
     pg_stat_statements.track: all
     shared_buffers: 1001MBApply these changes? [y/N]: y
Configuration changed
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt3sync/config.yml edit-config xbsyt3sync --pg max_connections=300
---
+++
@@ -16,6 +16,7 @@
     log_min_duration_statement: 5000
     log_temp_files: 10000
     maintenance_work_mem: 320MB
+    max_connections: 300
     max_wal_size: 2GB
     pg_stat_statements.track: all
     shared_buffers: 24043MBApply these changes? [y/N]: y
Configuration changed
{code}
And applied by cluster restart
{code:java}
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1async/config.yml restart xbsyt1async
When should the restart take place (e.g. 2020-10-21T19:07)  [now]:
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
|   Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB | Pending restart |
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
| xbsyt1async | xbtestpdb1 | 10.139.40.225:25106 |        | running |  4 |         0 |        *        |
| xbsyt1async | xbtestpdb2 | 10.139.40.224:25106 | Leader | running |  4 |         0 |        *        |
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
Are you sure you want to restart members xbtestpdb1, xbtestpdb2? [y/N]: y
Restart if the PostgreSQL version is less than provided (e.g. 9.5.2)  []:
Success: restart on member xbtestpdb1
Success: restart on member xbtestpdb2
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml restart xbsyt1sync
When should the restart take place (e.g. 2020-10-21T19:08)  [now]:
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
|  Cluster   |   Member   |         Host        |     Role     |  State  | TL | Lag in MB | Pending restart |
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
| xbsyt1sync | xbtestpdb1 | 10.139.40.225:25206 | Sync standby | running |  4 |         0 |        *        |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224:25206 |    Leader    | running |  4 |         0 |        *        |
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
Are you sure you want to restart members xbtestpdb1, xbtestpdb2? [y/N]: y
Restart if the PostgreSQL version is less than provided (e.g. 9.5.2)  []:
Success: restart on member xbtestpdb1
Success: restart on member xbtestpdb2
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt3async/config.yml restart xbsyt3async
When should the restart take place (e.g. 2020-10-21T19:08)  [now]:
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
|   Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB | Pending restart |
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
| xbsyt3async | xbtestpdb1 | 10.139.40.225:25108 |        | running |  4 |         0 |        *        |
| xbsyt3async | xbtestpdb2 | 10.139.40.224:25108 | Leader | running |  4 |         0 |        *        |
+-------------+------------+---------------------+--------+---------+----+-----------+-----------------+
Are you sure you want to restart members xbtestpdb1, xbtestpdb2? [y/N]: y
Restart if the PostgreSQL version is less than provided (e.g. 9.5.2)  []:
Success: restart on member xbtestpdb1
Success: restart on member xbtestpdb2
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt3sync/config.yml restart xbsyt3sync
When should the restart take place (e.g. 2020-10-21T19:08)  [now]:
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
|  Cluster   |   Member   |         Host        |     Role     |  State  | TL | Lag in MB | Pending restart |
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
| xbsyt3sync | xbtestpdb1 | 10.139.40.225:25208 | Sync standby | running |  3 |         0 |        *        |
| xbsyt3sync | xbtestpdb2 | 10.139.40.224:25208 |    Leader    | running |  3 |         0 |        *        |
+------------+------------+---------------------+--------------+---------+----+-----------+-----------------+
Are you sure you want to restart members xbtestpdb1, xbtestpdb2? [y/N]: y
Restart if the PostgreSQL version is less than provided (e.g. 9.5.2)  []:
Success: restart on member xbtestpdb1
Success: restart on member xbtestpdb2
{code}
And checked if it was applied
{code:java}
-bash-4.2$ for i in 106 206 007 108 208; do psql -p 25$i -c ""select current_setting('max_connections');"";done
 current_setting
-----------------
 300
(1 row) current_setting
-----------------
 300
(1 row) current_setting
-----------------
 250
(1 row) current_setting
-----------------
 300
(1 row) current_setting
-----------------
 300
(1 row)
{code}
 And checked clusters status
{code:java}
[root@xbtestpdb2 ~]# for i in `ls /etc/patroni_*/config.yml`;do echo $i; patronictl -c $i list;done
/etc/patroni_xbsyt1async/config.yml
+-------------+------------+---------------------+--------+---------+----+-----------+
|   Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-------------+------------+---------------------+--------+---------+----+-----------+
| xbsyt1async | xbtestpdb1 | 10.139.40.225:25106 |        | running |  4 |         0 |
| xbsyt1async | xbtestpdb2 | 10.139.40.224:25106 | Leader | running |  4 |         0 |
+-------------+------------+---------------------+--------+---------+----+-----------+
/etc/patroni_xbsyt1sync/config.yml
+------------+------------+---------------------+--------------+---------+----+-----------+
|  Cluster   |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+------------+------------+---------------------+--------------+---------+----+-----------+
| xbsyt1sync | xbtestpdb1 | 10.139.40.225:25206 | Sync standby | running |  4 |         0 |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224:25206 |    Leader    | running |  4 |         0 |
+------------+------------+---------------------+--------------+---------+----+-----------+
/etc/patroni_xbsyt3async/config.yml
+-------------+------------+---------------------+--------+---------+----+-----------+
|   Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-------------+------------+---------------------+--------+---------+----+-----------+
| xbsyt3async | xbtestpdb1 | 10.139.40.225:25108 |        | running |  4 |         0 |
| xbsyt3async | xbtestpdb2 | 10.139.40.224:25108 | Leader | running |  4 |         0 |
+-------------+------------+---------------------+--------+---------+----+-----------+
/etc/patroni_xbsyt3sync/config.yml
+------------+------------+---------------------+--------------+---------+----+-----------+
|  Cluster   |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+------------+------------+---------------------+--------------+---------+----+-----------+
| xbsyt3sync | xbtestpdb1 | 10.139.40.225:25208 | Sync standby | running |  3 |           |
| xbsyt3sync | xbtestpdb2 | 10.139.40.224:25208 |    Leader    | running |  3 |         0 |
+------------+------------+---------------------+--------------+---------+----+-----------+
{code}
 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10627200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade Kapacitor Enterprise to 1.5.6,XP-4014,101846,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,20/Oct/20 14:31,02/Nov/20 12:57,22/Feb/21 13:26,20/Oct/20 14:46,,,3.1.2,,,,,,,MONITORING,,,,"Upgrade kapacitor enterprise from 1.5.4 to 1.5.6 to solve multiple bugs

[https://github.com/influxdata/kapacitor/blob/master/CHANGELOG.md]

but mainly division by zero problem.

Update version in the inventory https://github.deutsche-boerse.de/dev/energy.monitoring/blob/master/ansible/roles/kapacitor-enterprise/defaults/main.yml#L24

 
{code:java}
ssh ec2-user@rollout-automation-prod.energy.svc.dbgcloud.io
sudo su - ansible
cd ~/git/energy.monitoring/ansible
git pull
ANSIBLE_CONFIG=ansible_aws.cfg ansible-playbook playbooks/kapacitor-enterprise.yml -i inventory/aws/svc

Check kapacitor nodes if they are ok.


{code}
 

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10713600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btjb:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Oct/20 14:44;hw120;Upgrade it done, kapacitor cluster is running fine.
{code:java}
[root@ip-10-115-78-115 ~]# kapacitor -skipVerify -url https://localhost:9092 version
Kapacitor Enterprise 1.5.6 (git: master d6b1e68c8efe795aa1ca3a68349d87a6ac3704e2)
[root@ip-10-115-78-115 ~]# kapacitorctl -skipVerify -url https://localhost:9092 member list
State: initialized
Cluster ID: f3ae8f8d-aba7-4d24-9fdf-0f2c6ad05f61
Local Member ID: 33eb8f91-2bf9-4b3c-82f3-24b0a14ad244
Member ID                               Gossip Address     RPC Address        API Address        Roles  Status
33eb8f91-2bf9-4b3c-82f3-24b0a14ad244    10.115.78.115:9090 10.115.78.115:9091 10.115.78.115:9092 worker alive
b300901d-9074-46d2-9572-c8334cfe91f2    10.115.92.175:9090 10.115.92.175:9091 10.115.92.175:9092 worker alive
[root@ip-10-115-78-115 ~]# kapacitor -skipVerify -url https://localhost:9092 list topic-handlers |wc -l
560
[root@ip-10-115-78-115 ~]# kapacitor -skipVerify -url https://localhost:9092 list tasks |wc -l
133

[root@ip-10-115-92-175 ~]# kapacitor -skipVerify -url https://localhost:9092 version
Kapacitor Enterprise 1.5.6 (git: master d6b1e68c8efe795aa1ca3a68349d87a6ac3704e2)
[root@ip-10-115-92-175 ~]# kapacitorctl -skipVerify -url https://localhost:9092 member list
State: initialized
Cluster ID: f3ae8f8d-aba7-4d24-9fdf-0f2c6ad05f61
Local Member ID: b300901d-9074-46d2-9572-c8334cfe91f2
Member ID                               Gossip Address     RPC Address        API Address        Roles  Status
33eb8f91-2bf9-4b3c-82f3-24b0a14ad244    10.115.78.115:9090 10.115.78.115:9091 10.115.78.115:9092 worker alive
b300901d-9074-46d2-9572-c8334cfe91f2    10.115.92.175:9090 10.115.92.175:9091 10.115.92.175:9092 worker alive
[root@ip-10-115-92-175 ~]# kapacitor -skipVerify -url https://localhost:9092 list topic-handlers |wc -l
560
[root@ip-10-115-92-175 ~]# kapacitor -skipVerify -url https://localhost:9092 list tasks |wc -l
133

# Logs seems to be clean
tail -f /var/log/kapacitor/kapacitor.log
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update AIP100 Software Architecture (Deadline 30/10),XP-4011,101823,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,qm925,qm925,20/Oct/20 10:34,04/Dec/20 10:59,22/Feb/21 13:26,04/Dec/20 10:59,,,3.2.x,,,,,,30/Oct/20 00:00,,,,,"h1. {color:#00875a}Value: Updated list of Open Source SW{color}
h2. Current Situation

As part of the 6th Amendment to the XBID MSA, DBAG needs to update the list of all open source software and their latest versions which will be in production after 3.1 deployment there. 
h2. Proposed solution 

Check the document AIP100 (The document for the update can be found on SharePoint *[here|https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/04%20XBID%20Legal%20Framework/01%20XBID%20Contracts%20and%20Change%20Requests/6th%20Amendment%20XBID%20MSA])*, check Open Srouce software currently in production together with planned 3.1 changes and summarize it so we can update AIP100. 

Deadline for completing this task *30/10/2020*

 

*Hint:* head to chapter 4.1 
h2. Acceptance criteria 
 * List of Open Source SW reflecting state after 3.1 deployment
 * Enriched list in case any open source SW is missing. 
 * list of open source with versions provided in this ticket so ACM ([~qm925]) can incorporate it to Amendment 6 of our contract. ",,ju827,qm925,rehapav,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10540800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bug0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/20 09:19;rehapav;The actual value in AIP100/4.1:

 

Apache HTTP Server 2.4

Apache Tomcat 8.5.35

Java Runtime Environment 1.8

Red Hat Directory Server 9.1

Postfix Mail Server 2.10.1

PostgreSQL v9.5

RabbitMQ 3.7.7

Red Hat Enterprise Linux Server release 7.5 (Maipo)

 

 

Updated 

Apache HTTP Server *2.4*

Apache Tomcat *8.5.57* 

Java Runtime Environment *1.8*

Red Hat Directory Server 9.1 *?*

Postfix Mail Server *2.10.1*

PostgreSQL *v12.4*

RabbitMQ *3.8.5*

Red Hat Enterprise Linux Server release *7.8*

 

[~sw455] [~ei349] [~qm925]

In order to change XBID contract to give us more breathing space,

*I suggest changing the approach redefine chapter as follows:*

In the table in chapter

4.1 Software requirements

leave only the following (removed items are part of RedHat distribution anyway)

 

Apache HTTP Server 2.4 or newer

Apache Tomcat 8.5 or newer

Java Runtime Environment 1.8 or newer

PostgreSQL v12 or newer

RabbitMQ 3.8 or newer

Red Hat Enterprise Linux Server release 7.8 or newer","22/Oct/20 12:45;qm925;[~rehapav], is this the complete list of major open source SW which we are currently using in XBID? I see at least two which are missing - Erlang and Java, probably there are more. 

Could you please double-check and update the list accordingly?

Also, I wouldn't advise to combine the RedHat items they refer to different things and have different versions.

 ","22/Oct/20 15:31;rehapav;[~qm925],

 I used as the input the only table from chapter 4.1 Software requirements, do not recommend to enrich the list for a single item, but focus on removal to the minor version reference from the contract.

 

ad 1) Erlang is not mentioned there and I do not recommend including this in the document.

Contrary we must remove (from customer perspective irrelevant) item that holds us back from upgrading 3rd party components without lengthy negotiations with clients.

ad 2) Java = Java Runtime Environment 

ad 3)

I removed on purpose:

Red Hat Directory Server 9.1 

Postfix Mail Server *2.10.1*

We do not even specify these internally during the deployments, we do not control versions of those. They simply come with Red Hat installation package.

I recommend also replacement the sentence 

"" Changes in the underlying software components are subject to Change Management Procedure.""

by

"" Changes in the underlying software components will be announced as a mandatory part of the major release and are not subject to Change Management Procedures.""","23/Oct/20 10:34;rehapav;Apache HTTP Server *2.4*

Apache Tomcat *8.5.57* 

Java Runtime Environment *1.8*

{color:#de350b}Red Hat Directory Server *1.3*{color}

{color:#de350b}Postfix Mail Server *2.10.1*{color}

PostgreSQL *v12.4*

RabbitMQ *3.8.5*

Red Hat Enterprise Linux Server release *7.8*

Erlang *22.1*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create s3 bucket with web access as a replacement of internal test comtrader web pages,XP-4009,101786,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cv179,eg288,eg288,19/Oct/20 16:43,02/Nov/20 12:57,22/Feb/21 13:26,23/Oct/20 14:45,,,3.1.2,,ComTrader,,,,23/Oct/20 00:00,,,,,"Original comtrader web pages for internal test envs (sytX, dst, perf) are going to be decommissioned soon.

The selected replacement is S3 bucket with CloudFront in front. The expected url is https://m7trading-internaltest.deutsche-boerse.com/

Please implement.

The same approach has been already implemented for customer facing envs where the s3 bucket is named s3-dbg-m7-customer-portal-fbsimu and the content is available on url https://m7trading-test.deutsche-boerse.com/xxx.

",,eg288,zs244,,,,,,,,,,,,,,,,,,,XP-3955,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10454400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3456,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bu7s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/20 14:45;eg288;implemented 
* aws S3 bucket:: s3-dbg-m7-customer-portal-fbtest
* public internet access via CloudFront with url: https://xbid-ct-internal.energy.prod.deutsche-boerse.cloud/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fixing problem for XBID Perf haproxy and web instances,XP-4008,101772,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,cs687,iv732,iv732,19/Oct/20 11:22,02/Nov/20 12:57,22/Feb/21 13:26,22/Oct/20 14:36,,,3.1.2,,,,,,,,,,,"This is related to the ticket:  https://jira.deutsche-boerse.com/browse/SYSENG-258

After SysEng recreated the VMs, we need to redeploy the instances.",,cs687,iv732,zs244,,,,,,,,,,,,,,,,,,SYSENGINT-38,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"redeployed rabbitmq and checked with jenkins job if the env is running 
*perf check_if_running*",,,,,,,,,,,,,,10540800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ax46:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,done,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Oct/20 17:59;iv732;* Restarted all web instances
 * As the host xbperfssl1 is cloned from xbperfssl2 (by Lambert), so the directory xbid-perf-haproxy2 is there. Already removed it.

TO DO:
 * According to Jiri Kuchta, these haproxy instances are not deployed separately but together with the rabbitmq deployment --> needs to redeploy perf rabbitmq.

 ","22/Oct/20 11:37;cs687;Rabbitmq Re-deployed with Jenkins Job *Pipeline XBID Ansible deploy full*

{code:java}
[rabbitmq@xbperfimq2 xbid]$ rabbitmqctl cluster_status
Cluster status of node xbid-perf-int-amq2@xbperfimq2 ...
Basics

Cluster name: xbid-perf-int-amq2@xbperfimq2.deutsche-boerse.de

Disk Nodes

xbid-perf-int-amq2@xbperfimq2
xbid-perf-int-amq4@xbperfimq4
xbid-perf-int-amq6@xbperfimq6

Running Nodes

xbid-perf-int-amq2@xbperfimq2
xbid-perf-int-amq4@xbperfimq4
xbid-perf-int-amq6@xbperfimq6

Versions

xbid-perf-int-amq2@xbperfimq2: RabbitMQ 3.8.5 on Erlang 22.1
xbid-perf-int-amq4@xbperfimq4: RabbitMQ 3.8.5 on Erlang 22.1
xbid-perf-int-amq6@xbperfimq6: RabbitMQ 3.8.5 on Erlang 22.1

Alarms

(none)

Network Partitions

(none)

Listeners

Node: xbid-perf-int-amq2@xbperfimq2, interface: [::], port: 53501, protocol: clustering, purpose: inter-node and CLI tool communication
Node: xbid-perf-int-amq2@xbperfimq2, interface: 0.0.0.0, port: 51501, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0
Node: xbid-perf-int-amq2@xbperfimq2, interface: 0.0.0.0, port: 52501, protocol: http, purpose: HTTP API
Node: xbid-perf-int-amq4@xbperfimq4, interface: [::], port: 53501, protocol: clustering, purpose: inter-node and CLI tool communication
Node: xbid-perf-int-amq4@xbperfimq4, interface: 0.0.0.0, port: 51501, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0
Node: xbid-perf-int-amq4@xbperfimq4, interface: 0.0.0.0, port: 52501, protocol: http, purpose: HTTP API
Node: xbid-perf-int-amq6@xbperfimq6, interface: [::], port: 53501, protocol: clustering, purpose: inter-node and CLI tool communication
Node: xbid-perf-int-amq6@xbperfimq6, interface: 0.0.0.0, port: 51501, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0
Node: xbid-perf-int-amq6@xbperfimq6, interface: 0.0.0.0, port: 52501, protocol: http, purpose: HTTP API

Feature flags

Flag: drop_unroutable_metric, state: disabled
Flag: empty_basic_get_metric, state: disabled
Flag: implicit_default_bindings, state: enabled
Flag: quorum_queue, state: enabled
Flag: virtual_host_metadata, state: enabled

rabbitmq 40696     1  0 11:29 ?        00:00:00 /bin/sh /xbid/xbid-perf-int-amq2/sbin/rabbitmq-server
{code}
","22/Oct/20 14:34;cs687;checked the env with the jenkins job -> Pipeline XBID Ansible deploy full
*Build #198 perf check_if_running (Oct 22, 2020 2:31:23 PM)*
","22/Oct/20 14:36;cs687;Ticket done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID PROD AMS cannot connect to Vault,XP-4007,101751,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,ll664,ll664,19/Oct/20 09:43,02/Nov/20 13:06,22/Feb/21 13:26,26/Oct/20 13:17,,,3.1.3,,,,,,,,,,,"David Siro:house_with_garden: 9:42 AM


 @xbid-hot guys, it seems like PROD AMS has some troubles connecting to Vault since Sunday, could you pls check that (@peter.pruchnerovic)? cheers
 [https://kibana.energy.svc.dbgcloud.io/goto/f473c2c00cafb9482dc29833c464464b]
{code:java}
October 18th 2020, 03:44:06.201
Servlet.service() for servlet [dispatcherServlet] in context with path [/ams] threw exception [Request processing failed; nested exception is org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""https://englobvault.deutsche-boerse.de:443/v1/sys/health"": Connection reset; nested exception is java.net.SocketException: Connection reset] with root cause
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465)
	at sun.security.ssl.InputRecord.read(InputRecord.java:503)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1395)
	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1379)
{code}


Please check, what AMS {{health}} endpoint says and why we didn't have any alert in #xbid_prod_alerts",,cs687,hw120,ll664,qo794,yn731,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4044,XP-3903,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"monitoring deployed, handled by Peter P. some days ago.  ",,,,,,,,,,,,,,10281600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bt42:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Oct/20 10:29;hw120;I could see in chronograf application status as 500 instead of 1, we should test why we got that number. Maybe the application was misbehaving and our parsing script was not able to deal with it.

[https://chronograf.energy.svc.dbgcloud.io/sources/3/chronograf/data-explorer?query=SELECT%20mean%28%22status%22%29%20AS%20%22mean_status%22%20FROM%20%22metrics_xbid%22.%22autogen%22.%22status_exec%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A%20AND%20%22client_environment%22%3D%27prod%27%20AND%20%22instance%22%3D%27ams1%27%20GROUP%20BY%20time%28%3Ainterval%3A%29%20FILL%28null%29]

 ","26/Oct/20 11:49;cs687;[~hw120], [~ll664] confirmed that Vault was simply down during that time. 
At least the monitoring/alerting part should work, i will check that why we had no message in the proper channel #xbid_alerts. 
","26/Oct/20 13:17;cs687;Reason: monitoring was not deployed during that time for this app. 
All is deployed in a proper way and it should work for the future. 

In future we should follow the process in case new app´s will be onboarded to deploy asap the monitoring clients as well to avoid such of this situation. 
ticket can be closed. ","26/Oct/20 13:17;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: This cert will expire soon: CN=xbprod-spm/emailAddress=xbprod-spm@xbid.deutsche-boerse.com,XP-4006,101720,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yn731,yn731,yn731,16/Oct/20 16:07,08/Dec/20 13:04,22/Feb/21 13:26,08/Dec/20 10:47,,,,,,,,,,BizOps,TechOps,,,bf0f37ba-cd68-4e90-b81b-de62c439cda1-1602657118340,,iv732,ub113,yn731,,,,,,,,,,,,,,,,,,,,,SERVICE-8457,,,,,,,,,,,,XP-4123,,,,,,,"05/Nov/20 17:04;iv732;xbprod-spm.crt;https://jira.deutsche-boerse.com/secure/attachment/89462/xbprod-spm.crt","02/Nov/20 11:33;iv732;xbprod-spm.p12;https://jira.deutsche-boerse.com/secure/attachment/89307/xbprod-spm.p12",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6566400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hyo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/20 16:07;yn731;[~iv732] could you take a look at this one?

 ","16/Oct/20 16:33;iv732;[~yn731] I see that it will expire on:  12/12/2020 6:31:58 PM CET

Will prepare the request.","19/Oct/20 08:41;yn731;Thanks [~iv732]. What type of certificate it is? What does it take to replace it?","19/Oct/20 08:43;iv732;[~yn731] it is SMIME cert, for email. We need to contact CustomerAdmin","02/Nov/20 11:33;iv732;New cert arrived (attached here)
Password: crXSx3qg","02/Nov/20 15:52;iv732;Updated the keystore in github, keep the same old password:

https://github.deutsche-boerse.de/dev-confidential/energy-mkt-production/tree/master/mail_keystore/xbid/prod","04/Nov/20 09:25;iv732;[~yn731] to save the time and keep it safe, I would recommend that we only replace the keystores directly on the hosts and then restart the instances.
A full redeployment of such instances takes much more time and can lead to a failure, because XBID Prod is not migrated to Ansible, and the current inventory maybe not 100% correct","04/Nov/20 15:14;yn731;Hello [~iv732]

Unfortunately,  I need more details. Like:
 * The time required of downtime of the SPM.
 * Impact for users after the certificates are replaced. ","05/Nov/20 12:13;yn731;Hi [~iv732]

You didn't provide me here the analysis yet. You did only for CMI in XP-4005

{quote}

Unfortunately,  I need more details. Like:
 * The time required of downtime of the SPM.
 * Impact for users after the certificates are replaced. 

{quote}","05/Nov/20 12:27;iv732;[~yn731] sorry, I thought because they are similar so I only updated the other ticket.
The details are exactly the same.","05/Nov/20 17:04;iv732;[~yn731] please send customer the public cert below:

 [^xbprod-spm.crt] ","08/Dec/20 10:47;yn731;The new certs are imported to keystored and uploaded to the hosts.

The restarting will be done with SERVICE-9060 ",,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: This cert will expire soon: CN=xbprod-cmi/emailAddress=xbprod-cmi@xbid.deutsche-boerse.com,XP-4005,101719,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,yn731,yn731,16/Oct/20 16:04,08/Dec/20 13:05,22/Feb/21 13:26,03/Dec/20 10:20,,,,,,,,,,BizOps,TechOps,waiting-customer,,548b3263-1e90-4f5a-b609-ccf674499ab4-1602657118177,,iv732,oh856,ub113,yn731,,,,,,,,,,,,,,,,,,,,SERVICE-8456,,,,,,,,,,,,XP-4123,,,,,,,"05/Nov/20 17:06;iv732;xbprod-cmi.crt;https://jira.deutsche-boerse.com/secure/attachment/89464/xbprod-cmi.crt","02/Nov/20 11:31;iv732;xbprod-cmi.p12;https://jira.deutsche-boerse.com/secure/attachment/89306/xbprod-cmi.p12",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6998400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000hyc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/20 16:05;yn731;[~iv732] could you take a look at this one?

 

 ","19/Oct/20 09:43;iv732;Request sent","02/Nov/20 11:32;iv732;New SMIMI certs are received (attached to this ticket)
Password:  k02FUxim","02/Nov/20 15:52;iv732;Updated the keystore in github, keep the same old password:

https://github.deutsche-boerse.de/dev-confidential/energy-mkt-production/tree/master/mail_keystore/xbid/prod","04/Nov/20 15:15;yn731;Hi [~iv732] I need here the same analysis that was done for XP-4006. That includes:
 * The time required of downtime of the CMI.
 * Impact for users after the certificates are replaced. ","04/Nov/20 17:02;iv732;[~yn731]
+ Downtime: 15 min
+ Impact for users: customers need to import our new public cert (which I can extract and attach here), so that they can send us encrypted emails.
My question:
+ how does customer send us encrypted emails? Do they send from their normal email client (like outlook, lotus note) or they need to import our cert into the XBID system?","05/Nov/20 17:06;iv732;[~yn731] please send customer the folowing public cert

 [^xbprod-cmi.crt] ","26/Nov/20 12:16;iv732;*The general procedure to request and deploy a new SMIME cert:*
1. Send a request per email to ""CustomerAdmin"", something similar to this:

{code:java}
From: Tuan Nguyen <Tuan.Nguyen@deutsche-boerse.com> 
Sent: Monday, October 19, 2020 8:50 AM
To: Customeradmin <customeradmin@clearstream.com>
Cc: Peter Pruchnerovic <peter.pruchnerovic@deutsche-boerse.com>; Oliver Heinsohn <oliver.heinsohn@deutsche-boerse.com>
Subject: SMIME cert renewal

The below email is classified: Internal

Hello,
could you please renew our SMIME certs below?

Certificate                                                                                                                                                                                                   Serial 

Email=xbprod-spm@xbid.deutsche-boerse.com,CN=xbprod-spm,OU=Mail,OU=XBID,OU=Energy,O=Deutsche Boerse AG,C=DE       768c055d846e5132eb6b1d99257cc185dd15042b

Thank you.
Regards,

{code}


2. Receive the new .p12 files (with certificate and private key included)
3. Import to our keystore, which is cmi.jks in case of CMI, and spm.jks in case of SPM
Those keystores are currently stored under: energy-mkt-production for those environments, which are still deployed with Perl, else in vault.
To do this, we can use keytool command line or Keystore Explorer GUI tool.
IMPORTANT: update both the certificate and password for the private key
4. Redeploy the instance.

In some special cases, where we just want to replace the keystore and restart the instances instead of redeploying, we need to be sure that the password for the private key must be the same as the one that is in used by the instances (in the .properties file). It is easily done with the Keystore Explorer Tool
","26/Nov/20 12:32;iv732;The actual steps done for this ticket particularly, in order to upload the keystores to the tomcat hosts:


{code:java}
Check:

ansible 'xb-xbid-prod-cmi?' -m shell -a ""ls -al {{ instance_directory }}/tomcat/lib/cmi.jks"" -b -k -K
ansible 'xb-xbid-prod-smi?:xb-xbid-prod-smc?' -m shell -a ""ls -al {{ instance_directory }}/tomcat/lib/spm.jks"" -b -k -K


Copy:

cd energy.automation.deployments/energy-mkt-production/mail_keystore/xbid/prod
cp energy.automation.deployments/energy-mkt-production/mail_keystore/xbid/prod/cmi/cmi.jks /tmp/cmi.jks
cp energy.automation.deployments/energy-mkt-production/mail_keystore/xbid/prod/smc/spm.jks /tmp/spm.jks

ansible 'xb-xbid-prod-cmi?' -m copy -a ""src=/tmp/cmi.jks dest={{ instance_directory }}/tomcat/lib/cmi.jks owner=tomcat group=tomcat mode=0664"" -b -k -K
ansible 'xb-xbid-prod-smi?:xb-xbid-prod-smc?' -m copy -a ""src=/tmp/spm.jks dest={{ instance_directory }}/tomcat/lib/spm.jks owner=tomcat group=tomcat mode=0664"" -b -k -K
{code}
","03/Dec/20 10:20;iv732;The new certs are imported to keystored and uploaded to the hosts.

The restarting will be done with SERVICE-9060 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clean up CMM's ReportCreator and its implementations,XP-4003,101713,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ll664,ll664,16/Oct/20 14:49,06/Nov/20 16:32,22/Feb/21 13:26,06/Nov/20 16:32,,,3.2.x,,,,,,,,,,,"Cleanup/refactor the code, it looks quite messy:
 * remove {{BaseReportCreator#doCreateReport}}, the method is used only in tests for {{CmmIntegReportCreator}}, and could be moved into {{createStreamedReport}} {{LocalReportCreator}}
 * check for other imporvements`",,hj444,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9244800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:ui",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Oct/20 13:20;hj444;Improvement : Validation messages inconsistency
see : XP-3907
h5. TSO Admin > 6month => 6 month validation
set start date : 2.3.2020
set end date : 22.10.2020
(also 22.4.2020+22.10.2020 => 6 month validation)
Message Report : Report can only be created for a period of up to 6 months.
ATC Values Report: Unexpected state : Report can only be created for a period of up to 6 months.
Activity Report : Unexpected state : Report can only be created for a period of up to 6 months.
{color:blue}_Inconsistency in validation messages._{color}

h5. Explicit participant > 2days => validations 
set start date : 18.10.2020 or 19.10.2020
set end date : 21.10.2020

Message Reports: Report can only be created for a period of up to 2 days.
Allocated Capacity Report:
Unexpected state : Report can only be created for a period of up to 2 days.
{color:blue}_Inconsistency in validation messages._{color}","04/Nov/20 14:44;ll664;Merged to {{develop}}. Please test:

* Shakedown of CMM report feature
* Error message consistency - see Janette's comment","06/Nov/20 16:09;tr866;Tested on docker with version XB R3.2.0-SNAPSHOT (Build ee7c28e84d44d06ff1ac9780bc71586d01058c8f)
h2. TSO Admin
h3. 1. start date > end date
set start date : 07.11.2020
set end date : 04.11.2020
 # Message report
 # ATC Values Report...
 # Activity Report

Result: Download not possible for all 3 reports with same error message. (/)
Error message: *{color:#de350b}Start Date cannot be after End Date.{color}*
h3. 2. start date < end date, end date to future(>tomorrow date):
set start date : 05.11.2020
set end date : 08.11.2020
 # Message report
 # ATC Values Report
 # Activity Report

Result: Download not possible for all 3 reports with same error message. (/)
Error message: *{color:#de350b}Can not generate reports for the future.{color}*
h3. 3. start date = end date = tomorrow
set start date : 07.11.2020
set end date : 07.11.2020
 # Message report
 # ATC Values Report
 # Activity Report

Result: Download possible for all 3 reports (/)
h3. 4. end data - start date > 6month
set start date : 07.05.2020
set end date : 07.11.2020
 # Message report
 # ATC Values Report
 # Activity Report

Result: Download not possible for all 3 reports with the same error message. (/) Messages consistent for all 3 reports. (/)
Error message: *{color:#DE350B}Report can only be created for a period of up to 6 months.{color}*
_Note: for dates 08.05.2020-07.11.2020 download possible for all 3 reports._
h3. 6. end date - start date = 6month
set start date : 08.5.2020
set end date : 07.11.2020
 # Message report
 # ATC Values Report
 # Activity Report

Result: Download possible for all 3 reports.

h2. Explicit participant
h3. 1. start date > end date
set start date : 07.11.2020
set end date : 06.11.2020
# Messages Report
# Allocated Capacity Report

Result: Download not possible for both reports. (/)
Error message: *{color:#DE350B}Start Date cannot be after End Date.{color}*
h3. 2. start date < end date
set start date : 06.11.2020
set end date : 07.11.2020
# Messages Report
# Allocated Capacity Report

Result: Download possible for both reports. (/)
h3. 3. end date - start date > 2days
set start date : 05.11.2020
set end date : 07.11.2020
# Messages Report
# Allocated Capacity Report

Result: Download not possible for both reports. (/) Messages for both reports consistent. (/)
Error message: *{color:#DE350B}Report can only be created for a period of up to 2 days.{color}*
h3. 4. end date - start date = 2days
set start date : 06.11.2020
set end date : 07.11.2020
# Messages Report
# Allocated Capacity Report

Result: Download possible for both reports. (/)

Ref data admin
1. start date > end date

set start date : 22.10.2020
set end date : 21.10.2020

Start Date cannot be after End Date. 

h2. Ref data admin
h3. 1. start date > end date
set start date : 07.11.2020
set end date : 06.11.2020
# Messages Report	
# ATC Values report	
# Activity Report	
# Balancing Group Report	
# User Report

Result: None of the 5 reports can be downloaded with the same error message.(/)
Error message: *{color:#DE350B}Start Date cannot be after End Date.{color}*
h3. end date in the future
start date: 07.11.2020
end date: 08.11.2020
# Messages Report	
# ATC Values report	
# Activity Report	
# Balancing Group Report	
# User Report

Result: None of the 5 reports can be downloaded with the same error message.(/)
Error message: *{color:#DE350B}Can not generate reports for the future.{color}*
h3. end date - start date > 6 months
start date: 06.05.2020
end date: 07.11.2020
# Messages Report	
# ATC Values report	
# Activity Report	
# Balancing Group Report	
# User Report

Result: None of the 5 reports can be downloaded with the same error message.(/)
Error message: *{color:#DE350B}Report can only be created for a period of up to 6 months.{color}*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbcutsrpt1 not migrated to Zulu Java,XP-4001,101706,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,cs687,qo794,qo794,16/Oct/20 13:54,02/Nov/20 12:57,22/Feb/21 13:26,23/Oct/20 09:38,,,3.1.2,,,,,,,,,,,"Zulu Java is missing on *xbcutsrpt1* (reportTool shared for all cutes)
{code:java}
[qo794@xbcutsrpt1 ~]$ java -version
java version ""1.8.0_192""
Java(TM) SE Runtime Environment (build 1.8.0_192-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode)
[qo794@xbcutsrpt1 ~]$ ls -l /opt/java/
total 4
drwxrwxr-x 8 root root 4096 21. led  2019 1.8.0_192
lrwxrwxrwx 1 root root   26 21. led  2019 default -> /etc/alternatives/java-jdk
{code}
""Migrate"" the server to use Zulu Java by default as on the other xbid servers

 

Check with SysEng or other TOs how this was done on other machines and prepare for the switch.

 

Acceptance criteria
 * installed Azul Java on *xbcutsrpt1*
 * *java -version* returns the Azul version
 * **devs informed about this update when done to perform potential follow-up actions on deployments, application or whatever needs to be updated. ",,cs687,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"* stopped java apps
* deployed zulu and removed/cleaned up oracle java 
* started java apps with ansible",,,,,,,,,,,,,,10540800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i0000009",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,see change description ,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/20 09:06;cs687;with the ticket https://jira.deutsche-boerse.com/browse/XP-3541
we found out that we have some java issues once we are deploying it via ansible 

seems like when we are starting the app with ansible user ""java: command not found"" is visible 
{code:java}
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.3.2.RELEASE)

Starting amr: Thu Oct 22 08:26:21 CEST 2020
/xbid/xbid-cute-amr1/runAMReporting.sh: line 8: java: command not found
Starting amr: Thu Oct 22 08:43:03 CEST 2020
/xbid/xbid-cute-amr1/runAMReporting.sh: line 8: java: command not found
Starting amr: Thu Oct 22 09:00:13 CEST 2020
09:00:14,160 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
09:00:14,160 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy]
{code}

the playbook looks good 
{code:java}
---
- name: Deploy XBID AM Reporting
  hosts: xbamr
  become: true
  become_user: ""tomcat""
  roles:
    - xbamr
{code}

https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/959f32db6e0b7372e6c764e269d4f484f17d93bc/playbooks/deploy_xbamr.yml

we also tried to execute a java command from jumphost with ansible user and it looks also successfully: 
{code:java}
[cs687@enprodauto1 {XB-3541 L | +1} ~/ansible/energy.automation.deployments]$ ssh ansible@xbcutsrpt1 which java
/opt/java/default/bin/java
{code}

Seems like there is a miss-configuration on the host itself 
[~qo794] we will check this issue while working on that ticket. 
","23/Oct/20 07:44;cs687;*PLAN:*

* stopping all the running tomcat instances on the host *xbcutsrpt1*
* deploying azul version ""XBID-zulu-8-8.48.0.53-1.x86_64""
* starting the tomcat instances again

instances which were running before: 
{code:java}
tomcat    73999      1  0 Oct21 ?        00:00:00 bash /xbid/xbid-ctso-amr1/runAMReporting.sh
tomcat    74001  73999  0 Oct21 ?        00:02:04 java -Xms512m -Xmx1g -DinstanceName=xbid-ctso-amr1 -jar am-reporting.jar
tomcat    77183      1  0 Oct21 ?        00:00:00 bash /xbid/xbid-lipa-amr1/runAMReporting.sh
tomcat    77185  77183  0 Oct21 ?        00:01:59 java -Xms512m -Xmx1g -DinstanceName=xbid-lipa-amr1 -jar am-reporting.jar
tomcat    79900      1  0 Oct21 ?        00:00:00 bash /xbid/xbid-lipb-amr1/runAMReporting.sh
tomcat    79902  79900  0 Oct21 ?        00:02:03 java -Xms512m -Xmx1g -DinstanceName=xbid-lipb-amr1 -jar am-reporting.jar
tomcat    85183      1  0 Oct22 ?        00:00:00 bash /xbid/xbid-cute-amr1/runAMReporting.sh
tomcat    85188  85183  0 Oct22 ?        00:01:22 java -Xms512m -Xmx1g -DinstanceName=xbid-cute-amr1 -jar am-reporting.jar
tomcat    99225      1  0 Oct19 ?        00:00:00 bash /xbid/xbid-lipa-report-tool1/runReportTool.sh
tomcat    99227  99225  0 Oct19 ?        00:04:23 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipa-report-tool1
tomcat    99228      1  0 Oct19 ?        00:00:00 bash /xbid/xbid-lipb-report-tool1/runReportTool.sh
tomcat    99229  99228  0 Oct19 ?        00:04:32 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipb-report-tool1
tomcat    99233      1  0 Oct19 ?        00:00:00 bash /xbid/xbid-ctso-report-tool1/runReportTool.sh
tomcat    99234  99233  0 Oct19 ?        00:04:36 java -jar report-tool-24-7.jar -DinstanceName=xbid-ctso-report-tool1
tomcat    99431      1  0 Oct19 ?        00:00:00 bash /xbid/xbid-cute-report-tool/runReportTool.sh
tomcat    99432  99431  8 Oct19 ?        07:49:16 java -jar report-tool-24-7.jar -DinstanceName=xbid-cute-report-tool
{code}

*ansible-playbook -l ""xbcutsrpt1"" -v -b -k -K playbooks/azul_java_install_8.48.yml*
{code:java}
Using /home/cs687/ansible/energy.azul.java.install/ansible.cfg as config file
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Migration process] ****************************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1]

TASK [Software Installation] ************************************************************************************************************************************************************************************************************************************************************************************************
changed: [xbcutsrpt1] => {""changed"": true, ""msg"": """", ""rc"": 0, ""results"": [""Loaded plugins: enabled_repos_upload, langpacks, package_upload, product-id,\n              : search-disabled-repos, subscription-manager\nResolving Dependencies\n--> Running transaction check\n---> Package XBID-zulu-8.x86_64 0:8.48.0.53-1 will be installed\n--> Processing Dependency: libasound.so.2(ALSA_0.9.0rc4)(64bit) for package: XBID-zulu-8-8.48.0.53-1.x86_64\n--> Processing Dependency: libasound.so.2(ALSA_0.9)(64bit) for package: XBID-zulu-8-8.48.0.53-1.x86_64\n--> Processing Dependency: libasound.so.2()(64bit) for package: XBID-zulu-8-8.48.0.53-1.x86_64\n--> Processing Dependency: libXtst.so.6()(64bit) for package: XBID-zulu-8-8.48.0.53-1.x86_64\n--> Running transaction check\n---> Package alsa-lib.x86_64 0:1.1.4.1-2.el7 will be installed\n---> Package libXtst.x86_64 0:1.2.3-1.el7 will be installed\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package       Arch     Version         Repository                         Size\n================================================================================\nInstalling:\n XBID-zulu-8   x86_64   8.48.0.53-1     DBG_Energy_Global_XBID-7_XBID-7   106 M\nInstalling for dependencies:\n alsa-lib      x86_64   1.1.4.1-2.el7   rhel-7-server-rpms                421 k\n libXtst       x86_64   1.2.3-1.el7     rhel-7-server-rpms                 20 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package (+2 Dependent packages)\n\nTotal download size: 107 M\nInstalled size: 155 M\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                               31 MB/s | 107 MB  00:03     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : alsa-lib-1.1.4.1-2.el7.x86_64                                1/3 \n  Installing : libXtst-1.2.3-1.el7.x86_64                                   2/3 \n  Installing : XBID-zulu-8-8.48.0.53-1.x86_64                               3/3 \nUploading Package Profile\nLoaded plugins: langpacks, product-id, subscription-manager\n  Verifying  : XBID-zulu-8-8.48.0.53-1.x86_64                               1/3 \n  Verifying  : libXtst-1.2.3-1.el7.x86_64                                   2/3 \n  Verifying  : alsa-lib-1.1.4.1-2.el7.x86_64                                3/3 \n\nInstalled:\n  XBID-zulu-8.x86_64 0:8.48.0.53-1                                              \n\nDependency Installed:\n  alsa-lib.x86_64 0:1.1.4.1-2.el7          libXtst.x86_64 0:1.2.3-1.el7         \n\nComplete!\nUploading Enabled Repositories Report\nLoaded plugins: langpacks, product-id, subscription-manager\n""]}

TASK [Software removal] *****************************************************************************************************************************************************************************************************************************************************************************************************
changed: [xbcutsrpt1] => (item=['java-1.8.0-oracle-1.8.0.141-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-jdbc-1.8.0.141-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-plugin-1.8.0.141-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x84_64', 'java-1.8.0-oracle-1.8.0.121-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-devel-1.8.0.121-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-jdbc-1.8.0.121-1jpp.1.el7_3.x86_64', 'java-1.8.0-oracle-1.8.0.111-1jpp.4.el7.x86_64', 'java-1.8.0-oracle-1.8.0.71-1jpp.1.el7.x86_64', 'java-1.8.0-oracle-devel-1.8.0.71-1jpp.1.el7.x86_64', 'java-1.8.0-oracle-plugin-1.8.0.71-1jpp.1.el7.x86_64', 'java-1.8.0-oracle-jdbc-1.8.0.71-1jpp.1.el7.x86_64', 'java-1.8.0-oracle-1.8.0.65-1jpp.3.el7_1.x86_64', 'java-1.8.0-oracle-devel-1.8.0.65-1jpp.3.el7_1.x86_64', 'java-1.8.0-oracle-jdbc-1.8.0.65-1jpp.3.el7_1.x86_64', 'SRVOPS-java-jdk-1.7.0_79-1-1.el6.x86_64', 'SRVOPS-java-jdk-1.7.0_99-1-1.el7.x86_64', 'SRVOPS-java-jdk-1.8.0_25-1-1.el6.x86_64', 'SRVOPS-java-jdk-1.8.0_65-1-1.el7.x86_64', 'SRVOPS-java-jdk-1.8.0_65-1-1.el6.x86_64', 'SRVOPS-java-jdk-1.8.0_72-1-1.el6.x86_64', 'SRVOPS-java-jdk-1.8.0_74-1-1.el6.x86_64', 'SRVOPS-java-jdk-1.8.0_192-1-1.el7.x86_64', 'SRVOPS-java-jdk-1.8.0_192-1-1.el6.x86_64']) => {""changed"": true, ""item"": [""java-1.8.0-oracle-1.8.0.141-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-jdbc-1.8.0.141-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-plugin-1.8.0.141-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x84_64"", ""java-1.8.0-oracle-1.8.0.121-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-devel-1.8.0.121-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-jdbc-1.8.0.121-1jpp.1.el7_3.x86_64"", ""java-1.8.0-oracle-1.8.0.111-1jpp.4.el7.x86_64"", ""java-1.8.0-oracle-1.8.0.71-1jpp.1.el7.x86_64"", ""java-1.8.0-oracle-devel-1.8.0.71-1jpp.1.el7.x86_64"", ""java-1.8.0-oracle-plugin-1.8.0.71-1jpp.1.el7.x86_64"", ""java-1.8.0-oracle-jdbc-1.8.0.71-1jpp.1.el7.x86_64"", ""java-1.8.0-oracle-1.8.0.65-1jpp.3.el7_1.x86_64"", ""java-1.8.0-oracle-devel-1.8.0.65-1jpp.3.el7_1.x86_64"", ""java-1.8.0-oracle-jdbc-1.8.0.65-1jpp.3.el7_1.x86_64"", ""SRVOPS-java-jdk-1.7.0_79-1-1.el6.x86_64"", ""SRVOPS-java-jdk-1.7.0_99-1-1.el7.x86_64"", ""SRVOPS-java-jdk-1.8.0_25-1-1.el6.x86_64"", ""SRVOPS-java-jdk-1.8.0_65-1-1.el7.x86_64"", ""SRVOPS-java-jdk-1.8.0_65-1-1.el6.x86_64"", ""SRVOPS-java-jdk-1.8.0_72-1-1.el6.x86_64"", ""SRVOPS-java-jdk-1.8.0_74-1-1.el6.x86_64"", ""SRVOPS-java-jdk-1.8.0_192-1-1.el7.x86_64"", ""SRVOPS-java-jdk-1.8.0_192-1-1.el6.x86_64""], ""msg"": """", ""rc"": 0, ""results"": [""java-1.8.0-oracle-1.8.0.141-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-jdbc-1.8.0.141-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-plugin-1.8.0.141-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3.x84_64 is not installed"", ""java-1.8.0-oracle-1.8.0.121-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-devel-1.8.0.121-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-jdbc-1.8.0.121-1jpp.1.el7_3.x86_64 is not installed"", ""java-1.8.0-oracle-1.8.0.111-1jpp.4.el7.x86_64 is not installed"", ""java-1.8.0-oracle-1.8.0.71-1jpp.1.el7.x86_64 is not installed"", ""java-1.8.0-oracle-devel-1.8.0.71-1jpp.1.el7.x86_64 is not installed"", ""java-1.8.0-oracle-plugin-1.8.0.71-1jpp.1.el7.x86_64 is not installed"", ""java-1.8.0-oracle-jdbc-1.8.0.71-1jpp.1.el7.x86_64 is not installed"", ""java-1.8.0-oracle-1.8.0.65-1jpp.3.el7_1.x86_64 is not installed"", ""java-1.8.0-oracle-devel-1.8.0.65-1jpp.3.el7_1.x86_64 is not installed"", ""java-1.8.0-oracle-jdbc-1.8.0.65-1jpp.3.el7_1.x86_64 is not installed"", ""SRVOPS-java-jdk-1.7.0_79-1-1.el6.x86_64 is not installed"", ""SRVOPS-java-jdk-1.7.0_99-1-1.el7.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_25-1-1.el6.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_65-1-1.el7.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_65-1-1.el6.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_72-1-1.el6.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_74-1-1.el6.x86_64 is not installed"", ""SRVOPS-java-jdk-1.8.0_192-1-1.el6.x86_64 is not installed"", ""Loaded plugins: enabled_repos_upload, langpacks, package_upload, product-id,\n              : search-disabled-repos, subscription-manager\nResolving Dependencies\n--> Running transaction check\n---> Package SRVOPS-java-jdk-1.8.0_192.x86_64 0:1-1.el7 will be erased\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                     Arch     Version   Repository                 Size\n================================================================================\nRemoving:\n SRVOPS-java-jdk-1.8.0_192   x86_64   1-1.el7   @server-ops-genoa-rh7.5   378 M\n\nTransaction Summary\n================================================================================\nRemove  1 Package\n\nInstalled size: 378 M\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Erasing    : SRVOPS-java-jdk-1.8.0_192-1-1.el7.x86_64                     1/1 \nUploading Package Profile\nLoaded plugins: langpacks, product-id, subscription-manager\n  Verifying  : SRVOPS-java-jdk-1.8.0_192-1-1.el7.x86_64                     1/1 \n\nRemoved:\n  SRVOPS-java-jdk-1.8.0_192.x86_64 0:1-1.el7                                    \n\nComplete!\nUploading Enabled Repositories Report\nLoaded plugins: langpacks, product-id, subscription-manager\n""]}

TASK [Set up alternatives management] ***************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""changed"": false}

TASK [JAVA_PATH variable definition file] ***********************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""changed"": false, ""checksum"": ""2ac5b59a89c17f5c111542ae2ad0dc9ddf1b1a89"", ""dest"": ""/etc/profile.d/java_srvops.sh"", ""gid"": 0, ""group"": ""root"", ""mode"": ""0644"", ""owner"": ""root"", ""path"": ""/etc/profile.d/java_srvops.sh"", ""size"": 133, ""state"": ""file"", ""uid"": 0}

TASK [JAVA_HOME directory base location] ************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""changed"": false, ""gid"": 0, ""group"": ""root"", ""mode"": ""0755"", ""owner"": ""root"", ""path"": ""/opt/java"", ""size"": 4096, ""state"": ""directory"", ""uid"": 0}

TASK [Symbolic link to java location] ***************************************************************************************************************************************************************************************************************************************************************************************
changed: [xbcutsrpt1] => {""changed"": true, ""dest"": ""/opt/java/default"", ""gid"": 0, ""group"": ""root"", ""mode"": ""0777"", ""owner"": ""root"", ""size"": 19, ""src"": ""/usr/lib/jvm/zulu-8"", ""state"": ""link"", ""uid"": 0}

TASK [Checking tomcat account presence] *************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""ansible_facts"": {""getent_passwd"": {""tomcat"": [""x"", ""500"", ""500"", ""Tomcat application user"", ""/home/tomcat"", ""/bin/bash""]}}, ""changed"": false}

TASK [Erase variable definition III-I] **************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""changed"": false, ""msg"": """"}

TASK [Erase variable definition IV-I] ***************************************************************************************************************************************************************************************************************************************************************************************
ok: [xbcutsrpt1] => {""changed"": false, ""msg"": """"}

TASK [Checking sslsrv account presence] *************************************************************************************************************************************************************************************************************************************************************************************
fatal: [xbcutsrpt1]: FAILED! => {""changed"": false, ""msg"": ""One or more supplied key could not be found in the database.""}
...ignoring

TASK [Erase variable definition III-II] *************************************************************************************************************************************************************************************************************************************************************************************
skipping: [xbcutsrpt1] => {""changed"": false, ""skip_reason"": ""Conditional result was False""}

TASK [Erase variable definition IV-II] **************************************************************************************************************************************************************************************************************************************************************************************
skipping: [xbcutsrpt1] => {""changed"": false, ""skip_reason"": ""Conditional result was False""}

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
xbcutsrpt1                 : ok=11   changed=3    unreachable=0    failed=0
{code}


*start the apps again:*
*ansible-playbook playbooks/deploy_xbamr.yml --limit '~.*' --inventory xb/xbid/cute --tags stop,start -k -K -b --diff -e app_version=1.0.3*
{code:java}
PLAY [Deploy XBID AM Reporting] *********************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [xb-xbid-cute-amr1]

TASK [xbamr : Show facts] ***************************************************************************************************************************************************************************************************************************************************************************************************
ok: [xb-xbid-cute-amr1] => {}

MSG:

['Required application version: 1.0.3', 'Instance dir: /xbid/xbid-cute-amr1', 'Clean DB before flyway migration: False']


TASK [xbamr : Clean crontab] ************************************************************************************************************************************************************************************************************************************************************************************************
ok: [xb-xbid-cute-amr1]

TASK [xbamr : Check if stop script exists] **********************************************************************************************************************************************************************************************************************************************************************************
ok: [xb-xbid-cute-amr1]

TASK [xbamr : Stop running application] *************************************************************************************************************************************************************************************************************************************************************************************
changed: [xb-xbid-cute-amr1]

TASK [xbamr : Start the application] ****************************************************************************************************************************************************************************************************************************************************************************************
changed: [xb-xbid-cute-amr1]

TASK [xbamr : Configure cron for daily reports generation - for testing only] ***********************************************************************************************************************************************************************************************************************************************
skipping: [xb-xbid-cute-amr1]

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
xb-xbid-cute-amr1          : ok=6    changed=2    unreachable=0    failed=0
{code}


","23/Oct/20 09:36;cs687;*after deployment:*
{code:java}
tomcat    78500      1  0 09:32 ?        00:00:00 bash /xbid/xbid-cute-amr1/runAMReporting.sh -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False
tomcat    78502  78500  4 09:32 ?        00:00:10 java -Xms512m -Xmx1g -DinstanceName=xbid-cute-amr1 -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False -jar am-reporting.jar
tomcat    78955      1  0 09:34 ?        00:00:00 bash /xbid/xbid-ctso-amr1/runAMReporting.sh -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False
tomcat    78957  78955  9 09:34 ?        00:00:10 java -Xms512m -Xmx1g -DinstanceName=xbid-ctso-amr1 -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False -jar am-reporting.jar
tomcat    79389      1  0 09:34 ?        00:00:00 bash /xbid/xbid-lipa-amr1/runAMReporting.sh -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False
tomcat    79391  79389 11 09:34 ?        00:00:10 java -Xms512m -Xmx1g -DinstanceName=xbid-lipa-amr1 -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False -jar am-reporting.jar
tomcat    79990      1  0 09:35 ?        00:00:00 bash /xbid/xbid-lipb-amr1/runAMReporting.sh -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False
tomcat    79992  79990 16 09:35 ?        00:00:11 java -Xms512m -Xmx1g -DinstanceName=xbid-lipb-amr1 -Dflyway.cleanBeforeMigrate=False -Dflyway.repairBeforeMigrate=False -jar am-reporting.jar
tomcat    80172      1  0 09:35 pts/3    00:00:00 bash /xbid/xbid-ctso-report-tool1/runReportTool.sh
tomcat    80173  80172 44 09:35 pts/3    00:00:11 java -jar report-tool-24-7.jar -DinstanceName=xbid-ctso-report-tool1
tomcat    80239      1  0 09:35 pts/3    00:00:00 bash /xbid/xbid-cute-report-tool/runReportTool.sh
tomcat    80240  80239 60 09:35 pts/3    00:00:11 java -jar report-tool-24-7.jar -DinstanceName=xbid-cute-report-tool
tomcat    80307      1  0 09:35 pts/3    00:00:00 bash /xbid/xbid-lipa-report-tool1/runReportTool.sh
tomcat    80308  80307 90 09:35 pts/3    00:00:10 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipa-report-tool1
tomcat    80384      1  0 09:36 pts/3    00:00:00 bash /xbid/xbid-lipb-report-tool1/runReportTool.sh
tomcat    80385  80384 99 09:36 pts/3    00:00:11 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipb-report-tool1
{code}
","23/Oct/20 09:38;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
perform VM power cycling - XBID (external) shared,XP-3998,101699,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ab039,rehapav,rehapav,16/Oct/20 13:40,20/Jan/21 14:48,22/Feb/21 13:26,20/Jan/21 14:48,,,,,,,,,,,,,,"Perform VM power off / power on (not reboot!) as redefined in SERVICE-8268

group 

(2) M7/XBID (internal) TEST

We identified additional VMs that needs power recycling

 
|Name|Host|Compatibility|EVC Mode|
|xbcutsctp1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbcutsedb1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsidm1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsntp1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutspmi1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsrep1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbmplsssl1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbmplsweb1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbpoc2mon1|fresxegy1007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbpoc2pgl1|fresxegy1010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbpoc2pgl2|fresxegy2010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbtestdbr1|fresxegy1008.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbtestldp1|fresxegy1008.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbtestldp2|fresxegy2010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbtinfclt1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|

 

 todo
 * review above provided list and confirm that ALL VMs are internal test only
 * plan and execute power recycling (TO+Syseng)

implementation team
 * power off can be done by xbid-techops, power on (and checking VM parameters) should be done by SysEng
 * restooring services then by xbid-techops",,rehapav,,,,,,,,,,,,,,,,,,,,,,,XP-3997,,,,,,,,,,,,SERVICE-8268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3628800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0by6w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/20 10:01;rehapav;[@Ramiro.Fafian|https://dbg-devops.slack.com/team/UK3BFPMRP] [@Serhii Botulinskyi|https://dbg-devops.slack.com/team/UGB0DMZC7] there are 3 internal tickets * cutes/lips VM recycling - environment specific VMs https://jira.deutsche-boerse.com/browse/XP-3997
 * cutes/lips VM recycling - shared VMs https://jira.deutsche-boerse.com/browse/XP-3998
 * internal test environemts - VMs that were not identified during last power recyling https://jira.deutsche-boerse.com/browse/XP-3995

From my point of view not much needs to be done # Agree with XBOPs that they have capacity in week 4-8/1 to perform this power off power on and staring up environments
 # Get confirmation from product team they can support starting up environments
 # Inform clients that during this week we will be performing technical maintenance on our environments and these will be rebooted one by one
 # execute","11/Jan/21 10:09;rehapav;[~ab039] this ticket should be closed - all should have been done on 8/1

?

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
perform VM power cycling - XBID (external) CUTEs/LIPs,XP-3997,101697,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ab039,rehapav,rehapav,16/Oct/20 13:38,21/Jan/21 10:15,22/Feb/21 13:26,21/Jan/21 10:15,,,,,,,,,,,,,,"Good to join with XP-3998. 

Perform VM power off / power on (not reboot!) as redefined in SERVICE-8268

group 

(2) M7/XBID (internal) TEST

We identified additional VMs that needs power recycling

 
|Name|Host|Compatibility|EVC Mode|
|xbctpaamq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpacor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpadow1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpaenq1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpbamq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpbcor1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpbdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpbenq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpcamq1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpccor1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpcdow1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpcenq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpdamq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpdcor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpddow1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpdenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpeamq1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpecor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpedow1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpeenq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctpfamq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfcor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfdow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpfenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgamq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgcor1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpgdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpgenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphamq1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphcor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphdow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctphenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpiamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpicor1|fresxegy1007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpidow1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpienq1|fresxegy1010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjcor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpjdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctpjenq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctpkamq1|fresxegy2007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpkcor1|fresxegy2010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Broadwell"" Generation|
|xbctpkdow1|fresxegy2008.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpkenq1|fresxegy2007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplamq1|fresxegy1010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplcor1|fresxegy1007.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpldow1|fresxegy1008.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctplenq1|fresxegy1010.deutsche-boerse.de|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|
|xbctpmcor1|fresxegy2007.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbctpmenq1|fresxegy2009.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbctsoamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbctsocor1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbctsodow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctsoecp1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbctsoenq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcuteamq1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutecor1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xbcutedow1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcuteecp1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcuteenq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipaamq1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipacor1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipadow1|fresxegy1009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipaecp1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipaenq1|fresxegy1008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipbamq1|fresxegy2008.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipbcor1|fresxegy2010.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|
|xblipbdow1|fresxegy2007.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipbecp1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xblipbenq1|fresxegy2009.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|

 

 todo
 * review above provided list and confirm that ALL VMs are internal test only
 * plan and execute power recycling (TO+Syseng)

implementation team
 * power off can be done by xbid-techops, power on (and checking VM parameters) should be done by SysEng
 * restooring services then by xbid-techops",,rehapav,,,,,,,,,,,,,,,,,,,,,,,XP-3995,,,,,,,,,,,,SERVICE-8268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3628800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0by6o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/20 10:01;rehapav;[@Ramiro.Fafian|https://dbg-devops.slack.com/team/UK3BFPMRP] [@Serhii Botulinskyi|https://dbg-devops.slack.com/team/UGB0DMZC7] there are 3 internal tickets * cutes/lips VM recycling - environment specific VMs https://jira.deutsche-boerse.com/browse/XP-3997
 * cutes/lips VM recycling - shared VMs https://jira.deutsche-boerse.com/browse/XP-3998
 * internal test environemts - VMs that were not identified during last power recyling https://jira.deutsche-boerse.com/browse/XP-3995

From my point of view not much needs to be done # Agree with XBOPs that they have capacity in week 4-8/1 to perform this power off power on and staring up environments
 # Get confirmation from product team they can support starting up environments
 # Inform clients that during this week we will be performing technical maintenance on our environments and these will be rebooted one by one
 # execute","07/Dec/20 13:15;rehapav;LIPB done SERVICE-9108

LIPA done SERVICE-9007","11/Jan/21 10:07;rehapav;[~ab039] I think this one can be closed - we did all outstanding environments in week 4/1 - 8/1

?

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Align ports for spring-boot applications according to convention,XP-3996,101695,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,16/Oct/20 13:27,23/Nov/20 22:18,22/Feb/21 13:26,19/Nov/20 09:32,,,,,,,,,,,,,,"A new port convention for spring-boot applications has been introduced, see [https://github.deutsche-boerse.de/dev/xbid-tutorials/wiki/Port-Assembling]

1. It is necessary to change ports for he following applications according to the convention on all envs (syt, cutes, simu, prod):
 * Report Tool (aka SLA)
 * ACR
 * AMR
 * AMS
 * PMI Logger
 * PMI Archiver

2. Prepare also pull requests for SIMU (SERVICE-8990) and PROD (SERVICE-8458) and add links to future deployment service tickets or redeploy if possible without customers approvals and planning.


*!! Note: applications together with telegraf must be redeployed*",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8208000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bwzz:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Nov/20 08:53;qo794;SIMU - ACR, AMR, AMS, report-tool, (pmi-logger and pmi-archiver already done):
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1234
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2375
","16/Nov/20 10:15;qo794;Other customer facing test envs: only redeployment of the affected applications and telegraf instances is needed after changes made for simulation.","16/Nov/20 16:36;qo794;SYT1 - https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2382
SYT2, 3, PERF - already fixed for pmi-logger and pmi-archiver, no other applications are  running there","18/Nov/20 16:58;qo794;PROD - https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2383, added to SERVICE-8458",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - XBID CUTE DST set real time back (backward time travel),XP-3994,101674,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,tm431,hw120,15/Oct/20 21:00,02/Nov/20 12:57,22/Feb/21 13:26,19/Oct/20 16:45,,,3.1.2,,,,,,19/Oct/20 00:00,TechOps,,,,"Detailed info in linked service ticket https://jira.deutsche-boerse.com/browse/SERVICE-8409

 

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,,,,,,,,,,,,,,Internal Deployment Request,eh941,ll664,uv683,,No,11145600,,CUTE,,,,,,dm700,lw641,ox626,rehapav,sw455,,19/Oct/20 16:32,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe PXs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID PROD Incident follow up - integer overflow,XP-3990,101646,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Fixed,qo794,ll664,ll664,15/Oct/20 13:59,03/Nov/20 15:02,22/Feb/21 13:26,30/Oct/20 16:04,,,3.2.x,,,,,,,,,,,"Follow up for PROD issue SMXBID-2168

Order history trigger call failed on integer overflow:

{code}
2020-10-15T02:23:34.708Z [Unmarshaller][][4eb984d1] TRACE c.d.e.m.t.M.incomingInfo - OrdrModify unmarshalled, Message{receivedTime=1602728614699, rabbitReceivedTime=1602728614698, appId=m7-EPEX, userId=XBEPEXX1, applicationUserId=null, messageId=null, contentEncoding=gzip, contentType=x-m7/request; version=1, messag
eSource=TRADING_PMI, replyTo=amq.gen-1Pg2BZAmbFtyIUY-NgvO5w, correlationId=[50, 48, 51, 57, 53, 57, 52, 48, 54, 57, 53, 56, 55, 54, 52, 52, 49, 95, 49], classId=null, contentClassId=null, keyClassId=null}
2020-10-15T02:23:34.708Z [Unmarshaller][][4eb984d1] TRACE c.d.e.m.t.M.incomingMessage - <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><OrdrModify xmlns=""http://www.deutsche-boerse.com/m7/v1"" ordrModType=""DELE""><StandardHeader marketId=""XSOB""/><OrdrList><Ordr ordrId=""561983712"" clOrdrId=""11022409186"" px=""396
9"" ppd=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983766"" clOrdrId=""11022409250"" px=""5197"" ppd=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983767"" clOrdrId=""11022409251"" px=""5223""
ppd=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983806"" clOrdrId=""11022409307"" px=""4342"" ppd=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983807"" clOrdrId=""11022409308"" px=""4377"" ppd
=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983808"" clOrdrId=""11022409309"" px=""4826"" ppd=""0"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/><Ordr ordrId=""561983468"" clOrdrId=""11022408881"" px=""5185"" ppd=""0
"" qty=""0"" displayQty=""0"" ordrExeRestriction=""NON"" type=""I"" validityRes=""GFS"" revisionNo=""1""/></OrdrList></OrdrModify>
2020-10-15T02:23:34.712Z [Persister][][] ERROR c.d.e.m.c.o.PersisterExceptionHandlerStrategy - Exception while executing a batch.
org.postgresql.util.PSQLException: ERROR: integer out of range
  Where: PL/pgSQL function process_cx_100_order_audit() line 4 at SQL statement
{code}


The problematic part was that we stored value of {{envers_sequence}} which yields {{bigint}} into {{REV_VAR}} variable which was {{integer}} in {{process_cx_100_order_audit}}:

{code}
create function process_cx_100_order_audit() returns trigger
    language plpgsql
as $$
DECLARE REV_VAR integer;
BEGIN
    select nextval('envers_sequence') into REV_VAR;
{code} 

This code was present in two triggers {{process_cx_100_order_audit}} / {{PROCESS_CMM_100_ALLOCATION_AUDIT}}.

We applied the fix to production DB directly. 

We should also: 

* incorporate those changes into flyway scripts - both {{acceptance}} and {{develop}} branch (see attached SQLs)
* see whether similar thing is not in the rest of triggers

",,ek176,jy268,ll664,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SMXBID-2168,,,,,,,"15/Oct/20 14:07;ll664;PROCESS_CMM_100_ALLOCATION_AUDIT.sql;https://jira.deutsche-boerse.com/secure/attachment/88660/PROCESS_CMM_100_ALLOCATION_AUDIT.sql","15/Oct/20 14:07;ll664;PROCESS_CX_100_ORDER_AUDIT.sql;https://jira.deutsche-boerse.com/secure/attachment/88661/PROCESS_CX_100_ORDER_AUDIT.sql",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9504000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:1",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Nov/20 15:01;jy268;No other trigger with vulnerability was found. Above scripts were added as part of flyway (will be executed on every env during deployment)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Failover event took place message sent with the same id during startup,XP-3989,101645,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,jy268,jy268,15/Oct/20 13:59,11/Nov/20 10:39,22/Feb/21 13:26,11/Nov/20 10:39,,,3.2.x,,Trading,,,,,,,,,"During https://jira.deutsche-boerse.com/browse/SMXBID-2173 analysis we have found that StartupTask resulting in StartupResult does not persist entities.
{code}
    private boolean isToPersist(ResponseEvent event) {
        Result result = event.getResult();
        return !(result instanceof StartupResult) || ((StartupResult) result).isToPersist();
    }
{code}

Due to that two messages were sent with the same id.
Please analyze and fix if following field should be persisted:
{code}
private StatusMessage failoverMessage;
{code}",,ek176,jy268,od044,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4115,,,,,,,SMXBID-2221,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Nov/20 12:41;jy268;Please proceed with smoke test.","10/Nov/20 12:55;jy268;Failover message is persisted in DB now so when another restart/failover occurs message is sent with higher id.","11/Nov/20 10:38;od044;Issue split into:
|XP-4115|(Split 2) Failover event took place message sent with the same id during startup - testing|
","11/Nov/20 10:39;od044;Implementation done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update xbid pipelines with new EEX artifactory,XP-3988,101643,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ek176,ek176,15/Oct/20 13:25,11/Nov/20 08:51,22/Feb/21 13:26,11/Nov/20 08:51,,,3.1.x,,,,,,,jenkins,,,,"XBID pipelines use the old artifactory (cmqaart). Switch to the new one by changing the Maven settings.

 

Current state: 23 old configurations:
{noformat}
xbid-pipeline$ grep -r MavenSettingsConfig1413814164464 |cut -d= -f2- |uniq -c

     23  'org.jenkinsci.plugins.configfiles.maven.MavenSettingsConfig1413814164464
{noformat}
See [https://github.deutsche-boerse.de/dev/xbid-pipeline/pull/112/files] for the solution. Use Inspect in Jenkins/job/maven build to obtain other values, if needed.

 

DoD:
 * All pipelines use the new artifactory
 * All pipelines are green",,eg288,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3988-all_pipelines_should_use_new_eex_artifactory,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Nov/20 16:27;eg288;all pipelines in xbid-pipeline repository uses uptodate serttings.xml EEXSettings - new artifactory only (id: 363c37d5-3718-4c0c-aa43-b2d5dd5e9492) with cloud artifactory only",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unexpected reboot of xbcuts instances,XP-3986,101630,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,hw120,hw120,15/Oct/20 10:56,02/Nov/20 12:57,22/Feb/21 13:26,15/Oct/20 12:02,,,3.1.2,,,,,,19/Oct/20 00:00,TechOps,,,,"14.10. there was accidental reboot of the following VMs

xbcutsams1
xbcutscha1
xbcutsprx1
xbcutsrpt1
xbcutsssl1
xbcutsweb1

 

We had to check them and start the instances there.

 

But xbcutsrpt1 failed to start, investigation is needed.",,hw120,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11232000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btjb:c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Oct/20 11:01;hw120;All instances started, with exception report-tool instaces running on xbcutsrpt1, which we have to fix first.

On VM xbcutsrpt1 filesystems mounted as /xbid and /xbid/logs are corrupted, I had to log in through vcenter console to that server, get root pwd from cyberark and uncomment those mounts from /etc/fstab.

Now VM started but FS are corrupted, so I have to recreate them and then redeploy report-tool instances using perl deployment job.

Next step is to deploy reporting tool only for LIPA, LIPB, CUTE, CTSO envs.","15/Oct/20 12:02;yo218;Recreated the filesystem and deployed the 4 instances

{noformat}

[tomcat@xbcutsrpt1 xbid]$ ps -fu tomcat
UID PID PPID C STIME TTY TIME CMD
tomcat 43246 43244 0 23:59 pts/1 00:00:00 -bash
tomcat 43292 1 0 23:59 pts/1 00:00:00 bash /xbid/xbid-cute-report-tool/runReportTool.sh
tomcat 43293 43292 80 23:59 pts/1 00:00:11 java -jar report-tool-24-7.jar -DinstanceName=xbid-cute-report-tool
tomcat 43364 1 0 23:59 pts/1 00:00:00 bash /xbid/xbid-ctso-report-tool1/runReportTool.sh
tomcat 43365 43364 99 23:59 pts/1 00:00:07 java -jar report-tool-24-7.jar -DinstanceName=xbid-ctso-report-tool1
tomcat 43385 1 0 23:59 pts/1 00:00:00 bash /xbid/xbid-lipa-report-tool1/runReportTool.sh
tomcat 43386 43385 84 23:59 pts/1 00:00:03 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipa-report-tool1
tomcat 43417 1 0 23:59 pts/1 00:00:00 bash /xbid/xbid-lipb-report-tool1/runReportTool.sh
tomcat 43418 43417 53 23:59 pts/1 00:00:01 java -jar report-tool-24-7.jar -DinstanceName=xbid-lipb-report-tool1
tomcat 43438 43246 0 23:59 pts/1 00:00:00 ps -fu tomcat

{noformat}","15/Oct/20 12:21;yo218;https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/41945/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failed elasticsearch data node,XP-3983,101605,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,hw120,hw120,15/Oct/20 00:02,02/Nov/20 12:57,22/Feb/21 13:26,15/Oct/20 00:40,,,3.1.2,,,,,,,Monitoring,TechOps,,,"I discovered we have a stopped elasticsearch data node

elasticsearch-data-node1.energy.svc.dbgcloud.io

In logs I have found that it stopped because of out of heap memory.

 

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11232000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btjb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,PROD,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Oct/20 00:09;hw120;Tried to start it, but it resulted in Kibana unavailability so I had to stop it.

In logs I could see it failed to discover master nodes through discovery-ec2 plugin.

I googled for the problem with no no luck to find the answer.

I played with plugin config, tried to change the proxy to proxy.core.fra.aws.dbgcloud.io instead of old default proxy.shrd.dbgcloud.io, didn't helped.

Tried to disable proxy, and then I could see in the logs that plugin was accessing aws api endpoint ec2.eu-central-1.amazonaws.com using port 80.

So I tried to change the discovery-ec2 plugin protocol from http to https
{code:java}
discovery:
  ec2:
    groups: [""sec-energy-elasticsearch-instances""]
    availability_zones:
      - eu-central-1a
      - eu-central-1b
      - eu-central-1c
#    tag.Type: ""energy-elasticsearch-cluster-data-node""
    host_type: ""private_ip""
    endpoint: ""ec2.eu-central-1.amazonaws.com""
    protocol: ""https""
    proxy:
      host: ""proxy.shrd.dbgcloud.io""
      port: ""3128""
{code}
and that one helped. Elasticsearch cluster is complete again.

So I am going to update elasticsearch template and then change it everywhere.

 

 ","15/Oct/20 00:40;hw120;Updated globally on all elasticsearch nodes

 
{code:java}
ssh ec2-user@rollout-automation-prod.energy.svc.dbgcloud.io
sudo su - ansible
cd git/energy.monitoring/ansible

2020-10-15 00:31:13 ⌚  ip-10-115-77-197 in ~/git/energy.monitoring/ansible
± |master U:1 ✗| → ANSIBLE_CONFIG=ansible_aws.cfg ansible all -i inventory/aws/svc --limit 'tag_Name_ec2_energy_svc_elasticsearch_*' -m shell -a 'grep protocol /etc/elasticsearch/elasticsearch.yml' --become -u ec2-user
10.115.108.86 | CHANGED | rc=0 >>
    protocol: ""http""10.115.80.222 | CHANGED | rc=0 >>
    protocol: ""http""10.115.79.35 | CHANGED | rc=0 >>
    protocol: ""http""10.115.92.195 | CHANGED | rc=0 >>
    protocol: ""http""10.115.95.58 | CHANGED | rc=0 >>
    protocol: ""http""10.115.81.27 | CHANGED | rc=0 >>
    protocol: ""http""10.115.74.155 | CHANGED | rc=0 >>
    protocol: ""http""10.115.81.194 | CHANGED | rc=0 >>
    protocol: ""https""10.115.79.213 | CHANGED | rc=0 >>
    protocol: ""http""10.115.71.196 | CHANGED | rc=0 >>
    protocol: ""http""10.115.76.4 | CHANGED | rc=0 >>
    protocol: ""http""10.115.100.65 | CHANGED | rc=0 >>
    protocol: ""http""10.115.70.190 | CHANGED | rc=0 >>
    protocol: ""http""10.115.95.218 | CHANGED | rc=0 >>
    protocol: ""http""

 2020-10-15 00:31:57 ⌚  ip-10-115-77-197 in ~/git/energy.monitoring/ansible
± |master U:1 ✗| → ANSIBLE_CONFIG=ansible_aws.cfg ansible all -i inventory/aws/svc --limit 'tag_Name_ec2_energy_svc_elasticsearch_*' -m shell -a 'sed -i ""s/    protocol: \""http\""/    protocol: \""https\""/g"" /etc/elasticsearch/elasticsearch.yml' --become -u ec2-user
[WARNING]: Consider using the replace, lineinfile or template module rather than running 'sed'.  If you need to use command because replace, lineinfile or template is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this message.10.115.80.222 | CHANGED | rc=0 >>
10.115.79.35 | CHANGED | rc=0 >>
10.115.95.58 | CHANGED | rc=0 >>
10.115.108.86 | CHANGED | rc=0 >>
10.115.92.195 | CHANGED | rc=0 >>
10.115.79.213 | CHANGED | rc=0 >>
10.115.74.155 | CHANGED | rc=0 >>
10.115.71.196 | CHANGED | rc=0 >>
10.115.81.194 | CHANGED | rc=0 >>
10.115.70.190 | CHANGED | rc=0 >>
10.115.95.218 | CHANGED | rc=0 >>
10.115.100.65 | CHANGED | rc=0 >>
10.115.81.27 | CHANGED | rc=0 >>
10.115.76.4 | CHANGED | rc=0 >>

 2020-10-15 00:34:35 ⌚  ip-10-115-77-197 in ~/git/energy.monitoring/ansible
± |master U:1 ✗| → ANSIBLE_CONFIG=ansible_aws.cfg ansible all -i inventory/aws/svc --limit 'tag_Name_ec2_energy_svc_elasticsearch_*' -m shell -a 'grep protocol /etc/elasticsearch/elasticsearch.yml' --become -u ec2-user
10.115.80.222 | CHANGED | rc=0 >>
    protocol: ""https""10.115.92.195 | CHANGED | rc=0 >>
    protocol: ""https""10.115.108.86 | CHANGED | rc=0 >>
    protocol: ""https""10.115.95.58 | CHANGED | rc=0 >>
    protocol: ""https""10.115.79.35 | CHANGED | rc=0 >>
    protocol: ""https""10.115.71.196 | CHANGED | rc=0 >>
    protocol: ""https""10.115.74.155 | CHANGED | rc=0 >>
    protocol: ""https""10.115.79.213 | CHANGED | rc=0 >>
    protocol: ""https""10.115.81.194 | CHANGED | rc=0 >>
    protocol: ""https""10.115.81.27 | CHANGED | rc=0 >>
    protocol: ""https""10.115.100.65 | CHANGED | rc=0 >>
    protocol: ""https""10.115.95.218 | CHANGED | rc=0 >>
    protocol: ""https""10.115.76.4 | CHANGED | rc=0 >>
    protocol: ""https""10.115.70.190 | CHANGED | rc=0 >>
    protocol: ""https""

{code}
Will not restart the services as on other nodes it is not causing any issue yet, will apply on the next restart.

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix OWASP vulnerabilities in all nightly develop builds in xbid projects,XP-3971,101550,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,14/Oct/20 12:43,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 12:44,,,3.1.2,,,,,,,,,,,Please fix all vulnerabilities found during nightly develop builds,,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bs4s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Split 1) ComTrader, TestClient and Catrina Cert expiry",XP-3968,101547,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,14/Oct/20 12:33,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 12:33,,,3.1.2,,ComTrader,,,,,,,,,"ComTrader, TestCLient and Catrina uses certificate that expires on Nov, 18 2020 12:49 CET

Filename: COMTRADER_AllNonProd_xbid-SOB.p12

Also, it is used to connect LTSs.

*Affected envs*: All

CT needs to be released.

Steps needed: 
 * techops to release new certificates
 * onboard those certificates into Comtrader
 * release new Comtrader versions (one for latest develop, one for 3.0.1 OCC files release on ind. cutes, lips, cutepx,cutetso)
 * see SERVICE-2129 how it was solved in the past
 * [~ub113], [~yn731]: inform customers as soon as possible about needed redeployment of all our Comtraders with updated cert. 
 * Discuss with [~iv732], [~hw120] if HA proxies are also needed
 * integrate those certificates into vault to prevent it's late expiration",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,split,,,,,,,,,,,,,,11318400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0i:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 19 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Sprint 1) Prepare Infrastucture (DBs) for  AM reporting tool deployment to LIPA, LIPB, CUTE, CTSO ",XP-3967,101546,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,tm431,qo794,14/Oct/20 12:29,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 12:30,,,3.1.2,,,,,,21/Oct/20 00:00,TechOps,,,,"*DECISION TAKEN after meeting*

1) AM reporting tool will be deployed into XBCUTSRPT1, where it will be stopped for all envs. (LIPA, LIPB, CUTE, CTSO) and started only for CUTE before Time Travel will happen. This will ensure that there will be AM reports on CUTE envs. generated for the future (for the time travel interval). During this time shift it will not be possible to use AM reporting on other envs. With backward time travel, we will need to delete logs and am reporting files (becouse they were generated for the future)

2) *We will need to prepare new 4 DBs* as a preparation step for AM reporting tool deployments into LIPA, LIPB, CUTE, CTSO we can already start with this

3) *We will need to check whether new FW* should be opened for AM indicator deployment. i.e. between SFTP server and XBCUTESRPT1 and i think XBCUTESRPT1 and CORs?

4) *New sftp user/s should be created.* 1) towards customers (folder) xbid_amreports_cute/am xbid_amreports_cute (lipa, lipb, ctso) and 2) some which application uses to write data, including correct ssh key

5) We can polish some running applicatins on this server, as it is meaningless to have SLA reporting running for inidividual cutees CTPA->CTPM as there is no SFTP server towards customers. So we can stop these applications:DinstanceName=xbid-*ctp*X-report-tool1  

we will leave them running for LIPA, LIPB, CTSO, CUTE

6) we can introduce Xms and Xmx for the application to avoid overloading of the server


*FORESEEN DEPLOYMENT INTO LIPB IS 29/10/2020*",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c0h",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Generate users for logging to SOB, CMM, SPM GUI",XP-3966,101543,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yn731,zi174,zi174,14/Oct/20 12:02,03/Nov/20 10:57,22/Feb/21 13:26,03/Nov/20 10:57,,,3.1.x,,,,,,02/Nov/20 00:00,BizOps,,,,"We need to create following users:

*Capacity management module (CMM) - user's email 'Harald.dunkel@syss.de'*
 Roles:
 • Reference Data Admin
 • TSO Admin
 • Explicit participant
 • File Management Admin

*Shared Order Book (SOB) + ComTrader - user's email Jürgen Zöller <juergen.zoeller@syss.de>*
 Roles:
 • Reporting
 • Exchange User – with both additional rights

• Super Admin

*Shipping Module (SM) - user's email 'Harald.dunkel@syss.de'*
 Roles:
 • TSO Admin, CCP Admin, SA Admin
 • TSO Operations, CCP Operations, SA Operations
 • Central Admin

 
h3. *After the users are created please follow XP-3960*

 ",,yn731,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3960,,,,,,,"30/Oct/20 12:30;yn731;DBAGTEST.p12;https://jira.deutsche-boerse.com/secure/attachment/89248/DBAGTEST.p12",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9590400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/20 12:29;yn731;From Slack: 
{quote}[Steffen|https://app.slack.com/team/U7BU3EE12]  [11:40 AM|https://dbg-devops.slack.com/archives/G01BLAY8M4K/p1604054436229200]
 [@Ramiro.Fafian|https://dbg-devops.slack.com/team/UK3BFPMRP] how about the client certs Ticket XP-3966
 i talked to franta and we have to make some changes in ansible playbook, ones we have the certs we could upload it to vault and could check it
{quote}
[~cs687]

Here you have the users for the purpose mentioned above.

DBAGTEST / xbidtest01!1

 

 ","30/Oct/20 12:31;yn731;[^DBAGTEST.p12]

^Cert. password:^  TjmK1CJg
 ","02/Nov/20 16:13;yn731;*CMM Users:*

XBSYSC03
 XBSYSC04
 XBSYSC05
 XBSYSC06

*SOB Users:*

XBSYSC01
 XBSYSC02
 XBSYSC07

*SPM Users:*

XBSYSM01 

XBSYSM02

XBSYSM03

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) Onboard second XLS for Security Testing ,XP-3965,101542,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ek176,od044,14/Oct/20 11:59,10/Nov/20 17:33,22/Feb/21 13:26,10/Nov/20 17:33,,,,,,,,,,,,,,"Under XP-3469, there is a new XLS that should be processed.

Todo:
 * Update tickets under XP-3469 epic to match the new XLS
 * Update [Security Testing::Confluence|http://confluence.energy.svc.dbgcloud.io/display/XBID/Security+Testing?src=contextnavpagetreemode]
 * Resolve ""Unclear points"" in XP-3469
 * Estimate/prioritize at least 2 tickets that can be planned into a new sprint",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2997,,,,,,,"14/Oct/20 12:02;od044;security-check-list-duc-v5.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88578/security-check-list-duc-v5.xlsx","30/Oct/20 13:28;hj444;security-check-list-duc-v6_20201030.xlsx;https://jira.deutsche-boerse.com/secure/attachment/89252/security-check-list-duc-v6_20201030.xlsx","02/Nov/20 15:02;od044;security-check-list-duc-v7_20201102.xlsx;https://jira.deutsche-boerse.com/secure/attachment/89323/security-check-list-duc-v7_20201102.xlsx","10/Nov/20 17:32;od044;security-check-list-duc-v8_20201110.xlsx;https://jira.deutsche-boerse.com/secure/attachment/89817/security-check-list-duc-v8_20201110.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,,,,,,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bo27:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Fix OWASP vulnerabilities in all nightly develop builds in xbid projects,XP-3964,101540,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,14/Oct/20 11:54,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 12:40,,,3.1.2,,,,,,,,,,,Please fix all vulnerabilities found during nightly develop builds,,jy268,,,,,,,,,,,,,,,,,,,,,,,XP-3949,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bsqw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SIMu restoration from backup created 29.10.2020 (to be performed on 17th November),XP-3963,101537,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,zi174,zi174,14/Oct/20 11:42,18/Nov/20 08:53,22/Feb/21 13:26,18/Nov/20 08:53,,,3.1.x,,,,,,16/Nov/20 00:00,TechOps,,,,"Please restore the simu environment from the Backup created in XP-3961 

The simulation must be with the same configuration and be ready for continuing UAT testing as well as turn off the certification check on SIMu.

*Please also, test that everything is working correctly and turn on the alarmtilt notification*",,cs687,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8990,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,steps are described in https://jira.deutsche-boerse.com/browse/SERVICE-8990,,,,,,,,,,,,,,8294400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bttb:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,.,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/20 08:53;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SIMu deployment for penetration tests (Monday 2nd November),XP-3962,101536,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,zi174,zi174,14/Oct/20 11:41,03/Nov/20 15:17,22/Feb/21 13:26,02/Nov/20 12:09,,,3.1.x,,,,,,02/Nov/20 00:00,TechOps,,,,"h2. *{color:#de350b}XP-3961 is a prerequisite for this action{color}*
 * use tosca-fake dataset
 * tick deploy with DB clean

{color:#172b4d}Please do a deployment to SIMu env, {color}

*Software version:*

PACKAGE R3.1.3
||Component||Version||Comment||
|xbid|3.1.8|New|
|spm|3.1.3|New|
|comtrader|3.1.2|*NEW WITH CERTIFICATES in SERVICE-8276 so no need to deploy any*|
|pmilogger|1.1.0|No change|
|pmiarchiving|1.0.19|No change|
|m7-xbid-report-tool|2.46|No change|
|alarmtilt-client|1.0.8|No change|
|h3. AMS|1.0.0|No change|
|h3. xbid-am-reporting|1.0.4| |
|rep-engine|5.0.56|No change|

{color:#172b4d} {color}",,cs687,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/20 12:09;cs687;final-state-deployment-xbid-simu.txt;https://jira.deutsche-boerse.com/secure/attachment/89308/final-state-deployment-xbid-simu.txt","02/Nov/20 09:54;cs687;xbid-simu021120.txt;https://jira.deutsche-boerse.com/secure/attachment/89298/xbid-simu021120.txt",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,deployed xbid-simu like mentioned in the description ,,,,,,,,,,,,,,9676800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,.,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/Oct/20 15:16;cs687;Going to deploy it with [~iv732] on Monday.","30/Oct/20 16:53;cs687;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2331 (already merged - for activation of the client certifcates) 

refer: https://jira.deutsche-boerse.com/browse/XP-3959 
Test were made in ticket above. 
","02/Nov/20 09:05;cs687;1.) merged pull-requests above!
2.) Deployment with clean-db: 

touched instances: 
* xbid
* spm
* reporting_engine
* pmi
* AMS
* AMR
* report_tool 

with the mentioned versions in the table 
","02/Nov/20 09:54;cs687;all instances are running: 
{code:java}
tomcat@xbidsimucor1:[/xbid]$ curl http://localhost:60108/m7core/health
{""status"":""UP"",""components"":{""diskSpace"":{""status"":""UP"",""details"":{""total"":[""java.lang.Long"",16095641600],""free"":[""java.lang.Long"",15300001792],""threshold"":[""java.lang.Long"",10485760],""exists"":true}},""elasticRest"":{""status"":""UP"",""details"":{""cluster_name"":""energy-svc-es-cluster-01"",""status"":""green"",""timed_out"":false,""number_of_nodes"":14,""number_of_data_nodes"":8,""active_primary_shards"":848,""active_shards"":1698,""relocating_shards"":0,""initializing_shards"":0,""unassigned_shards"":0,""delayed_unassigned_shards"":0,""number_of_pending_tasks"":0,""number_of_in_flight_fetch"":0,""task_max_waiting_in_queue_millis"":0,""active_shards_percent_as_number"":100.0}},""m7"":{""status"":""UP"",""details"":{""master"":true}},""ping"":{""status"":""UP""},""rabbit"":{""status"":""UP"",""components"":{""ackAmqpTmpl"":{""status"":""UP"",""details"":{""version"":""3.8.5""}},""eventAmqpTmpl"":{""status"":""UP"",""details"":{""version"":""3.8.5""}},""integAmqpTemplate"":{""status"":""UP"",""details"":{""version"":""3.8.5""}},""respAmqpTmpl"":{""status"":""UP"",""details"":{""version"":""3.8.5""}}}}}}tomcat@xbidsimucor1:[/xbid]$
{code}

pmi-archiver/logger were not started successfully, because of some port-conflicts.
Dev´s are on it, after fixing it we going to deploy it again. 

","02/Nov/20 10:15;cs687;3.) deployed apache to activate Client Certificates 
for wbc3/5 instances we had to change owner of /run/httpd 
and redeployed again. ","02/Nov/20 12:08;cs687;fix for pmi-archvier/logger
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2334

re-deployment was successfully!","02/Nov/20 12:09;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create DB backup from the Simulation environment - from 29.10.2020,XP-3961,101535,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,zi174,zi174,14/Oct/20 11:41,02/Nov/20 13:06,22/Feb/21 13:26,30/Oct/20 10:29,,,3.1.3,,,,,,30/Oct/20 00:00,TechOps,,,,"Due to the penetration test we need to create DB snapshot from 29.10.2020.

[~iv732] and [~cs687] to handle on Thursday 29th October after EOB or *Friday morning*. 

We need to have all data from SIMU environment which are necessary for restoration.

 

We need to perform backup of
 * ldiff file
 * all DBs 

same as it was done during the DST. 

 ",,cs687,iv732,zi174,,,,,,,,,,,,,,,,,,XP-3963,XP-3962,,,,,,,,,,,,,,,,,,,,,"30/Oct/20 03:48;iv732;xbid_simu_sm_tree_backup.ldif;https://jira.deutsche-boerse.com/secure/attachment/89225/xbid_simu_sm_tree_backup.ldif","30/Oct/20 03:48;iv732;xbid_simu_wholetree_backup.ldif;https://jira.deutsche-boerse.com/secure/attachment/89226/xbid_simu_wholetree_backup.ldif","30/Oct/20 03:48;iv732;xbid_simu_xbid_tree_backup.ldif;https://jira.deutsche-boerse.com/secure/attachment/89227/xbid_simu_xbid_tree_backup.ldif",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Backups are created and stored on xbsimupdb1,,,,,,,,,,,,,,9936000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:ro",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,done,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/20 15:13;cs687;xbsimupdb1:

*sync*:
for comp in rep ams cmi ctp spm; do pg_dump --port=25202 -d xbsimu$comp -n xbsimu$comp | gzip > /export/dump/xbsimu${comp}.sql.gz; done

*async*:
for comp in cor; do pg_dump --port=25102 -d xbsimu$comp -n xbsimu$comp | gzip > /export/dump/xbsimu${comp}.sql.gz; done

[~zi174] thats how want to have the backup correct? normal pg_dump!","29/Oct/20 16:35;iv732;[~zi174] [~cs687]: LDAP backup to ldif file at 03:45 30.10.2020: attached to this ticket.
","30/Oct/20 10:18;cs687;Dump´s are created and stored on *xbsimupdb1*:
*/export/dump/301020*

{code:java}
-rw-r--r-- 1 postgres postgres 3.8K Oct 30 10:07 xbsimurep.sql.gz
-rw-r--r-- 1 postgres postgres 5.4K Oct 30 10:07 xbsimuams.sql.gz
-rw-r--r-- 1 postgres postgres 484M Oct 30 10:10 xbsimucmi.sql.gz
-rw-r--r-- 1 postgres postgres  25K Oct 30 10:10 xbsimuctp.sql.gz
-rw-r--r-- 1 postgres postgres 481M Oct 30 10:11 xbsimuspm.sql.gz
-rw-r--r-- 1 postgres postgres  64M Oct 30 10:16 xbsimucor.sql.gz
{code}
","30/Oct/20 10:29;cs687;Ticket can be closed!","30/Oct/20 10:31;zi174;[~cs687] [~iv732], thank you guys for supporting us. As I'm on vacation (due to lots of vacation's days) I asked [~tm431] to check if the backup contains all necessary information. So, if necessary he will contact you :)

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generate user's certificates for penetration testers,XP-3960,101534,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ub113,zi174,zi174,14/Oct/20 11:40,03/Nov/20 11:37,22/Feb/21 13:26,03/Nov/20 11:37,,,3.1.x,,,,,,02/Nov/20 00:00,BizOps,,,,"Please generate user's certificates for the testers - SIMu environment.

The necessary information:

 

Requirement for penetration test is to make environment as prod-like as possible.
 1. TechOps should enable the certificate authentication. - covered by XP-3959
 2. BizOps can create certificate for SADMIN01, superadmin account needed to set all other users (make sure to create certificates with CA xbid-test and check if they are working)

3. Superadmin creates users needed for penetration test. Historical reference: SERVICE-5139 - In case we do not receive different requirements, users needed - covered by XP-3966

5. Create certificates for all users.

6. Zip all certificates and passwords together, provide them in the email to penetration testers. Email should look like this:

_Dear <<PenTester>>,_

 __ 

_For the purpose of penetration test, we already created four users that have different levels of access on the SOB/CMM/SPM component._

_SOB/CMM/SPM_ _can be accessed via following links:_

 _<<links to corresponding component>>_

_[https://cmm-simu1.xbid.deutsche-boerse.com|https://cmm-simu1.xbid.deutsche-boerse.com/]_

_[https://cmm-simu2.xbid.deutsche-boerse.com|https://cmm-simu2.xbid.deutsche-boerse.com/]_

_Certificates and passwords are attached_

 __ 

_Best regards..._

7. Offer further support during penetration testing.",,ub113,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10800000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/20 10:35;ub113;Hello [~zi174]
 Requirement for penetration test is to make environment as prod-like as possible. 
 1. TechOps should enable the certificate authentication.
 2. BizOps can create certificate for SADMIN01, superadmin account needed to set all other users (make sure to create certificates with CA xbid-test and check if they are working)
 3. Superadmin creates users needed for penetration test. Historical reference: SERVICE-5139
 4. In case we do not receive different requirements, users needed: 
 *Capacity management module (CMM)* 
 Roles:
 • Reference Data Admin
 • TSO Admin
 • Explicit participant
 • File Management Admin

*Shared Order Book (SOB) + ComTrader*
 Roles:
 • Reporting
 • Exchange User – with both additional rights

*Shipping Module (SM)*  
 Roles:
 • TSO Admin, CCP Admin, SA Admin
 • TSO Operations, CCP Operations, SA Operations
 • Central Admin

5. Create certificates for all users.

6. Zip all certificates and passwords together, provide them in the email to penetration testers. Email should look like this:

_Dear <<PenTester>>,_

 __ 

_For the purpose of penetration test, we already created four users that have different levels of access on the SOB/CMM/SPM component._

_SOB/CMM/SPM_  _can be accessed via following links:_

 _<<links to corresponding component>>_

_[https://cmm-simu1.xbid.deutsche-boerse.com|https://cmm-simu1.xbid.deutsche-boerse.com/]_

_[https://cmm-simu2.xbid.deutsche-boerse.com|https://cmm-simu2.xbid.deutsche-boerse.com/]_

_Certificates and passwords are attached_

 __ 

_Best regards..._

7. Offer further support during penetration testing.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Turn on certification check for SIMU env,XP-3959,101533,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,zi174,zi174,14/Oct/20 11:39,14/Jan/21 13:43,22/Feb/21 13:26,30/Oct/20 16:54,,,3.1.3,,,,,,02/Nov/20 00:00,TechOps,,,,"Due to the penetration test between 3.11-13.11, we need to turn on a certificate check for SIMu environment. The user needs to be allowed to access the GUI only with valid certificate (same behavior as on the production).

 

Currently the check is turned-off and we need to turn it on to have same conditions as on Production. 

It should be Apache configuration. (*SIMU deployment is already in Ansible*)

-- [~iv732], [~cs687]  to check. if it's already ready. 

Update config file to use other template and then deploy. 

This has to be done before the deployment. 

 ",,cs687,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/20 16:26;cs687;xb-pentet;https://jira.deutsche-boerse.com/secure/attachment/89280/xb-pentet",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"pull-requests for activation of the client certificates

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2331 (already merged - for activation of the client certifcates)",,,,,,,,,,,,,,9849600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:rc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,.,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/Oct/20 14:59;cs687;proper pull-request for the client cert enabling:
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files#diff-04093c7926bb0d4cc659013425141a18R35
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1202/files#diff-04093c7926bb0d4cc659013425141a18R35
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2331
","30/Oct/20 16:26;cs687;[~eh941]
we deployed apache_cmm with the updated role, output is attached to the ticket 
 [^xb-pentet] ","30/Oct/20 16:54;cs687;Done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 2) Adapt deployment script to the new server,XP-3955,101525,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,eg288,14/Oct/20 10:30,02/Nov/20 12:57,22/Feb/21 13:26,23/Oct/20 14:51,,,3.1.2,,,,,,,,,,,"When XP-3457 is finished, please prepare/update deployment Jenkins script to deploy it to setup download server. 

Align with [~qo288] and [~dp007] about how deployment works on other products. 

Design should remain the same as current state. 

 

[~cv179]'s latest update from XP-3457: 

New buckets are created and temporary URLs are available already.

S3 buckets are created (temporary fallback home for current websites):
 * s3-dbg-m7-customer-portal-fbprod
 * s3-dbg-m7-customer-portal-fbsimu
 * s3-dbg-m7-customer-portal-fbtest (not yet - internal account discussion)

 

example 1: xbid prod new home (domain will eventually switch):
 [https://m7trading.energy.prod.deutsche-boerse.cloud/xbid-prod/]
 example 2: xbid ctpa
 [https://m7trading-test.energy.prod.deutsche-boerse.cloud/xbid-ctpa/]

 

Once all content is migrated and available, we will switch the current m7trading domains on it.",,eg288,ek176,,,,,,,,,,,,,,,,,,,XP-3514,,,,,,,,,,,,,,,XP-3987,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10454400,,,,,,,,,,,,,,,XP-3456,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bo26:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/20 14:51;eg288;implemented, including update of [confluence page with CT links|https://confluence.energy.svc.dbgcloud.io/display/XBID/ComTrader+Links] to include new internal test download page url",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID - Deployment KPI definition 2021,XP-3950,101444,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,rehapav,rehapav,13/Oct/20 09:33,12/Feb/21 10:15,22/Feb/21 13:26,12/Feb/21 10:15,,,,,,,,,31/Dec/20 00:00,waiting-po,,,,"In the course of the year 2020 we have defined for products M7 and XBID *Deployment KPIs*, which are measured and presented on a quarter basis (4x per year on the Section update).

See KPI example attachment

 

As part of the definition of done for this ticket, please
 * review current KPIs and confirm these still make sense to you and you want these to be measure and presented
 ** average time of the deployment expected/actual = ability to deploy in planned window
 ** deployments per environment - how many deployments we have
 ** deployment per week - how many deployments in prod and non-prod we execute on weekly basis
 ** deployment success - how well are we deploying
 ** FYI: newly we will be also presenting technical data from slack channel - physical deployment jenkins trigger and physical deployment jenkins finish
 * re-define actual KPIs if you have any other ideas
 * define new KPIs is you have any other ideas
 * explain KPIs with BIZOPs ([~oh856] [~ub113] [~rehapav] and agree on the KPI implementation

 

Please especially for currently used KPI average actual/expected duration - this does not make sense for XBID.

Deployments planned across several days with multiple environments in one ticket is very difficult to measure.

*Unless XBID defines meaningful KPI*, it will lead to the requirement from BIZOPs to have *only 1 environment to be deployment by 1 ticket - no multiple deployments in one deployment ticket.*",,ei349,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8438,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bu50:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/21 15:48;rehapav;[~ei349] any update about this ticket - what would XBID development team like to measure?

So far we have just 1 new KPI requirement from M7T team - to measure startup of the components.","12/Jan/21 10:08;ei349;hi Pavel, I have it on my radar, but I need to resolve 2021 planning first. I will come back to this one right after it. ","12/Feb/21 10:14;rehapav;KPI definition for 2021 is closed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Fix OWASP vulnerabilities in all nightly develop builds in xbid projects,XP-3949,101437,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,13/Oct/20 07:58,14/Jan/21 11:48,22/Feb/21 13:26,15/Oct/20 13:47,,,3.1.2,,,,,,,,,,,Please fix all vulnerabilities found during nightly develop builds,,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3971,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11404800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bs4o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3394_flyway_standard_implementation,XP-3394_acceptance_flyway_standard_implementation,XP-4354,XP-3791-runTime,XP-4349_acceptance_fix_hp_fortify_issues,develop,XP-3394_acceptance_remove_unused_maven_properties,XP-4234,master-acceptance,master,acceptance,XP-3394_remove_schema_version,XP-3949,XP-4349_set_default_page,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Onboard LIPA, LIPB into Ansible (deadline 27th October)",XP-3947,101419,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ei349,ei349,12/Oct/20 15:58,02/Nov/20 13:06,22/Feb/21 13:26,27/Oct/20 12:35,,,3.1.3,,,,,,28/Oct/20 00:00,,,,,"This needs to be done before 27th October as deployment is going to take place on 28-29th October. 

Hints: 

devs can create inventory

tos need to create Vault entries 

several dry runs ",,eg288,ei349,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10195200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bs4q:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Oct/20 14:59;eg288;inventory for lipa and lipb: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2302]

 

[~hw120]  - please organize preparation of vault entries by tos team, lipb is more important due to deployment in SERVICE-8411","26/Oct/20 23:52;hw120;Prepared (extracted from xml config and app configs) vault variables for lipa and lipb ansible deployment.","27/Oct/20 12:34;hw120;Tried dry-run and it looks fine
 * LIPB

[https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FXBID%20Ansible%20Jobs%2FXBID%20Ansible%20deploy%20full/detail/XBID%20Ansible%20deploy%20full/216/pipeline/225/]
 * LIPA

[https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FXBID%20Ansible%20Jobs%2FXBID%20Ansible%20deploy%20full/detail/XBID%20Ansible%20deploy%20full/219/pipeline]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Install plugin rabbitmq_message_timestamp into RabbitMQ ,XP-3946,101405,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,od044,od044,12/Oct/20 12:02,06/Nov/20 09:34,22/Feb/21 13:26,13/Oct/20 09:43,,,3.1.2,,,,,,,,,,,"Plugin rabbitmq_message_timestamp is missing in RabbitMQ, probably miss during RabbitMQ upgrade.  

Impact:
Cannot collect and report performance on RabbitMQ.

Expect:
Install plugin rabbitmq_message_timestamp into RabbitMQ on Perf and SIMU env at least 
",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11404800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0brxk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Oct/20 09:42;eg288;The rabbitmq plugin rabbitmq_message_timestamp has been upgraded to support rabbitmq 3.8.x. 

Tested on perf environment by [~od044]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix password policy changes on SPM GUI - max length pwd = 64,XP-3942,101358,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ei349,ei349,09/Oct/20 15:56,02/Nov/20 12:57,22/Feb/21 13:26,22/Oct/20 16:55,,,3.1.2,,,,,,23/Oct/20 00:00,,,,,"Customers came back in XBID-5232 (originating from XBID-5223) that they would like to have same password policies in all our modules. 

SPM is missing and we have to onboard the same rules as for other modules. 

For details see external tickets with requirements: XBID-5194, XBID-5195, XBID-5197. 

 

*Hint:* 
 * avoid trimming to 64 chars

 

 ",,ei349,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XBID-5232,XBID-5223,XBID-5194,XP-3910,,,,"22/Oct/20 16:14;od044;Screenshot 2020-10-22 at 15.36.44.png;https://jira.deutsche-boerse.com/secure/attachment/88956/Screenshot+2020-10-22+at+15.36.44.png","22/Oct/20 16:14;od044;Screenshot 2020-10-22 at 15.39.19.png;https://jira.deutsche-boerse.com/secure/attachment/88957/Screenshot+2020-10-22+at+15.39.19.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10540800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1670,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bs4r:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,fixing-hp-fortify-acceptance-2021-02-15,XP-3942,acceptance,XP-4371_upgrade_dataset_version,XP-3942-acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Oct/20 16:51;od044;Test passed on SM 3.1.3 on SYT1 

- password is limit to min 12 and max 64 characters 
- user cannot change password that is less than 12 and bigger than 64 characters, in case excess there are validation error (see screen below)
- field is no trim, that mean user can enter more than 64 characters
- other restrictions as password history, special characters are still handle by LDAP and SM only display error message

StR
1. Login SM with any user 
2. Open change password form 
3. Try to submit new password that has less than 12 char - cannot submit
4. Try to submit new password that has more than 64 char - cannot submit
5. Try to submit new password that has 12 char and but DOES NOT fulfil one of the following least one uppercase, special char and number - cannot submit 
6. Try to submit new password that has 12 char and fulfil ALL of the following least one uppercase, special char and number - change password successfully 

!Screenshot 2020-10-22 at 15.36.44.png!  
!Screenshot 2020-10-22 at 15.39.19.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jenkins worker aws-rollout-automation does not have maven,XP-3927,101253,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,eg288,eg288,07/Oct/20 16:52,02/Nov/20 12:57,22/Feb/21 13:26,19/Oct/20 16:27,,,3.1.2,,,,,,14/Oct/20 00:00,,,,,"install maven 3.6.2 to jenkins worker aws-rollout-automation the same way as it is available on other jenkins workers

Reasoning:
 To be able to run xbid comtrader deployment which uses maven to build so called uber package. The uber package artifacts are then copied into aws S3 bucket, This is the reason why the deployment job needs to run on worker aws-rollout-automation.

 

Hint: 

- [~cv179] started some work on it and it seems that Maven is just not setup properly. ",,eg288,hw120,,,,,,,,,,,,,,,,,,,XP-3458,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10800000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i09",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/20 16:51;hw120;Jenkins job to test it

[https://englobjci1.deutsche-boerse.de/job/Energy/job/eg288-xbid-comtrader-uber-package-internal-envs/]

 ","19/Oct/20 16:27;eg288;Maven is not needed anymore on jenkins worker _aws-rollout-automation_. The uber package creation originaly implemented as maven plugin has been migrated to ansible playbook. The ansible is supported on worker aws-rollout-automation and it is a prefered way how to do stuff.

Closing the ticket as not implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove Holiday class and related code,XP-3926,101234,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,07/Oct/20 14:21,29/Oct/20 13:08,22/Feb/21 13:26,27/Oct/20 09:57,,,3.2.x,,,,,,,,,,,"Holiday feature was never used in xbid, remove all relevant code and performa DB changes",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09ia",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - XBID CUTE 2nd DST test Backwards time travel 12/10/2020,XP-3925,101229,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,tm431,hw120,07/Oct/20 14:12,02/Dec/20 11:31,22/Feb/21 13:26,12/Oct/20 21:21,,,3.1.2,,,,,,,,,,,Accurate info can be found in linked service ticket.,,hw120,,,,,,,,,,";02/Dec/20 11:31;zs244;18000",,,0,18000,,,0,18000,,,,,SERVICE-8184,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,tm431,,,,,,,,,,,,,,Internal Deployment Request,eg288,jy268,qo794,,No,11923200,,CUTE,,,,,,dm700,lw641,ox626,rehapav,sw455,,12/Oct/20 16:04,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bqv4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare rollout of new ACER reporting service,XP-3919,101151,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,ll664,ll664,06/Oct/20 13:30,02/Nov/20 13:06,22/Feb/21 13:26,28/Oct/20 15:15,,,3.1.3,,,,,,,,,,,"As we extracted ACER into separate service, we removed the code from original Report Tool. Hence with a deployment of new Report Tool version, it'll stop collecting/generating ACER reports.

We need to rollout the new ACER service ([https://github.deutsche-boerse.de/dev/xbid.acer-reporting]).

Suggested approach:
 * deploy and test in internal env - syt1
 * prepare data migration - there are already data collected in report tool DB, should be copied to new ACER DB.Script that does {{pg_dump}}/{{pg_restore}} with ACER tables only should be good enough.
 * deploy to SIMU with data migration
 * deploy to PROD with data migration
 * for PROD - leave one SLA node with old Report Tool that still has ACER features, just in case something goes wrong with new service",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10022400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3919-check,XP-3919,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Oct/20 13:40;ll664;ACER Reporting deployed to SYT1/SIMU (SERVICE-8545). I will watch it for couple of days and then schedule a PROD deploy.
","26/Oct/20 13:44;ll664;SIMU looks good apart from postgres privileges issue - fixed by [~cs687]. (uappsimusla01 user did not have enough rights for COR DB).

PROD deploy scheduled for Tuesday 27.10.2020 - SERVICE-8569
Ticket for log collection to Kibana created - XP-4045","28/Oct/20 15:06;ll664;ACER deployed to PROD, together with Report Tool version without ACER, that was deploy just to node1, so we have Report Tool with ACER on node2 just in case something goes wrong(SERVICE-8585).

The new reports are stored in {{/xbid/reports/acer}} in order to distinguish them from AM (stored in {{/xbid/reports/am}}). The original Report Tool stores them in {{/xbid/reports}}, but once the AM/ACER are running separately, this folder would no longer be used and would be empty.

Both nodes are running fine, DB migration also looks good, data are being collected. Closing the task.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace expired certificate on xbdsldap2,XP-3916,101131,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,hw120,hw120,06/Oct/20 10:21,02/Nov/20 12:57,22/Feb/21 13:26,07/Oct/20 00:49,,,3.1.2,,,,,,,Certificates,TechOps,,,"As some xbid simu services depends on this ldap server, we have to solve it as soon as possible.
 * Generate csr certificate request and store copy of generated cert and key to backup folder
 * Create ITSR ticket with request for new cert
 * Send email to ssl-admins with number of ITSR ticket and CSR file attached
 * Follow pdf guide to replace cert on ldap server

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/20 10:22;hw120;ssl_certificate_replacement.pdf;https://jira.deutsche-boerse.com/secure/attachment/88269/ssl_certificate_replacement.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bqao:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/20 23:17;hw120;Installed new certificate, and also enabled both ldap server on xb simu ams instances.

Creating documentation for this process as it was not trivial.","07/Oct/20 00:49;hw120;Created documentation for the whole process

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/LDAP+server+SSL+certificate+renewal]

I have to inform everybody I added Digicert CA to vault keystore /secret/certs/root/comodo/keystore

as probably redeployment of some modules would be necessary to pick up this change so they can correctly communicate with ldap server with new certificate.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA Report Tool - Service Boundary Report - missing data,XP-3905,101073,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Resolved,uv683,zi174,zi174,05/Oct/20 11:51,17/Feb/21 16:46,22/Feb/21 13:26,17/Feb/21 14:04,,,3.1.3,,,,,,08/Oct/20 00:00,,,,,"The attached report is missing data one the ""Sustainable Load Seconds"" sheet, please check what happened and regenerate it. ",,uv683,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/20 13:16;uv683;XBID Service Boundary Reporting September 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88328/XBID+Service+Boundary+Reporting+September+2020.xlsx","05/Oct/20 11:51;zi174;XBID Service Boundary Reporting September 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88208/XBID+Service+Boundary+Reporting+September+2020.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Looks like that last report tool deployment to PROD solved this. report for January has been created without problems. Need to keep an eye on it for the next few months however,,,,,,,,,,,,,,11923200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:9zz",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,Alpha Sprint 23 (S),Alpha Sprint 24,Alpha Christmas Sprint (S),Alpha Sprint 25,Alpha Sprint 26 (S),Alpha Sprint 27,Alpha Sprint 28 (S),,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/20 12:49;uv683;Looks like server run out of memory during loading all the sustainable load data
{code:java}
2020-10-01T04:03:53.085Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [generate-boundary-sla-report]
2020-10-01T04:05:32.060Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step generate-boundary-sla-report in job generate-boundary-sla-report
java.lang.OutOfMemoryError: Java heap space
        at java.util.Arrays.copyOf(Arrays.java:3236)
        at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
        at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
        at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)
        at org.apache.poi.openxml4j.opc.internal.MemoryPackagePartOutputStream.write(MemoryPackagePartOutputStream.java:88)
        at org.apache.xmlbeans.impl.store.Cursor._save(Cursor.java:590)
        at org.apache.xmlbeans.impl.store.Cursor.save(Cursor.java:2544)
        at org.apache.xmlbeans.impl.values.XmlObjectBase.save(XmlObjectBase.java:223)
        at org.apache.poi.xssf.usermodel.XSSFSheet.write(XSSFSheet.java:3656)
        at org.apache.poi.xssf.usermodel.XSSFSheet.commit(XSSFSheet.java:3577)
        at org.apache.poi.ooxml.POIXMLDocumentPart.onSave(POIXMLDocumentPart.java:463)
        at org.apache.poi.ooxml.POIXMLDocumentPart.onSave(POIXMLDocumentPart.java:468)
        at org.apache.poi.ooxml.POIXMLDocument.write(POIXMLDocument.java:236)
        at com.deutscheboerse.energy.xbid.reporttool.common.ExcelExporter.exportToXSSF(ExcelExporter.java:109)
        at com.deutscheboerse.energy.xbid.reporttool.common.ExcelExporter.exportToSheet(ExcelExporter.java:69)
        at com.deutscheboerse.energy.xbid.reporttool.boundary.report.sustainableload.SustainableLoadSheet.write(SustainableLoadSheet.kt:16)
        at com.deutscheboerse.energy.xbid.reporttool.boundary.report.BoundarySLAReportFile.write(BoundarySLAReportFile.kt:43)
        at com.deutscheboerse.energy.xbid.reporttool.boundary.report.BoundarySLAReportGenerator.createAndSaveReport(BoundarySLAReportGenerator.kt:19)
        at com.deutscheboerse.energy.xbid.reporttool.boundary.config.BoundarySLAJobConfig$generateBoundarySLAReportStep$1.execute(BoundarySLAJobConfig.kt:105)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:145)
        at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:258)
        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:208)
        at sun.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
 {code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AMS simu issues,XP-3902,101052,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,iv732,qo794,qo794,05/Oct/20 09:13,02/Nov/20 12:57,22/Feb/21 13:26,19/Oct/20 08:42,,,3.1.2,,AMS,GA,,,,,,,,"AMS on simu is still not working properly:
# probably an invalid password is configured in AMS for LDAP or the account is locked?
{code:title=ams_simu.log}
Caused by: javax.naming.directory.InvalidAttributeValueException: [LDAP: error code 19 - Exceed password retry limit. Contact system administrator to reset.]
{code}
# AMS flyway migration via ansible is not working at all, fix https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1158 (/)
# the database tables are still not fully migrated to the vesion 1.0.0. When redeploying AMS please keep in mind that xbdsldap2 server has to be manually removed from the application configuration (or verify whether it's still needed due to missing FW configuration)
{code:title=ams_simu.log}
java.lang.RuntimeException: Missing tableLock entry for VAULT_CERTIFICATE. The database is not initialized.
{code}
# user {{udev01xbsimuams}} cannot login to xbsimuams database via citrix
{code}
FATAL: password authentication failed for user ""udev01xbsimuams""
{code}",,hw120,iv732,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11836800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bptk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 19 (S),Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Oct/20 14:14;iv732;[~qo794] At least as I checked SIMU DB, there is no right assigned to user udev01xbsimuams. Should it have the same rights as user ""uapp01xbsimuams""? This is currently the common issue for all cuties environments as well, so if I know exactly which permissions are needed, I will do for all DBs.


{code:java}
xbsimuams=# \z
                                               Access privileges
  Schema   |          Name           |   Type   |       Access privileges        | Column privileges | Policies
-----------+-------------------------+----------+--------------------------------+-------------------+----------
 xbsimuams | expiration_check        | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams |                   |
 xbsimuams | expiration_check_id_seq | sequence | xbsimuams=rwU/xbsimuams       +|                   |
           |                         |          | uapp01xbsimuams=rU/xbsimuams   |                   |
 xbsimuams | flyway_schema_history   | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams |                   |
 xbsimuams | table_lock              | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams |                   |

{code}
","05/Oct/20 14:17;iv732;Regarding the deployment of SIMU AMS, [~hw120] you did the SIMU deployment, right? Did the flyway migration via ansible deployment work?","05/Oct/20 15:53;hw120;[~iv732] On idea, I was told to deploy AMS because of the flyway problem, nobody told me to or how to check if flyway migration work.

I am working on xbdsldap2 certificate renewal, it will be fixed today or tomorrow.","06/Oct/20 08:48;qo794;[~iv732] a DEV database user has usually less rights than an application user, the dev one does not have a write access for instance, check other existing databases (xbsimucor, etc.)","06/Oct/20 14:41;iv732;[~qo794] user udev is added


{code:java}
xbsimuams=# \z
                                               Access privileges
  Schema   |          Name           |   Type   |       Access privileges        | Column privileges | Policies
-----------+-------------------------+----------+--------------------------------+-------------------+----------
 xbsimuams | expiration_check        | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams+|                   |
           |                         |          | udev01xbsimuams=r/xbsimuams    |                   |
 xbsimuams | expiration_check_id_seq | sequence | xbsimuams=rwU/xbsimuams       +|                   |
           |                         |          | uapp01xbsimuams=rU/xbsimuams   |                   |
 xbsimuams | flyway_schema_history   | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams+|                   |
           |                         |          | udev01xbsimuams=r/xbsimuams    |                   |
 xbsimuams | table_lock              | table    | xbsimuams=arwdDxt/xbsimuams   +|                   |
           |                         |          | uapp01xbsimuams=arwd/xbsimuams+|                   |
           |                         |          | udev01xbsimuams=r/xbsimuams    |                   |
(4 rows)

{code}
","07/Oct/20 08:36;qo794;[~iv732] I got the following error when trying to select data from any DB table using udev01xbsimuams user:
{code}
An error occurred while performing the operation:
ERROR: permission denied for schema xbsimuams
Position: 15
{code}
Working correctly on syt1 though","07/Oct/20 16:50;iv732;The point 4 is solved by the following commands:

{code:java}
CREATE SCHEMA xbsimuams AUTHORIZATION xbsimuams;
GRANT SELECT ON ALL TABLES IN SCHEMA xbsimuams TO udev01xbsimuams;
GRANT USAGE ON SCHEMA xbsimuams TO udev01xbsimuams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbsimuams GRANT SELECT ON TABLES TO udev01xbsimuams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbsimuams GRANT USAGE ON SEQUENCES TO udev01xbsimuams;
GRANT CONNECT ON DATABASE xbsimuams TO udev01xbsimuams;
{code}
","07/Oct/20 17:07;iv732;For point 1: user xbid-simu-adm is not expired, not locked. Tested to login as this user, worked.

","07/Oct/20 17:58;iv732;Tested manually on the host, same error:

{code:java}
[tomcat@xbsimuams1 xbid-simu-ams1]$ ldapwhoami -H ldap://xbdsldap1.deutsche-boerse.de:389 -x -D 'uid=xbid-simu-adm,ou=simu,o=sm,dc=energy,dc=test' -W
Enter LDAP Password:
ldap_bind: Constraint violation (19)
        additional info: Exceed password retry limit. Contact system administrator to reset.

{code}


Checked in more details the policy. It is strange that even the policy still has

{code:java}
passwordmaxfailure = 3
{code}
even 
{code:java}
passwordlockout= off
{code}

I reset the password for this user several times. And then I can set the old original password back. Now it seems to works.
[~qo794] please check
","08/Oct/20 10:31;qo794;The ldap error is not longer present in AMS logs, working fine, point 1 is fixed.","08/Oct/20 10:48;iv732;Point 3: redeployed AMS.","08/Oct/20 11:05;qo794;I can confirm AMS is working fine, the ticket can be closed, thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,
Elasticsearch cluster is running out of space,XP-3844,100935,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,hw120,hw120,01/Oct/20 22:16,02/Nov/20 12:57,22/Feb/21 13:26,01/Oct/20 22:17,,,3.1.2,,,,,,,Monitoring,TechOps,,,"We can observe increased amount of logs and data being stored in elasticsearch.

Especially tomcat logs and newly about 40GB of data from coda service.

I had to create new ebs volumes and attach one to each elasticsearch data node.

Then extend volume group, logical volume and filesystem.",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Extended.,,,,,,,,,,,,,,12355200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bp5s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve XBID ansible deployment - add check action,XP-3841,100928,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,hw120,hw120,01/Oct/20 16:39,11/Feb/21 09:14,22/Feb/21 13:26,23/Oct/20 09:59,,,3.1.2,,,,,,,,,,,"We could really use action: *check* to see if instances are running or not.

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID Ansible Jobs/job/XBID Ansible deploy full|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID%20Ansible%20deploy%20full]

 

DoD:
 * Availability of *check* action in XBID ansible deployment, so every service must have it
 * It will display the status of all selected services/modules - if they are running or not",,hw120,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12355200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i9i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3919-check,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CT Profile Storage: Create /health endpoint,XP-3838,100919,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ek176,ek176,01/Oct/20 16:16,24/Nov/20 17:12,22/Feb/21 13:26,24/Nov/20 17:12,,,3.1.x,,,,,,,,,,,"CT Profile Storage server is lacking the /health and /info endpoint (all available endpoints need authorization).
 (As discussed on DevOps Community 2020-09-29)

Hints: Spring = 5.2.6 

DoD:
 * CTP server has a standard /health and /info endpoint (no auth needed) (/)
 * Ansible script is updated (checking the /health) (/)
 * Telegraph is monitoring the CTP",,ek176,hw120,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,profile-storage-1.8.x,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Oct/20 16:17;ek176;Additional info: {{#xbid-emergency}} excerpt from 2020-10-01 (SIMU deployment)

Telegraph config (part):

{noformat}
#############################################################################
#   Tomcat Application health check script                                  #
#############################################################################
[[inputs.exec]]
  commands = [""/etc/telegraf/scripts/health_check_tomcat.sh ctp 60104"",]
  timeout = ""15s""
  data_format = ""json""
  name_prefix = ""status_""
  [inputs.exec.tags]
    tomcat = ""xbsimuctp1_ctp""
    module = ""xbid_simu""
    product = ""xb""
    client = ""xbid""
    client_environment = ""simu""
    host_group_module=""xbsimuctp1 - tomcat - xbid_simu""
    instance = ""ctp1""
    datacenter = ""equinix""
#############################################################################
#   End of Tomcat Application health check script                           #
#############################################################################
{noformat}

Check script:

{noformat}
[root@xbsimuctp1 ~]# cat /etc/telegraf/scripts/health_check_tomcat.sh
#!/bin/bash
TOMCAT_CONTEXT=$1
TOMCAT_PORT=$2
curl -s http://127.0.0.1:${TOMCAT_PORT}/${TOMCAT_CONTEXT}/health | sed -e 's/""UP""/1/g; s/""DOWN""/0/g; s/""UNKNOWN""/-1/g; s/""OUT_OF_SERVICE""/-2/g; s/true/1/g;  s/""DISCONNECTED""/0/g; s/""CONNECTED""/1/g;  s/false/0/g; s/""MASTER""/1/g; s/""SLAVE""/0/g;'  | less
{noformat}

","03/Nov/20 15:03;jy268;new /health and /info endpoints added","06/Nov/20 09:30;jy268;ansible script updated, now it checks proper health endpoint *CTP 1.8.3 version required!!*","06/Nov/20 09:54;jy268;[~hw120] could you please set up telegraph to monitor CTP? If you want to do some testing, it is currently deployed on syt2 env. Please keep in mind that health endpoint is supported starting from CTP 1.8.3 version.","24/Nov/20 17:10;hw120;[~jy268]I tested deployment on syt2 and simu, there it seems to be a new version already deployed. For prod we have to wait for new application deployment - migration to ansible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OS upgrades for XBID SIMU (and XBID PROD later) decision how to proceed,XP-3830,100838,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,rehapav,rehapav,30/Sep/20 14:07,02/Nov/20 12:57,22/Feb/21 13:26,12/Oct/20 11:22,,,3.1.2,,,,,,16/Oct/20 00:00,,,,," 

List of VMs from ""XBID SIMU"" environment with different OS version then ""RHEL7.8""
||Name||Operating system||Note||Comment||
|xbsimupdb1|RedHat 7.5|(?) {color:#4c9aff}Currently known issue with package version conflict - Recomended ugrade to RHEL7.7 only{color}|{color:#de350b}*PRODUCT TEAM DECIDE how to move on - at the moment impossible to upgrade according to syseng team*{color}|
|xbsimupdb2|RedHat 7.5|(?) {color:#4c9aff}Currently known issue with package version conflict - Recomended ugrade to RHEL7.7 only{color}|{color:#de350b}*PRODUCT TEAM DECIDE how to move on - at the moment impossible to upgrade according to syseng team*{color}|
|xbsimupdb3|RedHat 7.5|(?) {color:#4c9aff}Currently known issue with package version conflict - Recomended ugrade to RHEL7.7 only{color}|{color:#de350b}*PRODUCT TEAM DECIDE how to move on - at the moment impossible to upgrade according to syseng team*{color}|
|xbsimupdb4|RedHat 7.5|(?) {color:#4c9aff}Currently known issue with package version conflict - Recomended ugrade to RHEL7.7 only{color}|{color:#de350b}*PRODUCT TEAM DECIDE how to move on - at the moment impossible to upgrade according to syseng team*{color}|

 

 

Please make a decision how to move on with OS upgrade for VMs with {color:#de350b}*red bold* {color}comment
 * pdbs OS upgrade - xbsimupdb1, xbsimupdb2, xbsimupdb3, xbsimupdb4

Dependency is on PatroniDB package - currently used package is PatroniDB 1.6.0 and required one is 1.6.5.

 

Please confirm we can use PatroniDB 1.6.5

Provide decision until 16/10 and at least 1 week before next XBID SIMU deployment

 

Decided: proceed with upgrade to RHEL 7.8 incl. patroni 1.6.5

 

This unblocks all remaining OS upgrades for PROD and SIMU.",,rehapav,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bokw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SIMU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Oct/20 17:12;yo218;as agreed with [~rehapav], we will proceed with upgrade to RHEL 7.8 incl. patroni 1.6.5","07/Oct/20 08:45;rehapav;I consider this ticket decided and done - i will schedule outstanding OS upgrades with next SIMU deployment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Update Ansible playbook to use the same name for SSL cert/key/chain for HAPROXY & APACHE on all XBID environments and instances,XP-3828,100831,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,iv732,ek176,30/Sep/20 12:51,02/Nov/20 12:57,22/Feb/21 13:26,30/Sep/20 12:53,,,3.1.2,,,,,,,,,,,"Currently we are using a single wildcard SSL Cert for all *haproxy* and *apache* instances in all environments.
 With the introduction of new ansible playbook, we now end up using different names for the SSL cert/key/chain in different environment/instances.
 In a shared hosts, like xbcutsweb1 under /shrd/ssl, we will have a bunch of files like this:
{code:java}
ctpa1_xbid_deutsche-boerse_com_cert.crt
ctpa1.xbid.deutsche-boerse.com_private.key
ctpb1_xbid_deutsche-boerse_com_cert.crt
ctpb1.xbid.deutsche-boerse.com_private.key
....
{code}
even though they are identical in content!

Further more, we have to store those in many different locations in Vault. 
 All of these can lead to the problem that maybe some of the locations are not updated whenever we get the new wildcard certificate.

So, my recommendation is that we should store that certificate stuff only in one single location in vault (currently secret/xb/xbid/common/cert). And all of them when being deployed will have the same name, such as: 
 xbid_cert.pem
 xbid_private.pem
 xbid_chain.pem

 

Clean also unnecessary vault secrets after finishing this task. ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,split,,,,,,,,,,,,,,12528000,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bk6d:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 18,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) ComTrader cannot connect to SYT1,XP-3827,100830,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,od044,ek176,30/Sep/20 12:50,02/Nov/20 12:57,22/Feb/21 13:26,30/Sep/20 12:51,,,3.1.2,,,,,,,,,,,"Update: TestClient works. ComTrader cannot connect.

 

-Test client cannot connect to SYT1. It looks like an issue with key store. Most probably HA Proxy.-

Here is error log:
{code:java}
13:47:49.622 INFO  c.d.g.m.v.M7ExchangeConnection - Sending login request for user 'XBEPEXX1' to host '10.136.14.19', port '50700', vhost 'ext'.
13:47:49.636 INFO  g.logger.message - S,1598269669636,0,<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><LoginReq xmlns=""http://www.deutsche-boerse.com/m7/v1"" user=""XBEPEXX1"" force=""false"" disconnectAction=""NO""><StandardHeader marketId=""XSOB""/></LoginReq>
13:47:49.693 ERROR c.d.g.a.AmqpConnectionManager - Handle IOException ...
javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:154)
	at sun.security.ssl.SSLSocketImpl.recvAlert(SSLSocketImpl.java:2020)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1127)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)
	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:750)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:129)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:134)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:277)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:49.693 ERROR c.d.g.a.AmqpBackend - error sending request
javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:154)
	at sun.security.ssl.SSLSocketImpl.recvAlert(SSLSocketImpl.java:2020)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1127)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)
	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:750)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:129)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:134)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:277)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:49.698 INFO  c.d.g.m.v.M7ExchangeConnection - Login message response 'null'
13:47:49.698 ERROR c.d.g.m.v.M7ExchangeConnection - Login unsuccessful. Response: 'null'
13:47:49.775 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:313)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:53.838 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.security.KeyStoreException: Uninitialized keystore
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: java.lang.RuntimeException: java.security.KeyStoreException: Uninitialized keystore
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.createSslContext(AmqpConnectionFactory.java:85)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.<init>(AmqpConnectionFactory.java:37)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.connect(AmqpBackend.java:155)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.initAmqpBackend(M7ExchangeConnection.java:1325)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.connect(M7ExchangeConnection.java:261)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.connect(DefaultBackendConnectionGateway.java:146)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:239)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.security.KeyStoreException: Uninitialized keystore
	at java.security.KeyStore.aliases(KeyStore.java:1233)
	at sun.security.ssl.SunX509KeyManagerImpl.<init>(SunX509KeyManagerImpl.java:127)
	at sun.security.ssl.KeyManagerFactoryImpl$SunX509.engineInit(KeyManagerFactoryImpl.java:70)
	at javax.net.ssl.KeyManagerFactory.init(KeyManagerFactory.java:256)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.createSslContext(AmqpConnectionFactory.java:72)
	... 14 common frames omitted
13:47:58.064 INFO  c.d.g.m.v.M7ExchangeConnection - Sending login request for user 'XBEPEXX1' to host '10.136.14.19', port '50700', vhost 'ext'.
13:47:58.064 INFO  g.logger.message - S,1598269678064,0,<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><LoginReq xmlns=""http://www.deutsche-boerse.com/m7/v1"" user=""XBEPEXX1"" force=""false"" disconnectAction=""NO""><StandardHeader marketId=""XSOB""/></LoginReq>
13:47:58.127 ERROR c.d.g.a.AmqpConnectionManager - Handle IOException ...
java.io.IOException: null
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106)
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:350)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.rabbitmq.client.ShutdownSignalException: connection error
	at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67)
	at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:37)
	at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:367)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:293)
	... 23 common frames omitted
Caused by: java.io.EOFException: null
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
	at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:95)
	at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:139)
	at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:542)
	... 1 common frames omitted
13:47:58.128 ERROR c.d.g.a.AmqpBackend - error sending request
java.io.IOException: null
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106)
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:350)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.rabbitmq.client.ShutdownSignalException: connection error
	at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67)
	at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:37)
	at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:367)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:293)
	... 23 common frames omitted
Caused by: java.io.EOFException: null
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
	at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:95)
	at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:139)
	at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:542)
	... 1 common frames omitted
13:47:58.129 INFO  c.d.g.m.v.M7ExchangeConnection - Login message response 'null'
13:47:58.129 ERROR c.d.g.m.v.M7ExchangeConnection - Login unsuccessful. Response: 'null'
13:47:58.174 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:313)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

{code}",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12528000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bdql:z9",9223372036854775807,,,,,,,,,,,split,,,,,,,,,,,,Alpha Sprint 18,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID: Prepare for creating Individual CuTe Environment for OKTE,XP-3824,100826,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,qm925,qm925,30/Sep/20 11:47,18/Feb/21 09:31,22/Feb/21 13:26,03/Feb/21 14:49,,,3.2.x,,,,,,,TechOps,,,,"Information from clients
 * *+Individual CuTe for OKTE+*

 * 
 ** As you know OKTE is a new NEMO to SIDC cooperation.
 ** OKTE intends to start initial implementation activities as of February 2021
 ** Therefore we would like to ask you to deliver Individual Cute environment for OKTE (4th Wave) until *01 February 2021*

*There is a HOWTO [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Setup+new+environment*]

*Hint: get inspired by Henex ticket: XP-2583.* 

*Acceptance criteria* 
 * analyse of what needs to be done and how long it will take (do we need to order something or is there anything special to be done specifically?)
 * align with syseng team so they also include their input 
 * create follow up ticket(s) with details for creating new environment for OKTE
 ** e.g. devs to create inventories and update deployment scripts
 * record estimated effort needed in the ticket so we can better prepare for the future planning. 
 * update [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Setup+new+environment] with latest procedue

 ",,ab039,ei349,iv732,qm925,,,,,,,,,,,,,,,,,,,,,,,,,XP-4509,,,,,,,M7ACM-1479,,,,,,,"18/Feb/21 09:31;ab039;XBID Connectivity Details Individual CuTes - v1.3.docx;https://jira.deutsche-boerse.com/secure/attachment/93033/XBID+Connectivity+Details+Individual+CuTes+-+v1.3.docx","21/Jan/21 10:47;iv732;ctpn_ssh_key;https://jira.deutsche-boerse.com/secure/attachment/91910/ctpn_ssh_key","21/Jan/21 10:47;iv732;ctpn_ssh_key.pub;https://jira.deutsche-boerse.com/secure/attachment/91911/ctpn_ssh_key.pub","22/Jan/21 10:06;iv732;fra1_xbctpnpmi.pea;https://jira.deutsche-boerse.com/secure/attachment/91979/fra1_xbctpnpmi.pea",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,follow up in the linked ticket,,,,,,,,,,,,,,345600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000a9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 26,Xbops Sprint 27,,,,,,,,,,,,,,,,,,,,,,,21.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/20 13:14;ei349;(flag) Flag added

Needs to be discussed with [~iv732]","11/Jan/21 09:06;iv732;Created the VMs request: SYSENGINT-246","11/Jan/21 09:27;iv732;Updated the excel sheet:  XBID_Environments_2021-01-11.xlsx","11/Jan/21 12:59;iv732;Contacted Tobias from CCI for the load balancer configuration

ISR ticket created: 91023700","11/Jan/21 13:46;iv732;Created a CRM7 ticket:  44025381

Contacted Benedicte Clotuche for the pea file
{code:java}
Hi
Bénédicte,
 Can you please create this bucket for our new XBID environment:

Fra1_xbctpnpmi


{code}","11/Jan/21 13:46;iv732;Inventory created.

Postgres Port: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/ports.yml]

(simply choose the next sequencial number)

Database setup: https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Create+and+configure+Postgres+DB

 

 ","15/Jan/21 11:40;iv732;#connect to db-host (in this case xbtestpdb1)

#create fs:
lvcreate -n lv_pgsql_ctpn_25035_data -L 5g datavg
lvcreate -n lv_pgsql_ctpn_25035_log -L 5g datavg
lvcreate -n lv_pgsql_ctpn_25035_backup -L 5g datavg
mkfs.xfs -f /dev/datavg/lv_pgsql_ctpn_25035_backup
mkfs.xfs -f /dev/datavg/lv_pgsql_ctpn_25035_log
mkfs.xfs -f /dev/datavg/lv_pgsql_ctpn_25035_data
mkdir -p /var/lib/pgsql_ctpn_25035/{data,log,backup}

#add fs to /etc/fstab
## Database dedicated filesystems
/dev/mapper/datavg-lv_pgsql_ctpn_25035_data /var/lib/pgsql_ctpn_25035/data xfs defaults 0 0
/dev/mapper/datavg-lv_pgsql_ctpn_25035_log /var/lib/pgsql_ctpn_25035/log xfs defaults 0 0
/dev/mapper/datavg-lv_pgsql_ctpn_25035_backup /var/lib/pgsql_ctpn_25035/backup xfs defaults 0 0

#mount new fs

mount /var/lib/pgsql_ctpn_25035/data
mount /var/lib/pgsql_ctpn_25035/log
mount /var/lib/pgsql_ctpn_25035/backup

#set proper permissions

chown -R postgres:postgres /var/lib/pgsql_ctpn_25035


#create directory for the install scripts (port for the new db is 25035)

mkdir -p /var/lib/pgsql_ctpn_25035/data/ADMIN/INSTALL

#copy 3 shell-scripts from /var/lib/pgsql/ADMIN/INSTALL/*.sh to the new directory

cp /var/lib/pgsql/ADMIN/INSTALL/*.sh /var/lib/pgsql_ctpn_25035/data/ADMIN/INSTALL
ll /var/lib/pgsql_ctpn_25035/data/ADMIN/INSTALL
cd /var/lib/pgsql_ctpn_25035/data/ADMIN/INSTALL
chown postgres:postgres *

#change to ""postgres"" user
#edit these scripts by new env

vim 001_CHOWN.sh
vim 002_MKDIR.sh
vim 003_MKDIR_AND_BACKUP_CONFIG.sh

#run the first two scripts

./001_CHOWN.sh
./002_MKDIR.sh

#before running this script 003_MKDIR_AND_BACKUP_CONFIG.sh run initdb!!!

/usr/pgsql-12/bin/pg_ctl initdb -D /var/lib/pgsql_ctpn_25035/data/12

#Then start the database 
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql_ctpn_25035/data/12 start



#run the third script

./003_MKDIR_AND_BACKUP_CONFIG.sh

#copy the rest of the ADMIN/INSTALL scripts from an other env (for example xbid cute cptl)

cp /var/lib/pgsql_ctpl_25033/data/12/ADMIN/INSTALL/0* .

#edit all scripts by new env
vim 000_VARIABLES.INP
vim 010_CREATE_DATABASE.sh
vim 020_CREATE_SCHEMA.sh
vim 030_ALTER_ROLE.sh (change the passwords!!!)
vim 034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sh

#copy the postgressql config and pg_hba.conf files from other environment and edit both

cd /var/lib/pgsql_ctpn_25035/data/12
cp /var/lib/pgsql_ctpm_25034/data/9.5/postgresql.conf .
vim postgresql.conf

# Important:  Change the listening address to 0.0.0.0 in order to automate pg_hba.conf

-bash-4.2$  vim /var/lib/pgsql_ctpn_25035/data/12/postgresql.conf
listen_addresses = '0.0.0.0'

cp /var/lib/pgsql_ctpm_25034/data/9.5/pg_hba.conf .
vim pg_hba.conf
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql_ctpn_25035/data/12 reload

cd /var/lib/pgsql_ctpn_25035/data/ADMIN/INSTALL
./010_CREATE_DATABASE.sh
./020_CREATE_SCHEMA.sh
./030_ALTER_ROLE.sh
./034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sh

# run the following command to creat ams database (will be automated!)
CREATE ROLE xbctpnams LOGIN;
ALTER ROLE xbctpnams WITH PASSWORD '9bAsbMtQd8';
CREATE ROLE udev01xbctpnams LOGIN;
ALTER ROLE udev01xbctpnams WITH PASSWORD 'TESTdev01xbctpnams';
CREATE ROLE uapp01xbctpnams LOGIN;
ALTER ROLE uapp01xbctpnams WITH PASSWORD '5mRsbVmQd5';
CREATE DATABASE   xbctpnams WITH OWNER  xbctpnams;
CREATE SCHEMA xbctpnams AUTHORIZATION xbctpnams;
GRANT SELECT ON ALL TABLES IN SCHEMA xbctpnams TO udev01xbctpnams;
GRANT USAGE ON SCHEMA xbctpnams TO udev01xbctpnams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbctpnams GRANT SELECT ON TABLES TO udev01xbctpnams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbctpnams GRANT USAGE ON SEQUENCES TO udev01xbctpnams;
GRANT CONNECT ON DATABASE xbctpnams TO udev01xbctpnams;

ALTER DEFAULT PRIVILEGES IN SCHEMA xbctpnams GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO uapp01xbctpnams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbctpnams GRANT USAGE ON SEQUENCES TO uapp01xbctpnams;
ALTER DEFAULT PRIVILEGES IN SCHEMA xbctpnams GRANT EXECUTE ON FUNCTIONS TO uapp01xbctpnams;
GRANT CONNECT ON DATABASE xbctpnams TO uapp01xbctpnams;
GRANT USAGE ON SCHEMA xbctpnams TO uapp01xbctpnams;



GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES   IN SCHEMA xbctpnams TO uapp01xbctpnams;
GRANT USAGE   ON ALL SEQUENCES  IN SCHEMA xbctpnams TO uapp01xbctpnams;
GRANT EXECUTE   ON ALL FUNCTIONS  IN SCHEMA xbctpnams TO uapp01xbctpnams;","15/Jan/21 11:40;iv732;Vault is done.
Steps:
1. Clone this repo: energy.automation.inventory
2. Under ~/energy.automation.inventory/bin, copy the vault script from any old env and modify it:

{code:java}
#!/bin/bash
#
# Creates vault entries required by ansible deployment for a new xbid environment.
#
# !!! provide correct values in CONFIGURATION section first before any ecxecution
#

#
# Start of CONFIGURATION
#

# Target environment identifier
tenv=ctpn
tenv_type=test # possible values: prod / simu / test


is_alarmtilt_enabled=true # possible values: true / false
alarmtilt_username=proc.launcher.n@deutsche-boerse.com
alarmtilt_password=1234567

mail_cluster=test # xb for PROD, test otherwise
mail_domain=xbid-test.deutsche-boerse.com
mail_user_cor_password=""DU6bru7Yl9""
mail_user_cmi_password=""bUowcWlXX-""
mail_user_spm_password=""Tk1w4nAbhD""

ldap_admin_username=xbid-ctpn-adm
ldap_amin_password=test01
# !!! the related kv put command is commented out, it should already exist in the vault
file_ldap_truststore=ldaptruststore.jks # file containing jks truststore enabling ssl access to ldap server

amqp_admin_username=comxerv
amqp_admin_password=m7


#
# CORE
#
# database CORE, user used by CORE
db_cor_cor_username=uapp01xbctpncor
db_cor_cor_password=""FQaHn4nnke""
db_cor_owner_password=""QRd4jHzmtnvqdxbctpncor""

# if true the the CORE stores performance stats into elastic database, if false then the performance stats are stored                                                                                                                         into a file
is_cor_elastic_enabled=true # possible values: true / false
cor_elastic_username=xbid_perfstats
cor_elastic_password=jgt9UdCfHrMe3dkwsfsp

#
# Trading enquiry (aka SOB)
#
# database CORE, user used by SOB
db_cor_sob_username=uapp01xbctpnsob
db_cor_sob_password=""3DSdmCeFxE""

# AMQP users accessing SOB
amqp_tmcore_password=fi97xVJ338xD
amqp_tmpmi_password=D9aWUlewBFGZ
amqp_tminteg_password=6EwfNvdUeP29
amqp_tmspm_password=6EwfNvdUeP29

# user used by SOB to access reporting engine
enq_reporting_user=remoteuser
enq_reporting_password=fdsb76v


#
# CMM
#
# database CORE, user used by CMM
db_cor_cmm_username=uapp01xbctpncmm
db_cor_cmm_password=""C5J5J9ycTT""

amqp_cmm_inquiry_username=cmm-inquiry
amqp_cmm_inquiry_password=m7


#
# CMI
#
# database CMI, user used by CMI
db_cmi_cmi_username=uapp01xbctpncmi
db_cmi_cmi_password=""JujZU7jeMp""
db_cmi_owner_password=""QRd4jHzmtnvqdxbctpncmi""

amqp_cmi_password=ploplophugahuga

#file_cmi_mail_keystore=cmi.jks # file containing certificates for mail encryption/decryption
#cmi_mail_keystore_password=test01
#cmi_mail_decrypt_keystore_password=""Bd51$/Zc""

# !!! the related kv put command is commented out, it should already exist in the vault
file_cmi_sftp_key=cmi_sftp_id_rsa_key # file containing key for sftp access


#
# SMC / SMI, a variable with spm in its name is shared by both modules
#
# database SPM, user used by both modules SMC and SMI
db_spm_smc_username=uapp01xbctpnspm
db_spm_smc_password=""urLjXwyD6t""
db_spm_owner_password=""QRd4jHzmtnvqdxbctpnspm""

amqp_smc_username=xbid-spm
amqp_smc_password=xbidtest01

file_spm_mail_keystore=spm.jks # file containing certificates for mail encryption/decryption
spm_mail_keystore_password=dummy
spm_mail_decrypt_keystore_password=dummy

# !!! the related kv put command is commented out, it should already exist in the vault
file_spm_ssh_known_hosts=spm_ssh_known_hosts # file containing ssh known hosts


# PMI-LOGGER
pmilog_amqp_password="".MPE?+7MUrg/a;Yx""

# RE (aka Reporting engine)
db_rep_owner_password=""QRd4jHzmtnvqdxbctpnrep""
db_rep_rep_username=uapp01xbctpnrep
db_rep_rep_password=""Y8YqZzg8f8""

# Report Tool
#db_report_tool_username=""report_tool_ctpn""
#db_report_tool_password=""OOt97gn09b5x27n9PWd0""
#db_cor_report_tool_username=""uapp01xbctpasla""
#db_cor_report_tool_password=""f4~3N%BS""
#db_spm_report_tool_username=""uapp01xbctpasla""
#db_spm_report_tool_password=""f4~3N%BS""

#
# End of CONFIGURATION
#

echo -e ""\nInitialize vault entries for environmnet ${tenv}, type: ${tenv_type}\n""

if [[ ""$is_alarmtilt_enabled"" = ""true"" ]]
then
    vault kv put /secret/xb/xbid/${tenv}/alarmtilt/proc_launcher_user password==${alarmtilt_password} username=${alar                                                                                                                        mtilt_username}
fi
vault kv put /secret/xb/xbid/${tenv}/amqp/admin password=${amqp_admin_password} user=${amqp_admin_username}
vault kv put /secret/xb/xbid/${tenv}/ldap/admin password=${ldap_amin_password} username=${ldap_admin_username}
#vault kv put /secret/certs/root/comodo/keystore value=""$(openssl base64 -A -in ${file_ldap_truststore})""

# CORE
vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}cor owner_password=${db_cor_owner_password} password=${db_cor_cor_pa                                                                                                                        ssword} username=${db_cor_cor_username}
if [[ ""$is_cor_elastic_enabled"" = ""true"" ]]
then
    vault kv put /secret/xb/xbid/${tenv}/elastic username=${cor_elastic_username} password=${cor_elastic_password}
fi

# Trading enquiry (aka SOB)
vault kv put /secret/app-messaging/${mail_cluster}/xb${tenv}-cor@${mail_domain} value=${mail_user_cor_password}
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}ext/tm-core-1 password=${amqp_tmcore_password} username=tm-core-1
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}ext/tm-pmi-1 password=${amqp_tmpmi_password} username=tm-pmi-1
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}int/tm-integ-1 password=${amqp_tminteg_password} username=tm-integ                                                                                                                        -1
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}int/tm-shipping-1 password=${amqp_tmspm_password} username=tm-ship                                                                                                                        ping-1
vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}sob password=${db_cor_sob_password} username=${db_cor_sob_username}
vault kv put /secret/xb/xbid/${tenv}/reporting_engine/remote_user password=${enq_reporting_password} username=${enq_r                                                                                                                        eporting_user}

# CMM
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}ext/cmm-inquiry-1 password=${amqp_cmm_inquiry_password} username=$                                                                                                                        {amqp_cmm_inquiry_username}
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}int/cmm-inquiry-1 password=${amqp_cmm_inquiry_password} username=$                                                                                                                        {amqp_cmm_inquiry_username}
vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}cmm password=${db_cor_cmm_password} username=${db_cor_cmm_username}

# CMI
#vault kv put /secret/app-messaging/${mail_cluster}/xb${tenv}-cmi@${mail_domain} value=${mail_user_cmi_password}
#vault kv put /secret/xb/xbid/${tenv}/amqp_cmi_pass value=${amqp_cmi_password}
#vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}cmi owner_password=${db_cmi_owner_password} password=${db_cmi_cmi_p                                                                                                                        assword} username=${db_cmi_cmi_username}

#vault kv put /secret/xb/xbid/${tenv}/mail/cmi/keystore password=${cmi_mail_keystore_password} file=""$(openssl base64                                                                                                                         -A -in ${file_cmi_mail_keystore})""
#vault kv put /secret/xb/xbid/${tenv}/mail/cmi/decrypt password=${cmi_mail_decrypt_keystore_password}
#vault kv put /secret/xb/xbid/${tenv_type}/sftp/id_rsa_sftp value=""$(openssl base64 -A -in ${file_cmi_sftp_key})""

# SMC
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}int/smc-1 password=${amqp_smc_password} username=${amqp_smc_userna                                                                                                                        me}
vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}spm owner_password=${db_spm_owner_password} password=${db_spm_smc_pa                                                                                                                        ssword} username=${db_spm_smc_username}
vault kv put /secret/xb/xbid/${tenv}/mail/smc/keystore password=${spm_mail_keystore_password} file=""$(openssl base64                                                                                                                         -A -in ${file_spm_mail_keystore})""
vault kv put /secret/xb/xbid/${tenv}/mail/smc/decrypt password=${spm_mail_decrypt_keystore_password}

#vault kv put /secret/xb/xbid/${tenv_type}/ssh/known_hosts value=@${file_smc_ssh_known_hosts})

# SMI
vault kv put /secret/app-messaging/${mail_cluster}/xb${tenv}-spm@${mail_domain} value=${mail_user_spm_password}
vault kv put /secret/xb/xbid/${tenv}/mail/smi/keystore password=${spm_mail_keystore_password} file=""$(openssl base64                                                                                                                         -A -in ${file_spm_mail_keystore})""
vault kv put /secret/xb/xbid/${tenv}/mail/smi/decrypt password=${spm_mail_decrypt_keystore_password}

# PMI-LOGGER
vault kv put /secret/xb/xbid/${tenv}/amqp/xb${tenv}ext/pmi-logger-1 password=${pmilog_amqp_password}

# RE
vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}rep owner_password=${db_rep_owner_password} password=${db_rep_rep_pa                                                                                                                        ssword} username=${db_rep_rep_username}

# Report Tool
#vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}reporttool/reporttool username=${db_report_tool_username} password=                                                                                                                        ${db_report_tool_password}
#vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}reporttool/cor username=${db_cor_report_tool_username} password=${d                                                                                                                        b_cor_report_tool_password}
#vault kv put /secret/xb/xbid/${tenv}/db/xb${tenv}reporttool/spm username=${db_spm_report_tool_username} password=${d                                                                                                                        b_spm_report_tool_password}

{code}
3. Execute it

{code:java}
[iv732@enprodauto1 {master L | ?16} ~/energy.automation.inventory/bin]$ ./xbid-env-vault-secrets-init-ctpn.sh

Initialize vault entries for environmnet ctpn, type: test

Success! Data written to: secret/xb/xbid/ctpn/alarmtilt/proc_launcher_user
Success! Data written to: secret/xb/xbid/ctpn/amqp/admin
Success! Data written to: secret/xb/xbid/ctpn/ldap/admin
Success! Data written to: secret/xb/xbid/ctpn/db/xbctpncor
Success! Data written to: secret/xb/xbid/ctpn/elastic
Success! Data written to: secret/app-messaging/test/xbctpn-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnext/tm-core-1
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnext/tm-pmi-1
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnint/tm-integ-1
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnint/tm-shipping-1
Success! Data written to: secret/xb/xbid/ctpn/db/xbctpnsob
Success! Data written to: secret/xb/xbid/ctpn/reporting_engine/remote_user
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnext/cmm-inquiry-1
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnint/cmm-inquiry-1
Success! Data written to: secret/xb/xbid/ctpn/db/xbctpncmm
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnint/smc-1
Success! Data written to: secret/xb/xbid/ctpn/db/xbctpnspm
Success! Data written to: secret/xb/xbid/ctpn/mail/smc/keystore
Success! Data written to: secret/xb/xbid/ctpn/mail/smc/decrypt
Success! Data written to: secret/app-messaging/test/xbctpn-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpn/mail/smi/keystore
Success! Data written to: secret/xb/xbid/ctpn/mail/smi/decrypt
Success! Data written to: secret/xb/xbid/ctpn/amqp/xbctpnext/pmi-logger-1
Success! Data written to: secret/xb/xbid/ctpn/db/xbctpnrep

{code}
","18/Jan/21 12:58;iv732;Preparing LDAP - DONE

GoTo S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\SI\LDAP
Take 2 of the existing .ldif files: one _sm and one _xbid
Copy and rename it to the new place
Open the file and search and replace
Import the .ldif file to the LDAP using Apache Directory Studio (or use CLI instead: Customer LDAP#AddLDIFtoM7testLDAP )","18/Jan/21 15:51;iv732;Running deployments, found different errors.

CREATE USERS: tomcat, rabbitmq
Modify /etc/ssh/sshd_config to have this line:
+ for rabbitmq host:
Match User ansible,globmon,scanmgr,rabbitmq
+ for tomcat host:
Match User ansible,globmon,scanmgr,tomcat


CREATE FILE SYSTEMS:
For the tomcat host: 
XBCTPNCOR1
XBCTPNENQ1
XBCTPNDOW1


lvcreate -n lv_xbid -L 2g rootvg
lvcreate -n lv_xbid_logs -L 4g rootvg

mkfs -t ext4 /dev/mapper/rootvg-lv_xbid
mkfs -t ext4 /dev/mapper/rootvg-lv_xbid_logs
mkdir -vp /xbid/logs
chown -R tomcat:tomcat /xbid

Edit /etc/fstab:

/dev/mapper/rootvg-lv_xbid /xbid ext4 defaults 0 0
/dev/mapper/rootvg-lv_xbid_logs /xbid/logs ext4 defaults 0 0

###
For the rabbitmq host

lvcreate -n lv_xbid -L 1g rootvg
lvcreate -n lv_xbid_logs -L 1g rootvg

Edit /etc/fstab to have these 2 lines at the end:

/dev/mapper/rootvg-lv_xbid /xbid ext4 defaults 0 0
/dev/mapper/rootvg-lv_xbid_logs /xbid/logs ext4 defaults 0 0

mkfs -t ext4 /dev/mapper/rootvg-lv_xbid
mkfs -t ext4 /dev/mapper/rootvg-lv_xbid_logs
mkdir -vp /xbid
mount -a
mkdir -vp /xbid/logs
chown -R rabbitmq:rabbitmq /xbid","19/Jan/21 17:05;iv732;Some error regarding vault:

secret/xb/xbid/ctpn/amqp_cmi_pass
secret/xb/xbid/ctpn/amqp_mon_pass
secret/xb/xbid/ctpn/amqp_spm_pass
secret/app-messaging/test/xbctpn-cmi@xbid-test.deutsche-boerse.com","19/Jan/21 17:09;iv732;Fixed the vault entries. Now get error with rabbitmq


{code:java}
/xbid/xbid-ctpn-ext-amq1/sbin/rabbitmq-server: line 47: erl: command not found
{code}
Installed erlang:  yum install XBID-erlang

Everything is working fine now excep this:


{code:java}
Trying to reach rabbit management UI on address http://localhost:52490

ok: [xb-xbid-ctpn-int-amq1] => {}



MSG:



Trying to reach rabbit management UI on address http://localhost:52491



TASK [xbrabbitmq-instance : Wait for rabbit management UI to become alive - check url response] ***

ok: [xb-xbid-ctpn-ext-amq1]

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (40 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (39 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (38 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (37 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (36 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (35 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (34 retries left).

FAILED - RETRYING: Wait for rabbit management UI to become alive - check url response (33 retries left).
{code}

Increased disk space on rabbitmq host. The problem is solved","20/Jan/21 13:31;iv732;Redeployed all components. Stuck at starting cor:

{code:java}
+ ansible-playbook playbooks/deploy_xbcor.yml --limit '~xb-xbid-ctpn-cor1' --inventory xb/xbid/ctpn --tags start --diff -e app_version=3.1.11
PLAY [Deploy XBID core] ********************************************************
TASK [Gathering Facts] *********************************************************
ok: [xb-xbid-ctpn-cor1]
TASK [xbtomcat : Start the application] ****************************************
fatal: [xb-xbid-ctpn-cor1]: FAILED! => {
    ""changed"": true,
    ""cmd"": ""/xbid/xbid-ctpn-cor1/tomcat/bin/start.sh"",
    ""delta"": ""0:01:00.714522"",
    ""end"": ""2021-01-20 13:18:05.118153"",
    ""rc"": 1,
    ""start"": ""2021-01-20 13:17:04.403631""
{code}
","20/Jan/21 15:59;iv732;Created ticket for Comtrader download:  https://jira.deutsche-boerse.com/browse/XP-4386","20/Jan/21 16:01;iv732;Installed ZULU Java.
Did this manually:

{code:java}
- name: JAVA_PATH variable definition file
  copy:
    src: ""files/java_srvops.sh""
    dest: ""/etc/profile.d/java_srvops.sh""
    owner: ""root""
    group: ""root""
    mode: ""0644""

{code}
Created /opt/java folder and the soft link default -> /usr/lib/jvm/zulu-8
set JAVA_HOME to point to /opt/java/default","21/Jan/21 10:43;iv732;generated ssh key for log transfer. Uploaded here.","21/Jan/21 11:02;iv732;EBSM logfile transfer

Ensure that the log file copy to EBSM is running

+ configure ssh key

+ update transfer script (also on github)

+ configure logmover on EBSM: /opt/logmover/properties/Logfile.properties & /opt/ebsm/properties/Logfile.properties

+ create crontab for tomcat user on the cor1 host","21/Jan/21 12:18;iv732;Configure env variable for tomcat user by copying the /xbid/profile directory from another env such as ctpm and modify them
Note; 
tomcat@xbctpncor1:[/xbid]$ touch ~/.bash_login
{code:java}
# cat /home/tomcat/.profile
# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs

PATH=$PATH:$HOME/bin
export PATH
export BASEDIR=xbid

if [ -f /xbid/profile/def.profile.sh ];then
    . /xbid/profile/def.profile.sh
fi

if [ -f /xbid/profile/aliases.profile.sh ];then
    . /xbid/profile/aliases.profile.sh
fi

{code}
{code:java}
cat /xbid/profile/def.profile.sh
#!/bin/ksh

if [ -f ~/.bashrc ]; then
        . ~/.bash_login
fi

PS1=`whoami`@`uname -n`':[$PWD]$ '
EDITOR=vi
set -o vi
TERM=vt100
export PS1 EDITOR TERM

# Determine the customer prefix from the filesystem base
if [[ $BASEDIR = ""cltr"" ]]
then
  cust=cltx;
else
  cust=$BASEDIR;
fi;
export cust

env=ctpn;
export env

# Determine the application instance
if [ $(echo `uname -n` | grep amq1) ]; then serv=amq1; fi;
if [ $(echo `uname -n` | grep amq2) ]; then serv=amq2; fi;
export serv

export PATH=$PATH:/${BASEDIR}/prodscripts
export PRODSUP_LOGDIR=/${BASEDIR}/logs/prodscripts
export PRODSCRIPT=/${BASEDIR}/prodscripts
export PRODSCRIPT_LOG=/${BASEDIR}/logs/prodscripts
export PRODSCRIPT_LAUNCH_RMT_FEAT=Y

cd /$BASEDIR

unset DISPLAY

if [ -d /opt/java/default ]
 then
  export JAVA_HOME=/opt/java/default
  export JRE_HOME=/opt/java/default/jre
fi

{code}

{code:java}
cat aliases.profile.sh
alias prod='cd /${BASEDIR}/prodscripts'
alias conf='cd /${BASEDIR}/prodscripts/config'
alias prof='cd /${BASEDIR}/profile'
alias logs='cd /${BASEDIR}/logs'
alias ls > /dev/null 2>&1
if [ $? -eq 0 ]
 then
  unalias ls
fi
alias sshamq1='ssh -o StrictHostKeyChecking=no rabbitmq@xbctpnamq1'
alias sshcor1='ssh -o StrictHostKeyChecking=no tomcat@xbctpncor1'
alias sshenq1='ssh -o StrictHostKeyChecking=no tomcat@xbctpnenq1'
alias sshdow1='ssh -o StrictHostKeyChecking=no tomcat@xbctpndow1'
alias sshrep1='ssh -o StrictHostKeyChecking=no tomcat@xbcutsrep1'
alias sshweb1='ssh -o StrictHostKeyChecking=no apache@xbcutsweb1'
alias sshssl1='ssh -o StrictHostKeyChecking=no sslsrv@xbcutsssl1'
alias sshpmi1='ssh -o StrictHostKeyChecking=no tomcat@xbcutspmi1'
alias sshrpt1='ssh -o StrictHostKeyChecking=no tomcat@xbcutsrpt1'

{code}
","21/Jan/21 13:54;iv732;
{code:java}
[tomcat@xbctpncor1 ~]$ cat .bash_profile
# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs

PATH=$PATH:$HOME/.local/bin:$HOME/bin

export PATH
export PWD=xbid

{code}
","21/Jan/21 13:59;iv732;
{code:java}
[tomcat@xbctpncor1 xbid]$ cat .profile
# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs

PATH=$PATH:$HOME/bin
export PATH
export BASEDIR=xbid
export PWD=xbid
if [ -f /xbid/profile/def.profile.sh ];then
    . /xbid/profile/def.profile.sh
fi

if [ -f /xbid/profile/aliases.profile.sh ];then
    . /xbid/profile/aliases.profile.sh
fi

if [ -f /xbid/profile/.bash_profile ];then
    . .bash_profile
fi

{code}
","21/Jan/21 16:00;iv732;According to Roman, our Jenkins job should be able to trigger the ""configure"" tag at the very beginning of the deployment.


{code:java}
Roman  3:56 PM
@Tuan Nguyen regarding the user setup:
We should already include user creation in those roles:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/tomcat_server
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/apache_server
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/haproxy_server
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/rabbitmq_server
Respective ansible playbooks mostly already include them, e.g.:
---
- name: Deploy XBID core
  hosts: xbcor
  serial: ""{{ ansible_run_serial | default(2) }}""
  become: true
  become_user: ""tomcat""
  roles:
    - { role: tomcat_server, tags: [""configure""], become: true, become_user: root }
    - xbcor
so only the jenkins pipeline needs a mechanism to trigger the configure tag as a first time setup (edited) 





3:58
In those roles, all setup steps that require root privileges should be included.
user creation
ulimits changes
permission changes
packet installation (erlang, java, ...)
(in future) lv and mountpoint creation
currently missing: reconfigure sssd /sshd after technical user creation. So after the first run, a os_authentication playbook would be required to run
{code}
","22/Jan/21 10:06;iv732;pea file received.
 [^fra1_xbctpnpmi.pea] 

put to vault

/secret/xb/xbid/ctpn/centera pea_xml=@${file_centera_pea_xml}","22/Jan/21 12:31;iv732;Modified transfer script to transfer log from each host, not only from the cor1 host


{code:java}
#!/bin/bash

. ~tomcat/.bash_profile

################################
#
# Purpose : Transfer the log file to EBSM host
#
# Author  : CM / SMD
#
# Language : shell
#
# Creation Date : 2015
#
#
################################

BASE_DIR=""xbid""
env=""ctpn""
cust=""xbid""
for file in `find /${BASE_DIR}/logs/* -type f -name ""*${env}*"" | grep $env | grep $cust | egrep -v ""heapdump|transferred|prodscripts|catalina|manager|localhost|startup_err|startup_log|shutdown_err|shutdown_log|rolled-over-|archived-messages|stdout|gc.log|pmi-messages.log"" 2>/dev/null`
do
          fil=`basename $file`
          dir=`dirname $file`
          if [ ! -f $dir/transferred/$fil.sent ]
          then
                filename=`basename ${file}`
                scp -p -o StrictHostKeyChecking=no ${file} ebsmbox@m7shrdebsm1.deutsche-boerse.de:/var/log/ebsm/inbox/${filename}.filepart
                ssh -o StrictHostKeyChecking=no ebsmbox@m7shrdebsm1.deutsche-boerse.de chmod 777 /var/log/ebsm/inbox/${filename}.filepart
                ssh -o StrictHostKeyChecking=no ebsmbox@m7shrdebsm1.deutsche-boerse.de mv /var/log/ebsm/inbox/${filename}.filepart /var/log/ebsm/inbox/${filename}
                # We want to recognise if the transfer has failed or was successful
                if [ $? = 0 ]
                then
                        echo $file is successfully transferred
                        # We only want to archive the scripts which are rolled over
                        if [[ ${file} == *""rollover""* ]]
                        then
                                mkdir -p $dir/transferred
                                touch $dir/transferred/$fil.sent
                                echo $dir/transferred/$fil.sent touched
                        fi
                else
                        echo $file is NOT successfully transferred
                fi
          else
                echo $file already transferred
                fileD=$(stat -L --format %y ${file} | awk '{print $1}')
                if [ ${fileD} != $(date +%Y-%m-%d) ]
                then
                        mkdir -p $dir/transferred
                        mv $file $dir/transferred
                        gzip $dir/transferred/$fil
                        echo $file moved
                fi
          fi
done
echo Tomcat log  transfer is completed
~

{code}

Tested uploading to ebsm successfully

{code:java}
[root@m7shrdebsm1 inbox]# ls -alrt *ctpn*
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Jan 20 15:37 xb_xbid_ctpn_cor-1_obkdepth_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  3773224 Jan 21 00:00 xb_xbid_ctpn_cor-1_standard_ixe_0_2021-01-20.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox 87606404 Jan 21 12:26 xb_xbid_ctpn_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 20695124 Jan 21 12:26 xb_xbid_ctpn_cor-1_gc_ixe.log.0.current

{code}
","22/Jan/21 12:54;iv732;crontab for log transfer done
","22/Jan/21 12:55;iv732;Updated confluence:
https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=10470502","25/Jan/21 12:13;iv732;requested CNAME record for ctpn profiles
https://jira.deutsche-boerse.com/browse/SYSENGEXT-313","25/Jan/21 12:14;iv732;configuring netbackup - done
Sent email to NBUADMINs:


{code:java}
Hello,
Can you please add the following backups:


1. VM backup (View: FFM_Energy). All the servers are in 476(DMZFRA1)(10.139.40.0/23)
                XBCTPNCOR1
                XBCTPNENQ1
                XBCTPNDOW1
                XBCTPNAMQ1
2. File backup (for database server)
                DB host: xbtestpdb1
                Port: 25035
                Scripts: 
                /usr/bin/
/usr/bin/backup-ampgsql#ctpn#Full.sh
 		/usr/bin/backup-ampgsql#ctpn#INCREMENTAL.sh
               	/usr/bin/backup-ampgsql#ctpn.sh
/usr/bin/query-ampgsql#ctpn.sh
               	/usr/bin/restore-ampgsql#ctpn.sh

                /etc
/etc/netbackup.ampgsql#ctpn
/etc/netbackup.ampgsql#ctpn#Full
               	/etc/netbackup.ampgsql#ctpn#INCREMENTAL



Thank you.
Regards,

{code}

","25/Jan/21 14:02;iv732;Added the new environment to the nightly config check job in Jenkins : All-TechOps-Check-Config","25/Jan/21 14:30;iv732;prepare Monitoring...

Error deploying filebeat:


{code:java}
- name: Deploy filebeat.yml config
  ^ here

fatal: [xbctpndow1]: FAILED! => {}

MSG:

The conditional check 'filebeat_product != false' failed. The error was: error while evaluating conditional (filebeat_product != false): 'filebeat_product' is undefined

The error appears to have been in '/home/jenkins/workspace/Energy-Operations/Monitoring/Deploy Monitoring Clients/roles/filebeat/tasks/install.yml': line 59, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: Deploy filebeat.yml config
{code}
","29/Jan/21 10:35;iv732;Got answer from CCI team


{code:java}
Tobias Henkes:server port 50490 
connection-log all 
session-sync 
tcp 
server port 50491 
connection-log all 
session-sync 
tcp 
server port 52490 
connection-log all 
session-sync 
tcp 
server port 52491 
connection-log all 
session-sync 
tcp 
server port 60490 
connection-log all 
session-sync 
tcp 
server port 60491 
connection-log all 
session-sync 
tcp 
server port 60492 
connection-log all 
session-sync 
tcp 
server port 60493 
connection-log all 
session-sync 
tcp 

server real XBCUTSSSL1 
port 50490 
port 50490 keepalive 
port 50491 
port 50491 keepalive 

server real XBCUTSWEB1 
port 60490 
port 60490 keepalive 
port 60491 
port 60491 keepalive 
port 60492 
port 60492 keepalive 
port 60493 
port 60493 keepalive 

server remote-name XBCTPNAMQ1 10.139.41.206 
source-nat 
port 52490 
port 52490 keepalive 
port 52491 
port 52491 keepalive 

server virtual XBID-ctpn1 10.136.142.36 
sym-priority 200 
port 50490 
port 50491 
port 52490 
port 52491 
port 60490 
port 60491 
port 60492 
port 60493 
bind 50490 XBCUTSSSL1 50490 
bind 50491 XBCUTSSSL1 50491 
bind 52490 XBCTPNAMQ1 52490 
bind 52491 XBCTPNAMQ1 52491 
bind 60490 XBCUTSWEB1 60490 
bind 60491 XBCUTSWEB1 60491 
bind 60492 XBCUTSWEB1 60492 
bind 60493 XBCUTSWEB1 60493
{code}
","29/Jan/21 12:41;iv732;FW request and DNS request must be submiited separately!!!!!!
New FW request:  #507105 | EGY - Internet access to XBID CTPN ","03/Feb/21 12:25;iv732;Issue split into:
|XP-4509|Wait for the Firewall request, check connections|
","18/Feb/21 09:31;ab039;Hi [~iv732], 

could you please update the IP and ports in Cute 14 in [^XBID Connectivity Details Individual CuTes - v1.3.docx]?",,,,,
CLONE - XBID SIMU new version of XBID R3.1.2 RabbitsMQ 3.8.5 ,XP-3822,100822,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,tm431,hw120,30/Sep/20 11:04,02/Nov/20 12:55,22/Feb/21 13:26,01/Oct/20 21:31,,,3.1.2,,,,,,,,,,,"0) perform VM power off / power on (not reboot!) as redefined in SERVICE-8268
|xbdsldap1|
|xbsimucbn1|
|xbsimucha1|
|xbsimusla1|
|xbsimuldp1|
|xbsimuglfs1|
|xbsimucons1|
|xbsimudbr1|
|xbsimucons3|
|xbsimucons5|

1) FIx all possilble problems after Hausen PowerMaintenance test from weekend 26-28/2020 ???

2) fix flyway history table
{code:java}
-bash-4.2$ cat /var/lib/pgsql/flyway_history_table_fix.sql
DROP INDEX ""schema_version_ir_idx"";
DROP INDEX ""schema_version_vr_idx"";
ALTER TABLE ""flyway_schema_history"" DROP COLUMN ""version_rank"";
ALTER TABLE ""flyway_schema_history"" DROP CONSTRAINT ""flyway_schema_history_pk"";
ALTER TABLE ""flyway_schema_history"" ALTER COLUMN ""version"" DROP NOT NULL;
ALTER TABLE ""flyway_schema_history"" ADD CONSTRAINT ""flyway_schema_history_pk"" PRIMARY KEY (""installed_rank"");
UPDATE ""flyway_schema_history"" SET ""type""='BASELINE' WHERE ""type""='INIT';

-bash-4.2$ for instance in cor; do psql -p 25102 -dxbsimu$instance -f flyway_history_table_fix.sql; done
-bash-4.2$ for instance in cmi spm rep ctp; do psql -p 25202 -dxbsimu$instance -f flyway_history_table_fix.sql; done
{code}
execute in all simu databases migrated to postgres 12 (cor, cmi, spm, rep, ctp)

3) configure AlarmTilt to all modules to
 [https://v5.alarmtilt.net/login.seam]

The config change is already merged into inventory, so only deployment of affected modules is needed -> deploy:  xbid, spm, pmi-logger
 * *Jenkins job: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID%20Ansible%20deploy%20full/]*
 * *choose only: xbid, spm, pmi-logger*

4) Increase max_connection in DB:
{code:java}
patronictl -c /etc/patroni_xbsimusync/config.yml edit-config xbsimusync --pg max_connections=500
patronictl -c /etc/patroni_xbsimusync/config.yml restart xbsimusync
patronictl -c /etc/patroni_xbsimuasync/config.yml edit-config xbsimuasync --pg max_connections=500
patronictl -c /etc/patroni_xbsimuasync/config.yml restart xbsimuasync{code}
5) Deploy new versions of RabbitMQ and Erlang 
   *Rabbit MQ* - by ansible deployment
 {color:#1d1c1d} 3.8.5  -> new version{color}
 {color:#1d1c1d}   {color}*Erlang* - by ansible adhoc command
 {color:#1d1c1d} 22.1 -> new version TOs to prepare{color}
{code:java}
ansible all --limit 'xb*-simu-*amq*:xb*-simu-*xmq*' -m shell -a ""yum update XBID-erlang -y"" -b -K
{code}
{color:#1d1c1d}
 MR from SERVICE-6837 where we already deployed{color}

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2041]

6) Migrate remaining servers to RHLE 7.8 - > just to double check if we did not miss anything from last deployment TO check

As decided in https://jira.deutsche-boerse.com/browse/XP-3437

we will exclude database and consul hosts from upgrade, so here is the list of remaining hosts
{code:java}
ansible all -m shell -a ""cat /etc/redhat-release"" -b --limit 'xbsimu*' -K
xbsimucom1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucom2 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucom4 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucom3 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucom6 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucom5 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimuglfs1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimuglfs1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimusla1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimusla1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucbn1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimucbn2 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimuldp1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.6 (Maipo)
xbsimuldp2 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.6 (Maipo)
{code}
And as decided in this tickets discussion

https://jira.deutsche-boerse.com/browse/SYSENG-144?focusedCommentId=291639&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-291639

also above hosts will be not be upgraded.

So only remaining hosts are
{code:java}
xbsimusla1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
xbsimusla1 | SUCCESS | rc=0 >> Red Hat Enterprise Linux Server release 7.5 (Maipo)
{code}
7) SLA reporting tool and AM indicator reporting tool DBs should be migrated to PostgreSQL 12.4 see XP-3585 xbsimusla1 and xbsimusla2 to version 12.4, they are running still on old version
{code:java}
yum install -y postgresql12 postgresql12-server postgresql12-contrib postgresql12-debuginfo

su - postgres
psql -c ""SELECT * FROM pg_stat_activity;""
psql -c ""ALTER USER pg_watch2 RENAME TO pgwatch2;""
for db in report_tool_db am_reporting; do psql -d $db -c ""ALTER TABLE schema_version RENAME TO flyway_schema_history;ALTER TABLE flyway_schema_history DROP CONSTRAINT schema_version_pk; ALTER TABLE flyway_schema_history ADD CONSTRAINT flyway_schema_history_pk PRIMARY KEY (installed_rank);""; done

/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql/9.5/data/ stop
mkdir -p /var/lib/pgsql/12/data/
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ initdb
/usr/pgsql-12/bin/pg_upgrade -b /usr/pgsql-9.5/bin -B /usr/pgsql-12/bin -d /var/lib/pgsql/9.5/data -D /var/lib/pgsql/12/data -o ' -c config_file=/var/lib/pgsql/9.5/data/postgresql.conf' -O ' -c config_file=/var/lib/pgsql/12/data/postgresql.conf'
cp /var/lib/pgsql/9.5/data/postgresql.conf /var/lib/pgsql/12/data/
cp /var/lib/pgsql/9.5/data/pg_hba.conf /var/lib/pgsql/12/data/
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ start
./analyze_new_cluster.sh

/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ stop

# as root user
systemctl disable postgresql-9.5.service
systemctl enable postgresql-12.service
systemctl start postgresql-12.service
systemctl status postgresql-12.service
tail -f /var/lib/pgsql/12/data/pg_log/postgresql-Thu.log
{code}
*Date:* 1st October

*Start time*: 8:00-8:30 AM

*End time:* 2nd October 9:00 PM

*Target environment:* Simulation

 

Before Deployment pls also merge one fix
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2127/files]

*Software version:*

PACKAGE R3.1.2
||Component||Version||Comment||
|xbid|3.1.7|New|
|spm|3.1.2|Redeploy|
|comtrader|3.1.0|No change|
|pmilogger|1.1.0|Redeploy|
|pmiarchiving|1.0.18|No change|
|m7-xbid-report-tool|2.46|No change|
|alarmtilt-client|1.0.8|No change|
|h3. AMS|1.0.0|No change|
|h3. xbid-am-reporting|1.0.2|New|
|rep-engine|5.0.56|No change|

***************************************
 SCOPE OF JIRAs incl MRs, or new versions

*CRs:*
 XBID-5214 - BR11 Net position
 XP-3574    in Testing after test new version of xbid-am-reporting should be released.

-XBID-5170 Possible AMS bug ? only configuratin change- This will be delivered in the future

*BUGs*
 *Jira filter:*
 project = ""XBID Project"" and Phase = ""R3.1 UAT Reg I/III"" and type in (Bug,Problem) AND status != Closed

-XBID-5255 Using a new user's Initial Password does not prompt Password Change(*)-
 -XP-3776-
 waiting customer, if confirmation that this is a bug will be provided or not

-XBID-5254 Exported RED File only contains one timeseries(*)-
 -XP-3744-
 waiting customer, if confirmation that this is a bug will be provided or not.

-XBID-5251 Warning Message appears when it shouldn't(*)-
 -XP-3607-
 waiting customer, if confirmation that this is a bug will be provided or not.

XBID-5248 SOB Change password requirements incorrect(/)
 XP-3506 - This is only change in TEXT in GUI
 Cor should be released

XBID-5247 Contract Halt not lifted through Automatic Unhalting functionality(/)
 XP-3590
 Cor should be released

-XBID-5232 All kinds of user changed passwords accepted on SM(*)-
 -XP-3553-
 this is SPM part, this was fixed by new policy, customer is asked to retest

XBID-5231 Internal Server Error when trying to publish specific combination of files(/)
 XP-3550
 Cor should be released, and retest. It is ok now to finish this before 1/10 but would be good

XBID-5228 AM indicators - sFTP access to ""am"" folder without being authorized to see the AM indicators report(*)
 XP-3544 TRIVIAL
 This will require big change in sftp logic, we can put it on hold as this is trivial

XBID-5223 65 character password seemingly accepted; unable to login after the change(/)
 XP-3530
 Cor sould be released

XBID-5217 Cannot access File Management screen in CMM(/)
 XP-3535 -> [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2127/files] fixed by MR no new cor version

XBID-5216 Error message while a manual upload of capacity(/)
 XP-3529
 Cor should be relesed

*BUGs which customer should not be informed about*
 XP-3599 DA Cannot be deleted in a specific situation XBID-4823 Latent Fault - DA cannot be deleted in a specific situation",,hw120,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8179,,,,,,,,,,,,XP-3585,XP-3843,SERVICE-8179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,tm431,,,,,,,,,,,,,,Internal Deployment Request,eg288,jy268,qo794,,No,12528000,,SIMU,,,,,,dm700,lw641,ox626,rehapav,sw455,,02/Oct/20 08:21,XP-2234,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bo27:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
perform VM power cycling - XBID (internal) TEST,XP-3821,100815,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,30/Sep/20 10:18,02/Nov/20 12:50,22/Feb/21 13:26,14/Oct/20 14:20,,,Not a release,,,,,,,TechOps,,,,"Perform VM power off / power on (not reboot!) as redefined in SERVICE-8268

group 

(2) M7/XBID (internal) TEST

 
|Name|Host|Compatibility|EVC Generation|
|xbctpmamq1|fresxegy2009.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbctpmdow1|fresxegy2010.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Broadwell"" Generation|
|xbcutsams1|fresxegy1008.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Broadwell"" Generation|
|xbcutscha1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsprx1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbcutsrpt1|fresxegy2008.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|
|xbcutsssl1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Westmere"" Generation|
|xbcutsweb1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbintecha1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbintecha2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbinteprx1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbinteprx2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbintessl1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbintessl2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbinteweb1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbinteweb2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfcha2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfcom1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfcom2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfssl1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfssl2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfweb1|fresxegy1011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbperfweb2|fresxegy2011.deutsche-boerse.de|ESXi 5.1 and later (VM version 9)|Intel® ""Sandy Bridge"" Generation|
|xbsyt1ams1|fresxegy1008.deutsche-boerse.de|ESXi 6.7 Update 2 and later (VM version 15)|Intel® ""Broadwell"" Generation|
|xbsyt3imq1|fresxegy1008.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbsyt3imq2|fresxegy2010.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbsyt3imq3|fresxegy1008.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbsyt3xmq1|fresxegy1008.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbsyt3xmq2|fresxegy2010.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbsyt3xmq3|fresxegy1008.deutsche-boerse.de|ESXi 6.7 and later (VM version 14)|Intel® ""Skylake"" Generation|
|xbtestdbr2|fresxegy2010.deutsche-boerse.de|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|

todo
 * plan and execute power recycling

implementation team
 * power off can be done by xbid-techops, power on (and checking VM parameters) should be done by SysEng
 * restooring services then by xbid-techops",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-38,SERVICE-8268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bohc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/20 14:20;rehapav;Done on 14/10",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DB dumps for xbsimusla1/2,XP-3820,100796,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,qo794,qo794,30/Sep/20 07:52,06/Jan/21 15:42,22/Feb/21 13:26,06/Jan/21 13:38,,,,,,,,,,,,,,"Daily DB dumps (stored on ebsm) are not created for databases (SLA and AMR) running on xbsimusla1/2. Please finish the configuration as mentioned here:

https://jira.deutsche-boerse.com/browse/XP-3792?focusedCommentId=295788&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-295788

 
 - Jenkins Job as in XP-3792 should work but requires preparation regarding keys, ..",,iv732,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3974400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000e",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,HOT Sprint 20 (S),Xbops Sprint 22,Xbops Sprint 23,Xbops Sprint 24,Xbops Christmas Sprint,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/20 16:48;iv732;+ Created this jenkins job to test just acer_reporting db: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID%20SIMU-Copy%20sla%20dumps%20to%20EBSM/
+ add umgrcopy to xbsimusla2
+ modifed sshd config to allow umgrcopy
+ copy ansible pub key to .ssh directory of umgrcopy
+ under /home/ugrcopy created a new .pgpass file with the content (I just found only 1 user ops_reportuser)

{code:java}
xbsimusla1.deutsche-boerse.de:5432:report_tool_db:ops_reportuser:OOt97gn09b5x27n9PWd0
xbsimusla1.deutsche-boerse.de:5432:acer_reporting:ops_reportuser:OOt97gn09b5x27n9PWd0
xbsimusla1.deutsche-boerse.de:5432:am_reporting:ops_reportuser:OOt97gn09b5x27n9PWd0
{code}
+ a test run returned error, seems that the password for ops_reportuser is not correct.

{code:java}
pg_dump: error: connection to database ""acer_reporting"" failed: FATAL:  password authentication failed for user ""ops_reportuser""
{code}

+ according to the database, we may need to use different users:


{code:java}
      Name      |       Owner       | Encoding |   Collate   |    Ctype    |      Access privileges
----------------+-------------------+----------+-------------+-------------+-----------------------------
 acer_reporting | ops_reportuser    | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 am_reporting   | ops_am_reportuser | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres       | postgres          | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 report_tool_db | postgres          | UTF8     | en_US.UTF-8 | en_US.UTF-8 | postgres=CTc/postgres      +

{code}

","18/Dec/20 16:52;iv732;[~hw120] I cannot finish this today, so I assign it back to you to continue to find the correct user/password and create backup for all dbs","06/Jan/21 13:28;iv732;Done. The problem was  that I created the .pgpass as root and forgot to change the owner to umgrcopy!
The files are copied to ebsm server:


{code:java}
-rw-rw-r--  1 transfer transfer     872474 Jan  6 13:27 xbsimusla1.acer_reporting.210106-1327.dump.gz
-rw-rw-r--  1 transfer transfer    1854087 Jan  6 13:27 xbsimusla2.acer_reporting.210106-1327.dump.gz
-rw-rw-r--  1 transfer transfer       5554 Jan  6 13:27 xbsimusla1.am_reporting.210106-1327.dump.gz
-rw-rw-r--  1 transfer transfer    1337220 Jan  6 13:27 xbsimusla2.am_reporting.210106-1327.dump.gz

{code}
","06/Jan/21 13:36;iv732;[~qo794]
Integrated to the main jenkins job:  https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-SIMU%20Copy%20journal%20and%20dumps%20to%20EBSM%20-%20Scheduled%20at%2022%20XX/

{code:java}
# ========== Copy XBID SIMU sla databases =======
port=5432
dat=$(date +%y%m%d-%H%M)
app_arr=('acer_reporting' 'am_reporting')
for app in ""${app_arr[@]}""
do
ssh -o StrictHostKeyChecking=no umgrcopy@xbsimusla1.deutsche-boerse.de <<EOF
	/usr/pgsql-12/bin/pg_dump -Fc -p $port -h xbsimusla1.deutsche-boerse.de -n public -U ops_reportuser ${app}  | gzip > /tmp/xbsimusla1.${app}.${dat}.dump.gz
	ls -alrt /tmp/xbsimusla1.${app}.${dat}.dump.gz
	scp -p -o StrictHostKeyChecking=no /tmp/xbsimusla1.${app}.${dat}.dump.gz transfer@m7shrdebsm1.deutsche-boerse.de:/opt/data/transfer/dbdumps/xbid_simu/
	rm -f /tmp/xbsimusla1.${app}.${dat}.dump.gz
EOF

ssh -o StrictHostKeyChecking=no umgrcopy@xbsimusla2.deutsche-boerse.de <<EOF
	/usr/pgsql-12/bin/pg_dump -Fc -p $port -h xbsimusla2.deutsche-boerse.de -n public -U ops_reportuser ${app}  | gzip > /tmp/xbsimusla2.${app}.${dat}.dump.gz
	ls -alrt /tmp/xbsimusla2.${app}.${dat}.dump.gz
	scp -p -o StrictHostKeyChecking=no /tmp/xbsimusla2.${app}.${dat}.dump.gz transfer@m7shrdebsm1.deutsche-boerse.de:/opt/data/transfer/dbdumps/xbid_simu/
	rm -f /tmp/xbsimusla2.${app}.${dat}.dump.gz
EOF
done
# ========== Copy XBID SIMU sla databases =======
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID 3.1.1 deployments on CTPX envs,XP-3819,100789,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,29/Sep/20 17:10,29/Sep/20 20:57,22/Feb/21 13:26,29/Sep/20 17:10,,,3.1.1,,,,,,,deployment,TechOps,,,"* Extracting passwords from xml configs and pushing to vault
 * upgrading posgresql to 12
 * upgrading erlang
 * run deployments
 * debug and fix problems",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8133,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12528000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bobk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Onboard second XLS for Security Testing ,XP-3807,100756,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,29/Sep/20 13:50,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 12:03,,,3.1.2,,,,,,,,,,,"Under XP-3469, there is a new XLS that should be processed.

Todo:
 * Update tickets under XP-3469 epic to match the new XLS
 * Update [Security Testing::Confluence|http://confluence.energy.svc.dbgcloud.io/display/XBID/Security+Testing?src=contextnavpagetreemode]
 * Resolve ""Unclear points"" in XP-3469
 * Estimate/prioritize at least 2 tickets that can be planned into a new sprint",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3965,,,,,,,,,,,,,,"08/Oct/20 17:53;od044;security-check-list-duc-v5.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88401/security-check-list-duc-v5.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12614400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bo27:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PMI Archiving Centera/ECS connection not working,XP-3805,100733,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,yo218,qo794,qo794,29/Sep/20 09:19,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 09:42,,,3.1.2,,PMI Tools,,,,,,,,,"Copy job to Centera in PMI Archiver is failing on xbprodpmi1/3, xbprodpmi2/4 are working fine:
{code:java}
2020-09-29 04:05:00.034 ERROR 48438 --- [pool-2-thread-1] c.d.e.m.p.a.t.ArchivingTasks             : Archiving failed
com.filepool.fplibrary.FPLibraryException: no primary cluster found
        at com.filepool.fplibrary.FPPool.RegisterApplication(Unknown Source) ~[fp-library-3.4.jar!/:3.4.757]
        at com.deutscheboerse.energy.m7.pmi.adapter.CenteraAdapter.<init>(CenteraAdapter.java:71) ~[pmi-common-1.0.19.jar!/:1.0.19]
        at com.deutscheboerse.energy.m7.pmi.adapter.CenteraAdapter.getDefault(CenteraAdapter.java:53) ~[pmi-common-1.0.19.jar!/:1.0.19]
        at com.deutscheboerse.energy.m7.pmi.archiver.service.AbstractService.initCenteraAdapter(AbstractService.java:102) ~[classes!/:1.0.19]
        at com.deutscheboerse.energy.m7.pmi.archiver.service.AbstractService.executeCenteraAndClose(AbstractService.java:92) ~[classes!/:1.0.19]
        at com.deutscheboerse.energy.m7.pmi.archiver.service.ArchiverService.archive(ArchiverService.java:72) ~[classes!/:1.0.19]
        at com.deutscheboerse.energy.m7.pmi.archiver.task.ArchivingTasks.runArchiving(ArchivingTasks.java:55) [classes!/:1.0.19]
        at sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source) ~[?:?]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_202]
        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_202]
        at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:65) [spring-context-4.3.3.RELEASE.jar!/:4.3.3.RELEASE]
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) [spring-context-4.3.3.RELEASE.jar!/:4.3.3.RELEASE]
        at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81) [spring-context-4.3.3.RELEASE.jar!/:4.3.3.RELEASE]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_202]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_202]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_202]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_202]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_202]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_202]
        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_202]
{code}

Moreover logs from pmi-archiver3/4/5/6, pmi-logger4/5/6 and db-archiver1/2 from simu are not present on ebsm server, can neither find them in Kibana.

Once this is fixed, please check that old files are deleted as well - currently they consume too much disk space.
",,iv732,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bnzk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Production,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/20 10:51;qo794;I've checked configurations on pmi servers and everything seems to be configured in the same way on all prod pmi servers.  TCP and UDP must be opened for port 3218. TCP is open, I can't check UDP though. [~hw120] could you please have a look at it? Thanks.","09/Oct/20 14:29;iv732;[~qo794] seems that both TCP and UDP port is open:
{code:java}
[root@xbprodpmi1 ~]#  nc -z -v -u 10.129.105.11 3218
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Connected to 10.129.105.11:3218.
Ncat: UDP packet sent successfully
Ncat: 1 bytes sent, 0 bytes received in 2.01 seconds.
{code}
and
{code:java}
[root@xbprodpmi1 ~]#  nc -z -v 10.129.105.11 3218
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Connected to 10.129.105.11:3218.
Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.
{code}
So maybe problem from centera side?

Moreover, I see many of such error. Can it be ignored?
{code:java}
2020-10-09 00:05:00.003  WARN 48438 --- [pool-2-thread-1] c.d.e.m.p.a.s.ArchiverService            : Can't rename file 'SOBPMI_log_20201006T130000_1200-1300.log.gz' because of invalid file name length

{code}","09/Oct/20 14:30;qo794;Warning like ""Can't rename file 'SOBPMI_log_20201006T130000_1200-1300.log.gz' because of invalid file name length"" can be ignored, it's a side effect of Centera failure.","09/Oct/20 14:32;qo794;How come it's working for servers in Hausen with the very same configuration? And the issues started after Equinix DC maintenance.","09/Oct/20 14:42;qo794;So maybe there is really a problem on Centera/ECS side and our xbprodpmi1/3 servers are not accepted.","09/Oct/20 15:58;iv732;[~hw120]  can you contact Centera team next week? I know only the guy boris.schegolev there, but it seems that he is no longer working in Deutsche Boerse.","13/Oct/20 11:59;yo218;it is the same issue as last year after power maintenance --> TECHLOG-2811
A restart of the service solved it back then, so I am going to restart now, too","14/Oct/20 09:42;yo218;Files from 24th of September until today are available now:
{noformat}
[root@xbprodcbn1 ~]# ls -la /opt/data01/xbid_omie_prod/OUT/pmi/pmi1/
total 80
drwxr-xr-x 20 101001 101001 4096 Oct 14 02:05 .
drwxr-xr-x  8 101001 101001 4096 Oct 31  2018 ..
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:25 20200924
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:32 20200925
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:22 20200926
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:31 20200928
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:15 20200929
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:29 20200930
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:08 20201001
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:28 20201002
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:29 20201003
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:09 20201004
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:27 20201005
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:24 20201006
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:21 20201007
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:20 20201008
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:30 20201009
drwxr-xr-x  2 101001 101001 4096 Oct 13 17:25 20201010
drwxr-xr-x  2 101001 101001 4096 Oct 14 01:05 20201011
drwxr-xr-x  2 101001 101001 4096 Oct 14 09:05 20201012 {noformat}
They will stay for a week in order to allow all customers to access them. After one week the situation will return back to normal and only 8 directories will be available",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup monitoring for AM/ACER jobs,XP-3798,100718,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ll664,ll664,28/Sep/20 15:13,08/Dec/20 12:54,22/Feb/21 13:26,01/Dec/20 11:43,,,,,,,,,,TechOps,,,,"As we extracted those to separate services from Report Tool, we don't have monitoring/alerting set up for them yet.

 

Prerequisity is to fix current monitoring false alarms first: XP-3382

We need to:
 * setup Telegraf to collect job status from the REST API - same as done for Report Tool
 * setup Kapacitor alerting
 * create follow up tickets for devs when ready to update the dashboard 
 ** [https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/report-tool-jobs?orgId=4]
 *

Todo: 
 * get information from others about where exactly those services are/will be running and what are their names
 * update monitoring deployment
 * update APIs for checking matrix
 * deploy it everywhere where new services are ",,hw120,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,All done.,,,,,,,,,,,,,,7171200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000h",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 22,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Nov/20 18:09;hw120;Ansible variables and telegraf deployment updated to work with amr/acr services.

Monitoring deployed everywhere besides prod, where it waits for a new service request and for AMR, end of UAT tests.

[~ll664] Please check grafana dashboard if it needs to be updated, I can see metrics from other environments already.","26/Nov/20 08:53;ll664;I see some jobs are missing in dashboard on node 1, but there's a deployment planned - https://jira.deutsche-boerse.com/browse/SERVICE-9159

 

Let's see how it goes after that.","30/Nov/20 16:23;hw120;[~ll664] SERVICE-9159 is done, please check.","01/Dec/20 11:14;ll664;Dashboard looks good, all job statuses are reported, thanks Peter.

https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/sla-acer-am-reporting?orgId=4",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ClamAV on SIMU SFTP hosts cannot be updated ,XP-3797,100700,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,iv732,iv732,28/Sep/20 09:55,05/Nov/20 11:43,22/Feb/21 13:26,05/Nov/20 11:43,,,,,,,,,,TechOps,,,,"h1. {color:#57d9a3}Antivirus daemon{color}

On xbsimucom3/4 we got this error:
{code:java}
Sep 28 01:10:54 xbsimucom4 clamd[6998]: Received 0 file descriptor(s) from systemd.
Sep 28 01:10:54 xbsimucom4 clamd[6998]: clamd daemon 0.99.4 (OS: linux-gnu, ARCH: x86_64, CPU: x86_64)
Sep 28 01:10:54 xbsimucom4 clamd[6998]: Log file size limited to 1048576 bytes.
Sep 28 01:10:54 xbsimucom4 clamd[6998]: Reading databases from /var/lib/clamav
Sep 28 01:10:54 xbsimucom4 clamd[6998]: Not loading PUA signatures.
Sep 28 01:10:54 xbsimucom4 clamd[6998]: Bytecode: Security mode set to ""TrustSigned"".
Sep 28 01:10:55 xbsimucom4 clamd[6998]: LibClamAV Warning: **************************************************
Sep 28 01:10:55 xbsimucom4 clamd[6998]: LibClamAV Warning: ***  The virus database is older than 7 days!  ***
Sep 28 01:10:55 xbsimucom4 clamd[6998]: LibClamAV Warning: ***   Please update it as soon as possible.    ***
Sep 28 01:10:55 xbsimucom4 clamd[6998]: LibClamAV Warning: **************************************************
{code}",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9417600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bxz1:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Oct/20 18:01;iv732;One more issue I found today:  the host xbsimucom1 seems not to accept any further SSH connection.
{code:java}
ssh xbsimucom1
ssh_exchange_identification: read: Connection reset by peer

{code}
Tried to log in via console to check the host, but couldn't access the host over Vcenter: frpvc2. Need to clarify with Lambert.

 ","04/Nov/20 11:16;iv732;Latest status: xbsimucom4/6 are having issue with Clamd process


{code:java}
xb-xbid-simu-com4 | FAILED | rc=3 >>
● clamd@scan.service - Generic clamav scanner daemon
   Loaded: loaded (/usr/lib/systemd/system/clamd@scan.service; enabled; vendor preset: disabled)
   Active: activating (start) since Wed 2020-11-04 10:27:10 CET; 2s ago
  Control: 10377 (clamd)
   CGroup: /system.slice/system-clamd.slice/clamd@scan.service
           └─10377 /usr/sbin/clamd -c /etc/clamd.d/scan.confnon-zero return code

xb-xbid-simu-com6 | FAILED | rc=3 >>
● clamd@scan.service - Generic clamav scanner daemon
   Loaded: loaded (/usr/lib/systemd/system/clamd@scan.service; enabled; vendor preset: disabled)
   Active: activating (start) since Wed 2020-11-04 10:26:48 CET; 24s ago
  Control: 22690 (clamd)
   CGroup: /system.slice/system-clamd.slice/clamd@scan.service
           └─22690 /usr/sbin/clamd -c /etc/clamd.d/scan.confnon-zero return code

{code}
","04/Nov/20 16:15;iv732;Solution:
1. Copy the .cvd files from /var/lib/clamav from a running server (xbsimucom1 for example) to xbsimucom4/6
2. Create the missing directories on xbsimucom4/6

{code:java}
cd /run 
mkdir clamd.scan
chown clamscan:clamscan clamd.scan/
chmod 740 clamd.scan/
systemctl restart clamd@scan

mkdir proftpd
chmod 755 proftpd/
systemctl start proftpd
{code}

    ","04/Nov/20 16:19;iv732;Now watching for the next update overnight","05/Nov/20 11:42;iv732;everything looks working fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Daily DB dump for simu not working,XP-3792,100652,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,qo794,qo794,25/Sep/20 09:25,30/Sep/20 11:34,22/Feb/21 13:26,29/Sep/20 23:24,,,3.1.2,,,,,,,TechOps,,,,"DB dumps for simu are empty:
{code}
-bash-4.2$ pwd
/opt/data/transfer/dbdumps/xbid_simu
-bash-4.2$ ls -lt | head -n 30
total 159831012
-rw-rw-r-- 1 transfer transfer         20 24. zář 23.01 xbsimucor.200924-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 23.01 xbsimucmi.200924-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 23.01 xbsimurep.200924-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 23.01 xbsimuspm.200924-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 16.38 xbsimucor.200924-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 16.38 xbsimucmi.200924-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 16.38 xbsimurep.200924-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 24. zář 16.38 xbsimuspm.200924-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 23.00 xbsimucor.200923-2300.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 23.00 xbsimucmi.200923-2300.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 23.00 xbsimurep.200923-2300.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 23.00 xbsimuspm.200923-2300.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 16.38 xbsimucor.200923-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 16.38 xbsimucmi.200923-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 16.38 xbsimurep.200923-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 23. zář 16.38 xbsimuspm.200923-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 22.59 xbsimucor.200922-2259.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 22.59 xbsimucmi.200922-2259.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 22.59 xbsimurep.200922-2259.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 22.59 xbsimuspm.200922-2259.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 16.38 xbsimucor.200922-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 16.38 xbsimucmi.200922-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 16.38 xbsimurep.200922-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 22. zář 16.38 xbsimuspm.200922-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 21. zář 23.01 xbsimucmi.200921-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 21. zář 23.01 xbsimucor.200921-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 21. zář 23.01 xbsimurep.200921-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 21. zář 23.01 xbsimuspm.200921-2301.dump.gz
-rw-rw-r-- 1 transfer transfer         20 21. zář 16.38 xbsimucor.200921-1638.dump.gz
{code}
Please fix.",,hw120,iv732,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3820,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12528000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bnio:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,SIMU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/20 16:30;iv732;[~qo794]  [~zi174]

This Jenkins job creates dumps and copies them to EBSM:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-Copy%20journal%20and%20dumps%20to%20EBSM/]

 

However in the script we are still referring to version 9.5, even though they were migrated to version 12. That's why we got the error
{code:java}
pg_dump: aborting because of server version mismatch
{code}
I updated the script. So we will check the new dumps on Monday","29/Sep/20 08:57;qo794;Looks like a job executed during a day still uses the old version, nightly backups are fine though:
{code}
-bash-4.2$ ls -lt | head -n 50
total 153964984
-rw-rw-r-- 1 transfer transfer   78133857 28. zář 22.26 xbsimucor.200928-2225.dump.gz
-rw-rw-r-- 1 transfer transfer  490144664 28. zář 22.25 xbsimucmi.200928-2221.dump.gz
-rw-rw-r-- 1 transfer transfer       6049 28. zář 22.23 xbsimurep.200928-2221.dump.gz
-rw-rw-r-- 1 transfer transfer  521856158 28. zář 22.23 xbsimuspm.200928-2221.dump.gz
-rw-rw-r-- 1 transfer transfer         20 28. zář 16.38 xbsimucmi.200928-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 28. zář 16.38 xbsimucor.200928-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 28. zář 16.38 xbsimurep.200928-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 28. zář 16.38 xbsimuspm.200928-1638.dump.gz
-rw-rw-r-- 1 transfer transfer   78161317 27. zář 22.26 xbsimucor.200927-2225.dump.gz
-rw-rw-r-- 1 transfer transfer  487731135 27. zář 22.25 xbsimucmi.200927-2221.dump.gz
-rw-rw-r-- 1 transfer transfer       6050 27. zář 22.23 xbsimurep.200927-2221.dump.gz
-rw-rw-r-- 1 transfer transfer  519164306 27. zář 22.22 xbsimuspm.200927-2221.dump.gz
-rw-rw-r-- 1 transfer transfer         20 27. zář 16.38 xbsimucor.200927-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 27. zář 16.38 xbsimucmi.200927-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 27. zář 16.38 xbsimurep.200927-1638.dump.gz
-rw-rw-r-- 1 transfer transfer         20 27. zář 16.38 xbsimuspm.200927-1638.dump.gz
{code}
Other problem: databases from xbsimusla1 and xbsimusla2 are not included, [~iv732] should I create a separate ticket or can it fixed within this one?","29/Sep/20 16:18;qo794;[~iv732] just noticed that dumps from prod are empty, the very same job is used also for prod, please fix asap, thanks.

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-Copy%20journal%20and%20dumps%20to%20EBSM/
{code}
+ ssh -o StrictHostKeyChecking=no umgrcopy@xbprodpdb1.deutsche-boerse.de
Pseudo-terminal will not be allocated because stdin is not a terminal.
-bash: line 1: /usr/pgsql-12/bin/pg_dump: No such file or directory
-rw-rw-r-- 1 umgrcopy umgrcopy 20 Sep 28 22:21 /tmp/xbprodrep.200928-2221.dump.gz
{code}","29/Sep/20 23:19;hw120;Created 3 new jenkins jobs to distribute the load in a separate time window.
 * CUTX Scheduled at 20:XX - [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-CUTX%20Copy%20journal%20and%20dumps%20to%20EBSM%20-%20Scheduled%20at%2020%20XX/]
 * SIMU Scheduled at 22:XX - [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-SIMU%20Copy%20journal%20and%20dumps%20to%20EBSM%20-%20Scheduled%20at%2022%20XX/]
 * PROD Scheduled at 23:XX - [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-PROD%20Copy%20journal%20and%20dumps%20to%20EBSM%20-%20Scheduled%20at%2023%20XX/]

Each jenkins job has a section for Postgres 9.5 and Postgres 12, we will have to update the list of DB as we migrate all envs to postgres 12. Added step to migration guide.

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Upgrade+XBID+db%27s+to+pg+v+12.4]

Prod and Simu jobs have section for dump of sla report db, but for Simu it doesn't work as there are some preparation steps missing like creating user on the host, exchanging ssh keys, add config to access the database...

Please create a separate Jira ticket to prepare environment to run xbsimuslaX dumps.

 

I also run all 3 jobs to test them, dumps are on ebsm server.","30/Sep/20 07:57;qo794;I can confirm db dumps are created correctly for prod, simu and cute:
{code}
-bash-4.2$ cd /opt/data/transfer/dbdumps/xbid_prod/
-bash-4.2$ ls -lt | head
total 1235187804
-rw-rw-r-- 1 transfer transfer  499539506 29. zář 23.27 xbprodsla2.200929-2323.dump.gz
-rw-rw-r-- 1 transfer transfer  499139200 29. zář 23.25 xbprodsla1.200929-2323.dump.gz
-rw-rw-r-- 1 transfer transfer 9515778048 29. zář 23.21 xbprodcor.200929-2250.dump.gz
-rw-rw-r-- 1 transfer transfer  776103993 29. zář 22.49 xbprodcmi.200929-2243.dump.gz
-rw-rw-r-- 1 transfer transfer       5824 29. zář 22.46 xbprodrep.200929-2243.dump.gz
-rw-rw-r-- 1 transfer transfer  681749872 29. zář 22.46 xbprodspm.200929-2243.dump.gz
-rw-rw-r-- 1 transfer transfer  499539490 29. zář 16.53 xbprodsla2.200929-1649.dump.gz
-rw-rw-r-- 1 transfer transfer  499139240 29. zář 16.51 xbprodsla1.200929-1649.dump.gz
-rw-rw-r-- 1 transfer transfer  498590894 28. zář 23.31 xbprodsla2.200928-2326.dump.gz

/opt/data/transfer/dbdumps/xbid_simu
-bash-4.2$ ls -lt | head
total 153782688
-rw-rw-r-- 1 transfer transfer   76442204 29. zář 22.52 xbsimucor.200929-2252.dump.gz
-rw-rw-r-- 1 transfer transfer  474244716 29. zář 22.52 xbsimucmi.200929-2248.dump.gz
-rw-rw-r-- 1 transfer transfer       6048 29. zář 22.50 xbsimurep.200929-2248.dump.gz
-rw-rw-r-- 1 transfer transfer  509097520 29. zář 22.49 xbsimuspm.200929-2248.dump.gz
-rw-rw-r-- 1 transfer transfer   76433698 29. zář 22.39 xbsimucor.200929-2239.dump.gz
-rw-rw-r-- 1 transfer transfer  474245739 29. zář 22.38 xbsimucmi.200929-2234.dump.gz
-rw-rw-r-- 1 transfer transfer       6049 29. zář 22.36 xbsimurep.200929-2234.dump.gz
-rw-rw-r-- 1 transfer transfer  508882014 29. zář 22.36 xbsimuspm.200929-2234.dump.gz
-rw-rw-r-- 1 transfer transfer         20 29. zář 16.38 xbsimucor.200929-1638.dump.gz

-bash-4.2$ pwd
/opt/data/transfer/dbdumps/xbid_cute
-bash-4.2$ ls -lt | head
total 81734068
-rw-rw-r-- 1 transfer transfer 399672887 29. zář 23.22 xbcutecmi.200929-2317.dump.gz
-rw-rw-r-- 1 transfer transfer      5747 29. zář 23.20 xbcuterep.200929-2317.dump.gz
-rw-rw-r-- 1 transfer transfer 478595060 29. zář 23.20 xbcutespm.200929-2317.dump.gz
-rw-rw-r-- 1 transfer transfer 159174861 29. zář 23.18 xbcutecor.200929-2317.dump.gz
-rw-rw-r-- 1 transfer transfer 412557366 28. zář 22.46 xbcutecmi.200928-2241.dump.gz
-rw-rw-r-- 1 transfer transfer      6076 28. zář 22.44 xbcuterep.200928-2241.dump.gz
-rw-rw-r-- 1 transfer transfer 484175175 28. zář 22.44 xbcutespm.200928-2241.dump.gz
-rw-rw-r-- 1 transfer transfer 160588574 28. zář 22.42 xbcutecor.200928-2241.dump.gz
-rw-rw-r-- 1 transfer transfer 411665961 27. zář 22.45 xbcutecmi.200927-2241.dump.gz
{code}

XP-3820 created to fix db dumps from xbsimusla1/2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - apply remaining PRs from energy-mkt-shared to inventory - needs to be done until 30.10,XP-3781,100528,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,ll664,ll664,23/Sep/20 09:23,02/Nov/20 13:06,22/Feb/21 13:26,27/Oct/20 18:18,,,3.1.3,,,,,,,,,,,"h2. Should be ready before 2020 pentests in SIMU, starts on 3. 11. 2020
h3.  There will be special deployment just for pentests

There are couple of PRs to old {{energy-mkt-shared}}, which fixes mainly pentest findings, that should go to Ansible inventory.

PRs are in the comments in FUTURE deployment ticket:
https://jira.deutsche-boerse.com/browse/SERVICE-3669

Go through them and update inventory accordingly.

If those PRs are not merged before the pentests, we'd get those findings again.


",,ek176,hw120,jy268,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Checked all pull requests and all changes have been already merged.,,,,,,,,,,,,,,10108800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bs4r:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/Sep/20 10:25;ek176;For example, XP-1316 was not merged (just to provide a timeline).

PR: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1150/files","22/Oct/20 13:38;jy268;PR mentioned by [~ek176] is the only one missing from pentests it was added to SERVICE-2640 list","22/Oct/20 16:14;jy268;[~hw120] almost everything is prepared in energy.automation.deployments except of one ticket which was done by Niklas. It does not have any link to XP ticket so I don't know what to do with that. It seems to be something from techops side, could you please take a look and ask Niklas if necessary? https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/677/files","27/Oct/20 17:59;hw120;Those changes are to allow englobmon1 monitoring host to check health status of the service.

Merged to ansible [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1195/files]

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove old order-book implementation,XP-3779,100523,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,lt112,lt112,23/Sep/20 08:21,29/Oct/20 13:03,22/Feb/21 13:26,28/Oct/20 15:18,,,3.2.x,,,,,,,,,,,"Old order-book code is still in production for validation, remove it

See {{OrderBookHandler}} calling {{orderBookExperimentService}}, continue from there

Refactor and move remaining classes to the better fitting place (e.g. OrderBookInfo)",,ll664,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10108800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:g",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 20,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/Oct/20 11:49;ll664;Removed old OBK and comparison/experiment related code. However I decided not to refactor {{OrderbookInfo}} and related model classes in to {{xbid-core}}.

The reason is that there is dependency hierarchy of modules {{comxerv-trading-data-model}} -> {{comxerv-public-api-mapper}} -> {{comxerv-public-api-amqp-adapter}}. Of course {{OrderbookInfo}} is used exclusively only within {{xbid-core}} module, but moving it would require moving all dependent classes - mappers. The reason is that much of this infrastructure is shared between XBID Core and Trading Inquiry modules.

This would somehow break the design consistency we have now - model classes are in {{model}} module, mappers in {{mapper}} module, but the OBK classes would be an exception. So for the sake of consistency, I'm keeping it as it is.

Of course we can discuss the module structure and maybe simplify it a bit (merge some of them together), but I'd do it in one go instead of separating just OBK.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OWASP checks in Jenkins - unify approach,XP-3777,100488,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qo794,qo794,qo794,22/Sep/20 11:27,02/Nov/20 12:57,22/Feb/21 13:26,13/Oct/20 10:57,,,3.1.2,,,,,,,,,,,"It's been decided that OWASP checks would be a part of nightly builds in all projects and fixing of new vulnerabilities would be responsibility of emergency shift.

Current status:
* some projects have the owasp check executed automatically during a maven ""verify"" step (xbid, etc.)
* for others the owasp check is not executed at all (report-tool, amr, acer, ...)
* all owasp jenkins jobs for pull requests are disabled

TODO:
* add the owasp check to all nightly pipelines as a separate step
* remove execution of owasp check from verify step
{code}
                    <executions>
                        <execution>
                                <goals>
                                    <goal>aggregate</goal> <!-- mvn verify -->
                                </goals>
                        </execution>
                    </executions>
{code}
* what about libraries? remove the owasp check from xbid libraries (not from shared ones)
* what about other branches than develop? I think it does not make any sense to check owasp for instance for acceptance and production branches. The OWASP check should be only executed in develop branch, remove it from acceptance pipeline.",,ek176,jy268,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11404800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,22/Sep/20 11:27,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bo27:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-4211-perf-analysis-jh,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-3909-develop,XP-4152-acceptance,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-3909,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-4122-perf-analysis,develop,XP-4505_xbid_develop_hpfortify_upgrade,master,master-acceptance,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,acceptance,XP-222-develop,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Sep/20 15:13;ek176;List of libraries where the OWASP plugin should be eliminated (if introduced by XBID) (may be uncomplete):
{noformat}
m7.energy-commons-amqp
m7.energy-commons-core
m7.energy-commons-date-time
m7.energy-commons-failover
m7.energy-commons-files-core
m7.energy-commons-files-entso
m7.energy-commons-hibernate
m7.energy-commons-jsf
m7.energy-commons-process
m7.energy-commons-test
--------------------- (edit: forked to xbid)
m7.energy-comxerv-commons
m7.energy-remote-commons
xbid-commons-transport
xbid.commons-passwd


{noformat}","25/Sep/20 08:40;qo794;xbid.commons-transport instead of m7.energy-commons-transport, it has already been forked","01/Oct/20 13:00;ek176;Removed execution from XBID (develop, acceptance):

[https://github.deutsche-boerse.de/dev/xbid/pull/798] [merged]
 [https://github.deutsche-boerse.de/dev/xbid/pull/797] [merged]

deleted the Jenkins job: {{xbid-pulls-owasp}}","09/Oct/20 07:32;jy268;Progress on projects:

XBID: (/)
SPM:  (/)
Reporting engine: (/)
Report tool: (/)
am-reporting: (/)
acer-reporting: (/)
access-management: (/)
pmi-logger: (/)
pmi-archiving: (/)
comtrader: (/)","12/Oct/20 15:41;jy268;Please review that all tasks were finished [~qo794]","13/Oct/20 10:56;qo794;All disabled owasp jenkins jobs for pull requests deleted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade PERF env for performance testing purpose,XP-3611,100224,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,od044,od044,18/Sep/20 12:13,02/Nov/20 12:57,22/Feb/21 13:26,08/Oct/20 15:00,,,3.1.2,,,,,,,,,,,"Please upgrade PERF env:

1) upgrade tomcats to *Apache Tomcat 8.5.57*
2) upgrade RabbitMQs incl ERLANG to: RabbitMQ *3.8.5* with Erlang * 22.1* -> package should be ready
3) upgrade RHEL to 7.8 version


",,eg288,iv732,od044,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11750400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bky0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Sep/20 11:29;eg288;From techops we need RHEL upgrade and new Erlang (manual steps)

Tomcat and RabbitMQ upgrade is done by ansible deployment script automatically","22/Sep/20 11:52;iv732;[~yo218] can you please take over this task?","06/Oct/20 12:36;yo218;RHEL Update to 7.8 finished and Erlang 22.1 is installed. Just the database hosts are not yet updated because of missing dependencies with glusterfs and patroni","08/Oct/20 15:00;od044;PERF env is updated:
- RabbitMQ  3.8.5
- Erlang 22.1
- Red Hat Enterprise Linux Server release 7.8 (Maipo)
- Apache Tomcat/8.5.57",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Re-run performance test again and analyse result,XP-3610,100217,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,18/Sep/20 10:39,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 10:38,,,3.1.2,,,,,,,,,,,Re-run performance test again,,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/20 11:50;od044;comparision-08-10-2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88483/comparision-08-10-2020.xlsx","18/Sep/20 12:51;od044;comparision.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87708/comparision.xlsx","18/Sep/20 12:51;od044;performance-internal-report-20200918.xls;https://jira.deutsche-boerse.com/secure/attachment/87707/performance-internal-report-20200918.xls","12/Oct/20 11:48;od044;performance-internal-report-20201008.xls;https://jira.deutsche-boerse.com/secure/attachment/88480/performance-internal-report-20201008.xls","12/Oct/20 11:50;od044;sc04-perf-rts3wave3-2-17092019.xls;https://jira.deutsche-boerse.com/secure/attachment/88482/sc04-perf-rts3wave3-2-17092019.xls","18/Sep/20 12:51;od044;sql-check-2020-09-18.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87706/sql-check-2020-09-18.xlsx","12/Oct/20 11:48;od044;sql-check-20201008.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88481/sql-check-20201008.xlsx","18/Sep/20 14:13;od044;xb_xbid_perf_cor-1_standard_ixe.log.gz;https://jira.deutsche-boerse.com/secure/attachment/87711/xb_xbid_perf_cor-1_standard_ixe.log.gz","18/Sep/20 14:13;od044;xb_xbid_perf_cor-1_standard_ixe_0_2020-09-18.log.gz;https://jira.deutsche-boerse.com/secure/attachment/87712/xb_xbid_perf_cor-1_standard_ixe_0_2020-09-18.log.gz",,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11491200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bkwg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/20 12:51;od044;New run on PERF
- the Order execution time is almost the same as the previous run during XP-3536

here is the actual comparison:  [^comparision.xlsx] 

Sql check:  [^sql-check-2020-09-18.xlsx] 
Report:  [^performance-internal-report-20200918.xls] ","22/Sep/20 11:00;od044;After more analysis we came up conclusion that the differences in Order execution time is not caused by DB upgrade (persister time are almost the same for all run).

I have also rerun the perf test on previous XBID version 2.0.25.2 and the Order execution time is still same. Thus we assume that the differences could be caused by specific environment where the run were performed. Because a run from last year was run o SIMU and  actual run was run on PERF.

Anyway, we have a plan to run another run on PERF on the latest RHEL and tomcat once PERF will be upgraded.  ","12/Oct/20 11:52;od044;I have re-run the performance again with SC04, that customer required in ticket XP-3832 on upgrade PERF env. The result is better than a run in the past on SIMU (can see in new comparison excel). 

Anyway, for a proper comparison, we need to wait for run on SIMU env.

Report:
actual on PERF: [^performance-internal-report-20201008.xls]  [^sql-check-20201008.xlsx]  
previous on SIMU:  [^sc04-perf-rts3wave3-2-17092019.xls] 
comparison:  [^comparision-08-10-2020.xlsx] 

PERF env: 
    RabbitMQ 3.8.5
    Erlang 22.1
    Red Hat Enterprise Linux Server release 7.8 (Maipo)
    Apache Tomcat/8.5.57
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AMS PROD logs missing on ebsm and in Kibana,XP-3605,100193,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,cs687,qo794,qo794,17/Sep/20 16:26,06/Nov/20 15:39,22/Feb/21 13:26,06/Nov/20 15:39,,,,,AMS,GA,,,,,,,,"AMS logs on PROD are neither available in Kibana nor on ebsm server

 

hints:
 * for EBSM we need to update transfer-log-app scripts
 * it's still not in ansible",,cs687,hw120,qo794,,,,,,,,,,,,,,,,,,,,,,,,XP-3309,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"* added tomcat pub key of xbidprodcor1 to authorized_keys xbprodams1/2
* added tomcat pub key to m7shrdebsm1 ebsmbox-user
* updated the script transfer_log_app.bash on xbidprodcor1 host 
* triggered the script ",,,,,,,,,,,,,,9244800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,17/Sep/20 16:26,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000002",9223372036854775807,,,,,,,,,,,"script /xbid/prodscripts/transfer_log_app.bash were not updated for the new instances/hosts xbprodams1/2
",,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,.,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/20 11:39;hw120;AMS logs are in kibana

[https://kibana.energy.svc.dbgcloud.io/goto/ba88542abd178b0375556b2e816dce0f]

solved in

https://jira.deutsche-boerse.com/browse/XP-3309

Thou I have no idea how to get them to EBSM","06/Nov/20 14:44;cs687;copied the *public key* /home/tomcat/.ssh/*ssh_tomcat_xbid_prod_rsa.pub* of tomcat user of host *xbidprodcor1* to xbprodams1/2 
/home/tomcat/.ssh/authorized_keys
{code:java}
-rw-r----- 1 tomcat tomcat  398 Nov  6 14:42 authorized_keys     
-rw------- 1 tomcat tomcat 1679 May 29 09:52 id_rsa              
-rw-r--r-- 1 tomcat tomcat  413 May 29 09:52 id_rsa.pub          
{code}

Tested the ssh connection without password entry:
{code:java}
tomcat@xbidprodcor1:[/home/tomcat/.ssh]$ ssh xbprodams1
Last login: Fri Nov  6 14:40:57 2020 from xbidprodcor1.deutsche-boerse.de
Kickstarted on 2020-05-29

tomcat@xbidprodcor1:[/home/tomcat/.ssh]$ ssh xbprodams2
Last login: Fri Nov  6 14:42:25 2020 from xbidprodcor1.deutsche-boerse.de
Kickstarted on 2020-05-29
{code}

*{color:red}copied the pub-key ""*id_rsa.pub*"" of tomcat user xbprodams1/2 to 
m7shrdebsm1 and added it in authorized_keys for ebsmbox user!{color}*



","06/Nov/20 14:51;cs687;+added the hosts to the script */xbid/prodscripts/transfer_log_app.bash*+
{code:java}
MACHINELIST=""xbid${env}cor1 xbid${env}cor2 xb${env}sob1 xb${env}sob2 xb${env}cmm1 xb${env}cmm2 xb${env}cmi1 xb${env}cmi2 xb${env}smc1 xb${env}smc2 xb${env}smi1 xb${env}smi2 xb${env}ecp1 xb${env}ecp2 xb${env}pmi1 xb${env}pmi2 xb${env}pmi3 xb${env}pmi4 xb${env}sla1 xb${env}sla2 
*xb${env}ams1 xb${env}ams2*""
{code}
","06/Nov/20 15:36;cs687;triggered the script:
{code:java}
tomcat@xbidprodcor1:[/xbid/prodscripts]$ ./transfer_log_app.bash
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-27.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-27.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-30.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-30.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-31.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-31.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-29.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-29.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-28.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-10-28.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-03.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-03.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-05.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-05.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-01.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-01.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-04.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-04.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/rollover/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-02.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams1/rollover/transferred/xb_xbid_prod_xbams-1_standard_ixe_0_2020-11-02.log.gz.sent touched
/xbid/logs/xbid-prod-ams1/xb_xbid_prod_xbams-1_standard_ixe.log is successfully transferred
xbprodams1 is completed

/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-02.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-02.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-30.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-30.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-01.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-01.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-27.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-27.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-04.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-04.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-31.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-31.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-05.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-05.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-28.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-28.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-29.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-10-29.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/rollover/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-03.log.gz is successfully transferred
/xbid/logs/xbid-prod-ams2/rollover/transferred/xb_xbid_prod_xbams-2_standard_hau_0_2020-11-03.log.gz.sent touched
/xbid/logs/xbid-prod-ams2/xb_xbid_prod_xbams-2_standard_hau.log is successfully transferred
xbprodams2 is completed
{code}
","06/Nov/20 15:39;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AMS PROD Health endpoint monitoring not working,XP-3604,100192,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,qo794,qo794,17/Sep/20 16:24,19/Oct/20 10:30,22/Feb/21 13:26,27/Sep/20 17:41,,,3.1.2,,AMS,GA,,,,TechOps,,,,"Even though AMS health endpoint reports DOWN due to problems with connection to SMTP server, no alerts have been posted to the xbid_prod_alerts slack channel:
{code}
[qo794@xbprodams1 xbid-prod-ams1]$ curl http://localhost:8080/ams/health
{""status"":""DOWN"",""components"":{""db"":{""status"":""UP"",""components"":{""ams"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""result"":""PASSWORD"",""validationQuery"":""SELECT id FROM table_lock LIMIT 1""}},""core_cmm"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""result"":""XIMPLALO"",""validationQuery"":""SELECT racf_id FROM cmm_280_user LIMIT 1""}},""core_trading"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""result"":1,""validationQuery"":""SELECT user_id FROM cx_282_user LIMIT 1""}},""spm"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""result"":""AMPSMFO7"",""validationQuery"":""SELECT user_id FROM user_spm LIMIT 1""}}}},""diskSpace"":{""status"":""UP"",""details"":{""total"":1023303680,""free"":888811520,""threshold"":10485760}},""ldap"":{""status"":""UP"",""components"":{""ldapCoreTemplate"":{""status"":""UP"",""details"":{""version"":""3""}},""ldapSmTemplate"":{""status"":""UP"",""details"":{""version"":""3""}}}},""mail"":{""status"":""DOWN"",""details"":{""reason"":""operation failed on all: {MailSenderImpl[smtp; englobmail1:25],MailSenderImpl[smtp; englobmail2:25]}; nested exception is org.springframework.mail.MailSendException: Test connection failure; nested exception is javax.mail.MessagingException: Could not connect to SMTP host: englobmail2, port: 25;\n  nested exception is:\n\tjava.net.SocketTimeoutException: connect timed out""}},""ping"":{""status"":""UP""},""vault"":{""status"":""UP""}}}
{code}",,hw120,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12700800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,17/Sep/20 16:24,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09v",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,PROD,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"27/Sep/20 17:41;hw120;Deployed monitoring with jenkins job.

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1235/console]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove ACER/AM code from original Report Tool (Split 1),XP-3597,100144,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ll664,tr866,16/Sep/20 12:55,02/Nov/20 12:57,22/Feb/21 13:26,30/Sep/20 12:25,,,3.1.2,,,,,,,,,,,"Once the AM/ACER features are extracted to separate services, remove related code from original Report Tool module.

Let's keep it only for SLA/KPI reports.",,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Sep/20 12:23;tr866;XBID Credit Points Report September 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88068/XBID+Credit+Points+Report+September+2020.xlsx","30/Sep/20 12:23;tr866;XBID Performance and SM SLA Reporting September 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88069/XBID+Performance+and+SM+SLA+Reporting+September+2020.xlsx","30/Sep/20 12:23;tr866;XBID Service Boundary Reporting September 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88070/XBID+Service+Boundary+Reporting+September+2020.xlsx","18/Sep/20 17:24;tr866;collect-performance-kpi-data.log;https://jira.deutsche-boerse.com/secure/attachment/87722/collect-performance-kpi-data.log","18/Sep/20 17:33;tr866;credit-points.log;https://jira.deutsche-boerse.com/secure/attachment/87723/credit-points.log","18/Sep/20 17:39;tr866;generate-boundary-sla-report.log;https://jira.deutsche-boerse.com/secure/attachment/87724/generate-boundary-sla-report.log","18/Sep/20 17:42;tr866;generate-performance-kpi-report.log;https://jira.deutsche-boerse.com/secure/attachment/87725/generate-performance-kpi-report.log","22/Sep/20 12:38;tr866;syt1-collect-performance-kpi-data.log;https://jira.deutsche-boerse.com/secure/attachment/87798/syt1-collect-performance-kpi-data.log","22/Sep/20 12:38;tr866;syt1-credit-points.log;https://jira.deutsche-boerse.com/secure/attachment/87799/syt1-credit-points.log","22/Sep/20 12:38;tr866;syt1-generate-boundary-sla-report.log;https://jira.deutsche-boerse.com/secure/attachment/87800/syt1-generate-boundary-sla-report.log","22/Sep/20 12:38;tr866;syt1-generate-performance-kpi-report.log;https://jira.deutsche-boerse.com/secure/attachment/87801/syt1-generate-performance-kpi-report.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,12528000,,,,,,,,,,,,,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bdql:zz9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),Alpha Sprint 18,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Sep/20 11:16;tr866;Testing on docker on develop branch with versions XB 3.1.6-SNAPSHOT-33b467870f44593f9efce28afe0921d4548c0ba7, Report Tool 2.48-SNAPSHOT-716c633fe3228bfb6ec154459b471082976972c1

Verifying the individual jobs are working:
# send-sla-reports (/) - after copying some sample SLA reports into report tool the email was successfully received in MailHog","18/Sep/20 15:33;tr866;Testing Import Jobs:
# collect-boundary-sla-data (/) :
#* no exception thrown in the logs (/)
{noformat}
2020-10-01 12:11:12.404 batch-jobs-thread-1 INFO  - o.s.b.c.l.s.SimpleJobLauncher - Job: [SimpleJob: [name=collect-boundary-sla-data]] completed with the following parameters: [{RUN_TIME=1601554272136}] and the following status: [COMPLETED] in 261ms
{noformat}
#* DB - computed_total table filled in (/)
# collect-performance-kpi-data>: (x)
#* exceptions in the [log file|^collect-performance-kpi-data.log] (x)
#* DB - No new data appeared in DB tables (x)
# collect-spm-files-generation-data: (/)
#* no exception thrown in the logs (/)
{noformat}
2020-10-01 14:29:42.235 http-nio-8080-exec-9 INFO  - o.s.b.c.l.s.SimpleJobOperator - Checking status of job with name=collect-spm-files-generation-data
2020-10-01 14:29:42.237 http-nio-8080-exec-9 INFO  - o.s.b.c.l.s.SimpleJobOperator - Attempting to launch job with name=collect-spm-files-generation-data and parameters=RUN_TIME(long)=1601562582235
2020-10-01 14:29:42.244 batch-jobs-thread-1 INFO  - o.s.b.c.l.s.SimpleJobLauncher - Job: [SimpleJob: [name=collect-spm-files-generation-data]] launched with the following parameters: [{RUN_TIME=1601562582235}]
2020-10-01 14:29:42.262 batch-jobs-thread-1 INFO  - o.s.b.c.j.SimpleStepHandler - Executing step: [collect-spm-files-generation-data]
2020-10-01 14:29:42.283 batch-jobs-thread-1 INFO  - c.d.e.x.r.p.c.SPMFilesGenerationCollector - Running SPMFilesGenerationCollector in CRON mode for period from 2018-12-01T00:00Z[UTC] to 2020-10-01T00:00Z[UTC]
2020-10-01 14:29:42.886 batch-jobs-thread-1 INFO  - o.s.b.c.s.AbstractStep - Step: [collect-spm-files-generation-data] executed in 624ms
2020-10-01 14:29:42.891 batch-jobs-thread-1 INFO  - o.s.b.c.l.s.SimpleJobLauncher - Job: [SimpleJob: [name=collect-spm-files-generation-data]] completed with the following parameters: [{RUN_TIME=1601562582235}] and the following status: [COMPLETED] in 645ms
{noformat}
#* DB (/) - computed_percentile table filled in
# credit-points: (x)
#* exceptions in the [log file|^credit-points.log] (x)
#* DB - No new data appeared in DB tables (x)","18/Sep/20 17:45;tr866;Testing generate report jobs:
# generate-boundary-sla-report
#* no report generated (x)
#* exception thrown in the [log file|^generate-boundary-sla-report.log]
# generate-performance-kpi-report
#* no report generated (x)
#* exception thrown in the [log file|^generate-performance-kpi-report.log]","22/Sep/20 12:38;tr866;Testing on Syt1 with version XB R3.1.5-d9d76cd1b071d193bde2482a415b6b15bba9dd89, Report Tool 2.48

# Report Tool Client can be successfully connected to Report Tool (/)
# ""list-jobs"" command provides the following list: (/)
{noformat}
╔═══════════════════════════════════╗
║ Name                              ║
╠═══════════════════════════════════╣
║ collect-boundary-sla-data         ║
╟───────────────────────────────────╢
║ collect-performance-kpi-data      ║
╟───────────────────────────────────╢
║ collect-spm-files-generation-data ║
╟───────────────────────────────────╢
║ credit-points                     ║
╟───────────────────────────────────╢
║ generate-boundary-sla-report      ║
╟───────────────────────────────────╢
║ generate-performance-kpi-report   ║
╟───────────────────────────────────╢
║ send-sla-reports                  ║
╚═══════════════════════════════════╝
{noformat}
# Import jobs:
## collect-boundary-sla-data (/)
##* no exception in the log file
##* records imported to computed_total table
## collect-performance-kpi-data (x)
##* exception thrown in the logs attached [^syt1-collect-performance-kpi-data.log]
##* no records imported in the SLA DB
## collect-spm-files-generation-data (/)
##* no expception in the log file
##* records imported to computed_percentile table
## credit-points (x)
##* exception thrown in the logs attached [^syt1-credit-points.log]
##* no records imported in the SLA DB
# Generate report jobs:
## generate-boundary-sla-report (x)
##*  no report generated
##*  exception thrown in the logs attached [^syt1-generate-boundary-sla-report.log]
## generate-performance-kpi-report (x)
##*  no report generated
##*  exception thrown in the logs attached [^syt1-generate-performance-kpi-report.log]
","24/Sep/20 11:00;tr866;Assistance needed from Development.
Import jobs are failing both on Syt1 and docker. This can be very easily caused just by some misconfiguration, but in the current state it's not possible to confirm that SLA/KPI reports are possible to be generated.","29/Sep/20 15:45;ll664;The problem was that {{default.period.from}} was set too in the past and when {{collect-performance-kpi-data}} or {{credit-points}} jobs have run, the query URL to Elastic was simply too long and request failed. I just removed the default value, the Report Tool already contains logic, that if it's not set, it will use start of current month.","30/Sep/20 10:45;tr866;Testing on docker with versions XB 3.1.8-SNAPSHOT-2660ef12b9bd984a14ae6b741078506be217b363, Report Tool 2.49-SNAPSHOT-1581db3a1376ad79b38d5b86d2f60555e09481f6

# Import jobs:
## collect-boundary-sla-data (/)
##* no exception in the log file
##* records imported to computed_total table
## collect-performance-kpi-data
##* no exception in the log file (/)
##* haven't found any table where the data was imported (?)
## collect-spm-files-generation-data (/)
##* no expception in the log file
##* records imported to computed_percentile table
## credit-points
##* no exception in the log file (/)
##* haven't found any table where the data was imported (?)
# Generate report jobs: 
## generate-boundary-sla-report 
##* reports generated:
##** XBID Credit Points Report August 2020.xlsx - no values in any sheet (?)
##** XBID Service Boundary Reporting September 2020.xlsx - values found in the sheets 'Orders', 'Trades' (/)
##* no exception thrown
## generate-performance-kpi-report
##* reports generated: XBID Performance and SM SLA Reporting September 2020.xlsx
##* only Sheet 'SM Files Generation Time' contains some values (?)
##* no exception thrown","30/Sep/20 11:46;tr866;Summary:
 # thanks to the last fix the jobs are not failing anymore and reports can be generated (/)
 # To be checked: (?)
 ## validate why some import jobs didn't fill in any table in the DB?
 it looked like kpi collect was expecting data in raw_orderbook, raw_sender tables that were empty
Answer: (/) All the reports can't checked in details as there were not all types of transactions needed and sufficient amout of data as on production. But as the logic of the reports hasn't changed and some data were present in the reports from the executed trades that should be enough as a smoke test that reports are still working.
 ## Validate the interval for collecting of data
 as mentionned in the fix the data are collected from the start of *current month* till the end of the previous day. e.g. today's date being 30.09.2020 the interval for collecting data was
{noformat}
From: 2020-09-01T00:00Z[UTC], To: 2020-09-30T00:00Z[UTC]{noformat}
So question is when the import jobs are being executed.
Main concern was that I wasn't able to collect data for the last day of the month as collect job running on 1st day of following months was collecting data already only from the start of the next month.
Answer: (/) Problem in previous test was there was no previous record found then it was looking for data by default from the beginning of the current month. When last record could be found it was able to import correctly the data from the last day of the previous month too.

_Note: Reports attached [^XBID Credit Points Report September 2020.xlsx], [^XBID Performance and SM SLA Reporting September 2020.xlsx], [^XBID Service Boundary Reporting September 2020.xlsx]_",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Execute XBID CUTE PX DST test,XP-3595,100140,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,16/Sep/20 11:59,30/Sep/20 11:34,22/Feb/21 13:26,21/Sep/20 23:31,,,3.1.2,,,,,,,DST,TechOps,,,"I need to learn and gather all necessary information and steps how to perform it correctly
 * Organize meeting with Lambert about DST time change
 ** he should show how to do it using jenkins job
 [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/DST%20Operations/]
 and repo it is using
 [https://github.deutsche-boerse.de/dev/energy.dst.ntp]
 ** Test jenkins job with check
 ** I still need to discuss with somebody from M7/bizops if also m7 servers would participate in this test, it would require to update git repo with list of hosts
 * Make sure I have correct list of hosts the way how to stop and start all instances
 * Sync with Steffen, Tuan and Niklas about database tasks
 ** they should know how to do DB snapshot and check if we have full backup
 https://jira.deutsche-boerse.com/browse/M7P-5789
 https://jira.deutsche-boerse.com/browse/SERVICE-6189
 [https://confluence.energy.svc.dbgcloud.io/display/IO/DB+Recovery+procedure]
 * Execute DST test on 21.9. 2020",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3542,SERVICE-8078,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13219200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bjp3:c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Sep/20 14:52;hw120;All done, the exact steps described in SERVICE-8078. I will also update confluence documentation about the changes.","21/Sep/20 23:30;hw120;Updated the documentation for DST test.

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/XBID+and+M7+Customer+DST+Tests]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Split 2) CMI - OCC - VDA Interconnectors - Minimum, Original file content verification - review",XP-3593,100136,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,hj444,od044,16/Sep/20 11:47,30/Sep/20 11:37,22/Feb/21 13:26,18/Sep/20 11:53,,,3.1.2,,,,,,,TestAutomation,,,,"more TCs will be added.
Same possible cases:
PDA-VDA-nonPDA : 
(DK1-DK1A-SE3) =>example : IC1: DK1-DK1A

                                                 IC2 : DK1A-SE3

TC1: setting for Minimum  VDA-PDA 
                         Minimum  VDA- nonPDA

 TC2: setting for Original VDA-PDA 
                         Minimum VDA-nonPDA

* Publish VDA-PDA 
              VDA- nonPDA
* Do allocation: VDA-PDA 
                        VDA- nonPDA
* Verify content of files
*NOTE :*
** Check before start - if is possible to use distribution scheduler for automation tests. If not create a task for adding needed objects, methods for creating test.
** *Before this task- XP-3343 has to be finished.*",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13737600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bgjx:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DC Power maintenance 2020,XP-3592,100133,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,16/Sep/20 10:50,30/Sep/20 11:34,22/Feb/21 13:26,27/Sep/20 17:01,,,3.1.2,,,,,,,TechOps,,,,"Preparation for and execution of XBID part of DC Power maintenance 2020, 26.-27.9.
 * Discuss and sync on all necessary steps
 * Learn the correct start/stop sequence of all modules - Jiri Kuchta
 * Prepare scripts with Roman to automate instance stopping and starting
 * Execute power maintenance tasks on 26.-27.9. 2020",,hw120,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8178,SERVICE-8146,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12700800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bjp3:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Sep/20 09:10;hw120;Stop sequence:
 * We can stop all tomcat instances at the same time
 * Then all remaining supporting services like rabbitmq, haproxy, apache, ldap, glusterfs, ftp, databases,...

Start sequence:
 * database instances, glusterfs, ldap, rabbitmq, apache, haproxy, ftp
 * cor1
 * all other instances and cor2
 * smi (shipping module integration) in the end (it should start after smc shipping module core)
 ** Also it depend where I want cor to be running in master mode, if I want to have master on cor2, then I first start cor2","27/Sep/20 15:44;rehapav;Can be set to done.","27/Sep/20 17:01;hw120;I had to update postgres monitoring deployment to handle upgraded postgres 12 instances and deploy it to all corresponding ctpX and perf instances.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate postgres databases running on xbsimusla1 and xbsimusla2 ,XP-3585,100059,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,eg288,eg288,15/Sep/20 12:02,02/Nov/20 12:57,22/Feb/21 13:26,01/Oct/20 17:15,,,3.1.2,,,,,,,,,,,"Migrate postgres databases version 9 running on xbsimusla1 and xbsimusla2 to version 12. The database is used by report tool and AM reporting.

For discussion: lets do it in normal working hours including report tool redeployment, I think customer will not notice

Curently xbreporttool does not support flyway repair which might be needed so we should implement XP-3567 ASAP",,eg288,hw120,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12355200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,15/Sep/20 12:02,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c0i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Sep/20 14:17;tm431;The migratin should be done on 1/10/2020 during standard SIMU deployment SERVICE-8179","01/Oct/20 17:16;hw120;{code:java}
yum install -y postgresql12 postgresql12-server postgresql12-contrib postgresql12-debuginfo

su - postgres
psql -c ""SELECT * FROM pg_stat_activity;""
psql -c ""ALTER USER pg_watch2 RENAME TO pgwatch2;""
for db in report_tool_db am_reporting; do psql -d $db -c ""ALTER TABLE schema_version RENAME TO flyway_schema_history;ALTER TABLE flyway_schema_history DROP CONSTRAINT schema_version_pk; ALTER TABLE flyway_schema_history ADD CONSTRAINT flyway_schema_history_pk PRIMARY KEY (installed_rank);""; done

/usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql/9.5/data/ stop
mkdir -p /var/lib/pgsql/12/data/
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ initdb
/usr/pgsql-12/bin/pg_upgrade -b /usr/pgsql-9.5/bin -B /usr/pgsql-12/bin -d /var/lib/pgsql/9.5/data -D /var/lib/pgsql/12/data -o ' -c config_file=/var/lib/pgsql/9.5/data/postgresql.conf' -O ' -c config_file=/var/lib/pgsql/12/data/postgresql.conf'
cp /var/lib/pgsql/9.5/data/postgresql.conf /var/lib/pgsql/12/data/
cp /var/lib/pgsql/9.5/data/pg_hba.conf /var/lib/pgsql/12/data/
/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ start
./analyze_new_cluster.sh

for instance in report_tool_db am_reporting; do psql -d$instance -f flyway_history_table_fix.sql; done

/usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql/12/data/ stop

# as root user
systemctl disable postgresql-9.5.service
systemctl enable postgresql-12.service
systemctl start postgresql-12.service
systemctl status postgresql-12.service
tail -f /var/lib/pgsql/12/data/pg_log/postgresql-Thu.log
{code}
Done, all went well. I stopped application before and started it after the migration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Running out of swap on database hosts,XP-3575,100008,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,14/Sep/20 12:14,30/Sep/20 11:34,22/Feb/21 13:26,24/Sep/20 22:56,,,3.1.2,,,,,,,OS,TechOps,,,"xbprodpdb1 is reporting high swap usage.

Consulted with Cybertec and got a recommendation on how to set kernel parameters correctly for swappiness in /etc/sysctl.conf:
{code:java}
vm.overcommit_memory = 2
vm.overcommit_ratio = 93
vm.swappiness = 1
{code}
based on this calculation they provided

memory_limit = swap + overcommit_ratio/100 * RAM
 # only commit as much memory as we have RAM
 # overcommit_ratio = ( (RAM - swap) / RAM ) * 100

[https://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit]

According to the documentation from redhat, I calculated value to be...

[https://access.redhat.com/solutions/68612]

RHEL6, 7:
 allocatable memory=(swap size + ((RAM size - huge tlb size) * overcommit ratio / 100))

where ""allocatable memory"" should be less or equal than 100

 

Discussing with Cybertec proper values, ask how it could be influenced by configured hugepages.

 
 - Implement on Test db hosts, it was already configured on pdb hosts

 ** xbtestpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 ** xbtestdbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbinteedb1: 4.8GB RAM, 4GB SWAP,  overcommit_ratio = 16

 - Implement on Simu and perf db hosts, wait for a week
 ** xbsimupdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbsimudbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbsimuedb1: 8GB RAM, 2GB SWAP,  overcommit_ratio = 75
 ** xbperfpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 - Implement on Prod and perf db hosts, wait for week
 ** xbprodpdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbproddbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbprodedb1: 4.8GB RAM, 2GB SWAP,  overcommit_ratio = 58

 

 
{code:java}
cat << EOF > /etc/sysctl.d/98-db.conf
## Cybertec recommendations

# don't overcommit memory
vm.overcommit_memory = 2

# only commit as much memory as we have RAM
# overcommit_ratio = ( (RAM - swap) / RAM ) * 100
vm.overcommit_ratio = 95

# Minimize swapping
vm.swappiness = 1
EOF

# to apply the settings run
sysctl -p/etc/sysctl.d/98-db.conf
# OR
sysctl --system
{code}
 

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12960000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bjoo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/20 10:11;hw120;Laurenz Albe explained how it should be calculated

To show the exact calculation:
(RAM - swap) / RAM * 100
(128418 - 7999) / 128418 * 100 = 93.77112242832001744300
So 93 is a safe value.","16/Sep/20 00:38;hw120;Updated on all test, simu and perf databasese, will wait for a week to implement it on prod.","24/Sep/20 22:56;hw120;Updated on prod.

Documented here

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Configure+swappiness+and+memory+overcommitment+to+prevent+swapping]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xb roles using info endpoint - obtain app version from info endpoint fails when app start fails but tomcat is running,XP-3568,99974,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eg288,eg288,11/Sep/20 16:38,20/Nov/20 12:45,22/Feb/21 13:26,20/Nov/20 12:45,,,,,,,,,,,,,,"if application start fails but tomcat stays runnig, then any following deployment fails when trying to get application version from info endpoint.

Improve robustnes of the roles so they can handle the scenario

Task Get application version cannot obtain the version, but the following task Set fact current application version is still executed and fails because it cannot get build version from the previous task. It works when the tomcat is not running, but if there is a tomcat wihout the app then it fails.
{code:java}
The error was: 'dict object' has no attribute 'build' 

{code}
 

See the full log here
{code:java}
TASK [xbpmi-archiver : Get application version] ********************************

fatal: [xb-xbid-simu-pmi-archiver4]: FAILED! => {
 ""changed"": false,
 ""connection"": ""close"",
 ""content"": ""\{\""timestamp\"":1599831889811,\""status\"":404,\""error\"":\""Not Found\"",\""message\"":\""No message available\"",\""path\"":\""/xbid-simu-pmi-archiver4/info\""}"",
 ""content_type"": ""application/json;charset=UTF-8"",
 ""date"": ""Fri, 11 Sep 2020 13:44:49 GMT"",
 ""json"": {
 ""error"": ""Not Found"",
 ""message"": ""No message available"",
 ""path"": ""/xbid-simu-pmi-archiver4/info"",
 ""status"": 404,
 ""timestamp"": 1599831889811
 },
 ""redirected"": false,
 ""status"": 404,
 ""transfer_encoding"": ""chunked"",
 ""url"": ""http://localhost:8104/xbid-simu-pmi-archiver4/info"",
 ""x_application_context"": ""application:simu:8104""
}

MSG:

Status code was 404 and not [200]: HTTP Error 404: 
...ignoring

 

 

TASK [xbpmi-archiver : Set fact current application version] *******************
fatal: [xb-xbid-simu-pmi-archiver1]: FAILED! => {}

MSG:

The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'build'

The error appears to have been in '/home/jenkins/workspace/Energy-Operations/XBID Ansible Jobs/XBID Ansible deploy full/roles/xbpmi-archiver/tasks/set_app_facts.yml': line 10, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: Set fact current application version
 ^ here

{code}",,eg288,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8121600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,11/Sep/20 16:38,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3568,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Nov/20 12:44;ll664;This is actually already implemented in https://github.deutsche-boerse.de/dev/energy.automation.deployments/commit/69f5d7c6d54defb1dafcc23cd429b68334470a91

{code}
TASK [Gathering Facts] *********************************************************

ok: [xb-xbid-syt1-smi2]

ok: [xb-xbid-syt1-smi1]


TASK [xbcommon : Get application version] **************************************

fatal: [xb-xbid-syt1-smi1]: FAILED! => {

    ""cache_control"": ""no-cache, no-store, max-age=0, must-revalidate"",

    ""changed"": false,

    ""connection"": ""close"",

    ""content"": ""<!doctype html><html lang=\""en\""><head><title>HTTP Status 404 – Not Found</title><style type=\""text/css\"">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 – Not Found</h1></body></html>"",

    ""content_language"": ""en"",

    ""content_length"": ""431"",

    ""content_type"": ""text/html;charset=utf-8"",

    ""date"": ""Fri, 20 Nov 2020 11:22:24 GMT"",

    ""expires"": ""0"",

    ""pragma"": ""no-cache"",

    ""redirected"": false,

    ""set_cookie"": ""JSESSIONID=C3F5D95C329722BE9F97D0FD3BA95533.xbid-syt1-smi1; Path=/spm; HttpOnly"",

    ""status"": 404,

    ""url"": ""http://localhost:60703/spm/info/x"",

    ""vary"": ""Origin, Access-Control-Request-Method, Access-Control-Request-Headers"",

    ""x_content_type_options"": ""nosniff"",

    ""x_frame_options"": ""DENY"",

    ""x_xss_protection"": ""1; mode=block""

}


MSG:


Status code was 404 and not [200]: HTTP Error 404: 

...ignoring

fatal: [xb-xbid-syt1-smi2]: FAILED! => {

    ""cache_control"": ""no-cache, no-store, max-age=0, must-revalidate"",

    ""changed"": false,

    ""connection"": ""close"",

    ""content"": ""<!doctype html><html lang=\""en\""><head><title>HTTP Status 404 – Not Found</title><style type=\""text/css\"">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 – Not Found</h1></body></html>"",

    ""content_language"": ""en"",

    ""content_length"": ""431"",

    ""content_type"": ""text/html;charset=utf-8"",

    ""date"": ""Fri, 20 Nov 2020 11:22:24 GMT"",

    ""expires"": ""0"",

    ""pragma"": ""no-cache"",

    ""redirected"": false,

    ""set_cookie"": ""JSESSIONID=650B968A1A5D2FDB7A5921DC6ABABC20.xbid-syt1-smi2; Path=/spm; HttpOnly"",

    ""status"": 404,

    ""url"": ""http://localhost:60703/spm/info/x"",

    ""vary"": ""Origin, Access-Control-Request-Method, Access-Control-Request-Headers"",

    ""x_content_type_options"": ""nosniff"",

    ""x_frame_options"": ""DENY"",

    ""x_xss_protection"": ""1; mode=block""

}


MSG:


Status code was 404 and not [200]: HTTP Error 404: 

...ignoring


TASK [xbcommon : Set fact current application version] *************************

skipping: [xb-xbid-syt1-smi1]

skipping: [xb-xbid-syt1-smi2]

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbreporttool - cleandb is preserved in application.properties thus each restart cleans the data,XP-3567,99973,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,eg288,eg288,11/Sep/20 16:23,02/Nov/20 12:57,22/Feb/21 13:26,13/Oct/20 09:30,,,3.1.2,,AM Indicators Reporting,SLA Report Tool,,,,,,,,"xbreporttool role exeuted with action deploy_wit_clean_db sets in application.properties:
flyway.cleanBeforeMigrate=True
 
afterwards each start/restart cleans the database as the property is set to true. The property is reset only with a next deployment without clean db.
 
*Possible solution:*
-update xbflyway role to provide cleandb task only and use it in the xbreporttool  instead of setting proeprty flyway.cleanBeforeMigrate. Flyway migration is still done by the report tool itself.-
*Discussion:*
-what about flyway repair, is reporttool able to run flyway repair or should it be also provided by xbflyway role? repair was already needed on other modules when we upgraded flyway recently-

h3. Solution agreed by the team
Flyway migration and repair will still be done by the application itself, not by an external flyway via ansible. The parameter {{flyway.cleanBeforeMigrate}} will be passed as an additional parameter on a command line to a start script, the same way the repair will be handled (currently not in place, has to be completely introduced).

h3. Affected applications
report-tool
am-reporting
acer-reporting",,eg288,qo794,,,,,,,,,,,,,,,,,,,XP-3585,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11491200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,11/Sep/20 16:23,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3567,XP-3791-runTime,XP-3949,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Oct/20 14:00;qo794;h2. Implemented changes
* Flyway repair
** added to report-tool, AMR and ACER
** configurable via *flyway.repairBeforeMigrate* parameter
** the new parameter cannot be set to {{true}} at the same time as *flyway.cleanBeforeMigrate*, does not make any sense, added check to the application

* Ansible deployment
** *flyway.repairBeforeMigrate* and *flyway.cleanBeforeMigrate* passed to a startup script as command line parameters, no longer a part of {{application.properties}} in the ansible project
** *flyway.repairBeforeMigrate* configurable via ansible inventory files, {{false}} by default
** *flyway.cleanBeforeMigrate* set to {{true}} for *cleandb* tag only, {{false}} by default
** *cleandb* must be used together with *start* tag otherwise it has no effect since the db cleanup is done by the application itself

Tested on AMR on syt1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Two SFTP nodes support in pmi archiving,XP-3566,99972,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,uv683,uv683,11/Sep/20 15:35,26/Nov/20 10:46,22/Feb/21 13:26,25/Nov/20 12:54,,,3.2.x,,PMI Tools,,,,,,,,,"It was discovered that pmi archiving was always working only with one sftp node. This could lead to issues when given node will be down and there are two nodes. Enhance shipping module to work with multiple nodes.

See https://jira.deutsche-boerse.com/browse/XP-3552

 

Hint: 
 * there is an library used for this one. 
 * -assumption: it should require only bump of versions and update a template - Incorrect assumption, PMI archiver uses some low level library to connect to sftp, the whole sftp related code must be rewritten to use our multi node sftp class.",,od044,qo794,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4114,,,XP-3552,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:b",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Nov/20 10:41;qo794;h2. Implementation changes in version 1.1.0
* {{sshj}} library removed and replaced by {{MultiNodeSftpTemplate}} from {{energy-commons-trasport}} library
* sftp features fully covered by integration tests using testcontainers
* conditional creation of sftp related beans based on {{sftp.enabled}} parameter
* kotlin added to the project
* spring-boot upgraded from 1.5.22 to 2.3.5
** logging.path renamed to logging.file.path
** server.contextPath renamed to server.servlet.context-path
* password sftp login removed (not used at all), the following application parameters removed:
** sftp.password
** sftp.usePassword
* added the following new application parameters:
** sftp.timeout - default 10000
** sftp.knownHosts
* ansible deployment updated: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1231","11/Nov/20 10:22;qo794;Issue split into:
|XP-4114|(Split 1) Two SFTP nodes support in pmi archiving|
","12/Nov/20 16:34;qo794;Please retest also all SFTP features as this code is completely new.","25/Nov/20 12:54;od044;Test passed on SYT1 and pmi-archiver1
- pmi-archiver SFTP functionality like uploading, cleaning work properly according to grace and retention settings 
- password is not used anymore 
- access to SFTP is via ssh key 

some log example:
{code}
2020-11-24 23:05:02.622  INFO 24684 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : Grace period directory: /xbid/logs/xbid-syt1-pmi-logger1/archived-messages
2020-11-24 23:05:02.622  INFO 24684 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : SFTP base directory: OUT/pmi/pmi1
2020-11-24 23:05:02.622  INFO 24684 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : Files older than '2020-11-23T00:05:02.622' will be copied to SFTP and moved to internal archive.
2020-11-24 23:05:02.622  INFO 24684 --- [scheduling-1] c.d.e.m.p.a.s.ArchiverService            : Files older than '2020-11-11T00:05:02.622' will be deleted from '/xbid/logs/xbid-syt1-pmi-logger1/internal-archived-messages'.
{code}

{code}
2020-11-25 11:53:05.000  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.t.ArchivingTasks             : Cleaning invoked
2020-11-25 11:53:05.000  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.t.ArchivingTasks             : Cleaning SFTP invoked
2020-11-25 11:53:05.000  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.s.CleanerService             : Deleting files from SFTP older than 2020-11-24
2020-11-25 11:53:05.010  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.SftpAdapter                  : Directory '20201115' won't be deleted. Added date '2020-11-24'.
2020-11-25 11:53:05.010  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.SftpAdapter                  : Directory '20201114' won't be deleted. Added date '2020-11-24'.
2020-11-25 11:53:05.010  INFO 61638 --- [scheduling-1] c.d.e.m.p.a.SftpAdapter                  : Directory '20200826' won't be deleted. Added date '2020-11-24'.
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - adjust timeouts for cor starting,XP-3565,99915,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eh941,eh941,10/Sep/20 13:43,30/Sep/20 11:35,22/Feb/21 13:26,25/Sep/20 11:42,,,3.1.2,,,,,,,,,,,longer timeout for cor* startup scripts to prevent false alarm ,,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12960000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/20 11:41;eg288;DONE. Var STARTUP_RETRIES in start up script roles/xbtomcat/templates/start.sh.j2 is now configurable. It is set to 60 for role xbcore. Other roles still use default value 30.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - update flyway configuration to use master node selection,XP-3564,99914,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,eh941,eh941,10/Sep/20 13:42,02/Nov/20 12:57,22/Feb/21 13:26,07/Oct/20 08:39,,,3.1.2,,,,,,,,,,,Flyway should use master node selection otherwise it fails on read-only transaction error.,,eh941,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bo27:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Oct/20 12:12;qo794;Added *""?targetServerType=master""* to {{flyway_url}} parameter for roles
* xbcmi
* xbcor
* xbctp
* xbsmc

Already present for roles: xbams and xbrep","07/Oct/20 08:39;qo794;Tested on CMI on syt1, working fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update monitoring deployment/inventory to work with new xbid ansible deployment,XP-3562,99885,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,hw120,hw120,10/Sep/20 10:25,02/Nov/20 13:06,22/Feb/21 13:26,28/Oct/20 00:32,,,3.1.3,,,,,,,ansible,MONITORING,TechOps,,"As xbid syt1 and simu environment have been deployed by new ansible way, they changed the inventory structure of directories/services and their variables, which caused monitoring deployment to break.

I have to update the inventory and ansible deployment to work with it and redeploy it.
 * update filebeat, telegraf to see/have available vars from xb deployment roles
 * redeploy to all ansible migrated envs",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,All seems to be working.,,,,,,,,,,,,,,10627200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btj9:c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Oct/20 23:01;hw120;Updated service default inventory variables for calculating port on xbcor and xbenq.

Redeployed on simu and all ansible deployed ctpX envs.

I can see I have to check Application health check status: UP alert and variables if something changed there also.","08/Oct/20 23:53;hw120;Updated service default inventory variables for calculating port on xbcmm, xbcmi, xbsmc, xbsmi.

Redeployed on simu and all ansible deployed ctpX envs.","09/Oct/20 00:00;hw120;Some xbid instances have multiple exec records for checking health status, for example:
{code:java}
[[inputs.exec]]
  commands = [""/etc/telegraf/scripts/health_check_tomcat.sh cmminteg 8080"",]  timeout = ""15s""
  data_format = ""json""
  name_prefix = ""status_""  [inputs.exec.tags]
    tomcat = ""xbctpedow1_cmminteg""
    module = ""xbid_ctpe""
    product = ""xb""
    client = ""xbid""
    client_environment = ""ctpe""
    host_group_module=""xbctpedow1 - tomcat - xbid_ctpe""
    instance = ""dow1""
    datacenter = ""equinix""
[[inputs.exec]]
  commands = [""/etc/telegraf/scripts/health_check_tomcat.sh spm 8082"",]  timeout = ""15s""
  data_format = ""json""
  name_prefix = ""status_""  [inputs.exec.tags]
    tomcat = ""xbctpedow1_spm""
    module = ""xbid_ctpe""
    product = ""xb""
    client = ""xbid""
    client_environment = ""ctpe""
    host_group_module=""xbctpedow1 - tomcat - xbid_ctpe""
    instance = ""dow1""
    datacenter = ""equinix""
{code}
But it is probably related to old perl deployment and inventory, should wait till migration to ansible.","13/Oct/20 22:58;hw120;Updated service default inventory variables for calculating port on xbrep, xbpmi-logger, xbpmi-archiver, xbctp.

Redeployed on simu and all ansible deployed ctpX envs.","13/Oct/20 23:40;hw120;xbapache*, haproxy* and rabbitmq are remaining.

Have to prepare list of services which are not monitored yet and create tickets for them.","16/Oct/20 00:18;hw120;Updated for haproxy and redeployed on ctpX and syt1 env.

Also tested and fixed problems on syt1 env.","21/Oct/20 22:32;hw120;Updated service default inventory variables for calculating port on xbamr and xbams

Redeployed on ctso, cute, lipa and lipb envs.","21/Oct/20 22:46;hw120;Updated service default inventory variables for calculating port on xbreporttool.

Redeployed on cute env.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Open Firewall from entestauto1 to perf DB,XP-3561,99883,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,iv732,iv732,10/Sep/20 10:11,06/Nov/20 09:26,22/Feb/21 13:26,30/Sep/20 10:37,,,3.1.2,,,,,,,TechOps,,,,"In order for Dev to run deployment on Perf, we need to open the firewall between the Jenkins workder entestauto1 to perf DB",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12528000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0biy8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/20 09:55;iv732;#505451 | EGY - Jenkins worker entestauto1 connects to perf DB","30/Sep/20 10:36;iv732;Done
{code:java}
Subject: EGY - Jenkins worker entestauto1 connects to perf DB
 Workflow name: Access Request
 Ticket ID: 505451
 Requester: Tuan Nguyen
 Status: Resolved
 Priority: Normal
 SLA Status: OK
 SLA Outcome: Due in 12 days
 
 Details: Your request was completed.Click here to confirm or reopen the ticket: 
 https://fw-request.deutsche-boerse.de/securechangeworkflow/pages/myRequest/verifyTicket.seam?ticketId=505451
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - haproxy configuration for syt2 is missing,XP-3556,99828,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,eh941,eh941,09/Sep/20 13:58,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 11:02,,,3.1.2,,,,,,,,,,,There is no _working_ configuration for syt2 at the moment. Create it.,,eg288,eh941,ek176,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11404800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bjw6:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 19 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Oct/20 11:37;eg288;1) Remove existing haproxy-be configuration, on single sided env where is only one rabbitmq instance like on syt2 all modules connects directly to the rabbitmq instance.

2) create configuration for haproxy-fe so it is possible to use SSL when connecting from outside to the rabbitmq","09/Oct/20 16:36;ek176;Successfully connected with new Cert (XP-3514) using TC-6.0.37-SNAPSHOT to 10.136.142.20:50800 as SADMIN03.

 

Note: AMQP servers only FE, using  {{{\{ amqp_addr_dc1 }}}}, instead of {{AMQP_SERVERS_EXT}} ","09/Oct/20 16:45;ek176;Certs offered on 10.136.142.20:50800 – verification ok:
{noformat}
    Verify return code: 0 (ok){noformat}
Shortened log:
{noformat}
$ openssl s_client -showcerts -connect 10.136.142.20:50800

CONNECTED(00000005)
depth=2 C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
verify return:1
depth=1 C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
verify return:1
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Bors
e Aktiengesellschaft, OU = Multi-Domain SSL, CN = syt2.xbid.m7.deutsche-boerse.com
verify return:1

---
Certificate chain

 0 s:C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse A
ktiengesellschaft, OU = Multi-Domain SSL, CN = syt2.xbid.m7.deutsche-boerse.com
   i:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA

 1 s:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
   i:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority

 2 s:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root

 3 s:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
---
Server certificate
subject=C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Bors
e Aktiengesellschaft, OU = Multi-Domain SSL, CN = syt2.xbid.m7.deutsche-boerse.com

issuer=C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
---

Acceptable client certificate CA names
C = DE, ST = Hessen, O = TRUST ROOT, OU = Security, CN = Norbert Roestel
C = DE, ST = Hessen, O = TRUST INTERMIDIATE, OU = Security, CN = Norbert Roestel
C = DE, ST = Hessen, O = DBAG, OU = Internet Security, CN = Norbert Roestel CA
C = DE, O = Deutsche Boerse Group, CN = Test Deutsche Boerse Group Root CA
C = DE, O = Deutsche Boerse Group, CN = Test Deutsche Boerse Group CA
C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Certification Authority
C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Organization Validation Secure Server CA
C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktien
gesellschaft, OU = PlatinumSSL, CN = simu1.cltx.m7.deutsche-boerse.com
C = DE, O = Exchange, OU = PKI Entity, CN = Gruppe Deutsche Boerse CA
C = DE, L = Eschborn, O = Deutsche B\C3\83\C2\B6rse Group, CN = DBG CLIENT CA XBID TEST

Client Certificate Types: RSA sign, DSA sign, ECDSA sign

Requested Signature Algorithms: RSA+SHA512:DSA+SHA512:ECDSA+SHA512:RSA+SHA384:DSA+SHA384:ECDSA+SHA384:RSA+SHA256:DSA+SHA256:ECDSA+SHA256:RSA+SHA224:DSA+SHA224:ECDSA+SHA224:RSA+SHA1:DSA+
SHA1:ECDSA+SHA1

Shared Requested Signature Algorithms: RSA+SHA512:DSA+SHA512:ECDSA+SHA512:RSA+SHA384:DSA+SHA384:ECDSA+SHA384:RSA+SHA256:DSA+SHA256:ECDSA+SHA256:RSA+SHA224:DSA+SHA224:ECDSA+SHA224:RSA+SH
A1:DSA+SHA1:ECDSA+SHA1

Peer signing digest: SHA512
Peer signature type: RSA
Server Temp Key: ECDH, P-256, 256 bits
---
SSL handshake has read 7973 bytes and written 453 bytes
Verification: OK
---
New, TLSv1.2, Cipher is ECDHE-RSA-AES256-GCM-SHA384
Server public key is 2048 bit
Secure Renegotiation IS supported
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : ECDHE-RSA-AES256-GCM-SHA384
    Session-ID: B5047442B432851078722028A466B93BD96D26D45289A0C3CCD70873A9334F0F
    Session-ID-ctx:  
    Master-Key: 2F13F5CD838D83301A663FBB88D346ACBC13DF799243BF09AC1BCA7A2D8C0A52FF9C45B82651E068A88E49AB1F05B756
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1602254462
    Timeout   : 7200 (sec)
    Verify return code: 0 (ok)
    Extended master secret: no
---
{noformat}","13/Oct/20 12:13;tr866;Successfully tested on environment Syt2 with version R3.1.5-d9d76cd1b071d193bde2482a415b6b15bba9dd89

# Connection with AMQP Test Client client-swing-6.0.36-with-deps working fine (/)
Succesfully connected to 10.136.142.20:50800 with user XBEPEXX1 using SSL connection with the usual certificate COMTRADER_AllNonProd_xbid-SOB.p12. Connection was made from OA network.
# Connection with ComTrader 2.5.1.67 to Syt2 with user SADMIN03 was working also fine. (/)
(only connection to Profile Server was refused, which I guess is not related to haproxy)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OWASP shared Suppression.xml file via HTTPS,XP-3555,99824,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ek176,ek176,09/Sep/20 13:53,02/Dec/20 10:00,22/Feb/21 13:26,02/Dec/20 09:59,,,,,,,,,,,,,,"OWASP sometime calls FalsePositives. The plugin can have multiple suppression files, even on HTTP(s) endpoints. 

 

Example False positive:
{noformat}
<suppress>
<notes><![CDATA[   file name: kotlin-stdlib-1.4.0.jar   ]]></notes>        <packageUrl regex=""true"">
^pkg:maven/org\.jetbrains\.kotlin/kotlin\-(common|reflect|stdlib(-jdk[78]|-common)?)@.*$</packageUrl>        
<!-- False positive: Fixed in 1.4.0 -->        
<cve>CVE-2020-15824</cve>    </suppress>{noformat}
AC:
 * Create github(?) endpoint hosting common owasp-suppression.xml file
 * Upgrade relevant projects (OWASP plugin configuration) ",,ek176,lt112,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7084800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3394_flyway_standard_implementation,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-761-spooooky-migration-from-grunt-to-webpack,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-4354,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-4234,master-acceptance,master,acceptance,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-3394_remove_schema_version,fixing-dataset,XP-4349_set_default_page,using-no-package-lock-during-npm-install,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Dec/20 10:00;lt112;OWASP file shared in artifactory at https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/xbid/owasp/1.0.0/suppressions.xml
all project linked
see description in https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-owasp-suppressions-editor/ for editing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - rabbitmq cluster restart doesn't work,XP-3554,99816,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,09/Sep/20 11:40,06/Nov/20 09:07,22/Feb/21 13:26,11/Sep/20 10:49,,,3.1.2,,,,,,,,,,,"When trying to restart it ends up on primary node on:

{noformat}
2020-09-09 10:52:53.590 [info] <0.339.0> Waiting for Mnesia tables for 30000 ms, 0 retries left
2020-09-09 10:53:23.591 [error] <0.338.0> CRASH REPORT Process <0.338.0> with 0 neighbours exited with reason: {{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_pa
rameters,rabbit_durable_queue]},{rabbit,start,[normal,[]]}} in application_master:init/4 line 138
2020-09-09 10:53:23.592 [info] <0.43.0> Application rabbit exited with reason: {{timeout_waiting_for_tables,[rabbit_user,rabbit_user_permission,rabbit_topic_permission,rabbit_vhost,rabbit_durable_route,rabbit_durable_exchange,rabbit_runtime_parameters,rabbit_durable_queue]},
{rabbit,start,[normal,[]]}}

{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14342400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bijs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update customer monitoring to avoid false-possitive alerts,XP-3551,99805,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,hw120,hw120,09/Sep/20 10:37,20/Jan/21 14:32,22/Feb/21 13:26,20/Jan/21 14:32,,,,,,,,,,MONITORING,TechOps,,,"We need to avoid the false-positive AT alarms

1) it looks like the problem is somewhere in the ""middle layer"" on the apache servers, network,... or we should do the same as was done for PROD issue XP-3434
 _the monitoring script is adjusted to run still every 5s but if the first attempt returns the faulted state then we will wait 10s and check again. updated only on prod, we have to update it on all envs_


 2) introduce some multiple checks before these AT are triggered",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3434,XP-3512,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Fixed on production,,,,,,,,,,,,,,14342400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i000000000000000go",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,HOT Sprint 18 (S),HOT Sprint 19,HOT Sprint 20 (S),Xbops Sprint 22,Xbops Sprint 23,Xbops Sprint 24,Xbops Christmas Sprint,Xbops Sprint 25,Xbops Sprint 26,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document changes made to the trading Test Client 6.0.17+,XP-3543,99734,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,rg535,radeale,radeale,07/Sep/20 17:10,06/Nov/20 09:32,22/Feb/21 13:26,16/Sep/20 10:32,,,3.1.2,,Trading,,,,,,,,,"Please document the changes made to the trading Test Client starting with the version 6.0.17 up to the version 6.0.36.

This should serve as a basis for a commercial offer to the customers.

Coordinate with [~radeale].",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/20 12:57;radeale;XP-3543-v2.txt;https://jira.deutsche-boerse.com/secure/attachment/87388/XP-3543-v2.txt","08/Sep/20 14:46;qo794;test-client-git-log-6.0.16-to-6.0.36-clean.txt;https://jira.deutsche-boerse.com/secure/attachment/87354/test-client-git-log-6.0.16-to-6.0.36-clean.txt","08/Sep/20 14:46;qo794;test-client-git-log-6.0.16-to-6.0.36.txt;https://jira.deutsche-boerse.com/secure/attachment/87353/test-client-git-log-6.0.16-to-6.0.36.txt",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14342400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,07/Sep/20 17:10,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bi20:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Sep/20 10:39;radeale;https://github.deutsche-boerse.de/dev/m7.test-client/commit/0f099b04e0749258180316da68ee7bd91679290b","08/Sep/20 14:52;qo794;A diff between versions 6.0.17 and 6.0.36 generated from https://github.deutsche-boerse.de/dev/m7.test-client using the following commands:
*  [^test-client-git-log-6.0.16-to-6.0.36.txt] 
{code:bash}
git log --oneline m7-test-client-6.0.16..m7-test-client-6.0.36 > test-client-git-log-6.0.16-to-6.0.36.txt
{code}
* an export without ""service"" lines:  [^test-client-git-log-6.0.16-to-6.0.36-clean.txt] 
{code}
grep -v ""pull request"" test-client-git-log-6.0.16-to-6.0.36.txt | grep -v ""'master'"" | grep -vi ""updating"" > test-client-git-log-6.0.16-to-6.0.36-clean.txt
{code}

h3. Notes:
* the export contains also changes from 6.0.16 just to show a point when the version 6.0.17 was created
* the first line is the newest, the last one the oldest change
* releases are divided by a line containing ""Merge branch "" and a release version
* commits below a certain release until a next release divisor line belong to that release, for instance the following lines surrounded by two releases belong to version 6.0.28:
{quote}
b371603b4 Merge branch 'release-m7-test-client-6.0.28'
fc3ad2cf4 XP-2172 corrected column order
0eda5590f XP-2172 loading Contract when mapping public trade confirmation
6ea552210 Merge branch 'release-m7-test-client-6.0.27'
{quote}","09/Sep/20 12:57;radeale;The changes are documented here:
 [^XP-3543-v2.txt] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Prepare Infrastucture (DBs) for  AM reporting tool deployment to LIPA, LIPB, CUTE, CTSO ",XP-3541,99709,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,tm431,tm431,07/Sep/20 14:11,02/Nov/20 12:57,22/Feb/21 13:26,22/Oct/20 09:13,,,3.1.2,,,,,,21/Oct/20 00:00,,,,,"*DECISION TAKEN after meeting*

1) AM reporting tool will be deployed into XBCUTSRPT1, where it will be stopped for all envs. (LIPA, LIPB, CUTE, CTSO) and started only for CUTE before Time Travel will happen. This will ensure that there will be AM reports on CUTE envs. generated for the future (for the time travel interval). During this time shift it will not be possible to use AM reporting on other envs. With backward time travel, we will need to delete logs and am reporting files (becouse they were generated for the future)

2) *We will need to prepare new 4 DBs* as a preparation step for AM reporting tool deployments into LIPA, LIPB, CUTE, CTSO we can already start with this

3) *We will need to check whether new FW* should be opened for AM indicator deployment. i.e. between SFTP server and XBCUTESRPT1 and i think XBCUTESRPT1 and CORs?

4) *New sftp user/s should be created.* 1) towards customers (folder) xbid_amreports_cute/am xbid_amreports_cute (lipa, lipb, ctso) and 2) some which application uses to write data, including correct ssh key

5) We can polish some running applicatins on this server, as it is meaningless to have SLA reporting running for inidividual cutees CTPA->CTPM as there is no SFTP server towards customers. So we can stop these applications:DinstanceName=xbid-*ctp*X-report-tool1  

we will leave them running for LIPA, LIPB, CTSO, CUTE

6) we can introduce Xms and Xmx for the application to avoid overloading of the server


*FORESEEN DEPLOYMENT INTO LIPB IS 29/10/2020*",,cs687,hw120,qo794,rehapav,tm431,zi174,,,,,,,,,,,,,,,,,,,,,,,XP-3967,,,,,,,SYSENGEXT-223,SERVICE-8297,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,all the mentioned steps which are described in the description are done,,,,,,,,,,,,,,10627200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btj9:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Sep/20 09:32;zi174;[~tm431] please add notes from the meeting, Thank you ","23/Sep/20 09:07;tm431;Notes Added, now we can continue in some refinement to e.g. create subtasks from the description and start to introduce/develope them","01/Oct/20 10:46;tm431;Sizing of DBs should be same as was done for XBID SIMU env, each DB should have same size as in SIMU if possible","01/Oct/20 13:13;rehapav;Request from syseng team 

Information to be included into the syseng Jira are

example: SYSENG-151
 * hostname
 * network 
 * count of CPU cores
 * RAM
 * HDD size
 * version of Postgre ","01/Oct/20 13:43;tm431;[~rehapav] same as was done for SIMU, unfortunetelly I do not have such knowlege, from DEV I just got that sizing and everything as was done in SIMU
 [~hw120]  provide other necesarry information to Pavel","02/Oct/20 10:47;tm431;So the conclusion from the SYSENG ticket is that you [~hw120]  or [~iv732]  should prepare these DBs.","12/Oct/20 12:34;yo218;Created the 4 databases and their users on xbcutsrpt1:
{noformat}
-bash-4.2$ createdb am_reporting_ctso -O ops_am_reportuser_ctso
-bash-4.2$ createdb am_reporting_cute -O ops_am_reportuser_cute
-bash-4.2$ createdb am_reporting_lipa -O ops_am_reportuser_lipa
-bash-4.2$ createdb am_reporting_lipb -O ops_am_reportuser_lipb
-bash-4.2$ psql -l
                                                           List of databases
        Name         |         Owner          | Encoding |   Collate   |    Ctype    |                Access privileges
---------------------+------------------------+----------+-------------+-------------+-------------------------------------------------
 am_reporting_ctso   | ops_am_reportuser_ctso | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 am_reporting_cute   | ops_am_reportuser_cute | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 am_reporting_lipa   | ops_am_reportuser_lipa | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 am_reporting_lipb   | ops_am_reportuser_lipb | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 {noformat}
And I created the vault entries for the db user","12/Oct/20 15:02;yo218;1) Inventory entries need to be created --> dev?

2) databases are prepared

3) all hosts are in the same network, no new FW rules should be required

4) Users existed already, I just added the same ssh keys as available for Simu. Keys for customer need to be added separately

5) The only running on process on xbcutsrpt1 is for cute:
{noformat}
/xbid/xbid-cute-report-tool/runReportTool.sh {noformat}
Logdirectories for all other environments are empty. Deleted the directories for ctpa-ctpm as requested

 6) Don't know what Xms and Xmx are","14/Oct/20 12:29;qo794;Issue split into:
|XP-3967|(Sprint 1) Prepare Infrastucture (DBs) for  AM reporting tool deployment to LIPA, LIPB, CUTE, CTSO |
","16/Oct/20 14:46;qo794;AMR configuration in ansible for CUTE, CTSO, LIPA and LIPB prepared: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2280

TODO for techops:
* ensure DB usernames and passwords are in vault for all envs in question
{code}
db_am_reporting_user: ""{{ lookup('hashi_vault', 'secret={{ db_secret_prefix }}/xb{{ env }}amreporting:username token={{ hashi_vault_token }} url={{ hashi_vault_addr }}') }}""
db_am_reporting_password: ""{{ lookup('hashi_vault', 'secret={{ db_secret_prefix }}/xb{{ env }}amreporting:password token={{ hashi_vault_token }} url={{ hashi_vault_addr }}') }}""
{code}
* review and merge the pull reuqest
* redeploy report-tool for CUTE together with telegraf (the application port was changed) - maybe try dry-run and we can check changes first
* deploy AMR on all envs in question - one by one, if first is ok continue with others
* after everything is fine, stop all AMR deployed above - is it needed? can we just leave them running?","21/Oct/20 10:39;cs687;[~qo794]: 

added the missing vault-secrets (double checked the password on the host *XBCUTSRPT1* in the application properties) 
* xb/xbid/ctso/db/uapp01xbctsosla
* xb/xbid/ctso/db/xbctsoreporttool/cor
* xb/xbid/simu/db/xbsimureporttool/spm
* xb/xbid/ctso/db/xbctsoreporttool/reporttool
* xb/xbid/ctso/db/xbctsoamreporting

* xb/xbid/cute/db/uapp01xbcutesla
* xb/xbid/cute/db/xbcutereporttool/cor
* xb/xbid/cute/db/xbcutereporttool/spm
* xb/xbid/cute/db/xbcutereporttool/reporttool
* xb/xbid/cute/db/xbcuteamreporting

* xb/xbid/lipb/db/uapp01xblipbsla
* xb/xbid/lipb/db/xblipbreporttool/cor
* xb/xbid/lipb/db/xblipbreporttool/spm
* xb/xbid/lipb/db/xblipbreporttool/reporttool
* xb/xbid/lipb/db/xblipbamreporting

* xb/xbid/lipa/db/uapp01xblipasla
* xb/xbid/lipa/db/xbsimureporttool/cor
* xb/xbid/lipa/db/xbsimureporttool/spm
* xb/xbid/lipa/db/xbsimureporttool/reporttool
* xb/xbid/lipa/db/xblipaamreporting

approved and merged pull-request 

added env´s to Jenkins Job
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1178/files

added the missing ports *port_env_digits*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2298/files","21/Oct/20 12:06;qo794;Added {{port_env_digits}} variable to all envs where it was missing: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2298

DB name fixed: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2299

Sftp host and port: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2300","21/Oct/20 14:02;cs687;xbid-cute-amr1 deployed successfully: 
{code:java}
tomcat@xbcutsrpt1 xbid-cute-amr1]$ curl http://localhost:63311/actuator/health
{""status"":""UP"",""components"":{""diskSpace"":{""status"":""UP"",""details"":{""total"":6207111168,""free"":5061984256,""threshold"":10485760,""exists"":true}},""ping"":{""status"":""UP""},""reportDb"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""validationQuery"":""isValid()""}}}}
{code}

xbid-ctso-amr1 deployed successfully: 
{code:java}
[tomcat@xbcutsrpt1 ~]$ curl http://localhost:63371/actuator/health
{""status"":""UP"",""components"":{""diskSpace"":{""status"":""UP"",""details"":{""total"":6207111168,""free"":4987568128,""threshold"":10485760,""exists"":true}},""ping"":{""status"":""UP""},""reportDb"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""validationQuery"":""isValid()""}}}}[tomcat@xbcutsrpt1 ~]$
{code}

xbid-lipa-amr1 deployed successfully:
{code:java}
[tomcat@xbcutsrpt1 ~]$ curl http://localhost:63381/actuator/health
{""status"":""UP"",""components"":{""diskSpace"":{""status"":""UP"",""details"":{""total"":6207111168,""free"":4913160192,""threshold"":10485760,""exists"":true}},""ping"":{""status"":""UP""},""reportDb"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""validationQuery"":""isValid()""}}}}[tomcat@xbcutsrpt1 ~]$
{code}

xbid-lipb-amr1 deployed successfully:
{code:java}
[tomcat@xbcutsrpt1 ~]$ curl http://localhost:63391/actuator/health
{""status"":""UP"",""components"":{""diskSpace"":{""status"":""UP"",""details"":{""total"":6207111168,""free"":4838752256,""threshold"":10485760,""exists"":true}},""ping"":{""status"":""UP""},""reportDb"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""validationQuery"":""isValid()""}}}}[tomcat@xbcutsrpt1 ~]$
{code}

","21/Oct/20 23:18;hw120;Redeployed telegraf for amr and report-tool modules.

Redeploying of report-tool is needed to pick up the port change.","22/Oct/20 09:08;cs687;all the amr-apps are deployed and started properly. 
during ansible deployment we found out that ansible user can not use the java command properly.

https://jira.deutsche-boerse.com/browse/XP-4001
all of the details are described in the ticket above. We agreed with [~qo794] on it that we will close this ticket and solve the mentioned issues above with XB-4001. 

","22/Oct/20 09:13;cs687;ticket is done ",,,,,,,,,,,,,,,,,,,,,,
Perform performance testing,XP-3536,99664,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ei349,ei349,04/Sep/20 13:48,07/Oct/20 08:47,22/Feb/21 13:26,18/Sep/20 10:35,,,3.1.2,,,,,,,,,,,Perform performance testing of latest acceptance version of XBID against agreed SLAs,,ei349,od044,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3610,,,,,,,"18/Sep/20 12:48;od044;comparision.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87703/comparision.xlsx","10/Sep/20 17:15;od044;db-check.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87433/db-check.xlsx","15/Sep/20 10:53;od044;perf-2020-09-10-report.xls;https://jira.deutsche-boerse.com/secure/attachment/87565/perf-2020-09-10-report.xls","18/Sep/20 12:48;od044;performance-internal-report-20200918.xls;https://jira.deutsche-boerse.com/secure/attachment/87705/performance-internal-report-20200918.xls","10/Sep/20 17:19;od044;sc11-perf-rts3wave3-1-12092019-to-compare.xls;https://jira.deutsche-boerse.com/secure/attachment/87435/sc11-perf-rts3wave3-1-12092019-to-compare.xls","18/Sep/20 12:48;od044;sql-check-2020-09-18.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87704/sql-check-2020-09-18.xlsx","21/Sep/20 10:53;od044;xb_xbid_perf_cor-1_standard_ixe_0_2020-09-10.log.gz;https://jira.deutsche-boerse.com/secure/attachment/87741/xb_xbid_perf_cor-1_standard_ixe_0_2020-09-10.log.gz","21/Sep/20 10:53;od044;xb_xbid_perf_cor-1_standard_ixe_1_2020_09_10.log.tar.gz;https://jira.deutsche-boerse.com/secure/attachment/87740/xb_xbid_perf_cor-1_standard_ixe_1_2020_09_10.log.tar.gz",,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13219200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bi24:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/20 17:22;od044;Run on PERF env XBID 3.1.5, scenario xbid-rts3b-2019-sc11-v01_wave3_final.xlsx
- Red Hat Enterprise Linux Server release 7.5 (Maipo)      
- Rabbit MQ 3.7 
- Erlang 21.0      
- PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39), 64-bit

Comparision can be found in  [^comparision.xlsx]. It was compared again run from 2019-09-17 (here its report  [^sc11-perf-rts3wave3-1-12092019-to-compare.xls] )
Actual report:  [^perf-2020-09-10-internal-report.xls]   [^db-check.xlsx] 

Quick summary
API response time is better 
Order execution time is worse 
Orderbook computation time is better 
Rabbit MQ time is similar

All result is under SLA Threshold
","18/Sep/20 12:50;od044;New run on PERF
- the Order execution time is almost the same as previous run 

here is the actual comparison:  [^comparision.xlsx] 

Sql check:  [^sql-check-2020-09-18.xlsx] 
Report:  [^performance-internal-report-20200918.xls] ","22/Sep/20 11:00;od044;After more analysis we came up conclusion that the differences in Order execution time is not caused by DB upgrade (persister time are almost the same for all run).

I have also rerun the perf test on previous XBID version 2.0.25.2 and the Order execution time is still same. Thus we assume that the differences could be caused by specific environment where the run were performed. Because a run from last year was run o SIMU and  actual run was run on PERF.

Anyway, we have a plan to run another run on PERF on the latest RHEL and tomcat once PERF will be upgraded.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - apache availibility doesn't work properly,XP-3528,99613,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,03/Sep/20 14:03,06/Nov/20 09:08,22/Feb/21 13:26,04/Sep/20 16:12,,,3.1.2,,,,,,,,,,,When deploying to SIMU there was a problem with detecting that the apache was running. It checks HTTP status of a localhost's request. This concept might be wrong. Check port availability instead.,,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14860800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bhbs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) Update Ansible playbook to use the same name for SSL cert/key/chain for HAPROXY & APACHE on all XBID environments and instances,XP-3527,99600,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,iv732,iv732,03/Sep/20 11:07,02/Nov/20 12:57,22/Feb/21 13:26,05/Oct/20 10:23,,,3.1.2,,,,,,,,,,,"Currently we are using a single wildcard SSL Cert for all *haproxy* and *apache* instances in all environments.
 With the introduction of new ansible playbook, we now end up using different names for the SSL cert/key/chain in different environment/instances.
 In a shared hosts, like xbcutsweb1 under /shrd/ssl, we will have a bunch of files like this:
{code:java}
ctpa1_xbid_deutsche-boerse_com_cert.crt
ctpa1.xbid.deutsche-boerse.com_private.key
ctpb1_xbid_deutsche-boerse_com_cert.crt
ctpb1.xbid.deutsche-boerse.com_private.key
....
{code}
even though they are identical in content!

Further more, we have to store those in many different locations in Vault. 
 All of these can lead to the problem that maybe some of the locations are not updated whenever we get the new wildcard certificate.

So, my recommendation is that we should store that certificate stuff only in one single location in vault (currently secret/xb/xbid/common/cert). And all of them when being deployed will have the same name, such as: 
 xbid_cert.pem
 xbid_private.pem
 xbid_chain.pem

 

Clean also unnecessary vault secrets after finishing this task. ",,ek176,hw120,iv732,,,,,,,,,,,,,,,,,,XP-3583,,,,,,,,XP-3828,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12441600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 19 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3527-xbid-common-cert-haproxy,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Sep/20 15:03;ek176;Actually, the files are not really the same in the content:

{noformat}
xbcutsweb1 ssl]$ md5sum -- /shrd/ssl/* |cut -d"" "" -f1 |sort |uniq -c
      1 005497eb5262748180906537d35cb92e
      1 0339481682b209a44bfc6fa4d4e73056
      1 072069961ff005b4a9b0488d4d59dc44
      1 09e3756749c2c356dd74e01946a448ff
      1 0d8e2a87503c19130532898a6daba585
      1 0dedabfa5d1fd0e3d4cbcc62157468fe
      1 1385b2d13f209f74d18295d378301ce9
      1 154d3418ce6cc46db79851346991ed10
      1 188da78c148b6e411b497e726f64e84b
      1 1bf4c599bb97fd6453fdca9579480399
      1 1c3b697b810c017e203639aff25f4f67
      1 2c6ac7790d045f880f55681bd59f7076
      1 2dc35ee62412fe7464fe893a248fc898
      1 30ecc3fad4824e42bd69c37efeed9936
      1 3f3885f9938cf1d8a5eb1b0ab6757cc0
      1 43f4d4927289d8b20e771556733c2aaa
      1 44ad5b69a1bf19f7908f78ff9b9588b7
      1 46dabf6a9f6de0f882ba873f24b87694
      1 4bf5104a8cb8c32c80b21e76f43ef812
      1 528ddfb6b6299aac999d8ad41ae0886d
      1 575d7356840eaeed086131f3ecdf5ee6
      1 60e449c510428be77f64411f65666bda
      1 6345216a7abcd576412722befea65bbe
      1 643b30eb38cc0ba5ae2ed775b0f26d57
      1 72a4ccc2ee80b14c33429679124ed5b3
      1 732cb099c4b917197877a51805415a81
      1 73a1967e5e2e83cbc53ff9745fb0dbc1
      1 7b29414cf8ed94e13123de07b8030688
      1 80514e09d105d81debcfdfcc73f66f22
      1 8a275610d44089a961514fd7e3128830
      1 8b905434d1d4531764ca8df9ac6b70cd
      1 8e26efa593912f1fcd024f5aa6022670
      1 8f9a7180c6df8e8b6f7cf4adf36a5093
      1 914715ab58482f5729c8e7d59b637e4a
      1 93138e61a2ec8c6cfff72f7c458d0684
      1 95bb78f7a576e524f16892785ce290cc
      1 9d3dc5ae12f9ded2e2915db66c83b59f
      1 a1ce525762256c05635bf27b13113c25
      1 a20ecd066151424d55b85a26f9c77c45
      1 a4280bf5851ff835240cdeaa10526926
      1 a42e0b35d27024c3f9a74239a3e314c7
      1 a4d82ef8b1e6d4777eb8df9e288fd5ee
      1 aca08043963bd67b922473c8e029dfa7
      1 af6e9bb2ce6f5591593df173d1335c7b
      1 b297bc834adeaba953f1d0c4fdd042ff
      1 b975856fea4e6fea440e1e29084ef221
      1 bf2b0c6a4eae2ff22becd856cfad15a6
      1 c16ec9b635a75bc0b64dc44ff9149e1d
      1 c696a7692e16f2b8eaa50bd5ae241144
      1 d45e14a9369c5350177c20ce4dff4613
      1 d6caffce5df76165bf9b1af74037ecac
      1 d6f08917db00bb3268ad0bd20a7de993
      1 d990d8f4c5354a052213fd30f5545bc4
      1 e07795e393be975185984f2ac6c35f54
      1 e8c336d007760409282eef6797507c62
      1 f6075e30eac80233c48ee7c2a97f3678
      1 f74f3405fdd508c0223b2039fd4cc608
      1 fa111c73a5805fe51072c08dba9c87ba
      1 fc57bcc737971a2c3fc41e5322c53790
{noformat}
","18/Sep/20 15:17;iv732;Because they are still old certs with different CNs. We didn't clean them up. In the actual config, they are using just the same files xbid_private, xbid_cert.

And they were deployed with perl.","21/Sep/20 13:18;ek176;Hi [~iv732], 

I cannot locate the certificate files in the Vault path specified ({color:#0747a6}{{secret/xb/xbid/common/cert}}{color}):
{noformat}
MSG:

An unhandled exception occurred while running the lookup plugin 'hashi_vault'. Error was a <class 'ansible.errors.AnsibleError'>, original message: The secret secret/xb/xbid/common/cert doesn't seem to exist for hashi_vault lookup
fatal: [xb-xbid-syt1-cmi-web2]: FAILED! => {}{noformat}
The current Ansible taks is:
  
{noformat}
- name: Deploy certificate, chain and key
  copy:
    content: ""{{ lookup('hashi_vault', 'secret=secret/{{ product }}/{{ customer }}/common/cert:{{ item.key }} token={{ hashi_vault_token }} url={{ hashi_vault_addr }}') }}""
    dest: ""{{ item.value }}""
    mode: ""0640""
  loop: ""{{ lookup('dict', apache_ssl_files) }}""{noformat}
Can you please check the Ansible secret path or list the vault so I do not have to wild-guess (I have no access beyond secret/).
  

Thanks, m.

 ","21/Sep/20 14:10;hw120;{code:java}
vault list /secret/xb/xbid/common/cert
Keys
----
sectigo_chain.pem
sectigo_subCA.pem
trustedCAs.pem_CMM_PROD
trustedCAs.pem_SOB_PROD
trustedCAs.pem_TEST
usertrust_rootCA.pem
xbid_cert.cer
xbid_cert.pem
xbid_private.pem
xbid_request.csr
{code}","21/Sep/20 17:22;ek176;Hi [~iv732], 

can you please verify the permissions at the Vault for the [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy-ansible] Jenkins job?

 

I've added debug output for the value keys (to make sure they are the same as listed above), but still getting the same error: [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy-ansible/88/console]

 
{noformat}
MSG:

An unhandled exception occurred while running the lookup plugin 'hashi_vault'. Error was a <class 'ansible.errors.AnsibleError'>, original message: The secret /secret/xb/xbid/common/cert doesn't seem to exist for hashi_vault lookup
fatal: [xb-xbid-syt1-cmm-web2]: FAILED! => {}{noformat}
Thanks, m.

 

Note: I'm getting the same results for the vault path both with and without leading slash.","22/Sep/20 09:29;iv732;Added the following to the dev policy
{code:java}
path ""/secret/xb/xbid/common/cert*"" {
  capabilities = [""read""]
}

{code}","22/Sep/20 11:23;ek176;The correct path is: {{secret=secret/\{{ product }}/\{{ customer }}/common/cert/\{{ item.key }}:value}}","24/Sep/20 16:38;ek176;Hi [~iv732],

(regarding HA Proxy/trustedCAs.pem)

 

please check whether the following vault paths exist. These are currently present in Ansible HA Proxy role.
{noformat}
secret/xb/certs/test/trustedCAs.pem

secret/xb/certs/prod/{{ VAR }}/trustedCAs.pem 
         where VAR is in {extbe, intbe, cmm, sob, cha1, cha1}{noformat}
 

According to the {{inventory/xb/xbid/prod/haproxy/main.yml}} and the following ({{e.a.deployments/roles/xbhaproxy/defaults/main.yml}}) variable (see below), these should be available for Non-prod and prod environment:
{noformat}
haproxy_trusted_ca_vault_path: ""secret/{{ product }}/certs/{% if env == 'prod' %}prod/{{ instance.split('-')[0] }}{% else %}test{% endif %}/trustedCAs.pem""{noformat}
 

On the other hand, in the {{energy-mkt-shared/master/templates/haprox/*}}, there is only:
{noformat}
... ca-file @(BASEDIR)/vault/@(INSTANCENAME)/trustedCAs.pem{noformat}
Can you also please advise on the new vault path for these?

 

Thanks","30/Sep/20 12:51;ek176;Issue split into:
|XP-3828|(Split 1) Update Ansible playbook to use the same name for SSL cert/key/chain for HAPROXY & APACHE on all XBID environments and instances|
","30/Sep/20 13:59;iv732;{code:java}
vault list secret/xb/certs/test
Keys
----
trustedCAs.pem
trustedCAs.pem.old

{code}
{code:java}
 
vault list secret/xb/certs/prod 
Keys 
----
cmm/
sob/
trustedCAs.pem
{code}

","30/Sep/20 14:00;iv732;{code:java}
vault list secret/xb/certs/prod
Keys
----
cmm/
sob/
trustedCAs.pem

{code}
{code:java}
 
vault list secret/xb/certs/test 
Keys 
---- 
trustedCAs.pem 
trustedCAs.pem.old
{code}","30/Sep/20 14:57;iv732;[~ek176] I believe the following vault path is also ok, no need to change:

 
{code:java}
secret/xb/certs/test/trustedCAs.pem
secret/xb/certs/prod/{{ VAR }}/trustedCAs.pem 
         where VAR is in {extbe, intbe, cmm, sob, cha1, cha1}
{code}
However, for prod env, as I see we only differentiate between ""cmm"" and ""non-cmm"" trustedcas.pem. It looks a littel bit more clearly.",,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - add option to change alarmtilt endpoint,XP-3526,99597,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,03/Sep/20 09:50,30/Sep/20 11:37,22/Feb/21 13:26,03/Sep/20 13:07,,,3.1.2,,,,,,,,,,,"Customers' environments (except for PROD) use different endpont for alarmtilt calls {{https://v5-webservices.alarmtilt.net/atsrv-ejb/ws-res-v3/AlarmTILTRestrictedWebService}}.

Change it for them.",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14860800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bh8w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LDAP cert expiry,XP-3522,99553,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,tm431,tm431,02/Sep/20 10:49,30/Sep/20 11:37,22/Feb/21 13:26,11/Sep/20 13:50,,,3.1.2,,,,,,,,,,,"1.9.2020 11:45 from xbid_emergency slack channel message from Roman
{code:java}
Hi, just wanted to ask, do you pay attention to the xbdpldap1/2 certificate? It will expire in less than 3 weeks - If it's possible to replace it seamlessly, we should do it already. If not, I hope a short maintenance is already planned. And if everything is settled, sorry for the noise. {code}
from the communicatoin I think that restart is needed, so short maintenance window should be arranged BO vs. Customers bu I do not know which envs. are affected
|CN|Expiry|updated|
|xbdpldap1.deutsche-boerse.de|19/09/2020 00:00|29/06/2020 09:53|
|xbdpldap2.deutsche-boerse.de|19/09/2020 00:00|29/06/2020 09:53|",,ei349,iv732,localadmin,tm431,ub113,yn731,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/20 08:57;iv732;xbdpldap1_deutsche-boerse_de_cert.cer;https://jira.deutsche-boerse.com/secure/attachment/87470/xbdpldap1_deutsche-boerse_de_cert.cer","11/Sep/20 08:57;iv732;xbdpldap2_deutsche-boerse_de_cert.cer;https://jira.deutsche-boerse.com/secure/attachment/87471/xbdpldap2_deutsche-boerse_de_cert.cer",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14169600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdql:zzi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/20 11:04;yn731;Hi [~iv732]

Basically we need to know if it can be done seamlessly. 

I had a brief conversation with [~pd122] and he says that it should be possible as there are 2 LDAP servers. 
{quote}_[urban|https://app.slack.com/team/U71QM5VR7] [4:54 PM|https://dbg-devops.slack.com/archives/DLWK1TFU7/p1598972056015100]_

_ok, to increase the chance of success I think it would be wise to try to find out which of the 2 servers is actually being used by the app (depends on the config, can be verified in the logs) and then start with the other_
 _so if anything goes wrong (not that I would expect it), “hot” server is not affected_ _(edited)_ 
{quote}
So maybe it can be done without notifying the customer?

Description of affected envs. can be found here [https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Certificates+overview]","03/Sep/20 12:13;iv732;Cert requested. ITSR:  6B3177
[~sw455] can you approve the request asap? Thanks.","10/Sep/20 10:07;iv732;Cert recevied

Planning the replacement.[^xbdpldap1_deutsche-boerse_de_cert.cer]

^Private keys:  https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/xb/xbid/prod/cert/^","11/Sep/20 13:42;yn731;[~iv732]. Whenever you have more free time, it would be good to document this certificate replacement.

Also, can it be added to monitoring? ","11/Sep/20 13:50;iv732;Cert updated successfully.

Imported to vault:, so that it will be monitored [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/xb/xbid/prod/cert/]

Urban will consider the documentation as well as automation, because the current documentation doesn't seem to be clear.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) CUTE wildcard cert for ProfileServer,XP-3515,99544,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,02/Sep/20 09:36,04/Sep/20 13:32,22/Feb/21 13:26,02/Sep/20 09:36,,,3.1.1,,ComTrader,,,,,TechOps,,,,"***To be (ideally) executed before UAT deployments, Aug 05*

 

TBD:
 # [~iv732] Please discuss whether we still want to have shared infrastructure for the profile servers (for CUTEs/LIPs). 
 # [~iv732] Please create a request for relevant DNS records (independently) (/)
 # [~iv732] Please create request(s) for relevant firewall rules
 # [~iv732] Please prepare the PR (for wildcard certificate) ready and notify/coordinate next steps (/)
 # [~iv732] Please switch the endpoints to the new certificate
 # [~tm431] [~radeale] To negotiate and update/distribute new Connection Details
 # [~ek176] To execute and verify that CT works
 # [~ek176] To upgrade/release CT that checks cert's CN 

 

 ====

The current certificate for CUTEs' profile server is about to expire on *Monday, September 21, 2020 at 1:59:59 AM*

CN=[cute1.profiles.xbid.deutsche-boerse.com|http://cute1.profiles.xbid.deutsche-boerse.com/] 

 

There are two options, can be executed 1., then 2.:
 # Just change the certificate for the wildcard one. The _CN check_ is disabled, so there should be no issue.
 # (TechOps needed): Create correct DNS records, turn CN check on, update/release ComTrader.

[~iv732], [~yn731], [~tm431] FYI",,ek176,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14947200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b9uq:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Split 2) ComTrader, TestClient and Catrina Cert expiry",XP-3514,99505,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ab039,ek176,ek176,01/Sep/20 13:00,25/Nov/20 09:56,22/Feb/21 13:26,19/Nov/20 08:23,,,3.1.x,,ComTrader,,,,,,,,,"ComTrader, TestCLient and Catrina uses certificate that expires on Nov, 18 2020 12:49 CET

Filename: COMTRADER_AllNonProd_xbid-SOB.p12

Also, it is used to connect LTSs.

*Affected envs*: All

CT needs to be released.

Steps needed: 
 * techops to release new certificates
 * onboard those certificates into Comtrader
 * release new Comtrader versions (one for latest develop, one for 3.0.1 OCC files release on ind. cutes, lips, cutepx,cutetso)
 * see SERVICE-2129 how it was solved in the past
 * [~ub113], [~yn731]: inform customers as soon as possible about needed redeployment of all our Comtraders with updated cert. 
 * Discuss with [~iv732], [~hw120] if HA proxies are also needed
 * integrate those certificates into vault to prevent it's late expiration",,ab039,ek176,iv732,tm431,yn731,,,,,,,,,,,,,,,,,,,,,,,,XP-3968,,,,,,,SERVICE-8990,SERVICE-8526,XP-3782,SERVICE-8276,XP-3326,XBID-5236,XP-3558,"30/Sep/20 11:03;iv732;COMTRADER_AllNonProd_xbid-SOB.p12;https://jira.deutsche-boerse.com/secure/attachment/88065/COMTRADER_AllNonProd_xbid-SOB.p12","30/Sep/20 13:43;iv732;PMITEST_AllNonProd_xbid-CMM.p12;https://jira.deutsche-boerse.com/secure/attachment/88075/PMITEST_AllNonProd_xbid-CMM.p12","30/Sep/20 13:43;iv732;PMITEST_AllNonProd_xbid-SOB.p12;https://jira.deutsche-boerse.com/secure/attachment/88074/PMITEST_AllNonProd_xbid-SOB.p12",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8208000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0i:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,develop,XP-3514-update-certs-master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Sep/20 13:39;iv732;[~ei349] I haven't created the client cert so far. Not sure who normally did it.
[~yo218] [~ub113]: maybe you know who generated such client cert?","01/Sep/20 14:22;yo218;[~iv732] just use the jenkins job for it: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/Energy-Client-Certificates/]","07/Sep/20 16:23;ek176;Note, for CT:
{code:java}
xbid.comtrader$ find . -iname '*.p12' -exec md5sum \{\} \; |sort |grep -v target      
49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpa/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpb/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpc/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpd/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpe/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpf/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpg/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctph/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpi/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpj/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpk/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpl/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpm/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctso/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/cute/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/dst/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/lipa/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/lipb/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/performance/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/simu/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest1/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest2/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest3/COMTRADER_AllNonProd_xbid-SOB.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpa/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpb/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpc/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpd/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpe/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpf/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpg/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctph/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpi/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpj/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpk/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpl/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpm/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctso/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/cute/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/dst/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/lipa/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/lipb/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/performance/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/simu/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest1/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest2/certificate.p12

49450bf7f622a00df78a7c532ed2eee4  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest3/certificate.p12

ea2bf1905ac6b0120f32fd0f56f31103  ./comtrader-custom/src/main/conf/XSOBv1/envs/prod/COMTRADER_AllNonProd_xbid-SOB.p12

ea2bf1905ac6b0120f32fd0f56f31103  ./comtrader-custom/src/main/resources/ssl/XSOBv1/production/certificate.p12



{code}","07/Sep/20 16:24;ek176;Note for CT: 
{code:java}
$ find . -iname '*.jks' -exec md5sum \{\} \; |sort |grep -v target                  
785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest1/cacerts.jks

785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest2/cacerts.jks

785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/conf/XSOBv1/envs/systemtest3/cacerts.jks

785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest1/cacerts.jks.jks

785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest2/cacerts.jks.jks

785420503ae734584e9bf7eee5ac3b5d  ./comtrader-custom/src/main/resources/ssl/XSOBv1/systemtest3/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpa/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpb/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpc/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpd/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpe/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpf/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpg/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctph/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpi/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpj/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpk/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpl/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctpm/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/ctso/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/cute/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/dst/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/lipa/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/lipb/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/performance/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/prod/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/conf/XSOBv1/envs/simu/cacerts.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpa/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpb/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpc/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpd/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpe/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpf/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpg/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctph/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpi/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpj/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpk/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpl/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctpm/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/ctso/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/cute/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/dst/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/lipa/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/lipb/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/performance/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/production/cacerts.jks.jks

a030fe66b4060158786d4b621ba64876  ./comtrader-custom/src/main/resources/ssl/XSOBv1/simu/cacerts.jks.jks



{code}","09/Sep/20 15:15;tm431;Do not forgot to check also *PMITEST_AllNonProd_xbid-SOB.p12 PMITEST_AllNonProd_xbid-CMM.p12*  see SERVICE-2129 

 ","10/Sep/20 09:55;yn731;Notification to customer draft:
----
_Dear All,_

_Please, be informed that the below certificates are expiring on 18/11/2020:_ 
 * _COMTRADER_AllNonProd_xbid-SOB.p12_
 * _PMITEST_AllNonProd_xbid-SOB.p12;_
 * _PMITEST_AllNonProd_xbid-CMM.p12_

_This will affect all testing environments SIMU, LIPA, LIPB, CTSO, CUTEPX, CTPA->CTPM._ 

_New certificates will be issued by DBAG and provided to the parties here in this ticket (So all LTSs can be amended). Afterward, DBAG will need to upload these certificates into all test environments. This task will require downtime for such environments._

_To perform the certificate renewal, DBAG will need a total of 2 days:_
 # _The first day to perform the certificate upload._
 # _A second day for contingency, for all test environments._

_Also, a new version of Comtrader needs to be released and deployed._

_Please, align internally and revert to us with a date when this can be done. DBAG needs at least 14 days to prepare all the necessary actions._

_Do not hesitate to contact us if you have any questions._

_Kind regards,_

_DBAG._","24/Sep/20 15:57;tm431;[~iv732] whenever you have time, please start with preparation of the new certificates","30/Sep/20 11:03;iv732;[~tm431]  [~ek176]

The new cert is attached here.

[^COMTRADER_AllNonProd_xbid-SOB.p12]

Password:  j9ZgLMCQ

 

Imported to vault to monitor:

 

https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/xb/xbid/common/cert/COMTRADER_AllNonProd_xbid-SOB.pem","30/Sep/20 13:24;tm431;we will also need 
PMITEST_AllNonProd_xbid-SOB.p12;
PMITEST_AllNonProd_xbid-CMM.p12
(they are in here SERVICE-2129 )

as I think they are expiring as well","30/Sep/20 13:25;tm431;Then for DEVs, please release new version of CT, uploud this new cert into some SYT and test the connection via CT, Testclient and Catrina testclient","30/Sep/20 13:44;iv732;[~tm431]

The other 2 are attached here as well:

 

[^PMITEST_AllNonProd_xbid-SOB.p12]

Password:    Y7DD+8yP

 

[^PMITEST_AllNonProd_xbid-CMM.p12]

^Password:    EPaJN27A^

 

^also added the public cert to vault^","07/Oct/20 15:05;ek176;All files are signed by ""DBG CLIENT CA XBID TEST"" authority. Not affected by CA change XP-3782.

 
||File||Signed by||
|COMTRADER_AllNonProd_xbid-SOB.p12 |Certificate[1]: 
Owner: CN=COMTRADER_AllNonProd_xbid-SOB, OU=XBID-TEST 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE
 
Certificate[2]: 
Owner: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE|
|PMITEST_AllNonProd_xbid-CMM.p12|Certificate[1]: 
Owner: CN=PMITEST_AllNonProd_xbid-CMM, OU=XBID-TEST 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE
 
Certificate[2]: 
Owner: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE|
|PMITEST_AllNonProd_xbid-SOB.p12|Certificate[1]: 
Owner: CN=PMITEST_AllNonProd_xbid-SOB, OU=XBID-TEST 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE
 
Certificate[2]: 
Owner: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE 
Issuer: CN=DBG CLIENT CA XBID TEST, O=Deutsche BÃ¶rse Group, L=Eschborn, C=DE|","09/Oct/20 14:10;ek176;ComTrader: Updated for all envs except PROD. Connected via CT to SYT1, SYT2, connected via TC to SYT1.

New state (MD5):

 
{noformat}
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpa/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpb/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpc/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpd/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpe/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpf/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpg/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctph/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpi/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpj/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpk/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpl/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctpm/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/ctso/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/cute/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/dst/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/lipa/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/lipb/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/performance/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/simu/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/systemtest1/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/systemtest2/COMTRADER_AllNonProd_xbid-SOB.p12
7edf733e7c919e3601a8fcd335056c78  ./XSOBv1/envs/systemtest3/COMTRADER_AllNonProd_xbid-SOB.p12
ea2bf1905ac6b0120f32fd0f56f31103  ./XSOBv1/envs/prod/COMTRADER_AllNonProd_xbid-SOB.p12{noformat}
Old state (shortened):
{noformat}
49450bf7f622a00df78a7c532ed2eee4  ./XSOBv1/envs/*/COMTRADER_AllNonProd_xbid-SOB.p12
ea2bf1905ac6b0120f32fd0f56f31103  ./XSOBv1/envs/prod/COMTRADER_AllNonProd_xbid-SOB.p12
{noformat}
 ","09/Oct/20 17:53;ek176;ComTrader's Profile Storage Settings (to be released as 3.2.1 or later) overview (CSV): https://github.deutsche-boerse.de/ek176/shared/tree/master/utils/comtrader-ctp-overview","12/Oct/20 08:57;tm431;[~ek176] as discussed today please prepare two version of CT which will include new CERT.

One version for R2.X based on CT version 2.5.1.58
 One version for R3.1 based on CT version 3.1.1

we will deploy these versions on cca 27-29/10/2020 so till that time ideally test it on SYTx envs

 ","14/Oct/20 08:12;tm431;here is the overview, which version should be deployed where (on 27-28/10/2020)

LIPB,CTPA,CTPC,CTPD,CTPE,CTPG,CTPI,CTPJ,CTPK,CTPL -> R3.1 based on CT version 3.1.1


CUTE,CTSO,LIPA,CTPB,CTPF,CTPH,CTPM ->  R2.X based on CT version 2.5.1.58 ","14/Oct/20 12:33;ek176;Issue split into:
|XP-3968|(Split 1) ComTrader, TestClient and Catrina Cert expiry|
","21/Oct/20 12:40;ek176;CT 2.5.1.61 released [https://m7trading-test.deutsche-boerse.com/xbid-ctpb/comtrader-webstart-2.5.1.61-xbid-ctpb/index.html] and connected to DBAGSOBR@CTP-B (/)

(Note: profile storage links were left untouched = not updated)

—

CT 3.1.2 released [https://m7trading-test.deutsche-boerse.com/xbid-lipb/comtrader-webstart-3.1.2-xbid-lipb/index.html] and connected to DBAGSOBR@LIP-B (/)

(Note: profile storage uses new links already)

—

The next step is to deploy it for all the envs as time comes (after XP-3458 / XP-3955 is done and upon CUTE deployment)","23/Oct/20 10:38;ek176;The CT versions (before SERVICE-8133) on 2020-09-21:

Note: Two versions for CTP-A 
{noformat}
Env        CT_ver    SSL     HTTP      JNLP_size  last_updated
xbid-ctpa  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 13:32
xbid-ctpa  2.5.1.52  SSL_OK  HTTP_200  4838       2019-06-12 08:31
xbid-ctpb  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 15:20
xbid-ctpc  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 08:15
xbid-ctpd  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 08:33
xbid-ctpe  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 08:37
xbid-ctpf  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 10:29
xbid-ctpg  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 10:33
xbid-ctph  2.5.1.66  SSL_OK  HTTP_200  5137       2020-07-29 13:53
xbid-ctpi  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 12:42
xbid-ctpj  2.5.1.68  SSL_OK  HTTP_200  5137       2020-07-30 15:51
xbid-ctpk  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-28 12:14
xbid-ctpl  2.5.1.68  SSL_OK  HTTP_200  5137       2020-07-30 16:07
xbid-ctpm  2.5.1.60  SSL_OK  HTTP_200  5032       2020-03-20 13:25
xbid-ctso  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 16:01
xbid-cute  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 15:56
xbid-lipa  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 16:22
xbid-lipb  2.5.1.58  SSL_OK  HTTP_200  4930       2020-01-27 16:26
xbid-simu  3.1.0     SSL_OK  HTTP_200  5169       2020-08-05 08:48 
{noformat}
After SERVICE-8133 and the DNS switch of the [https://m7trading-test.deutsche-boerse.com,|https://m7trading-test.deutsche-boerse.com%2C/] the state is the following (2020-10-23):
{noformat}
Env        CT_ver    SSL     HTTP      JNLP_size  last_updated
xbid-ctpa  3.1.1     SSL_OK  HTTP_200  4983        2020-10-21 16:01
xbid-ctpb  2.5.1.58  SSL_OK  HTTP_200  4965        2020-10-23 07:04
xbid-ctpc  3.1.1     SSL_OK  HTTP_200  4983        2020-10-20 15:45
xbid-ctpd  3.1.1     SSL_OK  HTTP_200  4983        2020-10-20 15:51
xbid-ctpe  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:00
xbid-ctpf  2.5.1.58  SSL_OK  HTTP_200  4930        2020-01-28 10:29
xbid-ctpg  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:07
xbid-ctph  2.5.1.66  SSL_OK  HTTP_200  5137        2020-07-29 13:53
xbid-ctpi  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:12
xbid-ctpj  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:13
xbid-ctpk  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:13
xbid-ctpl  3.1.1     SSL_OK  HTTP_200  4983        2020-10-22 14:13
xbid-ctpm  2.5.1.60  SSL_OK  HTTP_200  5032        2020-03-20 13:25
xbid-ctso  2.5.1.58  SSL_OK  HTTP_200  4930        2020-01-27 16:01
xbid-cute  2.5.1.58  SSL_OK  HTTP_200  4930        2020-01-27 15:56
xbid-lipa  2.5.1.58  SSL_OK  HTTP_200  4930        2020-01-27 16:22
xbid-lipb  2.5.1.58  SSL_OK  HTTP_200  4965        2020-10-23 06:59
xbid-simu  3.1.0     SSL_OK  HTTP_200  5169        2020-08-05 08:48

{noformat}
This should be correct state before next deployment to CUTEs/SIMU end of Oct.

Note: LIP-A/B, CUTES-A,B did have incorrect version due to testing XP-3514 and XP-3458, this was fixed.

Note: After DNS switch, the 3.1.1 versions were not available, were also re-deployed. ","26/Oct/20 10:35;ek176;The certs have been updated in the relevant repos. 

 

Command (commented for clarity): 
{noformat}
 find . -iname '*.p12' -exec md5sum \{\} \; |grep 
    -e 49450bf7f622a00df78a7c532ed2eee4 # COMTRADER old SOB
    -e 3092b4cc324fbc0cb8d8d01e3d3055e1 # PMITEST old CMM
    -e 13474e2d61aa744c0e8b7e456ccbb2c6 # PMITEST old SOB
    -e ea2bf1905ac6b0120f32fd0f56f31103 # COMTRADER oldest
    -e 42ab0248f6919ff07f4ce28445a86b51 # COMTRADER veryold 
    |grep -v 'm7.comtrader/comtrader-custom' # now using xbid.comtrader{noformat}
 

Certs:

*PMITEST_AllNonProd_xbid-SOB.p12*
{noformat}
energy-mkt-shared/templates/lts/cor/xbid_all_cute_pmi-sob.p12 (master){noformat}
*PMITEST_AllNonProd_xbid-CMM.p12*: No usage found (neither password usage)

 

*COMTRADER_AllNonProd_xbid-SOB.p12*
{noformat}
(both xbid-dev-env and master branches)
energy-mkt-shared/templates/lts/cor/COMTRADER_AllNonProd_xbid-SOB.p12
energy-mkt-shared/templates/lts/cor/xbid_all_cute_comtrader-sob.p12
energy-mkt-shared/templates/standalone/pmi-logger/AllNonProdXbidSOB.p12
---
m7.pmi-logger/src/main/resources/AllNonProdXbidSOB.p12
---
m7.test-client/test-scenario-creator/src/main/resources/ssl/AllNonProdXbidSOB.p12
m7.test-client/test-scenario-runner/src/main/resources/ssl/AllNonProdXbidSOB.p12
{noformat}","26/Oct/20 12:05;ek176;ComTrader: PROD certificate is currently outdated and the password has been invalidated (last updated 2017-05-19) in  [l96033f0|https://github.deutsche-boerse.de/dev/xbid.comtrader/commit/96033f0a918bc7373d303f7f9e27dad1b004723a], However the cert is actually ignored. The customer has to provide it's own (personalized) cert.

 For the sake of completeness:
{noformat}
xbid.comtrader/comtrader-custom/src/main/conf/XSOBv1/envs/prod$ keytool -list -keystore COMTRADER_AllNonProd_xbid-SOB.p12 -v

Enter keystore password:   ********

Your keystore contains 1 entry
Entry type: PrivateKeyEntry
Certificate chain length: 2

Certificate[1]:
Owner: CN=COMTRADER, OU=AllNonProd, OU=SOB, OU=XBID, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=Gruppe Deutsche Boerse CA, OU=PKI Entity, O=Exchange, C=DE
Serial number: 13bce
Valid from: Mon Nov 23 14:45:18 CET 2015 until: Fri Nov 23 14:45:18 CET 2018
  CA:false

Certificate[2]:
Owner: CN=Gruppe Deutsche Boerse CA, OU=PKI Entity, O=Exchange, C=DE
Issuer: CN=Gruppe Deutsche Boerse CA, OU=PKI Entity, O=Exchange, C=DE
Serial number: 1
Valid from: Mon Dec 20 10:30:55 CET 2004 until: Fri Dec 20 10:29:37 CET 2024
  CA:true

{noformat}
 ","09/Nov/20 14:37;ek176;Cleaning performed:
 * *TestClient*: Contained outdated passwords (invalidated in [71c0d4d|https://github.deutsche-boerse.de/dev/m7.test-client/pull/131/commits/71c0d4d90fdab2806e324477b24bf42c3c91bfc2]), outdated certs (updated in [b200a08|https://github.deutsche-boerse.de/dev/m7.test-client/pull/131/commits/b200a08383d3dd7dd1f5767e900f53c2d67ad6e2])
 * *Energy-mkt-shared*-master: Updated PMITest and Comtrader SOB certs ([PR|https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/736/files])
 * *Energy-mkt-shared*-xbid-dev-env: Updated certs ([6c7165e|https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/735/commits/6c7165e0998f2c8b74e74d1239094bf278451d46])
 * *PMI-logger*: Updated certificate ([PR|https://github.deutsche-boerse.de/dev/m7.pmi-logger/pull/83]). Note, the cert is not used effectively.
 * *ComTrader*: Prod version is shipped with expired cert and invalid password (see [README PR|https://github.deutsche-boerse.de/dev/xbid.comtrader/pull/33/files])
","19/Nov/20 08:23;ab039;All non-prod CTs have been released.",,,,,,,,,,,,,,,
(Split 2) Prepare new consul enterprise test cluster - deployment on internal test env and migration of M7 test patroni,XP-3513,99480,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,01/Sep/20 09:56,08/Dec/20 12:54,22/Feb/21 13:26,03/Dec/20 22:51,,,,,,,,,,Consul,TechOps,,,"We had network structure change in the meantime, so we have new VMs to migrate to.
 * Deploy consul cluster to new VMs
 * Create FW requests for xbid and m7 test database servers
 * Migrate patroni internal test syt1 and syt3 clusters to new consul cluster
 * Involve 7tops - Steffen for shadowing, to share the knowledge between products

 

As consulted with Cybertec:
 {color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
 So the process would be:
 # Pause cluster to disable automatic failover and dependency on consul cluster, patronictl pause
 # Deploy new consul client
 # Change config and reload patroni service on ALL cluster members.
 # Verify using patronictl list that all members have registered themselves in the new consul
 # patronictl resume
 # Check if patroni and consul have clean logs

 

All steps described here...

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/consul_instance/README.md#new-cluster-deployment---example-for-energy-shrd-test]

We had to do this clean up before we started

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/consul_instance/README.md#cleanup-tasks-in-the-case-when-you-have-to-do-clean-redeploy-of-consul-on-already-deployed-serversclients]

Also, we had to
 * update static routes on bond interfaces, with help from Andrei
 * change default gateway to second/new network
 * update ansible inventory to remove old consul server hosts
 * update ansible inventory to include new renamed hosts
 * do the deployment of consul while the first bond to the old network was down

 ",,ei349,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-7209,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6912000,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i000000000000000hs",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,HOT Sprint 18 (S),HOT Sprint 19,HOT Sprint 20 (S),Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Sep/20 12:48;hw120;Deployment scheduled on Monday 7.9. at 11-12, had to wait for Steffen to be able to see it.","08/Sep/20 10:38;hw120;Went through deployment on aws test env with Steffen, also checked and prepared FWs with him.

Waiting for FW implementation.

We have a problem with network classification of xbid test, it is classified as SIMULATION so we can't connect it to the consul test cluster.

We would have to connect xbid test databases to consul simu, problem is with dbr test hosts are in datalake network which are classied as DEVELOPMENT.

To work around it we would have to move existing or create new test dbr to simu datalake network.","24/Nov/20 13:35;ei349;Removing it now from the Ops sprint backlog. [~hw120]  please contact [~ei349] when this needs to be prioritized to the sprint. ","03/Dec/20 21:47;hw120;New consul test cluster was deployed 26.11. together with migration of m7 test patroni clusters on m7testpdb1/2 servers.

In the process we discovered patroni bug we had to solve together with Cybertec support, thanks to Julian Markwort. Documented here

[https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Troubleshooting+Patroni#TroubleshootingPatroni-Issue:Deletedconsuldataandrestartedpatroniservices]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create custom haproxy Ansible role,XP-3511,99442,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ek176,ek176,31/Aug/20 15:08,30/Sep/20 11:37,22/Feb/21 13:26,09/Sep/20 16:24,,,3.1.2,,,,,,,PenetrationTest,,,,"To be solved after UATs 2020-09

 

Current state: The haproxy role is shared with M7. 

Reason:
 * Within XP-2503 the TLS config for HA proxy was changed, differing from M7's config
 * The default value should be the secure, the insecure should be as exception (as done within XP-2503 for Apache TLS config)

AC: 
 * xb_haproxy role created (might wrap the original one) with default (secure) config: https://jira.deutsche-boerse.com/browse/XP-2503?focusedCommentId=286265&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-286265
 * TODO: Decide whether it can be changed/planned for PROD (based on UAT's result)

 

 ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdql:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,XP-3554-rabbitmq-restart,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add more disks and extend space on influxdb aws instances,XP-3510,99420,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,31/Aug/20 12:26,01/Sep/20 12:18,22/Feb/21 13:26,31/Aug/20 12:26,,,3.1.1,,,,,,,Monitoring,TechOps,,,"We are running out of space on our time-series database behind out monitoring soultiion - influxdb.

 - In AWS account dbg-product-sz I have to attach new disks to instances

500gb disks to both ec2-energy-svc-influxdb-data-node instances

200gb disks to all three ec2-energy-svc-influxdb-meta-node instances

 - extend volume group, lvm and resize filesystem

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Done.,,,,,,,,,,,,,,15120000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bg7s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
goferd service eating up memory on many servers,XP-3503,99374,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,hw120,hw120,27/Aug/20 23:18,27/Sep/20 15:26,22/Feb/21 13:26,31/Aug/20 10:43,,,3.1.1,,,,,,,TechOps,,,,"It is affecting randomly servers from internal tests to production.

It seems it is a component - agent? of red hat satellite server.

Already many servers are starting to fill up even swap file.

We should either solve the problem or stop this service on all servers.

I will create another ticket to syseng to investigate the issue.

 

Service is logging that it can't contact englobsat1 server on port 5647.

I tried with telnet and it can't be accessed.
{quote}telnet englobsat1.deutsche-boerse.de 5647
{quote}
Maybe network/fw issue or service is reaching its limits.

 

It seems it is known that goferd has memory leak issues in certain situations.

[https://access.redhat.com/solutions/4886141]",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-30,SYSENGEXT-146,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bfxs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Aug/20 00:58;hw120;After consultation with SYSENG on-call service and Lambert, we decided to stop this service on all energy servers.
{code:java}
# Executed from [enprodauto1 {master L | +1} ~/git/energy.automation.deployments]$

ansible all -m shell -a ""systemctl stop goferd"" -b --limit 'xb*:!*-*' --ask-become-pass
ansible all -m shell -a ""systemctl stop goferd"" -b --limit 'm7*:!*-*' --ask-become-pass
ansible all -m shell -a ""systemctl stop goferd"" -b --limit 'en*:!*-*' --ask-become-pass
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible full deployment job fails with error Method code too large!,XP-3499,99353,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eg288,eg288,27/Aug/20 12:20,01/Sep/20 14:43,22/Feb/21 13:26,31/Aug/20 10:52,,,3.1.1,,,,,,,,,,,"Jenkins job xbid-full-ansible-deploy is configured with pipilene energy.automation.deployments/jenkins/selfservice/Jenkinsfile_deploy_xbid_full

The error after execution:
{code}
Running in Durability level: MAX_SURVIVABILITY
org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:
General error during class generation: Method code too large!java.lang.RuntimeException: Method code too large!
	at groovyjarjarasm.asm.MethodWriter.a(Unknown Source)
	at groovyjarjarasm.asm.ClassWriter.toByteArray(Unknown Source)
	at org.codehaus.groovy.control.CompilationUnit$17.call(CompilationUnit.java:827)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1065)
	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:603)
	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:581)
	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:558)
	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:298)
	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:268)
	at groovy.lang.GroovyShell.parseClass(GroovyShell.java:688)
	at groovy.lang.GroovyShell.parse(GroovyShell.java:700)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.doParse(CpsGroovyShell.java:142)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.reparse(CpsGroovyShell.java:127)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.parseScript(CpsFlowExecution.java:561)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.start(CpsFlowExecution.java:522)
	at org.jenkinsci.plugins.workflow.job.WorkflowRun.run(WorkflowRun.java:331)
	at hudson.model.ResourceController.execute(ResourceController.java:97)
	at hudson.model.Executor.run(Executor.java:428)1 error	at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:310)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1085)
{code}",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15465600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,27/Aug/20 12:20,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bfsk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update pgwatch monitoring to work with postgres 12,XP-3471,99257,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,25/Aug/20 23:28,29/Sep/20 14:22,22/Feb/21 13:26,25/Aug/20 23:57,,,3.1.1,,,,,,,TechOps,,,,"Fix password auth for user pgwatch2:

 - update deployment to be able to alter postgres pgwatch2 user role password in case it already exists or is different
{quote}alter role pgwatch2 with password 'XXXX';
{quote}
 - deploy on already upgraded postgres 12 instances syt1, syt2 and syt3",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15552000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bf8o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,N/A,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jenkins deployment job - fails for single sided envs with error cor2 cannot be found,XP-3467,99228,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,25/Aug/20 10:27,01/Sep/20 12:18,22/Feb/21 13:26,27/Aug/20 11:13,,,3.1.1,,,,,,,,,,,"jenkins deployment job xbid-full-ansible-deploy fails for single sided envs with error:
{code}
[core] + ansible-playbook playbooks/deploy_xbcor.yml --limit xb-xbid-dst1-cor2 --inventory xb/xbid/dst1 --tags start --diff -e app_version=3.1.2
[core] [WARNING]: Could not match supplied host pattern, ignoring: xb-xbid-dst1-cor2
         ERROR! Specified hosts and/or --limit does not match any hosts
{code}",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15552000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,25/Aug/20 10:27,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bf2o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Aug/20 12:18;eg288;The parameter --limit has been modified when executing deploy_xbcor.yml playbook. The parameter now exludes cor1 instead of explicitly asking for cor2.
{code:java}
+ ansible-playbook playbooks/deploy_xbcor.yml --limit '!*cor1' --inventory xb/xbid/dst1 --tags start --diff -e app_version=3.1.2 

PLAY [Deploy XBID core] ******************************************************** 
skipping: no hosts matched 

PLAY RECAP *********************************************************************
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename pg_watch2 to pgwatch2,XP-3466,99220,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,yo218,yo218,25/Aug/20 07:38,31/Aug/20 15:38,22/Feb/21 13:26,25/Aug/20 22:59,,,3.1.1,,,,,,,TechOps,,,,"The monitoring role has to be renamed as postgres upgrade is not working when there are role names starting with pg_

Upgrade the deployment role and use the new name on all environments",,hw120,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15552000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bf0w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/20 22:59;hw120;Already done for when updated monitoring for M7 and postgres 11 migration

https://jira.deutsche-boerse.com/browse/TECHLOG-3241

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade Docker container to PostgresSQL12,XP-3461,99215,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,yo218,yo218,25/Aug/20 07:24,21/Dec/20 15:09,22/Feb/21 13:26,06/Nov/20 15:42,,,3.2.x,,,,,,,,,,,All docker images which are used for tests have to use the latest PosgreSQL database (version 12.4),,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9676800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0btja:5",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-1261-owasp-fix,acceptance,XP-4526-resource-managment-fix,XP-4076,develop,master,XP-2311,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Nov/20 10:22;qo794;Docker image upgraded in the following projects:
* xbid-test
* xbid
* am-reporting
* report-tool
* acer-reporting
* shipping
* ams
* custom-docker-images - patroni upgraded to 1.6.0 as well",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade internal environments to PostgreSQL 12,XP-3460,99214,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,25/Aug/20 07:21,01/Sep/20 12:18,22/Feb/21 13:26,28/Aug/20 12:08,,,3.1.1,,,,,,,,,,,"Similar to XP-2979, the remaining internal environments have to be updated

Syt2 (/)
 Syt3 (sync+async) (/)
 DST (/)
 Shared Internal (/)
 Shared Internal EDB (/)
 Syt1 SLA (/)
 Performance (/)
 Performance EDB (/)
 Performance SLA(/)",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bezk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Aug/20 12:08;yo218;All internal environments have been upgraded",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Adapt deployment script to the new server,XP-3458,99204,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,24/Aug/20 16:07,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 10:44,,,3.1.2,,,,,,,,,,,"When XP-3457 is finished, please prepare/update deployment Jenkins script to deploy it to setup download server. 

Align with [~qo288] and [~dp007] about how deployment works on other products. 

Design should remain the same as current state. 

 

[~cv179]'s latest update from XP-3457: 

New buckets are created and temporary URLs are available already.

S3 buckets are created (temporary fallback home for current websites):
 * s3-dbg-m7-customer-portal-fbprod
 * s3-dbg-m7-customer-portal-fbsimu
 * s3-dbg-m7-customer-portal-fbtest (not yet - internal account discussion)

 

example 1: xbid prod new home (domain will eventually switch):
 [https://m7trading.energy.prod.deutsche-boerse.cloud/xbid-prod/]
 example 2: xbid ctpa
 [https://m7trading-test.energy.prod.deutsche-boerse.cloud/xbid-ctpa/]

 

Once all content is migrated and available, we will switch the current m7trading domains on it.",,ei349,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3955,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15638400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3456,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bo26:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Find a new hosting,XP-3457,99203,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cv179,ei349,ei349,24/Aug/20 16:06,02/Nov/20 13:06,22/Feb/21 13:26,26/Oct/20 08:16,,,3.1.3,,,,,,,TechOps,,,,"After [~cv179] finishes preparation on S3 bucket serverless solution. Please align with [~ll664] and [~dp007] about furher steps. 

 

Please be aware that deadline for complete migration is set to September EOM. 

 

[~cv179]: please  update the in the ocmment about new URLs and solution details when finished. ",,cv179,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10281600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3456,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c0jc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/20 08:44;cv179;New buckets are created and temporary URLs are available already.

S3 buckets are created (temporary fallback home for current websites):
 * s3-dbg-m7-customer-portal-fbprod
 * s3-dbg-m7-customer-portal-fbsimu
 * s3-dbg-m7-customer-portal-fbtest (not yet - internal account discussion)

 

example 1: xbid prod new home (domain will eventually switch):
[https://m7trading.energy.prod.deutsche-boerse.cloud/xbid-prod/]
example 2: xbid ctpa
[https://m7trading-test.energy.prod.deutsche-boerse.cloud/xbid-ctpa/]

 

Once all content is migrated and available, we will switch the current m7trading domains on it.

 

 ","26/Oct/20 08:15;cv179;All the S3 buckets are in place and onboarded to the pipelines if I understood it right.

For fbtest we sticked to the external availability. Additional protection, if needed, could be achieved by authentication headers (user/password).

The internaltest domain is for example [https://xbid-ct-internal.energy.prod.deutsche-boerse.cloud/xbid-systemtest1/]

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jenkins ansible deployment job - no dataset info to SMC and CMI modules,XP-3455,99194,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,eg288,eg288,24/Aug/20 14:08,02/Sep/20 11:49,22/Feb/21 13:26,02/Sep/20 10:43,,,3.1.1,,,,,,,,,,,"jenkins ansible deployment job passes dataset info only to CORE module and it ignores SMC and CMI modules

the jenkins job is defined as pipeline:

energy.automation.deployments/jenkins/selfservice/Jenkinsfile_deploy_xbid_full",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14947200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,24/Aug/20 14:08,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bev4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Sep/20 10:43;od044;Test passed on SYT1 
- deployment job deployed dataset correctly ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) ComTrader cannot connect to SYT1,XP-3454,99193,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,od044,od044,24/Aug/20 14:02,03/Feb/21 11:04,22/Feb/21 13:26,03/Feb/21 11:04,,,3.1.x,,,,,,,,,,,"Update: TestClient works. ComTrader cannot connect.

 

-Test client cannot connect to SYT1. It looks like an issue with key store. Most probably HA Proxy.-

Here is error log:
{code:java}
13:47:49.622 INFO  c.d.g.m.v.M7ExchangeConnection - Sending login request for user 'XBEPEXX1' to host '10.136.14.19', port '50700', vhost 'ext'.
13:47:49.636 INFO  g.logger.message - S,1598269669636,0,<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><LoginReq xmlns=""http://www.deutsche-boerse.com/m7/v1"" user=""XBEPEXX1"" force=""false"" disconnectAction=""NO""><StandardHeader marketId=""XSOB""/></LoginReq>
13:47:49.693 ERROR c.d.g.a.AmqpConnectionManager - Handle IOException ...
javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:154)
	at sun.security.ssl.SSLSocketImpl.recvAlert(SSLSocketImpl.java:2020)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1127)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)
	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:750)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:129)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:134)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:277)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:49.693 ERROR c.d.g.a.AmqpBackend - error sending request
javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:154)
	at sun.security.ssl.SSLSocketImpl.recvAlert(SSLSocketImpl.java:2020)
	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1127)
	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1367)
	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:750)
	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:129)
	at com.rabbitmq.client.impl.SocketFrameHandler.sendHeader(SocketFrameHandler.java:134)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:277)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:49.698 INFO  c.d.g.m.v.M7ExchangeConnection - Login message response 'null'
13:47:49.698 ERROR c.d.g.m.v.M7ExchangeConnection - Login unsuccessful. Response: 'null'
13:47:49.775 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:313)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13:47:53.838 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.security.KeyStoreException: Uninitialized keystore
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: java.lang.RuntimeException: java.security.KeyStoreException: Uninitialized keystore
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.createSslContext(AmqpConnectionFactory.java:85)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.<init>(AmqpConnectionFactory.java:37)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.connect(AmqpBackend.java:155)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.initAmqpBackend(M7ExchangeConnection.java:1325)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.connect(M7ExchangeConnection.java:261)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.connect(DefaultBackendConnectionGateway.java:146)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:239)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.security.KeyStoreException: Uninitialized keystore
	at java.security.KeyStore.aliases(KeyStore.java:1233)
	at sun.security.ssl.SunX509KeyManagerImpl.<init>(SunX509KeyManagerImpl.java:127)
	at sun.security.ssl.KeyManagerFactoryImpl$SunX509.engineInit(KeyManagerFactoryImpl.java:70)
	at javax.net.ssl.KeyManagerFactory.init(KeyManagerFactory.java:256)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionFactory.createSslContext(AmqpConnectionFactory.java:72)
	... 14 common frames omitted
13:47:58.064 INFO  c.d.g.m.v.M7ExchangeConnection - Sending login request for user 'XBEPEXX1' to host '10.136.14.19', port '50700', vhost 'ext'.
13:47:58.064 INFO  g.logger.message - S,1598269678064,0,<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><LoginReq xmlns=""http://www.deutsche-boerse.com/m7/v1"" user=""XBEPEXX1"" force=""false"" disconnectAction=""NO""><StandardHeader marketId=""XSOB""/></LoginReq>
13:47:58.127 ERROR c.d.g.a.AmqpConnectionManager - Handle IOException ...
java.io.IOException: null
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106)
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:350)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.rabbitmq.client.ShutdownSignalException: connection error
	at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67)
	at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:37)
	at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:367)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:293)
	... 23 common frames omitted
Caused by: java.io.EOFException: null
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
	at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:95)
	at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:139)
	at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:542)
	... 1 common frames omitted
13:47:58.128 ERROR c.d.g.a.AmqpBackend - error sending request
java.io.IOException: null
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:106)
	at com.rabbitmq.client.impl.AMQChannel.wrap(AMQChannel.java:102)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:350)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:813)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:767)
	at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:887)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.createChannel(AmqpConnectionManager.java:84)
	at com.deutscheboerse.gateway.amqp.AmqpConnectionManager.getChannel(AmqpConnectionManager.java:73)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.setupRequestChannel(AmqpRpcClient.java:229)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:135)
	at com.deutscheboerse.gateway.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:117)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:497)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:416)
	at com.deutscheboerse.gateway.amqp.AmqpBackend.sendRequest(AmqpBackend.java:401)
	at com.deutscheboerse.gateway.amqp.AmqpExchangeConnection.sendRequest(AmqpExchangeConnection.java:127)
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:280)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.rabbitmq.client.ShutdownSignalException: connection error
	at com.rabbitmq.utility.ValueOrException.getValue(ValueOrException.java:67)
	at com.rabbitmq.utility.BlockingValueOrException.uninterruptibleGetValue(BlockingValueOrException.java:37)
	at com.rabbitmq.client.impl.AMQChannel$BlockingRpcContinuation.getReply(AMQChannel.java:367)
	at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:293)
	... 23 common frames omitted
Caused by: java.io.EOFException: null
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
	at com.rabbitmq.client.impl.Frame.readFrom(Frame.java:95)
	at com.rabbitmq.client.impl.SocketFrameHandler.readFrame(SocketFrameHandler.java:139)
	at com.rabbitmq.client.impl.AMQConnection$MainLoop.run(AMQConnection.java:542)
	... 1 common frames omitted
13:47:58.129 INFO  c.d.g.m.v.M7ExchangeConnection - Login message response 'null'
13:47:58.129 ERROR c.d.g.m.v.M7ExchangeConnection - Login unsuccessful. Response: 'null'
13:47:58.174 ERROR c.d.c.t.a.l.RabbitLoginPanel - null
java.util.concurrent.ExecutionException: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at javax.swing.SwingWorker.get(SwingWorker.java:602)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.done(RabbitLoginPanel.java:258)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:190)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:758)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:74)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:728)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:205)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)
Caused by: com.deutscheboerse.commons.gateway.LoginException: Login unsuccessful.
	at com.deutscheboerse.gateway.m7.v1.M7ExchangeConnection.login(M7ExchangeConnection.java:313)
	at com.deutscheboerse.commons.gateway.DefaultBackendConnectionGateway.login(DefaultBackendConnectionGateway.java:183)
	at com.deutscheboerse.comxerv.testclient.app.login.MultiLoginModel.login(MultiLoginModel.java:242)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:252)
	at com.deutscheboerse.comxerv.testclient.app.login.RabbitLoginPanel$3.doInBackground(RabbitLoginPanel.java:248)
	at javax.swing.SwingWorker$1.call(SwingWorker.java:295)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at javax.swing.SwingWorker.run(SwingWorker.java:334)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

{code}",,ek176,hj444,od044,tr866,,,,,,,,,,,,,,,,,,,,,,,,,XP-3827,,,,,,,,,,,,,,"07/Sep/20 11:24;tr866;2020-09-07_09-54-05-745_comtrader_logfile.0.log;https://jira.deutsche-boerse.com/secure/attachment/87294/2020-09-07_09-54-05-745_comtrader_logfile.0.log","24/Aug/20 14:13;od044;COMTRADER_AllNonProd_xbid-SOB.p12;https://jira.deutsche-boerse.com/secure/attachment/86656/COMTRADER_AllNonProd_xbid-SOB.p12","30/Sep/20 12:49;tr866;comxerv-test-client.log;https://jira.deutsche-boerse.com/secure/attachment/88073/comxerv-test-client.log",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,24/Aug/20 14:02,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,Alpha Sprint 23 (S),Alpha Sprint 24,Alpha Christmas Sprint (S),Alpha Sprint 25,Alpha Sprint 26 (S),,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/20 10:16;ek176;xbsyt1cor1 has NFS issues, [~iv732] please fix

{{dmesg shows:}}

{{[1124136.277734] INFO: task Journaller:28256 blocked for more than 120 seconds. }}
{{[1124136.277759] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message. }}
{{[1124136.277778] Journaller      D ffff8f42f30862a0     0 28256      1 0x00000080 }}
{{[1124136.277781] Call Trace: }}
{{[1124136.277787]  [<ffffffffa5983ef0>] ? bit_wait+0x50/0x50 }}
{{[1124136.277788]  [<ffffffffa5985da9>] schedule+0x29/0x70 }}
{{[1124136.277790]  [<ffffffffa59838b1>] schedule_timeout+0x221/0x2d0 }}
{{[1124136.277806]  [<ffffffffc02ff7e6>] ? rpc_run_task+0xf6/0x150 [sunrpc] }}
{{[1124136.277815]  [<ffffffffc030e850>] ? rpc_put_task+0x10/0x20 [sunrpc] }}
{{[1124136.277843]  [<ffffffffc054fa7a>] ? nfs_initiate_pgio+0xda/0x160 [nfs] }}
{{[1124136.277846]  [<ffffffffa5306d32>] ? ktime_get_ts64+0x52/0xf0 }}
{{[1124136.277848]  [<ffffffffa5983ef0>] ? bit_wait+0x50/0x50 }}
{{[1124136.277849]  [<ffffffffa598549d>] io_schedule_timeout+0xad/0x130 }}
{{[1124136.277851]  [<ffffffffa5985538>] io_schedule+0x18/0x20 }}
{{[1124136.278006]  [<ffffffffa5983f01>] bit_wait_io+0x11/0x50 }}
{{[1124136.278014]  [<ffffffffa5983a27>] __wait_on_bit+0x67/0x90 }}
{{[1124136.278018]  [<ffffffffa53bd741>] wait_on_page_bit+0x81/0xa0 }}
{{[1124136.278022]  [<ffffffffa52c7840>] ? wake_bit_function+0x40/0x40 }}
{{[1124136.278023]  [<ffffffffa53bd871>] __filemap_fdatawait_range+0x111/0x190 }}
{{[1124136.278026]  [<ffffffffa53cb261>] ? do_writepages+0x21/0x50 }}
{{[1124136.278027]  [<ffffffffa53bd904>] filemap_fdatawait_range+0x14/0x30 }}
{{[1124136.278028]  [<ffffffffa53bfde6>] filemap_write_and_wait_range+0x56/0x90 }}
{{[1124136.278036]  [<ffffffffc05448df>] nfs_file_fsync+0x3f/0x1b0 [nfs] }}
{{[1124136.278040]  [<ffffffffa5482ce0>] vfs_fsync_range+0x20/0x30 }}
{{[1124136.278042]  [<ffffffffa54003fe>] SyS_msync+0x1fe/0x250 }}
{{[1124136.278045]  [<ffffffffa5992ed2>] system_call_fastpath+0x25/0x2a }}
{{[1124566.473532] nfs: server 10.139.40.225 not responding, still trying }}
{{[1125168.144723] nfs: server 10.139.40.225 not responding, still trying}}
{{ }}","03/Sep/20 16:21;ek176;Invalid HA PRoxy CA was replaced in Vault

SYT1 redeployed, successfully connected with XBEPEXX2 user, 10.136.142.19:50700.

SSL connection >>on<< with  COMTRADER_AllNonProd_xbid-SOB.p12 cert, TC 6.0.37-SNAPSHOT

 ","07/Sep/20 11:23;tr866;Tested on environment Syt1 with version XB R3.1.5 (Build d9d76cd1b071d193bde2482a415b6b15bba9dd89)
# with AMQP Test Client client-swing-6.0.36-with-deps: Connection was successful and order could be entered (/)
# Comtrader 2.5.1.67: connection not successful with following exceptions: (x)
{noformat}
Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
{noformat}
[logfile|^2020-09-07_09-54-05-745_comtrader_logfile.0.log] attached","29/Sep/20 16:21;ek176;The TLS endpoint presents an invalid certificate (not verifiable):
{noformat}
 Verify return code: 21 (unable to verify the first certificate){noformat}
Shortened log:
{noformat}
$ openssl s_client -showcerts -connect 10.136.142.19:50700                  
CONNECTED(00000005)
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, CN = *.xbid.deutsche-boerse.com
verify error:num=20:unable to get local issuer certificate
verify return:1
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, CN = *.xbid.deutsche-boerse.com
verify error:num=21:unable to verify the first certificate
verify return:1
140254143254976:error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure:../ssl/record/rec_layer_s3.c:1528:SSL alert number 40
---
Certificate chain
 0 s:C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, CN = *.xbid.deutsche-boerse.com
   i:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
Common Name: *.xbid.deutsche-boerse.com
...
Issuer: Sectigo RSA Organization Validation Secure Server CA, Sectigo Limited Write review of Sectigo
Serial Number: 4eff1f5f71fff28ec3b14723e43e18a5
---
Server certificate
subject=C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, CN = *.xbid.deutsche-boerse.comissuer=C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA---
Acceptable client certificate CA names
C = DE, O = Deutsche Boerse AG, CN = TEST Deutsche Boerse AG CA
C = DE, O = Deutsche Boerse Group, CN = TEST Deutsche Boerse Group Root CA
C = DE, L = Eschborn, O = Deutsche B\C3\83\C2\B6rse Group, CN = DBG CLIENT CA XBID TEST
Client Certificate Types: RSA sign, DSA sign, ECDSA sign
Requested Signature Algorithms: RSA+SHA512:DSA+SHA512:ECDSA+SHA512:RSA+SHA384:DSA+SHA384:ECDSA+SHA384:RSA+SHA256:DSA+SHA256:ECDSA+SHA256:RSA+SHA224:DSA+SHA224:ECDSA+SHA224:RSA+SHA1:DSA+SHA1:ECDSA+SHA1
Shared Requested Signature Algorithms: RSA+SHA512:DSA+SHA512:ECDSA+SHA512:RSA+SHA384:DSA+SHA384:ECDSA+SHA384:RSA+SHA256:DSA+SHA256:ECDSA+SHA256:RSA+SHA224:DSA+SHA224:ECDSA+SHA224:RSA+SHA1:DSA+SHA1:ECDSA+SHA1
Peer signing digest: SHA512
Peer signature type: RSA
Server Temp Key: ECDH, P-256, 256 bits
---
SSL handshake has read 2692 bytes and written 453 bytes
Verification error: unable to verify the first certificate
---
New, TLSv1.2, Cipher is ECDHE-RSA-AES256-GCM-SHA384
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : ECDHE-RSA-AES256-GCM-SHA384
    Session-ID: 1ED70EE3AAF6468E6F33FEB3BC6FD66C5D3CFAE5E95D59650309D3B84DDE574D
    Session-ID-ctx: 
    Master-Key: 9A9C9EA500C6E768830EB49457DBF634412DFEDFF52BABFBD5FA201C8449CCB283174A1CAED440A0D99C29E6DC0DC8C9
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1601388509
    Timeout   : 7200 (sec)
    Verify return code: 21 (unable to verify the first certificate)
    Extended master secret: no
{noformat}","30/Sep/20 11:29;ek176;HA Proxy redeployed, sucessfully connected as SADMIN03/SYT1 with CT 3.1.2

Connected to SYT1 with TestClient as XBEPEXX2 (10.136.142.19:50700)

 
{noformat}
$ openssl s_client -showcerts -connect 10.136.142.19:50700
CONNECTED(00000003)
...
    Verify return code: 0 (ok)
    Extended master secret: no
{noformat}","30/Sep/20 12:44;tr866;Tested on Syt1 with versions XB R3.1.7-e922653c32d74b65d2ccf8d3a2fbb006f8c577d5, AMQP Test Client client-swing-6.0.36-with-deps.jar, ComTrader 2.5.1.67
# ComTrader (/)
# AMQP Test Client
## IXE server(10.136.142.19) (/)
## HAU server(10.136.14.19) (x)
log attached [^comxerv-test-client.log]","30/Sep/20 12:48;ek176;Not a cert issue.
{noformat}
$ openssl s_client -showcerts -connect 10.136.14.19:50700
....
    Verify return code: 0 (ok)
    Extended master secret: no
{noformat}","30/Sep/20 12:50;ek176;Issue split into:
|XP-3827|(Split 1) ComTrader cannot connect to SYT1|
","13/Jan/21 12:55;hj444;Test SYT1: Version R3.2.3 (Build f8ed207ffd3066b56f11d298d662e63e4fbe80f9)

ComTrader V. 3.2.1 2020-10-23T10:59:26Z
JRE: 1.8.0_171-b11, Webstart: javaws-11.171.2.11
JVM: Java HotSpot(TM) Client VM by Oracle Corporation
OS: Windows Server 2012 R2 6.3 x86
121MB / 1024MB
XBID-SOB 3.2.3

Comtrader :
 * IXE server(10.136.142.19) (/) DC1
 * HAU server(10.136.14.19) (x) DC2

h4. Master DC1: IXE server(10.136.142.19)
{code:java}
2021-01-13T10:43:21.855+0100 [rader-Worker-22] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest1 TS A (XBID): XBOMIEA1@10.136.142.19:50700/ext/XSOBv1
2021-01-13T10:43:24.282+0100 [rader-Worker-22] INFO  c.d.c.c.s.a.ComTraderConnectionFactory - set up SSL context
2021-01-13T10:43:24.335+0100 [rader-Worker-22] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2021-01-13T10:43:24.565+0100 [rader-Worker-22] INFO  c.d.c.c.s.a.AmqpRpcClient - Request channel created
2021-01-13T10:43:24.565+0100 [rader-Worker-22] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new response channel
2021-01-13T10:43:24.643+0100 [rader-Worker-22] INFO  c.d.c.c.s.a.AmqpRpcClient - Response channel created
2021-01-13T10:43:24.648+0100 [rader-Worker-22] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Request: 621605809 LoginReq 
2021-01-13T10:43:24.806+0100 [rader-Worker-22] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Response: 621605809 UserRprt 
2021-01-13T10:43:24.808+0100 [trader-Worker-2] INFO  c.d.c.c.s.a.AmqpBroadcastClient - Connecting to broadcast queue comxerv.broadcastQueue.XBOMIEA1...
2021-01-13T10:43:24.848+0100 [lication Thread] INFO  c.d.c.c.j.s.MainPanelServiceImpl - Load window with suffix: 0
2021-01-13T10:43:24.848+0100 [trader-Worker-6] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Request: 1066703954 SystemInfoReq 
2021-01-13T10:43:24.858+0100 [lication Thread] INFO  c.d.c.c.j.c.AbstractBorderPaneController - Load: MainPanel.fxml
2021-01-13T10:43:24.887+0100 [trader-Worker-2] INFO  c.d.c.c.s.a.AmqpBroadcastClient - Connected to broadcast queue comxerv.broadcastQueue.XBOMIEA1
2021-01-13T10:43:24.888+0100 [trader-Worker-6] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Response: 1066703954 SystemInfoResp 
2021-01-13T10:43:24.890+0100 [trader-Worker-6] INFO  c.d.c.c.c.e.Exchange - System info has been loaded!{code}
h4. Switch DC1->DC2
{code:java}
2021-01-13T11:47:51.439+0100 [rader-Worker-33] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2021-01-13T11:47:52.460+0100 [rader-Worker-33] ERROR c.d.c.c.s.a.AmqpRpcClient - Channel creation failed
java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(Unknown Source)
	...
{code}
*After XBID is back again and active try to login into Comtrader :*
 * 
 ** Expected - login into DC2: 10.136.14.19

{code:java}
2021-01-13T11:48:03.480+0100 [rader-Worker-34] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest1 TS A (XBID): XBOMIEA1@10.136.14.19:50700/ext/XSOBv1
2021-01-13T11:48:03.480+0100 [oadcastListener] INFO  c.d.c.c.s.a.PrioritizingBroadcastListener - Interrupted while waiting for next broadcast - exiting. Broadcast priority queue dump: []
2021-01-13T11:48:05.130+0100 [rader-Worker-34] INFO  c.d.c.c.s.a.ComTraderConnectionFactory - set up SSL context
2021-01-13T11:48:05.149+0100 [rader-Worker-34] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2021-01-13T11:48:05.229+0100 [rader-Worker-34] INFO  c.d.c.c.s.a.AmqpRpcClient - Request channel created
2021-01-13T11:48:05.229+0100 [rader-Worker-34] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new response channel
2021-01-13T11:48:05.308+0100 [rader-Worker-34] INFO  c.d.c.c.s.a.AmqpRpcClient - Response channel created
2021-01-13T11:48:05.309+0100 [rader-Worker-34] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Request: 1168976440 LoginReq 
2021-01-13T11:48:07.973+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - CPU: Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz - 8 x 2597
2021-01-13T11:48:20.941+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - RAM: null
2021-01-13T11:48:20.941+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - Screen info (2): 1096x616, 1920x1200
2021-01-13T11:48:20.941+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - Uptime: PT3946.490S
2021-01-13T11:48:20.941+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - Session: XSOBv1/XBOMIEA1 (2021-01-13T11:48:03.480+0100)
2021-01-13T11:48:54.681+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - CPU load - process / system: 0.08 / 0.13
2021-01-13T11:48:54.681+0100 [rader-Worker-28] INFO  c.d.c.c.s.i.InfoLogger - Memory usage: 105MB / 1024MB
2021-01-13T11:49:05.309+0100 [rader-Worker-34] ERROR c.d.c.c.a.c.c.AbstractComXervAmqpBackend - error sending request
java.io.IOException: Timeout occurred while waiting for response from server
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:121)
	at com.deutscheboerse.comxerv.comtrader.api.comxerv.common.AbstractComXervAmqpBackend.sendRequest(AbstractComXervAmqpBackend.java:214)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AbstractAmqpBackend.sendRequest(AbstractAmqpBackend.java:218)
	at com.deutscheboerse.comxerv.comtrader.api.comxerv.common.AbstractComXervExchangeConnection.sendRequest(AbstractComXervExchangeConnection.java:203)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AbstractExchangeConnection.sendRequestAndReturnException(AbstractExchangeConnection.java:163)
	at com.deutscheboerse.comxerv.comtrader.api.m7.v1.ComXervExchangeConnection.doLogin(ComXervExchangeConnection.java:333)
	at com.deutscheboerse.comxerv.comtrader.api.m7.v1.ComXervExchangeConnection.login(ComXervExchangeConnection.java:309)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.BackendConnectionGatewayImpl.login(BackendConnectionGatewayImpl.java:82)
	at com.deutscheboerse.comxerv.comtrader.service.LoginServiceImpl.lambda$doLogin$3(LoginServiceImpl.java:62)
	at com.deutscheboerse.ui.jfx.util.LoggingRunnable.run(LoggingRunnable.java:21)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
2021-01-13T11:49:05.309+0100 [rader-Worker-34] ERROR c.d.c.c.s.a.AbstractAmqpBackend - error sending request
java.lang.RuntimeException: Request/response error. Correlation id = 1168976440. Timeout occurred while waiting for response from server
	at com.deutscheboerse.comxerv.comtrader.api.comxerv.common.AbstractComXervAmqpBackend.sendRequest(AbstractComXervAmqpBackend.java:251)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AbstractAmqpBackend.sendRequest(AbstractAmqpBackend.java:218)
	at com.deutscheboerse.comxerv.comtrader.api.comxerv.common.AbstractComXervExchangeConnection.sendRequest(AbstractComXervExchangeConnection.java:203)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AbstractExchangeConnection.sendRequestAndReturnException(AbstractExchangeConnection.java:163)
	at com.deutscheboerse.comxerv.comtrader.api.m7.v1.ComXervExchangeConnection.doLogin(ComXervExchangeConnection.java:333)
	at com.deutscheboerse.comxerv.comtrader.api.m7.v1.ComXervExchangeConnection.login(ComXervExchangeConnection.java:309)
	at com.deutscheboerse.comxerv.comtrader.service.amqp.BackendConnectionGatewayImpl.login(BackendConnectionGatewayImpl.java:82)
	at com.deutscheboerse.comxerv.comtrader.service.LoginServiceImpl.lambda$doLogin$3(LoginServiceImpl.java:62)
	at com.deutscheboerse.ui.jfx.util.LoggingRunnable.run(LoggingRunnable.java:21)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.io.IOException: Timeout occurred while waiting for response from server
	at com.deutscheboerse.comxerv.comtrader.service.amqp.AmqpRpcClient.sendMessage(AmqpRpcClient.java:121)
	{code}
*Master is 10:136:14:19 - DC2 but Comtrader is logged : 10.136.142.19 - DC1*
{code:java}
2021-01-13T12:11:00.040+0100 [trader-Worker-2] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2021-01-13T12:11:00.045+0100 [trader-Worker-2] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/XBOMIEA1 exists, attempting to load it.
2021-01-13T12:11:00.067+0100 [trader-Worker-2] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
2021-01-13T12:11:00.227+0100 [rader-Worker-17] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest1 TS A (XBID): XBOMIEA1@10.136.142.19:50700/ext/XSOBv1
2021-01-13T12:11:02.637+0100 [rader-Worker-17] INFO  c.d.c.c.s.a.ComTraderConnectionFactory - set up SSL context
2021-01-13T12:11:02.687+0100 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2021-01-13T12:11:02.923+0100 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Request channel created
2021-01-13T12:11:02.923+0100 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new response channel
2021-01-13T12:11:03.001+0100 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Response channel created
2021-01-13T12:11:03.007+0100 [rader-Worker-17] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Request: 1284886699 LoginReq 
2021-01-13T12:11:03.144+0100 [rader-Worker-17] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Response: 1284886699 UserRprt 
2021-01-13T12:11:03.146+0100 [rader-Worker-27] INFO  c.d.c.c.s.a.AmqpBroadcastClient - Connecting to broadcast queue comxerv.broadcastQueue.XBOMIEA1...
2021-01-13T12:11:03.184+0100 [lication Thread] INFO  c.d.c.c.j.s.MainPanelServiceImpl - Load window with suffix: 0
2021-01-13T12:11:03.193+0100 [lication Thread] INFO  c.d.c.c.j.c.AbstractBorderPaneController - Load: MainPanel.fxml
2021-01-13T12:11:03.222+0100 [rader-Worker-27] INFO  c.d.c.c.s.a.AmqpBroadcastClient - Connected to broadcast queue comxerv.broadcastQueue.XBOMIEA1
2021-01-13T12:11:03.702+0100 [lication Thread] INFO  c.d.c.c.j.c.AbstractBorderPaneController - Load: ContractTree.fxml
2021-01-13T12:11:03.732+0100 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: {code}","03/Feb/21 11:03;ek176;In fact, this is an expected behavior. Closing",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Flyway is not working with postgres 12,XP-3453,99191,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eg288,eg288,24/Aug/20 12:55,01/Sep/20 12:18,22/Feb/21 13:26,01/Sep/20 10:31,,,3.1.1,,,,,,,,,,,"Flyway migration fails with error after the database has been upgraded to postgres 12 (XP-2979)
{code:java}
STDOUT:


Flyway 4.2.0 by Boxfuse


Database: jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25106,xbtestpdb2.deutsche-boerse.de:25106/xbsyt1cor (PostgreSQL 12.4)



STDERR:


ERROR: 

Unable to clean schema ""xbsyt1cor""

----------------------------------

SQL State  : 42703

Error Code : 0

Message    : ERROR: column pg_proc.proisagg does not exist

  Hint: Perhaps you meant to reference the column ""pg_proc.prolang"".

  Position: 134
{code}

h2. How to test
* idealy migration from previous production version without cleandb should be done for XBID and SPM at least
* if it works the other modules should work as well
",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,24/Aug/20 12:55,,,,,,,,,,,,,None,,,,,,,,,,"1|y0beug:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Aug/20 13:34;eg288;* PR for ansible deployment (used latest flyway version available in energy artifacotry, it is 6.0.4):
[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1051]
* PR for xbid project (used latest flyway version 6.5.5):
[https://github.deutsche-boerse.de/dev/xbid/pull/770]
* SPM does not explicitly define flyway version in pom.xml thus it is using the latest one out of the box
* Reporting engine project does not have dependency on the flyway at all
* AMS (aka access-management) is using flyway 6.2.1 -> no change required
* PR for AMR (aka AM reporting), used latest flyway version 6.5.5:
https://github.deutsche-boerse.de/dev/xbid.am-reporting/pull/8
* PR for SLA report tool, , used latest flyway version 6.5.5:
https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/353","01/Sep/20 10:30;od044;Test passed on SYT1 
- deployment finish successfully with new flyway version",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"pmi logger, ansible start fails for instances configured to use backup rabbitmq cluster",XP-3446,99104,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,20/Aug/20 15:27,27/Aug/20 10:22,22/Feb/21 13:26,20/Aug/20 16:34,,,3.1.1,,,,,,,,,,,"The pmi logger start script tests health indicator which is never UP for pmi-logger instances running against backup (i.e. disabled) rabbitmq cluster. Because these instances cannot connect to the disabled backup rabbitmq cluster.
The design for pmi logger applications is to run all 6 instances all the time. 3 instances are connected to the first rabbitmq cluster. The other 3 instnaces are trying to connect to the second backup rabbitmq cluster in a reasonable interval. When the backup cluster is started the other 3 pmi logger instances would connect to it and they would start to record the AMQP traffic.

Solution is to modify start script not to test health check indicator. So the start script will finish succesfully even for pmi-logger instances whose health indicator is reporting DOWN due to missing AMQP connection.",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15984000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,20/Aug/20 15:27,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bebc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID SIMU DRT TEST description,XP-3445,99085,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lw641,rehapav,rehapav,20/Aug/20 12:36,02/Nov/20 12:54,22/Feb/21 13:26,06/Oct/20 11:02,,,3.1.2,,,,,,,,,,,"During   Hausen DC maintenance 26/9

it is foreseen that  XBID SIMU environment will participate on DRT tests.

 

We need to 
 * describe the test
 * describe what is added value of the test
 * request from XBID approval that DBAG can use XBID SUMU environment for this test

 ",,lw641,qm925,rehapav,rg535,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15552000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3402,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0be80:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/20 13:36;lw641;*Communication draft to XTG to share via XBID ticket*

*--*

Dear XTG,

As communicated in <ticketnumber>, DBAG will be performing *DC Hausen Power Maintenance on Sep 26th*, affecting various environments on XBID, including *SIMU*. We would like to use this opportunity to run internal Disaster Recover tests on SIMU environment *in parallel* with the ongoing power maintenance. By doing so, we are planning to improve the quality of our contingency plans and seek how to optimize our recovery scenarios.

As such, *DBAG would like to ask your explicit approval for using XBID SIMU* to run these tests. We are aware about the ongoing UAT testing but we believe it shouldn't interfere since the testing is planned to be done over the weekend of Sep 26-27th.

Please find below 2 possible options and consequences of each. Let us know which one would you like to proceed with.
h3. +Option 1+ - XTG approves DR testing on SIMU environment.

*Duration:*
 * Preparation phase: Sep 2nd - Failover of XBID SIMU to DC Hausen during 3.1.1 deployment
 * DC Power Maintenance: Sep 26th 08:00 - Sep 27th 20:00

*Impact:*
 # XBID SIMU will be explicitly used by DBAG for DRT testing;
 # DBAG does not guarantee any accessibility to customers for the mentioned period;
 # XBID SIMU will be without redundancy:

 * any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 * any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 * any remaining open connection to DC Hausen will be closed.

 
h3. +Option 2+ - XTG does not approve DR testing on SIMU environment.
h4. Duration:
 * DC Power Maintenance: Sep 26th 08:00 - Sep 27th 20:00
 * XBID SIMU fully redundant: Sep 27th 20:00

h4. Impact:
 # XBID SIMU will be without redundancy:

 * any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 * any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 * any remaining open connection to DC Hausen will be closed.

 

Thanks and looking forward to hearing from you.

Regards, DBAG

--

*end of draft*

 ","25/Aug/20 14:42;rg535;There are not two options for DR Testing.

*I suggest you change this sentence*
_Please find below 2 possible options and consequences of each. Let us know which one would you like to proceed with._

*to read as follows*
Please find below our proposal for DR testing on the SIMU environment including the consequences. You will also find a description of the process, if you reject our proposal for DR testing. 
Let us know if we may use the SIMU environment for DR testing as described in our proposal. 

*I suggest you rename:*
_Option 1 - XTG approves DR testing on SIMU environment._

*To:*
DBAG's proposal for DR Testing on SIMU environment.

*I suggest you rename*
_Option 2 - XTG does not approve DR testing on SIMU environment._

*to*
Process if XTG does not approve DR testing on SIMU environment.","25/Aug/20 16:01;qm925;[~rg535], [~lw641], [~rehapav], [~ei349],

Please see below my proposal for DC Hausen non-production env, impact analysis + request for DRT

 

Dear all,

Please let us provide you with the Impact analysis for the already announced secondary data center power maintenance (in Hausen) on the 26-27/9/2020 for all XBID non-production environments.
 #  *CuTe PX, CuTe TSO, LIP A, LIP B, Individual CuTes*

 * Impact
 * No impact expected


 * Timeline
 * n/a

 #  *Simulation*

We would like to use this opportunity to run internal Disaster Recover tests on SIMU environment *in parallel* with the ongoing power maintenance. By doing so, we are planning to improve the quality of our contingency plans and seek how to optimize our recovery scenarios.

As such, *DBAG would like to ask your explicit approval for using XBID SIMU* to run these tests. We are aware about the ongoing UAT testing but we believe it shouldn't interfere since the testing is planned to be done over the weekend of Sep 26-27th.

Please find below our proposal for DR testing on the SIMU environment including the consequences. You will also find a description of the process, if you reject our proposal for DR testing. Let us know if we may use the SIMU environment for DR testing as described in our proposal.

*DBAG's proposal for DR Testing on SIMU environment.*

*Duration:*
 * Preparation phase: Wednesday, 02/09 - Failover of XBID SIMU to DC Hausen during 3.1.1 deployment
 * DC Power Maintenance: Sep 26th 08:00 - Sep 27th 20:00 – DRT execution
 * Sunday 27/09 at 20:00 – Simu becomes fully redundant again

*Impact:*
 # XBID SIMU will be explicitly used by DBAG for DRT testing;
 # DBAG does not guarantee any accessibility to customers for the mentioned period (Saturday morning till Sunday evening)
 # XBID SIMU will be without redundancy:

 * any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 * any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 * any remaining open connection to DC Hausen will be closed.

*Process if XTG does not approve DR testing on SIMU environment.*

*Duration:*
 * Saturday 26/9 at 8:00 – XBID Simu loses redundancy, secondary data center Hausen without power
 * No data center failover available 


 * Sunday 27/9 at 20:00, - XBID Simu becomes fully redundant again,  secondary data center Hausen will be fully operational again
 * Standard failover behavior restored

*Impact:*
 # XBID SIMU will be without redundancy:

 * any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 * any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 * any remaining open connection to DC Hausen will be closed.

 May I kindly ask for your feedback regarding the DRT no later than XX/XX.

Thanks and looking forward to hearing from you.

Regards, DBAG","25/Aug/20 16:06;rg535;[~qm925] the proposal looks good.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UAT planning - review,XP-3440,99052,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,zi174,zi174,zi174,19/Aug/20 12:51,06/Nov/20 09:30,22/Feb/21 13:26,24/Aug/20 16:37,,,3.1.1,,,,,,,,,,,check the attached document,,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/20 12:51;zi174;XTG-R3.1-UAT_I_III_Regression-Test_Plan-v1.0.docx;https://jira.deutsche-boerse.com/secure/attachment/86535/XTG-R3.1-UAT_I_III_Regression-Test_Plan-v1.0.docx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16156800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0be0w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split1) Ansible - make the jenkins form more usable,XP-3439,99049,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,ek176,19/Aug/20 11:39,20/Aug/20 08:02,22/Feb/21 13:26,19/Aug/20 11:39,,,3.1.1,,,,,,,,,,,Try to do some checkboxes that checks other checkboxes and so on. Currently there are too many form inputs to fill in,,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SPlit,,,,,,,,,,,,,,16156800,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bda0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade RHEL to 7.8 on SIMU,XP-3437,99041,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ei349,ei349,19/Aug/20 10:24,02/Sep/20 11:49,22/Feb/21 13:26,02/Sep/20 11:34,,,3.1.1,,,,,,,TechOps,,,,"Upgrade RHEL om SIMUlation to 7.8. 

Agree with PO on execution date for it. 

(probably it will be on 1-3rd September)

 

Align with SysEng to prepare the update so we can just perform the restart on agreed date. ",,ei349,iv732,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3378,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdqn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/20 11:43;iv732;List of hosts

{code:java}
xbsimuweb1/2/3/4/5/6
xbsimuwbc1/2/3/4/5/6
xbsimucons1/2/3/4/5/6
xbsimupdb1/2/3/4
xbsimupmi1/2/3/4
xbsimucom1/2/3/4/5/6
xbsimuglfs1/2
xbsimucha1/2
xbsimussl1/2/3/4/5/6
xbsimussc1/2/3/4/5/6
xbsimubha1/2/3/4
xbsimueha1/2
xbsimuidm1/2
xbdsldap1/2
xbsimuldp1/2
xbsimucbn1/2
xbsimupdb1/2/3/4
xbsimupdb1/2/3/4
xbsimudbr1/2
xbsimuedb1
xbsimuxmq1/2/3/4/5/6
xbsimuimq1/2/3/4/5/6
xbsimurts1/2
xbsimuprx1/2
xbidsimucor1/2
xbsimusob1/2
xbsimucmm1/2
xbsimucmi1/2
xbsimusmc1/2
xbsimusmi1/2
xbsimuecp1/2
xbsimuctp1/2
xbsimurep1/2
xbsimuams1/2
{code}
","25/Aug/20 12:12;iv732;[~ei349] [~hw120] [~yo218] do we (should we) plan to upgrade all hosts including Postgres, Consul? It is not that easy as running a playbook to stop/start application, and I am not confident in case of those servers have any problem. Moreover, we will start using for the first time the new Ansible playbook on that day. It can also take time in case of any unforeseen issues.
","25/Aug/20 17:18;iv732;SYSENG ticket:  https://jira.deutsche-boerse.com/browse/SYSENG-144
","26/Aug/20 10:00;ei349;[~rehapav]: what do you think about [~iv732]'s comment? I don't know what was your plan for scope of RHEL upgrade. ","26/Aug/20 10:14;ei349;[~iv732], [~rehapav]  please also make sure that that SysEng can support so we can have the upgrade finished on 2nd September on SIMU. ","26/Aug/20 10:22;rehapav;[~iv732] please exclude Postgres, Consul from this RH upgrade.

Let's deliver XBID 3.1 with ansible and upgrade only hosts excluding Consul and Posgre to RH 7.8","26/Aug/20 11:13;iv732;The following hosts will not be upgraded:


{code:java}
xbsimucons1/2/3/4/5/6
xbsimupdb1/2/3/4
xbsimupdb1/2/3/4
xbsimupdb1/2/3/4
xbsimudbr1/2
xbsimuedb1
{code}
","01/Sep/20 08:10;iv732;The following hosts will be upgraded

{code:java}
xbsimuweb1
xbsimuweb2
xbsimuweb3
xbsimuweb4
xbsimuweb5
xbsimuweb6
xbsimuwbc1
xbsimuwbc2
xbsimuwbc3
xbsimuwbc4
xbsimuwbc5
xbsimuwbc6
xbsimupmi1
xbsimupmi2
xbsimupmi3
xbsimupmi4
xbsimussl1
xbsimussl2
xbsimussl3
xbsimussl4
xbsimussl5
xbsimussl6
xbsimussc1
xbsimussc2
xbsimussc3
xbsimussc4
xbsimussc5
xbsimussc6
xbsimubha1
xbsimubha2
xbsimubha3
xbsimubha4
xbsimueha1
xbsimueha2
xbsimuidm1
xbsimuidm2
xbsimuxmq1
xbsimuxmq2
xbsimuxmq3
xbsimuxmq4
xbsimuxmq5
xbsimuxmq6
xbsimuimq1
xbsimuimq2
xbsimuimq3
xbsimuimq4
xbsimuimq5
xbsimuimq6
xbsimurts1
xbsimurts2
xbsimuprx1
xbsimuprx2
xbidsimucor1
xbidsimucor2
xbsimusob1
xbsimusob2
xbsimucmm1
xbsimucmm2
xbsimucmi1
xbsimucmi2
xbsimusmc1
xbsimusmc2
xbsimusmi1
xbsimusmi2
xbsimuecp1
xbsimuecp2
xbsimuctp1
xbsimuctp2
xbsimurep1
xbsimurep2
xbsimuams1
xbsimuams2

{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID impact analysis for Hausen DC maintenance 26/9,XP-3433,98988,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,rehapav,rehapav,18/Aug/20 10:04,06/Nov/20 10:14,22/Feb/21 13:26,27/Sep/20 15:44,,,3.1.2,7tops_sprint102,,,,,,7tops,,,,"h1. XBID impact analysis for Hausen DC maintenance 26/9

 

*<email>*

 

Dear all,

 let me provide you with the
 * Impact analysis for already announced Secondary DC (Hausen) Maintenance 26-27/9/2020 as well as
 * announcement of 2 (two) consecutive Maintenance windows before and after DC Maintenance weekend.

 

Please note that this Impact Analysis is also included in the ticket SMXBID-1933,.

 

Impact analysis is prepared for 3 groups of environments:
 * XBID PRODUCTION
 * XBID SIMULATION
 * all remaining XBID test environments

h2. *Group 1*

*Environment*: XBID PRODUCTION
h3. Impact
 * DBAG announces first technical maintenance window - XBID PROD DC Hausen Maintenance Preparation - on Friday 25/9 at 13:00 for 1 hour
 ** {color:#172b4d}market halt - 5 minutes{color}
 ** {color:#172b4d}Failover of XBID Solution to the primary data center Equinix - 30{color} minutes
 ** XBID members/clients reconnect all their connections to primary data center Equinix, such as:
 *** LTS connectivity over MPLS
 *** COLT connectivity
 *** all Web GUI connectivity
 *** CT connectivity
 ** shakedown tests - 20 minutes
 ** {color:#172b4d}market unhalt - 5 minutes{color}
 * XBID PROD will be without redundancy during DC Hausen maintenance (see timeline), during this period
 ** any incident that leads to failover-request to the secondary data center will stop the system abruptly (instead of standard failover to the secondary data center and setting market to halt) - this will trigger ICC call and DBAG will restart XBID on primary data center Equinix
 ** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable
 ** any remaining open connection to DC Hausen will be closed
 * DBAG announces second technical maintenance window - XBID PROD DC Hausen Maintenance Post check- on Sunday 25/9 at 17:00 for 1 hour
 ** market halt - 5 minutes
 ** Reconnection of DC Hausen back to the XBID cluster - 30 minutes
 ** shakedown tests - 20 minutes
 ** market unhalt - 5 minutes
 ** Above provided timeline for Maintenance Window on Sunday 27/9 is indicative only, in case of delay DBAG will notify OPSCOM as soon as possible.

h3. Timeline
 * Friday 25/9, 13:00 - 14:00, 1 hour technical maintenance window
 ** XBID Solution runs in Equinix
 ** XBID Solution remains fully redundant,  Secondary data center Hausen remains fully operational
 ** Standard failover behavior
 * Saturday 26/9 at 8:00, XBID loses redundancy, Secondary data center Hausen without power
 ** No data center failover available 
 * Sunday 27/9, 17:00 - 18:00, 1 hour technical maintenance window
 ** DC Hausen will be activated
 ** XBID becomes fully redundant again,  Secondary data center Hausen fully operational
 ** Standard failover behavior restored

h2. Group 2

*Environment*: XBID SIMULATION

 

DBAG requested approval to use XBID SIMU environment during DC Hausen Maintenance for internal DBAG DRT testing in a dedicated ticket {color:#1d1c1d}XP-3445.{color}

Based on approval or denial of this request DBAG has defined two scenarios for XBID SIMU during DC Hausen maintenance.
h3. +Option 1+: Approved Case
h4. Impact in case XBID SIMU is approved to be used for DRT testing
 * XBID SIMU will be explicitly used by DBAG for DRT testing 
 * DBAG does not guarantee accessibility to XBID SIMU for customers from Saturday Morning till Sunday evening

h4. Timeline in case XBID SIMU is approved to be used for DRT testing
 * Wednesday 2/9 - Failover of XBID SIMU to DC Hausen during 3.1.1. deployment
 * Saturday 26/9 at 8:00 -> Sunday 27/9 at 16:00 - DRT test
 * Sunday 27/9 at 20:00 -  XBID SIMU becomes fully redundant again

h3. +Option 2+: Declined case
h4. Impact in case XBID SIMU will not participate in DRT testing
 * XBID SIMU will be without redundancy during DC Hausen maintenance (see timeline), during this period
 ** any incident that leads to failover-request to the secondary data center will stop the system abruptly (instead of standard failover to the secondary data center and setting market to halt) 
 ** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable
 ** any remaining open connection to DC Hausen will be closed

h4. Timeline in case XBID SIMU will not participate in DRT testing
 * Saturday 26/9 at 8:00 - XBID loses redundancy, Secondary data center Hausen without power
 ** No data center failover available 
 * Sunday 27/9 at 20:00, - XBID becomes fully redundant again,  Secondary data center Hausen will be fully operational again
 ** Standard failover behavior restored

h2. *Group 3*

*Environments*:  all other XBID environments, such as all CUTEs including individuals and CUTE TSO/PXS and all LIPs
h3. Impact
 * No impact expected

h3. Timelines
 * n/a 

 

In case you have any questions, do not hesitate to ask.

*</email>* 

 ",,ei349,qm925,rehapav,rg535,yo218,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-8146,XP-3445,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15552000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdn4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/20 10:48;ei349;Things to consider for Hausen maintenace, DRT preparations and for impact analysis for customer communication  
 * Simu should be on Equinix on Friday to prevent ongoing UAT disruption which can affect strict UAT timeline
 * Which exact environments will be affected for how long? 
 * What's the end state after maintenance - where will be primary node? (Equinix?)
 * Simu DRT should be done
 * What will be DRT duration and how many times will customers see failovers or disruptions or whatever what might affect them? 
 * What will be impact even though customers will not see any distruption for some environments - like for production there will be no redundancy when Hausen is down. ","18/Aug/20 13:09;qm925;Individual CuTes + LIP B should be added in the analysis ","20/Aug/20 09:35;rehapav;XBID PROD
 * Whole Saturday XBID PROD will be without redundancey
 * no instance to fail over - we will recover back on Equinix
 * we will not be hn market halt in Hausen but in core down on Equinix (functionally its same)
 * announce MW on Friday 25/9 cca 17:00 for 2 hours
 ** use this window to failover to Equinix
 ** use this window for clients to connect to Equinix
 * please note that SPM hase seamless fialover so it may failvoer any time to Hausen - how to handle this failover ?","20/Aug/20 09:47;rehapav;XBID SIMU
 * DRT tests to be exeucted
 ** who supports this test?
 ** during the test we will be in market halt
 ** who will unhalt the market? or its not needed for the test?
 * UAT running until 25/9 at 17:00 
 * failover to Hausen during deployment on 1-2/9
 * Sunday we recover SMU to double sided

 ","20/Aug/20 09:52;rehapav;XBID non-PROD, non-SIMU
 * we keep all CUTEs/LIPAs running
 * life migration due to the stretched cluster during Saturday 
 * failover stretched cluster
 * will this cause market halt ?
 ** databases?
 ** connections ?
 * last year we had issues only with non-patroni rest survived
 * so should not have any impact","24/Aug/20 10:53;ei349;Hi [~rehapav], looking good so far. Maybe just small minor remarks: 
 * Group1
 ** Impact 
 *** Maintenance  
 **** failover might be optional - If we proof that everything is on Equinix - market halt should be decided on their side, same with potential shakedown and market unhalt
 **** Text update proposal: Customers should check connectivity details and use Equinix endpoints only (eg. LTS over MPLS, COLT, GUI, CT)
 *** XBID prod without redundancy 
 **** Hausen connection will not be rejected, but endpoints will not be reachable, won't they?
 *** Timeline
 **** Sunday 27/9 at 18:00 - are we sure we don't need any maintenance window for failover possibility restoration? 

 * Group 2 
 ** Option1
 *** Impact
 **** Another impact is that DBAG cannot guarantee any accessibility to customers from Saturday Morning to Sunday evening
 *** Timeline
 **** Approved date for 3.1.1 deployment is 2nd September - let's do failover to Hausen there
 ** Option 2 
 *** Impact
 **** Hausen connection will not be rejected, but endpoints will not be reachable, won't they?","24/Aug/20 11:15;rehapav;[~ei349] incorporated all but part:

Maintenance  
 * failover might be optional - If we proof that everything is on Equinix - market halt should be decided on their side, same with potential shakedown and market unhalt
 * Text update proposal: Customers should check connectivity details and use Equinix endpoints only (eg. LTS over MPLS, COLT, GUI, CT)

I do not think we should offer too complex scenario.

Lets stick to the plan - halt the market, all the parties has time to reconnect to Equinix, DBAG has time to failover.

 

Sunday 27/9 at 18:00 - are we sure we don't need any maintenance window for failover possibility restoration? 

-  let me check that witn Niklas ","24/Aug/20 15:21;yo218;""Sunday 27/9 at 18:00 - are we sure we don't need any maintenance window for failover possibility restoration? ""

yes, we are","25/Aug/20 14:24;sw455; 

Dear all,

let me provide you with the
 * Impact analysis for already announced DC Hausen Maintenance 26-27/9/2020 as well as
 * announcement of 2 (two) consecutive Maintencnance windows before and after DC Maintenance weekend.

 

Please note that this Impact Analysis is also included in the ticket SMXBID-1933,.

 

Impact analysis is prepared for 3 groups of environments:
 * XBID PRODUCTION
 * XBID SIMULATION
 * all remaining XBID test environments

h2. *Group 1*

*Environment*: XBID PRODUCTION
h3. Impact
 * DBAG announces first technical maintenance window - XBID PROD DC Hausen Maintenance Preparation - on Friday 25/9 at 13:00 for 1 hour
 ** {color:#172b4d}market halt - 5 minutes{color}
 ** {color:#172b4d}Failover of XBID solution to the primary data center Equinix - 30{color} minutes
 ** XBID members/clients reconnect all their connections to primary data center Equinix, such as:
 *** LTS connectivity over MPLS
 *** COLT connectivity
 *** all Web GUI connectivity
 *** CT connectivity
 ** shakedown tests - 20 minutes
 ** {color:#172b4d}market unhalt - 5 minutes{color}
 * XBID PROD will be without redundancy during DC Hausen maintenance (see timeline), during this period:
 ** application failover to secondary data center will not be possible. In case of failover triggering events, recovery will be done directly within instances in primary datacenter. Standard incidents processes remain: alerting is unaffected, ICC calls to take place in the event of failover notification or other unavailability.
 ** Connection endpoints in Hausen will not be reachable; any new connection attempts to Hausen DC will fail
 ** any remaining open connections at DC Hausen endpoints will be terminated
 * DBAG announces second technical maintenance window - XBID PROD DC Hausen Maintenance Post check- on Sunday 25/9 at 17:00 for 1 hour
 ** market halt - 5 minutes
 ** Reconnection of DC Hausen back to the XBID cluster - 30 minutes
 ** shakedown tests - 20 minutes
 ** market unhalt - 5 minutes
 ** Above provided timeline for Maintenance Window on Sunday 27/9 is indicative only, in case of delay DBAG will notify OPSCOM as soon as possible.

h3. Timeline
 * Friday 25/9, 13:00 - 14:00, 1 hour technical maintenance window:
 ** Ensure XBID solution master instances running in Equinix Datacenter
 ** Note: after 25/9 14:00 until 26/9 08:00, the Secondary data center Hausen remains fully operational; full redundancy and standard failover processes will remain in place for the XBID solution.
 * Saturday 26/9 at 8:00, XBID loses redundancy, Secondary data center Hausen without power
 ** No data center failover available 
 * Sunday 27/9, 17:00 - 18:00, 1 hour technical maintenance window
 ** DC Hausen will be activated
 ** BID becomes fully redundant again,  Secondary data center Hausen fully operational
 ** Standard failover behavior restored

h2. Group 2

*Environment*: XBID SIMULATION

 
 * DBAG will utlize the XBID *Simution* environment during DC Hausen Maintenance for Disaster Recovery testing - details here: {color:#de350b}XBID-XXXX{color}.
 * Between Saturday morning utill Sunday evening XBID *Simulation* is expected to experience one or more failover events. Normal availability of the *Simulation* environment can not be gauranteed during this time.

h4. Timeline:
 * 2nd of Sep 2020 - Failover of XBID SIMU to DC Hausen during 3.1.1. deployment
 * Saturday 26/9 at 8:00 -> Sunday 27/9 at 16:00 - Disaster Recovery testing activities
 * Sunday 27/9 at 20:00 -  XBID SIMU becomes fully redundant again

h2. *Group 3*

*Environments*:  all other XBID environments, such as all CUTEs including individuals and CUTE TSO/PXS and all LIPs
h3. Impact
 * No impact expected

h3. Timelines
 * n/a 

 

In case you have any questions, do not hesitate to ask.

*</email>* ","25/Aug/20 14:25;sw455;[~rehapav] - my revision above. I would send the notifcation of the Disaster Recovery Plan testing as a *notification*, not as a request for approval.","25/Aug/20 14:49;rg535;Dear all, the revisions look good. Suzanna","25/Aug/20 14:57;yq577;Mail for Prod, CuteTSO, CutePX: 
h2. *XBID Production* 
h3. *Impact*
 * DBAG announces first technical maintenance window - XBID PROD DC Hausen Maintenance Preparation - on Friday 25/9 at 13:00 for 1 hour
 ** {color:#172b4d}market halt - 5 minutes{color}
 ** {color:#172b4d}Failover of XBID Solution to the primary data center Equinix - 30{color} minutes
 ** XBID members/clients reconnect all their connections to primary data center Equinix, such as:
 *** LTS connectivity over MPLS
 *** COLT connectivity
 *** all Web GUI connectivity
 *** CT connectivity
 ** shakedown tests - 20 minutes
 ** {color:#172b4d}market unhalt - 5 minutes{color}
 * XBID PROD will be without redundancy during DC Hausen maintenance (see timeline), during this period
 ** any incident that leads to failover-request to the secondary data center will stop the system abruptly (instead of standard failover to the secondary data center and setting market to halt) - this will trigger ICC call and DBAG will restart XBID on primary data center Equinix
 ** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable
 ** any remaining open connection to DC Hausen will be closed
 * DBAG announces second technical maintenance window - XBID PROD DC Hausen Maintenance Post check- on Sunday 25/9 at 17:00 for 1 hour
 ** market halt - 5 minutes
 ** Reconnection of DC Hausen back to the XBID cluster - 30 minutes
 ** shakedown tests - 20 minutes
 ** market unhalt - 5 minutes
 ** Above provided timeline for Maintenance Window on Sunday 27/9 is indicative only, in case of delay DBAG will notify OPSCOM as soon as possible.

h3. *Timeline*
 * Friday 25/9, 13:00 - 14:00, 1 hour technical maintenance window
 ** XBID Solution runs in Equinix
 ** XBID Solution remains fully redundant,  Secondary data center Hausen remains fully operational
 ** Standard failover behavior
 * Saturday 26/9 at 8:00, XBID loses redundancy, Secondary data center Hausen without power
 ** No data center failover available 
 * Sunday 27/9, 17:00 - 18:00, 1 hour technical maintenance window
 ** DC Hausen will be activated
 ** XBID becomes fully redundant again,  Secondary data center Hausen fully operational
 ** Standard failover behavior restored**

h2. *XBID Non-Production (CuTe TSO, CuTe PX)*
h3. *Impact*
 * No impact expected

h3. *Timelines*
 * n/a 

 

In case you have any questions, do not hesitate to ask.","25/Aug/20 16:18;ei349;h1. *MAIL TO BE SENT TO THE CUSTOMERS:* 

*Subject:* SIDC - ENV - Secondary Data-Center Yearly Maintenance Impact Analysis

Dear Camilla, dear XTG leaders, dear Jiri,

Please be informed that the impact analysis for Deutsche Börse group-wide maintenance activities in the secondary data center (Hausen) which will take place on 26^th^ and 27^th^ September 2020 is now available in the ticket *SMXBID-1933 for PRODUCTION* and *XBID-XXXX for all non-production environments*.

In the respective tickets you can also find more details about the timeline and the activities connected to the maintenance.

Please review the tickets and raise any questions or concerns directly there.

Thanks and Regards,
 -------------------------------------------------------------------
 Deutsche Börse AG
 Mergenthalerallee 61
 65760 Eschborn

Postal Address:
 60485 Frankfurt am Main
 Link : [https://xbid.servicedesk.deutsche-boerse.com|https://xbid.servicedesk.deutsche-boerse.com/]
h1. *TICKET FOR PROD ONLY (SMXBID-1933)*
h2. *XBID Production*
h3. *Impact*
 * DBAG announces technical maintenance window - XBID PROD DC Hausen Maintenance Preparation - on Friday 25/9 at 13:00 for 1 hour
 ** {color:#172b4d}market halt - 5 minutes{color}
 ** {color:#172b4d}Failover of XBID Solution to the primary data center Equinix - 30{color} minutes
 ** XBID members/clients reconnect all their connections to primary data center Equinix, such as:
 *** LTS connectivity over MPLS
 *** COLT connectivity
 *** all Web GUI connectivity
 *** CT connectivity
 ** shakedown tests - 20 minutes
 ** {color:#172b4d}market unhalt - 5 minutes{color}
 * XBID PROD will be without redundancy during DC Hausen maintenance (see timeline), during this period
 ** any incident that leads to failover-request to the secondary data center will stop the system abruptly (instead of standard failover to the secondary data center and setting market to halt) - this will trigger ICC call and DBAG will restart XBID on primary data center Equinix
 ** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable
 ** any remaining open connection to DC Hausen will be closed
 * On Sunday 25/9 at 17:00 DBAG will reconnect DC Hausen to the cluster
 ** Full failover possibility will be restored. 
 ** DBAG will reconnect DC Hausen to the cluster
 ** XBID becomes fully redundant again
 ** Secondary data center Hausen fully operational
 ** Standard failover behavior restored
 ** no impact expected

h3. *Timeline*
 * Friday 25/9, 13:00 - 14:00, 1 hour technical maintenance window
 ** XBID Solution runs in Equinix
 ** XBID Solution remains fully redundant,  Secondary data center Hausen remains fully operational
 ** Standard failover behavior
 * Saturday 26/9 at 8:00, XBID loses redundancy, Secondary data center Hausen without power
 ** No data center failover available 
 * Sunday 27/9, 17:00 - 18:00 DBAG will reconnect DC Hausen to the cluster
 ** XBID becomes fully redundant again
 ** Secondary data center Hausen fully operational
 ** Standard failover behavior restored
 ** no impact expected

In case you have any questions, do not hesitate to ask.
h1. *TICKET FOR OTHER ENVS (CREATE XBID-XXX TICKET)*
h2.  

Dear all,

Please let us provide you with the Impact analysis for the already announced secondary data center power maintenance (in Hausen) on the 26-27/9/2020 for all XBID non-production environments.
h3. *1. CuTe PX, CuTe TSO, LIP A, LIP B, Individual CuTes*
 * Impact
 ** No impact expected
 *  Timeline
 ** n/a

h3. *2. Simulation*

We would like to use this opportunity to run internal Disaster Recover tests on SIMU environment *in parallel* with the ongoing power maintenance. By doing so, we are planning to improve the quality of our contingency plans and seek how to optimize our recovery scenarios.

As such, *DBAG would like to ask your explicit approval for using XBID SIMU* to run these tests. We are aware about the ongoing UAT testing but we believe it shouldn't interfere since the testing is planned to be done over the weekend of Sep 26-27th.

Please find below our proposal for DR testing on the SIMU environment including the consequences. You will also find a description of the process, if you reject our proposal for DR testing. Let us know if we may use the SIMU environment for DR testing as described in our proposal.

*DBAG's proposal for DR Testing on SIMU environment:*
 * *Duration:*
 ** Preparation phase: Wednesday, 02/09 - Failover of XBID SIMU to DC Hausen during 3.1.1 deployment
 ** DC Power Maintenance: Sep 26th 08:00 - Sep 27th 20:00 – DRT execution
 ** Sunday 27/09 at 20:00 – Simu becomes fully redundant again
 * *Impact:*
 ** XBID SIMU will be explicitly used by DBAG for DRT testing;
 ** DBAG does not guarantee any accessibility to customers for the mentioned period (Saturday morning till Sunday evening)
 ** XBID SIMU will be without redundancy:
 *** any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 *** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 *** any remaining open connection to DC Hausen will be closed.

*Process if XTG does not approve DR testing on SIMU environment:*
 * *Duration:*
 ** Saturday 26/9 at 8:00 – XBID Simu loses redundancy, secondary data center Hausen without power
 ** No data center failover available 
 ** Sunday 27/9 at 20:00, - XBID Simu becomes fully redundant again,  secondary data center Hausen will be fully operational again
 ** Standard failover behavior restored
 * *Impact:*
 ** XBID SIMU will be without redundancy:
 *** any incident that leads to failover-request to the secondary data center will stop the system abruptly;
 *** any new connection attempt to Hausen DC will fail; Hausen endpoints will not be reachable;
 *** any remaining open connection to DC Hausen will be closed.

May I kindly ask for your feedback regarding the DRT no later than XX/XX.

Thanks and looking forward to hearing from you.

Best regards, DBAG",,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool - Spring Batch upgrade broke the existing job deserialization,XP-3431,98977,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,17/Aug/20 15:21,20/Aug/20 17:22,22/Feb/21 13:26,18/Aug/20 09:39,,,3.1.1,,,,,,,,,,,"The upgrade to Spring Boot {{2.3.1.RELEASE}} also upgrade Spring Batch dependency to 4.2.4

 

There is backwards compatibility bug, resulting in Spring Batch not being able to load/deserialize old job execution context data.
{code:java}
2020-08-17 15:03:38.717 http-nio-8080-exec-3 ERROR - o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.IllegalArgumentException: Unable to deserialize the execution context] with root cause
com.fasterxml.jackson.databind.exc.InvalidTypeIdException: Missing type id when trying to resolve subtype of [map type; class java.util.HashMap, [simple type, class java.lang.String] -> [simple type, class java.lang.Object]]: missing type id property '@class'
 at [Source: (ByteArrayInputStream); line: 1, column: 2]
	at com.fasterxml.jackson.databind.exc.InvalidTypeIdException.from(InvalidTypeIdException.java:43)
	at com.fasterxml.jackson.databind.DeserializationContext.missingTypeIdException(DeserializationContext.java:1794)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingTypeId(DeserializationContext.java:1323)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._handleMissingTypeId(TypeDeserializerBase.java:303)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:166)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:107)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserializeWithType(MapDeserializer.java:413)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4482)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3479)
	at org.springframework.batch.core.repository.dao.Jackson2ExecutionContextStringSerializer.deserialize(Jackson2ExecutionContextStringSerializer.java:123)
	at org.springframework.batch.core.repository.dao.Jackson2ExecutionContextStringSerializer.deserialize(Jackson2ExecutionContextStringSerializer.java:102)
	at org.springframework.batch.core.repository.dao.JdbcExecutionContextDao$ExecutionContextRowMapper.mapRow(JdbcExecutionContextDao.java:325)
	at org.springframework.batch.core.repository.dao.JdbcExecutionContextDao$ExecutionContextRowMapper.mapRow(JdbcExecutionContextDao.java:312)
	at org.springframework.jdbc.core.RowMapperResultSetExtractor.extractData(RowMapperResultSetExtractor.java:94)
	at org.springframework.jdbc.core.RowMapperResultSetExtractor.extractData(RowMapperResultSetExtractor.java:61)
	at org.springframework.jdbc.core.JdbcTemplate$1.doInPreparedStatement(JdbcTemplate.java:679)
	at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:617)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:669)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:700)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:712)
	at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:768)
	at org.springframework.batch.core.repository.dao.JdbcExecutionContextDao.getExecutionContext(JdbcExecutionContextDao.java:114)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.getJobExecutionDependencies(SimpleJobExplorer.java:232)
	at org.springframework.batch.core.explore.support.SimpleJobExplorer.getJobExecutions(SimpleJobExplorer.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy113.getJobExecutions(Unknown Source)
	at com.deutscheboerse.energy.xbid.reporttool.web.JobOperatorController.jobHistory(JobOperatorController.kt:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:626)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1589)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
 {code}

The suggested fix is to migrated DB data so a new version of Jackson can cope with them, see https://stackoverflow.com/questions/62718203/spring-batch-4-2-4-unable-to-deserialize-the-execution-context
",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16243200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdko:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Aug/20 09:39;ll664;Fixed, deploy to prod scheduled in SERVICE-7868.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate SIMU deployment to Ansible ,XP-3430,98975,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ei349,ei349,17/Aug/20 14:14,15/Sep/20 09:56,22/Feb/21 13:26,02/Sep/20 11:35,,,3.1.1,,,,,,,TechOps,,,,"h1. Simulation deployed by Ansible 

Create inventory for SIMU (devs jointly with TOs)

Get inspired by another doublesided environment and adapt it on SIMU

Create vault entries - TECHOPS (devs can support them with file template for values) 

Hints:
 * first two topic can be done by devs and reviewed by TOs
 * Do the dry run and see how much it differs from current simu

h2. Acceptance Criteria
 * script release candidate for deployment to SIMUlation ",,ei349,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c009",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3430-apache-syt,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Aug/20 12:18;iv732;Checking the script from Franta","01/Sep/20 08:12;iv732;
Copied Jenkins pipeline from ""selfservice""
Added missing vault entries.
Did ""dry run"" several times, still had errors",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Report Tool to alerting when the instance is down,XP-3425,98965,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ll664,ll664,17/Aug/20 12:20,08/Dec/20 13:11,22/Feb/21 13:26,01/Dec/20 15:29,,,,,,,,,,TechOps,,,,"Currently, there are no alerts if any Report Tool instance is down, add it.

 

Health endppoint: {{/actuator/health}}",,hw120,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7084800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3438,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdn8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Xbops Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/20 15:28;hw120;Implemented and deployed some time ago, to be sure I just tested it by stopping report-tool1 instance on syt1 to see alerts, you can see them in xbid_alert_syt channel.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
migrate xbid PERF env to ansible deployment ,XP-3420,98958,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,17/Aug/20 10:45,30/Sep/20 11:37,22/Feb/21 13:26,11/Sep/20 15:31,,,3.1.2,,,,,,,,,,,reuse script for vault entries which should be delivered as part of XP-3419,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16329600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdgg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
migrate xbid DST env to ansible deployment,XP-3419,98957,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,17/Aug/20 10:44,27/Aug/20 10:22,22/Feb/21 13:26,24/Aug/20 15:38,,,3.1.1,,,,,,,TechOps,,,,"* Steps needed:
 ** Inventory, vault entries, deployment, troubleshooting errors

 
 * should be similar to syt2 env
 * create script for creating all required vault entries, which can be reused for other env including customer facing ones

AC:
 * DST deployable by Ansible 
 * generic parametrized script for creating vault entries ready",,eg288,,,,,,,,,,,,,,,,,,,,XP-3420,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15724800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbp:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Aug/20 11:50;eg288;generic parametrized script for creating vault entries location: *energy.automation.inventory/bin/xbid-env-vault-secrets-init.sh*
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate all ansible playbooks which uses pmi user to tomcat user,XP-3418,98946,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,eg288,eg288,14/Aug/20 16:35,30/Sep/20 11:37,22/Feb/21 13:26,03/Sep/20 13:50,,,3.1.2,,,,,,,Waiting-Internal,waiting-techops,,,"Playbooks deploy_xbreporttool and deploy_xbamr uses pmi user, but user tomcat should be used instead. As discussed with ops team (Niklas Albers) all customer facing environments including SIMU and PROD uses tomcat only. The pmi user is not available there and playbooks using pmi user would fail there.

Steps:
1) change owner of /xbid on xbsytsla1 to tomcat
2) update the playbooks to run under tomcat user
3) for discussion: remove /xbid/xbid-syt1-ams1 directory, I think the ams is now deployed to another VM and this is no l;onger used",,eg288,ek176,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14860800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdqk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Aug/20 14:10;ek176;The AMS runs on {{xbsyt1ams1}} (ixe) {{// inventory/xb/xbid/syt1/xbams/main.yml}}","21/Aug/20 14:27;ek176;[~ek176] [~iv732]: Please perform the following (SYT1):

Related Jenkins: [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-full-ansible-deploy/]

 
 # Wait on PR ready: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1048]
 # Announce and check that RT can be redeployed/restarted (nobody uses it on SYT1)
 # Stop the ReportTool on SYT1
 # On {{xbsyt1sla1}} host exec: *{color:#403294}{{chown -R tomcat:tomcat /xbid}}{color}*
 # Merge the PR above
 # Redeploy and start RT on SYT1","02/Sep/20 12:25;ek176;The PR has been merged with the SIMU deployment (Sept, 2nd)

[~iv732] Please change the owner of the /xbid directory on xbsyt1sla1 host","03/Sep/20 09:59;iv732;[~ek176] owner updated. Are you going to deploy RT?

{code:java}
[root@xbsyt1sla1 ~]# chown -R tomcat:tomcat /xbid
[root@xbsyt1sla1 ~]# ls -al /xbid
total 48
drwxr-xr-x  9 tomcat tomcat  4096 Aug 31 10:57 .
dr-xr-xr-x 19 root   root    4096 Sep 10  2018 ..
drwxrwxr-x  6 tomcat tomcat  4096 Mar  2  2020 backup
drwxr-xr-x 10 tomcat tomcat  4096 Aug 11 14:23 logs
drwx------  2 tomcat tomcat 16384 Sep 10  2018 lost+found
drwxr-xr-x  4 tomcat tomcat  4096 Aug 31 10:58 xbid-syt1-amr1
drwxr-xr-x  2 tomcat tomcat  4096 Mar 25 12:49 xbid-syt1-ams1
drwxr-xr-x  3 tomcat tomcat  4096 Aug 26 10:55 xbid-syt1-report-tool
drwxr-x---  3 tomcat tomcat  4096 Aug  4 12:45 xbid-syt1-report-tool.bkp

{code}
","03/Sep/20 13:20;ek176;Issue with master.elector value fixed by [~eg288] 

RT Redeployed, runninng.","03/Sep/20 13:27;ek176;[~iv732] Please remove the directory:

Host: {{xbsyt1sla1}}

Directory: {{/xbid/xbid-syt1-ams1}}

 

The AMS currently runs on different machine (xbsyt1ams1).

Then, the ticket can be closed:

{{[tomcat@xbsyt1sla1]$ ps -U tomcat -f |grep java }}
{{*tomcat*    19839  19836  0 12:32 ?        00:00:20 java -jar am-reporting.jar -DinstanceName=xbid-syt1-amr1 }}
{{*tomcat*    26687  26686  3 13:14 pts/2    00:00:22 java -jar report-tool-24-7.jar -DinstanceName=xbid-syt1-report-tool}}","03/Sep/20 13:50;iv732;Directory removed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split2) Ansible - make the jenkins form more usable,XP-3414,98928,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,14/Aug/20 09:54,01/Sep/20 12:18,22/Feb/21 13:26,27/Aug/20 15:28,,,3.1.1,,,,,,,,,,,Try to do some checkboxes that checks other checkboxes and so on. Currently there are too many form inputs to fill in,,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3439,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16588800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bd9s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate XBID modules with HP Fortify,XP-3413,98926,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,14/Aug/20 09:30,31/Aug/20 15:38,22/Feb/21 13:26,19/Aug/20 14:59,,,3.1.1,,,,,,,,,,,"- set HP Fortify quality gate to develop and acceptance (if applicable)

The following should be covered in the end
{noformat}
name: AID292_XBID_Access_Management version: ACCEPTANCE
name: AID292_XBID_Access_Management version: DEVELOP
name: AID292_XBID_AM_Reporting version: DEVELOP
name: AID292_XBID_Acer_Reporting version: DEVELOP
name: AID292_XBID_Report_Tool version: DEVELOP
name: AID292_XBID_ComTrader version: ACCEPTANCE
name: AID292_XBID_ComTrader version: DEVELOP
name: AID292_XBID_PMI_Archiving version: ACCEPTANCE
name: AID292_XBID_PMI_Archiving version: DEVELOP
name: AID292_XBID_PMI_Logger version: ACCEPTANCE
name: AID292_XBID_PMI_Logger version: DEVELOP
name: AID292_XBID_Shipping version: ACCEPTANCE
name: AID292_XBID_Shipping version: DEVELOP
name: AID292_XBID_Reporting_Engine version: ACCEPTANCE
name: AID292_XBID_Reporting_Engine version: DEVELOP
name: AID292_XBID_Main version: ACCEPTANCE
{noformat}",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3245,XP-3244,XP-3243,XP-3242,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16588800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bd58:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2979-postgresql,XP-3345-version-bump,XP-3361,develop,XP-3345,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master-acceptance,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,acceptance,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tomcat - invalid AJP configuration after upgrade to version 8.5.57,XP-3407,98904,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,13/Aug/20 12:49,20/Aug/20 08:02,22/Feb/21 13:26,14/Aug/20 15:08,,,3.1.1,,,,,,,,,,,"AJP configuration in server.xml must use setting secretRequired=""false"". Currently the AJP connector fails to initialize and the tomcat instance is not accessible from apache http server.

catalina.out snippet:
{code}
26-May-2020 13:37:00.888 SEVERE [main] org.apache.catalina.core.StandardService.startInternal Failed to start connector [Connector[AJP/1.3-8010]]
        org.apache.catalina.LifecycleException: Protocol handler start failed
                at org.apache.catalina.connector.Connector.startInternal(Connector.java:1057)
                at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)
                at org.apache.catalina.core.StandardService.startInternal(StandardService.java:440)
                at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)
                at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:766)
                at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)
                at org.apache.catalina.startup.Catalina.start(Catalina.java:688)
                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
                at java.lang.reflect.Method.invoke(Method.java:498)
                at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:343)
                at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:474)
        Caused by: java.lang.IllegalArgumentException: The AJP Connector is configured with secretRequired=""true"" but the secret attribute is either null or """". This combination is not valid.
                at org.apache.coyote.ajp.AbstractAjpProtocol.start(AbstractAjpProtocol.java:274)
                at org.apache.catalina.connector.Connector.startInternal(Connector.java:1055)
                ... 12 more
{code}",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bd54:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade kotlin to 1.4.0 due to HIGH vulnerability CVE-2020-15824,XP-3400,98830,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jy268,jy268,11/Aug/20 16:11,06/Nov/20 11:34,22/Feb/21 13:26,02/Sep/20 11:02,,,3.1.1,,SLA Report Tool,,,,,Tech-Debt,,,,"Update: The 1.4.0 ver is available since Aug, 14.

During development we have found that there is severe vulnerability in kotlin <1.4.0 version. It appeared in report-tool but probably will appear in other applications as well. 

Please remove CVE-2020-15824 from suppressions and upgrade kotlin to 1.4.0: [https://mvnrepository.com/artifact/org.jetbrains.kotlin/kotlin-stdlib]

vulnerability described: [https://nvd.nist.gov/vuln/detail/CVE-2020-15824]
 * suppressed also in xbid project

 

Note: Kotlin is used in other projects as well, consider updating (followup ticket):
 * Giant Ant-Eater (*g) (already done)
 * SPM (+)
 * ComTrader (+)
 * XBID (+)
 * Routing-benchmark (+) (OWASP plugin not in use)
 * m7.dataset-generator (+)
 * TestClient (+)
 * ReportTool (+)
 * Xbid-Test (+) (OWASP plugin not in use)
 * m7.alarmtilt-adapter (*g)
 * ReportingEnigne (*g) (false alarm)
 * xbid-perf-tools (+) (OWASP plugin not in use)
 * energy.resource-management (+)

 

Legend:
 * (/) Released, refs updated in relevant projects (i.e. XBID, SPM)
 * (+) Merged, not released
 * (*) Waiting review/merge
 * (*g) No update needed (false alarm)",,ek176,jy268,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3555,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14342400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,acceptance,XP-4155-npe-fix,XP-4276-split-io,XP-4276-new-format,XP-4526-resource-managment-fix,develop,XP-3230,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Sep/20 10:58;ek176;NO real testing is needed, as there was no functional change. 

The only smoke test should be performed on ReportTool – as there was an upgrade of elasticsearch library.","02/Sep/20 11:01;tr866;Smoke tests were executed on environment Syt1 with versions XBID 3.1.5, SPM 3.1.2.
No unexpected suspcious behaviour was observed in SOB,CMM,SPM that could be related to the upgrade.","09/Sep/20 14:10;ek176;OWASP Maven plugin reports the vulnerability again (false positive). Suppressed in GAE, created follow-up ticket XP-3555.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cherry-pick XP-2467 from losses branch and test CMM/CMI reports labeling,XP-3396,98817,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,qo794,qo794,11/Aug/20 10:57,20/Aug/20 08:02,22/Feb/21 13:26,17/Aug/20 16:25,,,3.1.1,,CMM,,,,,,,,,"CMM/CMI reports confidential labeling already implemented within XP-2467, but it's only in the losses branch.

h4. TODO
* cherry pick XP-2467 changes from the losses branch to develop
* test CMM/CMI reports contain a confidential label

h4. Acceptance criteria
* all CMM/CMI XML reports contain the following confidential label (additionally to XP-2467 also PCF files):
{code:xml}
<!-- The information displayed hereby are classified as: CONFIDENTIAL -->
{code}
* all CMM CSV reports contain the following confidential label, see the example for the Messages report:
{code}
""Message History Report for border FR-DE from 02.03.2020 till 03.03.2020 created 2020-03-02 16:35:10 (CET) by QA-BAL-ALL-----MADM002. The information displayed hereby are classified as: CONFIDENTIAL""
{code}",,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/20 16:23;od044;20180215_ATCValuesreport_50HzT-AMP_20180215164605.csv;https://jira.deutsche-boerse.com/secure/attachment/86509/20180215_ATCValuesreport_50HzT-AMP_20180215164605.csv","17/Aug/20 16:23;od044;20180215_ATC_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86519/20180215_ATC_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_ActivityReport_50HzT-AMP_20180215164607.csv;https://jira.deutsche-boerse.com/secure/attachment/86508/20180215_ActivityReport_50HzT-AMP_20180215164607.csv","17/Aug/20 16:23;od044;20180215_BalancingGroupReport_50HzT-AMP_20180215164609.csv;https://jira.deutsche-boerse.com/secure/attachment/86506/20180215_BalancingGroupReport_50HzT-AMP_20180215164609.csv","17/Aug/20 16:23;od044;20180215_IAR-I_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86518/20180215_IAR-I_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_NSF_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86516/20180215_NSF_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_NetPI_10YPT-REN------W_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86515/20180215_NetPI_10YPT-REN------W_001.xml","17/Aug/20 16:23;od044;20180215_NetPX_10YES-REE------0_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86514/20180215_NetPX_10YES-REE------0_001.xml","17/Aug/20 16:23;od044;20180215_OCC_ES-PT_EXPL_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86517/20180215_OCC_ES-PT_EXPL_001.xml","17/Aug/20 16:23;od044;20180215_RCA_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86513/20180215_RCA_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_RID_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86512/20180215_RID_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_TAR_ES-PT_001.xml;https://jira.deutsche-boerse.com/secure/attachment/86511/20180215_TAR_ES-PT_001.xml","17/Aug/20 16:23;od044;20180215_UserReport_50HzT-AMP_20180215164612.csv;https://jira.deutsche-boerse.com/secure/attachment/86507/20180215_UserReport_50HzT-AMP_20180215164612.csv","17/Aug/20 16:25;od044;ACK_TSMA07-TSMA13_TSDA10-TSVDA1_TSTSO1_NTC_60_T_2_20200616000000.xml;https://jira.deutsche-boerse.com/secure/attachment/86520/ACK_TSMA07-TSMA13_TSDA10-TSVDA1_TSTSO1_NTC_60_T_2_20200616000000.xml","17/Aug/20 16:23;od044;Balancing group_SADMIN03_20180215174801.csv;https://jira.deutsche-boerse.com/secure/attachment/86505/Balancing+group_SADMIN03_20180215174801.csv","17/Aug/20 16:23;od044;Messages_Report_50HzT-AMP_20180215_20180215174603.csv;https://jira.deutsche-boerse.com/secure/attachment/86510/Messages_Report_50HzT-AMP_20180215_20180215174603.csv","17/Aug/20 16:23;od044;Racf_SADMIN03_20180215174809.csv;https://jira.deutsche-boerse.com/secure/attachment/86504/Racf_SADMIN03_20180215174809.csv",,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16243200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bcns:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Aug/20 16:22;od044;Test passed on docker R3.1.3-SNAPSHOT (Build 94e02704cf30fc687adebc595606a50c279dacda)
- all CMI outbound files, ACK file, reports contain label
{code}
The information displayed hereby are classified as: CONFIDENTIAL
{code}

Example can find in attachements
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMI - update generated files query for selection the latest for today/tommorrow,XP-3395,98788,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,hj444,hj444,10/Aug/20 14:02,20/Aug/20 08:02,22/Feb/21 13:26,18/Aug/20 14:44,,,3.1.1,,,,,,,TestAutomation,,,,"Refactor :
- Add possibility to filter generated files 
for cases -when there are more files generated based on settings in FTC - (today, tommorrow),  the latest version for expected date(today/tommorrow is selected,...
xbid-test/test-common/src/main/java/com/deutscheboerse/energy/m7/test/api/v1/db/DatabaseAccessorCmi.java


example actual query:
{code}select * from tbxi710_file_content c 
 join tbxi700_file_header h on c.file_header_id = h.id 
 where h.file_type = 'com.deutscheboerse.energy.cmminteg.filetype.cim.occ.OCC' and h.party_id = '10XDE-RWENET---W' and connector_id = 13
 order by h.id desc limit 1{code}

Query result is the file for next day - with the highest ID
id : 6
name : 20180216_OCC_APG-DE_IMPL_001.xml
create_time : 2018-02-15 16:36:27
date : 2018-02-15 23:00:00

_Update for example_ :
{code}select * from tbxi710_file_content c 
 join tbxi700_file_header h on c.file_header_id = h.id 
 where h.file_type = 'com.deutscheboerse.energy.cmminteg.filetype.cim.occ.OCC' and h.party_id = '10XDE-RWENET---W' and connector_id = 13 
 order by h.date asc, h.id desc limit 1{code} 

 id : 5
create_time : 2018-02-15 16:36:27
name : 20180215_OCC_APG-DE_IMPL_001.xml
date: 2018-02-14 23:00:00",,hj444,,,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16934400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bcnw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-4526-resource-managment-fix,XP-3230,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove schema_version from cx_600_configuration,XP-3394,98785,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,uv683,uv683,10/Aug/20 13:01,05/Feb/21 12:03,22/Feb/21 13:26,05/Feb/21 12:03,,,,,Reporting Engine,Trading,,,,,,,,"For some obsolete reason there is this configuration option with value 4.1.1. It was a comxerv version back in the ancient times. However reporting engine has this SchemaVersionVerifier which is checking at start time if this configuration option is set and contains 4.1.1. but it doesn't make sense anymore for the last couple of years.

 

Remove from reporting-engine and core as well.",,eg288,hj444,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Feb/21 11:45;hj444;DownloadReport_ReportinEngine_05022021.png;https://jira.deutsche-boerse.com/secure/attachment/92390/DownloadReport_ReportinEngine_05022021.png","05/Feb/21 11:44;hj444;RunJobForPeriod_ReportingEngine.png;https://jira.deutsche-boerse.com/secure/attachment/92389/RunJobForPeriod_ReportingEngine.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1468800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0cfxr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 26,HOT Sprint 27 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3394_flyway_standard_implementation,minor-fixups,acceptance,XP-3394_remove_schema_version,XP-3394_acceptance_flyway_standard_implementation,develop,XP-2232,XP-3394_acceptance_remove_unused_maven_properties,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Jan/21 13:48;eg288;Implemented in dvelop branch (version 5.1.x)

To test:
 * test flyway migration
 ** deploy version 5.0.56
 ** then deploy version 5.1.1 which includes this code
 ** verify flyway migration took place (table flyway_schema_history in reporting database includes script V005__drop_table_platform_x_version.sql, it was not there before the 5.1.x deployment)
 * smoke test reporting engine

 ","05/Feb/21 10:50;hj444;Retest :
SYT1
XBID : Version R3.2.4-fad912d6a0f8988766558c3939737894fe94084b
Reporting engine : Version 5.0.56 Platform sob

DB check :  flyway_schema_history table content
Deploy : Version 5.0.56 Platform sob
||installed_rank||	version||	description||	type	script||	checksum||	installed_by||	installed_on||	execution_time||	success||
|1	|1	|create scheduler|	SQL	V001__create_scheduler.sql|	1613983513|	xbsyt1rep|	05/02/2021 09:17|	117	|TRUE|
|2	|2	|create reporting|	SQL	V002__create_reporting.sql|	1818224622|	xbsyt1rep|	05/02/2021 09:17|	17|	TRUE|
|3	|3	|clean setup scheduler|	SQL	V003__clean_setup_scheduler.sql|	-1671647011|	xbsyt1rep|	05/02/2021 09:17|	66|	TRUE|
|4	|4	|clean setup reporting sob-4.1|	SQL	V004__clean_setup_reporting_sob-4.1.sql|	-1310199583|	xbsyt1rep|	05/02/2021 09:17|	147|	TRUE|

Deploy : Version 5.1.1 Platform sob
||installed_rank||	version||	description||	type	script||	checksum||	installed_by||	installed_on||	execution_time||	success||
|1	|1	|create scheduler|	SQL	V001__create_scheduler.sql|	1613983513|	xbsyt1rep|	05/02/2021 09:17|	117	|TRUE|
|2	|2	|create reporting|	SQL	V002__create_reporting.sql|	1818224622|	xbsyt1rep|	05/02/2021 09:17|	17|	TRUE|
|3	|3	|clean setup scheduler|	SQL	V003__clean_setup_scheduler.sql|	-1671647011|	xbsyt1rep|	05/02/2021 09:17|	66|	TRUE|
|4	|4	|clean setup reporting sob-4.1|	SQL	V004__clean_setup_reporting_sob-4.1.sql|	-1310199583|	xbsyt1rep|	05/02/2021 09:17|	147|	TRUE|
|5	|5	|drop table platform x version|	SQL	V005__drop_table_platform_x_version.sql|	775240647|	xbsyt1rep|	05/02/2021 10:38|	6	|TRUE","05/Feb/21 11:42;hj444;Smoke test : Version 5.1.1 Platform sob

SYT1: 
 1. Login int TestClient
 2. Do trades
 3. Login into reporting engine GUI : [https://10.136.143.246:60705/reporting-engine-app/sob/reporting.html] 
 4. Open - Run job for period :
 - Configure:
 -- Name: Subscriber: ADMIN
 -- Set tomorrow date for today reports: Actual date 5.2.2021 -> set in/to will be 06.02.2021

 !RunJobForPeriod_ReportingEngine.png!

5. Add Job - for all 3 reports
 6. Open - Download reports
 7. Verify reports are in list of generated reports
 8. Download reports
!DownloadReport_ReportinEngine_05022021.png!

  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - resolve dependencies between modules,XP-3392,98780,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eh941,eh941,10/Aug/20 11:29,13/Aug/20 19:47,22/Feb/21 13:26,12/Aug/20 10:48,,,3.1.0,,,,,,,,,,,"Currently deployment might fail because of unresolved dependencies between modules. E.g. CMM can't start without having Rabbit artifacts created by core module.

Adjust pipeline in order to respect following dependencies.

{noformat}
Start infrastructure (already there) -> Start XBID core module -> Start Shipping Module Core -> Start the rest
{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16934400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bcgg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Add option to disable several input channels in CMI,XP-3390,98764,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,eh941,eh941,07/Aug/20 13:58,11/Dec/20 15:23,22/Feb/21 13:26,09/Dec/20 14:05,,,3.2.x,,,,,,,,,,,"If the ECP is not configured the log is full of following exceptions:
{noformat}
2020-08-07T11:47:54.001Z [TaskScheduler-6][][] ERROR c.d.e.c.t.e.w.c.ECPMessagingClientDefault - Unknown exception occured when calling ECP WS. .
java.lang.NullPointerException: null
        at org.springframework.ws.transport.http.AbstractHttpWebServiceMessageSender.supports(AbstractHttpWebServiceMessageSender.java:63)
        at org.springframework.ws.client.support.WebServiceAccessor.createConnection(WebServiceAccessor.java:107)
        at org.springframework.ws.client.core.WebServiceTemplate.sendAndReceive(WebServiceTemplate.java:551)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:390)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:383)
        at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:373)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.lambda$marshalSendAndReceive$4(MultiNodeWsTemplate.java:54)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.doWithFallback(MultiNodeWsTemplate.java:110)
        at com.deutscheboerse.energy.commons.transport.ecp.MultiNodeWsTemplate.marshalSendAndReceive(MultiNodeWsTemplate.java:54)
        at com.deutscheboerse.energy.commons.transport.ecp.ws.client.ECPMessagingClientDefault.doReceiveMessage(ECPMessagingClientDefault.java:153)
        at com.deutscheboerse.energy.commons.transport.ecp.ws.client.ECPMessagingClientDefault.receiveMessage(ECPMessagingClientDefault.java:75)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessage(EcpTransport.java:106)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessages(EcpTransport.java:79)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1556)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
        at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
        at com.deutscheboerse.energy.commons.transport.ecp.EcpTransport.receiveMessages(EcpTransport.java:63)
        at com.deutscheboerse.energy.cmminteg.transport.ecp.EcpHandler.receive(EcpHandler.java:59)
        at sun.reflect.GeneratedMethodAccessor147.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)
        at com.deutscheboerse.energy.failover.aop.SkipExecutionIfNotMasterAspect.aroundHandler(SkipExecutionIfNotMasterAspect.java:41)
        at sun.reflect.GeneratedMethodAccessor145.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)

{noformat}
But it doesn't mean the application has a bug inside. Add switch to enable/disable SFTP, ECP, Mail, SCP input channels in CMI, SPM.
 
Acceptance criteria: 
 * possibility to turn on/off input channels in CMI, SPM for all channels (document how it's done and inform developers!)
 ** e.g. property like EcpChannelEnabled=false in the inventory
 * always log information about skipped channel because it's disabled. ",,eh941,ek176,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4238,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6220800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c4g3:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 23,HOT Sprint 24 (S),,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2478-tobago-upgrade-clean02,XP-2478-tobago-upgrade-clean01,XP-4250-develop,develop,XP-2400,master,XP-4250-metrics-integration-test-2,XP-4155-resourcemanagment-upgrade,XP-2478-tobago-upgrade,XP-4250-metrics-integration-test,XP-4277-develop-sonar-test,XP-4211-perf-analysis-develop,fixing-dataset,XP-4211-perf-analysis-develop-jh,XP-761-spooooky-migration-from-grunt-to-webpack,XP-4250-develop-jh,using-no-package-lock-during-npm-install,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Dec/20 15:22;lt112;Added properties for CMI, SMC and SMI
{code}
channels_ecp_enabled: true
channels_mail_enabled: true
channels_scp_enabled: true
channels_sftp_enabled: true
{code}

See related configuration changes https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1269/files",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Elastic health endpoint is evaluated even though the elastic is disabled,XP-3389,98763,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,eh941,eh941,07/Aug/20 13:36,31/Aug/20 13:21,22/Feb/21 13:26,19/Aug/20 11:41,,,3.1.1,,,,,,,,,,,"In the config file there is:

{noformat}
elastic.enabled=False
elastic.username=
elastic.password=
{noformat}

yet there is following health status:

{code:json}
{
   ""status"":""DOWN"",
   ""details"":{
      ""m7"":{
         ""type"":""org.springframework.boot.actuate.health.Health"",
         ""status"":""UP"",
         ""details"":{
            ""master"":true
         }
      },
      ""rabbit"":{
         ""type"":""org.springframework.boot.actuate.health.Health"",
         ""status"":""UP"",
         ""details"":{
            ""ackAmqpTmpl"":{
               ""type"":""org.springframework.boot.actuate.health.Health"",
               ""status"":""UP"",
               ""details"":{
                  ""version"":""3.7.7""
               }
            },
            ""respAmqpTmpl"":{
               ""type"":""org.springframework.boot.actuate.health.Health"",
               ""status"":""UP"",
               ""details"":{
                  ""version"":""3.7.7""
               }
            },
            ""eventAmqpTmpl"":{
               ""type"":""org.springframework.boot.actuate.health.Health"",
               ""status"":""UP"",
               ""details"":{
                  ""version"":""3.7.7""
               }
            },
            ""integAmqpTemplate"":{
               ""type"":""org.springframework.boot.actuate.health.Health"",
               ""status"":""UP"",
               ""details"":{
                  ""version"":""3.7.7""
               }
            }
         }
      },
      ""diskSpace"":{
         ""type"":""org.springframework.boot.actuate.health.Health"",
         ""status"":""UP"",
         ""details"":{
            ""total"":[
               ""java.lang.Long"",
               5150212096
            ],
            ""free"":[
               ""java.lang.Long"",
               3791433728
            ],
            ""threshold"":[
               ""java.lang.Long"",
               10485760
            ]
         }
      },
      ""elasticsearchRest"":{
         ""type"":""org.springframework.boot.actuate.health.Health"",
         ""status"":""DOWN"",
         ""details"":{
            ""error"":""org.elasticsearch.client.ResponseException: method [GET], host [https://elasticsearch.energy.svc.dbgcloud.io:443], URI [/_cluster/health/], status line [HTTP/1.1 401 Unauthorized]\n{\""error\"":{\""root_cause\"":[{\""type\"":\""security_exception\"",\""reason\"":\""unable to authenticate user [] for REST request [/_cluster/health/]\"",\""header\"":{\""WWW-Authenticate\"":[\""Bearer realm=\\\""security\\\""\"",\""ApiKey\"",\""Basic realm=\\\""security\\\"" charset=\\\""UTF-8\\\""\""]}}],\""type\"":\""security_exception\"",\""reason\"":\""unable to authenticate user [] for REST request [/_cluster/health/]\"",\""header\"":{\""WWW-Authenticate\"":[\""Bearer realm=\\\""security\\\""\"",\""ApiKey\"",\""Basic realm=\\\""security\\\"" charset=\\\""UTF-8\\\""\""]}},\""status\"":401}""
         }
      }
   }
}
{code}",,eh941,ek176,,,,,,,,,,,,,,,,,,,,,,,,,XP-3299,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16156800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:zz",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3443-rounding,cpm,why-optional,XP-3829-routing-integration,acceptance,ramping-analysis,develop,XP-3520-ramping_analysis,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Aug/20 15:38;ek176;The current default value (${{{elastic.enabled:true}}}) has been preserved.

Note that {{@ConditionalOnProperty(...  matchIfMissing = true)}} is used. 

In case the default value is to be changed, remember to update both places ({{ElasticConfig}} class)","19/Aug/20 09:28;ek176;Actual behaviour:
||elastic.enabled property||/health||/health elasticRest node||Note||
|False|{{{""status"": ""UP"",}}
{{  ""components"": {}}
{{      ...,}}
{{      ...}}
{{  }}}
{{}}}|<missing>|---|
|True|{{{""status"": ""DOWN"",}}
{{  ""components"": {}}
{{      ...,}}
{{      ""elasticRest"": {}}
{{        ""status"": ""DOWN"",}}
{{        ""details"": { }}{{""error"": ""...."" }}{{}}}
{{      },}}
{{      ...}}
{{  }}}
{{}}}|<present>|---|
|<missing>|Same as True|<present>|Default value (true) used|
|<invalid>|N/A|N/A|Core startup fail: {{IllegalArgumentException: Invalid boolean value}}|",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA Report tool - template modification - Credit Points,XP-3388,98756,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,zi174,zi174,07/Aug/20 09:51,20/Aug/20 17:21,22/Feb/21 13:26,14/Aug/20 10:02,,,3.1.1,,,,,,,,,,,"Please use the newest template for Credit Points report 

 
 * fixed wrong naming - instead of PX we need to use NEMOs",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Aug/20 09:56;zi174;credit-points-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/86327/credit-points-report.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17193600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bd24:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
E2E pipeline does not support 'acceptance' branch,XP-3387,98751,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ll664,ll664,ll664,07/Aug/20 09:21,14/Dec/20 14:54,22/Feb/21 13:26,14/Dec/20 14:54,,,,,,,,,,,,,,https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy%2Fxbid-end-to-end-dynamic-pipeline/detail/xbid-end-to-end-dynamic-pipeline/1159/pipeline,,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,5961600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bcag:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/20 10:02;ei349;Dear [~ll664], can you please check if it's still needed? ","14/Dec/20 14:53;ll664;Checked, works with {{acceptance}}, closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kapacitor alerts for XBID Report Tool Jobs,XP-3382,94259,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ll664,ll664,06/Apr/20 15:49,08/Dec/20 12:54,22/Feb/21 13:26,25/Nov/20 18:02,,,,,,,,,,MONITORING,TechOps,,,"We have a couple of batch jobs that run every day and we'd like to received alerts on Slack ({{#xbid_prod_alerts}}) everytime the job fails or its status is not reported (deadman).

The data are already ready in influx measurement {{metrics_xbid.autogen.report_tool_jobs}}.

Based on the discussion with [~hw120], the idea is following:

* a job fails if {{status}} field reports value other than 0
* let's have a kapacitor batch alert that checks the statuses every 30 minutes for last 24 hours
* deadman alerting - should be grouped by {{jobName}}, i.e. that particular job did not report its status for last 24 hrs

I'll also try to prepare Influx queries and paste here.

https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/report-tool-jobs?orgId=4",,hw120,ll664,qo794,,,,,,,,,,,,,,,,,,XP-3798,,,,,,,,,,,,,,,XP-2534,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"Prod will be redeployed with new service request, together with monitoring as it requires change of ansible inventory.",,,,,,,,,,,,,,7603200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c09i000000000000000a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),HOT Sprint 16 (S),HOT Sprint 17,HOT Sprint 18 (S),HOT Sprint 19,HOT Sprint 20 (S),Xbops Sprint 22,Xbops Sprint 23,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,XP-3382,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Apr/20 09:09;ll664;I tried to come up with queries for following scenarios.

h4. Alerts on failing jobs
{code}
SELECT ""status"" FROM ""metrics_xbid"".""autogen"".""report_tool_jobs"" WHERE time > :dashboardTime: AND time < :upperDashboardTime: AND ""client""='xbid' AND ""client_environment""='prod' GROUP BY ""jobName"", ""instance""
{code}

Returns job status per job and instance. We should have alert anytime a there is a job with status != 0.

h4. Deadman alerts

It would be good to have alerts when there is no job status reported, say in last 24 hours - indicating that the node is down or something went wrong with the job itself. This should be grouped by jobName and instance as well (probably).

","07/Jul/20 17:52;hw120;Alert on failing job is prepared and deployed

https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1200/files/

Deadman alert I will prepare when I return from holiday.","19/Aug/20 00:34;hw120;We are getting multiple alerts seems false-positive, like this one every night
{quote}WARNING on xbid - prod - sla1 - collect-performance-kpi-data | XBID Report Tool job status
{quote}
My assumption is that it might be related to a different time when the report metric is generated. For example, one day it is generated at 2:16 but the next day it is at 2:32. We have data window of 24h so when alert is triggered 2:30, it has zero values. Therefore I increased window to 28h to see how it will behave.

Alert change is deployed, waiting to see how it will behave.","19/Aug/20 14:32;hw120;It didn't helped, but all queries manually run returns correct values.

 

Trying to remove alignGroup query parameter

[https://docs.influxdata.com/kapacitor/v1.5/nodes/query_node/#aligngroup]

Deployed, we will see if it would help tomorrow.","31/Aug/20 12:36;hw120;Extended alert window to 30h, it seems it helped with repeating false-positive alerts:
{quote}WARNING on xbid - prod - sla1 - collect-performance-kpi-data | XBID Report Tool job status{quote}
{quote}WARNING on xbid - prod - sla2 - collect-performance-kpi-data | XBID Report Tool job status{quote}
I have to check if today's new alerts are relevant.","23/Oct/20 08:51;qo794;Extending the check window did not help to get rid of false alarms.

I've briefly checked the kapacitor and telegraf scripts and I think mapping job status COMPLETED to 0 (OK) and others to 1 (FAILURE) does not work very well. Also STARTING and STARTED should be treated as 0. A job status can have the following values COMPLETED, STARTING, STARTED, STOPPING, STOPPED, FAILED, ABANDONED or UNKNOWN; where everything ""higher"" than STARTED signifies more serious failure.

Then also the kapacitor script should be modified, instead of using {{mean}} functions there should be {{last}} function:
{code}
var query = batch
  |query('''
    SELECT mean(""status"") AS mean
    FROM ""{{ item[1] }}"".""autogen"".""report_tool_jobs""
    ''')
    .groupBy('product', 'client_environment', 'client', 'jobName', 'instance')
    .period(period)
    .every(every)
    .fill('none')
    .alignGroup()
  |httpOut('points')
{code}

Or we can use real job status values instead of 0/1, but that would mean more changes, also in Grafana charts.
","03/Nov/20 00:09;hw120;Changed mean() to last() and deployed, we shall see if it helps, but I guess it could.","03/Nov/20 11:07;qo794;The mapping of job status to 0/1 is done completely in the application, so a code change, release and deployment are needed. I'll fix that in the application.","03/Nov/20 12:30;qo794;The mapping of job status fixed in:
* report-tool v2.51
* am-reporting v1.0.5
* acer-reporting v1.0.2

[~hw120] you can test kapacitor change together with the new version of report-tool.","04/Nov/20 23:34;hw120;* Deployed latest versions of amr, acr and report-tool to syt1
 * Updated and cleaned inventory for it to work
 * Updated telegraf deployment to include all 3 services
 * Deployed telegraf there for all 3 services

All seems to be fine, [~qo794] please check.","25/Nov/20 17:07;hw120;Environments where it is running
 * report-tool: syt1, perf, cute, lipa, lipb, simu, prod
 * amr: syt1, ctso, cute, lipa, lipb, simu, prod
 * acr: syt1, simu, prod

SYT1 and SIMU are done, telegraf and new versions with the fix are there.

Everywhere else I deployed only telegraf.

For prod there will be new service request from [~qo794] for acr and report-tool. AMR can't be deployed yet, not untill UAT ends.

For all other cute environments we don't care, as no alerting is necessary and customers don't need it.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare new consul enterprise test cluster - test new version and update ansible deployment,XP-3381,91682,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,30/Jan/20 15:52,24/Nov/20 00:03,22/Feb/21 13:26,01/Sep/20 12:47,,,3.1.1,,,,,,28/Feb/20 00:00,Consul,TechOps,,,"We had network structure change in the meantime, so we have new VMs to migrate to.
 * Get and upload new consul binaries to artifactory
 * Upgrade from consul 1.6.2 to 1.8.3, study changes
 * We need to update ansible role with changes for actual consul version - there are security fixes as well as fixes for network segmentation we are using
 * Implement changes to enable collecting monitoring metrics
 ** [https://learn.hashicorp.com/tutorials/consul/monitor-health-telegraf]
 * Test deploy to aws instances to check if all works as expected
 * Update documentation

 ",,hw120,,,,,,,,,,,,,,,,,,,,XP-3322,,,,,,,,XP-3513,,,,,,,SYSENGEXT-74,M7P-6004,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bbbp:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/Jan/20 15:52;hw120;[10:46|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580291172002000]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
Hello, we are planning to migrate all test patroni postgres instances to consul enterprise, and I would like to ask how would patroni behave when we stop the cluster, replace consul cluster with the new one, update tokens in configs and then start patroni cluster.
 
 
[10:46|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580291215002900]
Would it work or not? Would it require some kind of initialization of k/v store - config files stored in consul?
 
 
[10:47|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291233003100]
{color:#9f69e7}[Hans-Jürgen Schönig|https://app.slack.com/team/UB96YF59N]{color} 
[@Ants Aasma|https://dbg-devops.slack.com/team/UCUEBS6L9]
 
 
[10:49|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291361005500]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
If taking the cluster offline is an option that approach will work fine. If you are not taking the application offline make sure to bring up nodes in the reverse order from shutdown to prevent any lost transactions.
 
 
[10:49|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291392006200]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
Patroni maintains a copy of the config stored in consul and will replay that into a New, empty, consul store
 
 
[10:49|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291393006400]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
The first node to connect to consul will re-initialize all settings from locally cached information.
 
 
[10:51|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291466007700]
It's also possible to migrate with no downtime, that requires that Patroni pause mode is turned on before starting the change and then turned off with resume after everything is migrated.
 
 
[10:52|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580291520008600]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
but will it pick up change in patroni config like consul token?
 
 
[10:52|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291552009100]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
Just reload or restart patroni then
 
 
[10:53|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580291581010000]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
so first pause, then reload and then resume?
 
 
[10:55|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291716011900]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
Yes. That *should* work, but if possible test that procedure on a non-production first. I personally haven't verified that it works correctly, so if there is something that we are missing you may end up with a bit of downtime.
 
 
[10:57|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580291851013800]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
I was about to add: all of this assumes that consul enterprise uses the same protocol as Standard consul !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/1f642.png!
I would just assume that, but it should be very easy to try this with a scratch patroni cluster (edited) 
 
 
[11:03|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580292208019200]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
Also: you need to make sure that you change the consul section for All members on a cluster and do a reload in all of them...
Otherwise, if you mistakenly stop maintenance mode on a not yet migrated member, then it might promote itself to a database leader, because the already migrated member is invisible to the not migrated one, because it can't see that one
 
 
[11:03|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580292227019600]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
yes, it is the same, we already use consul enterprise with m7simupdbX and m7prodpdbX servers
 
 
[11:09|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580292544019800]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
Good !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/1f44d.png!
 
 
[11:16|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580292961020500]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
hmm, but if consul token change would require restart of patroni, wouldn't it also restart postgres instances?
 
 
[11:16|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580292983021000]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
When pause mode is activated a shutdown of Patroni doesn't shut down postgres
 
 
[11:16|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580293012021800]
When advocating for this feature I actually called it maintenance mode
 
 
[11:17|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580293030022200]
{color:#bb86b7}[Peter Pruchnerovic|https://app.slack.com/team/U7289MAM9]{color} 
we would have to migrate also xbidsimu and xbprod pdb servers, but we should first test migration on test env
 
 
[11:17|https://dbg-devops.slack.com/archives/CC9M54FDE/p1580293048022700]
it would be super cool if we would find a safe way to migrate without downtime
 
 
[11:19|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580293155023600]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
It is safe as long as there is no hardware or human failure in the process
 
 
[11:24|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580293466024300]
{color:#e0a729}[Julian Markwort|https://app.slack.com/team/UBF4FFSV7]{color} 
I don't even think you have to restart patroni, a reload should be fine
 
 
[11:25|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580293518025500]
It should use the new configuration for the next loop Iteration after the reload
 
 
[11:26|https://cybertecpostgresql.slack.com/archives/CC9M54FDE/p1580293592026800]
{color:#9b3b45}[Ants Aasma|https://app.slack.com/team/UCUEBS6L9]{color} 
So the process would be: # patronictl pause
 # Change config and reload patroni service on ALL cluster members.
 # Verify using patronictl list that all members have registered themselves in the new consul
 # patronictl resume","12/Aug/20 15:57;hw120;Got new consul enterprise version binaries and pushed to artifactory, prepared how to for it.

https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Downloading+Consul+Enterprise+Binaries+and+putting+them+into+artifactory","19/Aug/20 00:38;hw120;Merged changes from upstream consul ansible role

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1040]

Have to test it now.","01/Sep/20 09:56;hw120;Issue split into:
|XP-3513|(Split 2) Prepare new consul enterprise test cluster - deployment on internal test env|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Ansible - rabbitmq cluster,XP-3380,98689,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,05/Aug/20 13:31,20/Aug/20 08:02,22/Feb/21 13:26,14/Aug/20 09:54,,,3.1.1,,,,,,,,,,,must support the both 3 node cluster and 1 node.,,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17366400,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bb90:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove H1 2020 ACER reports from the sftp server,XP-3377,98686,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,qm925,qm925,05/Aug/20 12:43,12/Aug/20 11:02,22/Feb/21 13:26,12/Aug/20 11:02,,,Not a release,,,,,,,TechOps,,,,The ACER Reports for H1/2020 can be removed already from the SFTP server. ,,iv732,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16761600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/20 10:56;iv732;Done.


{code:java}
for px in cropex epex gme hupx np omie opcom ote tge; do rm -f /opt/data01/xbid_${px}_prod/OUT/acer/acer_h1_2020_v3.zip; done
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Application labeling: e-mails,XP-3375,98667,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,zi174,qo794,05/Aug/20 10:18,13/Aug/20 19:40,22/Feb/21 13:26,05/Aug/20 10:18,,,3.1.0,,,,,,,,,,,"According to the data leakage standard, it's necessary to label all documents, reports, GUI etc. which are visible/send to the customer. We have to provide an information of the security classification (public, internal, confidential, strictly confidential)

· All DBG documents, physical and electronic, must be labelled based on the confidentiality of included information.

· DBG strictly confidential and confidential information shall only be disclosed outside DBG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement.

!screenshot-1.png!

Affected areas:

*Emails*
 * all emails sent to the customer need labeling - preliminary consideration is to set this label in email client - just keep in mind that the email must have a same classification as sent file/document

 - 5SPs

*If applicable

 

-Note: This might be solved on the e-mail server level. See M7P-4732-

Note2: Tell BizOps ([~ub113], [~yn731]) to include it in the list for informing our customers. 

------------------------------------------------------
Affected projects and modules:
* xbid (core, cmm, cmi, sob)
* access-management (AMS aka GA)
* m7-shipping (smc, smi)",,qo794,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3372,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17366400,,,,,,,,,,,,,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b9on:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID-XP Cloning - missing environment field during the cloning,XP-3373,98655,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Fixed,ub113,ei349,ei349,05/Aug/20 09:00,18/Sep/20 15:45,22/Feb/21 13:26,18/Sep/20 15:45,,,Not a release,,,,,,,,,,,PPO - what about field environment (in support tickets). Transfer from entry JIRA projects to XP might bring better overview? eg. https://jira.deutsche-boerse.com/browse/XBID-5090 a https://jira.deutsche-boerse.com/browse/XP-2982,,dm700,ei349,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15033600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bby8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/20 14:56;ei349;thanks for help","06/Aug/20 14:55;ub113;Hello [~ei349]

This is fixed. Please verify that field XBID Environment is cloned from XBID project.

Also, I noticed that we are using two different fields ([Environment] and Xbid Environment) in XP project to set environments and we might want to correct that.","01/Sep/20 12:14;ei349;thanks a lot. Please fill spent story points and close the ticket. 

we will follow up on the meeting this week. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Inform customers about labeling,XP-3372,98651,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ub113,ei349,ei349,05/Aug/20 08:16,01/Sep/20 12:19,22/Feb/21 13:26,01/Sep/20 12:18,,,3.1.0,,,,,,,BizOps,,,,"Gather information from development about labeling impact. (emails, reports, messages, ...)

Draft an ticket for informing customers about this change and send it to PO and ACM for review. 

 

Hint: check - XP-3331

 ",,ei349,qm925,ub113,,,,,,,,";01/Sep/20 12:18;ub113;5400",,,0,5400,,,0,5400,,,,,,,,,,,,,XBID-5198,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bby6:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Aug/20 10:55;ub113;Hello [~ei349] [~qm925]

Find my draft below:

_Dear Vladimir Satek, dear Lindsay Noble, dear Camilla Vedeler, dear OPSCOM Members,_
 _According to the data leakage standard, all DBG documents, physical and electronic, must be labelled based on the confidentiality of included information._ 
 _*Solution:*_
 _Text ""The below email is classified as Confidential"" added at the beginning of all emails sent from XBID Core, CMM, CMI, SOB, SMC, SMI, AMS._ 
 _*Impact:*_
 _DBAG strictly confidential and confidential information shall only be disclosed outside DBAG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement._
 _*Implementation:*_
 _This change will be implemented with R.3.1_

 

Do we need to provide the classification for the customers too (regarding Public, Internal, Confidential, Strictly Confidential emails)? ","06/Aug/20 11:30;qm925;Yes, the classification is needed. Also, for all emails/reports etc coming from the system, how do we apply the labels (e.g. the SLA reports - are they always going to be labelled as confidential, is this done automatically?)","06/Aug/20 11:40;ub113;Hi [~qm925]

SLA reports are currently shared via IMT ticket - please see {color:#1d1c1d}SMXBID-1977{color}.

Emails that we send out of the mailbox must have a same classification as sent file/document. I am not sure that this falls under the scope of the development, they focused only on automatic emails and reports sent from the application itself.","06/Aug/20 11:45;qm925;Hi Ana, the way of distribution shouldn't matter. In the text above it is mentioned that this change will impact all DBAG documents - physical and electronic (including reports) Furthermore, the Service Boundaries report and the Performance report are generated by the system, so they will have a label.","07/Aug/20 10:18;ub113;Hello [~ei349] [~qm925]

I updated the draft for this topic. Please keep in mind that classification is quoted from an internal document (Data Leakage Prevention) so it might need modification.

_Dear Vladimir Satek, dear Lindsay Noble, dear Camilla Vedeler, dear OPSCOM Members,_

_According to the data leakage standard, all DBAG documents, physical and electronic, must be labelled based on the confidentiality of included information._

_Four labels are used in DBAG:_

_o            Public: Information intended & authorized for general use inside & outside DBAG._

_o            Internal: Information, which is intended for use only within projects & organizational context._

_o            Confidential: Sensitive information intended for use only by a restricted group of people._

_o            Strictly Confidential: The most sensitive information intended for the use within a very limited group of people on management level. Typically protected by regulation, law._

_*Solution:*_

_Text ""The below email is classified as Confidential"" added at the beginning of all emails sent from XBID Core, CMM, CMI, SOB, SMC, SMI, AMS._

_*Impact:*_

_DBAG strictly confidential and confidential information shall only be disclosed outside DBAG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement._

_*Implementation:*_

_This change will be implemented with R.3.1_","10/Aug/20 09:02;ei349;Hi [~ub113] , some minor changes to make it more generic. Customers don't know about exact security standards in DBAG, they just know that we have something like this. Labeling is also not only for emails but for majority of our printable documents. See updated wording below. [~qm925], can you also have a look on updated proposal please? 

-------

 

_Dear Vladimir Satek, dear Lindsay Noble, dear Camilla Vedeler, dear OPSCOM Members,_

_According to the DBAG obligatory security standards, all DBAG documents, physical and electronic, must be labelled based on the confidentiality of included information._

_Four labels are used in DBAG:_

_o            Public: Information intended & authorized for general use inside & outside DBAG._

_o            Internal: Information, which is intended for use only within projects & organizational context._

_o            Confidential: Sensitive information intended for use only by a restricted group of people._

_o            Strictly Confidential: The most sensitive information intended for the use within a very limited group of people on management level. Typically protected by regulation, law._

_*Solution:*_
 * _Text ""The below email is classified as Confidential"" added at the beginning of all emails sent from XBID Core, CMM, CMI, SOB, SMC, SMI, AMS._
 * _Majority of printable documents generated from XBID solution might contain ""Confidential"" label._ 

_*Impact:*_

_DBAG strictly confidential and confidential information shall only be disclosed outside DBAG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement._

_*Implementation:*_

_This change will be implemented with R3.1._","12/Aug/20 15:31;ei349;update. Can you please [~ub113] and [~qm925] review? 

------

 

Dear Vladimir Satek, dear Lindsay Noble, dear Camilla Vedeler, dear OPSCOM Members,

According to mandatory security standards, all DBAG documents, physical and electronic, must be labelled based on the confidentiality of included information.

From now on all printable documents from the XBID Solution will be labeled as Confidential:
 * Confidential: Sensitive information intended for use only by a restricted group of people.

*Solution:*

This change will affect: 
 * all e-mails sent by the application as follows: 
 ** Text _""The below email is classified as Confidential""_ added at the beginning of all emails sent from XBID Core, CMM, CMI, SOB, SMC, SMI, AMS.
 * all XML reports will contain comment as follows:
{code:xml}
<!-- The information displayed hereby are classified as: CONFIDENTIAL -->
{code}

 * all CSV reports will contain the following confidential label. See the example for the CMM Messages report:
{code:java}
""Message History Report for border FR-DE from 02.03.2020 till 03.03.2020 created 2020-03-02 16:35:10 (CET) by QA-BAL-ALL-----MADM002. The information displayed hereby are classified as: CONFIDENTIAL""{code}

_*Impact:*_
 * all documents from the XBID Solution will be labeled as Confidential.

*_Disclaimer_*

DBAG strictly confidential and confidential information shall only be disclosed outside DBAG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement.

_*Implementation:*_

_This change will be become effective with R3.1._","12/Aug/20 15:43;ub113;Shared in XBID-5198. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - flyway migration,XP-3368,98628,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,lt112,lt112,04/Aug/20 11:09,20/Aug/20 08:02,22/Feb/21 13:26,10/Aug/20 13:00,,,3.1.1,,,,,,,,,,,"Current shared flyway migration is unstable, introduce separate for XBID only

original: {{energy.automation.deployments/playbooks/include_tasks/flyway_migrate.yml}}

Example of failures:

{noformat}
fatal: [xb-xbid-syt3-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-4.2.0/flyway"",
        ""-user=xbsyt3cor"",
        ""-url=jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor"",
        ""-schemas=xbsyt3cor"",
        ""-password=pw3DBAxbsyt3cor"",
        ""-locations=filesystem:/home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg"",
        ""-group=true"",
        ""-outOfOrder=false"",
        ""migrate""
    ],
    ""delta"": ""0:00:04.323430"",
    ""end"": ""2020-08-04 10:50:35.962123"",
    ""rc"": 1,
    ""start"": ""2020-08-04 10:50:31.638693""
}
STDOUT:
Flyway 4.2.0 by Boxfuse
Database: jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor (PostgreSQL 9.5)
Successfully validated 94 migrations (execution time 00:00.361s)
Creating Metadata table: ""xbsyt3cor"".""schema_version""
Current version of schema ""xbsyt3cor"": << Empty Schema >>
STDERR:
ERROR: Unable to load filesystem resource: /home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg/V0002__removeRacfEntity.sql (encoding: UTF-8)
{noformat}

{noformat}
fatal: [xb-xbid-syt3-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-4.2.0/flyway"",
        ""-user=xbsyt3cor"",
        ""-url=jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor"",
        ""-schemas=xbsyt3cor"",
        ""-password=pw3DBAxbsyt3cor"",
        ""-locations=filesystem:/home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg"",
        ""-group=true"",
        ""-outOfOrder=false"",
        ""migrate""
    ],
    ""delta"": ""0:00:03.589505"",
    ""end"": ""2020-08-04 10:54:09.512497"",
    ""rc"": 1,
    ""start"": ""2020-08-04 10:54:05.922992""
}
STDOUT:
Flyway 4.2.0 by Boxfuse
Database: jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor (PostgreSQL 9.5)
Successfully validated 94 migrations (execution time 00:00.308s)
Creating Metadata table: ""xbsyt3cor"".""schema_version""
Current version of schema ""xbsyt3cor"": << Empty Schema >>
STDERR:
ERROR: Unable to load filesystem resource: /home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg/V0058__add_missing_version_to_some_history_tables.sql (encoding: UTF-8)
{noformat}

{noformat}
fatal: [xb-xbid-syt3-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-4.2.0/flyway"",
        ""-user=xbsyt3cor"",
        ""-url=jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor"",
        ""-schemas=xbsyt3cor"",
        ""-password=pw3DBAxbsyt3cor"",
        ""-locations=filesystem:/home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg"",
        ""-group=true"",
        ""-outOfOrder=false"",
        ""migrate""
    ],
    ""delta"": ""0:00:03.140104"",
    ""end"": ""2020-08-04 10:56:49.517784"",
    ""rc"": 1,
    ""start"": ""2020-08-04 10:56:46.377680""
}
STDOUT:
Flyway 4.2.0 by Boxfuse
Database: jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor (PostgreSQL 9.5)
Successfully validated 94 migrations (execution time 00:00.208s)
Current version of schema ""xbsyt3cor"": << Empty Schema >>
STDERR:
ERROR: Unable to load filesystem resource: /home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg/V0047__trade_history_and_rev_and_rev_type.sql (encoding: UTF-8)
{noformat}

{noformat}
fatal: [xb-xbid-syt3-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-4.2.0/flyway"",
        ""-user=xbsyt3cor"",
        ""-url=jdbc:postgresql://xbtestpdb1.deutsche-boerse.de:25108,xbtestpdb2.deutsche-boerse.de:25108/xbsyt3cor"",
        ""-schemas=xbsyt3cor"",
        ""-password=pw3DBAxbsyt3cor"",
        ""-locations=filesystem:/home/jenkins/workspace/Energy/xbid-full-ansible-deploy/playbooks/flyway_role/xbid-core-3.1.0-db-cfg"",
        ""-group=true"",
        ""-outOfOrder=false"",
        ""migrate""
    ],
    ""delta"": ""0:00:00.417849"",
    ""end"": ""2020-08-04 11:03:25.748207"",
    ""rc"": 1,
    ""start"": ""2020-08-04 11:03:25.330358""
}
STDERR:
Error: Could not find or load main class org.flywaydb.commandline.Main
{noformat}",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17452800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible for new am-reporting service,XP-3363,98610,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,03/Aug/20 14:55,13/Aug/20 19:47,22/Feb/21 13:26,12/Aug/20 15:44,,,3.1.0,,,,,,,,,,,Implement ansible role.,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbi8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Aug/20 15:43;ll664;Role created, inventory has been set up for syt1. Deployment verified and working.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove ACER/AM code from original Report Tool,XP-3362,98603,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ll664,ll664,03/Aug/20 14:54,30/Sep/20 11:37,22/Feb/21 13:26,16/Sep/20 12:56,,,3.1.2,,,,,,,,,,,"Once the AM/ACER features are extracted to separate services, remove related code from original Report Tool module.

Let's keep it only for SLA/KPI reports.",,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3597,,,,,,,,,,,,,,"14/Sep/20 11:54;tr866;SLA DB Screenshot.PNG;https://jira.deutsche-boerse.com/secure/attachment/87532/SLA+DB+Screenshot.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13737600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdql:zz",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/Sep/20 11:57;tr866;Testing on docker with versions XB 3.1.6-SNAPSHOT-48dec4c7beae04feba2c45993bd9bbec818169be, Report Tool 2.48-SNAPSHOT-bdb7c6bfe5ded2efdf5885f40423823a52a74ca6

# In DB I still can see tables for ACER and AM Reporting
!SLA DB Screenshot.PNG|height=40%,width=40%!
# In Report Tool client jobs for ACER and AM Reporting still can be found","14/Sep/20 16:08;tr866;Testing on docker with versions XB 3.1.6-SNAPSHOT-48dec4c7beae04feba2c45993bd9bbec818169be, Report Tool 2.48-SNAPSHOT-72ff685134d636ab5e5960e49af08cb6941f2002

Report Tool Client unable to connect (x)
When xbid-test was build both on branch XP-3361 or develop(where XP-3361 seems to be merged already), the client can't connect to Report Tool service.
I run the client the same usual way same as with previous version:
{noformat}
java -DrestEndpoint=http://localhost:24087/ -jar ~/IdeaProjects/m7.xbid-report-tool/operator-cli/target/report-tool-operator-cli-XXX-SNAPSHOT.jar
{noformat}

the following error is thrown when ""list-jobs"" command is run in the client:

{code:java}
org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:24087/job-names"": Connection reset; nested exception is java.net.SocketException: Connection reset
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:748)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:674)
        at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:315)
        at com.deutscheboerse.energy.xbid.reporttool.cli.RestConnector.callRest(RestConnector.kt:32)
        at com.deutscheboerse.energy.xbid.reporttool.cli.RestConnector.callRest$default(RestConnector.kt:21)
        at com.deutscheboerse.energy.xbid.reporttool.cli.CliCommands.listJobs(CliCommands.kt:78)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:282)
        at org.springframework.shell.Shell.evaluate(Shell.java:180)
        at org.springframework.shell.Shell.run(Shell.java:142)
        at org.springframework.shell.jline.InteractiveShellApplicationRunner.run(InteractiveShellApplicationRunner.java:84)
        at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:786)
        at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:776)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)
        at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:140)
        at com.deutscheboerse.energy.xbid.reporttool.cli.Cli.main(Cli.java:19)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
        at org.springframework.boot.loader.Launcher.launch(Launcher.java:109)
        at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
        at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88)
Caused by: java.net.SocketException: Connection reset
        at java.net.SocketInputStream.read(SocketInputStream.java:210)
        at java.net.SocketInputStream.read(SocketInputStream.java:141)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:743)
        at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678)
        at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:852)
        at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678)
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593)
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
        at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
        at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:82)
        at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
        at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:53)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:739)
        ... 26 more
{code}
","16/Sep/20 12:44;tr866;Testing on docker with versions XB 3.1.6-SNAPSHOT-48dec4c7beae04feba2c45993bd9bbec818169be
Report Tool 2.48-SNAPSHOT-2d7efcf4994956b8d7a4a39aa58e45d8ebb96aba

# Report tool can be successfully started (/)
# Report Tool Client can be successfully connected to Report Tool (/)
# ""list-jobs"" command provides the following list: (/)
{noformat}
╔═══════════════════════════════════╗
║ Name                              ║
╠═══════════════════════════════════╣
║ collect-boundary-sla-data         ║
╟───────────────────────────────────╢
║ collect-performance-kpi-data      ║
╟───────────────────────────────────╢
║ collect-spm-files-generation-data ║
╟───────────────────────────────────╢
║ credit-points                     ║
╟───────────────────────────────────╢
║ generate-boundary-sla-report      ║
╟───────────────────────────────────╢
║ generate-performance-kpi-report   ║
╟───────────────────────────────────╢
║ send-sla-reports                  ║
╚═══════════════════════════════════╝
{noformat}
# Connection to DB successful (/)
# To test generate couple of reports (?)","16/Sep/20 12:55;tr866;Issue split into:
|XP-3597|Remove ACER/AM code from original Report Tool (Split 1)|
","16/Sep/20 12:56;tr866;Generation of the reports/send email left for testing. Development part done most probably.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extract ACER reporting into separate service,XP-3361,98602,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,ll664,ll664,03/Aug/20 14:52,04/Jan/21 15:27,22/Feb/21 13:26,15/Sep/20 14:49,,,3.1.2,,,,,,,,,,,"Suggested approach:

* fork {{m7.xbid-report-tool}} into {{xbid.acer-reporting}} repository
* complete git history would be kept
* remove SLA/AM related code
* remove AM functionality from original Report-Tool
* deploy to same VM as original Report-Tool
* a new (logical) DB would be required, Postgres is already running or Report-Tool VMs


The ACER logic could be forked from here: https://github.deutsche-boerse.de/dev/xbid.am-reporting/commit/86d411444677a7da636d309a7db4da926d637fd3

The commit contains cleaned version of AM/ACER features, withou the SLA/KPI stuff, so one does not need to extract it from Report Tool again.
",,hj444,ll664,tr866,,,,,,,,,,,,,,,,,,XP-3364,,,,,,,,,,,,,,,,,,,,,,"11/Sep/20 17:01;tr866;2020-09_INTRADAY_TRADE_VOLUME_2020-09-12-120910.xml;https://jira.deutsche-boerse.com/secure/attachment/87500/2020-09_INTRADAY_TRADE_VOLUME_2020-09-12-120910.xml",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13824000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdql:zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-3361,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4273-owasp-zap-enable,XP-4505_pipeline_option_timestamps,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,XP-4526-resource-managment-fix,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Sep/20 09:50;hj444;Testing new acer-reporting.

Acer -reporting: 
* Docker build and run from xbid-test->OK
* Docker Acer DB logins -> OK
* Acer CLI - >testing

 ","11/Sep/20 17:07;tr866;Successfully tested the following on docker with versions XB3.1.6-SNAPSHOT-5425273836633eec0d388eaa9b9a3071a7f35689, Acer Reporting 1.0.0-SNAPSHOT-29a719b4c8de6fc2b38e7ae552b3cfd7a7c8ca61
 # Acer could be ran separately as a containber in docker(/)
 # Acer DB is running in separated container too and could be accessible(/)
 # Acer Client could be started and connected to Acer Reporting(/)
 ""list-jobs"" command worked showing the following list of reports:
 ╔═════════════════════════════════════════════════╗
 ║ Name                                                                                                                    ║
 ╠═════════════════════════════════════════════════╣
 ║ bid-ask-spread-report                                                                                          ║
 ╟─────────────────────────────────────────────────╢
 ║ intraday-trade-volume-import                                                                             ║
 ╟─────────────────────────────────────────────────╢
 ║ intraday-trade-volume-report                                                                              ║
 ╟─────────────────────────────────────────────────╢
 ║ trade-volume-hour-to-delivery-import                                                                ║
 ╟─────────────────────────────────────────────────╢
 ║ trade-volume-hour-to-delivery-report                                                                 ║
 ╟─────────────────────────────────────────────────╢
 ║ weighted-average-price-import                                                                           ║
 ╟─────────────────────────────────────────────────╢
 ║ weighted-average-price-last-trading-hour-import                                              ║
 ╟─────────────────────────────────────────────────╢
 ║ weighted-average-price-last-trading-hour-report                                               ║
 ╟─────────────────────────────────────────────────╢
 ║ weighted-average-price-report                                                                            ║
 ╚═════════════════════════════════════════════════╝
# intraday-trade-volume-import successfully imported data into DB(/)
# intraday-trade-volume-report successfully generated the attached [report|^2020-09_INTRADAY_TRADE_VOLUME_2020-09-12-120910.xml] into /tmp/acer folder(/)

_Note: I wasn't able to import data into xbid bid_ask_spread table. Most probably I missed some ruel for bid ask spreads. (?)_
 ","15/Sep/20 09:54;hj444;Jobs :
 trade-volume-hour-to-delivery-import (/)
 weighted-average-price-import (/)
 weighted-average-price-last-trading-hour-import (/)
ACER reporting DB tables updated based on imported values
 

bid-ask-spread core table updated based on orders in OBK (/)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade RHEL to 7.8 on double sided SYT (1 or 3) ,XP-3357,98595,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ei349,ei349,03/Aug/20 13:08,27/Aug/20 10:22,22/Feb/21 13:26,20/Aug/20 12:12,,,3.1.1,,,,,,,syseng,TechOps,,,"Upgrade RHEL to 7.8 on some double sided System Test (1 or 3) and verify that everything works. 

Product team is responsible for coordination of this initiative executed in Systems Engineering team. 
h2. Acceptance criteria 
 * SYT1 or 3 upgraded to 7.8
 * ticket for next step created and PO informed about prioritization ",,ei349,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-84,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16070400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3378,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbp:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/20 13:35;ei349;changed from 8.2 to 7.8 because 8.2. is not needed at the moment and it would be quite rushed. ","12/Aug/20 14:28;hw120;Created syseng request to upgrade os on specified environments. I requested upgrade only for VMs fully dedicated to those environments, there are still a lot of shared VMs like apache, haproxy, reporting, pmi, postgres..., not sure if I should request upgrade also on those as outage there would influence all internal test environments.","19/Aug/20 00:36;hw120;All instances have been updated, we need only to schedule downtime to
 * stop all instances with jenkins
 * reboot all vms
 * start all instances with jenkins","19/Aug/20 17:30;hw120;Stopped all syt1 instances:

 

[https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-full-ansible-deploy/build?delay=0sec]

 

Rebooted all servers:
{code:java}
cat << EOF > ~/xb_syt1_hosts
xbsyt1imq1
xbsyt1imq2
xbsyt1imq3
xbsyt1imq4
xbsyt1imq5
xbsyt1imq6
xbsyt1xmq1
xbsyt1xmq2
xbsyt1xmq3
xbsyt1xmq4
xbsyt1xmq5
xbsyt1xmq6
xbsyt1ecp1
xbsyt1ecp2
xbsyt1ams1
xbsyt1cmi1
xbsyt1cmi2
xbsyt1cmm1
xbsyt1cmm2
xbsyt1cor1
xbsyt1cor2
xbsyt1sob1
xbsyt1sob2
xbsyt1sla1
xbsyt1spm1
xbsyt1spm2
EOF

for host in `cat ~/xb_syt1_hosts`; do ssh $host ""sudo su -c 'hostname'""; done
for host in `cat ~/xb_syt1_hosts`; do ssh $host ""sudo su -c 'cat /etc/redhat-release'""; done
for host in `cat ~/xb_syt1_hosts`; do ssh $host ""sudo su -c 'reboot'""; done
for host in `cat ~/xb_syt1_hosts`; do ssh $host ""sudo su -c 'uptime'""; done
{code}
Started all syt1 instances:

[https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-full-ansible-deploy/build?delay=0sec|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/38337/console]

 

 ","19/Aug/20 17:55;hw120;Stopped all syt3 instances:

GROUP(TOMCAT) GROUP(ECP) GROUP(REP) GROUP(CTP)

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/38335/console]

For rabbitmq I used

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Deploy-Playbook/build?delay=0sec]

 

Rebooted all servers:
{code:java}
Check if anything is still running
ansible all -m shell -a ""ps aux |grep java"" -b --limit '*xb-*syt3*:!*haproxy*:!*amq*:!*web*:!*pdb*:!*pmi*:!*mon*' -e ""ansible_sudo_pass=`cat ~/.ssh/grc`""

cat << EOF > ~/xb_syt3_hosts
xbsyt3imq1
xbsyt3imq2
xbsyt3imq3
xbsyt3xmq1
xbsyt3xmq2
xbsyt3xmq3
xbsyt3ecp1
xbsyt3ecp2
xbsyt3cmi1
xbsyt3cmi2
xbsyt3cmm1
xbsyt3cmm2
xbsyt3cor1
xbsyt3cor2
xbsyt3sob1
xbsyt3sob2
xbsyt3spm1
xbsyt3spm2
EOF

for host in `cat ~/xb_syt3_hosts`; do ssh $host ""sudo su -c 'hostname'""; done
for host in `cat ~/xb_syt3_hosts`; do ssh $host ""sudo su -c 'cat /etc/redhat-release'""; done
for host in `cat ~/xb_syt3_hosts`; do ssh $host ""sudo su -c 'reboot'""; done
for host in `cat ~/xb_syt3_hosts`; do ssh $host ""sudo su -c 'uptime'""; done
{code}
Started all syt3 instances:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Deploy-Playbook/build?delay=0sec]

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/38337/console]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Artifactory accepts only https - some xbid projects still use http,XP-3356,98577,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eg288,eg288,31/Jul/20 15:19,13/Aug/20 19:47,22/Feb/21 13:26,12/Aug/20 15:14,,,3.1.0,,,,,,,,,,,"maven pom, distributionManagement section - some xbid projects still uses http instead of https, it causes problems during release when artifacts are uploaded into artifactory

* pmi logger, archiver and query apps
* xbid-api
* m7.test-client",,eg288,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,cpm,XP-3777,XP-3345-version-bump,develop,XP-3594-allocation-plans,XP-3345,XP-3594-cpm-ramping,master,master-acceptance,acceptance,master-cpm,CPM-release-settings,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Aug/20 15:14;ll664;I went through all xbid git repos and changed artifactory links to https where it haven't been done already. Hopefully did not miss anything.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - rabbitmq cluster,XP-3352,98564,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,31/Jul/20 10:39,13/Aug/20 19:41,22/Feb/21 13:26,05/Aug/20 13:32,,,3.1.0,,,,,,,,,,,must support the both 3 node cluster and 1 node.,,eh941,,,,,,,,,,,,,,,,,,,,XP-3195,,,,,,,,XP-3380,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17798400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb8w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
syt3 - rabbitmq  3 nodes cluster,XP-3351,98562,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,eg288,eg288,31/Jul/20 10:30,11/Aug/20 13:01,22/Feb/21 13:26,04/Aug/20 16:15,,,3.1.0,,,,,,,TechOps,,,,"Upgrade the double sided syt3 environtment to use 3 node cluster 

Currently syt3 env still uses obsolete 2 node cluster streched over the two datacenters.

Steps:
* request new VMs
* update ansible configuration for syt3 to deploy 3 node cluster onto new VMs",,eg288,ei349,yo218,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17366400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xru:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/20 13:09;ei349;[~yo218]: can you please estimate this ticket? ","03/Aug/20 16:11;yo218;VM's have been requested and are available now","03/Aug/20 16:12;yo218;PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2036]","04/Aug/20 16:15;yo218;New hosts exist:

xbsyt3xmq1-3
xbsyt3imq1-3

Backend modules need to connect to backend ha proxies now: 

xbintebha1-4



This might change very soon, but for now we can use it this way.

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2039/files]

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2038/files]

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2036/files]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fork Comtrader to XBID one and version it according to product version ,XP-3349,98557,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,31/Jul/20 09:40,05/Aug/20 09:31,22/Feb/21 13:26,03/Aug/20 08:06,,,3.1.0,,,,,,,,,,,"We want separate repo to have common branching model in all modules (XP-3233), currently we might clash with m7 branches.",,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17712000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/20 14:55;ll664;New repo here: https://github.deutsche-boerse.de/dev/xbid.comtrader

All builds/sonar etc. should be ready and working.

Notes for future:

* versioning changed - now it's 3.1.x (was 2.5.x)
* we should provide links to two previous versions of CT, this needs to be done manual, as the previous versions are artefacts produced from old repo.
* we might not need it, it won't work anyway as XBID 3.1 contains breaking XSD changes - this needs to be communicated to customers ([~ei349] FYI)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jenkins job ComTrader build uber package (2.1 and 2.5 only) fails when parameter previousVersions specified,XP-3348,98538,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Cannot Reproduce,lt112,eg288,eg288,30/Jul/20 12:14,31/Aug/20 16:10,22/Feb/21 13:26,19/Aug/20 16:21,,,3.1.1,,ComTrader,,,,,,,,,"The stated error is _Caused by: java.util.zip.ZipException: archive is not a ZIP archive_. But whne the artifact is downloaded manually it can be opened by WinZip.

{code}
[INFO] Downloading comtrader-webstart-2.5.1.58-xbid-ctpj.zip from http://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/comxerv/comtrader-webstart/2.5.1.58/comtrader-webstart-2.5.1.58-xbid-ctpj.zip
[INFO] Download finished
[INFO] Unzipping comtrader-webstart-2.5.1.66-xbid-ctpj.zip into /home/jenkins/scmci1/workspace/Energy/ComTrader build uber package (2.1 and 2.5 only)/comtrader-webstart/target/uber-package/comtrader-webstart-2.5.1.66-xbid-ctpj
[INFO] Unzipping comtrader-webstart-2.5.1.58-xbid-ctpj.zip into /home/jenkins/scmci1/workspace/Energy/ComTrader build uber package (2.1 and 2.5 only)/comtrader-webstart/target/uber-package/comtrader-webstart-2.5.1.58-xbid-ctpj
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Comtrader 2.5.1.66:
[INFO] 
[INFO] Comtrader .......................................... SUCCESS [  9.244 s]
[INFO] Build Comtrader Artifact Maven Plugin .............. SUCCESS [ 41.395 s]
[INFO] comtrader-custom ................................... SUCCESS [  1.961 s]
[INFO] comtrader-test-utils ............................... SUCCESS [  0.888 s]
[INFO] comtrader-fx-utils ................................. SUCCESS [  1.693 s]
[INFO] comtrader-core ..................................... SUCCESS [ 11.144 s]
[INFO] comtrader-exchange-api ............................. SUCCESS [  0.168 s]
[INFO] comtrader-comxerv-common ........................... SUCCESS [  1.286 s]
[INFO] comtrader-m7-v1 .................................... SUCCESS [  3.179 s]
[INFO] comtrader-javafx ................................... SUCCESS [ 14.701 s]
[INFO] comtrader-webstart ................................. FAILURE [01:14 min]
[INFO] comtrader-test ..................................... SKIPPED
[INFO] comtrader-headless ................................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  02:49 min
[INFO] Finished at: 2020-07-30T12:08:35+02:00
[INFO] ------------------------------------------------------------------------
Waiting for Jenkins to finish collecting data
[ERROR] Failed to execute goal com.deutscheboerse.comxerv:build-shippable-artifact:2.5.1.66:build-uber-package (buildUberPackage) on project comtrader-webstart: Failed to build Comtrader uber-package: Error while expanding /home/jenkins/scmci1/workspace/Energy/ComTrader build uber package (2.1 and 2.5 only)/comtrader-webstart/target/comtrader-webstart-2.5.1.58-xbid-ctpj.zip: archive is not a ZIP archive -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal com.deutscheboerse.comxerv:build-shippable-artifact:2.5.1.66:build-uber-package (buildUberPackage) on project comtrader-webstart: Failed to build Comtrader uber-package
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:215)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.jvnet.hudson.maven3.launcher.Maven35Launcher.main (Maven35Launcher.java:130)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at jenkins.maven3.agent.Maven35Main.launch (Maven35Main.java:178)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:139)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:70)
    at hudson.remoting.UserRequest.perform (UserRequest.java:211)
    at hudson.remoting.UserRequest.perform (UserRequest.java:54)
    at hudson.remoting.Request$2.run (Request.java:369)
    at hudson.remoting.InterceptingExecutorService$1.call (InterceptingExecutorService.java:72)
    at java.util.concurrent.FutureTask.run (FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)
    at java.lang.Thread.run (Thread.java:748)
Caused by: org.apache.maven.plugin.MojoExecutionException: Failed to build Comtrader uber-package
    at com.deutscheboerse.comxerv.uberpackage.UberPackagePlugin.execute (UberPackagePlugin.java:61)
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.jvnet.hudson.maven3.launcher.Maven35Launcher.main (Maven35Launcher.java:130)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at jenkins.maven3.agent.Maven35Main.launch (Maven35Main.java:178)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:139)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:70)
    at hudson.remoting.UserRequest.perform (UserRequest.java:211)
    at hudson.remoting.UserRequest.perform (UserRequest.java:54)
    at hudson.remoting.Request$2.run (Request.java:369)
    at hudson.remoting.InterceptingExecutorService$1.call (InterceptingExecutorService.java:72)
    at java.util.concurrent.FutureTask.run (FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)
    at java.lang.Thread.run (Thread.java:748)
Caused by: org.codehaus.plexus.archiver.ArchiverException: Error while expanding /home/jenkins/scmci1/workspace/Energy/ComTrader build uber package (2.1 and 2.5 only)/comtrader-webstart/target/comtrader-webstart-2.5.1.58-xbid-ctpj.zip
    at org.codehaus.plexus.archiver.zip.AbstractZipUnArchiver.execute (AbstractZipUnArchiver.java:195)
    at org.codehaus.plexus.archiver.AbstractUnArchiver.extract (AbstractUnArchiver.java:149)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.unzip (UberPackageCreator.kt:115)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.unzipAllPackages (UberPackageCreator.kt:86)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.create (UberPackageCreator.kt:55)
    at com.deutscheboerse.comxerv.uberpackage.UberPackagePlugin.execute (UberPackagePlugin.java:59)
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.jvnet.hudson.maven3.launcher.Maven35Launcher.main (Maven35Launcher.java:130)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at jenkins.maven3.agent.Maven35Main.launch (Maven35Main.java:178)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:139)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:70)
    at hudson.remoting.UserRequest.perform (UserRequest.java:211)
    at hudson.remoting.UserRequest.perform (UserRequest.java:54)
    at hudson.remoting.Request$2.run (Request.java:369)
    at hudson.remoting.InterceptingExecutorService$1.call (InterceptingExecutorService.java:72)
    at java.util.concurrent.FutureTask.run (FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)
    at java.lang.Thread.run (Thread.java:748)
Caused by: java.util.zip.ZipException: archive is not a ZIP archive
    at org.apache.commons.compress.archivers.zip.ZipFile.positionAtEndOfCentralDirectoryRecord (ZipFile.java:958)
    at org.apache.commons.compress.archivers.zip.ZipFile.positionAtCentralDirectory (ZipFile.java:883)
    at org.apache.commons.compress.archivers.zip.ZipFile.populateFromCentralDirectory (ZipFile.java:621)
    at org.apache.commons.compress.archivers.zip.ZipFile.<init> (ZipFile.java:295)
    at org.apache.commons.compress.archivers.zip.ZipFile.<init> (ZipFile.java:218)
    at org.codehaus.plexus.archiver.zip.AbstractZipUnArchiver.execute (AbstractZipUnArchiver.java:168)
    at org.codehaus.plexus.archiver.AbstractUnArchiver.extract (AbstractUnArchiver.java:149)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.unzip (UberPackageCreator.kt:115)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.unzipAllPackages (UberPackageCreator.kt:86)
    at com.deutscheboerse.comxerv.uberpackage.UberPackageCreator.create (UberPackageCreator.kt:55)
    at com.deutscheboerse.comxerv.uberpackage.UberPackagePlugin.execute (UberPackagePlugin.java:59)
    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)
    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)
    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)
    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)
    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)
    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)
    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)
    at org.jvnet.hudson.maven3.launcher.Maven35Launcher.main (Maven35Launcher.java:130)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:289)
    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:229)
    at jenkins.maven3.agent.Maven35Main.launch (Maven35Main.java:178)
    at sun.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke (Method.java:498)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:139)
    at hudson.maven.Maven3Builder.call (Maven3Builder.java:70)
    at hudson.remoting.UserRequest.perform (UserRequest.java:211)
    at hudson.remoting.UserRequest.perform (UserRequest.java:54)
    at hudson.remoting.Request$2.run (Request.java:369)
    at hudson.remoting.InterceptingExecutorService$1.call (InterceptingExecutorService.java:72)
    at java.util.concurrent.FutureTask.run (FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:624)
    at java.lang.Thread.run (Thread.java:748)
[ERROR] 
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :comtrader-webstart
{code}",,eg288,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16934400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,30/Jul/20 12:14,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),HOT Sprint 15,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/20 14:15;lt112;so far could not reproduce, possibly random download issue?

{noformat}
previousVersions: 3.1.0
{noformat}

{noformat}
[INFO] Downloading comtrader-webstart-3.1.0-xbid-ctpk.zip from https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/xbid/comtrader-webstart/3.1.0/comtrader-webstart-3.1.0-xbid-ctpk.zip
[INFO] Download finished
[INFO] Unzipping comtrader-webstart-3.1.0-xbid-ctpk.zip into /home/jenkins/scmci1/workspace/Energy/xbid-comtrader-uber-package/comtrader-webstart/target/uber-package/comtrader-webstart-3.1.0-xbid-ctpk
[INFO] Unzipping comtrader-webstart-3.1.0-xbid-ctpk.zip into /home/jenkins/scmci1/workspace/Energy/xbid-comtrader-uber-package/comtrader-webstart/target/uber-package/comtrader-webstart-3.1.0-xbid-ctpk
[INFO] Building zip: /home/jenkins/scmci1/workspace/Energy/xbid-comtrader-uber-package/comtrader-webstart/target/comtrader-webstart-3.1.0-xbid-ctpk-uber-package.zip
{noformat}","04/Aug/20 14:17;lt112;[~eg288] did it happen multiple times?","10/Aug/20 13:55;eg288;I did it several times with arartifact comtrader-webstart-2.5.1.58-xbid-ctpj.zip. It was always failing. I did not try any other artifacts. Feel free to close the issue if it works for other artifacts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update PMI Archiver on SFTP server,XP-3347,98527,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,30/Jul/20 10:49,20/Aug/20 08:02,22/Feb/21 13:26,06/Aug/20 11:47,,,3.1.1,,,,,,,TechOps,,,,"Currently we are duplicating the PMI archiver files by copying the files from pmi_archiver_\{env} to xbid_\{customer}_\{env}. We used a different approach for the AM reports which sounds way more effective by mounting the files. I tried it already for one single customer and it seemed to work fine:
{noformat}
[root@xbcutscom1 pmi]#  mount --bind /opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_opcom_lipa/OUT/pmi{noformat}
Has to be done on cbn and com hosts! Mount command has to be entered to /etc/fstab file.

This one time action can replace the whole sftp_mover part and will save quite some disk space",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17280000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zzi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Aug/20 07:19;yo218;prepared and tested the method on internal test, seems to work fine. Performed the changes on all Cutes (xbcutscbn1 and xbcutscom1). Example:
{noformat}
[root@xbcutscbn1 data01]# while read p; do rm ""$p""/OUT/pmi/* -rf; done <sftp_mover/userlist_pmi_archiver_lipa
[root@xbcutscbn1 data01]# while read p; do mount --bind /opt/data01/pmi_archiver_lipa/OUT/pmi  ""$p""/OUT/pmi; done <sftp_mover/userlist_pmi_archiver_lipa
[root@xbcutscbn1 data01]# while read p; do rm ""$p""/OUT/pmi/* -rf; done <sftp_mover/userlist_pmi_archiver_cute
[root@xbcutscbn1 data01]# while read p; do mount --bind /opt/data01/pmi_archiver_cute/OUT/pmi  ""$p""/OUT/pmi; done <sftp_mover/userlist_pmi_archiver_cute {noformat}
Deactivated the cron on xbcutscbn1

Added the following lines to /etc/fstab:
{noformat}
#ctso
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_bsp_ctso/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_omie_ctso/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_gme_ctso/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_np_ctso/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_epex_ctso/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_ctso/OUT/pmi /opt/data01/xbid_cropex_ctso/OUT/pmi  none    bind    0 0

#cute
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_omie_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_gme_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_np_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_epex_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_indra_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_hupx_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_cropex_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_ote_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_bsp_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_opcom_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_ibex_cute/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_cute/OUT/pmi /opt/data01/xbid_tge_cute/OUT/pmi  none    bind    0 0

#lipa
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_omie_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_gme_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_np_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_epex_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_hupx_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_cropex_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_ote_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_bsp_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_opcom_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_ibex_lipa/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipa/OUT/pmi /opt/data01/xbid_tge_lipa/OUT/pmi  none    bind    0 0

#lipb
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_omie_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_gme_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_np_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_epex_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_hupx_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_cropex_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_ote_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_bsp_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_opcom_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_ibex_lipb/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver_lipb/OUT/pmi /opt/data01/xbid_tge_lipb/OUT/pmi  none    bind    0 0
 {noformat}","06/Aug/20 07:51;yo218;executed on Simu (xbsimucbn1/2 and xbsimucom1-6):
{noformat}
while read p; do rm ""$p""/OUT/pmi/* -rf; done </opt/data01/sftp_mover/userlist
while read p; do mount --bind /opt/data01/pmi_archiver/OUT/pmi  ""$p""/OUT/pmi; done <sftp_mover/userlist{noformat}
Added the following lines to /etc/fstab to all 6 hosts:
{noformat}
#binding directory of pmi_archiver to customer accounts
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_omie_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_np_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_epex_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_indra_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_ote_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_hupx_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_cropex_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_ote_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_bsp_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_opcom_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_ibex_simu/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_tge_simu/OUT/pmi  none    bind    0 0


{noformat}","06/Aug/20 11:47;yo218;executed on Prod (xbprodcbn1/2 and xbprodcom1-6):
{noformat}
while read p; do rm ""$p""/OUT/pmi/* -rf; done </opt/data01/sftp_mover/userlist
while read p; do mount --bind /opt/data01/pmi_archiver/OUT/pmi  ""$p""/OUT/pmi; done <sftp_mover/userlist{noformat}
Added the following lines to /etc/fstab to all 6 hosts:
{noformat}
#binding the pm_archiver dir to each customer
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_omie_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_gme_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_np_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_epex_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_ote_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_hupx_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_opcom_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_bsp_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_tge_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_cropex_prod/OUT/pmi  none    bind    0 0
/opt/data01/pmi_archiver/OUT/pmi /opt/data01/xbid_minsait_prod/OUT/pmi  none    bind    0 0
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare for next development ,XP-3345,98487,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,29/Jul/20 12:37,02/Nov/20 12:57,22/Feb/21 13:26,01/Oct/20 12:07,,,3.1.2,,,,,,,,,,,"Merge 3.1.x all modules to Acceptance

Create 3.2 version of xbid modules in Develop (comtrader, xbid, shipping, report-tool?, AMS)

https://github.deutsche-boerse.de/dev/xbid
https://github.deutsche-boerse.de/dev/m7.xbid-shipping-module
https://github.deutsche-boerse.de/dev/xbid.comtrader

https://github.deutsche-boerse.de/dev/xbid.access-management
https://github.deutsche-boerse.de/dev/xbid-reporting-engine
https://github.deutsche-boerse.de/dev/m7.pmi-logger
https://github.deutsche-boerse.de/dev/m7.pmi-archiving

Cross Product Matching on separate dev branch - already done - {{cpm}} branch created. ",,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12441600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),Alpha Sprint 18,Alpha Sprint 19 (S),,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-support-owasp-fix,XP-3777,XP-4370_acceptance_hp_fortify_issues,XP-4211-perf-analysis-jh,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-3394_acceptance_flyway_standard_implementation,XP-3114,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4275-acceptance,XP-3909-develop,XP-3942-acceptance,XP-4152-acceptance,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-3909,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-3922,XP-4505_xbid_hpfortify_upgrade,fixing-hp-fortify-acceptance-2021-02-15,fixing-owasp,XP-3942,XP-3345-version-bump,XP-4349_acceptance_fix_hp_fortify_issues,XP-4122-perf-analysis,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-3394_acceptance_remove_unused_maven_properties,master,master-acceptance,XP-3496-acceptance,acceptance,XP-4371_upgrade_dataset_version,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-222-develop,XP-222-acceptance,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Sep/20 14:22;ll664;On the UAT alignment meeting on 23.9.2020 13:00, there was an idea by [~eg288] not to merged to {{acceptance}} now, as all that we develop at the moment are UAT fixes. This would save us some burden of maintaining two branches which actually makes sense.

I'd postpone this for some time.","01/Oct/20 10:48;ll664;Merges to acceptance based on versions in https://jira.deutsche-boerse.com/browse/SERVICE-8179
","01/Oct/20 12:07;ll664;Merged and versions for next development bumped.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMI - OCC - update/create new methods for OCC creation (createOutboundFileForInterConnector),XP-3343,98482,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,29/Jul/20 10:36,31/Aug/20 15:39,22/Feb/21 13:26,11/Aug/20 13:55,,,3.1.0,,,,,,,TestAutomation,,,,"1. Prepare objects for OCC file creation 
_example_ : createOutboundFileForInterConnector :  could be found : xbid-test/test-common/src/main/java/com/deutscheboerse/energy/m7/test/api/v1/db/DatabaseAccessorCmi.java)

OCC creation extends the configuration panel for FTC :
Add - new attributes for configuration of OCC files: 
- Auction Type : Implicit/Explicit
- VDA Quantity : Minimum/Original 

2. Include updated/new OCC file creation methods into the steps.


",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3231,XP-3230,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16848000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bark:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3443-rounding,why-optional,cpm,XP-4273-owasp-zap-enable,XP-3829-routing-integration,ramping-analysis,XP-3443-recursion,XP-4526-resource-managment-fix,XP-3230,develop,XP-3520-ramping_analysis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Aug/20 10:17;hj444;pull request created : [https://github.deutsche-boerse.de/dev/xbid-test/pull/245]
Ready for review.

 

New feature file added occFile.feature with 2 basic scenarios.
Existing methods updated for extended OCC file configuration.
...more in pull request


 ","11/Aug/20 13:55;hj444;merged - jira will be closed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade of secure TLS Ciphers,XP-3341,98456,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,28/Jul/20 15:46,14/Oct/20 10:05,22/Feb/21 13:26,02/Sep/20 11:03,,,Not approved by customer,,,,,,02/Sep/20 00:00,TechOps,,,,"Dear Vladimir, dear Lindsay, dear OPSCOM Members,
h2. Current Situation

As a result of continuous security tests on DBAG's side, we identified that we are using TLS Ciphers that will be deprecated in the near future.

The following ciphers with older algorithms are supported by the AMQP server, which are not considered insecure  but still should be replaced in the near future:
 * TLS_DHE_RSA_WITH_AES_128_CBC_SHA
 * TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
 * TLS_DHE_RSA_WITH_AES_256_CBC_SHA
 * TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
 * TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
 * TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
 * TLS_DHE_RSA_WITH_SEED_CBC_SHA
 * TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
 * TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
 * TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
 * TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384

h2. Solution

We will upgrade the TLS Ciphers to the recommended suite TLS 1.2. This will provide more security in the way how any XBID user is accessing XBID by using the web browser. There is *no action needed on your side*, everything will be done on DBAG's side.
h2. Impact

There might be an impact on the users which are using older versions of Windows together with Internet Explorer browser. If we implement this change it will not be possible for them to connect afterwards:
 * (/) Chrome 51 Win 7 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (/) Chrome 57 Win 7 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (/) Firefox 49 Win 7 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (/) Firefox 53 Win 7 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (x) IE 6 XP No connection
 * (x) IE 7 Vista No connection
 * (x) IE 8 XP No connection
 * (x) IE 8 Win 7 No connection
 * (x) IE 11 Win 7 No connection
 * (x) IE 11 Win 8.1 No connection
 * (/) IE 11 Win 10 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (/) Edge 13 Win 10 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)
 * (/) Edge 13 Win Phone 10 TLSv1.2 ECDHE-RSA-AES256-GCM-SHA384, 256 bit ECDH (P-256)

h2. Implementation

As this can be considered as a security threat, DBAG would like to proceed with the upgrade within R3.1. If you decline this request, we need to ask the Parties for a time limited exception and we need to tackle this item in the future. ",,ei349,ek176,qm925,tr866,,,,,,,,,,,,,,,,,,,,,,XBID-5191,,,,,,XP-3511,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14947200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xt2:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,XP-3341-update-tls-ciphers,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/Jul/20 15:46;ek176;Q:

> _May I ask, similarly to Joint QARM discussion from 27/7, what are the potential side effects of this implementation, so we can evaluate impact on regression testing?_ (Martin Vancura)

Suggested A:

Dear Martin,

the change affects only the communication channel between the software client (web browser) and the XBID server(s). No functional change, nor API change was performed in any modules. The connection still uses TLS 1.2, only the ciphers available are reduced to secure ones. The change affects the outbound network servers that terminate the TLS connection.

The TLS setting is independent of the XBID modules deployment/settings. TLS 1.2 serves as a secure ""corridor"" to the XBID servers.

Once the connection is established, everything works as usual. We have internally verified the connection works using recent versions of ComTrader and TestClient (unsupported tool) within our internal testing infrastructure.

 

The only issue might occur when using custom tools to connect, i.e. outdated curl/wget tool or an obsolete proxy or library that terminates the TLS 1.2 connection. This in fact poses a security risk that should be mitigated by upgrading to secure versions.

An example might be a simple health check of the web endpoint:
{noformat}
$ curl -X OPTIONS https://www.deutsche-boerse.com/dbg-de/
{noformat}
 

DBAG suggests to implement the proposed change within UAT phase to identify possible issues in an early phase. The setting can be quite easily reverted and expected downtime is below 15 minutes (?). Neither DB clean nor market HALT is needed.

 

BR

 

   ______.","30/Jul/20 16:25;qm925;Hi Mira, hi Jirka,

The draft is fine. I have only several minor comments. Please see below:


 * I would change the tense in this sentence: ""No functional change, nor API change was performed in any modules"" to ""No functional change, nor API change *will be* performed in any modules""
 * ""We have internally verified the connection works *using recent versions of ComTrader and TestClient (unsupported tool)* within our internal testing infrastructure"". I would remove the text in bold.
 * DBAG suggests to implement the proposed change within *R3.1* UAT phase to identify possible issues in an early phase. Please add the text in bold","19/Aug/20 14:21;ei349;(flag) Flag added

Not approved yet","28/Aug/20 11:06;ek176;Approved for UAT/Simu. [~ei349] Please confirm","31/Aug/20 15:09;ek176;[~iv732] Please check the following PRs:

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1061]

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2098]

 

The TLS params are upgraded:

1) for Apache:  (xb_apache role) For all envs except PROD (Ansible deployment not ready yet for PROD, Cutes). 

2) for HA Proxy (shared haproxy role): Changed in xbid vars. (Exception in PROd to keep current state)  ","01/Sep/20 10:14;ek176;To be tested:
 * Deployment to SYTx
 * Verify that Apache uses the new config
 * Verify that HA Proxy use the new config
 * Verify connection with used browsers work (IE 11, Chrome, Firefox)","02/Sep/20 11:03;tr866;Smoke tests were executed on environment Syt1 with versions XBID 3.1.5, SPM 3.1.2.
No unexpected suspcious behaviour was observed in SOB,CMM,SPM that could be related to the upgrade.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check how the sec. standards affect the customer,XP-3331,98351,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,zi174,zi174,24/Jul/20 08:21,31/Aug/20 15:38,22/Feb/21 13:26,03/Aug/20 10:27,,,3.1.0,,,,,,,,,,,"These standards have an impact to the customer:

 

Access Control Standard
 * the parameter which says how many last passwords needs to be different is going to be change to 6 (from previous 5) - USM700 update

 

Data Leakage Prevention Standard
 * Application labeling: Reports - the reports are labeled with a ""Confidential label"" e.g. [^XBID Performance and SM SLA Reporting June 2020.xlsx]
 * Application labeling: e-mails - the emails will be labeled e.g. The below email is classified: Confidential

 

 ",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3372,,,,,,,,,,,"30/Jul/20 12:40;zi174;XBID Performance and SM SLA Reporting June 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/86142/XBID+Performance+and+SM+SLA+Reporting+June+2020.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18403200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9zs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upload the fixed H1/2020 ACER reports on SFTP ,XP-3329,98340,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,qm925,qm925,23/Jul/20 15:02,31/Aug/20 15:38,22/Feb/21 13:26,23/Jul/20 15:57,,,3.1.0,,,,,,,,,,,"There has been an issues with the ACER reports for H1/2020. 

The reports have been regenerated and they need to be uploaded again on sftp for the clients. 

The correct sftp path for the clients should be *_Path is /OUT/acer_*

 

For more details, please check *__* XP-3209",,iv732,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/20 15:28;ll664;acer_h1_2020_v3.zip;https://jira.deutsche-boerse.com/secure/attachment/85983/acer_h1_2020_v3.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18403200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9xc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/20 15:55;iv732;copied to all customers:
{code:java}
for px in cropex epex gme hupx np omie opcom ote tge; do ls -la /opt/data01/xbid_${px}_prod/OUT/acer/; done
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 6 101022 101022     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 101012 101012     4096 Jul 23 15:53 .
drwxr-xr-x 7 101012 101012     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 7 101013 101013     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 7 101027 101027     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 101014 101014     4096 Jul 23 15:53 .
drwxr-xr-x 7 101014 101014     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 101015 101015     4096 Jul 23 15:53 .
drwxr-xr-x 7 101015 101015     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 7 101029 101029     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 7 101024 101024     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip
total 11222
drwxr-xr-x 2 root   root       4096 Jul 23 15:53 .
drwxr-xr-x 7 101026 101026     4096 Jul 13 14:52 ..
-rw-r--r-- 1 root   root   11482449 Jul 23 15:53 acer_h1_2020_v3.zip

{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) CUTE wildcard cert for ProfileServer,XP-3326,98326,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ek176,ek176,23/Jul/20 10:07,30/Sep/20 11:37,22/Feb/21 13:26,16/Sep/20 08:08,,,3.1.2,,ComTrader,,,,,TechOps,,,,"***To be (ideally) executed before UAT deployments, Aug 05*

 

TBD:
 # [~iv732] Please discuss whether we still want to have shared infrastructure for the profile servers (for CUTEs/LIPs). 
 # [~iv732] Please create a request for relevant DNS records (independently) (/)
 # [~iv732] Please create request(s) for relevant firewall rules
 # [~iv732] Please prepare the PR (for wildcard certificate) ready and notify/coordinate next steps (/)
 # [~iv732] Please switch the endpoints to the new certificate (/)
 # [~tm431] [~radeale] To negotiate and update/distribute new Connection Details
 # [~ek176] To execute and verify that CT works (/)
 # [~ek176] To upgrade/release CT that checks cert's CN 

 

 ====

The current certificate for CUTEs' profile server is about to expire on *Monday, September 21, 2020 at 1:59:59 AM*

CN=[cute1.profiles.xbid.deutsche-boerse.com|http://cute1.profiles.xbid.deutsche-boerse.com/] 

 

There are two options, can be executed 1., then 2.:
 # Just change the certificate for the wildcard one. The _CN check_ is disabled, so there should be no issue.
 # (TechOps needed): Create correct DNS records, turn CN check on, update/release ComTrader.

[~iv732], [~yn731], [~tm431] FYI",,ek176,iv732,yn731,,,,,,,,,,,,,,,,,,XP-3583,XP-3327,,,,,,,XP-3515,,,,,,,XP-3071,,,,,,,"15/Sep/20 16:22;ek176;20200915_ConnDetails_CUTES.txt;https://jira.deutsche-boerse.com/secure/attachment/87590/20200915_ConnDetails_CUTES.txt","15/Sep/20 14:49;ek176;20200915_cutes_check_02.xls;https://jira.deutsche-boerse.com/secure/attachment/87587/20200915_cutes_check_02.xls",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13737600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9uo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,Alpha Sprint 15 (S),Alpha Sprint 16,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/20 10:40;ek176;The server is used in the following envs (ComTrader configs):
{code:java}
ctpa-xsob-ext
ctpb-xsob-ext
ctpc-xsob-ext
ctpd-xsob-ext
ctpe-xsob-ext
ctpf-xsob-ext
ctpg-xsob-ext
ctph-xsob-ext
ctpi-xsob-ext
ctpj-xsob-ext
ctpk-xsob-ext
ctpl-xsob-ext
ctpm-xsob-ext
ctso-xsob-ext
cute-xsob-ext
lipa-xsob-ext
lipb-xsob-ext
{code}
Full grep:

 
{noformat}
ctpa/jnlp/ctpa-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpa/services/"" },
ctpb/jnlp/ctpb-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpb/services/"" },
ctpc/jnlp/ctpc-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpc/services/"" },
ctpd/jnlp/ctpd-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpd/services/"" },
ctpe/jnlp/ctpe-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpe/services/"" },
ctpf/jnlp/ctpf-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpf/services/"" },
ctpg/jnlp/ctpg-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpg/services/"" },
ctph/jnlp/ctph-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctph/services/"" },
ctpi/jnlp/ctpi-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpi/services/"" },
ctpj/jnlp/ctpj-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpj/services/"" },
ctpk/jnlp/ctpk-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpk/services/"" },
ctpl/jnlp/ctpl-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpl/services/"" },
ctpm/jnlp/ctpm-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctpm/services/"" },
ctso/jnlp/ctso-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-ctso/services/"" },
cute/jnlp/cute-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-cute/services/"" },
lipa/jnlp/lipa-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-lipa/services/"" },
lipb/jnlp/lipb-xsob-ext.jnlp.json:        { ""name"":""profileStorageUrl"", ""value"":""https://cute1.profiles.xbid.deutsche-boerse.com:60304/xbid-lipb/services/"" },
{noformat}
 

 ","23/Jul/20 14:18;ek176;DNS records to be created, all pointing to (if agreed by TechOps): 

{{cute1.profiles.xbid.deutsche-boerse.com (*{color:#de350b}193.29.80.72{color}*)}}
{noformat}
ctpa-profiles.xbid.deutsche-boerse.com
ctpb-profiles.xbid.deutsche-boerse.com
ctpc-profiles.xbid.deutsche-boerse.com
ctpd-profiles.xbid.deutsche-boerse.com
ctpe-profiles.xbid.deutsche-boerse.com
ctpf-profiles.xbid.deutsche-boerse.com
ctpg-profiles.xbid.deutsche-boerse.com
ctph-profiles.xbid.deutsche-boerse.com
ctpi-profiles.xbid.deutsche-boerse.com
ctpj-profiles.xbid.deutsche-boerse.com
ctpk-profiles.xbid.deutsche-boerse.com
ctpl-profiles.xbid.deutsche-boerse.com
ctpm-profiles.xbid.deutsche-boerse.com
ctso-profiles.xbid.deutsche-boerse.com
cute-profiles.xbid.deutsche-boerse.com
lipa-profiles.xbid.deutsche-boerse.com
lipb-profiles.xbid.deutsche-boerse.com{noformat}","23/Jul/20 14:27;iv732;https://jira.deutsche-boerse.com/browse/SYSENG-67

cute1-profiles.xbid.deutsche-boerse.com
simu1-profiles.xbid.deutsche-boerse.com
simu2-profiles.xbid.deutsche-boerse.com
prod1-profiles.xbid.deutsche-boerse.com
prod2-profiles.xbid.deutsche-boerse.com
syt2-profiles.xbid.deutsche-boerse.de 
","23/Jul/20 14:31;iv732;Should we have the number at the end of the environment, like our standard?
So they will look like this:

ctpa1-profiles.xbid.deutsche-boerse.com
ctpb1-profiles.xbid.deutsche-boerse.com
ctpc1-profiles.xbid.deutsche-boerse.com
ctpd1-profiles.xbid.deutsche-boerse.com
ctpe1-profiles.xbid.deutsche-boerse.com
ctpf1-profiles.xbid.deutsche-boerse.com
ctpg1-profiles.xbid.deutsche-boerse.com
ctph1-profiles.xbid.deutsche-boerse.com
ctpi1-profiles.xbid.deutsche-boerse.com
ctpj1-profiles.xbid.deutsche-boerse.com
ctpk1-profiles.xbid.deutsche-boerse.com
ctpl1-profiles.xbid.deutsche-boerse.com
ctpm1-profiles.xbid.deutsche-boerse.com
ctso1-profiles.xbid.deutsche-boerse.com
cute1-profiles.xbid.deutsche-boerse.com
lipa1-profiles.xbid.deutsche-boerse.com
lipb1-profiles.xbid.deutsche-boerse.com
","24/Jul/20 13:50;ek176;Can be. But I doubt the secondary server will ever be created.

Technically, the syt2-profiles should've been syt2-1-profiles...","27/Jul/20 11:59;ek176;[~iv732] Can you please make the request and link the SYSENG ticket here?","27/Jul/20 12:21;iv732;[~ek176] ok, I will request the ones without number. It makes sense.","27/Jul/20 12:28;iv732;SYSENG ticket created:  https://jira.deutsche-boerse.com/browse/SYSENG-112","27/Aug/20 08:49;iv732;[~ek176] DNS records are there. Can you create PR?","01/Sep/20 10:43;ek176;[~iv732] The PR is ready. Please update the endpoints to serve the new wildcard certificate and then merge the PR:

[https://github.deutsche-boerse.de/dev/xbid.comtrader/pull/12]

(The CN check is still disabled, so no change except the endpoint is expected)

The communication with customers (new _Connection Details_) to be communicated within XBID-5208","02/Sep/20 09:36;ek176;Issue split into:
|XP-3515|(Split 1) CUTE wildcard cert for ProfileServer|
","02/Sep/20 10:00;ek176;Following communication should be done in {color:#1d1c1d}XBID-5208{color} after todays deployment, so e.g. tomorrow by [~yn731]   just copy paste (checked by [~ek176]).

Dear all,

please be informed that both (old and new) following IP addresses are valid after yesterdays SIMU deployment for a ComTrader's Profile Server.

*OLD*

URL Equinix:                 [https://simu1.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/]

URL Hausen:                 [https://simu2.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/]

IP Equinix:                     193.29.80.74

IP Hausen:                    193.29.80.82

Port:                             60104

Protocol:                                   HTTPS

*NEW*

URL Equinix:                 [https://simu1-profiles.xbid.deutsche-boerse.com:60104/xbid-simu/|https://simu1_profiles.xbid.deutsche-boerse.com:60104/xbid-simu/]

URL Hausen:                 [https://simu2-profiles.xbid.deutsche-boerse.com:60104/xbid-simu/|https://simu2_profiles.xbid.deutsche-boerse.com:60104/xbid-simu/]

IP Equinix:                     193.29.80.74

IP Hausen:                    193.29.80.82

Port:                             60104

Protocol:                                   HTTPS

Please let us know when we can turn off the old once. No impact on CT is expected before or after turning off the old endpoints. New connectivity details document will be provided after the OLD addresses will be turned down.","02/Sep/20 10:04;ek176;[~yn731] FYI: Similar changes will be performed for CUTEs and LIPs and should be communicated. And, of course, finally for PROD.

 

The PR for CUTEs: [https://github.deutsche-boerse.de/dev/xbid.comtrader/pull/12]

The endpoint for PROD is already updated (not effective until release): [https://github.deutsche-boerse.de/dev/xbid.comtrader/commit/1607119115c7dcd564057598c96a5d67137c404e]

Prepared CN check PR: [https://github.deutsche-boerse.de/dev/xbid.comtrader/pull/11]","15/Sep/20 10:05;iv732;Configured updated to use wildcard cert: @xbcutsweb1:/shrd/xbid-cute-ctp-web1/config/conf.d/xbid_ctp.conf

Instance xbid-cute-ctp-web1 restarted.","15/Sep/20 14:18;ek176;The endpoints below have been tested. All return correct SSL certificate with a 401 Unauthorized result (as expected).

The IP address for all the endpoints and port below remains the same: 
 * IP: 193.29.80.72
 * Port: 60304

 
|Env|Config|Primary/Backup|CT config|Endpoint|
|ctpa|NEW|primary|./jnlp/ctpa-xsob-ext.jnlp.json|*[https://ctpa-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpa/services/*]|
|ctpb|NEW|primary|./jnlp/ctpb-xsob-ext.jnlp.json|*[https://ctpb-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpb/services/*]|
|ctpc|NEW|primary|./jnlp/ctpc-xsob-ext.jnlp.json|*[https://ctpc-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpc/services/*]|
|ctpd|NEW|primary|./jnlp/ctpd-xsob-ext.jnlp.json|*[https://ctpd-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpd/services/*]|
|ctpe|NEW|primary|./jnlp/ctpe-xsob-ext.jnlp.json|*[https://ctpe-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpe/services/*]|
|ctpf|NEW|primary|./jnlp/ctpf-xsob-ext.jnlp.json|*[https://ctpf-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpf/services/*]|
|ctpg|NEW|primary|./jnlp/ctpg-xsob-ext.jnlp.json|*[https://ctpg-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpg/services/*]|
|ctph|NEW|primary|./jnlp/ctph-xsob-ext.jnlp.json|*[https://ctph-profiles.xbid.deutsche-boerse.com:60304/xbid-ctph/services/*]|
|ctpi|NEW|primary|./jnlp/ctpi-xsob-ext.jnlp.json|*[https://ctpi-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpi/services/*]|
|ctpj|NEW|primary|./jnlp/ctpj-xsob-ext.jnlp.json|*[https://ctpj-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpj/services/*]|
|ctpk|NEW|primary|./jnlp/ctpk-xsob-ext.jnlp.json|*[https://ctpk-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpk/services/*]|
|ctpl|NEW|primary|./jnlp/ctpl-xsob-ext.jnlp.json|*[https://ctpl-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpl/services/*]|
|ctpm|NEW|primary|./jnlp/ctpm-xsob-ext.jnlp.json|*[https://ctpm-profiles.xbid.deutsche-boerse.com:60304/xbid-ctpm/services/*]|
|ctso|NEW|primary|./jnlp/ctso-xsob-ext.jnlp.json|*[https://ctso-profiles.xbid.deutsche-boerse.com:60304/xbid-ctso/services/*]|
|cute|NEW|primary|./jnlp/cute-xsob-ext.jnlp.json|*[https://cute-profiles.xbid.deutsche-boerse.com:60304/xbid-cute/services/*]|
|lipa|NEW|primary|./jnlp/lipa-xsob-ext.jnlp.json|*[https://lipa-profiles.xbid.deutsche-boerse.com:60304/xbid-lipa/services/*]|
|lipb|NEW|primary|./jnlp/lipb-xsob-ext.jnlp.json|*[https://lipb-profiles.xbid.deutsche-boerse.com:60304/xbid-lipb/services/*]|

Created via [check.sh|https://github.deutsche-boerse.de/ek176/shared/blob/master/utils/check_cutes_CTP_ssl/check.sh] script.","15/Sep/20 16:24;ek176;Conndetails proposal added (autogenerated!). Need to be human-checked.","15/Sep/20 16:49;ek176;CTPA:

Tested OLD CTP server: {color:#00875A}CN mismatch {color}(expected):
{noformat}
2020-09-15T16:47:25.776+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - CT: 3.1.1-SNAPSHOT/2020-09-15T14:29:18Z

Caused by: java.io.IOException: The https URL hostname does not match the Common Name (CN) on the server certificate in 
the client's truststore.  Make sure server certificate is correct, or to disable this check (NOT recommended for product
ion) set the CXF client TLS configuration property ""disableCNCheck"" to true.
{noformat}
Tested NEW CTP server: {color:#00875A}OK{color} (Unauth, no CN error; expected):
{noformat}
Caused by: com.deutscheboerse.comxerv.comtrader.service.profile.ProfileServiceAuthenticationException: Remote profile se
rvice authentication failed. Invalid username or password.
{noformat}","16/Sep/20 08:06;ek176;CN Check enabled in the CT for CUTES. Code merged. Can be disabled from the commandline by:
{code:java}
-Djavaws.com.deutscheboerse.comxerv.comtrader.ctpSslCertCommonNameCheckDisable=false
{code}

ComTraders to be released within XP-3514",,,,,,,,,,,,,,,,,,,,
Communicate development impact to customers,XP-3316,98291,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ub113,ei349,ei349,22/Jul/20 10:23,05/Oct/20 15:02,22/Feb/21 13:26,05/Oct/20 15:02,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Customer impact clarity{color}
h2. Current Situation

During the development of R3.1 we had also internal scope resulting from different DBAG or Energy Section initiatives which might have impact on XBID noticeable to customers.
h2. Proposed Solution 

Communicate to customers all impact resulted from R3.1 internal development. 

Hints: 
 * OPS should have consolidated output which was continuously communicated from development. 
 * Sources of customer impact
 ** penetration tests fixes (password policies, email headers, validation messages, ... )
 ** security standards (application labeling)
 ** tech debt - AFAIK RabbitMQ upgrade but probably no other impact. Better to double check
 * Double check with somebody from development

h2. Acceptance Criteria 
 * List of all items with understandable customer impact 
 * Customer E-mail draft sent all BOs,PO,ACM ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18576000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xvw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 2) Sonar Quality gate - add check to the nightly pipelines ,XP-3315,98283,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ll664,lt112,22/Jul/20 08:38,06/Nov/20 11:10,22/Feb/21 13:26,27/Jul/20 11:19,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Quality Gate Improvement{color}
h2. Current Situation

We have the Sonar Quality Gate as a part of our DoD: [https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?spaceKey=XBID&title=Definition+of+Done+and+Potentially+Shippable]

But we don't check the status very often.
h2. Proposed solution 

Configure nightly builds so they fail if quality gate fails (doesn't work like this at the moment).
 [https://www.jenkins.io/blog/2017/04/18/continuousdelivery-devops-sonarqube/]
 * Relevant for important projects:
 ** XBID 
 ** SPM
 ** Report Tool
 ** ComTrader",,ek176,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18144000,,,,,,,,,,,,,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b70l:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/20 11:20;lt112;https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-report-tool-nightly-pipeline/
https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-comtrader-nightly-pipeline/
https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-develop-nightly-pipeline/
https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-shipping-nightly/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
R3.1 Buffer HOT,XP-3311,98275,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,21/Jul/20 14:20,20/Aug/20 17:20,22/Feb/21 13:26,05/Aug/20 10:17,,,3.1.0,,,,,,,,,,,"empty buffer for various emerging tasks based on sprint context
* do not take this task
* will be automatically (manually) done at the end of sprint ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18662400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9on:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
R3.1 Buffer Alpha,XP-3310,98274,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,21/Jul/20 14:19,20/Aug/20 17:20,22/Feb/21 13:26,05/Aug/20 10:49,,,3.1.0,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18662400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9hr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
No AMS logs in Kibana/EBSM,XP-3309,98265,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ll664,ll664,21/Jul/20 12:25,30/Sep/20 12:06,22/Feb/21 13:26,27/Sep/20 17:51,,,Not a release,,,,,,,,,,,"Configure it for all {{xb*ams*}} envs/instances, but mainly for PROD.

 

Steps needed: 
 * analyze logs 
 * find out if they have mutliline and what's the timestamp 
 * modify inventory 
 * create elastic search pipelines to parse and ingest log lines",,hw120,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,12700800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bdql:zzy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/20 17:50;hw120;Luckily it follows standards for tomcat services so I could just deploy filebeat there.

Deployed on all the environments.

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1238/console]

Logs are visible in kibana

[https://kibana.energy.svc.dbgcloud.io/goto/ba88542abd178b0375556b2e816dce0f]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM continuos fails to trigger e2e pipeline,XP-3308,98261,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,21/Jul/20 10:58,30/Sep/20 11:34,22/Feb/21 13:26,30/Sep/20 11:22,,,3.1.2,,,,,,,,,,,see https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy%2Fxbid-end-to-end-dynamic-pipeline/detail/xbid-end-to-end-dynamic-pipeline/1097/pipeline,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18662400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9io:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 18,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3942,XP-3345-version-bump,develop,XP-3922-develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade Tomcat for XBID 3.1 to latest 8.5.x,XP-3307,98257,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,21/Jul/20 10:41,20/Aug/20 17:20,22/Feb/21 13:26,11/Aug/20 11:49,,,3.1.1,,,,,,,,,,,"With 3.1 release we should upgrade Tomcat.

Currently we plan 8.5.54 (see SERVICE-3669), but couple of new vulnerabilities were discovered:
{code:java}
CVE-2020-13934
CVE-2020-13935
{code}
We should upgrade to latest 8.5.x

Upgrade docker images/internal envs.

Inform Techops to do the same on servers. ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16848000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Aug/20 11:44;ll664;Tomcat upgraded, tested on Docker and XBID SYT1.

 

Future deployment updated (SERVICE-3669).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add buildnumber to SM and Report Tool,XP-3306,98256,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,21/Jul/20 10:33,31/Aug/20 15:38,22/Feb/21 13:26,23/Jul/20 10:43,,,3.1.0,,,,,,,,,,,"Both module should log version + build number on startup, as XBID does.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18662400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9hk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 13 (S),Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3279-am-snake-case,XP-3306,acceptance,XP-3285-am-atc-utilization,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extract AM reporting into separate service,XP-3295,98123,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,ll664,ll664,16/Jul/20 13:26,20/Aug/20 08:02,22/Feb/21 13:26,11/Aug/20 09:19,,,3.1.1,,,,,,,,,,,"Report-tool is becoming too big and this brings couple of problems that arose during investigation of incorrect ACER reports (XP-3251).

In a nutshell, it was too hard to track what changes were deployed to particular Report Tool due to large number of deployments and changes made. Most of the were related to SLA reporting, so it was hard to see what bugfix of ACER was deployed and when.

To avoid this, we should extract reporting of AM into separate service.

Benefits:
 * 3 separated services for the distinct reporting domains - SLA, ACER, AM
 * isolated release and deployment lifecycle
 * easier change tracking and troubleshoot
 * independent services does not affect each other. For instance, in the past OOM in SLA reporting brought whole node down and affect data collection for ACER
 * code change in one area does not affect other one
 * faster builds - currrently it takes ~20 mins, needs to run all tests for SLA/ACER even for a tiny changes in AM code

Suggested approach:
 * fork {{m7.xbid-report-tool}} into {{xbid.am-reporting}} repository
 * complete git history would be kept
 * remove SLA/ACER related code
 * remove AM functionality from original Report-Tool
 * deploy to same VM as original Report-Tool
 * a new (logical) DB would be required, Postgres is already running or Report-Tool VMs
 * setup deployments, builds, etc.
 * create followup ticket to make ACER a separate service

*Hints:*
 * same PG instance
 * DB separated 
 * same virtual machine 
 * remove tables from DBs where are not needed anymore
 * shrink the flyway migration scripts (we have currently 30 for report tool)
 ** make it one just for i.e. AM reporting. ",,ll664,,,,,,,,,,,,,,,,,,,,XP-3363,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16848000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3359,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-4526-resource-managment-fix,develop,XP-3230,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Aug/20 09:19;ll664;New service created here: https://github.deutsche-boerse.de/dev/xbid.am-reporting

All the non-related code has been removed, builds/pipeline set up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible XBID inventory - duplicate mail_user_domain definition,XP-3294,98103,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,16/Jul/20 11:14,20/Aug/20 08:02,22/Feb/21 13:26,14/Aug/20 15:08,,,3.1.1,,,,,,,,,,,"The vars mail_user_domain and usermail_domain defined in inventory/xb/vars.xml have the same meaning.

All modules should use mail_user_domain which has consistent name with other mail variables and usermail_domain should be removed

Double check that usermail_domain is not used by a role shared with other projects.",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19094400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update product name in tosca dataset to align with product name on PROD,XP-3293,98092,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,16/Jul/20 10:08,11/Sep/20 14:12,22/Feb/21 13:26,22/Jul/20 11:02,,,3.1.0,,,,,,,,,,,"Update product name in tosca dataset to align with product name on PROD.

For testing purpose, we need to have product name the same as in PROD

- XBID_Hour_Power
- XBID_Half_Hour_Power
- XBID_Quarter_Hour_Power",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19094400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b8hs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update default pg_hba.conf for xbproddbr1/2 hosts,XP-3288,97987,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,yo218,yo218,14/Jul/20 09:36,09/Nov/20 08:22,22/Feb/21 13:26,09/Nov/20 08:22,,,,,,,,,,,,,,"Please update the default pg_hba.conf for the replica hosts and add the following line:

host all uapp01xbprodcor 10.139.54.203/32 md5

This will enable the statistics generator to connect to the database. As you can see in the related ticket XP-3237, I added the line manually and reloaded the process, but it will be gone after the next redeployment/reinit of the replica hosts",,cs687,ei349,yo218,,,,,,,,,,,,,,,,,,,,,XP-3237,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,pg_hba.conf entry is on both hosts *xbprodsla1/2* and on both cluster (async/sync) active running. no need to keep the ticket open for XB-3383,,,,,,,,,,,,,,9072000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ax45:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),Alpha Sprint 18,Alpha Sprint 19 (S),Alpha Sprint 20,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/20 15:08;ei349;[~hw120] link this also to the automation ticket please. ","09/Nov/20 08:21;cs687;no need to keep this ticket open.
all the necessary pg_hba.conf settings are im-place on both hosts both clusters.

*I put a reminder to linked ticket XP-3383*
","09/Nov/20 08:22;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TO - Fix Squid cache vulnerability ,XP-3284,97961,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,13/Jul/20 12:26,15/Oct/20 15:05,22/Feb/21 13:26,15/Oct/20 15:05,,,Not a release,,,,,,,Security,TechOps,,,"*VMT Tickets due April, 2021*

 

The Squid cache is vulnerable: _SQUID-2020:7 Cache Poisoning Issue in HTTP Request processing_ *CVE-2020-15049*

[https://github.com/squid-cache/squid/security/advisories/GHSA-qf3v-rc95-96j5]

Patched versions (safe): 4.12, 5.0.3

Affected (reported) hosts:
 * xbinteprx1, xbinteprx2
 * xbcutsprx1
 * xbsimuprx1, xbsimuprx2
 * xbprodprx1, xbprodprx2

AC: Fixed versions are used on the above hosts. Eventually, plan to eliminate.

DoD: CERT-663 to CERT-669 tickets are closed (due Apr, 2021) in VMT.

 

Hint: consult system engineering. 

 

[~hw120], [~iv732]: can you please discuss with SysEng how to resolve this item? (on product or syseng level?)",,ek176,hw120,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-27,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,11145600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1665,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bh9o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/20 10:29;hw120;Created ticket with SYSENG, investigated affected versions and checked redhat squid release notes.

Consulted with Lambert, there is no fix available from redhat yet.","14/Sep/20 14:10;zi174;This issue needs to be fixed by RedHat. Not fixable from XBID side. ","14/Oct/20 09:59;yo218;There is a new patch available: 

squid-3.5.20-17.el7_9.4.src.rpm

further details: [https://access.redhat.com/errata/RHSA-2020:4082]

Patches are ready to be installed, please let us know whether you want to schedule a downtime for customer facing environments or whether we can perform it any time (it is just required for alarmtilt, right? So personally I would consider the impact very low, but this is just my humble opinion) ","15/Oct/20 15:05;yo218;patches applied for all proxies (internal/cute/simu/prod)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ACER Reports for H1 2020,XP-3283,97959,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,qm925,qm925,13/Jul/20 12:22,31/Aug/20 15:37,22/Feb/21 13:26,20/Jul/20 11:55,,,3.1.0,,,,,,,,,,,"The ACER Reports for H1/2020 are available for download by the NEMOs by Friday, 17/07 EOD. After this period they should be removed from the SFTP server. ",,iv732,qm925,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18748800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b7og:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/20 12:33;yo218;I will be on vacation at that time. [~iv732] please delete the reports which I copied in XP-3209 on Monday,  20th of July","20/Jul/20 11:00;iv732;[~qm925] deleted the current reports on SFTP servers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update Jenkins job to deploy Wildcard cert,XP-3276,97918,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,iv732,iv732,10/Jul/20 13:34,11/Nov/20 13:39,22/Feb/21 13:26,11/Nov/20 13:39,,,Not a release,,,,,,,,,,,"Update the Jenkins job to add following functions:
1. backup old cert/key before requesting new one
2. deploy the new wildcard cert to ALL envs at the same time
",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8812800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xro:000c09i0000000009",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/20 13:38;iv732;The creating of CSR, importing cert to vault, and deploying new wildcard cert to Prod, Simu and all Test envs can be done now using the Jenkins jobs under:  https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID%20SSL%20Certificate/

Task is done.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move module versions to 3.1.x,XP-3269,97885,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ei349,ei349,09/Jul/20 09:37,31/Aug/20 13:21,22/Feb/21 13:26,29/Jul/20 11:44,,,3.1.0,,,,,,,,,,,"All modules (part of XBID solution) should be upgraded to version 3.1.x if possible
* reporting engine is an exception",,dm700,eg288,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17971200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9on:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,why-optional,XP-3777,ramping-analysis,xbid-losses-poc,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,cpm,XP-4505_xbid_hpfortify_upgrade,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,master,master-acceptance,XP-3443-rounding,XP-3829-routing-integration,XP-3243-report-tool-hp-fortify,acceptance,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-3520-ramping_analysis,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/Jul/20 17:10;eg288;* xbid and sm version has been changed to 3.1.0-SNAPSHOT
* branch xbid-3.0.x has been renamed to xbid-losses-poc including master branch for release and also corespoding branch in xbid-test
* end-to-end-test pipeline compatibility pack for branch xbid-3.0.x has been removed, the branch is considered obsolete

PR:
https://github.deutsche-boerse.de/dev/xbid/pull/748
https://github.deutsche-boerse.de/dev/xbid/pull/749
https://github.deutsche-boerse.de/dev/xbid-pipeline/pull/90
https://github.deutsche-boerse.de/dev/m7.xbid-shipping-module/pull/836",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TECHOPS - Automate SFTP tasks such as Create new user, Add new key ",XP-3266,97859,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,iv732,iv732,08/Jul/20 15:42,27/Aug/20 10:22,22/Feb/21 13:26,26/Aug/20 11:11,,,3.1.1,,,,,,,TechOps,,,,"* finish Jenkins job
 * modify playbook
 * convert vault entries
 * debug problem ",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15984000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xtk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/20 11:54;iv732;https://github.deutsche-boerse.de/dev/energy.xbid.sftp
https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/SFTP
","12/Aug/20 11:04;iv732;Playbook updated. Now user info should only be stored in vault, no longer in the repo.
Now updating all Vault entries to work with the new playbook","20/Aug/20 09:16;iv732;Playbook done
Vault done
Current issue: proftpd doesn't create User Home Directory. Debugging...","20/Aug/20 17:56;iv732;Solved the issue.
Migration:
1. inte : DONE
2. cuts: DONE
3. simu: DONE
4. prod: DONE

Playbook done.
Jenkins job:  https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-SFTP-User%20tasks/
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test coverage in XBID develop,XP-3265,97858,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,dm700,dm700,08/Jul/20 15:19,31/Aug/20 15:39,22/Feb/21 13:26,03/Aug/20 10:32,,,3.1.0,,,,,,,,,,,coverage in SOnar on xbid develop has drop significantly in short time - https://sonar.energy.dev.dbgcloud.io/project/activity?custom_metrics=coverage&graph=custom&id=com.deutscheboerse.energy.xbid%3Axbid%3Adevelop,,dm700,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/20 15:19;dm700;xbid develop.png;https://jira.deutsche-boerse.com/secure/attachment/85470/xbid+develop.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17280000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b8hw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2979-postgresql,XP-3361,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,master-acceptance,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-3243-report-tool-hp-fortify,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,acceptance,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_reporting_tools_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Aug/20 14:34;lt112;real coverage ok, technical issue in measuring as expected, fixed (back to 73.9% https://sonar.energy.dev.dbgcloud.io/dashboard?id=com.deutscheboerse.energy.xbid%3Axbid%3Adevelop)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Security tests run automatically - DEADLINE 31.12.2020,XP-3263,97848,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,08/Jul/20 13:18,20/Jan/21 12:11,22/Feb/21 13:26,04/Jan/21 11:30,,,,,,,,,,,,,,"We have no security test cases. These should be run automatically, see XP-2987

Tests to be used: Cucumber GUI tests

Security tool: OWASP ZAProxy/BUrpSuit in headless mode

AC: 
 * Security tests run automatically",,ek176,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4157,,,XP-4273,,,,XP-2997,,,,,,,"08/Sep/20 12:46;hj444;XBID_Security_tests_analysis_v3.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87345/XBID_Security_tests_analysis_v3.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,3542400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3469,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w3:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),Alpha Sprint 24,Alpha Christmas Sprint (S),,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-4526-resource-managment-fix,develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Nov/20 13:08;zi174;[~ek176] please chcek this ticket if it is still relevant, if yes we would need to solve it until the end of the year","20/Nov/20 13:50;ek176;Yes, it's still relevant. Need to be planned into sprint.","20/Nov/20 17:08;ek176;Issue split into:
|XP-4157|(Split 2) Security tests run automatically - DEADLINE 31.12.2020|
","22/Dec/20 16:24;ek176;Example of failing (unsuppressed) alerts:
{noformat}
Copying log to: target/selenium-tests-logs/xbid-cmminteg-db
File closed: True
[INFO] 
[INFO] --- exec-maven-plugin:1.6.0:exec (docker-copy-zaproxy-alertsSummary) @ selenium-tests ---
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100    71  100    71    0     0     79      0 --:--:-- --:--:-- --:--:--    79
100    71  100    71    0     0     79      0 --:--:-- --:--:-- --:--:--    79
[INFO] 
[INFO] --- exec-maven-plugin:1.6.0:exec (docker-copy-zaproxy-alerts) @ selenium-tests ---
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
  0 2146k    0 15809    0     0  12013      0  0:03:02  0:00:01  0:03:01 12012
100 2146k  100 2146k    0     0  1624k      0  0:00:01  0:00:01 --:--:-- 1623k
[INFO] 
[INFO] --- exec-maven-plugin:1.6.0:exec (docker-zaproxy-alerts-quality-gate) @ selenium-tests ---
Using alerts file: target/selenium-tests-logs/owasp-zap-alerts.json
Using suppressions file: target/classes/owasp-zap-suppressions.json
Suppressing: CWE: 565, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-cmi-1:8080/cmm-integration/, name: Loosely Scoped Cookie
Suppressing: CWE: 16, WASC: 13, risk: Low, confidence: Medium, url: http://xbid-cmi-1:8080/cmm-integration/, name: Cookie Without SameSite Attribute
...
...
...
Suppressing: CWE: 565, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-trading-1:8080/xbid-trading/logout.html, name: Loosely Scoped Cookie
OWASP ZAP Quality gate: AlertsTotal: 807, AlertsSuppressed: 803, AlertsValid: 4
Error. Unresolved alerts found: 4
ZAP_Alert: CWE: 16, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-reporting:8080/xbid-reporting/sob/reporting.html, name: Charset Mismatch (Header Versus Meta Content-Type Charset)
ZAP_Alert: CWE: 16, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-reporting:8080/xbid-reporting/sob/runjobperiod.html, name: Charset Mismatch (Header Versus Meta Content-Type Charset)
ZAP_Alert: CWE: 16, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-reporting:8080/xbid-reporting/sob/reporting.html?dateFieldLength=10, name: Charset Mismatch (Header Versus Meta Content-Type Charset)
ZAP_Alert: CWE: 16, WASC: 15, risk: Informational, confidence: Low, url: http://xbid-reporting:8080/xbid-reporting/sob/reports.html, name: Charset Mismatch (Header Versus Meta Content-Type Charset)
[ERROR] Command execution failed.
org.apache.commons.exec.ExecuteException: Process exited with an error: 2 (Exit value: 2)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.execute(DefaultExecutor.java:166)
	at org.codehaus.mojo.exec.ExecMojo.executeCommandLine(ExecMojo.java:804)
	at org.codehaus.mojo.exec.ExecMojo.executeCommandLine(ExecMojo.java:751)
	at org.codehaus.mojo.exec.ExecMojo.execute(ExecMojo.java:313)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)
	at org.jvnet.hudson.maven3.launcher.Maven33Launcher.main(Maven33Launcher.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchStandard(Launcher.java:330)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:238)
	at jenkins.maven3.agent.Maven33Main.launch(Maven33Main.java:178)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at hudson.maven.Maven3Builder.call(Maven3Builder.java:139)
	at hudson.maven.Maven3Builder.call(Maven3Builder.java:70)
	at hudson.remoting.UserRequest.perform(UserRequest.java:211)
	at hudson.remoting.UserRequest.perform(UserRequest.java:54)
	at hudson.remoting.Request$2.run(Request.java:369)
	at hudson.remoting.InterceptingExecutorService$1.call(InterceptingExecutorService.java:72)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[JENKINS] Archiving disabled
[WARNING] Attempt to (de-)serialize anonymous class org.jfrog.hudson.maven2.MavenDependenciesRecorder$1; see: https://jenkins.io/redirect/serialization-of-anonymous-classes/
[JENKINS] Archiving disabled[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 19:03 min
[INFO] Finished at: 2020-12-22T16:20:02+01:00

[INFO] Final Memory: 64M/700M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile ""selenium-tests"" could not be activated because it does not exist.
Waiting for Jenkins to finish collecting data
[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:exec (docker-zaproxy-alerts-quality-gate) on project selenium-tests: Command execution failed. Process exited with an error: 2 (Exit value: 2) -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
channel stopped
Archiving artifacts
Setting status of b8b05648c2a3a29fe59e72680fbdacc89cdf86ce to FAILURE with url https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-test-selenium-pulls/413/ and message: 'Build finished. '
Using context: xbid-test-selenium-pulls
[WS-CLEANUP] Deleting project workspace...
[WS-CLEANUP] Deferred wipeout is used...
[WS-CLEANUP] done
Finished: FAILURE{noformat}","22/Dec/20 17:08;ek176;Example of passing check (all alerts are suppressed):
{noformat}
[INFO] --- exec-maven-plugin:1.6.0:exec (docker-zaproxy-alerts-quality-gate) @ selenium-tests ---
Using alerts file: target/selenium-tests-logs/owasp-zap-alerts.json
Using suppressions file: target/classes/owasp-zap-suppressions.json
OWASP ZAP Quality gate: AlertsTotal: 806, AlertsSuppressed: 806, AlertsValid: 0
[INFO] {noformat}","04/Jan/21 11:30;ek176;Nightly builds 880 to 884 passing OK. Suppression info is printed, alertsSummary and alerts detail JSON files are found within archived artefacts. Closing the ticket (followup ticket created).

 

Example (pipeline) output:
{noformat}
[INFO] --- exec-maven-plugin:1.6.0:exec (docker-zaproxy-alerts-quality-gate) @ selenium-tests ---
Using alerts file: target/selenium-tests-logs/owasp-zap-alerts.json
Using suppressions file: target/classes/owasp-zap-suppressions.json
OWASP ZAP Quality gate: AlertsTotal: 806, AlertsSuppressed: 806, AlertsValid: 0{noformat}
Alerts summary (JSON):
{code:java}
{""alertsSummary"":{""High"":28,""Low"":160,""Medium"":28,""Informational"":590}}
{code}","11/Jan/21 14:12;ek176;Fix: Removed -newsession and -last_scan_report parameters that were causing trouble (non-idempotent start).

When needed, a custom script must be created to provide unique params each run (start).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Create Jenkins pipeline/playbook for ansible deployment,XP-3262,97847,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,qo794,qo794,08/Jul/20 13:14,04/Aug/20 19:53,22/Feb/21 13:26,16/Jul/20 13:27,,,3.1.0,,,,,,,,,,,"The current Jenkins pipeline [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy-ansible/] allows deploying only one component at a time, it is not possible to deploy the whole xbid. And other features are missing too. In general in this shape it's not possible to use it. See all possibilities we have with the current Jenkins deploy job: [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy%20form/]

Maybe something similar to M7? {{jenkins/deploy_full.groovy}}

 

Pipeline will contain env, dataset, infrastructure, modules, etc. 

This can be enriched when other modules are onboarded to ansible. ",,lt112,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19094400,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:yi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jul/20 13:27;lt112;https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-full-ansible-deploy/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Ansible - SMI Deployment ,XP-3261,97846,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,eh941,08/Jul/20 12:28,04/Aug/20 19:53,22/Feb/21 13:26,15/Jul/20 09:04,,,3.1.0,,,,,,,,,,,"Hint:
 * Similar to CMI/Xbid Core. 
 * use basic role XBID Tomcat with working scripts.

 

 ",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19785600,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,Alpha Sprint 13 (S),,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revert GUI application labelling,XP-3255,97839,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ei349,ei349,08/Jul/20 11:21,20/Aug/20 08:02,22/Feb/21 13:26,06/Aug/20 16:27,,,3.1.1,,,,,,,,,,,"Verify that there is no label on GUI except printable artifacts. 

If you find any Confidental label - create tickets with following description: 

- Revert all GUI labeling in applications. 
- Only where it should remains are printable documents like emails and reports. ",,ei349,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17193600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbq:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Aug/20 16:27;od044;Test passed on XBID R3.1.2-SNAPSHOT (Build 63b516d589cb02490696dfd570e7d59b96ed7dd4) and SM 3.1.1-SNAPSHOT
- Confidental label is not occurred anywhere on GUI of module CMM, CMI, SOB, SM

Thus we can close this ticket no additional for reverting is necessary. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
H1 2020 Acer Reports check,XP-3251,97834,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ei349,ei349,08/Jul/20 10:28,20/Aug/20 17:15,22/Feb/21 13:26,23/Jul/20 16:43,,,3.1.0,,,,,,,,,,,There are already generated reports for Acer from H1 2020. Please perform sanity check and inform in #xbid_scrum and tag PO and ACM about assumed correctness. ,,ei349,ll664,qm925,radeale,tr866,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3329,XBID-5187,XBID-4943,,,,,"14/Jul/20 15:29;tr866;Acer Reports imported to Excel - H1 2020 Check.zip;https://jira.deutsche-boerse.com/secure/attachment/85691/Acer+Reports+imported+to+Excel+-+H1+2020+Check.zip","22/Jul/20 12:14;tr866;Imported fixed Acer Reports to Excel.xlsx;https://jira.deutsche-boerse.com/secure/attachment/85963/Imported+fixed+Acer+Reports+to+Excel.xlsx","23/Jul/20 12:48;tr866;Retest 2 - Acer Reports Imported to Excel - H1 2020.zip;https://jira.deutsche-boerse.com/secure/attachment/85976/Retest+2+-+Acer+Reports+Imported+to+Excel+-+H1+2020.zip","14/Jul/20 15:29;tr866;Suspicious Volume Reports for January.zip;https://jira.deutsche-boerse.com/secure/attachment/85692/Suspicious+Volume+Reports+for+January.zip","16/Jul/20 16:13;ll664;acer_h1_2020_v2.zip;https://jira.deutsche-boerse.com/secure/attachment/85796/acer_h1_2020_v2.zip","22/Jul/20 16:20;ll664;acer_h1_2020_v3.zip;https://jira.deutsche-boerse.com/secure/attachment/85970/acer_h1_2020_v3.zip",,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18403200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b3xj:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 13 (S),Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3306,XP-3279-am-snake-case,XP-3291,XP-3324-am-mira-test,XP-3281,XP-3285-am-atc-utilization,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/Jul/20 12:49;tr866;h4. Check of the problems found in previous reports:
 # 
 ## EIC check
 ### German MA EIC are used (/)
 ### 10YDE-ENBW-----N EIC not found (/)
 ### 10YDE-EON------1 EIC not found (/)
 ### 10YDE-RWENET---I EIC not found (/)
 ### 10YMA-ONE------O EIC not found (/)
 ## Volumes check: values for volumes for Quarterly product X02 should have 3 decimals and at least some should have not all 0 starting from 2nd decimal:
 ### INTRADAY_TRADE_VOLUME:
 **** Highly suspicious *{color:#de350b}report for 01(January){color}*: compared to all other months all values are having only *{color:#de350b}3 decimals{color}* instead of 5 decimals and all last two decimals are *{color:#de350b}00{color}* (x)
 **** all other months 02-06 look ok: 5 decimals and non-zero digits on lower decimals (/)
 ### TRADE_VOLUME_HOUR_TO_DELIVERY:
 **** *{color:#de350b}SAME PROBLEM{color}*: Highly suspicious *{color:#de350b}report for 01(January){color}*: compared to all other months all values are having only *{color:#de350b}3 decimals{color}* instead of 5 decimals and all last two decimals are *{color:#de350b}00{color}* (x)
 **** all other months 02-06 look ok: 5 decimals and non-zero digits on lower decimals (/)
 ## *OMIE* (DA with EIC 10YES-REE------0) is still having records for *X04 block product* only in Bid Ask Spread report, which we concluded before that it's correct and it continues to appear every time (/)
 ## Check if products X02(Half Hourly) and X03(Quarter Hourly) are also present only for the expected bidding zones:
 ### X02: DE (10Y1001A1001A82H), FR (10YFR-RTE------C) (/)
 ### X03: DE (10Y1001A1001A82H) , AT (10YAT-APG-----L) , SI (-10YSI-ELES-----O) (/)
 ## EICs of the last joining bidding zones in 2nd wave appear in all reports for all months: (/)
 --- 10YCA-BULGARIA-R
 --- 10YCZ-CEPS-----N
 --- 10YHR-HEP------M
 --- 10YHU-MAVIR----U
 --- 10YPL-AREA-----S
 --- 10YRO-TEL------P
 --- 10YSI-ELES-----O

h4. Summary:

Following *volume reports* for *January* have *{color:#de350b}different number of decimals (3){color}* than the same reports for all *{color:#00875a}other months (5){color}* and all values are having *{color:#de350b}00{color}* for the 2 last decimals which doesn't make sense at least for Quarterly hourly X03 product:
 2020-01_INTRADAY_TRADE_VOLUME_2020-02-01-070000.xml
 2020-01_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-02-01-081500.xml

At least once there must happen a case similar to the example:
 0.1 MW of a 15-minute product yields 0.1 MW * 0.25h = 0.025 MWh","16/Jul/20 11:11;ll664;Indeed, the volume reports are incorrect for January 2020. The reason is that the H1 reports were taken from {{sla1}} node, which run and quite old version - 2.18 - in Feb 2020. The version did not include the conversion of quantities to MWHs (XP-2095, released in 2.21).

On 26.2., a new version 2.32 was deployed to {{sla1}} (SERVICE-5662) and reports were ok again. So the safest bet is to regenerate January 2020 reports again on {{sla1}} and create a new batch for H1. The only problem here is that we have already distributed the incorrect reports to customers (XP-3209), [~zi174], [~ei349], please suggest how to move forward on this.

Just a side note, reports on {{sla2}} aren't flawless too. They were multiple deployments of newer version, but some reports didn't contain the price conversion fix (XP-2582), released in 2.29. So simply taking reports from other node wouldn't work.","16/Jul/20 12:19;zi174;[~qm925] can you please check David's comment? From my point of view, the best approach would be generate the reports again with all correct values and deliver to the customer with information that the data for January are wrong. What do you think [~qm925]? ","16/Jul/20 13:58;qm925;Is it possible to generate the correct data for January as well somehow?","16/Jul/20 14:05;ll664;Yep, I'll generate corrected reports again and submit it here for a sanity check.","16/Jul/20 14:08;qm925;Ok, then please regenerate them. After we validate that all data is correct I will notify the clients, as the reports went out already last Friday. 

 ","16/Jul/20 16:13;ll664;Reports attached, it's again the whole bunch, but only january reports are regenerated. Please check [~tr866].

 [^acer_h1_2020_v2.zip] ","20/Jul/20 12:14;qm925;Hi guys, 

Could you please let me know what is the status of the validation of the reports? 
Would it be possible to provide the correct reports to the clients latest by tomorrow noon?","22/Jul/20 12:37;tr866;Hi, 
 sorry, we were having multiple ongoing tasks in paralel.
 Regarding the newly generated reports, they look all ok, the values are having correct number of {color:#00875a}*decimals and rounding* {color}looks good too.

On top of it I also noticed that in newly generated reports the confidential label was added which was missing before
{code:xml}
{<!-- The information displayed hereby are classified as: CONFIDENTIAL -->
{code}
and the name spaces in all newly generated reports are ns1:, which is correct.

Sadly thanks to that I realized then other reports for months 02-04 have *{color:#de350b}various name spaces{color}* and I think in context of this ticket XBID-4943 all the reports should have actually *ns1:*

List of name spaces used in the latest reports:
 {color:#00875a}month 06 : ns1 (/)
 month 05 : ns1 (/){color}
 {color:#de350b}month 04: (x)
 2020-04_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-05-01-084500 - ns3
 2020-04_WEIGHTED_AVERAGE_PRICE_2020-05-01-083000 - ns3
 2020-04_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-05-01-081500 - none
 2020-04_INTRADAY_TRADE_VOLUME_2020-05-01-070000 - ns2
 2020-04_BID_ASK_SPREAD_2020-05-01-053000 - ns3
 
 month 03: (x)
 2020-03_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-04-01-084500 - ns3
 2020-03_WEIGHTED_AVERAGE_PRICE_2020-04-01-083000 - n3
 2020-03_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-04-01-081500 - none
 2020-03_INTRADAY_TRADE_VOLUME_2020-04-01-070000 - ns2
 2020-03_BID_ASK_SPREAD_2020-04-01-053000 - ns3
 
 month 02: (x)
 2020-02_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-03-01-084500 - ns3
 2020-02_WEIGHTED_AVERAGE_PRICE_2020-03-01-083000 - ns3
 2020-02_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-03-01-081500 - none
 2020-02_INTRADAY_TRADE_VOLUME_2020-03-01-070000 - ns2
 2020-02_BID_ASK_SPREAD_2020-03-01-053000 - ns3{color}
 {color:#00875a}month 01 : ns1 (/)
{color}

Tomas","22/Jul/20 16:20;ll664;[~tr866] I've generated 02-04 month agains, namespaces fixed, pls check [^acer_h1_2020_v3.zip]","23/Jul/20 13:00;tr866;Name spaces got fixed correctly and stayed correct for the other reports.
All the previously checked items mentionned above were verified again for all reports for months 02-04 and everything looks good now. (/)(y)","23/Jul/20 13:05;qm925;That's great. Then we can upload them again on the sftp and once this is done, I will notify the clients.

Thank you, guys :) ","23/Jul/20 14:56;radeale;Once the task is done, please inform the customer (also) via XBID-5187 :)",,,,,,,,,,,,,,,,,,,,,,,,,
Integrate ComTrader with HP Fortify,XP-3245,97796,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,07/Jul/20 13:59,20/Aug/20 08:02,22/Feb/21 13:26,18/Aug/20 10:04,,,3.1.1,,ComTrader,,,,,,,,,"create jobs for prod  and develop.

Hint:

check [https://github.deutsche-boerse.de/dev/xbid-pipeline/blob/develop/hp-fortify-nightly]",,dm700,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-comtrader-develop-nightly-pipeline/
https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-comtrader-acceptance-nightly-pipeline/",,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate Reporting Engine with HP Fortify,XP-3244,97795,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,07/Jul/20 13:59,20/Aug/20 08:02,22/Feb/21 13:26,18/Aug/20 10:11,,,3.1.1,,,,,,,,,,,"create jobs for prod  and develop.

Hint:

check [https://github.deutsche-boerse.de/dev/xbid-pipeline/blob/develop/hp-fortify-nightly]",,dm700,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-reporting-engine-develop-nightly-pipeline/
https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-reporting-engine-acceptance-nightly-pipeline/",,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate Report Tool with HP Fortify,XP-3243,97794,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,07/Jul/20 13:59,20/Aug/20 08:02,22/Feb/21 13:26,18/Aug/20 10:03,,,3.1.1,,,,,,,,,,,"create jobs for prod  and develop.

Hint:

check [https://github.deutsche-boerse.de/dev/xbid-pipeline/blob/develop/hp-fortify-nightly]",,dm700,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-report-tool-nightly-pipeline/,,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3243-report-tool-hp-fortify,XP-3243-hp-fortify-develop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate SPM with HP fortify ,XP-3242,97793,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,07/Jul/20 13:51,19/Aug/20 14:59,22/Feb/21 13:26,19/Aug/20 14:59,,,Not a release,,,,,,,,,,,"create jobs for prod  and develop.

Hint:

check [https://github.deutsche-boerse.de/dev/xbid-pipeline/blob/develop/hp-fortify-nightly]",,dm700,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid stats loader - no data uploaded since 25.5.,XP-3237,97748,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eg288,eg288,eg288,03/Jul/20 15:14,04/Feb/21 16:32,22/Feb/21 13:26,06/Jul/20 14:38,,,3.1.0,,,,,,,,,,,"Data are missing in xbid statistics since 25.5.

[https://grafana.energy.svc.dbgcloud.io/d/XdDToRhik/orders-new-all?orgId=5&from=now-90d&to=now]

The data loader is not running probably. Please investigate.",,eg288,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b6hk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/20 14:38;yo218;the required entry got lost in pg_hba.conf

added it manually and reload the db:
{noformat}
host      all             uapp01xbprodcor 10.139.54.203/32 md5 {noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - CT Profile Storage deployment,XP-3235,97744,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eg288,eg288,03/Jul/20 14:24,20/Aug/20 08:02,22/Feb/21 13:26,17/Aug/20 16:17,,,3.1.1,,ComTrader,,,,,,,,,"h1. ComTrader Profile Server Ansible Deployment

Module CT Profile Storage (aka ctp) deployment should be migrated to ansible

Notes:
 # see role m7ctp for inspiration, but hopefully it will be possible to reuse xbtomcat as base role
 # energy-mkt-shrd - ctp deployement for test env is defined in syt2.xml

 

Hint:
 * it's Tomcat - check xbtomcat role used for other modules. 
 * there is ansible role from other product already - check if it can be used (but more complex, much higher activity)",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb93:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Identify all XP tickets PROD vs latest Develop,XP-3234,97741,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ei349,ei349,03/Jul/20 13:54,13/Aug/20 19:41,22/Feb/21 13:26,05/Aug/20 09:03,,,3.1.0,,,,,,,,,,,"Udpate [https://github.deutsche-boerse.de/dev/xbid-product/blob/develop/CHANGELOG.md]

so there will be visible all tickets resolved to R3.1.x compare to latest Prod version. 

 

Demo to POPOSH and team pls",,ei349,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/20 14:34;uv683;prod_vs_develop.xlsx;https://jira.deutsche-boerse.com/secure/attachment/86234/prod_vs_develop.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17366400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b9us:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jul/20 14:43;uv683;{code}git rev-list --oneline xbid-2.0.36.5..develop | grep -o -i -e 'XP-[0-9]\+' | sort | uniq | sed 's/^/https:\/\/jira.deutsche-boerse.com\/browse\//' > develop.csv{code}
* print commit hash prefix and commit message in one line
* contains all commits that are reachable from develop but not from xbid-2.0.36.5
* grep only ticket numbers
* -o print only the matched part of string
* -i ignore case
* -e regexp pattern
* sort alphabetically
* only unique ticket numbers
* append JIRA link

This results in a list of jira links that can be opened in Excel/Calc. In case that commits have been cherry picked into prod branch we need to the same for production branch and compare.
{code}git rev-list --oneline develop..xbid-2.0.36.5 | grep -o -i -e 'XP-[0-9]\+' | sort | uniq | sed 's/^/https:\/\/jira.deutsche-boerse.com\/browse\//' > prod.csv{code}

Just to be sure go through a ticket list in prod.csv and try to find given XP ticket as string in git on branch master-xbid-2.0.36.5. This can be nicely done in IDEA. It has to be done to verify that there is indeed a commit for this JIRA ticket and not that the ticket is just written in commit message as reference. The later should not happen often. If the ticket is indeed in prod branch, remove it from develop list if it is there - means it was cherry picked.
 
Last thing is to check if tickets from develop branch were not reverted
{code}git log xbid-2.0.36.5..develop --oneline |grep -i revert{code}
If there are some findings, check manually and potentially remove from develop list.
 
Now you can open your develop.csv and finetune it by copying e.g. status and overview from JIRA to respective tickets. Watch out for splits-there is no need to display all of them if there are commits for more than one split ticket, just read the overview:-)","30/Jul/20 14:46;uv683;Following modules has been searched and dev vs prod compared. Common merge-base commit date for modules added to the end. Before this date both develop and prod branches have the same commits.
* core,trading,cmi,cmm 2.4.2020
* shipping  7.8.2019
* reporting engine 11.5.2020
* comtrader 26.6.2019
* pmi logger 24.9.2019
* pmi archiving 14.2.2019
* alarm tilt client 14.2.2019
Result attached [^prod_vs_develop.xlsx] ","05/Aug/20 09:28;uv683;It seemed strange that xbid core prod vs develop have the merge-base commit from April 2020. It shouldn't be like this. So I have also double checked the results for core module by selecting some  commit from 6.3.2019 and using 
{code}
git rev-list --oneline 401d0e4402b542b6cebf22d1886df3db24500fb4..develop | grep -o -i -e 'XP-[0-9]\+' | sort | uniq 
{code}
to compare differences between develop and this commit and then between xbid-2.0.36.5 and this commit. 
{code}
git rev-list --oneline 401d0e4402b542b6cebf22d1886df3db24500fb4..xbid-2.0.35.5 | grep -o -i -e 'XP-[0-9]\+' | sort | uniq 
{code}
Then I created a diff from these lists. Result was the same. Branch xbid-2.0.35.x was indeed created from develop on 2.4.2020.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create common branching model for all XBID modules,XP-3233,97740,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,03/Jul/20 13:46,13/Aug/20 19:40,22/Feb/21 13:26,05/Aug/20 10:48,,,3.1.0,,,,,,,,,,,"All modules that are part of the delivery should have following branching structure:

{{develop}} - actively developed software version
{{acceptance}} - software being in the UAT phase, {{develop}} branch is merged here at the start of the UAT phase
{{prod}} - production code - {{acceptance}}  branch is merged here once it is deployed to PROD

List of modules:

TBD

 ",,dm700,ei349,ek176,ll664,qo794,,,,,,,,,,,,,,,,XP-3345,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17452800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xw0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3233-acceptance-jgitflow,XP-3922,fixing-owasp,fixing-hp-fortify-acceptance-2021-02-15,hotfix,prod,XP-4211-perf-analysis-jh,master-prod,XP-4370_acceptance_hp_fortify_issues,XP-3394_acceptance_flyway_standard_implementation,XP-4122-perf-analysis,XP-4349_acceptance_fix_hp_fortify_issues,XP-3394_acceptance_remove_unused_maven_properties,master-acceptance,XP-3496-acceptance,XP-4250,acceptance,XP-3233-prod-jgitflow,XP-4371_upgrade_dataset_version,XP-4275-acceptance,XP-3942-acceptance,XP-222-acceptance,XP-4152-acceptance,XP-3909,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Aug/20 11:10;ll664;Branches created and protection rules set up. Repose affected:

https://github.deutsche-boerse.de/dev/xbid
https://github.deutsche-boerse.de/dev/m7.xbid-shipping-module
https://github.deutsche-boerse.de/dev/xbid.comtrader
https://github.deutsche-boerse.de/dev/xbid-reporting-engine
https://github.deutsche-boerse.de/dev/xbid.access-management
https://github.deutsche-boerse.de/dev/m7.pmi-logger
https://github.deutsche-boerse.de/dev/m7.pmi-archiving","04/Aug/20 09:54;ll664;Confluence page to document the branching model: https://confluence.energy.svc.dbgcloud.io/display/XBID/Branching+model",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Split 1) CMI - OCC - VDA Interconnectors - Minimum, Original file content verification - implementation",XP-3230,97736,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,hj444,hj444,03/Jul/20 13:32,21/Dec/20 15:09,22/Feb/21 13:26,16/Sep/20 11:48,,,3.1.2,,,,,,,TestAutomation,,,,"more TCs will be added.
Same possible cases:
PDA-VDA-nonPDA : 
(DK1-DK1A-SE3) =>example : IC1: DK1-DK1A

                                                 IC2 : DK1A-SE3

TC1: setting for Minimum  VDA-PDA 
                         Minimum  VDA- nonPDA

 TC2: setting for Original VDA-PDA 
                         Minimum VDA-nonPDA

* Publish VDA-PDA 
              VDA- nonPDA
* Do allocation: VDA-PDA 
                        VDA- nonPDA
* Verify content of files
*NOTE :*
** Check before start - if is possible to use distribution scheduler for automation tests. If not create a task for adding needed objects, methods for creating test.
** *Before this task- XP-3343 has to be finished.*",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3593,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bgjw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4273-owasp-zap-enable,XP-4526-resource-managment-fix,develop,XP-3230,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible roles should support profiles,XP-3227,97713,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,03/Jul/20 09:18,20/Aug/20 17:14,22/Feb/21 13:26,17/Jul/20 09:34,,,3.1.0,,,,,,,,,,,"Currently all ansible roles use a shared xbtomcat role, which does not support profile setting (e.g. to specify dataset)",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19353600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b6a8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3227-profiles,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Jul/20 12:08;lt112;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/982
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1955",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ITDBR_XBID.doc: §6-8 Timeline, Testing,  Appendices",XP-3217,97696,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lw641,sw455,sw455,02/Jul/20 17:49,08/Feb/21 10:58,22/Feb/21 13:26,08/Feb/21 10:58,,,,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§5.2 Overall Recovery Timelines* 

through 

*§8 Appendices* 

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx]

 

 

Notes:
 * Section 6 - should represent our human validations (BizOps type 'shakedown')
 * Section 7 - we discussed we would fill in together and consult with ESO (it covers expected frequency of this type of testing, etc.)
 * Section 8 - ESO & [~sw455]  can support with as needed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b66w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §5 Technical Recovery concepts ,XP-3216,97694,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,sw455,sw455,02/Jul/20 17:37,31/Aug/20 15:39,22/Feb/21 13:26,19/Aug/20 07:29,,,3.1.1,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§5 Technical Recovery concepts* 

*§5.1 Storage and Backup*

*§5.1.1 Data restoration*

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx]

 ",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16761600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zz",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 17:37;sw455;[~yo218] - thought you'd be best to support this part of the DRP. When you start progress on this, if the content expected there is unclear, reach out to Serhii and/or myself and we will align on it. Thanks!","11/Aug/20 16:57;yo218;[https://teams.deutsche-boerse.de/sites/sp0232/_layouts/15/WopiFrame.aspx?sourcedoc=\{40E52AF3-D1A3-4C8A-AAE5-5FD58D5E7E4E}&file=ITDRP_XBID_v1.0.docx&action=default]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §4 Recovery Strategy,XP-3215,97693,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,sw455,sw455,02/Jul/20 17:34,31/Aug/20 15:39,22/Feb/21 13:26,20/Aug/20 12:10,,,3.1.1,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§4 Recovery Strategt*

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx]

 

 

Notes:
 * This section is the primary content of the document and will require full collab of the product team roles, dev/ops. The idea in our alignment meeting was to let development/functional specialist begin with the application design and how it should handle the disaster simulation, and call for support of operations when it gets to the operational procedures part of the recovery strategy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000xt8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §3 ICT Roles and Responsibilities ,XP-3214,97692,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lw641,sw455,sw455,02/Jul/20 17:30,08/Feb/21 11:00,22/Feb/21 13:26,08/Feb/21 11:00,,,,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§3 Roles & Responsibilities*

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx]

  

Notes:
 * [~lw641] - I thought this section would be appropriate for you to fill (with my support as needed) but Jakub mentioned that Pavel Popelka may have already done this? You may want to check with him",,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6048000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b660:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/20 10:15;lw641;To be completed after vacation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §2.5 ICT Outsourcing,XP-3213,97691,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lw641,sw455,sw455,02/Jul/20 17:25,09/Feb/21 15:36,22/Feb/21 13:26,09/Feb/21 15:36,,,,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§2.5 ICT Outsourcing* 

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx]

  

 

Notes:
 * For XBID, ACM/CR should have a well maintained list of 3rd party services dependancies on the product. We can review this together [~lw641] to see what is applicable to be mentioned in the DRP",,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1036800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b65s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/20 10:13;lw641;To be completed after vacation.","09/Feb/21 15:36;lw641;XBID Application has got multiple ICT outsourcings and they are [listed in detail here|https://bluebook.deutsche-boerse.de/sites/ps0080/_layouts/15/WopiFrame.aspx?sourcedoc=%7BC8FB907C-C799-4669-80DA-762389B4A56C%7D&file=Exhibit%2021%20-%20Subcontractors_v4.0.pdf&action=default&IsList=1&ListId=%7BB4CB2BE2-4529-4D70-951B-8FC9A9CE6110%7D&ListItemId=7478]. For the sake of keeping the DRT document OPS-oriented, I've only mentioned two major tools in there (AlarmTilt and OpsGenie).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §2.4 Structure Overview ,XP-3212,97690,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,sw455,sw455,02/Jul/20 17:19,31/Aug/20 15:39,22/Feb/21 13:26,14/Jul/20 09:26,,,3.1.0,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :
 *§2.4 Structure Overview*

 

https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19267200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b65k:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/20 12:54;sw455;(y)","14/Jul/20 12:55;zi174;I've added diagram pictures which describes the XBID Solution, I believe it's sufficient for this chapter",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ITDBR_XBID.doc: §2.2 Infrastructure,XP-3211,97689,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,sw455,sw455,02/Jul/20 17:18,31/Aug/20 15:39,22/Feb/21 13:26,18/Aug/20 10:23,,,3.1.1,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :
 * *§ 2.2 Infrastructure in scope*,
 * *§2.2.1 Necessary Infrastructure*
 * *§2.2.2: Necessary IT Resources* **",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16243200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:zyi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 17:23;sw455;[~yo218] - thought you'd be best to support this part of the DRP. When you start progress on this, if the content expected there is unclear, reach out to Serhii and/or myself and we will align on it. Thanks!","18/Aug/20 10:23;yo218;Those three parts are finished, waiting to be reviewed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"ITDBR_XBID.doc: §2 Scope, Pre-req's, Dependancies",XP-3210,97688,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lw641,sw455,sw455,02/Jul/20 17:15,08/Feb/21 10:57,22/Feb/21 13:26,08/Feb/21 10:57,,,,,,,,,,,,,,"Fill out sections of ITDRP_XBID_v1.0.docx :

*§2: Scope* through *§2.1: List of Applications*

(Section 2.2 through 2.3  have own subtask)

 

 [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Disaster%20Recovery%20Plan/Work/ITDRP_XBID_v1.0.docx] 

 

 

Notes:
 * See comments in document for who can support each area if additional info is needed

 * applicable legal entities management or CR team can support if needed
 * 2.3.2 - see ESO for guidance on this, it's not clear whether this will be linked to any other ITDRP's - but maybe it should be linked to Business Continuity Plans, Risk Assessments, etc.",,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6048000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3122,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b654:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/20 10:12;lw641;To be completed after vacation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upload Acer reports 2020 H1 to Sftp,XP-3209,97685,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,qo794,qo794,02/Jul/20 16:54,31/Aug/20 15:39,22/Feb/21 13:26,03/Jul/20 08:28,,,3.1.0,,,,,,,,,,,,,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3251,,,,,,,"02/Jul/20 17:00;qo794;ACER_2020_H1.zip;https://jira.deutsche-boerse.com/secure/attachment/85373/ACER_2020_H1.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b64g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 17:01;qo794;[~yo218] please upload the acer reports  [^ACER_2020_H1.zip] to the SFTP for customers (see TECHLOG-3102 for more details), thanks.","03/Jul/20 08:08;yo218;Uploaded files files to all 9 PXs:
{noformat}
[root@xbprodcbn1 ~]# for px in cropex epex gme hupx np omie opcom ote tge; do ls -la /opt/data01/xbid_${px}_prod/OUT/acer/; done
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 5 101022 101022     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 101012 101012     4096 Jul  3 08:08 .
drwxr-xr-x 6 101012 101012     4096 Jul  1  2019 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 6 101013 101013     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 6 101027 101027     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 101014 101014     4096 Jul  3 08:08 .
drwxr-xr-x 6 101014 101014     4096 Jul  1  2019 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 101015 101015     4096 Jul  3 08:08 .
drwxr-xr-x 6 101015 101015     4096 Jul  1  2019 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 6 101029 101029     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 6 101024 101024     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
total 11563
drwxr-xr-x 2 root   root       4096 Jul  3 08:08 .
drwxr-xr-x 6 101026 101026     4096 Jul  3 07:56 ..
-rw-r--r-- 1 root   root   11832274 Jul  3 08:08 ACER_2020_H1.zip
[root@xbprodcbn1 ~]#
 {noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ANALYZE - Find out what is the problem with upgrading postgres driver,XP-3206,97656,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,02/Jul/20 12:17,08/Dec/20 09:27,22/Feb/21 13:26,08/Dec/20 09:27,,,3.2.x,,,,,,,,,,,"When postgres driver is upgraded in xbid to version 42.2.10+. Some failover tests start to fail. It looks like that socket timeout is not taken into account. See XP-3203 for details.

[https://stackoverflow.com/questions/62694710/socket-timeout-not-working-when-uprading-to-postgres-jdbc-driver-42-2-10]

 

Hint: talk to [~uv683]
h2.  
h2.  Acceptance Criteria
 * analysis 
 * follow up ticket with fix plan 
 ** if nothing found - create regular /remind on slack to check for new major Postgre driver upgrade",,ek176,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3203,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20304000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0c1w3:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[PROD] P3P5-V1 - Lacking validation of the server certificate,XP-3205,97648,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,02/Jul/20 10:43,02/Nov/20 12:57,22/Feb/21 13:26,14/Oct/20 09:09,,,3.1.2,,ComTrader,,,,,PenetrationTest,Security,,,"Enable CN check on Prod. Release new CT with the following change:

 

Simply delete the following config line (default: check is enabled):
{noformat}
 { ""name"":""ctpSslCertCommonNameCheckDisable"", ""value"":""true"" }{noformat}",,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Merged,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b5wo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 11:20;ek176;After deployment to PROD, please update [https://vmt.deutsche-boerse.de/browse/PT-1517]","03/Jul/20 13:13;ei349;Please update: 

https://jira.deutsche-boerse.com/browse/SERVICE-3669",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix failing failover tests,XP-3203,97596,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,uv683,01/Jul/20 10:16,20/Aug/20 17:13,22/Feb/21 13:26,02/Jul/20 10:42,,,3.1.0,,,,,,,,,,,"After upgrading a lot of dependencies in xbid on 17.6. by commit be643f064bc5d77f5e35d68246ee82cc544b9491, nighly pipeline started to fail. Find out why and fix.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20304000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b5lc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Jul/20 09:27;uv683;First issue was with Spring Actuator. From version off Spring Boot 2.2+ {{HealthAggregator}}

is no longer used for aggreagating healt statutes. New interface {{StatusAggregator}}

is introduces instead. Since we were relying on custom {{ResourceHealthAggregator}} implementation, it was ignored by Spring Boot and its own internal implementation of {{StatusAggregator}} was used. I have created an adapter

{{HealthAggregatorStatusAggregatorAdapter}} which enables us to use our old implementation with new Spring Boot. Changed in resourcemanagement were needed as well.","02/Jul/20 10:30;uv683;Next issue was that failover scenario {{Scenario: Disconnect xbid-trading-1 from XBID_DB}} start failing on line 

{{Then within 60 seconds partial health check statuses db of xbid-trading-1 to be in state CONNECTING}}

I have discovered that java thread, resposible for checking DB status gets stuck on reading from database.

 
{code:java}
""pool-14-thread-1@12955"" prio=5 tid=0x45 nid=NA runnable""pool-14-thread-1@12955"" prio=5 tid=0x45 nid=NA runnable  java.lang.Thread.State: RUNNABLE   at java.net.SocketInputStream.socketRead0(SocketInputStream.java:-1)   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)   at java.net.SocketInputStream.read(SocketInputStream.java:171)   at java.net.SocketInputStream.read(SocketInputStream.java:141)   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465)   at sun.security.ssl.InputRecord.read(InputRecord.java:503)   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975)   - locked <0x3e55> (a java.lang.Object)   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933)   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105)   - locked <0x3e37> (a sun.security.ssl.AppInputStream)   at org.postgresql.core.VisibleBufferedInputStream.readMore(VisibleBufferedInputStream.java:161)   at org.postgresql.core.VisibleBufferedInputStream.ensureBytes(VisibleBufferedInputStream.java:128)   at org.postgresql.core.VisibleBufferedInputStream.ensureBytes(VisibleBufferedInputStream.java:113)   at org.postgresql.core.VisibleBufferedInputStream.read(VisibleBufferedInputStream.java:73)   at org.postgresql.core.PGStream.receiveChar(PGStream.java:370)   at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2043)   at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:312)   - locked <0x3e3a> (a org.postgresql.core.v3.QueryExecutorImpl)   at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448)   at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369)   at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:153)   at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:103)   at org.apache.tomcat.dbcp.dbcp2.PoolableConnection.validate(PoolableConnection.java:287)   at org.apache.tomcat.dbcp.dbcp2.PoolableConnectionFactory.validateConnection(PoolableConnectionFactory.java:630)   at org.apache.tomcat.dbcp.dbcp2.PoolableConnectionFactory.validateObject(PoolableConnectionFactory.java:648)   at org.apache.tomcat.dbcp.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:476)   at org.apache.tomcat.dbcp.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:353)   at org.apache.tomcat.dbcp.dbcp2.PoolingDataSource.getConnection(PoolingDataSource.java:134)   at org.apache.tomcat.dbcp.dbcp2.BasicDataSource.getConnection(BasicDataSource.java:753)   at com.deutscheboerse.energy.resourcemanagement.db.DbConnectionChecker.pingConnection(DbConnectionChecker.java:49)   at com.deutscheboerse.energy.resourcemanagement.db.DbConnectionChecker.lambda$new$0(DbConnectionChecker.java:28)   at com.deutscheboerse.energy.resourcemanagement.db.DbConnectionChecker$$Lambda$250.1931785101.run(Unknown Source:-1)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)   at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:-1)   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)   at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)   at java.lang.Thread.run(Thread.java:748) {code}
 

This should not happen because socket timeout on given datasource is 45s. Now it was stuck for ~30minutes. It was caused by upgrading postgres driver from 42.2.9 to 42.2.14. I have tried all the minor versions in between but they were all the same.

I have downgraded postgres driver version back to 42.2.9.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
role xbtomcat - configurable timezone ,XP-3199,97532,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,30/Jun/20 13:04,04/Aug/20 19:53,22/Feb/21 13:26,01/Jul/20 10:50,,,3.1.0,,,,,,,,,,,"xbtomcat role has hardcoded timezone CET, it is defined in var java_general_opts

but modules reportiong engine (role xbrep) and trading enquiry (role xbenq) should run in UTC -> it must be configurable, CET is a good default",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20476800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b57s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report tool fails on out of memory when downloading from elastic,XP-3197,97488,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eh941,eh941,29/Jun/20 13:45,31/Aug/20 15:38,22/Feb/21 13:26,29/Jun/20 16:43,,,3.1.0,,,,,,,,,,,"There are 8M+ records to be loaded to the memory. It crashes as following:

{noformat}
java.lang.OutOfMemoryError: Java heap space
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.JsonHelper.getLoglines(JsonHelper.java:46)
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.ElasticRestExtractor.getPagedLoglines(ElasticRestExtractor.java:105)
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.ElasticRestExtractor.extractLogLines(ElasticRestExtractor.java:88)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.ElasticFluxFactory$createFluxFromElastic$1.accept(ElasticFluxFactory.kt:15)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.ElasticFluxFactory$createFluxFromElastic$1.accept(ElasticFluxFactory.kt:9)
        at reactor.core.publisher.FluxCreate.subscribe(FluxCreate.java:94)
        at reactor.core.publisher.FluxWindow.subscribe(FluxWindow.java:90)
        at reactor.core.publisher.Flux.subscribe(Flux.java:7799)
        at reactor.core.publisher.ParallelSource.subscribe(ParallelSource.java:87)
        at reactor.core.publisher.ParallelRunOn.subscribe(ParallelRunOn.java:92)
        at reactor.core.publisher.ParallelFlatMap.subscribe(ParallelFlatMap.java:105)
        at reactor.core.publisher.ParallelMergeSequential.subscribe(ParallelMergeSequential.java:72)
        at reactor.core.publisher.FluxBuffer.subscribe(FluxBuffer.java:73)
        at reactor.core.publisher.Flux.subscribe(Flux.java:7799)
        at reactor.core.publisher.ParallelSource.subscribe(ParallelSource.java:87)
        at reactor.core.publisher.ParallelRunOn.subscribe(ParallelRunOn.java:92)
        at reactor.core.publisher.ParallelPeek.subscribe(ParallelPeek.java:89)
        at reactor.core.publisher.ParallelMergeSequential.subscribe(ParallelMergeSequential.java:72)
        at reactor.core.publisher.FluxFlatMap.subscribe(FluxFlatMap.java:97)
        at reactor.core.publisher.MonoCount.subscribe(MonoCount.java:39)
        at reactor.core.publisher.Mono.block(Mono.java:1493)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.rawrecord.RawRecordFacade.importFromElastic(RawRecordFacade.kt:112)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.rawrecord.RawRecordFacade.importRawOrderBookFromElastic(RawRecordFacade.kt:92)
        at com.deutscheboerse.energy.xbid.reporttool.performance.PerformanceKPIJobConfig$collectRawData$1.execute(PerformanceKPIJobConfig.kt:82)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)

{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20563200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b4y0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade RabbitMQ to 3.8.5 and inform Ops,XP-3195,97485,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,29/Jun/20 11:28,13/Aug/20 19:41,22/Feb/21 13:26,05/Aug/20 14:28,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Latest version of Rabbit{color}
h2. Current situation

we've prepared upgrade to RabbitMQ 3.8.*3* but there is already newer version. 
h2. Proposed solution

Upgrade to RabbitMQ 3.8.*5*, perform testing, analyze customer impact compare to current production and inform our Ops about this change so it can reach customer facing envs. 

 

Hints: 
 * docker update
 * ansible inventory update 
 * shakedown on SYT

h2. Acceptance Criteria
 * RabbitMQ upgraded to 3.8.5 
 * Impact analysis from the customer point of view. 
 * Informed BOs about this change 

 ",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17712000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b70n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,HOT Sprint 14 (S),HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/Jul/20 15:49;eg288;The rabbitmq 3.8.5 package is prepared for ansible deployment:
https://artifactory.dbgcloud.io/artifactory/energy-prod-local/rabbitmq/

It is NOT available for old perl deployment script which looks for rabbitmq packages here:
https://cmqaart.deutsche-boerse.de/artifactory/clip-dev-local/borg/rabbitmq/
but it should not be needed as we should use ansible only when XP-3352 is finished, ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
server xbcutscom1 is not accessible through ssh,XP-3191,97431,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,25/Jun/20 15:22,31/Aug/20 15:38,22/Feb/21 13:26,25/Jun/20 16:02,,,3.1.0,,,,,,,,,,,"I can't ssh to server xbcutscom1, but alerts are reporting only high number of zombie processes.

I can't even log in through vcenter remote console locally.

We need to schedule downtime for server restart and investigate the issue.

So far I have found only possible problem with 3rd party software/kernel module.
Possibly virus scanner.
",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGEXT-63,,,,,,,"25/Jun/20 15:21;hw120;Screenshot at 2020-06-25.png;https://jira.deutsche-boerse.com/secure/attachment/85164/Screenshot+at+2020-06-25.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20822400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b4m0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/20 16:02;hw120;Rebooted server from vmware vcenter console.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance Tool Update,XP-3190,97356,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tm431,tm431,24/Jun/20 14:50,20/Aug/20 17:12,22/Feb/21 13:26,15/Jul/20 12:20,,,3.1.0,,,,,,,,,,,We need to amend performance tool to be working with API changes for R3.1 There is new attribute added in OrdrExeRprt and in another message see XBID-4977,,tm431,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19180800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b3xj:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 13 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/20 12:20;tr866;As discussed on SU it's a fix of an internal tool, no need of test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) Send SLA reports automatically,XP-3188,97352,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tr866,uv683,tr866,24/Jun/20 12:20,04/Aug/20 19:53,22/Feb/21 13:26,26/Jun/20 18:04,,,3.1.0,,SLA Report Tool,,,,,TechOps,,,,"At the moment all three of our sla reports - namely Credit points, Boundary and Performance reports are generated every month but are left on the server to be picked up manually. Let's automate this task by e.g. sending these reports to email addresses in application properties. Let's discuss to which emails.

mail list: 
 - [~zi174]
 - [~ei349]
 - [~uv683]

steps needed
 * node name for identification, sender mail address, version of report tool 

AC: 

- mail with identification of node containing SLA reports sent to specified distribution list.",,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20736000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:z9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/20 18:04;tr866;Successfully tested on environment Syt1 with version Report Tool 2.40
When follwoing was added into application.property

{code}
send.sla.reports.by.mail.cron=0 * * * * ?

#keep blank if you do not want to receive SLA reports by email
mail.smtp.addresses=tomas.bendasek@deutsche-boerse.com
mail.smtp.timeout=300000
mail.from=DEV-report-tool@deutsche-boerse.com
mail.smtp.hosts=englobmail1,englobmail2
mail.smtp.ports=25,25
environment=Syt1
hostname=local
{code}

and *SEND_SLA_REPORTS* entry was deleted from the SLA1 database table generated_report, then a an email was received within a minute on the configured address from sender DEV-report-tool@deutsche-boerse.com with subject ""Syt1 SLA reports for 2020-05"" and body ""Generated on local by Report Tool version 2.40"" with the SLA reports in the attachment. 

Following record was saved in the report tool logfile:
{code}2020-06-26T16:03:00.058Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [retrieve-last-sent-month]
2020-06-26T16:03:00.061Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.r.LastGeneratedMonthTasklet - Last generated month for SEND_SLA_REPORTS is null
2020-06-26T16:03:00.064Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [retrieve-last-sent-month] executed in 6ms
2020-06-26T16:03:00.118Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [generate-attachments-and-send]
2020-06-26T16:03:00.122Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.m.MailReportsSender - Found attachment XBID Service Boundary Reporting May 2020.xlsx
2020-06-26T16:03:00.126Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.m.MailReportsSender - Found attachment XBID Performance and SM SLA Reporting May 2020.xlsx
2020-06-26T16:03:00.126Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.m.MailReportsSender - Found attachment XBID Credit Points Report May 2020.xlsx
2020-06-26T16:03:00.132Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.m.MailReportsSender - Sending reports for May 2020 to tomas.bendasek@deutsche-boerse.com
2020-06-26T16:03:00.357Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [generate-attachments-and-send] executed in 239ms
2020-06-26T16:03:00.414Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [mark-sla-reports-for-month-as-sent]
2020-06-26T16:03:00.417Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.r.MarkMonthAsGeneratedTasklet - SEND_SLA_REPORTS report generation finished, marking month 2020-05-01T00:00:00Z as done
2020-06-26T16:03:00.421Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [mark-sla-reports-for-month-as-sent] executed in 7ms
2020-06-26T16:03:00.425Z [h-jobs-thread-1][][] INFO  o.s.b.c.l.s.SimpleJobLauncher - Job: [FlowJob: [name=send-sla-reports]] completed with the following parameters: [{RUN_TIME=1593187380000}] and the following status: [COMPLETED] in 419ms{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clenaup of unused parts,XP-3187,97351,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,24/Jun/20 11:43,20/Aug/20 08:02,22/Feb/21 13:26,18/Aug/20 11:48,,,3.1.1,,,,,,,,,,,"1) inventory, remove obsolete entries for pmilogger monitoring under xb/xbid/\{{ env }}/pmilogger, the new xbpmi-logger role has monitoring vars defined in xb/xbid/xvbpmi-logger.yml",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bbbr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Jul/20 13:24;ei349;[~eg288]: can you please estimate this ticket?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) HP Fortify: Fix High Findings,XP-3184,97347,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,hj444,24/Jun/20 11:16,04/Aug/20 19:53,22/Feb/21 13:26,08/Jul/20 12:11,,,3.1.0,,,,,,,,,,,"[https://hpfortify.dwain.infra/ssc/html/ssc/version/10475/fix/null/?issueFilters=FOLDER_FOLDER:5b50bb77-071d-08ed-fdba-1213fa90ac5a&filterSet=dbd63fcc-432f-4066-8388-1b008de27dc1]

 

_Problem_: HP Fortify reports 0 Critical, 17 High, 0 Medium findings for XBID_DEVELOP (*AID292_XBID_MAIN*). 

 

 

_Task_: Fix/supress reported high findings (and critical/medium if any).

 

_AC_: 0 critical, 0 high and 0 medium findings in HP Fortify

 

Suggestion: Group by Category.

Check also with [~dm700] why are views so dynamic.",,dm700,ek176,hj444,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 10:30;ek176;20200702_fortify_xbid_develop.png;https://jira.deutsche-boerse.com/secure/attachment/85353/20200702_fortify_xbid_develop.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19785600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7q:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/20 11:30;ek176;Checked 2020-06-29: Suppressed False positives

No more coding work on this ticket is expected.

 

Please perform only a quick smoke test.","02/Jul/20 10:30;ek176;!20200702_fortify_xbid_develop.png!","08/Jul/20 12:11;tr866;Ticket closed as agreed, no suspicious behaviour was observed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) OWASP dep plugin not active in xbid/dev,XP-3183,97346,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,24/Jun/20 11:14,20/Aug/20 17:12,22/Feb/21 13:26,24/Jun/20 11:16,,,3.1.0,,,,,,,,,,,"The OWASP depdendency-maven plugin is not active in xbid/develop.

Needs to be in <build><plugins> part, not <pluginMangement>.

 TODO: 
 * Make sure the dependency check is done on PR
 * Fix relevant findings

AC 
- enrich pull request and nightly pipeline build for XBID repo with OWASP check. 
- green affected pipelines
 ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20995200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"(Split 1) Ansible - PMI Logger, Archiver and query deployment",XP-3182,97345,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,eg288,24/Jun/20 11:14,04/Aug/20 19:53,22/Feb/21 13:26,03/Jul/20 14:07,,,3.1.0,,,,,,,,,,,,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040006",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 14:07;eg288;implemented as roles xbpmi-logger, xbpmi-archiver and xbpmi-query for syt1 env",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Review Journal timeouts - PROD incident followup,XP-3178,97327,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,24/Jun/20 08:55,19/Nov/20 08:56,22/Feb/21 13:26,19/Nov/20 08:56,,,3.1.x,,,,,,,,,,,"We had an PROD incident on 22.6.2020, the XBID Core went down as it was unable to writer messages into journal. The reason was temporary network glitch (dead switch/unstable DC interconnection). 

h2. Could this have been prevented if we had longer timeouts?

Review:

* the lenght of the network outage
* timeouts on the Chronicle journal level (if any)
* glusterfs network timeouts



{quote}
Antoine Vigues:house_with_garden:  6:28 PM
Hi @here: Just got a call from Networks team. DBA had 2 issues today on the networks:
ADVA connection was unstable (interconnection between DCs)
A central switch in the DMZ died at 14:37
Networks thinks that our issue on XBID might be more related to issue Nr. 1 but the timing of issue Nr. 2 fits perfectly with our XBID incident.
{quote}

XBID Core log:

{code}
June 22nd 2020, 14:37:05.452
	Handling error on event 'com.deutscheboerse.energy.m7.core.in.RequestEvent@5a2d5fc2[error=<null>,input=Input:Message{receivedTime=1592829421071, rabbitReceivedTime=1592829421070, appId=NPSID, userId=NPADM002, applicationUserId=null, messageId=null, contentEncoding=null, contentType=x-m7/request; version=1, messageSource=TRADING_PMI, replyTo=amq.gen-UJJDjicJhDym-JbcT6m-1g, correlationId=[51, 100, 56, 53, 52, 102, 52, 100, 45, 98, 49, 97, 102, 45, 52, 48, 101, 97, 45, 57, 52, 51, 56, 45, 48, 53, 102, 50, 56, 52, 55, 54, 102, 53, 50, 56], classId=null, contentClassId=null, keyClassId=null},request=<null>]'
java.lang.AssertionError: java.io.IOException: Input/output error
	at net.openhft.chronicle.VanillaChronicle$VanillaAppenderImpl.finish(VanillaChronicle.java:642)
	at com.deutscheboerse.energy.m7.core.in.journal.AbstractChronicleQJournaler.doOnEvent(AbstractChronicleQJournaler.java:89)
	at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQJournaler.doOnEvent(ChronicleQJournaler.java:70)
	at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQJournaler.doOnEvent(ChronicleQJournaler.java:28)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Input/output error
	at java.nio.MappedByteBuffer.force0(Native Method)
	at java.nio.MappedByteBuffer.force(MappedByteBuffer.java:203)
	at net.openhft.lang.io.VanillaMappedBytes.force(VanillaMappedBytes.java:91)
	at net.openhft.chronicle.VanillaIndexCache.append(VanillaIndexCache.java:86)
	at net.openhft.chronicle.VanillaChronicle$VanillaAppenderImpl.finish(VanillaChronicle.java:627)
	... 9 common frames omitted
{code}

dmesg on core1:
{code}
[49763369.415255] nfs: server xbprodpdb1 not responding, still trying
[49766309.439740] nfs: server xbprodpdb1 OK
[49768077.288050] nfs: server xbprodpdb1 not responding, still trying
[49768146.078714] nfs: server xbprodpdb1 OK
{code} 

glusterfs log:
{code}
[root@xbprodpdb1 ~]# journalctl -u glusterd
-- Logs begin at Thu 2020-05-28 11:36:54 CEST, end at Mon 2020-06-22 14:55:07 CEST. --
May 28 11:37:04 xbprodpdb1 systemd[1]: Starting GlusterFS, a clustered file-system server...
May 28 11:37:04 xbprodpdb1 systemd[1]: Started GlusterFS, a clustered file-system server.
May 28 11:37:08 xbprodpdb1 rpc.statd[3858]: Version 1.3.0 starting
May 28 11:37:08 xbprodpdb1 sm-notify[3859]: Version 1.3.0 starting
May 28 11:37:08 xbprodpdb1 rpc.statd[3858]: Failed to create listener xprt (statd, 1, udp6)
May 28 11:37:08 xbprodpdb1 rpc.statd[3858]: Failed to create listener xprt (statd, 1, tcp6)
Jun 22 14:37:03 xbprodpdb1 nfs[3781]: [2020-06-22 12:37:03.859565] C [rpc-clnt-ping.c:166:rpc_clnt_ping_timer_expired] 0-journal_xbprodcor-client-2: server 10.139.95.189:49152 has not responded in the last 1 seconds, disconnecting.
Jun 22 14:37:03 xbprodpdb1 nfs[3781]: [2020-06-22 12:37:03.863424] C [rpc-clnt-ping.c:166:rpc_clnt_ping_timer_expired] 0-journal_xbprodcor-client-3: server 10.139.95.188:49152 has not responded in the last 1 seconds, disconnecting.
Jun 22 14:37:03 xbprodpdb1 nfs[3781]: [2020-06-22 12:37:03.863459] C [rpc-clnt-ping.c:166:rpc_clnt_ping_timer_expired] 0-journal_xbprodcor-client-1: server 10.139.95.190:49152 has not responded in the last 1 seconds, disconnecting.
{code}



",,ll664,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8208000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0l:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 22,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/20 08:57;ll664;Recovery times based on dmesg output:
{code:java}
[49763369.415255] nfs: server xbprodpdb1 not responding, still trying
[49766309.439740] nfs: server xbprodpdb1 OK
{code}
This is *49 minutes*, which is rather long, but I'm not very familiar with glusterfs architecture, so it might be ok if there is redudant path or something.
{code:java}
[49768077.288050] nfs: server xbprodpdb1 not responding, still trying
[49768146.078714] nfs: server xbprodpdb1 OK
{code}
This outage is 68 seconds, which seems more realistic.

On Chronicle Journal level, there are no timeouts per se. It's plain files from its perspective.

For the glusterfs, it would be good to know:

1. What was the actual outage duration? When did the gluster become unavailable and when was the connection restored?
2. What are the timeouts on the glusterfs? Could we have survived the network glitch if they were longer?
","29/Jun/20 09:00;ll664;Asked the questions in the linked syseng ticket. Flipping to waiting state.","19/Nov/20 08:55;ll664;RCA provided, see comments in SYSENG ticket. Long story short, it seems like we cannnot really do better here by tweaking glusterfs configuration/timeouts. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance apache_instance role to support XBID,XP-3174,97285,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eg288,eg288,23/Jun/20 10:25,31/Aug/20 15:39,22/Feb/21 13:26,31/Jul/20 10:52,,,3.1.0,,,,,,,,,,,"h2. Current situation

We cannot deploy Apaches at the moment
h2. Proposed solution 

TBD - [~eg288]
h2. Acceptance criteria 

TBD - [~eg288]",,eg288,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19180800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y05:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/Jul/20 18:42;yo218;prepared the role and deployed the first modules to syt1. It is still in branch xbid_apache. [~eg288] will take over",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
pmi user does not see java run time when ansible deploy,XP-3166,97149,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,22/Jun/20 09:20,31/Aug/20 15:39,22/Feb/21 13:26,22/Jun/20 17:54,,,3.1.0,,,,,,,,,,,"On machine xbintepmi1 user pmi does not see java run time when deploying using ansible. The start script fails with error:
{code:java}
/xbid/xbid-syt1-pmi1/runLoggerEnv.sh: line 4: java: command not found
{code}

The start script succeeds only when full path to java is specified. 

The pmi user can see java when I ssh to the machine. Also echo $PATH provides different results. When connected via ssh:
{code:java}
/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin:/home/pmi/.local/bin:/home/pmi/bin:/opt/java/default/bin:/home/pmi/.local/bin:/home/pmi/bin:/opt/java/default/bin
{code}

When via ansible:
{code:java}
/sbin:/bin:/usr/sbin:/usr/bin
{code}
",,eg288,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21168000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b300:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/20 10:20;yo218;The proper link to the java binary was missing in /bin/. Creating a link would have solved the issue, but I realized that still the old oracle java was installed. So I used the chance to install zulu on xbintepmi1+2 and xbinterep1+2.

Issue seems to be fixed now:
{noformat}
[yo218@enprodauto1 {master L | ?5} ~/git/energy.automation.os.install]$ ansible all --limit xb-xbid-inte-pmi1 -m shell -a ""java"" --become-user=pmi
 [WARNING]: While constructing a mapping from /usr/local/share/energy.automation.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict key (additional_params). Using last defined value only.xb-xbid-inte-pmi1 | FAILED | rc=1 >>
Usage: java [-options] class [args...]
           (to execute a class)
   or  java [-options] -jar jarfile [args...]
           (to execute a jar file)
where options include:
    -d32          use a 32-bit data model if available
    -d64          use a 64-bit data model if available
    -server       to select the ""server"" VM
                  The default VM is server,
                  because you are running on a server-class machine.
    -cp <class search path of directories and zip/jar files>
    -classpath <class search path of directories and zip/jar files>
                  A : separated list of directories, JAR archives,
                  and ZIP archives to search for class files.
    -D<name>=<value>
                  set a system property
    -verbose:[class|gc|jni]
                  enable verbose output
    -version      print product version and exit
    -version:<value>
                  Warning: this feature is deprecated and will be removed
                  in a future release.
                  require the specified version to run
    -showversion  print product version and continue
    -jre-restrict-search | -no-jre-restrict-search
                  Warning: this feature is deprecated and will be removed
                  in a future release.
                  include/exclude user private JREs in the version search
    -? -help      print this help message
    -X            print help on non-standard options
    -ea[:<packagename>...|:<classname>]
    -enableassertions[:<packagename>...|:<classname>]
                  enable assertions with specified granularity
    -da[:<packagename>...|:<classname>]
    -disableassertions[:<packagename>...|:<classname>]
                  disable assertions with specified granularity
    -esa | -enablesystemassertions
                  enable system assertions
    -dsa | -disablesystemassertions
                  disable system assertions
    -agentlib:<libname>[=<options>]
                  load native agent library <libname>, e.g. -agentlib:hprof
                  see also, -agentlib:jdwp=help and -agentlib:hprof=help
    -agentpath:<pathname>[=<options>]
                  load native agent library by full pathname
    -javaagent:<jarpath>[=<options>]
                  load Java programming language agent, see java.lang.instrument
    -splash:<imagepath>
                  show splash screen with specified image
See http://www.oracle.com/technetwork/java/javase/documentation/index.html for more details.non-zero return code {noformat}","22/Jun/20 14:04;ei349;Dear, [~eg288] please close if finished. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ISCP Requirment: Fill out PAM-SIEM Application Questionaire,XP-3162,97127,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,rl336,rl336,rl336,19/Jun/20 14:32,31/Aug/20 15:39,22/Feb/21 13:26,30/Jul/20 12:57,,,3.1.0,,,,,,,Identity&AccessManagement,ISCP,,,"Like discussed in the meeting from 17th of June, please fill out the Questionaire for XBID
 template and description are available on SharePoint:
h2. Please Use Template here:

[https://teams.deutsche-boerse.de/sites/sp0232/_layouts/15/WopiFrame.aspx?sourcedoc=\{2795AE25-0D1B-4425-AC3F-17669BFE9236}&file=XBID_PAM-SIEM-ApplicationQuestionnaire_1.3.xlsb.xlsx&action=default]

 

Due Date is 31.7.2020.",,ne232,rl336,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ESO-282,,,,,,,"17/Jul/20 11:10;iv732;PAM-SIEM-ApplicationQuestionnaire_1.0.xlsb_updated.xlsx;https://jira.deutsche-boerse.com/secure/attachment/85819/PAM-SIEM-ApplicationQuestionnaire_1.0.xlsb_updated.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16761600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1665,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b2v4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/20 12:11;zi174;Dear [~rl336],

please check the file [^PAM-SIEM-ApplicationQuestionnaire_1.2.xlsb.xlsx] and let us know if you need any additional clarification.

 

Jakub","22/Jul/20 22:44;rl336;Hi [~zi174], stupidly we have to fill out the component sheet for each XBID component,
second stupidly - corresponding to MEGA XBID has 14 components.

I have ad all Sheets for the 14 components with CID number and I have taken over the component Infos from XBID Core. 
it is uploaded to SharePoint:
https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F02%20General%20topics%2FSecurity%2FSIEM%5FPAM%20Onboarding%2FISCP%20Questionaire%202020%2FXBID&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7BB91642FD%2D7D32%2D4F21%2D8FBB%2DF503B3712788%7D

Please have a look again with the minimal effort as possible.
Why: from the beginning of next year MEGA will be replaced with a CMS based solution and SIEM / PAM onboarding for Energy is planned for 2021 / 2022. 
We can also have a call to fill out it together. 
- Regina - ","30/Jul/20 12:58;zi174;[~rl336],

we've updated and reviewed the questionnaire and from our point of view, the document is done. 

 

Please check and let us know if you need more info

Jakub

 ","12/Aug/20 09:57;rl336;it is fine, thanks. I will send it to ISCP Team",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Finalization of Rapid7 Onboarding,XP-3159,97106,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ei349,rl336,rl336,19/Jun/20 09:43,31/Aug/20 15:38,22/Feb/21 13:26,20/Jul/20 11:32,,,3.1.0,,,,,,,SecurityTools,SecurityTools&Processes,TechOps,,"see attached list, XBID Servers onboarded to Rapid7 with 'All credentials failed' (see column AO rapid7_auth_scan_status)
Please fix it asap. 

all shared Servers are in the list for M7T",,ei349,rl336,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ESO-280,,,,,,,"19/Jun/20 09:42;rl336;2020-05_Energy_XBID_Security_Tool_onboarding_report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/84990/2020-05_Energy_XBID_Security_Tool_onboarding_report.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19958400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b2qo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/20 10:20;rl336;In meantime it would be good if you/admins have checked the ssh pre-requisites described here:
https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20Tool%20onboarding%20process/Rapid7%20on-boarding%20process.docx?d=w73f999a63ed942bdba0919392ccc016c

please see also ESO-280","22/Jun/20 14:24;ei349;Dear [~rl336], 

 

all regarding rapid7 onboarding should be fine. Those values with ALL CREDENTIALS FAILED are not in the scope fro rapid7 onboarding. 

Check the column AJ - rapid7_in_scope. 

 

Jirka ","06/Jul/20 11:08;rl336;see: Onboarding list from June 2020, attached to ESO-280: you are right [~ei349] all credentials failed value is only valid for Servers they will not be onboarded: AJ = '0' , but two Servers are in the list M7AAMPRPRODAPP1, M7AAMPRPRODAPP2. 
Because these are M7A Servers - will clarify it with Michael Beckmann, Asset Manager.
This ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
History tables retention deletes too eagerly,XP-3156,97079,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,jy268,jy268,18/Jun/20 13:59,20/Aug/20 17:09,22/Feb/21 13:26,23/Jun/20 10:14,,,3.1.0,,,,,,,,,,,"Retention script deletes too many rows during one iteration. For example
{code}
DELETE FROM cx_211_contract_history WHERE last_update_time < ?;
{code}

can delete INSERT historical change but leave next UPDATE / DELETE. In this case history starts to be inconsistent.

Suggestion is to delete only DELETED entities, which will result in such a script
{code}
DELETE FROM cx_211_contract_history WHERE contract_id IN (SELECT contract_id FROM cx_211_contract_history WHERE last_update_time < ? AND revtype = 2);
{code}",,jy268,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21081600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b2ko:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Jun/20 11:13;jy268;[~qo794] please review https://github.deutsche-boerse.de/dev/xbid/pull/733","22/Jun/20 16:09;qo794;the new version of the script: https://github.deutsche-boerse.de/dev/xbid/blob/develop/src/main/db/history-cleanup/cor.sql","22/Jun/20 16:15;jy268;[~yo218], could you please use the script from here https://github.deutsche-boerse.de/dev/xbid/blob/develop/src/main/db/history-cleanup/cor.sql and merge it to COR section of jenkins houskeeping job?","23/Jun/20 10:14;yo218;Updated the job XBID-Cleanup-DBs-Select. Currently used shell script:
{noformat}
 #!/bin/bash
DAYS=""40""
if [[ $config == *""prod""* ]]
then
   DAYS=""40""
fi;OLDDATE=""$(date ""+%Y-%m-%d 23:00:00.000000"" -d ""$DAYS days ago"")""
echo ""Deleting history data older than $DAYS days in ${config}""### CMI
rm -f /tmp/tmp.cmi.sql
cat << EOF > /tmp/tmp.cmi.sql
BEGIN;
DELETE FROM tbxi700_file_header_history WHERE create_time < '$OLDDATE';
DELETE FROM tbxi701_acknowledgement_header_history WHERE create_time < '$OLDDATE';
COMMIT;
VACUUM tbxi700_file_header_history;
VACUUM tbxi701_acknowledgement_header_history;
EOF### SPM
rm -f /tmp/tmp.spm.sql
cat << EOF > /tmp/tmp.spm.sql
BEGIN;
DELETE FROM acknowledgement_history WHERE created_date < '$OLDDATE';
DELETE FROM file_header_history WHERE last_modified_date < '$OLDDATE';
COMMIT;
VACUUM acknowledgement_history;
VACUUM file_header_history;
EOF### COR
rm -f /tmp/tmp.cor.sql
cat << EOF > /tmp/tmp.cor.sql
BEGIN;
DELETE FROM cmm_101_allocation_history WHERE id IN (SELECT id FROM cmm_101_allocation_history WHERE allocated_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_106_allocation_metadata_history WHERE id IN (SELECT id FROM cmm_106_allocation_metadata_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_121_capacity_history WHERE id IN (SELECT id FROM cmm_121_capacity_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_131_contract_history WHERE contract_id IN (SELECT contract_id FROM cmm_131_contract_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_233_inter_connector_status_history WHERE last_update_time < '$OLDDATE'; --this one does not include subselect as rows are never deleted.
DELETE FROM cx_002_market_state_history WHERE last_update_time < '$OLDDATE'; --this one does not include subselect as rows are never deleted.
DELETE FROM cx_101_order_history WHERE order_id IN (SELECT order_id FROM cx_101_order_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_111_trade_history WHERE trade_id IN (SELECT trade_id FROM cx_111_trade_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_117_trade_allocation_history WHERE allocationid in (SELECT allocationid FROM cx_117_trade_allocation_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_151_messages_history WHERE message_id IN (SELECT message_id FROM cx_151_messages_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_211_contract_history WHERE contract_id IN (SELECT contract_id FROM cx_211_contract_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_296_session_history WHERE session_id IN (SELECT session_id FROM cx_296_session_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_441_contract_delivery_area_state_history WHERE id IN (SELECT id FROM cx_441_contract_delivery_area_state_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_673_trade_flow_history WHERE trade_flow_id IN (SELECT trade_flow_id FROM cx_673_trade_flow_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);COMMIT;
VACUUM cmm_101_allocation_history;
VACUUM cmm_106_allocation_metadata_history;
VACUUM cmm_121_capacity_history;
VACUUM cmm_131_contract_history;
VACUUM cmm_233_inter_connector_status_history;
VACUUM cx_002_market_state_history;
VACUUM cx_101_order_history;
VACUUM cx_111_trade_history;
VACUUM cx_117_trade_allocation_history;
VACUUM cx_151_messages_history;
VACUUM cx_211_contract_history;
VACUUM cx_296_session_history;
VACUUM cx_441_contract_delivery_area_state_history;
VACUUM cx_451_holidays_history;
VACUUM cx_673_trade_flow_history;
EOF{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DB cleanup for SLA tool,XP-3153,97042,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,18/Jun/20 07:21,13/Aug/20 19:41,22/Feb/21 13:26,07/Jul/20 12:41,,,3.1.0,,,,,,,,,,,"The database for the reporting tool on xbprodsla1 is growing, currently it has more than 40GB:
{noformat}
[root@xbprodsla1 ~]# df -h | grep pgsql
/dev/mapper/rootvg-lv_postgres_data    59G   41G   16G  72% /var/lib/pgsql {noformat}
Please evaluate the possibility of cleaning up old data. 

BTW: There are no backups taken for this DB. Is this intentional or a mistake?",,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3197,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|000y0t:s00000020i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3153,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Jun/20 08:34;qo794;h2. Analysis
* there is already a housekeeping job for cleaning up old data running daily: {{com.deutscheboerse.energy.xbid.reporttool.database.DbDataHousekeeper}}
* it removes old data from the following tables
** raw_sender
** raw_orderbook
** public_orderbook
** heart_beat
** computed_percentile
** computed_total
* the housekeeping job is a part of the Performance KPI collector job
* the job has not run on *xbprodsla1* since 28.5.2020
{code:sql}
select * from db_clean_stats order by executed desc limit 10;
{code}
||id||deleted_to||deleted_table||rows_deleted||executed||
|7598|2020-03-28|computed_total|207727|2020-05-28 00:41:02|
|7597|2020-03-28|computed_percentile|150|2020-05-28 00:41:01|
|7596|2020-05-25|heart_beat|17280|2020-05-28 00:41:01|
|7595|2020-05-25|public_orderbook|5321010|2020-05-28 00:41:01|
|7594|2020-05-25|raw_orderbook|948922|2020-05-28 00:40:51|
|7593|2020-05-25|raw_sender|875828|2020-05-28 00:40:48|
|7592|2020-03-27|computed_total|207472|2020-05-27 00:41:04|
|7591|2020-03-27|computed_percentile|150|2020-05-27 00:41:04|
|7590|2020-05-24|heart_beat|17280|2020-05-27 00:41:04|
|7589|2020-05-24|public_orderbook|6156926|2020-05-27 00:41:04|
* db tables sizes
||table_name||pg_relation_size \[in bytes\]||
|raw_orderbook|8068636672|
|raw_sender|7517126656|
|public_orderbook|3241648128|
|computed_total|1653317632|
|acer_intraday_trade_volume|125386752|
|acer_trade_volume_hour_to_delivery|80191488|
|acer_weighted_average_price|44138496|
|batch_step_execution_context|36167680|
|batch_step_execution|27033600|
|acer_weighted_average_price_last_trading_hour|25247744|
|batch_job_execution_context|5513216|
|heart_beat|3350528|
|computed_percentile|1392640|
|batch_job_execution|647168|
|batch_job_instance|589824|
|db_clean_stats|573440|
|batch_job_execution_params|450560|
|flyway_schema_history|8192|
|generated_report|8192|
|acer_product|8192|
|v_sender_order_entry|0|
|sender_real_waits_times_orders|0|
|am_trades_evolution|0|
|am_net_position|0|
|am_volume_per_border|0|
|sender_real_times|0|
|sender_real_times_all|0|
|sender_real_process_times_orders|0|
|sender_real_times_all_raw_sender|0|
|sender_real_times_raw_sender|0|
|v_sender_order|0|

Logs on *xbprodsla1* are full of errors, mainly ""java.io.IOException: Too many open files"". SERVICE-6620 created to restart it.
","26/Jun/20 09:15;qo794;{quote}
BTW: There are no backups taken for this DB. Is this intentional or a mistake?
{quote}
[~yo218] could you please take care of this (or delegate it) and setup the backup for sla tool databases on both nodes? thanks.","29/Jun/20 13:43;qo794;Restarting of the application did not help, failing on OutOfMemoryError
{code}
2020-06-27T00:47:13.434Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-raw-data-from-elastic-and-parse in job collect-performance-kpi-data
java.lang.OutOfMemoryError: Java heap space
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.JsonHelper.getLoglines(JsonHelper.java:46)
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.ElasticRestExtractor.getPagedLoglines(ElasticRestExtractor.java:105)
        at com.deutscheboerse.energy.xbid.reporttool.extractor.elastic.ElasticRestExtractor.extractLogLines(ElasticRestExtractor.java:88)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.ElasticFluxFactory$createFluxFromElastic$1.accept(ElasticFluxFactory.kt:15)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.ElasticFluxFactory$createFluxFromElastic$1.accept(ElasticFluxFactory.kt:9)
        at reactor.core.publisher.FluxCreate.subscribe(FluxCreate.java:94)
        at reactor.core.publisher.FluxWindow.subscribe(FluxWindow.java:90)
        at reactor.core.publisher.Flux.subscribe(Flux.java:7799)
        at reactor.core.publisher.ParallelSource.subscribe(ParallelSource.java:87)
        at reactor.core.publisher.ParallelRunOn.subscribe(ParallelRunOn.java:92)
        at reactor.core.publisher.ParallelFlatMap.subscribe(ParallelFlatMap.java:105)
        at reactor.core.publisher.ParallelMergeSequential.subscribe(ParallelMergeSequential.java:72)
        at reactor.core.publisher.FluxBuffer.subscribe(FluxBuffer.java:73)
        at reactor.core.publisher.Flux.subscribe(Flux.java:7799)
        at reactor.core.publisher.ParallelSource.subscribe(ParallelSource.java:87)
        at reactor.core.publisher.ParallelRunOn.subscribe(ParallelRunOn.java:92)
        at reactor.core.publisher.ParallelPeek.subscribe(ParallelPeek.java:89)
        at reactor.core.publisher.ParallelMergeSequential.subscribe(ParallelMergeSequential.java:72)
        at reactor.core.publisher.FluxFlatMap.subscribe(FluxFlatMap.java:97)
        at reactor.core.publisher.MonoCount.subscribe(MonoCount.java:39)
        at reactor.core.publisher.Mono.block(Mono.java:1493)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.rawrecord.RawRecordFacade.importFromElastic(RawRecordFacade.kt:112)
        at com.deutscheboerse.energy.xbid.reporttool.rawdata.rawrecord.RawRecordFacade.importRawOrderBookFromElastic(RawRecordFacade.kt:92)
        at com.deutscheboerse.energy.xbid.reporttool.performance.PerformanceKPIJobConfig$collectRawData$1.execute(PerformanceKPIJobConfig.kt:82)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:145)
{code}
Improvement implemented within XP-3197, redeploying SERVICE-6633","30/Jun/20 13:51;qo794;Inconsistent flyway scripts in xbprodsla1 database - SERVICE-6638","02/Jul/20 08:26;qo794;The DB housekeeping job finally executed:
{code}
2020-07-01T17:09:50.518Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [collect-raw-data-from-elastic-and-parse] executed in 16h29m50s403ms
2020-07-01T17:09:50.637Z [h-jobs-thread-1][][] INFO  o.s.b.c.j.SimpleStepHandler - Executing step: [collect-database]
2020-07-01T17:09:50.666Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - lastCleanedDay = 2020-05-25
2020-07-01T17:09:50.666Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - Cleaning database with parameters: cleanRawDataUntil='2020-06-29', cleanSummaryDataUntil='2020-05-02'
2020-07-01T17:09:50.666Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - Cleaning generic DB tables
2020-07-01T17:11:04.560Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 31434136 rows has been deleted from raw_sender
2020-07-01T17:12:22.649Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 33968963 rows has been deleted from raw_orderbook
2020-07-01T17:16:35.452Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 169597710 rows has been deleted from public_orderbook
2020-07-01T17:16:35.958Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 551821 rows has been deleted from heart_beat
2020-07-01T17:16:35.959Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - Cleaning sumary DB tables
2020-07-01T17:16:35.995Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 5250 rows has been deleted from computed_percentile
2020-07-01T17:16:46.035Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.d.DbDataHousekeeper - 7345601 rows has been deleted from computed_total
2020-07-01T17:16:46.049Z [h-jobs-thread-1][][] INFO  o.s.b.c.s.AbstractStep - Step: [collect-database] executed in 6m55s411ms
{code}
Table sizes:
||table_name||pg_relation_size||rows||
|public_orderbook|28112650240|12457804|
|raw_orderbook|10823753728|2227758|
|raw_sender|10079830016|2082692|
|computed_total|1802551296|12721479|
Housekeeping history:
||id||deleted_to||deleted_table||rows_deleted||executed||
|7610|2020-05-03|computed_total|201407|2020-07-02 05:50:39|
|7609|2020-05-03|computed_percentile|150|2020-07-02 05:50:38|
|7608|2020-06-30|heart_beat|17280|2020-07-02 05:50:38|
|7607|2020-06-30|public_orderbook|5303340|2020-07-02 05:50:38|
|7606|2020-06-30|raw_orderbook|967135|2020-07-02 05:50:01|
|7605|2020-06-30|raw_sender|894398|2020-07-02 05:49:48|
|7604|2020-05-02|computed_total|7345601|2020-07-01 17:16:46|
|7603|2020-05-02|computed_percentile|5250|2020-07-01 17:16:35|
|7602|2020-06-29|heart_beat|551821|2020-07-01 17:16:35|
|7601|2020-06-29|public_orderbook|169597710|2020-07-01 17:16:35|
|7600|2020-06-29|raw_orderbook|33968963|2020-07-01 17:12:22|
|7599|2020-06-29|raw_sender|31434136|2020-07-01 17:11:04|
|7598|2020-03-28|computed_total|207727|2020-05-28 00:41:02|
|7597|2020-03-28|computed_percentile|150|2020-05-28 00:41:01|
|7596|2020-05-25|heart_beat|17280|2020-05-28 00:41:01|
|7595|2020-05-25|public_orderbook|5321010|2020-05-28 00:41:01|
|7594|2020-05-25|raw_orderbook|948922|2020-05-28 00:40:51|
|7593|2020-05-25|raw_sender|875828|2020-05-28 00:40:48|
","02/Jul/20 09:48;yo218;The database is growing even faster now:
{noformat}
/dev/mapper/rootvg-lv_postgres_data    94G   75G   16G  83% /var/lib/pgsql {noformat}
Here is the overview about the tables and their sizes:
{noformat}
    table_schema    |                  table_name                   | row_estimate |   total    |   index    |   toast    |   table
--------------------+-----------------------------------------------+--------------+------------+------------+------------+------------
 public             | public_orderbook                              |  1.53647e+08 | 45 GB      | 18 GB      | 8192 bytes | 26 GB
 public             | raw_orderbook                                 |  3.07809e+06 | 11 GB      | 796 MB     | 3792 kB    | 10 GB
 public             | raw_sender                                    |  2.87078e+06 | 10 GB      | 737 MB     | 3808 kB    | 9615 MB
 public             | computed_total                                |  1.16511e+07 | 5501 MB    | 3781 MB    |            | 1720 MB
 {noformat}","02/Jul/20 09:59;yo218;list of table size for xbprodsla2:
{noformat}
    table_schema    |                  table_name                   | row_estimate |   total    |   index    |   toast    |   table
--------------------+-----------------------------------------------+--------------+------------+------------+------------+------------
 public             | public_orderbook                              |  1.62892e+07 | 9551 MB    | 6348 MB    | 8192 bytes | 3203 MB
 public             | computed_total                                |   1.1401e+07 | 2394 MB    | 1048 MB    |            | 1346 MB
 public             | raw_orderbook                                 |  2.73911e+06 | 1405 MB    | 345 MB     | 360 kB     | 1060 MB
 public             | raw_sender                                    |  2.46346e+06 | 1263 MB    | 292 MB     | 368 kB     | 971 MB
 {noformat}
 ","02/Jul/20 10:12;qo794;Agreed with Nikals to execute full vacuum that should clean up the database, a lot of rows were deleted yesterday after the heavy load - see my comment above, and now databases on both nodes have more or less the same amount of records in tables, so their sizes should be also similar.","07/Jul/20 12:37;yo218;After VACUUM FULL the db size went down to 8 GB:
{noformat}
/dev/mapper/rootvg-lv_postgres_data    94G  7.7G   82G   9% /var/lib/pgsql {noformat}","07/Jul/20 12:41;yo218;Created XP-3239 for the creation of backups, closing this one",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - db archiver,XP-3152,97039,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eg288,eg288,17/Jun/20 17:19,01/Sep/20 12:18,22/Feb/21 13:26,27/Aug/20 10:49,,,3.1.1,,,,,,,,,,,"Create ansible role for  db archiver tool. The db archiver is shell script only. 

Search for xbid-syt1-db-archiver1 in energy-mkt-shared repo how it is done in old way.",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21513600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bd26:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),Alpha Sprint 16,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shutdown host xbcutsrep1 to increase RAM,XP-3151,97037,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,iv732,iv732,iv732,17/Jun/20 16:28,31/Aug/20 15:38,22/Feb/21 13:26,18/Jun/20 11:19,,,3.1.0,,,,,,,,,,,"We need to increase RAM for the host xbcutsrep1, because the server has only 150 MB free and is swapping heavily . It doesn't have ""Memory Hot Plug"" option enabled, so we need to shutdown the server to proceed. It can take up to 15 minutes

When can we do that?",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21513600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b2bc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/20 11:19;iv732;Done.

tomcat@xbcutsrep1:[/shrd]$ free -h
 total used free shared buff/cache available
Mem: 31G 8.6G 20G 20M 1.8G 22G
Swap: 2.0G 0B 2.0G",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add CPU resources to xbprodweb[1-6] and xbprodssl[1-6],XP-3150,97027,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,iv732,hw120,hw120,17/Jun/20 11:33,31/Aug/20 15:39,22/Feb/21 13:26,24/Jun/20 11:06,,,3.1.0,,,,,,,,,,,"I noticed alerts for xbid prod, apache and ssl servers cpu and load.

I checked history data in grafana and we should add second cpu to xb prod web and ssl servers to prevent possible future issues.
They have only 1 vCPU, we should increase it to 2.

Please increase vCPU count to 2 on the following VMs(they have hotplug enabled):
xbprodweb[1-6]
xbprodssl[1-6]

See CPU and LOAD panels
https://grafana.energy.svc.dbgcloud.io/d/uvfJv-Siz/system?orgId=4&from=now-90d&to=now&var-host=xbprodweb1%20-%20apache%20-%20xbid_prod&var-host=xbprodweb2%20-%20apache%20-%20xbid_prod&var-host=xbprodweb3%20-%20apache%20-%20xbid_prod&var-host=xbprodweb4%20-%20apache%20-%20xbid_prod&var-host=xbprodweb5%20-%20apache%20-%20xbid_prod&var-host=xbprodweb6%20-%20apache%20-%20xbid_prod&var-client_env=prod&var-group=apache&var-interval=$__auto_interval_interval

https://grafana.energy.svc.dbgcloud.io/d/uvfJv-Siz/system?orgId=4&from=now-90d&to=now&var-host=xbprodssl1%20-%20haproxy%20-%20xbid_prod&var-host=xbprodssl2%20-%20haproxy%20-%20xbid_prod&var-host=xbprodssl3%20-%20haproxy%20-%20xbid_prod&var-host=xbprodssl4%20-%20haproxy%20-%20xbid_prod&var-host=xbprodssl5%20-%20haproxy%20-%20xbid_prod&var-host=xbprodssl6%20-%20haproxy%20-%20xbid_prod&var-client_env=prod&var-group=haproxy&var-interval=$__auto_interval_interval


",,hw120,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20995200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b294:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/20 12:31;iv732;Opened a ticket by Syseng:  https://jira.deutsche-boerse.com/browse/SYSENG-76","24/Jun/20 11:06;iv732;Lambert added that resource",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Restart XBID CUTE Proftpd to apply new log rotate settings,XP-3148,96983,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,iv732,iv732,16/Jun/20 17:55,31/Aug/20 15:38,22/Feb/21 13:26,24/Jun/20 09:05,,,3.1.0,,,,,,,,,,,"Together with Peter, we have found out that proftpd process keeps holding data used by already deleted logs. 

On xbcutscbn1, the real used space for log is: 
 [root@xbcutscbn1 ~]# du -sh /var/log/* |grep G
 7.6G /var/log/proftpd
 4.3G /var/log/wtmp
 But it is reported as:
 [root@xbcutscbn1 ~]# df -h |grep /var/log

/dev/mapper/rootvg-lv_varlog 60G 49G 8.2G 86% /var/log

Checked with lsof:

[root@xbcutscbn1 ~]#lsof /var/log |grep deleted

proftpd 57219 100108 13w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 57219 100108 18w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 57223 100019 13w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 57223 100019 18w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 57224 100111 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 57224 100111 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 57225 100049 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 57225 100049 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 57227 100017 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 57227 100017 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 57387 100111 13w REG 253,2 11289026088 1024003 /var/log/proftpd/sftp.log-20200517 (deleted)
 proftpd 57387 100111 17w REG 253,2 8543477376 237 /var/log/wtmp-20200601 (deleted)
 proftpd 57387 100111 18w REG 253,2 413096598 87 /var/log/xferlog-20200517 (deleted)
 proftpd 58814 100105 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 58814 100105 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 58817 100105 13w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 58817 100105 18w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 58821 100059 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 58821 100059 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 58823 100059 12w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)
 proftpd 58823 100059 17w REG 253,2 105901528 163 /var/log/xferlog-20200607 (deleted)
 proftpd 58824 100000 13w REG 253,2 7307688647 1024009 /var/log/proftpd/sftp.log-20200607 (deleted)

 ## Changed the logrotate config for proftpd 
 /var/log/proftpd/*.log /var/log/xferlog \{ compress missingok notifempty copytruncate }

 

## We need to restart proftpd process to apply the change

 

 ",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21427200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b1zs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jun/20 11:02;iv732;Reboot done.

Will check the result",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - unify mail configuration,XP-3147,96965,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,16/Jun/20 14:48,04/Aug/20 19:53,22/Feb/21 13:26,18/Jun/20 11:36,,,3.1.0,,,,,,,,,,,"Currently we have keys {{mail_cluster}} for some roles and {{mail_smtp_hosts}} for others. Unify it.

All mail related properties should have {{mail_}} prefix",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21600000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b1vs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve logging for PersistenceContext,XP-3146,96958,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,16/Jun/20 13:39,04/Aug/20 19:53,22/Feb/21 13:26,18/Jun/20 14:15,,,3.1.0,,,,,,,,,,,"Right now the PersistenceContext is logging without database task.

It's up to the discussion but it would be handy to have there:
* database tasks - toString() implementation needed - no more lambdas
* how many rows were affected by the query (shouldn't be a problem because the {{javax.persistence.Query#executeUpdate}} returns the number of entities updated or deleted",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21513600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b1ug:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Jun/20 15:18;eh941;Added extra logging that works even for lambdas which can't have {{toString}} override.

The logline looks like following:

{noformat}
2020-06-17 10:20:55.869 [main] INFO  - c.d.e.m.c.p.DatabaseTaskExecutor:17 - Database task com.deutscheboerse.energy.m7.core.out.executor.BatchPersistenceExecutorIntegrationTest$$Lambda$390/221046595@198f7c5f execution took 13 ms and affected 1 rows
{noformat}

I updated {{toString}} methods where it was possible. E.g. 

{noformat}
2020-06-17 15:16:47.059 [Persister] INFO  - c.d.e.m.c.p.DatabaseTaskExecutor:17 - Database task ContractDatabaseHousekeepingTask{deletedContracts=of size 150, updatedByUserId='7777777777777777SYSTEM', executionTime=2018-08-12T10:00:04.073+02:00} execution took 30 ms and affected 150 row(s)
2020-06-17 15:16:47.073 [Persister] INFO  - c.d.e.m.c.p.DatabaseTaskExecutor:17 - Database task MessagesDatabaseHousekeepingTask{deleteMessagesUntil=2018-08-05T10:00:04.073+02:00} execution took 14 ms and affected 0 row(s)
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dump history tables from production dump to report-tool test,XP-3138,96888,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,15/Jun/20 10:31,04/Aug/20 19:53,22/Feb/21 13:26,23/Jun/20 11:00,,,3.1.0,,SLA Report Tool,,,,,,,,,"Report-tool uses production data parsed via custom tool.

Replace parsed data with real data from production:
- find fitting dump (must contain WHOLE month and a few days before and after)
- dump required tables (see {{report-tool/src/test/resources/am/coredb/data}} folder in report-tool) and all that might become useful for tests
- fix all tests (expected output)",,lt112,,,,,,,,,,,,,,,,,,,,XP-3141,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21772800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azyn:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,XP-3011-fix,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
WAITING - Ansible - remove duplicate var definitions when ansible is upgraded to 2.7,XP-3136,96856,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eg288,eg288,12/Jun/20 09:00,31/Aug/20 15:37,22/Feb/21 13:26,20/Aug/20 12:18,,,3.1.1,,,,,,,,,,,"Some vars are duplicated in xbid inventory due to ansible bug prior version 2.7, vars from an imported role are not exposed at the playbook to other roles. For details see [https://github.com/ansible/ansible/issues/37466].

When ansible is upgraded to version 2.7 seerch for TODO XP-3136 and remove duplicate definitions.

 

Hint: search for TODO ",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16070400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xtu:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/Jul/20 13:36;ei349;waiting on Ansible 2.7 upgrade done currently by [~cv179]","20/Aug/20 12:17;eg288;The definition of all ports for apache and tomcat instances is now done by convention. As a consequence TODO XP-3136 was removed as the variable is no longer needed -> closing this ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible improvement - rename var instance_oldname to instance_id,XP-3135,96848,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,11/Jun/20 15:53,31/Aug/20 15:37,22/Feb/21 13:26,26/Jun/20 16:33,,,3.1.0,,,,,,,,,,,"role xbtomcat defines var instance_oldname, rename the var to instance_id",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22032000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b16o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible improvement - use amqp port global vars in all xbid roles,XP-3134,96847,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eg288,eg288,11/Jun/20 15:45,31/Aug/20 15:38,22/Feb/21 13:26,18/Jun/20 09:48,,,3.1.0,,,,,,,,,,,"Use amqp port global vars instead of local vars. The global vars are defined in inventroy inventory/xb/vars.yml 

{code}
...
# AMQP ports
amqp_ext_port: ""51{{ PORT_ENV_DIGIT }}00""
amqp_ext_port_admin: ""52{{ PORT_ENV_DIGIT }}00""
amqp_int_port: ""51{{ PORT_ENV_DIGIT }}01""
amqp_int_port_admin: ""52{{ PORT_ENV_DIGIT }}01""
...
{code}",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22032000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b16g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - move/create common tomcat's task for war and dataset file downloading,XP-3131,96837,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,eh941,eh941,11/Jun/20 13:21,18/Nov/20 09:46,22/Feb/21 13:26,18/Nov/20 09:46,,,3.1.x,,,,,,,,,,,"Every xbid application needs to download a war file from the artifactory and copy it into webapps. Some of the apps need to download the dataset.
Create tasks for it in common tomcat role",,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8812800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btja:8",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Nov/20 16:44;eg288;review done - approved",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA Report tool - template modification,XP-3130,96833,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,zi174,zi174,11/Jun/20 12:33,20/Aug/20 17:07,22/Feb/21 13:26,14/Jul/20 15:11,,,3.1.0,,,,,,,,,,,"Please use the newest templates for generation of reports (in attachment). The templates are modified according to the agreement with the customer and they reflect an actual scenario. It is necessary:
 * import the templates to the Report Tool
 * modify mapping in the Report Tool - the excels have been changed (columns have been removed) ",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/20 09:46;zi174;credit-points-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/85592/credit-points-report.xlsx","11/Jun/20 12:44;zi174;kpi-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/84775/kpi-report.xlsx","10/Jul/20 10:42;zi174;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/85529/sla-report.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22118400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b3xj:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,Alpha Sprint 13 (S),,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3279-am-snake-case,XP-3306,XP-3324-am-mira-test,XP-3291,XP-3281,XP-3130,XP-3285-am-atc-utilization,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Wrap ansible flyway role with xbid flyway role,XP-3129,96830,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,lt112,lt112,11/Jun/20 11:56,31/Aug/20 15:38,22/Feb/21 13:26,13/Aug/20 13:23,,,3.1.1,,,,,,,,,,,"- create simplified xbid flyway role that calls energy flyway role
- describe properly using {{README.md}} file",,eh941,ek176,lt112,,,,,,,,,,,,,,,,,,,,,,,,XP-3368,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b12w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/20 13:22;eh941;Duplicate, already done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cleanup old Docker images from Artifactory (30 days),XP-3128,96829,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,11/Jun/20 11:52,20/Aug/20 08:02,22/Feb/21 13:26,19/Aug/20 09:29,,,3.1.1,,,,,,,,,,,"*Clean after 30 days*

We have old docker images in artifactory which might be not needed anymore. 
 Agree on the policies and prepare the cleanup script.

View on artifactory
 * [https://artifactory.dbgcloud.io/artifactory/webapp/#/artifacts/browse/tree/Properties/xbid-docker-dev-local/xbid/xbid-core/2.0.40-SNAPSHOT-6dc216e23b55a2437a6477cbc80f291a79e93a94]

Artifactory cleanup job 
 * [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/Artifactory%20Cleanup%20XBID]

Docker Registry Cleanup
 * [https://englobjci1.deutsche-boerse.de/job/Energy/job/XBID] -

 ",,dm700,ei349,ek176,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,16156800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bbbr:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Aug/20 14:56;jy268;Expected execution
{code}
./clean_artifactory.py -p xbid -d 30 -o xbid-docker-dev-local -a '' -r 2
{code}
if testing, please run as:
{code}
./clean_artifactory.py -p xbid -d 30 -o xbid-docker-dev-local -a '' -r 2 --dry-run
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - dataset version and name configurable in jenkins dev deployment job,XP-3127,96816,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,10/Jun/20 18:12,03/Nov/20 15:21,22/Feb/21 13:26,02/Nov/20 12:06,,,3.1.x,,,,,,,,,,,"ansible deployment jenkins jobs used by devel;opers:
https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-dev-ansible-deploy/

the pipeline file must be updated and also all existing ansible roles using a dataset",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9676800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btja:7",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Nov/20 12:05;eg288;The dataset selection/deployment is implemented in xbid deployment full pipeline which is sufficient.

Adding dataset selection into the xbid deployment dev pipeline has no value as this pipeline is for playbook development & testing before a changes are merged into master branch. At this stage the dataset  selection is not needed.

Closing as not implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make HP Fortify numbers stable,XP-3125,96785,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ei349,ei349,10/Jun/20 13:54,20/Aug/20 17:06,22/Feb/21 13:26,16/Jun/20 16:06,,,3.1.0,,,,,,,,,,,"Discuss with [~dm700] why are numbers in https://hpfortify.dwain.infra/ssc/html/ssc/version/10475/overview/null/?issueFilters=FOLDER_FOLDER:5b50bb77-071d-08ed-fdba-1213fa90ac5a&filterSet=a243b195-0a59-3f8b-1403-d55b7a7d78e6 so dynamic. 

When finished we can proceed with XP-3092. 

AC: 
- we have understanding where does numbers come from
- numbers have stable values spread",,ei349,ek176,,,,,,,,,,,,,,,,,,,XP-3092,,,,,,,,,,,,,,,,,,,,,,"10/Jun/20 14:05;ek176;fortify_warnings.png;https://jira.deutsche-boerse.com/secure/attachment/84677/fortify_warnings.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21600000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/20 14:24;ek176;Consider also the number of warnings. The 3.000 number was for the successfully finished pipeline. The lower one (might) be for failed ones.
||Day||Warnings||Pipeline state||
|05-06|193|Aborted|
|06-06|193|Aborted|
|07-06|193|Aborted|
|08-06|---|Failed|
|09-06|3000|OK|
|10-06|3000|OK|

So it seems that the '3000' warnings correlate to successfully finished pipeline. 

!fortify_warnings.png!","16/Jun/20 16:06;ek176;Since the 2020-06-09 the no of warnings seems to be stable: 3.000 And the number of findings found also.

Closing the ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split)REP - remove distinct from TC540,XP-3124,96771,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eg288,uv683,10/Jun/20 12:51,11/Sep/20 14:13,22/Feb/21 13:26,15/Jun/20 10:51,,,3.1.0,,Reporting Engine,,,,,,,,,"To generate a report the reporting engine loads all needed data from database into memory. Then all the data are transformed itno JAXB objects and only then written as one chunk into a XML file. It is very demanding on memory, especially for ADMIN member, where the resulting XML report TC540 can have around 70MB .

The production instance runs with 8 GB of memory and it fails with OutOfMemory on busy days.

Optimize the report generation to decrease memory consuption.

Info:
 * fails during night, day ok
 * 25 minutes -> 18min data load
 * query returns 1_800k of lines
 * (/) one option is add memory +4 GB - Ask Niklas -> memory added, the application uses 12GB, it works for now
 * another is change query run by hour than day
 * analyse

SQL query for report TC540 reads table cx_101_order_history. The query selects data according to colums last_update_time. There is an index in place. See XP-2882 for further details.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22118400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aw27:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 09:30;uv683;I have removed distinct from TC540 query in reporting engine by adding a condition {{contractHistory.revtype=0}} which should make join with order history much smaller. This condition picks only insertion into contract history and is not interested in any subsequent updates.

Moreover I have also added an index 
{code:java}
CREATE INDEX CONCURRENTLY idx_last_upd_time_bal_group ON cx_101_order_history (last_update_time, balancing_group_eic) {code}
into xbid core DB. I have tested all the combinations of columns that appear in {{WHERE}} statement and found out that this two columns are sufficient and query is not make faster by adding any more columns to the index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upload Agile Pilot release to ESCROW,XP-3121,96767,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,10/Jun/20 12:20,16/Jun/20 16:11,22/Feb/21 13:26,16/Jun/20 16:11,,,Agile Pilot,,,,,,,,,,,,,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21600000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azyn:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/20 13:47;ei349;franta created some nice tool but it needs some manual tweaking still. 
for more info ask [~jy268], [~eh941]","16/Jun/20 16:11;jy268;Sources were successfully deployed to deposix servers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
REP - batch process reports by hours,XP-3114,96740,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,eg288,uv683,10/Jun/20 10:10,02/Nov/20 12:57,22/Feb/21 13:26,13/Oct/20 17:25,,,3.1.2,,Reporting Engine,,,,,,,,,"To generate a report the reporting engine loads all needed data from database into memory. Then all the data are transformed itno JAXB objects and only then written as one chunk into a XML file. It is very demanding on memory, especially for ADMIN member, where the resulting XML report TC540 can have around 70MB .

The production instance runs with 8 GB of memory and it fails with OutOfMemory on busy days.

Optimize the report generation to decrease memory consuption.

Info:
 * fails during night, day ok
 * 25 minutes -> 18min data load
 * query returns 1_800k of lines
 * (/) one option is add memory +4 GB - Ask Niklas -> memory added, the application uses 12GB, it works for now
 * another is change query run by hour than day
 * analyse",,jy268,od044,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/20 15:35;od044;xbperfcor-20201008.dump;https://jira.deutsche-boerse.com/secure/attachment/88491/xbperfcor-20201008.dump",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11318400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c0e",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 18 (S),HOT Sprint 19,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,XP-3114,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Oct/20 15:43;jy268;Please test if TC540 test generates the same content as in previous version (for example one which is currently on production)","13/Oct/20 17:25;od044;Test passed on Reporting engine v 5.1.0
- verified on SYT2 with Xbid 3.1.5
- compare report from reporting-engine v 5.0.54 (actual on PROD) and 5.1.0 (with fix) - report are identical (/)

StR
1. Deploy Reporting engine v 5.0.54
2. Generate/enter orders and match trades, tested against appox. 4,7k orders nad 2,7k trades 
3. Generate reports TC540 as ADMIN subscriber 
4. Deploy Reporting engine v 5.1.0 with the fix 
6. Generate reports TC540 as ADMIN subscriber 
7. Compare those reports ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide README to shared ansible role xbtomcat,XP-3113,96728,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,lt112,lt112,09/Jun/20 19:48,04/Aug/20 19:53,22/Feb/21 13:26,12/Jun/20 14:40,,,3.1.0,,,,,,,,,,,"Shared role {{xbtomcat}} is missing {{README.md}} file. As it is supposed to be imported by other roles, it should describe usage and prerequisites.

e.g.:
The following is expected inside the {{xbtomcat}} role 
{code}
app_endpoint_health: ""http://localhost:{{ tomcat_port_http }}/<app>/health""
app_config_files:  
  - source: context.xml.j2
    target: ""{{ tomcat_directory }}/conf/context.xml""
  - source: server.xml.j2
    target: ""{{ tomcat_directory }}/conf/server.xml""
  - source: <app>.logback.xml.j2
    target: ""{{ tomcat_directory }}/lib/<app>.logback.xml""
  - source: <app>_env.properties.j2
    target: ""{{ tomcat_directory }}/lib/<app>_env.properties""
    mode: ""0640""
{code}",,ek176,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22204800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azyk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Send SLA reports automatically,XP-3112,96727,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tr866,uv683,uv683,09/Jun/20 17:22,04/Aug/20 19:53,22/Feb/21 13:26,24/Jun/20 12:21,,,3.1.0,,SLA Report Tool,,,,,TechOps,,,,"At the moment all three of our sla reports - namely Credit points, Boundary and Performance reports are generated every month but are left on the server to be picked up manually. Let's automate this task by e.g. sending these reports to email addresses in application properties. Let's discuss to which emails.

mail list: 
 - [~zi174]
 - [~ei349]
 - [~uv683]

steps needed
 * node name for identification, sender mail address, version of report tool 

AC: 

- mail with identification of node containing SLA reports sent to specified distribution list.",,tr866,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3188,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20995200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,XP-3011-fix,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Jun/20 15:01;uv683;There is a new cron property that is setting a time at which all SLA reports found in system are collected and send to desired addresses. This property is
{code:java}
 send.sla.reports.by.mail.cron{code}
Moreover there are some more new properties that will have to changes with deployment to environemnts, currently these are set with some defaults in application.properties
{code:java}
#keep blank if you do not want to receive SLA reports by email
mail.smtp.addresses=jakub.musil@deutsche-boerse.com,jiri.vlasimsky@deutsche-boerse.com,jakub.hesoun.ext@deutsche-boerse.com
mail.smtp.timeout=300000
mail.from=DEV-report-tool@deutsche-boerse.com
mail.smtp.hosts=localhost
mail.smtp.ports=1025
environment=DEV
hostname=local {code}
You can test that this is working by running a report tool localy along with hogmail docker image, which is listening for smtp messages on 1025. Just start it like this 
{code:java}
docker run -d -p 1025:1025 -p 8025:8025 mailhog/mailhog {code}
 ","24/Jun/20 12:20;tr866;Issue split into:
|XP-3188|(Split 1) Send SLA reports automatically|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace Consul server cert on Prod ,XP-3111,96698,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,yo218,yo218,09/Jun/20 09:48,13/Aug/20 19:40,22/Feb/21 13:26,16/Jun/20 13:12,,,3.1.0,,,,,,,,,,,"The server certificates are about to expire on 19th on June. The database servers would not be able to communicate with consul anymore in order to check the master status. The whole application would immediately stop working. The certificates can probably be replaced one by one without any downtime, but this should be verified in Simu once again. 

 
|CN|Expiration|Updated|
|server.xb-xbid-prod.consul|2020-06-19 00:00:00|2020-06-09 05:28:08|

 ",,hw120,iv732,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21686400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,09/Jun/20 09:48,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 12:10;hw120;{code:bash}
1.) Clone repository
git clone git@github.deutsche-boerse.de:dev/energy.automation.deployments.git
cd energy.automation.deployments/

2.) go to vault where certs are located /secret/global/consul/xb-xbid-prod
and backup the secrets for example on enprodauto1:
    ca_cert
    ca_key
    client_cert
    client_key
    server_cert
    server_key

3.) Generate new ca and certs
export CONSUL_DC=xb-xbid-prod && \
export CONSUL_BINARY=/usr/local/bin/consul && \
./roles/consul_instance/create-consul-cluster.sh

4.) ""pause"" patroni cluster to activate maintenance mode, that failover is deactivated
[root@xbprodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done
[root@xbprodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause;done
[root@xbprodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done

5.) Stop consul services
ansible all -m shell -a ""systemctl status consul""  -b --limit 'xb*-prod*:&consul' --ask-sudo-pass

6.) Copy server.cert and server.key to the consul servers and clients:
ansible all -m copy -a 'src=consul-agent-ca.pem dest=/etc/consul/ssl/ca.crt owner=consul group=bin mode=0644 backup=yes' -b --limit 'xb*-prod*:&consul' --ask-sudo-pass
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0.pem dest=/etc/consul/ssl/server.crt owner=consul group=bin mode=0644 backup=yes' -b --limit 'xb*-prod*:&consul' --ask-sudo-pass
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0-key.pem dest=/etc/consul/ssl/server.key owner=consul group=bin mode=0600 backup=yes' -b --limit 'xb*-prod*:&consul' --ask-sudo-pass
# specific case is our xbid prod dbr sync instances 
ansible all -m copy -a 'src=consul-agent-ca.pem dest=/etc/patroni_xbprodsync/ca_cert.pem owner=postgres group=postgres mode=0644 backup=yes' -b --limit 'xb*-prod-*dbr-sync*:&postgres' --ask-sudo-pass
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0.pem dest=/etc/patroni_xbprodsync/consul_crt.pem owner=postgres group=postgres mode=0644 backup=yes' -b --limit 'xb*-prod-*dbr-sync*:&postgres' --ask-sudo-pass  
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0-key.pem dest=/etc/patroni_xbprodsync/consul_key.pem owner=postgres group=postgres mode=0600 backup=yes' -b --limit 'xb*-prod-*dbr-sync*:&postgres' --ask-sudo-pass
# specific case is our xbid prod dbr async instances 
ansible all -m copy -a 'src=consul-agent-ca.pem dest=/etc/patroni_xbprodasync/ca_cert.pem owner=postgres group=postgres mode=0644 backup=yes' -b --limit 'xb*-prod-*dbr-async*:&postgres' --ask-sudo-pass  
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0.pem dest=/etc/patroni_xbprodasync/consul_crt.pem owner=postgres group=postgres mode=0644 backup=yes' -b --limit 'xb*-prod-*dbr-async*:&postgres' --ask-sudo-pass 
ansible all -m copy -a 'src=xb-xbid-prod-server-consul-0-key.pem dest=/etc/patroni_xbprodasync/consul_key.pem owner=postgres group=postgres mode=0600 backup=yes' -b --limit 'xb*-prod-*dbr-async*:&postgres' --ask-sudo-pass

7.) Start consul cluster and check if it is complete and healthy
ansible all -m shell -a ""systemctl start consul""  -b --limit 'xb*-prod-cons*:&consul:!*-consul-*' --ask-sudo-pass
ansible all -m shell -a ""systemctl status consul""  -b --limit 'xb*-prod-cons*:&consul:!*-consul-*' --ask-sudo-pass
ansible all -m shell -a ""export CONSUL_HTTP_TOKEN=ac17e28e-dba4-5e2e-bca6-f0b4d1fa4db0 && /usr/local/bin/consul members"" -b --limit 'xb*-prod-cons*:&consul:!*-consul-*' --ask-sudo-pass
ansible all -m shell -a ""tail -n 30 /var/log/consul/consul.log""  -b --limit 'xb*-prod-cons*:&consul:!*-consul-*' --ask-sudo-pass

8.) Start consul clients and check if it is complete and healthy
ansible all -m shell -a ""systemctl start consul""  -b --limit 'xb*-prod-consul-*:&consul' --ask-sudo-pass
ansible all -m shell -a ""systemctl status consul""  -b --limit 'xb*-prod-consul-*:&consul' --ask-sudo-pass
ansible all -m shell -a ""export CONSUL_HTTP_TOKEN=ac17e28e-dba4-5e2e-bca6-f0b4d1fa4db0 && /usr/local/bin/consul members"" -b --limit 'xb*-prod-consul-pdb*:&consul' --ask-sudo-pass
ansible all -m shell -a ""tail -n 30 /var/log/consul/consul.log""  -b --limit 'xb*-prod-consul-*:&consul' --ask-sudo-pass

9.) Check consul logs on server and client nodes if all is running fine
journalctl -u consul

10.) deactivate the maintenance mode again
[root@xbprodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume;done
[root@xbprodpdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list;done

11.) Check patroni logs for any consul related problems, example
journalctl -u patroni_xbprodasync.service
journalctl -u patroni_xbprodsync.service
{code}","16/Jun/20 13:12;hw120;All done.

I have encountered a few problems. xbproddbrX instances have patroni connected directly to one consul server node and also consul ssl certs are in /etc/patroni_XXX/ directory.

There is a problem with old patroni systemctl service file, if you restart patroni service, it will kill postgres instance.

As recommended by Cybertec support, I modified

/usr/lib/systemd/system/patroni_xbprodsync.service
/usr/lib/systemd/system/patroni_xbprodasync.service

on all xb prod patroni instances and changed
{quote}KillMode=control-group
{quote}
to
{quote}KillSignal=SIGINT
KillMode=process
{quote}
and run this to apply the change
{quote}systemctl daemon-reload
{quote}
I also tested it that now restart of patroni service will not kill postgres instance.

We might consider modifying also simu and test xb patroni clusters.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some unclear error in SOB ,XP-3110,96675,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,od044,od044,08/Jun/20 15:34,04/Aug/20 19:53,22/Feb/21 13:26,12/Jun/20 09:44,,,3.1.0,,,,,,,,,,,"Found error below in SOB log. 
{code}
2020-06-08T13:08:08.771Z [0.0-8009-exec-9][SADMIN02][] ERROR o.a.m.t.i.u.Deprecation - The attribute 'margin' of 'UIGridLayout' is deprecated. Please refer the documentation for further information.
{code}

Find a proper undeprecated atrtibute substition for UIGridLayout.margin so this error dissapears from log. 

",,eh941,od044,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 14:59;eh941;original.png;https://jira.deutsche-boerse.com/secure/attachment/84793/original.png","11/Jun/20 15:00;eh941;without-margin.png;https://jira.deutsche-boerse.com/secure/attachment/84794/without-margin.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22032000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,08/Jun/20 15:34,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,XP-2484,XP-3110-deprecated-log,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Jun/20 15:06;eh941;After some research I found out following conclusions:
* The {{margin}} attribute *really does something*. On the following screenshot you can see the page layout when it's enabled:
 !original.png! 
And there without {{margin=""5""}}:
 !without-margin.png! 

As you can see the margin is gone.

* Even though it's marked as {{deprecated}} there is no suggested substitute for that. There is just a a message {quote}Please use single attributes from {
Margin between container component and the children.{quote}. I wasn't able to figure out what is meant by this.
* In the newest tobago 2.x which is currently  2.4.1 (we're using 2.0.9) the attribute is still there with the very same deprecated comment
* On Tobago homepage they use the attribute in the demo:
{code}
    <f:facet name=""layout"">
      <tc:gridLayout rows=""fixed;*"" margin=""10""/>
    </f:facet>
{code}

Having those information *I decided just to hide the error message*. It's quite clear the attribute is there for a reason and it's kept there even though it's marked as deprecated for years now. It might be marked as deprecated by a mistake. Who knows.","11/Jun/20 15:13;eh941;How to test it - redeploy trading inquiry to whatever environment. The only change was done in deployment configuration therefore it doesn't matter which XBID version will be used. Verify the error is no longer in the logs. The error used to show even on homepage when logged in as SADMIN01.","11/Jun/20 16:54;tr866;Reproduced on Syt3 with version XB R2.0.40-e63ee9db80fa99ff4d76ace8c9d1244ee7d1d4bb
 Since Admin's login to WebGUI many errors appear in the trading inquiry log file like
{noformat}
2020-06-11T14:29:17.031Z [nio-8009-exec-4][SADMIN02][] ERROR o.a.m.t.i.u.Deprecation - The attribute 'margin' of 'UIGridLayout' is deprecated. Please refer the documentation for further information.{noformat}
After redeplyoment of Trading Inquiry with same version XB R2.0.40-e63ee9db80fa99ff4d76ace8c9d1244ee7d1d4bb
 no such error appears in the log file anymore.(/)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) OWASP dep plugin not active in xbid/dev,XP-3107,96631,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,05/Jun/20 13:10,20/Aug/20 17:06,22/Feb/21 13:26,07/Jul/20 14:17,,,3.1.0,,,,,,,,,,,"The OWASP depdendency-maven plugin is not active in xbid/develop.

Needs to be in <build><plugins> part, not <pluginMangement>.

 TODO: 
 * Make sure the dependency check is done on PR
 * Fix relevant findings

AC 
- enrich pull request and nightly pipeline build for XBID repo with OWASP check. 
- green affected pipelines
 ",,ek176,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3183,,,,,,,XP-2855,,,,,,,"24/Jun/20 10:03;tr866;CMM-Capacity-Management-Upload-screenshot-localhost_24082-2020.06.24-09_58_15.jpg;https://jira.deutsche-boerse.com/secure/attachment/85110/CMM-Capacity-Management-Upload-screenshot-localhost_24082-2020.06.24-09_58_15.jpg","24/Jun/20 10:03;tr866;CMM-Capacity-Overview-H2H-localhost_24082-2020.06.24-09_54_49.jpg;https://jira.deutsche-boerse.com/secure/attachment/85111/CMM-Capacity-Overview-H2H-localhost_24082-2020.06.24-09_54_49.jpg","17/Jun/20 14:58;ek176;owasp_test_fail_pass.png;https://jira.deutsche-boerse.com/secure/attachment/84927/owasp_test_fail_pass.png","17/Jun/20 14:58;ek176;owasp_test_fail_plugin_only.png;https://jira.deutsche-boerse.com/secure/attachment/84928/owasp_test_fail_plugin_only.png",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19872000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7n:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Jun/20 14:57;ek176;Make sure that the checks do not clash with Sonar (as OWAS was copied from):
||Test branch||xbid-pulls-sonar||xbid-pulls-owasp||PR Checks||
|XP-3107-test-fail
 (Removed owasp-suppressions.xml)|{color:#00875a}OK #1516{color}|{color:#00875a}FAIL (expected) #8{color}|{color:#00875a}FAIL (expected){color}|
|XP-3107-test-pass|{color:#00875a}OK #1517{color}|{color:#00875a}OK #9{color}|{color:#00875a}OK{color}|
|XP-3107-owasp-plugin-fix-rabbit-231|{color:#00875a}OK #1519{color}|{color:#00875a}OK #11{color}|{color:#00875a}OK{color}|
 ","17/Jun/20 14:59;ek176;(Was not able to add to previous comment)

 

Pass/Fail test on PR:

!owasp_test_fail_pass.png!

 

(Deliberately) failed OWASP dependency check:

!owasp_test_fail_plugin_only.png!","17/Jun/20 15:04;ek176;Please retest issues from: XP-2542","24/Jun/20 10:07;tr866;Tested on Docker with version XB R2.0.43-SNAPSHOT (Build 4f4a4516f1bcae38ce673cdd33e2eaf58816c561)
As mentionned above I had a look on issues in the linked ticket and both issues are appearing again and should be fixed.
Capacity Management>Capacity Overview>H2H Matrix (H2H Configuration: H2H View: By Area(for all contracts; From Area: 50HzT)
[!CMM-Capacity-Overview-H2H-localhost_24082-2020.06.24-09_54_49.jpg|thumbnail , width=50%,height=50%!|^CMM-Capacity-Management-Upload-screenshot-localhost_24082-2020.06.24-09_58_15.jpg]

Capacity Management>Capacity Overview>Upload
When file is uploaded following error is shown:
[!CMM-Capacity-Management-Upload-screenshot-localhost_24082-2020.06.24-09_58_15.jpg|thumbnail , width=50%,height=50%!|^CMM-Capacity-Management-Upload-screenshot-localhost_24082-2020.06.24-09_58_15.jpg]","24/Jun/20 11:10;tr866;Otherwise when doing smoketest throught CMM, CMI, SOB no other issues were observed.","24/Jun/20 11:14;ek176;Issue split into:
|XP-3183|(Split 2) OWASP dep plugin not active in xbid/dev|
","30/Jun/20 13:21;ek176;Upgrade Tobago to 2.0.10 broke also NTC upload. Reverted to 2.0.9","07/Jul/20 08:20;ek176;Also reverted in trading: Tobago 2.0.9","07/Jul/20 14:17;ek176;Tobago upgrade stalled at 2.0.9.
Even 2.0.10 breaks file upload",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Onboard missing certificates from other team's monitoring,XP-3106,96628,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,ei349,ei349,05/Jun/20 12:45,13/Aug/20 19:41,22/Feb/21 13:26,18/Jun/20 15:50,,,3.1.0,,,,,,,TechOps,,,,"h1. {color:#00875a}Better Certificates Monitoring{color}
h2. Current Situation 

There are notifications coming in our M7-SI mailbox and are managed by our BOs. Some of those certificates are not onboarded in our section monitoring tools. 
h2. Proposed Solution 

Gather information about monitored certificates from monitoring triggering M7-SI mailbox emails. Handover to TOs and onboard them to our monitorin tool so we can prevent expiration problems in the future. 
h2. Acceptance Criteria
 * list of certificates from other team's monitoring tool
 * missing certificates onboarded in our energy monitoring tool. ",,ei349,ub113,yn731,yo218,,,,,,,";11/Jun/20 16:52;yn731;7200",,,0,7200,,,0,7200,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 16:49;yn731;image-2020-06-11-16-49-09-082.png;https://jira.deutsche-boerse.com/secure/attachment/84797/image-2020-06-11-16-49-09-082.png","11/Jun/20 16:50;yn731;image-2020-06-11-16-50-43-837.png;https://jira.deutsche-boerse.com/secure/attachment/84799/image-2020-06-11-16-50-43-837.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21427200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azyn:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 16:51;yn731;+Monitoring emails to M7-SI Inbox:+

1) From: PKI monitoring <[secops_pki@vmnoddi.cedelgroup.com|mailto:secops_pki@vmnoddi.cedelgroup.com]>

The majority of Jira certificates are reported here. But it also includes other types. The search criteria are shown below:
 * M7 certificates: XX certificates with ""ou=m7"" in the DN and expiring in the next 28 days (not relevant for us)

or
 * XBID certificates: XX certificates with ""*ou=xbid*"" in the DN and expiring in the next 28 days

The example below was Tagged as ""Test"" in its subject. These need to be clarified with the sender.

!image-2020-06-11-16-50-43-837.png|width=867,height=215!

 

2) From: [certificate@enprodauto1.deutsche-boerse.de|mailto:certificate@enprodauto1.deutsche-boerse.de] - Client Certificate Expiration Report

The whole process is described in the email message (Quoted below).
{quote}This is an automated email to inform you about certificate activity. Please initiate proper activity.

 Energy Client certificates

==========================

 This repository can be found here:

[https://github.deutsche-boerse.de/dev/energy.cert-tools]

 Documentation can be found here:

[https://confluence.energy.svc.dbgcloud.io/display/ET/Client+Certificates]

 To remove this alarm, generate new certificates if needed and revoke affected certificates within Vault.

 The respective cron-job can be found on enprodauto1:/etc/cron.d/certmgr
{quote}
 

 ","16/Jun/20 17:14;yo218;Moved all CuTes mail certificates to Vault (only the public part):
{noformat}
Success! Data written to: secret/xb/xbid/ctpa/cert/xbctpa-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpa/cert/xbctpa-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpa/cert/xbctpa-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpb/cert/xbctpb-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpb/cert/xbctpb-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpb/cert/xbctpb-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpc/cert/xbctpc-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpc/cert/xbctpc-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpc/cert/xbctpc-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpd/cert/xbctpd-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpd/cert/xbctpd-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpd/cert/xbctpd-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpe/cert/xbctpe-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpe/cert/xbctpe-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpe/cert/xbctpe-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpf/cert/xbctpf-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpf/cert/xbctpf-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpf/cert/xbctpf-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpg/cert/xbctpg-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpg/cert/xbctpg-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpg/cert/xbctpg-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctph/cert/xbctph-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctph/cert/xbctph-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctph/cert/xbctph-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpi/cert/xbctpi-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpi/cert/xbctpi-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpi/cert/xbctpi-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpj/cert/xbctpj-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpj/cert/xbctpj-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctpj/cert/xbctpj-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctso/cert/xbctso-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctso/cert/xbctso-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/ctso/cert/xbctso-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/cute/cert/xbcute-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/cute/cert/xbcute-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/cute/cert/xbcute-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipa/cert/xblipa-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipa/cert/xblipa-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipa/cert/xblipa-spm@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipb/cert/xblipb-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipb/cert/xblipb-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/lipb/cert/xblipb-spm@xbid-test.deutsche-boerse.com {noformat}","16/Jun/20 17:22;yo218;same for Simu:
{noformat}
Success! Data written to: secret/xb/xbid/simu/cert/xbsimu-cmi@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/simu/cert/xbsimu-cor@xbid-test.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/simu/cert/xbsimu-spm@xbid-test.deutsche-boerse.com {noformat}","16/Jun/20 17:28;yo218;[~iv732] stated that the monitoring will include the files as they are within the already monitored file structure. The only outstanding poin is Prod. I couldn|t find the latest Prod certs, they must have been created end of last year. At least the ones I could found expired in December 19. Can you please provide the certificates [~ub113]or [~yn731]?","17/Jun/20 10:56;yn731;Hello [~yo218]

Are you talking about SMIME certs?","17/Jun/20 11:15;yo218;yes","17/Jun/20 11:33;yn731;AFAIK BizOps does not generate/store them. I can only see these ones: S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\SI\Connectivity Prod\Mail ","18/Jun/20 15:29;yo218;yes, I found them as well. And those expired end of last year. You must have provided them to the customer in November or December","18/Jun/20 15:30;yo218;aha, or maybe not. They seem to be valid for three years, so actually they will just expire this year in December. So I will add them now","18/Jun/20 15:34;yn731;Indeed","18/Jun/20 15:50;yo218;{noformat}
Success! Data written to: secret/xb/xbid/prod/cert/xbprod-cmi@xbid.deutsche-boerse.com
Success! Data written to: secret/xb/xbid/prod/cert/xbprod-spm@xbid.deutsche-boerse.com {noformat}
Prod is also monitored now. That should be all",,,,,,,,,,,,,,,,,,,,,,,,,,,
Change regular tables to history tables in report-tool,XP-3100,96605,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,lt112,lt112,04/Jun/20 15:23,31/Aug/20 15:38,22/Feb/21 13:26,04/Jun/20 15:47,,,3.1.0,,SLA Report Tool,,,,,,,,,"Currently regular tables (delivery areas, market areas) are used and joined to history tables (order history, trade history, ...) when generating reports in report tool.

Possible issue in case of MA/DA deletion (low chance of happening and easy fix in case it happens)

h2. Effort
- introduce new test data (history tables)
- rewrite SQL scripts",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22636800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,04/Jun/20 15:23,,,,,,,,,,,,,,,,,,,,,,,"1|y0azsg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/20 15:47;lt112;no longer valid",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HP Fortify - setup alerts if we don't meet the criteria,XP-3095,96523,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,dm700,ll664,ll664,03/Jun/20 09:58,14/Dec/20 10:44,22/Feb/21 13:26,14/Dec/20 10:44,,,3.1.x,,,,,,,Tech-Debt,,,,"As we have Fortify part of our DoD, if it fails, we should be alerted (#xbid_emergency).
 * Relevant for important projects:
 ** XBID
 ** SM
 ** Report Tool
 ** Reporting Engine
 ???",,dm700,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22809600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,03/Jun/20 09:58,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000co",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(split 1) Sonar Quality gate - add check to the nightly pipelines ,XP-3094,96522,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ll664,ll664,03/Jun/20 09:55,06/Nov/20 11:10,22/Feb/21 13:26,22/Jul/20 08:38,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Quality Gate Improvement{color}
h2. Current Situation

We have the Sonar Quality Gate as a part of our DoD: [https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?spaceKey=XBID&title=Definition+of+Done+and+Potentially+Shippable]

But we don't check the status very often.
h2. Proposed solution 

Configure nightly builds so they fail if quality gate fails (doesn't work like this at the moment).
 [https://www.jenkins.io/blog/2017/04/18/continuousdelivery-devops-sonarqube/]
 * Relevant for important projects:
 ** XBID 
 ** SPM
 ** Report Tool
 ** ComTrader",,dm700,ek176,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3315,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22809600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,03/Jun/20 09:55,,,,,,,,,,,,,,,,,,,,,,,"1|y0b70l:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-3285-am-atc-utilization,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,master-comtrader-2.5.x,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-2979-postgresql,XP-3345-version-bump,XP-3361,develop,XP-3345,XP-4505_xbid_develop_hpfortify_upgrade,master,master-acceptance,XP-3243-report-tool-hp-fortify,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,acceptance,comtrader-2.5.x,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HP Fortify: Fix High Findings,XP-3092,96505,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,02/Jun/20 15:59,04/Aug/20 19:53,22/Feb/21 13:26,24/Jun/20 11:17,,,3.1.0,,,,,,,,,,,"[https://hpfortify.dwain.infra/ssc/html/ssc/version/10475/fix/null/?issueFilters=FOLDER_FOLDER:5b50bb77-071d-08ed-fdba-1213fa90ac5a&filterSet=dbd63fcc-432f-4066-8388-1b008de27dc1]

 

_Problem_: HP Fortify reports 0 Critical, 17 High, 0 Medium findings for XBID_DEVELOP (*AID292_XBID_MAIN*). 

 

 

_Task_: Fix/supress reported high findings (and critical/medium if any).

 

_AC_: 0 critical, 0 high and 0 medium findings in HP Fortify

 

Suggestion: Group by Category.

Check also with [~dm700] why are views so dynamic.",,ek176,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3184,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20995200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Jun/20 16:07;ek176;For the pathManipulation, consider using: [File.createTempFile(...)|https://docs.oracle.com/javase/7/docs/api/java/io/File.html#createTempFile%28java.lang.String,%20java.lang.String%29]","22/Jun/20 16:02;ek176;Please performa a quick smoke test. There should be no functional impact.","24/Jun/20 11:16;hj444;Issue split into:
|XP-3184|(Split 1) HP Fortify: Fix High Findings|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integration tests not included in Sonar coverage,XP-3090,96478,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qo794,qo794,qo794,02/Jun/20 10:08,06/Nov/20 11:10,22/Feb/21 13:26,03/Jun/20 07:53,,,3.1.0,,GA,,,,,,,,,"The test coverage in Sonar shows about 54%, classes covered by integration tests have 0% test coverage there!

https://sonar.energy.dev.dbgcloud.io/dashboard?id=com.deutscheboerse.energy.xbid%3Aaccess-management",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22809600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s00001i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Jun/20 07:53;qo794;After the fix the code coverage increased in Sonar to *88.2%*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CrossedObkValidator does not detect crossed AON order-books,XP-3086,96456,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,lt112,lt112,01/Jun/20 14:54,03/Nov/20 12:08,22/Feb/21 13:26,03/Nov/20 12:08,,,3.2.x,,,,,,,,,,,"The following code used in {{CrossedObkValidator}} will only catch AON for max and min, but would not work for the example below.
{code}
        if (maxBuyPrice < minSellPrice) {
            return;
        }
        if ((isAonOrder(maxBuy) || isAonOrder(minSell)) && maxBuy.getExposedQuantity() != minSell.getExposedQuantity()) {
            return;
        }
{code}

Example:
B100@200
B99@150
S80@150
",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22896000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,01/Jun/20 14:54,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:t",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMI Spring Security version warning,XP-3079,96364,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,28/May/20 11:10,04/Aug/20 19:53,22/Feb/21 13:26,10/Jun/20 10:54,,,2.0.31,3.1.0,,,,,,,,,,"This pops up in the logs:
{code}
2020-05-28 11:09:50.770 RMI TCP Connection(2)-127.0.0.1 WARN  - org.springframework.security.core.SpringSecurityCoreVersion - **** You are advised to use Spring 5.1.14.RELEASE or later with this version. You are running: 5.1.13.RELEASE
{code}

Check and upgrade.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23328000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,28/May/20 11:10,,,,,,,,,,,,,,,,,,,,,,,"1|y0ayeg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3048-only-two-ts-in-case-of-no-atc-in-requested-time-range,acceptance,develop,XP-3015,XP-3079,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sonar for m7-shipping develop,XP-3078,96331,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ei349,ei349,27/May/20 15:16,06/Nov/20 11:10,22/Feb/21 13:26,03/Jun/20 16:10,,,3.1.0,,,,,,,,,,,[~dm700] - Sonar XBID quality gate is applied on m7-shipping develop? m7-shipping sm-2.0 (and xbid develop) is in the gate but m7-shipping develop does not seem to be there 🧐,,dm700,ei349,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/20 15:24;dm700;Sonar snapshot.png;https://jira.deutsche-boerse.com/secure/attachment/85472/Sonar+snapshot.png","08/Jul/20 15:25;dm700;xbid pipeline.png;https://jira.deutsche-boerse.com/secure/attachment/85473/xbid+pipeline.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19699200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s00001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/20 10:10;qo794;The quality gate changed in Sonar to ""XBID way"" for *m7-shipping develop*","03/Jun/20 08:16;qo794;XBID Quality Gate (https://sonar.energy.dev.dbgcloud.io/quality_gates/show/7) checks only the following values:
{quote}
Maintainability Rating on New Code - A
Reliability Rating on New Code - A
Security Rating on New Code - A
{quote}
All above checks are passed for m7-shipping develop","03/Jun/20 16:10;qo794;XBID Quality Gate definition will be treated/discussed within XP-3099","08/Jul/20 15:26;dm700;reopened - Sonar gate for shipping develop has not passed but shipping nightly did not stop, how is this possible? can you please check again the configuration in Jenkins?","08/Jul/20 15:29;qo794;this is the reason: XP-3094",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Send May SLA report to customers ,XP-3076,96326,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ei349,ei349,27/May/20 13:54,13/Aug/20 19:45,22/Feb/21 13:26,01/Jun/20 14:43,,,3.1.0,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23414400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,0.25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
REP - remove distinct from TC540,XP-3073,96316,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eg288,uv683,27/May/20 12:45,04/Aug/20 19:53,22/Feb/21 13:26,10/Jun/20 12:52,,,3.1.0,,Reporting Engine,,,,,,,,,"To generate a report the reporting engine loads all needed data from database into memory. Then all the data are transformed itno JAXB objects and only then written as one chunk into a XML file. It is very demanding on memory, especially for ADMIN member, where the resulting XML report TC540 can have around 70MB .

The production instance runs with 8 GB of memory and it fails with OutOfMemory on busy days.

Optimize the report generation to decrease memory consuption.

Info:
 * fails during night, day ok
 * 25 minutes -> 18min data load
 * query returns 1_800k of lines
 * (/) one option is add memory +4 GB - Ask Niklas -> memory added, the application uses 12GB, it works for now
 * another is change query run by hour than day
 * analyse

SQL query for report TC540 reads table cx_101_order_history. The query selects data according to colums last_update_time. There is an index in place. See XP-2882 for further details.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3124,XP-3115,XP-3114,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22204800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aw26:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,1.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3073,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Jun/20 10:18;uv683;I have split this issue into three tasks.
 * this one is dealing with TC540 query and indices
 * XP-3114 is about batching report data collection and generation into smaller time windows (hours) rather than days to minimize memory impact
 * XP-3115 is about finding inefficiencies in queries for TC810 and TC830 reports","10/Jun/20 12:51;uv683;Issue split into:
|XP-3124|(split)REP - remove distinct from TC540|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split) Report tool fails to generate when there are too many distinct response times,XP-3072,96315,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,lt112,eh941,27/May/20 12:27,04/Aug/20 19:53,22/Feb/21 13:26,02/Jun/20 12:54,,,3.1.0,,SLA Report Tool,,,,,,,,,"Internal report fails to generate when there is more than 65536 rows.

{{BaseGroupPercentileReportGenerator}}
{{CommonPercentileReportGenerator}}

* consider exporting to {{xlsx}} instead of {{xls}}
* refactor, rewrite, aggregate data in memory, not in excel",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23414400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0awfw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 2) P3P5-V1 - Lacking validation of the server certificate,XP-3071,96242,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hj444,zi174,ek176,27/May/20 09:24,04/Aug/20 19:53,22/Feb/21 13:26,03/Jul/20 12:12,,,3.1.0,,,,,,,PenetrationTest,,,,"|FINDING: P3P5-V1|
|LOCATION: Client component|
|RISK: High|

|Description:
The assessment showed that an attacker is able to intercept the communication between the ComTrader client and the profile server. This way, he can obtain login credentials and thus gain unauthorized access to the application.
 The data transmitted between the client and the server is protected with TLS to ensure confidentiality and integrity. However, it is possible to perform a man-in-the-middle attack as the client does not verify the server certificate. Therefore, an attacker can present a fake certificate to the client to then intercept the communication between the client and the server.
 Consequently, the attacker is able to obtain the following information:
 • username
 • password
 Example
 Intercepted request containing the base64-encoded application username and password:
 POST /xbid-simu/services/RemoteProfileServiceV3 HTTP/1.1
 Content-Type: text/xml; charset=UTF-8
 Accept: */*
 Authorization: Basic VUxUUkFCT0I6Q2██████████████
 SOAPAction: """"
 User-Agent: Apache-CXF/3.1.14
 Cache-Control: no-cache
 Pragma: no-cache
 Host: simu1.profiles.xbid.deutsche-boerse.com:60104
 Connection: close
 Content-Length: 278
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfile xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><arg0>XSOBv1</arg0><arg1>ULTRABOB</arg1><arg2>simu</arg2></ns2:loadProfile></soap:Body></soap:Envelope>
 

|*Threat:* As an attacker is able to intercept the communication between the client and the server, the login credentials for the ComTrader application are exposed to the attacker. He is thus able to access the ComTrader application and query data depending on the role of the targeted user without being authorized.|

|*Recommendation:* We recommend validating the TLS certificate of the server in the client component when establishing the connection. To do so, the client should check whether the server certificate
 • has been issued by the CA known to the client,
 • if it has been issued to the host name of the server
 • and if it is still valid.
 To also ensure the integrity and confidentiality of the connection in case the CA is compromised or if an attacker manages to obtain a certificate in the server’s name from the CA, we recommend carrying out an additional “pinning” of the server certificate. In practice, this can lead to the fact that the client has to be updated every time the server certificate is changed.
 For more information on certificate pinning, please refer to:
 • https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning|
|

 ",,ek176,hj444,rl336,,,,,,,,,,,,,,,,,,XP-3205,,,,,,,,,,,,,,,PD-425,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20217600,,,,,,,,,,,,,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b1gn:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,comtrader-2.5.x,master-comtrader-2.5.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"25/Jun/20 14:20;ek176;DNS names requested:
syt2-profiles.xbid.deutsche-boerse.de
simu1-profiles.xbid.deutsche-boerse.com
simu2-profiles.xbid.deutsche-boerse.com
prod1-profiles.xbid.deutsche-boerse.com
prod2-profiles.xbid.deutsche-boerse.com","01/Jul/20 17:38;ek176;Released CT 2.5.1.65

Works on simu:
{code:java}
2020-07-01T17:34:26.659+0200 [lication Thread] INFO  c.d.c.c.s.CleanupServiceImpl - Configuring old data cleanup to run every 60 minutes
2020-07-01T17:34:29.234+0200 [JavaFX-Launcher] INFO  c.d.c.c.s.i.InfoLogger - PROXY: 
2020-07-01T17:34:29.235+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - CT: 2.5.1.65/2020-07-01T15:26:18Z
2020-07-01T17:34:29.235+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - OS: Windows Server 2012 R2/6.3/x86
2020-07-01T17:34:29.235+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - JVM: Java HotSpot(TM) Client VM/1.8.0_171/javaws-11.171.2.11
2020-07-01T17:34:29.235+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Clientsystem Timezone: Europe/Prague
2020-07-01T17:34:29.235+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Session environment: Citrix


2020-07-01T17:34:39.368+0200 [trader-Worker-8] INFO  c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://simu1-profiles.xbid.deutsche-boerse.com:60104/xbid-simu/services/RemoteProfileServiceV3
2020-07-01T17:34:39.532+0200 [trader-Worker-8] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-07-01T17:34:40.251+0200 [trader-Worker-8] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-07-01T17:34:40.607+0200 [trader-Worker-8] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-07-01T17:34:40.635+0200 [trader-Worker-8] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-07-01T17:34:40.639+0200 [trader-Worker-8] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/DBAGSOBR exists, attempting to load it.
2020-07-01T17:34:40.674+0200 [trader-Worker-8] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
2020-07-01T17:34:40.852+0200 [rader-Worker-11] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Simu SOB: DBAGSOBR@10.103.128.23:50100/ext/XSOBv1
{code}","02/Jul/20 10:21;rl336;https://vmt.deutsche-boerse.de/browse/PT-1517","02/Jul/20 14:31;hj444;Test SYT1:
ComTrader V. 2.5.1.65 2020-07-01T15:26:18Z
JRE: 1.8.0_191-b12, Webstart: javaws-11.191.2.12
JVM: Java HotSpot(TM) 64-Bit Server VM by Oracle Corporation
OS: Linux 4.15.0-96-generic amd64
265MB / 4096MB
XBID-SOB 2.0.42

{code}2020-07-02T13:25:49.855+0200 [lication Thread] INFO  c.d.c.c.s.CleanupServiceImpl - Configuring old data cleanup to run every 60 minutes
2020-07-02T13:25:49.962+0200 [JavaFX-Launcher] INFO  c.d.c.c.s.i.InfoLogger - PROXY: http_proxy=http://webproxy.deutsche-boerse.de:8080/,https_proxy=http://webproxy.deutsche-boerse.de:8080/,no_proxy=.dyn.deutsche-boerse.de,.deutsche-boerse.de,.oa.pnrad.net,.pnrad.net,.cedelgroup.com,.xeop.de
2020-07-02T13:25:49.963+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - CT: 2.5.1.65/2020-07-01T15:26:18Z
2020-07-02T13:25:49.963+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - OS: Linux/4.15.0-96-generic/amd64
2020-07-02T13:25:49.963+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - JVM: Java HotSpot(TM) 64-Bit Server VM/1.8.0_191/javaws-11.191.2.12
2020-07-02T13:25:49.963+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Clientsystem Timezone: Europe/Prague
2020-07-02T13:25:49.963+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Session environment: null
2020-07-02T13:25:49.968+0200 [JavaFX-Launcher] INFO  c.d.c.c.j.ComtraderBase - Set Locale: en
2020-07-02T13:25:49.972+0200 [JavaFX-Launcher] INFO  c.d.c.c.j.u.StuckApplicationGuard - The StuckApplicationGuard is enabled.
2020-07-02T13:25:49.973+0200 [JavaFX-Launcher] INFO  c.d.c.c.j.u.StuckApplicationGuard - Expected load is now set to HEAVY/120000 millis
2020-07-02T13:25:50.044+0200 [lication Thread] INFO  c.d.c.c.j.c.BorderPaneAbstractController - Load: GuiMessageRecorder.fxml
2020-07-02T13:25:50.092+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - CPU: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz - 4 x 3839.745
2020-07-02T13:25:50.094+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - RAM: 32777788 kB
2020-07-02T13:25:50.095+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Screen info (1): 1920x1200
2020-07-02T13:25:50.098+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Uptime: PT3.835S
2020-07-02T13:25:50.098+0200 [trader-Worker-1] INFO  c.d.c.c.s.i.InfoLogger - Session: 
2020-07-02T13:25:50.426+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/xsob1/overrides.json
2020-07-02T13:25:50.432+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/default-overrides.json
2020-07-02T13:25:50.433+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/admin-only-overrides.json
2020-07-02T13:25:50.435+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-bespoke-trades-overrides.json
2020-07-02T13:25:50.436+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-change-password-overrides.json
2020-07-02T13:25:50.437+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-implied-price-overrides.json
2020-07-02T13:25:50.437+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-indicative-orders-overrides.json
2020-07-02T13:25:50.439+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-continuous-export-overrides.json
2020-07-02T13:25:50.440+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-closing-price-overrides.json
2020-07-02T13:25:50.440+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-auction-overrides.json
2020-07-02T13:25:50.441+0200 [lication Thread] INFO  c.d.c.c.j.o.AbstractOverrideConfigurationsExecutorImpl - Loading GUI overrides: guisettings/overrides/suppress-block-vwap-overrides.json
2020-07-02T13:25:50.496+0200 [lication Thread] INFO  c.d.c.c.j.c.AbstractBorderPaneController - Load: SingleLoginPanel.fxml
2020-07-02T13:25:50.912+0200 [lication Thread] INFO  c.d.c.c.j.u.FxDelaySensor - FxDelay: 937ms
2020-07-02T13:26:01.933+0200 [trader-Worker-8] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/XBEPEXA2 exists, attempting to load it.
2020-07-02T13:26:02.031+0200 [rader-Worker-17] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest1 TS A (XBID): XBEPEXA2@10.136.142.19:50700/ext/XSOBv1
2020-07-02T13:26:02.891+0200 [rader-Worker-17] INFO  c.d.c.c.s.a.ComTraderConnectionFactory - set up SSL context
2020-07-02T13:26:02.931+0200 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2020-07-02T13:26:03.101+0200 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Request channel created
2020-07-02T13:26:03.101+0200 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new response channel
2020-07-02T13:26:03.252+0200 [rader-Worker-17] INFO  c.d.c.c.s.a.AmqpRpcClient - Response channel created
2020-07-02T13:26:03.265+0200 [rader-Worker-17] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Request: 872193899 LoginReq 
2020-07-02T13:26:03.373+0200 [rader-Worker-17] DEBUG c.d.c.c.s.a.AbstractAmqpBackend - Response: 872193899 UserRprt 
2020-07-02T13:26:03.374+0200 [rader-Worker-18] INFO  c.d.c.c.s.a.AmqpBroadcastClient - Connecting to broadcast queue comxerv.broadcastQueue.XBEPEXA2...
2020-07-02T13:26:03.393+0200 [lication Thread] INFO  c.d.c.c.j.s.MainPanelServiceImpl - Load window with suffix: 0{code}","02/Jul/20 16:49;ek176;SYT2: CN Check disabled ({color:#00875a}[INSECURE]{color} info displayed, CTP remote ops return {color:#00875a}200{color}): 
{noformat}
2020-07-02T16:33:44.456+0200 [rader-Worker-21] WARN  c.d.c.c.s.r.RemoteServiceProxy - [INSECURE] SSL Profile Storage CommonName check is disabled. Certificate issued for another endpoint will be accepted.
2020-07-02T16:33:44.456+0200 [rader-Worker-21] INFO  c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://syt2-profiles.xbid.deutsche-boerse.de:60806/profile-storage/services/RemoteProfileServiceV3
2020-07-02T16:33:44.457+0200 [rader-Worker-21] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-07-02T16:33:44.623+0200 [rader-Worker-21] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-07-02T16:33:44.663+0200 [rader-Worker-21] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-07-02T16:33:44.684+0200 [rader-Worker-21] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-07-02T16:33:44.685+0200 [rader-Worker-21] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/XBEPEXA2 does not exist.
2020-07-02T16:33:44.685+0200 [rader-Worker-21] INFO  c.d.c.c.s.p.ProfileManagerImpl - Attempting to create a new default profile.
2020-07-02T16:33:44.716+0200 [rader-Worker-21] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-07-02T16:33:44.744+0200 [rader-Worker-21] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}createProfile returned 200{noformat}
SIMU: CN check Enabled (No [INSECURE] warning in logs, CTP remote ops return 200):
{noformat}
2020-07-02T16:41:18.816+0200 [rader-Worker-22] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-07-02T16:41:18.847+0200 [rader-Worker-22] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-07-02T16:41:18.849+0200 [rader-Worker-22] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/DBAGSOBR exists, attempting to load it.
2020-07-02T16:41:19.610+0200 [rader-Worker-22] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200{noformat}","03/Jul/20 11:56;ek176;Info about CN check disable added to the _Troubleshooting_ section of: [https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+ComTrader+Release+HOWTO]","03/Jul/20 12:10;hj444;SYT2 test done. 
 Citrix : Comtrader run via internal webstart LINK (not local profile link)
 [https://m7trading-internaltest.deutsche-boerse.com/comtrader-2.5.x/xbid.html]

{code}
[JavaFX-Launcher] INFO c.d.c.c.s.i.InfoLogger - PROXY: 
2020-07-03T10:29:12.738+0200 [trader-Worker-1] INFO c.d.c.c.s.i.InfoLogger - CT: 2.5.1.66/2020-07-02T14:21:43Z
2020-07-03T10:29:12.739+0200 [trader-Worker-1] INFO c.d.c.c.s.i.InfoLogger - OS: Windows Server 2012 R2/6.3/x86
2020-07-03T10:29:12.739+0200 [trader-Worker-1] INFO c.d.c.c.s.i.InfoLogger - JVM: Java HotSpot(TM) Client VM/1.8.0_171/javaws-11.171.2.11
{code}

 

from logs:
{code:java}
[lication Thread] INFO  c.d.c.c.j.c.AbstractBorderPaneController - Load: SingleLoginPanel.fxml
2020-07-03T10:29:13.905+0200 [lication Thread] WARN  c.d.c.c.j.u.FxDelaySensor - FxDelay: 1141ms
2020-07-03T10:29:20.736+0200 [rader-Worker-10] WARN  c.d.c.c.s.r.RemoteServiceProxy - [INSECURE] SSL Profile Storage CommonName check is disabled. Certificate issued for another endpoint will be accepted.
2020-07-03T10:29:20.847+0200 [rader-Worker-10] INFO  c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://syt2-profiles.xbid.deutsche-boerse.de:60806/profile-storage/services/RemoteProfileServiceV3
2020-07-03T10:29:20.988+0200 [rader-Worker-10] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-07-03T10:29:21.624+0200 [rader-Worker-10] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-07-03T10:29:21.828+0200 [rader-Worker-10] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-07-03T10:29:21.852+0200 [rader-Worker-10] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-07-03T10:29:21.854+0200 [rader-Worker-10] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/SADMIN01 exists, attempting to load it.
2020-07-03T10:29:21.873+0200 [rader-Worker-10] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
2020-07-03T10:29:22.001+0200 [trader-Worker-9] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest2 TS A (XBID): SADMIN01@10.136.142.20:50800/ext/XSOBv1
2020-07-03T10:29:23.560+0200 [trader-Worker-9] INFO  c.d.c.c.s.a.ComTraderConnectionFactory - set up SSL context
2020-07-03T10:29:23.601+0200 [trader-Worker-9] INFO  c.d.c.c.s.a.AmqpRpcClient - Creating new request channel
2020-07-03T10:29:23.778+0200 [trader-{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze our network infrastructure for potential future segregation,XP-3066,96198,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ei349,ei349,26/May/20 15:15,06/Aug/20 12:52,22/Feb/21 13:26,06/Aug/20 12:52,,,Not a release,,,,,,,TechOps,,,,"h1. {color:#00875a}Overview about our environments and their coupling{color}
h2. Current Situation

We might have a situations with hard access to our remote environments. We have to use jumphosts, tunneling or CyberArk. There might be a easier ways how to access our envs if they will below to proper segregated network. (see XP-3066 for all details)
h2. Proposed Solution

 Analyze our environments and prepare a list of what is segregated and can be ""easily"" moved and where are using shared hardware or VM and we need to find a proper solution like duplicating the machine or other way. 
h2. Acceptance Criteria

- Overview about our environments. In which network they are, what is individual machine and can be potentially moved and what's shared. ",,ei349,ek176,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17280000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3068,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bbbr:zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Aug/20 12:50;yo218;Currently we have one shared ""Test"" network which contains all internal and customer facing (CuTes & LIPs) test environments. It contains the following VLANs:
||Range||Label||Zone||VLAN ID||Required for Dev network||
|10.139.40.0/23|XBID TEST BE|SIMULATION|476|yes|
|10.139.93.0/28|XBID TEST ECP DB|SIMULATION|200|no|
|10.136.143.0/24|XBID-TST-LB-FF|INTERNET DMZ|474|no|
|10.136.15.0/24|XBID TEST LB HAU|INTERNET DMZ|471|no|
|10.136.152.160/27|XBID TEST SFTP EQX|INTERNET DMZ|194|yes|
|10.136.24.160/27|XBID TEST SFTP HAU|INTERNET DMZ|196|yes|
|10.136.152.0/28|XBID TEST ECP EQX|EXTRANET DMZ|256|no|
|10.136.24.0/28|XBID TEST ECP HAU|EXTRANET DMZ|254|no|
|10.136.153.0/24|XBID TEST MPLS LB EQX|EXTRANET DMZ|244|no|
|10.136.25.0/24|XBID TEST MPLS LB HAU|EXTRANET DMZ|242|no|
|10.136.158.32/27|XBID TEST MPLS CLIENT|EXTRANET DMZ|173|no|
|10.136.152.32/28|XBID TEST TRS2 EQX|EXTRANET DMZ|248|no|
|10.136.24.32/28|XBID TEST TRS2 HAU|EXTRANET DMZ|246|no|
|10.136.158.0/28|XBID TEST TRS3|EXTRANET DMZ|172|no|
|10.136.142.0/24|XBID TEST WEB EQX|INTERNET DMZ|473|no|
|10.136.14.0/24|XBID TEST WEB EQX|INTERNET DMZ|470|no|

 

In my point of view, the MPLS and ECP VLANs don't need to be duplicated as neither Colt nor Orange is available for internal environments. Furthermore we won't need dedicated Internet DMZ as the environments won't be connected to the internet. So we would have to request 3 new VLANs from the network team. Which network equipment can be shared and which components have to be bought can be answered from network team the best.

 

Virtual machines that would have to be moved to a new internal dev network:
||Syt1||Syt2||Syt3||Shared Internal||Performance||DST||
|xbsyt1ams1
 xbsyt1cmi1
 xbsyt1cmi2
 xbsyt1cmm1
 xbsyt1cmm2
 xbsyt1cor1
 xbsyt1cor2
 xbsyt1ecp1
 xbsyt1ecp2
 xbsyt1imq1
 xbsyt1imq2
 xbsyt1imq3
 xbsyt1imq4
 xbsyt1imq5
 xbsyt1imq6
 xbsyt1sla1
 xbsyt1sob1
 xbsyt1sob2
 xbsyt1spm1
 xbsyt1spm2
 xbsyt1xmq1
 xbsyt1xmq2
 xbsyt1xmq3
 xbsyt1xmq4
 xbsyt1xmq5
 xbsyt1xmq6|xbsyt2amq1
 xbsyt2cmi1
 xbsyt2cmm1
 xbsyt2cor1
 xbsyt2ecp1
 xbsyt2sob1
 xbsyt2spm1|xbsyt3cmi1
 xbsyt3cmi2
 xbsyt3cmm1
 xbsyt3cmm2
 xbsyt3cor1
 xbsyt3cor2
 xbsyt3ecp1
 xbsyt3ecp2
 xbsyt3imq1
 xbsyt3imq2
 xbsyt3imq3
 xbsyt3sob1
 xbsyt3sob2
 xbsyt3spm1
 xbsyt3spm2
 xbsyt3xmq1
 xbsyt3xmq2
 xbsyt3xmq3|xbintebha1
 xbintebha2
 xbintebha3
 xbintebha4
 xbintecbn1
 xbintecbn2
 xbintecha1
 xbintecha2
 xbintecom1
 xbintecom2
 xbintecom3
 xbintecom4
 xbintectp1
 xbintectp2
 xbinteedb1
 xbinteidm1
 xbinteidm2
 xbintepmi1
 xbintepmi2
 xbinteprx1
 xbinteprx2
 xbinterep1
 xbinterep2
 xbinterts1
 xbinterts2
 xbintessl1
 xbintessl2
 xbinteweb1
 xbinteweb2|xbperfbha2
 xbperfbha4
 xbperfcbn2
 xbperfcha2
 xbperfcmi1
 xbperfcmm1
 xbperfcom1
 xbperfcom2
 xbperfctp1
 xbperfecp1
 xbperfidm2
 xbperfimq2
 xbperfimq4
 xbperfimq6
 xbperfpdb1
 xbperfpdb2
 xbperfrep1
 xbperfrts2
 xbperfrts4
 xbperfsmc1
 xbperfsmi1
 xbperfsob1
 xbperfssl1
 xbperfssl2
 xbperfweb1
 xbperfweb2
 xbperfxmq2
 xbperfxmq4
 xbperfxmq6|xbdst1amq1
 xbdst1app1|

 Physical host that would have to be moved to a new internal dev network:
||Syt1||Syt2||Syt3||Shared Internal||Performance||DST||
| | | | |xbidperfcor1| |

Shared hosts, which would need to be duplicated:
||Name||Purpose||Suggestion||
|xbdtldap1|Old (still used) LDAP server|not required|
|xbdtldap2|Old (still used) LDAP server|not required|
|xbtestldp1|New (not yet used) LDAP server|new VM: xbinteldp1|
|xbtestldp2|New (not yet used) LDAP server|new VM: xbinteldp2|
|xbtestpdb1|Physical database host|new VM: xbintevdb1|
|xbtestpdb2|Physical database host|new VM: xbintevdb2|
|xbtestdbr1|Virtual database replication host|new VM: xbintedbr1|
|xbtestdbr1|Virtual database replication host|new VM: xbintedbr1|

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Estimate effort of fixes for R3.1,XP-3064,96160,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,tm431,tm431,26/May/20 10:38,13/Aug/20 20:12,22/Feb/21 13:26,04/Jun/20 10:37,,,3.1.0,,,,,,,R3.1Bugs,,,,"[https://jira.deutsche-boerse.com/projects/XBID/versions/18942]

Please find with finalization of this task for Monday 1st June. Customers should provide us with the final list officialy. 

–

 

Estimate following bugs, they should be ready byt 3.1 release, i.e. ready to be deployed into UAT on 5/8 (August) /2020

Following are trivial, but can be tricky to fix

 

 
|XBID-3381(/)| Trivial|XP-255|AU execution restriction is not listed in any specification|To be fixed, API change we should tell them| |To Develop|
|XBID-3409   (/)                    | Trivial|XP-253|Dynamic filter in Message Panel seems to not behave correctly (drop-down menu)|To be fixed, Fix is ready but I think that new version of CT must be released| |To Develop|
|XBID-3420 (/)| Trivial|XP-252|Usability: No change of user without closing ALL IE-sessions|To be fixed, can be tricky| |To Develop|
|XBID-3371(/)| Trivial|XP-256|Shipping Module user certificate not shown on modification|This I believe was fixed in some previous versions, but customers do not know about it| |Fixed|
|XBID-1804 (/)| Trivial|XP-262|Double authentification requested to File Management user on CMM|{color:#de350b}Can be tricky to fix, or impossible. Discussion must be opened{color}| | |
|XBID-4665(/)| Trivial|XP-1998|Failover Scenario 1.6 - unexpected FR_AE_10 and FR_AE_011 received during the execution|This should be fixed by other fixes|[~tm431]|Fixed|
|XBID-3393(/)| Trivial|XP-98/XP-2476|Usability improvement in CMM: better messages to the user| Maybe fixed?| | |

 
|XBID-4712(/)|Minor| XP-2129|Latent FAULT: SM files missing for some synch points|This is alrady fixed, but I do not know in which branch, I think SPM from develop should only be released, as COR part already was| |Fixed|
|XBID-4765/ XBID-4824    (/)|Minor| XP-2262|Latent FAULT: Can't access to SOB WebGUI|This is fixed in Agile pilot version, but customers do not know about it| |Fixed|
|XBID-4634 (/)|Minor| XP-1893|Latent FAULT: CMI FTC validity interval not working correctly|To be fixed| |To Develop|
|XBID-4746/XBID-4823(/)|Minor| XP-2218|Latent FAULT: DA cannot be deleted in a specific situation|{color:#de350b}This can be tricky to develop{color}| |To Develop|

  
|XBID-5067/SMXBID-1198(/)|Major|XP-2943|OPSCOM Hot fix in Agile version - SMXBID-1198 Missing RCA file or missing transaction in a RCA file|This was fixed, and deployed with R3.0 OCC| |Fixed|
|XBID-5103(/)|Trivial|XP-3032|Error messages inconsistent when IC identification in NTC/CBS file fails|{color:#de350b}Discussion is ongoing, we need to set deadline for them{color}| | |
|XBID-5090(/)|Trivial|XP-2982|HLS100A 2.19 Sending email after third attempt of sending automatic file via SCP|Fixed in develop| |Fixed|
|XBID-5110(/)|Minor|XP-3041|sftp not working in LIPA, LIPB, CutePX again|We (alfa) should inform them in external ticket that it is OK and that this was caused by infrastructure issues...| | |
|XBID-4773(/)|Major| XP-2270|Double publication of NSF files in sftp communication|{color:#de350b}More info is needed for investigation, I have asked for more details, but did not get any. We should set them the deadline{color}| | |
|XBID-5066(/)|Trivial|XP-2936|Regression Tests: The changes in user attributes have been withdrawn, although the 'No' option has been selected|Fixed| | |

 XBID-5066

*OCC R3.0 OCC bugs to be included, final list will be known after OCC file testing is finished i.e. after 15/6/2020*
 *There is also one or two latent fault do not forget to mention it in Managerial documents*

 
|XBID-5116 (/)|Minor|XP-3055|Login in leads to CMM Error: Server error |Fixed, will be included in 10/6/2020 deployment under R3.0 OCC| |Fixed|
|XBID-5119(/)|Trivial|XP-3061|*Latent Fault* Given new files were sent, CMI downloads unexpected file|We need their confirmation, but will be fixed in R3.1 under refresh gui improvement| | |
|XBID-5121(/)|Trivial|XP-3065|Generated from"" times cannot be set separately; and value is not retained|Fixed, will be included in 10/6/2020 deployment under R3.0 OCC| |Fixed|
|XBID-5123(/)|Major|XP-3082|OCC file triggered by two simultaneous special allocation misses latest updateTime|Most probably not a bug| | |
|XBID-5127(/)|Minor|XP-3048|Only latest ATCs should be reflected in OCC|Our Bug, we have the fix, and should be deployd 10/6/2020, if customers confirm that they want it| |Fixed|

 

 

 ",,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s0000w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/20 10:37;tm431;Closing issue. Tickets were estimated",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare the list of customer impact from tech debt/security implementation tasks,XP-3063,96158,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,26/May/20 09:46,19/Aug/20 14:43,22/Feb/21 13:26,19/Aug/20 14:43,,,3.1.0,3.1.1,,,,,,,,,,"Find a suspicious list of tasks what might potentially have an impact on customers in any way:

Check mainly epics
 * Penetration tests tickets 
 * Tech debt
 * Security 

Don't waste that much time on this one. Create a follow up ticket with the list so we can analyze further. ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23500800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Trade recall screen show an error in Trading Inquiry,XP-3060,96099,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qm925,eh941,eh941,25/May/20 11:12,31/Aug/20 15:39,22/Feb/21 13:26,26/May/20 14:14,,,3.1.0,,,,,,,Latent_Faults,,,,"When there is an recall request then the Web GUI shows an error.

See  !screenshot-10.136.14.19_60700-2020.05.22-17_02_56.png!

{color:#de350b}*The error is in place since version 2.0.30*{color}",,eh941,qm925,tm431,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/20 11:11;eh941;screenshot-10.136.14.19_60700-2020.05.22-17_02_56.png;https://jira.deutsche-boerse.com/secure/attachment/84107/screenshot-10.136.14.19_60700-2020.05.22-17_02_56.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19267200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0awv4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"25/May/20 11:13;eh941;It was found out when testing XP-3027","25/May/20 11:14;eh941;Caused by preArranged flag deletion","26/May/20 14:14;tr866;Successfully tested on docker with version R2.0.40-SNAPSHOT (Build 0583f80ad12640ed4ef9502823bdec3d303a8ca6)
The Admin's WebGUI is now working correctly and the requested recalls are displayed in ""Requested Recalls"" overview and the recalls can be processed. In Comtrader no problems were observed anymore, it was most probably cause by some specific setup on Syt1 as also AMQP Test Client was struggling to log in with certain users.","13/Jul/20 10:12;eh941;The bug was there since version 2.0.30. It affects only the GUI - core module isn't affected at all. The fix was done in version 2.0.40. The bug was created by XP-1963 which is primarily a tech-debt task.","13/Jul/20 11:44;tr866;draft of the answer:

Dear Gertjan Brouwer,

The bug was created by implementation of a tech-debt task. The issue is being qualified as Latent Fault and is present in the application since version 2.0.30 which implies its presence on Production as well. As a consequence of this glitch the WebGUI gets broken when there exists a requested recall for a trade and ""Requested Recalls"" tab is selected. It affects only the GUI on one specific tab and there's no impact on the core module, i.e. stability of the system. As a workaround the requested recalls still can be processed in ComTrader and after they are processed the WebGUI behaves normally again. We have already a fix available. In case of high urgency it is possible to deliver the fix by deployment of the trading inquiry which on a double sided environment like Production can be done seamlessly.","13/Jul/20 12:29;tm431;***********suggested answer*******

*Classificaion*
 This behavior is bug and is being qualified as Latent Fault. It is present in the application since version 2.0.30 which implies its presence on Production as well


 *Description of the bug*
 As a consequence of this glitch the WebGUI gets broken when there exists a requested recall for a trade and ""Requested Recalls"" tab is selected. It affects only the GUI on one specific tab and there's no impact on the core module, i.e. stability of the system.

*Workaround*

As a workaround the requested recalls still can be processed in ComTrader and after they are processed the WebGUI behaves normally again.

*Permanent fix*
 We have already a fix available and can be deployed into any test env in cca 2days after your confirmation

DBAG will also include this fix into R3.1

*Note*

In case of high urgency it is possible to deliver the fix by deployment of the trading inquiry (SOB) which on a double sided environment like Production can be done seamlessly.

FYI. Lindsay Noble and Camila Vedeler","14/Jul/20 11:58;qm925;*Classification*
 DBAG's analysis determined that this is a Latent Fault. The issue is present in the application since the introduction of version 2.0.30 which implies its presence in Production as well.

The trade and recall feature is described in the following specifications: HLS100 - Functional Description SOB

*Description of the bug*
 As a consequence of this glitch, the WebGUI gets broken when there exists a requested recall for a trade and ""Requested Recalls"" tab is selected. It affects only the GUI on one specific tab and there's no impact on the core module, i.e. stability of the system.

*Workaround*
 As a workaround the requested recalls can be processed in ComTrader and after they are processed, the WebGUI behaves normally again.

*Permanent fix*
 We have already a fix available for this issues which can be deployed into any test env in cca 2days after your confirmation

DBAG can also include this fix into R3.1., if confirmed by  the Parties.

*Note*

In case of high urgency, it is possible to deliver the fix by deploying the trading inquiry (SOB) which on a double sided environment like Production can be done seamlessly.

FYI. Lindsay Noble and Camila Vedeler","14/Jul/20 12:19;tm431;MFG130 - User Manual Central Admin WegGUI -> chapter 2.2
MFG120 - Central Admin Manual XBID-ComTrader -> chapter 3.6.2.2 Process Recall

HLS100 - Functional Description SOB -> chapter 2.3.2 WebGui there is following mention:
 * *Trade Recall Processing*
Acceptance or rejection of requested recalls.

and whole chapter 7.2 Trade Recall

We do not mention this explicitly in DFS700 Reference Data Module - GUI
In DFS510 there is only description on message level, i.e. the recall requests can be accepted/rejected by a message",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade Report Tool to Spring Boot 2.3,XP-3059,96087,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ll664,ll664,25/May/20 08:41,04/Aug/20 19:53,22/Feb/21 13:26,10/Jun/20 10:51,,,3.1.0,,,,,,,,,,,"A new version has been released: https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.3-Release-Notes

Contains couple of improvements, also fixes  for instance this [Tomcat CVE|https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9484].

Once succesfully upgraded, create tasks also for the rest of the components.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23587200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,25/May/20 08:41,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s000f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3013-submitted-orders-product-grouping,develop,master,XP-3011-fix,XP-3059-spring-boot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report tool fails to generate when there are too many distinct response times,XP-3058,96028,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,lt112,lt112,22/May/20 14:48,04/Aug/20 19:53,22/Feb/21 13:26,27/May/20 12:27,,,3.1.0,,SLA Report Tool,,,,,,,,,"Internal report fails to generate when there is more than 65536 rows.

{{BaseGroupPercentileReportGenerator}}
{{CommonPercentileReportGenerator}}

* consider exporting to {{xlsx}} instead of {{xls}}
* refactor, rewrite, aggregate data in memory, not in excel",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3072,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23760000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,22/May/20 14:48,,,,,,,,,,,,,,,,,,,,,,,"1|y0awfs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3012-deprecated-class-fix,XP-3012,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shipping Module leaks RabbitMQ channels when Trading Inquiry is down long enough,XP-3053,95929,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,ll664,ll664,20/May/20 11:48,30/Sep/20 11:37,22/Feb/21 13:26,03/Sep/20 13:05,,,3.1.2,,,,,,,,,,,"When Tradin is down, SM requests for trades fails with no response, but the consumer channel is kept. After a while a channel limit is reached and no consumer could be created anymore.

This effectively stops XBID-SM synchronization.

Happened on CTPA after the Core was down for couple of hours/days.

{code}
2020-05-20T09:40:20.016Z [sformingHandler][][] ERROR c.d.m.s.a.LoggingRetryListener - Retry failed: [RetryContext: count=4, lastException=org.springframework.amqp.AmqpResourceNotAvailableException: The channelMax limit is reached. Try later., exhausted=false]
org.springframework.amqp.AmqpResourceNotAvailableException: The channelMax limit is reached. Try later.
        at org.springframework.amqp.rabbit.connection.SimpleConnection.createChannel(SimpleConnection.java:59)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createBareChannel(CachingConnectionFactory.java:1326)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.access$200(CachingConnectionFactory.java:1312)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.doCreateBareChannel(CachingConnectionFactory.java:655)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createBareChannel(CachingConnectionFactory.java:638)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getCachedChannelProxy(CachingConnectionFactory.java:608)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.getChannel(CachingConnectionFactory.java:499)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.access$1600(CachingConnectionFactory.java:100)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory$ChannelCachingConnectionProxy.createChannel(CachingConnectionFactory.java:1331)
        at org.springframework.amqp.rabbit.listener.DirectMessageListenerContainer.doConsumeFromQueue(DirectMessageListenerContainer.java:649)
        at org.springframework.amqp.rabbit.listener.DirectMessageListenerContainer.adjustConsumers(DirectMessageListenerContainer.java:310)
        at org.springframework.amqp.rabbit.listener.DirectMessageListenerContainer.setConsumersPerQueue(DirectMessageListenerContainer.java:158)
        at org.springframework.amqp.rabbit.listener.DirectReplyToMessageListenerContainer.getChannelHolder(DirectReplyToMessageListenerContainer.java:190)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.doSendAndReceiveWithDirect(RabbitTemplate.java:1788)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.doSendAndReceive(RabbitTemplate.java:1657)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.sendAndReceive(RabbitTemplate.java:1377)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.sendAndReceive(RabbitTemplate.java:1370)
        at com.deutscheboerse.m7.shipping.service.AmqpTradeFetcherImpl.sendRequest(AmqpTradeFetcherImpl.java:115)
        at com.deutscheboerse.m7.shipping.service.AmqpTradeFetcherImpl.lambda$doFetchTrades$1(AmqpTradeFetcherImpl.java:82)
        at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287)
        at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:164)
        at com.deutscheboerse.m7.shipping.service.AmqpTradeFetcherImpl.doFetchTrades(AmqpTradeFetcherImpl.java:82)
        at com.deutscheboerse.m7.shipping.service.AmqpTradeFetcherImpl.fetchTradesInRange(AmqpTradeFetcherImpl.java:67)
        at com.deutscheboerse.m7.shipping.service.SynchronizationPackageServiceImpl.createNewPackage(SynchronizationPackageServiceImpl.java:31)
        at com.deutscheboerse.m7.shipping.service.SynchronizationPackageServiceImpl$$FastClassBySpringCGLIB$$e95de092.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
        at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)
        at com.deutscheboerse.m7.shipping.service.SynchronizationPackageServiceImpl$$EnhancerBySpringCGLIB$$1f06da6f.createNewPackage(<generated>)
        at com.deutscheboerse.m7.shipping.core.transformer.ShippingSynchronizationPointEventTransformer.doCreateSyncPackages(ShippingSynchronizationPointEventTransformer.java:124)
        at com.deutscheboerse.m7.shipping.core.transformer.ShippingSynchronizationPointEventTransformer.transform(ShippingSynchronizationPointEventTransformer.java:85)
        at com.deutscheboerse.m7.shipping.core.eventhandler.TransformingHandler.doOnEvent(TransformingHandler.java:61)
        at com.deutscheboerse.m7.shipping.core.eventhandler.TransformingHandler.doOnEvent(TransformingHandler.java:25)
        at com.deutscheboerse.m7.shipping.core.eventhandler.AbstractEventHandler.onEvent(AbstractEventHandler.java:40)
        at com.deutscheboerse.m7.shipping.core.eventhandler.AbstractEventHandler.onEvent(AbstractEventHandler.java:18)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)

{code}

Hint: it might be caused by missing cleanup on exceptions. ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,14860800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,20/May/20 11:48,,,,,,,,,,,,,,,,,,,,,,,"1|y0bdql:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/20 13:05;ll664;Could not reproduce with current SM version (3.1.2), however it is reproducible with 2.0.10.4. The suspect is spring-amqp library, which we upgraded from 2.1.2 to 2.2.7 in the meantime. So it was most likely a bug in spring-amqp, though I wasn't able to find exact ticket in its changelog.

 

Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix performance test pipeline,XP-3052,95897,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,20/May/20 09:47,04/Aug/20 19:53,22/Feb/21 13:26,28/May/20 10:53,,,3.1.0,,Other,,,,,performance,,,,"https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-performance-test/

* does not use generated scenario
** example:
*** -generated scenario: {{/xbid/performance/test-client/pipeline_scenarios_xml/scenario_XBDBX001.xml}}
*** copied scenario: {{/xbid/performance/test-client/scenarios_xml/scenario_XBDBX001.xml}} -> {{/xbid/performance/new/scenario_XBDBX001.xml}}
*** used scenario:
**** either {{/xbid/performance/new/scenario_XBDBX001.xml}}
**** or {{/xbid/performance/test-client/scenarios_xml/scenario_XBDBX001.xml}}
* seems to use outdated runner?
** {{scenario-runner:0.0.4}} vs {{test-scenario-runner:6.0.33}}",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23328000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,20/May/20 09:47,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s00001r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-3243-report-tool-hp-fortify,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_reporting_tools_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/May/20 10:17;lt112;https://github.deutsche-boerse.de/dev/xbid-pipeline/pull/82",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add more file transfer configuration to tosca-fake dataset ,XP-3044,95848,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,19/May/20 12:46,04/Aug/20 19:53,22/Feb/21 13:26,03/Jun/20 15:04,,,3.1.0,,,,,,,,,,,"Add more file transfer configuration to tosca-fake dataset.
For the testing purpose, it would be good to have a default file transfer configuration for all file types in the dataset. ",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ayos:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,XP-2476-change-label-to-universal-one,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Jun/20 15:04;od044;New dataset version 1.3.63
- all ICs contain FTC for all file types in default ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix tosca grid in tosca fake dataset,XP-3043,95847,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,19/May/20 12:43,11/Aug/20 13:01,22/Feb/21 13:26,22/May/20 14:15,,,3.1.0,,,,,,,,,,,"Fix Tosca grid in tosca fake dataset. 
Adjust contract resolution on IC with VDA 
- TSDA17-TSVDA2
- TSDA10-TSVDA1

A resolution must be the same as on VDA-PDA IC

",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23846400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aucu:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/May/20 14:15;od044;Contract resolutions are aligned. Verified on R2.0.40-SNAPSHOT",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PostgreSQL Baseline Implementation,XP-3036,95743,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,iO924,iO924,15/May/20 09:28,20/Nov/20 17:00,22/Feb/21 13:26,04/Nov/20 10:10,,,Not a release,,Other,,,,,,,,,"h1. {color:#00875a}PostgreSQL Security{color}
h2. Current Situation 

There is a new security baseline for PostgreSQL and we need to check if we are compliant. 
h2. Proposed Solution 

Please check if we have set our databases according to the Baseline below. 
 * [https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20baselines/PostgreSQL_Security_Baseline.pdf]

_Keep in mind that we have Cybertec as a support company that can as well take care of that and identify our gaps._ 

Please check or contact Cybertec and assess if we fulfill requirements listed in PostgreSQL Security Baseline. If no, please create follow up tickets. 
h2. Acceptance Criteria 
 * Assessment of security baseline in regards of our PostgreSQL servers
 * Follow up tickets in the backlog in case of actions needed on our side. ",,cb162,cs687,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,all questions answered ,,,,,,,,,,,,,,8035200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bxyk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Nov/20 10:06;cs687;Regarding the mentioned pdf-file we come to the following result on production DB-Hosts: 

*3.1 Operating System:*
 * OS01 (/)
 * OS02
 * OS03
 * OS04
 * OS05 (/)
 * OS06 (verified it is not used!) (/)
 * OS07
 * OS08
 * OS09
 * OS10 (/)
 * OS11 (/)
 * OS12 (/)
 * OS13 (/)

 

*3.2 PostgreSQL settings:*
 * PS01 (The default is {{none}}. Only superusers can change this setting.) (/)

 

*3.3 PostgreSQL Versions/Patches*
 * VP01 (/) (version PostgreSQL 12) 

 

*3.4 PostgreSQL Privileges*
 * PP01 (/)
 * PP02 (/) (all of them are written directly in PL/SQL language) 
 * PPO3 (/) (have no security definer functions) 

 

*4 Other PostgreSQL settings*
 * OP01 (/)","04/Nov/20 10:07;cs687;Regarding the open topics its related to SYSENG-Team. 
there is already ticket existing for m7 
https://jira.deutsche-boerse.com/browse/SYSENGINT-70

Our part is done, i will just link the SYSENGINT ticket as well!","04/Nov/20 10:10;cs687;done","20/Nov/20 17:00;cb162;update

Thanks [~cs687]

I checked the machines below

m7prodpdb1
m7prodpdb2
m7prodpdb3
m7prodpdb4
m7simupdb1
m7simupdb2
m7simupdb3
m7simupdb4
xbprodpdb1
xbprodpdb2
xbprodpdb3
xbprodpdb4
xbsimupdb1
xbsimupdb2
xbsimupdb3
xbsimupdb4

 

I attached my detailed review + how-to/remediation actions:

3.1

OS01 (x) need upgrade for xbprodpdb1,2,3,4 + m7simupdb1,2,3,4

OS02 (i) to be checked against RHEL Baselines (off topic here)

OS03 (i) I don t have access inside DB because of Vault secret permission denied 

OS05 + OS06 (/)

OS07 +OS08 (off) NOT APPLICABLE

OS09+OS10+OS11+OS12 (/)

OS13 (i) I would say not applicable but maybe double check

3.2

PS01 + PS03 (i) don t have access inside DB, to be checked by Operations Team (see how-to+remediation)

3,3

VP01(x) need upgrade for xbprodpdb1,2,3,4 + m7simupdb1,2,3,4

3.4

PP01 + PP02 (i) don t have access inside DB, to be checked by Operations Team (see how-to+remediation)

 

Let me know how I can help further.

Thanks

Cristian

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace expiring root CA,XP-3030,95679,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,yo218,yo218,ei349,13/May/20 15:22,13/Aug/20 19:41,22/Feb/21 13:26,22/May/20 10:36,,,3.1.0,,,,,,,,,,,"The AddTrust External Root CA is about to expire in May 2020 (30th). We need to find out where it is still used like server certificates for webservers, haproxies, LDAP, (consul?).

It need to be replaced for all environments",,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24537600,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 10:50;yo218;Replacement happened for all XBID non prod environments already",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rollout of auditd configuration on linux devices - Production,XP-3029,95661,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,iO924,iO924,13/May/20 13:10,31/Aug/20 15:39,22/Feb/21 13:26,24/Jun/20 15:52,,,3.1.0,,,,,,,SECURITY,,,,"We will have to roll out the [auditd Configuration|https://github.deutsche-boerse.de/dev/sec.auditd-recommendation] on the following servers in production:

 
|XBDPLDAP1|
|XBIDPRODCOR1|
|XBIDPRODCOR2|
|XBIDPRODPG1|
|XBIDPRODPG2|
|XBPRODBHA1|
|XBPRODBHA2|
|XBPRODBHA3|
|XBPRODBHA4|
|XBPRODCBN1|
|XBPRODCBN2|
|XBPRODCHA1|
|XBPRODCHA2|
|XBPRODCMI1|
|XBPRODCMI2|
|XBPRODCMM1|
|XBPRODCMM2|
|XBPRODCOM1|
|XBPRODCOM2|
|XBPRODCOM3|
|XBPRODCOM4|
|XBPRODCOM5|
|XBPRODCOM6|
|XBPRODCONS1|
|XBPRODCONS2|
|XBPRODCONS3|
|XBPRODCONS4|
|XBPRODCONS5|
|XBPRODCONS6|
|XBPRODCTP1|
|XBPRODCTP2|
|XBPRODDBR1|
|XBPRODDBR2|
|XBPRODECP1|
|XBPRODECP2|
|XBPRODEDB1|
|XBPRODEHA1|
|XBPRODEHA2|
|XBPRODGLFS1|
|XBPRODGLFS2|
|XBPRODIDM1|
|XBPRODIDM2|
|XBPRODIMQ1|
|XBPRODIMQ2|
|XBPRODIMQ3|
|XBPRODIMQ4|
|XBPRODIMQ5|
|XBPRODIMQ6|
|XBPRODLDP1|
|XBPRODLDP2|
|XBPRODMAIL1|
|XBPRODMAIL2|
|XBPRODPDB1|
|XBPRODPDB2|
|XBPRODPDB3|
|XBPRODPDB4|
|XBPRODPMI1|
|XBPRODPMI2|
|XBPRODPMI3|
|XBPRODPMI4|
|XBPRODPRX1|
|XBPRODPRX2|
|XBPRODREP1|
|XBPRODREP2|
|XBPRODSLA1|
|XBPRODSLA2|
|XBPRODSMC1|
|XBPRODSMC2|
|XBPRODSMI1|
|XBPRODSMI2|
|XBPRODSOB1|
|XBPRODSOB2|
|XBPRODSSC1|
|XBPRODSSC2|
|XBPRODSSC3|
|XBPRODSSC4|
|XBPRODSSC5|
|XBPRODSSC6|
|XBPRODSSL1|
|XBPRODSSL2|
|XBPRODSSL3|
|XBPRODSSL4|
|XBPRODSSL5|
|XBPRODSSL6|
|XBPRODWBC1|
|XBPRODWBC2|
|XBPRODWBC3|
|XBPRODWBC4|
|XBPRODWBC5|
|XBPRODWBC6|
|XBPRODWEB1|
|XBPRODWEB2|
|XBPRODWEB3|
|XBPRODWEB4|
|XBPRODWEB5|
|XBPRODWEB6|
|XBPRODXMQ1|
|XBPRODXMQ2|
|XBPRODXMQ3|
|XBPRODXMQ4|
|XBPRODXMQ5|
|XBPRODXMQ6|

 

[https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0823%2F400%5FPublication%2FSecurity%20Policy%20Framework%2F70%5FConcepts&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6&View=%7BC85F9C0B%2D376E%2D4AE7%2D89B7%2DABE540693D5D%7D]

 

Please try to carry this task out during the time window of 28.05.2020-10.06.2020 if possible

 

Best Regards

Michael",,iO924,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 09:05;iO924;sec.auditd-recommendation-master.zip;https://jira.deutsche-boerse.com/secure/attachment/83837/sec.auditd-recommendation-master.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20908800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:u",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/20 15:52;yo218;auditd has been onboarded on Prod",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rollout of auditd configuration on linux devices - Simulation,XP-3028,95660,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,iO924,iO924,13/May/20 13:08,11/Aug/20 16:35,22/Feb/21 13:26,27/May/20 09:16,,,3.1.0,,,,,,,SECURITY,,,,"We will have to roll out the [auditd Configuration|https://github.deutsche-boerse.de/dev/sec.auditd-recommendation] on the following servers in simulation:
|name|
|XBDSLDAP1|
|XBDSLDAP2|
|XBIDSIMUCOR1|
|XBIDSIMUCOR2|
|XBSIMUAMS1|
|XBSIMUAMS2|
|XBSIMUBHA1|
|XBSIMUBHA2|
|XBSIMUBHA3|
|XBSIMUBHA4|
|XBSIMUCBN1|
|XBSIMUCBN2|
|XBSIMUCHA1|
|XBSIMUCHA2|
|XBSIMUCMI1|
|XBSIMUCMI2|
|XBSIMUCMM1|
|XBSIMUCMM2|
|XBSIMUCOM1|
|XBSIMUCOM2|
|XBSIMUCOM3|
|XBSIMUCOM4|
|XBSIMUCOM5|
|XBSIMUCOM6|
|XBSIMUCONS1|
|XBSIMUCONS2|
|XBSIMUCONS3|
|XBSIMUCONS4|
|XBSIMUCONS5|
|XBSIMUCONS6|
|XBSIMUCTP1|
|XBSIMUCTP2|
|XBSIMUDBR1|
|XBSIMUDBR2|
|XBSIMUECP1|
|XBSIMUECP2|
|XBSIMUEDB1|
|XBSIMUEHA1|
|XBSIMUEHA2|
|XBSIMUGLFS1|
|XBSIMUGLFS2|
|XBSIMUIDM1|
|XBSIMUIDM2|
|XBSIMUIMQ1|
|XBSIMUIMQ2|
|XBSIMUIMQ3|
|XBSIMUIMQ4|
|XBSIMUIMQ5|
|XBSIMUIMQ6|
|XBSIMULDP1|
|XBSIMULDP2|
|XBSIMUPDB1|
|XBSIMUPDB2|
|XBSIMUPDB3|
|XBSIMUPDB4|
|XBSIMUPMI1|
|XBSIMUPMI2|
|XBSIMUPMI3|
|XBSIMUPMI4|
|XBSIMUPRX1|
|XBSIMUPRX2|
|XBSIMUREP1|
|XBSIMUREP2|
|XBSIMURTS1|
|XBSIMURTS2|
|XBSIMUSLA1|
|XBSIMUSLA2|
|XBSIMUSMC1|
|XBSIMUSMC2|
|XBSIMUSMI1|
|XBSIMUSMI2|
|XBSIMUSOB1|
|XBSIMUSOB2|
|XBSIMUSSC1|
|XBSIMUSSC2|
|XBSIMUSSC3|
|XBSIMUSSC4|
|XBSIMUSSC5|
|XBSIMUSSC6|
|XBSIMUSSL1|
|XBSIMUSSL2|
|XBSIMUSSL3|
|XBSIMUSSL4|
|XBSIMUSSL5|
|XBSIMUSSL6|
|XBSIMUWBC1|
|XBSIMUWBC2|
|XBSIMUWBC3|
|XBSIMUWBC4|
|XBSIMUWBC5|
|XBSIMUWBC6|
|XBSIMUWEB1|
|XBSIMUWEB2|
|XBSIMUWEB3|
|XBSIMUWEB4|
|XBSIMUWEB5|
|XBSIMUWEB6|
|XBSIMUXMQ1|
|XBSIMUXMQ2|
|XBSIMUXMQ3|
|XBSIMUXMQ4|
|XBSIMUXMQ5|
|XBSIMUXMQ6|

[https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0823%2F400%5FPublication%2FSecurity%20Policy%20Framework%2F70%5FConcepts&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6&View=%7BC85F9C0B%2D376E%2D4AE7%2D89B7%2DABE540693D5D%7D]

 

 

Please try to carry this task out during the time window of 21.05.2020-03.06.2020 if possible

 

Best Regards

Michael",,iO924,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 09:04;iO924;sec.auditd-recommendation-master.zip;https://jira.deutsche-boerse.com/secure/attachment/83836/sec.auditd-recommendation-master.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23414400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 16:06;yo218;performed the changes manually on xbsimurts2 to check whether I understood probably what needs to be done. Will check the next report for a result","15/May/20 14:02;yo218;created a playbook and executed it for xbsimurts1. Will check the new report on Monday for teh result","25/May/20 16:24;yo218;First 30 hosts are onboarded - confirmed by Thorsten Gässner. Will proceed with all hosts this week","27/May/20 09:11;yo218;All hosts have applied the new config and Thorsten Gässner confirmed that they are onboarded. I will doublecheck next weeks report, but close this ticket already","27/May/20 09:16;yo218;The following command can be used in order to deploy the config, using the energy.automation.os.install repo:
{noformat}
 ansible-playbook playbooks/os_agents.yml --tags audit --limit xb-xbid-simu* -b -k -K {noformat}
For some hosts the installation of the libraries failed with the following error:

{noformat}
Error:  Multilib version problems found
(...)
Protected multilib versions: audit-libs-2.8.4-4.el7.x86_64 != audit-libs-2.8.1-3.el7_5.1.i686
{noformat}

In order to fix this, I had to perform a ""yum upgrade auditd-libs"" Example:
{noformat}
ansible all --limit xb-xbid-simu-web* -m shell -a ""yum upgrade -y audit-libs"" -b -k -K
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split) Tomcat logging - timestamps should include timezone,XP-3025,95650,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eg288,eh941,13/May/20 12:47,04/Aug/20 19:53,22/Feb/21 13:26,14/May/20 11:44,,,3.1.0,,,,,,,,,,,"the timestamps in catalina.out must include also timezone information to enable proper parsing of the log file by monitoring stack

Doc for Tomcat SimpleFormatter""
https://docs.oracle.com/javase/8/docs/api/java/util/logging/SimpleFormatter.html

Doc for String.format() used by Tomcat SimpleFormatter:
https://dzone.com/articles/java-string-format-examples
https://docs.oracle.com/javase/8/docs/api/java/util/Formatter.html

Tomcat logging in general:
http://tomcat.apache.org/tomcat-8.5-doc/logging.html
https://docs.oracle.com/javase/10/core/java-logging-overview.htm#JSCOR-GUID-B83B652C-17EA-48D9-93D2-563AE1FF8EDA
",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24537600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ar3j:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-3025-catalina-out-format-master,xbid-dev-env,XP-2942,traversal-XP-2485,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/May/20 11:44;eh941;Created MR for all CuTes, LIPs, Simu and Prod - https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/655","14/May/20 11:45;eh941;Successfully tested on Syt1. Logline looks like following:

{noformat}
2020-06-02T17:48:50.881+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application archive [/xbid/xbid-syt1-sob1/tomcat/webapps/intraday.war] has finished in [17,863] ms 
2020-06-02T17:48:50.882+0000 INFO org.apache.catalina.startup.HostConfig - Deploying web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/docs] 
2020-06-02T17:48:50.901+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/docs] has finished in [19] ms 
2020-06-02T17:48:50.901+0000 INFO org.apache.catalina.startup.HostConfig - Deploying web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/examples] 
2020-06-02T17:48:50.988+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/examples] has finished in [87] ms 
2020-06-02T17:48:50.989+0000 INFO org.apache.catalina.startup.HostConfig - Deploying web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/ROOT] 
2020-06-02T17:48:50.995+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/ROOT] has finished in [6] ms 
2020-06-02T17:48:50.996+0000 INFO org.apache.catalina.startup.HostConfig - Deploying web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/host-manager] 
2020-06-02T17:48:51.012+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/host-manager] has finished in [16] ms 
2020-06-02T17:48:51.013+0000 INFO org.apache.catalina.startup.HostConfig - Deploying web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/manager] 
2020-06-02T17:48:51.020+0000 INFO org.apache.catalina.startup.HostConfig - Deployment of web application directory [/xbid/xbid-syt1-sob1/tomcat/webapps/manager] has finished in [8] ms 

{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Release 3.0 Managerial Documents,XP-3007,95558,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qm925,qm925,qm925,12/May/20 11:22,31/Aug/20 15:39,22/Feb/21 13:26,05/Aug/20 12:27,,,3.1.0,,,,,,,,,,,"Following documents need to be delivered:
 - *{color:#172b4d}Release Plan{color}*
 - *{color:#172b4d}Acceptance Criteria Plan{color}*
 - *{color:#172b4d}Test Strategy{color}*

Delivery date of the first draft - end May - beginning of June

[SharePoint|https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/02%20XBID%20Releases/XBID%203.0/Managerial%20Documents]",,qm925,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3064,M7ACM-1163,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17366400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0atmn:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),HOT Sprint 15,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/20 15:08;tm431;Managerial documents are ready for internal review round, ACM needs to have them ready for this internal review by 29/5/2020.

This is the timeline agreed by customers.
 * 5/6 – DBAG – provision of initial version of the documents (assumption)
 * 8-19/6 – QARM/XTG – Review/commenting of the document by group members
 * 22-24/6 - QARM/XTG – internal alignment calls in XTG/QARM on the comments
 * 24/6 – NEMOs/TSOs - hand over of the comment to DBAG
 * 25/6 – joint CC with DBAG to explain principal comments
 * 26/6-3/7 – DBAG - incorporation of the comments
 * 3/7 – DBAG – handover of the documents to NEMOs/TSOs
 * 6-7/7 – QARM/XTG – individual review of DBAG’s responses
 * 8/7 - QARM/XTG – alignment
 * 9/7 – joint CC – 1st round of documents finalization
 * 14/7 – joint CC – 2nd round of documents finalization
 * 16/7 – joint CC – 3rd round of documents finalization (if needed)
 * 5/8 – Deployment into UAT environmet

In following link there are R3.1 issues which customer have identified and wants them to have in the release. Customer deadline for the final list is I think by the EOB 29/5/2020

[https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2fsites%2fps0080%2fShared%20Documents%2f02%20XBID%20Releases%2fXBID%203%2e0%2fBugs%20for%20R3%2e0&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44]

in XBID-3064 we will track the effort needed for these bugfixes, and their risk on the whole system","05/Aug/20 12:27;tm431;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reports overview,XP-3005,95550,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,ei349,ei349,12/May/20 09:19,13/Aug/20 19:41,22/Feb/21 13:26,27/May/20 13:04,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Reports overview {color}
h2. Current situation

We have lots of reports with different retention policies. 
h2. Proposed solution

Prepare overview about our customer reports with details like retention policy (how long until it expires), where it's stored, how it can be reached and if customers can do it on their own or it's DBAG obligation to distribute it. 
h2. Acceptance criteria
 * list of customer reports
 * each report row contains information about retention/time validity policy
 * each report row contains information where it's stored 
 * each report row contains information how it can be downloaded or reached (GUI?, BizOps responsibility? FTP?, E-mail?, ...) 

h2. Additional information

RCB information we provided in the past: 

*Data storage accessibility*As agreed in last JSC (27/9)
Data storage and accessibility - How long are data available?
•DBAG: can be different per module / feature*General:*
•*Historical DB tables – data is kept for 40 days*
•*Archive historic data is archived for 10 years but can be made available only on an audited request and is not deliverable immediately*
•*SM files: 48 hours GUI and applicable channels, SM reports 3 days*
•*CMM: outbound files 120 min, inbound today + yesterday*
•*Reporting Engine: days, removal point not specified*",,eg288,ei349,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/20 13:45;zi174;Reports_overview.xlsx;https://jira.deutsche-boerse.com/secure/attachment/84224/Reports_overview.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23846400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0atmi:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/May/20 10:48;tm431;Trading reports, generated in SOB Webgui (modul which gnereates them is calle REP Reporting engine), are stored in the GUI for download for 6days? 7 ? [~eg288] . Upon support request we can generate them from DB dumps. Specification which describes these reports is DFS240
 * TC540 Daily Order Maintenance
 * TC810 Daily Trade Confirmation
 * TC830 Power Flow Report

h2.  ","21/May/20 15:26;eg288;Reporting engine stores 5 last generated reports. The reports are sorted by the date when they were generated and the 5 latest is kept. It does not matter for what date the reports were generated. 

Example:
I have following reports
Tc540_2020.02.10 generated on 10.2.
Tc540_2020.02.09 generated on 09.2.
Tc540_2020.02.08 generated on 08.2.

now I will manually generat reports
Tc540_2020.02.04 generated on 10.2.
Tc540_2020.02.05 generated on 10.2.
Tc540_2020.02.06 generated on 10.2.

the the report is removed Tc540_2020.02.08 because it is oldest (generated on 08.2.),

next day the report Tc540_2020.02.11 is generated and the Tc540_2020.02.09 is removed ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare infrastructure for AMS for all customer testing ENVS,XP-3004,95545,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,tm431,tm431,12/May/20 07:54,13/Aug/20 19:41,22/Feb/21 13:26,04/Jun/20 11:23,,,3.1.0,,,,,,,,,,,"h1. GIANT ANTEATER preparation for ALL customer testing ENVS

It is foreseen to deploy AMS into ALL testing environments in late May (beginning of JUNE).

We need to get infrastructure ready for this. VMs, DBs, Firewalls requests etc. Alarm notificatio layer. Very simillar what was done in SIMU in SERVICE-6077
 I belive we will have shared architecture for all envs.
 * LIPA, LIPB, CUTEPX, CTSO
 * *all* individula cutees *CTPA-CTPM*

 

*goal of this task is to have all infrastructure ready, the deployment will be done later only on selected envs, via ansible.*

 inform also [~rehapav] about this initiative

 

 ",,iv732,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ar3e:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/20 12:24;iv732;VM Request was sent. So far no approval!","27/May/20 11:01;iv732;[~tm431]

For SIMU and PROD we have requested the VM with the following hardware resources:

CPU    2

RAM   5 GB 

Disk     40 GB  

For these shared VMs, how much resources do you think we will need? ","27/May/20 14:49;iv732;FW to send email via SMTP server","28/May/20 17:14;iv732;https://jira.deutsche-boerse.com/browse/SYSENG-58","04/Jun/20 11:23;iv732;VMs are done.

Port 25 to englobmon1/2 are open.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sentinel One Onboarding,XP-2983,95434,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,ei349,ei349,07/May/20 08:28,04/Aug/20 19:53,22/Feb/21 13:26,04/Aug/20 10:08,,,3.1.0,,,,,,,,,,,"Dear Colleagues,

We will need to install the security tool Sentinel one on each Jump Host, Internet facing server and end point. 

In case of any questions regarding sentinel one, please contact Alexander Hasenbiller!

Documentation can be found here:

[https://mysites.deutsche-boerse.de/personal/np476/Documents/Cyber%20Security%20Defense/Endpoint%20Detection%20and%20Response/SentinelOne/Software/Agents]

[https://vmcolorado:8443/index.php/SentinelOne#Onboarding_Sentinel_One_Red_Hat_Agent_on_TEST_infrastructure]

[https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20Tool%20onboarding%20process/SentinelOne%20Onboarding%20Process.pdf]

 

Internet facing server on energy side: 
|XBSIMUWEB6|
|XBSIMUWEB5|
|XBSIMUWEB4|
|XBSIMUWEB3|
|XBSIMUWEB2|
|XBSIMUWEB1|
|XBSIMUSSL6|
|XBSIMUSSL5|
|XBSIMUSSL4|
|XBSIMUSSL3|
|XBSIMUSSL2|
|XBSIMUSSL1|
|XBSIMUCOM4|
|XBSIMUCOM6|
|XBSIMUCOM5|
|XBSIMUCOM3|
|XBSIMUCOM2|
|XBSIMUCOM1|
|XBPRODCOM6|
|XBPRODCOM5|
|XBPRODCOM3|
|XBPRODCOM1|
|XBPRODCOM4|
|XBPRODCOM2|
|XBPRODWEB5|
|XBPRODWEB4|
|XBPRODWEB3|
|XBPRODWEB6|
|XBPRODSSL1|
|XBPRODWEB2|
|XBPRODWEB1|
|XBPRODSSL6|
|XBPRODSSL5|
|XBPRODSSL4|
|XBPRODSSL3|
|XBPRODSSL2|
|XBPRODPRX2|
|XBPRODPRX1|
|XBSIMUPRX2|
|XBSIMUPRX1|
|XBSIMUCHA1|
|XBPRODCHA2|
|XBPRODCHA1|
|XBSIMUCHA2|",,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17452800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay6n:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/May/20 14:42;yo218;[https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20Tool%20onboarding%20process/SentinelOne%20Onboarding%20Process.pdf#search=sentinel]","27/May/20 16:51;yo218;{noformat}
[yo218@enprodauto1 {SentinelOne L | ?1} ~/git/energy.automation.os.install]$ time ansible-playbook playbooks/os_agents.yml --limit @sentinel_simu.txt --tags sentinelone -k -K -b
{noformat}","05/Jun/20 11:18;yo218;Onboarding of Simu happened. I will check the report on Monday and monitor the behavior of Simu before we can proceed with Prod. After installation of the agent, an initial scan has been triggered which caused very high CPU usage for round about 20 minutes. In theory it shouldn't harm as long as we install the agent on the 6 web- and ssl servers one by one instead of all at once. However, as we have a Prod deployment scheduled for the 17th of June, we might want to consider performing the installation during this maintenance window. What is your position [~ei349]?","08/Jun/20 09:21;yo218;The report confirmed that only Production host are missing. Still waiting for the confirmation of [~ei349]whether I should proceed or wait for the Prod maintenance window","16/Jun/20 12:36;yo218;Some high CPU usage alerts popped up during the weekend on the hosts where s1 is installed. I would like to monitor the behavior for another week before I will deploy to all Prod hosts","18/Jun/20 15:06;yo218;Onboarding has been stopped as GIS figured out some issues. And I am still investigating together with Alexander Hazenbiller why we high CPU load every few days on the already installed hosts","23/Jun/20 12:59;yo218;the high CPU load seems to be related to obsolete patrol agents. Removed it on xbprodweb6 and continued monitoring the behavior ","30/Jul/20 07:43;yo218;We added a second CPU to all web and ssl server. No performance issues occured since then. We have the latest client running on Simu, will check the status of the onboarding project to see whether we can proceed with prod now","31/Jul/20 10:27;yo218;Installed the agent on all Prod hosts. Will check the report on Monday and hopefully close the ticket then","04/Aug/20 10:08;yo218;Alexander Hazenbiller confirmed that all host are on onboarded and online",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reconfigure DB-Backups,XP-2981,95412,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,yo218,yo218,06/May/20 11:26,13/Aug/20 19:41,22/Feb/21 13:26,23/Jun/20 12:57,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}Stable DB backups {color}

Currently netbackup is scheduling our database backups. This doesn't work out well since we have three slave nodes with patroni which can't be backed up. Therefor we have several failed backups each day which makes it hard to monitor a real issue with the backup. We need to create a jenkins job that will trigger the backups (full and incr) on the leader node",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21081600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s3c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/20 10:39;yo218;New jenkins jobs are available: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/","02/Jun/20 10:40;yo218;currently all internal environments are handled by the new method. Changes for Cutes have been requested already","04/Jun/20 07:13;yo218;CuTes have been added on Tuesday. I will procedd monitoring the behavior and will request Simu on Monday next week. Production will follow another week later","08/Jun/20 17:14;yo218;Added all Simu environments today. There is just one outstanding topic for M7 shrd simu but the rest seems to be working fine ","09/Jun/20 10:00;yo218;Shared Simu topic is solve. All ,backups worked fine yesterday. I will monitor it for a week and change it for Prod on Monday","18/Jun/20 15:06;yo218;Prod has been added. Now jsut ECP databases are outstanding","23/Jun/20 12:57;yo218;all working fine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade DB to latest postgres 12.2 on one SystemTest,XP-2979,95386,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,06/May/20 10:08,27/Aug/20 10:22,22/Feb/21 13:26,25/Aug/20 07:49,,,3.1.1,,,,,,,TechOps,,,,"We are currently running PostgreSQL v9.5, the latest version is 12.2. We should upgrade the test clusters and test the XBID solution on the new version, then proceed in the regular staging manner 

 TO - 2 SPs, Dev - 3

start with 1 test environment, check if everything works

create new ticket(s) for
 - remaining test envs.
 - findings (like JDBC driver)
 - upgrade of test containers 
 - removing tech debt from the code because new features might be availabel (compare old and new versions of PGSQL)

update docker images 

update SERVICE-3669

 

INFORM BOs and ACM to inform customers about such upgrade.",,od044,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3453,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15638400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3436,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xro:000c02",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2979-postgresql,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Aug/20 18:01;yo218;Installed the cluster successfully on syt1. Things which have to be taken care of:
 * user pg_watch2 has to be renamed to pgwatch2 --> monitoring has to be adjusted
 * patroni 1.6 need to be installed (XBID-patroni package already available)
 * pg_hba.conf need to be copied
 * flyway 6.x has to be used
 ** update inventory (done)
 ** rename schema_version table flyway_schema_history one ach db","20/Aug/20 18:27;yo218;{noformat}
[root@xbtestpdb1 xbsyt1async]# systemctl stop patroni_xbsyt1sync.service
[root@xbtestpdb1 xbsyt1async]# chmod +w /var/lib/pgsql_syt1_25206/data/9.5/xbsyt1sync
[root@xbtestpdb1 xbsyt1async]# find / -name pg_ctl | grep 12
/usr/pgsql-12/bin/pg_ctl
[root@xbtestpdb1 xbsyt1async]# su - postgres
-bash-4.2$ mkdir -p /var/lib/pgsql_syt1_25206/data/12/xbsyt1sync/
-bash-4.2$ /usr/pgsql-12/bin/pg_ctl -D /var/lib/pgsql_syt1_25206/data/12/xbsyt1sync/ initdb -o '--data-checksums'
-bash-4.2$ /usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_syt1_25206/data/9.5/xbsyt1sync/ start
-bash-4.2$ psql -p 25206 -c ""ALTER USER pg_watch2 RENAME TO pgwatch2;
-bash-4.2$ /usr/pgsql-9.5/bin/pg_ctl -D /var/lib/pgsql_syt1_25206/data/9.5/xbsyt1sync/ stop
-bash-4.2$ /usr/pgsql-12/bin/pg_upgrade    -b /usr/pgsql-9.5/bin    -B /usr/pgsql-12/bin    -d /var/lib/pgsql_syt1_25206/data/9.5/xbsyt1sync    -D /var/lib/pgsql_syt1_25206/data/12/xbsyt1sync    -o ' -c config_file=/var/lib/pgsql_syt1_25206/data/9.5/xbsyt1sync/postgresql.conf'    -O ' -c config_file=/var/lib/pgsql_syt1_25206/data/12/xbsyt1sync/postgresql.conf'
-bash-4.2$ exit
logout
[root@xbtestpdb1 xbsyt1async]# sed -i 's/9.5/12/g'  /usr/lib/systemd/system/patroni_xbsyt1async.service
[root@xbtestpdb1 xbsyt1async]#  sed -i 's/9.5/12/g' /etc/patroni_xbsyt1sync/config.yml
[root@xbtestpdb1 xbsyt1async]# patronictl -c /etc/patroni_xbsyt1sync/config.yml remove xbsyt1sync
+---------+--------+------+------+-------+----+-----------+
| Cluster | Member | Host | Role | State | TL | Lag in MB |
+---------+--------+------+------+-------+----+-----------+
+---------+--------+------+------+-------+----+-----------+
Please confirm the cluster name to remove: xbsyt1sync
You are about to remove all information in DCS for xbsyt1sync, please type: ""Yes I am aware"": Yes I am aware
[root@xbtestpdb1 xbsyt1async]# systemctl start patroni_xbsyt1sync.service
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml list
+------------+------------+---------------------+--------+---------+----+-----------+
|  Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------+------------+---------------------+--------+---------+----+-----------+
| xbsyt1sync | xbtestpdb1 | 10.139.40.225:25206 | Leader | running |  2 |         0 |
+------------+------------+---------------------+--------+---------+----+-----------+





{noformat}","21/Aug/20 11:07;yo218;both clusters in syt1 are up and running with pg v 12.4:
{noformat}
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1async/config.yml list
+-------------+------------+---------------------+--------+---------+----+-----------+
|   Cluster   |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-------------+------------+---------------------+--------+---------+----+-----------+
| xbsyt1async | xbtestpdb1 | 10.139.40.225:25106 | Leader | running |  2 |         0 |
| xbsyt1async | xbtestpdb2 | 10.139.40.224:25106 |        | running |  2 |         0 |
+-------------+------------+---------------------+--------+---------+----+-----------+
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml list
+------------+------------+---------------------+--------------+---------+----+-----------+
|  Cluster   |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+------------+------------+---------------------+--------------+---------+----+-----------+
| xbsyt1sync | xbtestpdb1 | 10.139.40.225:25206 |    Leader    | running |  2 |         0 |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224:25206 | Sync standby | running |  2 |           |
+------------+------------+---------------------+--------------+---------+----+-----------+

[root@xbtestpdb1 ~]# su - postgres
Last login: Fri Aug 21 11:02:40 CEST 2020
-bash-4.2$ psql -p 25106 -c ""select version();""
                                                 version
---------------------------------------------------------------------------------------------------------
 PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39), 64-bit
(1 row)-bash-4.2$ psql -p 25206 -c ""select version();""
                                                 version
---------------------------------------------------------------------------------------------------------
 PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39), 64-bit
(1 row) {noformat}
 ","21/Aug/20 11:07;yo218;Please verify whether the application is running fine on syt1 with the new database","24/Aug/20 13:57;od044;Smoke test passed 
- application is running 
- deployment finish successfully with flyway 6.0.4 version 
- basic features work properly like creation, modification, deletion, publish, allocation, upload, download, file generation ","25/Aug/20 07:49;yo218;Created follow up tickets",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Saving of ACER reports called twice,XP-2974,95341,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,qo794,qo794,05/May/20 10:29,04/Aug/20 19:53,22/Feb/21 13:26,21/May/20 15:30,,,3.1.0,,SLA Report Tool,,,,,,,,,"h1. {color:#00875a}Store Acer reports only once{color}

The step saving already generated report is called twice ({{com.deutscheboerse.energy.xbid.reporttool.common.ItemCollectingWriter#close}} is executed twice), see the log from production:
{code:java|title=xb_xbid_prod_rpt-1_standard_ixe_0_2020-05-01.log}
2020-05-01T05:30:02.955Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_BID_ASK_SPREAD_2020-05-01-053000.xml
2020-05-01T05:30:03.350Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_BID_ASK_SPREAD_2020-05-01-053000.xml
2020-05-01T07:00:01.222Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_INTRADAY_TRADE_VOLUME_2020-05-01-070000.xml
2020-05-01T07:00:01.900Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_INTRADAY_TRADE_VOLUME_2020-05-01-070000.xml
2020-05-01T08:15:00.676Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-05-01-081500.xml
2020-05-01T08:15:00.982Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_TRADE_VOLUME_HOUR_TO_DELIVERY_2020-05-01-081500.xml
2020-05-01T08:30:00.528Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_WEIGHTED_AVERAGE_PRICE_2020-05-01-083000.xml
2020-05-01T08:30:00.832Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_WEIGHTED_AVERAGE_PRICE_2020-05-01-083000.xml
2020-05-01T08:45:00.350Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-05-01-084500.xml
2020-05-01T08:45:00.550Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.c.ItemsFileGenerator - Report saved to /xbid/reports/2020-04_WEIGHTED_AVERAGE_PRICE_LAST_TRADING_HOUR_2020-05-01-084500.xml
{code}
Easy to reproduce locally by triggering for instance generation of big-ask-spread report manually.",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,25315200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,05/May/20 10:29,,,,,,,,,,,,,,,,,,,,,,,"1|y0atmn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tomcat logging - timestamps should include timezone,XP-2951,95069,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eg288,eg288,28/Apr/20 17:10,04/Aug/20 19:53,22/Feb/21 13:26,13/May/20 12:48,,,3.1.0,,,,,,,,,,,"the timestamps in catalina.out must include also timezone information to enable proper parsing of the log file by monitoring stack

Doc for Tomcat SimpleFormatter""
https://docs.oracle.com/javase/8/docs/api/java/util/logging/SimpleFormatter.html

Doc for String.format() used by Tomcat SimpleFormatter:
https://dzone.com/articles/java-string-format-examples
https://docs.oracle.com/javase/8/docs/api/java/util/Formatter.html

Tomcat logging in general:
http://tomcat.apache.org/tomcat-8.5-doc/logging.html
https://docs.oracle.com/javase/10/core/java-logging-overview.htm#JSCOR-GUID-B83B652C-17EA-48D9-93D2-563AE1FF8EDA
",,eg288,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3025,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24624000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0atcs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 8,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/May/20 15:32;eh941;This one is really tricky.

By simply adding this to {{conf/logging.properties}} in tomcat:

{code}
# this line is actually changed not added
java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter 
java.util.logging.SimpleFormatter.format=%1$tFT%1$tT.%1$tL%1$tz %4$s %5$s %n
{code}

The result shows as following:

{noformat}
2020-05-12T15:26:39.205+0200 INFO Server version name:   Apache Tomcat/8.5.50 
2020-05-12T15:26:39.210+0200 INFO Server built:          Dec 7 2019 19:19:46 UTC 
2020-05-12T15:26:39.210+0200 INFO Server version number: 8.5.50.0 
2020-05-12T15:26:39.211+0200 INFO OS Name:               Linux 
2020-05-12T15:26:39.211+0200 INFO OS Version:            4.15.0-99-generic 
2020-05-12T15:26:39.212+0200 INFO Architecture:          amd64 
2020-05-12T15:26:39.212+0200 INFO Java Home:             /usr/lib/jvm/zulu-8-amd64/jre 
2020-05-12T15:26:39.213+0200 INFO JVM Version:           1.8.0_202-b05 
2020-05-12T15:26:39.214+0200 INFO JVM Vendor:            Azul Systems, Inc. 
2020-05-12T15:26:39.214+0200 INFO CATALINA_BASE:         /home/odehfra/apps/apache-tomcat-8.5.50 
2020-05-12T15:26:39.215+0200 INFO CATALINA_HOME:         /home/odehfra/apps/apache-tomcat-8.5.50 
2020-05-12T15:26:39.217+0200 INFO Command line argument: -Djava.util.logging.config.file=/home/odehfra/apps/apache-tomcat-8.5.50/conf/logging.properties 
2020-05-12T15:26:39.218+0200 INFO Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 
2020-05-12T15:26:39.220+0200 INFO Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 
2020-05-12T15:26:39.220+0200 INFO Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 
2020-05-12T15:26:39.221+0200 INFO Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 
2020-05-12T15:26:39.221+0200 INFO Command line argument: -Dignore.endorsed.dirs= 
2020-05-12T15:26:39.222+0200 INFO Command line argument: -Dcatalina.base=/home/odehfra/apps/apache-tomcat-8.5.50 
2020-05-12T15:26:39.222+0200 INFO Command line argument: -Dcatalina.home=/home/odehfra/apps/apache-tomcat-8.5.50 
2020-05-12T15:26:39.222+0200 INFO Command line argument: -Djava.io.tmpdir=/home/odehfra/apps/apache-tomcat-8.5.50/temp 
2020-05-12T15:26:39.223+0200 INFO The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib] 
2020-05-12T15:26:39.299+0200 INFO Initializing ProtocolHandler [""http-nio-8080""] 
2020-05-12T15:26:39.308+0200 INFO Using a shared selector for servlet write/read 
2020-05-12T15:26:39.321+0200 INFO Initializing ProtocolHandler [""ajp-nio-8009""] 
2020-05-12T15:26:39.323+0200 INFO Using a shared selector for servlet write/read 
2020-05-12T15:26:39.324+0200 INFO Initialization processed in 443 ms 
2020-05-12T15:26:39.350+0200 INFO Starting service [Catalina] 
2020-05-12T15:26:39.350+0200 INFO Starting Servlet Engine: Apache Tomcat/8.5.50 
{noformat}

But from my perspective it isn't even close to be sufficient for us. The date is still in local format (not sure if it's a problem) and there is no rolling strategy defined. I'll keep on investigating.","13/May/20 12:47;eh941;Issue split into:
|XP-3025|(Split) Tomcat logging - timestamps should include timezone|
","13/May/20 12:48;eh941;Split",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse SLA against report tool,XP-2935,94933,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,24/Apr/20 09:38,13/Aug/20 19:41,22/Feb/21 13:26,28/Apr/20 10:33,,,3.1.0,,,,,,,,,,,"h3. Background
We have encountered a strange behavior when a customer had run performance tests against SIMU env.
* ~210 000 orders were sent
* ~210 000 order events were shown in grafana
* ~35 000 order entries were reported by Report Tool

h3. Cause
* orders were sent in batches (OrdrEntry contains a list of orders, we usually put just a single order there, but customer had put several)
* report tool counts OrdrEntry requests

h3. Analyze
* are our SLAs bound to amount of orders or amount of requests carrying them?
* example: let's say we fullfill our SLA by processing up to 100 OrdrEntry requests per hour
** what if every single of those requests contains 100 orders?
* *Does are SLA-related contract consider this?*",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,25920000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ap2p:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Apr/20 10:02;lt112;ReportTool takes {{raw-sender}} log-line on request arrival and on response departure, the difference is saved as execution time, it is unrelated to the amount of orders contained inside this single request","28/Apr/20 10:33;lt112;- report sent to customers
- SLAs revisited, works as expected, probably can be abused and will be tackled as part of cross-product matching SLA negotiations",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change the way of transferring logs from application servers to EBSM server,XP-2933,94866,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,iv732,iv732,23/Apr/20 10:56,31/Aug/20 15:38,22/Feb/21 13:26,08/Jul/20 13:52,,,3.1.0,,,,,,,,,,,"Request from Techops team, regarding the issue that in the new envs we will not allow one technical user from one host (in this case is tomcat host) to connect to any other hosts in order to trigger the log transfer.
 
The host itself must be able to deal with the log transfer to ebsm.",,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19785600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0apjs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jun/20 09:47;iv732;Starting with m7 auction","24/Jun/20 13:42;iv732;Trying new solution: a scheduled Jenkins job will run an ansible playbook, which will connect to all the hosts and copy log to ebsm","06/Jul/20 13:19;iv732;* create user log_transfer on each application host
 * generate a key pair for log_transfer user. public key will be copied to ebsmbox .ssh folder on ebsm host. Stored in [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/xb/xbid/common/log_transfer]
 * use ansible to deploy transfer script to each app host with all the corresponding variables
 * use ansible to add a cron job for user log_transfer on each app host","08/Jul/20 13:52;iv732;Paused, waiting for final progress on the future of EBSM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
set up bake agents and automatic agent updates for CheckMK,XP-2932,94865,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,iv732,iv732,23/Apr/20 10:56,31/Aug/20 15:39,22/Feb/21 13:26,07/Jul/20 16:44,,,3.1.0,,,,,,,,,,,Prepare CheckMK fix for handover to other responsible. ,,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19785600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0apjk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/20 12:24;iv732;Created tested key and cert","09/Jun/20 09:46;iv732;Blocker: the solution requires port 443 open on the checkmk server. However, as we plan to change the general design of checkmk, this request will be likely rejected.

Still working together with Piotr and Ilgar to get the Hardware monitoring done.","07/Jul/20 16:44;iv732;Ilgar will continue with building up a new inventory only for Host. Basically the hardware monitoring is done. Ilgar will continue with the rest.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reporting engine - add jolokia agent to enable JVM stats in grafana,XP-2925,94783,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,22/Apr/20 09:20,04/Aug/20 19:53,22/Feb/21 13:26,13/May/20 12:06,,,3.1.0,,,,,,,,,,,"h1. Missing java statistics on RE

add jolokia agent to enable JVM stats in grafana, the same as approach as in other modules like core or cmm 
 i.e. missing GC stats.

 

AC:
 * added jolokia for RE
 * working statistics
 * tell BOs to inform customers about new RE to be deployed together with agile pilot on May",,eg288,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-3254,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24624000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ak70:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 8 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,xbid-dev-env,traversal-XP-2485,XP-2942,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/May/20 16:41;eg288;implemented in re-5.0.53","08/May/20 12:05;jy268;Please find my comments in github review.","12/May/20 08:30;jy268;Review approved and merged.","12/May/20 14:59;eg288;Tested in syt1 env. The endpoint is providing data
{code}
>curl http://localhost:62705/reporting-engine-app/jolokia
{""request"":{""type"":""version""},""value"":{""agent"":""1.6.2"",""protocol"":""7.2"",""config"": ...
{code}

but it is not visible in grafan yet. Created TECHLOG-3254 to implement the changes also in monitoring.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - enhance inventory plugin,XP-2908,94641,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,lt112,lt112,17/Apr/20 13:47,04/Aug/20 19:53,22/Feb/21 13:26,22/Apr/20 10:36,,,3.1.0,,,,,,,,,,,"Enable inventory to:
- merge objects (not replace)
- allow internal references (inside object)",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,26438400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aock:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/20 13:54;lt112;h1. Implementation notes and examples

h2. Merge
When encountering already existing key, attempt to recursively merge content

h3. Example
{{xb/vars.yml}}
{code}
db:
  core:
    port: 1234
    host: ""localhost""
  cmm:
    port: 4321
    host: ""127.0.0.1""
{code}
{{xb/xbid/syt1/vars.yml}}
{code}
db:
  core:
    host: ""xbsyt1coredb""
  cmm:
    host: ""xbsyt1cmmdb""
{code}

resulting in:

{code}
db:
  core:
    port: 1234
    host: ""xbsyt1coredb""
  cmm:
    port: 4321
    host: ""xbsyt1cmmdb""
{code}

h2. Internal references
- generate unique prefix
- move all values from trees to {{_prefix_key0_key1_..._keyN}}, replace values with references to newly created keys

h3. Example
{code}
some_var: ""hello""

db:
  core:
    port: 1234
    host: ""localhost""
  cmm:
    port: 4321
    host: ""127.0.0.1""
{code}

is (inside the plugin script) parsed (dynamically) into:

{code}

some_var: ""hello""

_prefix_db_core_port: 1234
_prefix_db_core_host: ""localhost""
_prefix_db_cmm_port: 4321
_prefix_db_cmm_host: ""127.0.0.1""

db:
  core:
    port: ""{{ _prefix_db_core_port }}""
    host: ""{{ _prefix_db_core_host }}""
  cmm:
    port: ""{{ _prefix_db_cmm_port }}""
    host: ""{{ _prefix_db_cmm_host }}""
{code}","22/Apr/20 10:36;lt112;Done in https://github.deutsche-boerse.de/lt112/energy.automation.dyninv/tree/XP-2908-dinv-objects-enhancement
Changes forbidden by TO, reopen after splitting XBID Ansible
Issues to solve:
- does not parse {{<role>/default/main.yml}} -> can use {{<product>/<role>.yml}}, but this will not be processed for included roles without hosts

Possible solution:
- add preprocessing to deployment",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare infrastructure for AMS in PROD,XP-2894,94530,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,tm431,tm431,15/Apr/20 10:57,13/Aug/20 19:41,22/Feb/21 13:26,03/Jun/20 09:23,,,3.1.0,,,,,,,,,,,"h1. GIANT ANTEATER preparation for Production

It is foreseen to deploy AMS into PROD in late May. We need to get infrastructure ready for this. VMs, DBs, Firewalls requests etc. Alarm notificatio layer. Very simillar what was done in SIMU in SERVICE-6077",,iv732,tm431,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22809600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ar3i:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/May/20 10:53;tm431;The target date by when all should be prepared is 03/06/2020 when the deployment of AMS is foresseen to happen into PROD","19/May/20 11:45;iv732;[~tm431] do we have any documentation for this request? I dont know how many VMs we need to set up, which packages must be installed.","19/May/20 12:45;tm431;I do not know it, but guys from your team can help, or [~yo218] knows, as he did same for SIMU","19/May/20 13:20;yo218;--> https://jira.deutsche-boerse.com/browse/TECHLOG-3203","27/May/20 10:34;iv732;New VMs are requested:  https://jira.deutsche-boerse.com/browse/SYSENG-54","03/Jun/20 09:23;iv732;VMs are ready

IP addresses and DNS records were i,plemented on Saturday 30.05.2020
{noformat}
====================================================================
[enprodauto1 ~]$ nslookup xbprodams1
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbprodams1.deutsche-boerse.de
Address: 10.139.95.253

[enprodauto1 ~]$
====================================================================
{noformat}
{noformat}
====================================================================
[enprodauto1 ~]$ nslookup xbprodams2
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbprodams2.deutsche-boerse.de
Address: 10.139.95.252

[enprodauto1 ~]$
===================================================================={noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Certificates - Initial analysis,XP-2893,94529,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tm431,tm431,tm431,15/Apr/20 10:55,13/Aug/20 19:41,22/Feb/21 13:26,24/Jun/20 13:50,,,3.1.0,,,,,,,,,,,"h1. {color:#00875a}XBID Certificates Overview {color}
h2. {color:#172b4d}Current state{color}

{color:#172b4d}There was a initiative (INIT-236) in 2019 to analyze and monitor energy certificates. Output can be found here: {color}
 * [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Certificate+Management]

Last couple of weeks showed that this list and certificates monitoring is not finished. 
h2. {color:#172b4d}Proposed solution{color}

Cooperate closely with among all possible parties within the section (BOs, TOs, Devs, testers, analysts) and provide consolidated output of all possible certificates you can find. App, client, rabbit, server, DB, consul, comtrader, mail, root CA, webservers, ha proxies, ldap, jira... ANY! 

 

[~yo218]  puts more details regarding RootCA: 
 * The AddTrust External Root CA is about to expire in May 2020 (30th). We need to find out where it is still used like server certificates for webservers, haproxies, LDAP, (consul?).
 * It need to be replaced for all environments

h2. {color:#172b4d}Acceptance criteria{color}
 * {color:#172b4d}consolidated output containing all possible certificates with information like: {color}
 ** how is certificated created
 ** where it's stored 
 ** where it's used
 ** who is responsible for it's renewal
 ** how often it expires
 ** any other useful information
 * once overview is completed, we check what kind of certificates can be replaced seamlessly (when customer can't notice it) to minimize the amount of notifications sent to the customer.
 * talk to system engineering about possibility of moving from Energy Certificate TrustStore to the OS one. ",,ek176,lw641,tm431,ub113,yn731,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3023,SMXBID-1855,,,,,,"08/May/20 10:29;yo218;results_xbid_simu.txt;https://jira.deutsche-boerse.com/secure/attachment/83659/results_xbid_simu.txt","10/Jun/20 16:40;yo218;results_xbid_simu_june.txt;https://jira.deutsche-boerse.com/secure/attachment/84739/results_xbid_simu_june.txt",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21772800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ap2p:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 7,HOT Sprint 8 (S),HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/20 08:25;tm431;Suggestion for template. Still in Progress final version shoudl be discussed during todays call

COMTRADER_AllNonProd_xbid-SOB.p12
 *Name/identification:* All of us should use same expressions so we know about which certificate we are talking....
 *Description:* This certificate is for login into AMQP by LTS and Comtrader or any internal testing tool (Testclient, Catrina)
 *Client facing? YES,* public part is provided to customers, so they can upload it into their LTS or Catrina e.g.

*Where it is stored:*

a) private part in server XXXX

b) public part is provided to customers, and to us and is sotred then localy

*Example from PAST:* Examples of past renewal such as SERVICE tickets, bugs, issues etc. For learning purposes
 XBID-4475, SERVICE-2129

*Where can we find PWD for this cert*: SERVICE-2129

*Is this also for PROD:* I do not know, but somth like this should be provided. All details then must be filled by bizzops

*How is the expiration checked:*

a) PROD envs. by xxxx

b) TEST envs. by xxx

*Who is responsible for it's renewal:* Bizzops for both Prod and Test envs

*What are the impacts of the renewal:* What needs to be stopped? What is the impact on Customers. Will they be logged out?

*What ENVs are affected*: All client facing test environments

*Other remarks:* *WITH RENEWING OF THIS CERT COMMTRADER MUST BE UPDATED AND NEW VERSION RELASED* AND DEPLOYED into both PROD and TEST envs. THIS requires at least 14days upfront notification

What is the difference between this cert and PMITEST_AllNonProd_xbid-SOB and PMITEST_AllNonProd_xbid-CMM

 
 * how is certificated created
 * where it's stored 
 * where it's used
 * who is responsible for it's renewal
 * how often it expires
 * any other useful information


I will describe certs which are client facing, such as Emails, their keys for SFTP etc... 

 ","23/Apr/20 09:58;tm431;Summary of yesterdays meeting, thank you Niklas for this sum up



 

Which certs are used and to be monitored:
 * Server certificates used by ssl and webservers
 * Tuan is working on a single cert using wildcards (*.xbid.deutsche-boerse.com)


 * Server certificates for LDAP
 * To be clarified: Can we use the same wildcard cert as above?


 * Server certificates for consul
 * To be clarified: Can we use the same wildcard cert as above?


 * Email certificates
 * should be stored in vault and monitored

 * Add Trust Root CA
 * Used in Truststores, LDAP, … ?


 * Deutsche Börse Root CA (Test and Prod)
 * Energy Root CA (Prod, Prod-CMM, Test)

 

Mira has a tool which can scan hosts for existing certs and their expiration date
 * Can be used for initial cert collection
 * For the actual expiration monitoring we will rely on vault and opsgenie
 * @mira can you extend it to detect jks files as well?

 

Result should be a confluence page, showing which certs exist and the procedures for renewing and replacing them

 

Please feel free to add or update anything

 

Best regards,

Niklas

 ","24/Apr/20 10:52;ek176;The script is available: [https://github.deutsche-boerse.de/ek176/shared/tree/master/utils/cert_check_primer]

In addition to checking magic bytes/ trying to process certs, it also lists files with an interesting suffix. 

The output is a CSV file that should be processed manually.","29/Apr/20 11:12;tm431;Here is the output from [~iv732]  script, regarding XBID envs

secret/xb/xbid/ctpa/cert/ctpa1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpa/cert/haproxy/ctpa1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpa/cert/web/ctpa1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpb/cert/ctpb1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpc/cert/ctpc1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpd/cert/ctpd1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpe/cert/ctpe1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpf/cert/ctpf1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpg/cert/ctpg1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctph/cert/ctph1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpi/cert/ctpi1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpj/cert/ctpj1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpk/cert/ctpk1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpl/cert/ctpl1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctpm/cert/ctpm1.xbid.deutsche-boerse.com
 secret/xb/xbid/ctpm/cert/ctpm1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/ctso/cert/ctso1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/cute/cert/cute1.profiles.xbid.deutsche-boerse.com.cer
 secret/xb/xbid/cute/cert/cute1.xbid.deutsche-boerse.com
 secret/xb/xbid/cute/cert/cute1.xbid.deutsche-boerse.com.cer
 secret/xb/xbid/cute/cert/cute1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/dst1/cert/dst_xbid_m7_deutsche-boerse_com_cert.cer
 secret/xb/xbid/lipa/cert/lipa1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/lipb/cert/lipb1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/perf/cert/cmm/server.pem
 secret/xb/xbid/perf/cert/ext/server.pem
 secret/xb/xbid/perf/cert/perf1.xbid.deutsche-boerse.com
 secret/xb/xbid/perf/cert/perf1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/perf/cert/perf2_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/perf/cert/server.pem
 secret/xb/xbid/perf/cert/sob/server.pem
 secret/xb/xbid/prod/cert/cmm/prod1-server.pem
 secret/xb/xbid/prod/cert/cmm/prod1.xbid.deutsche-boerse.com
 secret/xb/xbid/prod/cert/cmm/prod2-server.pem
 secret/xb/xbid/prod/cert/cmm/prod2.xbid.deutsche-boerse.com
 secret/xb/xbid/prod/cert/cmm/server.pem
 secret/xb/xbid/prod/cert/prod1_profiles_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/prod/cert/prod1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/prod/cert/prod2_profiles_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/prod/cert/prod2_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/prod/cert/sob/prod1-server.pem
 secret/xb/xbid/prod/cert/sob/prod1.xbid.deutsche-boerse.com
 secret/xb/xbid/prod/cert/sob/prod2-server.pem
 secret/xb/xbid/prod/cert/sob/prod2.xbid.deutsche-boerse.com
 secret/xb/xbid/prod/cert/sob/server.pem
 secret/xb/xbid/prod/cert/web/cmi/cmi-prod2_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/simu/cert/cmm/server.pem
 secret/xb/xbid/simu/cert/simu1.xbid.deutsche-boerse.com
 secret/xb/xbid/simu/cert/simu1_profiles_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/simu/cert/simu1_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/simu/cert/simu2.xbid.deutsche-boerse.com
 secret/xb/xbid/simu/cert/simu2_profiles_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/simu/cert/simu2_xbid_deutsche-boerse_com_cert.cer
 secret/xb/xbid/simu/cert/sob/server.pem
 secret/xb/xbid/simu12345/cert/cmm/asim1_hupx_deutsche-boerse_com_cert.cer
 secret/xb/xbid/syt1/cert/cmm/server.pem
 secret/xb/xbid/syt1/cert/ext/server.pem
 secret/xb/xbid/syt1/cert/ext/syt1.xbid.deutsche-boerse.com
 secret/xb/xbid/syt1/cert/sob/server.pem
 secret/xb/xbid/syt1/cert/syt1.xbid.deutsche-boerse.com
 secret/xb/xbid/syt1/cert/syt1_xbid_m7_deutsche-boerse_com_cert.cer
 secret/xb/xbid/syt2/cert/syt2_xbid_m7_deutsche-boerse_com_cert.cer
 secret/xb/xbid/syt3/cert/syt3_xbid_m7_deutsche-boerse_com_cert.cer
 secret/global/consul/aws-test/server_cert
 secret/global/consul/blablabla/server_cert
 secret/global/consul/energy-aws-test/server_cert
 secret/global/consul/energy-shrd-prod/server_cert
 secret/global/consul/energy-shrd-simu/server_cert
 secret/global/consul/energy-shrd-test/server_cert
 secret/global/consul/kucera-test/server_cert
 secret/global/consul/m7-shrd-simu/server_cert
 secret/global/consul/m7-shrd-test/server_cert
 secret/global/consul/xb-xbid-prod/server_cert
 secret/global/consul/xb-xbid-simu/server_cert","29/Apr/20 11:14;tm431;Place in confluence where certificates will be described (after we will have the whole list) is here:

https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Certificates+overview","29/Apr/20 11:16;tm431;Mira's script will be uploaded into ansible playbook and run through all servers... this will be done in next sprint","29/Apr/20 11:45;tm431;[~iv732] what about following points? Does this script check following?


 * Server certificates for LDAP
 * To be clarified: Can we use the same wildcard cert as above?

 * Server certificates for consul
 * To be clarified: Can we use the same wildcard cert as above?","06/May/20 13:39;yo218;Roman created another overview: [https://github.deutsche-boerse.de/pages/dev/energy.automation.certificate/]","06/May/20 13:39;yo218;* Server certificates for LDAP
 * To be clarified: Can we use the same wildcard cert as above?

 * Server certificates for consul
 * To be clarified: Can we use the same wildcard cert as above?

yes","06/May/20 16:22;yo218;I attached the results for all Simu hosts","26/May/20 10:41;lw641;New acceptance criteria added - as discussed on internal XBID core call on 26/05/2020:
 * once overview is completed, we check what kind of certificates can be replaced seamlessly (when customer can't notice it)","08/Jun/20 09:33;tm431;[~yo218] can you attach updated list of certs from SIMU after wildcards (or how is it called) were introduced? The list should then be significantly shortened.","08/Jun/20 10:09;yo218;[~ek176] please attach the latest version of your script to this ticket","09/Jun/20 13:41;ek176;It's still in the same place:

[https://github.deutsche-boerse.de/ek176/shared/tree/master/utils/cert_check_primer]

namely:

[https://github.deutsche-boerse.de/ek176/shared/blob/master/utils/cert_check_primer/check_cert.sh] ","10/Jun/20 16:40;yo218;attached an updated list","15/Jun/20 10:30;tm431;[~yo218] we can slowly start with description of external certificates

in [https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Certificates+overview]

id_rsa_scp, cmi.jks, ldapkeystore.jks, xbid_privete.pem, server-privkey.pem, server.pem, rustedCAs.pem, server-cert.pem, xbid_cert.pem",,,,,,,,,,,,,,,,,,,,,,
(Split 2) Create separate slack channel for alerts from SYT,XP-2892,94517,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eg288,qo794,qo794,15/Apr/20 10:02,11/Feb/21 12:19,22/Feb/21 13:26,24/Nov/20 15:34,,,3.2.x,,,,,,,,,,,"Currently all alerts from non-prod environments are reported to one slack channel: {{xbid_alerts}}. This way the channel is flooded with notifications from our internal SYT envs so the customers facing env alerts can be easily missed, moreover it's hard to even monitor this channel. It would be great to report all notifications from SYT envs to a different channel, maybe also renaming the current one to be more self-explanatory (it's not clear at the first glance what alerts are reported there).

 

New XBID Alerts Slack channels:
 * #xbid_alerts_syt - dst1|perf|syt[123] environments
 * #xbid_alerts_cute - ^ctp|ctso|cute|^lip|simu environments
 * #xbid_alerts_prod - prod environment

Couple of exceptions, some of the hosts, like xbtestpdb1/2 are running both internal tests and cute postgrers instances or ldap servers which are also used by both of them.",,eg288,hw120,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,7689600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040000603",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 21,HOT Sprint 22 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Nov/20 23:01;hw120;Tested on disk alert only, modified kapacitor handlers as in pull request
{code:java}
[root@ip-10-115-78-115 handlers]# kapacitor -skipVerify -url https://localhost:9092 show-topic-handler disk disk_slack_xbid_syt
ID: disk_slack_xbid_syt
Topic: disk
Kind: slack
Match: ""product"" =~ /^xb/ AND (""client_environment"" =~ /dst1|perf|syt[123]/ OR ""host"" =~/inte|test/)
Options: {""channel"":""xbid_alerts_syt""}
[root@ip-10-115-78-115 handlers]# kapacitor -skipVerify -url https://localhost:9092 show-topic-handler disk disk_slack_xbid_cute
ID: disk_slack_xbid_cute
Topic: disk
Kind: slack
Match: ""product"" =~ /^xb/ AND (""client_environment"" !~ /prod|dst1|perf|syt[123]/ OR ""host"" =~/cuts|test/)
Options: {""channel"":""xbid_alerts_cute""}
[root@ip-10-115-78-115 handlers]# kapacitor -skipVerify -url https://localhost:9092 show-topic-handler disk disk_slack_xbid_prod
ID: disk_slack_xbid_prod
Topic: disk
Kind: slack
Match: ""product"" =~ /^xb/ AND ""client_environment"" =~ /prod/
Options: {""channel"":""xbid_alerts_prod""}
{code}
Then generated file to fill up the space up to warning level using dd on:

xbsyt1sla1

xbctpadow1

xbprodams1

 

Prod alert ended up correctly in xbid_alerts_prod but both remaining ended up in xbid_alerts_cute.

 

We have to modify the condition somehow.

 

Reverted back.

 ","13/Nov/20 09:48;eg288;* can one alarms ended in two slack channels? or once a match is found then the alarm is not propagated further to following handlers?
* what client environment is defined for given alarm and machines xbsyt1sla1, xbctpadow1. Is it shrd?

Note to slack_xbid_cute condition:
{code}
Match: ""product"" =~ /^xb/ AND (""client_environment"" !~ /prod|dst1|perf|syt[123]/ OR ""host"" =~/cuts|test/)
{code}
for client_environment shrd is the following part always true no matter what host it is.
{code}
""client_environment"" !~ /prod|dst1|perf|syt[123]/
{code}","16/Nov/20 22:06;hw120;Because one alert from kapacitor topic is sent by multiple handlers to Alerta, Slack, Opcgenie, therefore I assume it could be sent through multiple slack handlers.
{code:java}
[root@xbsyt1sla1 xbid]# cat /etc/telegraf/telegraf.conf
# Tags can also be specified via a normal map, but only one form at a time:
[global_tags]
  host = ""xbsyt1sla1""
  machine = ""tomcat""
  group = ""tomcat""
  module = ""shrd""
  client = ""shrd""
  product = ""xb""
  client_environment = ""shrd""
  host_group_module=""xbsyt1sla1 - tomcat - shrd""
  datacenter = ""equinix""

[root@xbctpadow1 ~]# cat /etc/telegraf/telegraf.conf
# Tags can also be specified via a normal map, but only one form at a time:
[global_tags]
  host = ""xbctpadow1""
  machine = ""tomcat""
  group = ""tomcat""
  module = ""xbid_ctpa""
  client = ""xbid""
  product = ""xb""
  client_environment = ""ctpa""
  host_group_module=""xbctpadow1 - tomcat - xbid_ctpa""
  datacenter = ""equinix""
{code}
Yes, it seems like cute condition caught also shrd host, but then OR condition doesn't work or works differently.
{code:java}
OR ""host"" =~/inte|test/
{code}
I will try to modify it to and test it.
{code:java}
OR ""host"" =~/.*inte.*|.*test.*/
{code}
 ","24/Nov/20 00:32;hw120;Fixed issues with xb[amr|acer|reporttool] telegraf_shrd_env.

Changed conditions to:

xbid_alerts_syt
{code:java}
match: ""\""product\"" =~ /^xb/ AND (\""client_environment\"" =~ /dst1|perf|syt[123]/ OR \""host\"" =~/^xbinte/)""{code}
xbid_alerts_cute
{code:java}
match: ""\""product\"" =~ /^xb/ AND (\""client_environment\"" =~ /^ctp|ctso|cute|^lip|simu/ OR \""host\"" =~ /^xbcuts|^xbtest|^xbdtld|^xbdsld/)""
{code}
I want to avoid duplicate alerts that would otherwise be caused by client_environment: shrd. Shrd hosts must be covered by ""OR host"" condition.

 

I tested it by filling disk space to trigger alert on hosts:
 * xbsyt1ams1
 * xbinteweb1
 * xbctpadow1
 * xbcutsweb1

...and it seems all fine.

I think we can update it, inform everybody about the change, add everyone to those channels and redeploy it.","24/Nov/20 12:08;hw120;Change deployed, users added to new channels, updated documentation, informed about the change in the slack.

We only need to archive old channels in a week or so. I will ask Aymon (slack admin) to do it for us.","24/Nov/20 12:47;eg288;New channels: _xbid_alerts_prod_, _xbid_alerts_cute_ and _xbid_alerts_syt_","24/Nov/20 13:03;hw120;We still need to change elasticsearch watcher alerts for xbid, going to do it today.

Also there are couple of jenkins jobs which are sending alerts there and needs to be updated.","24/Nov/20 14:01;hw120;Consulted with Roman about jenkins selfhealing alerts:

think i set them up here: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Selfhealing/
the actual slack might be sent in the end by some script that is executed via ansible
at least it corresponds to this folder structure: https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/jenkins/selfhealing
the second one in the end is here: https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/rabbitmq_instance/templates/prodscripts/rabbitmq/rabbitmq_include#L86
yes and the first one directly from jenkins: https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/selfhealing/Jenkinsfile_slave-slave#L46
probably you could also just search github for the error text... i think in an ideal world, you will find the exact point of implementation....",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Ansible - improvements,XP-2891,94494,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,14/Apr/20 17:12,04/Aug/20 19:53,22/Feb/21 13:26,30/Jun/20 15:36,,,3.1.0,,,,,,,,,,,"h1. Cleanup of Ansible scripts
 # define artifactory path prefix on a global level, {{eex-dev-local}} is not intuitive (/)

 ** var artifactory_path in roles xbrep and xbenq
 # define {{db_cluster|length > 1 }}more transparently (e.g. defining global var {{is_double_sided}} or something) (/)
 # inconsistency of {{smtp_hosts}} + {{smtp_ports}} versus {{ldap_addr}} + {{ldap_port (x) (not implemented, evaluted as not important)}}",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21168000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040000602i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Jun/20 14:13;ei349;[~eg288]: please update. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security concept vol 3,XP-2889,94476,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,14/Apr/20 11:42,13/Aug/20 19:41,22/Feb/21 13:26,20/Apr/20 10:35,,,3.1.0,,,,,,,,,,,"Here is the list of open points that can still be fixed in this RA:
 * Network diagram and interface table should be updated in the SC
 ** {color:#de350b}Word - chapter 9.1.2. fill this table with all servers mentioned in AIP 110 {color}*{color:#4c9aff}DEV{color}/{color:#de350b}TechOps{color}?*
 * -What process is followed to assign access privileges to the application to internal DBG personnel?-
 ** -{color:#de350b}Word - chapter 9.2.2 User access provisioning, how access to the production are assigned?{color}- {color:#403294}*-BizOps-* {color}
 We don't have any process. The accounts are discussed with the customer and they must be approved by the customer.

 * Are there TechOPS procedures in place? Where are they stored?
 ** {color:#de350b}Word - Chapter 12.1.1 Documented operating procedures *TechOps* - we need to describe how the system is run, how the configuration is done, how the production bugs are handled etc. These things are missing on the confluence page.{color}
 * -What tool is used for capacity monitoring of the servers?-
 ** {color:#de350b}Word - chapter 12.1.3 Capacity management {color} *TechOps:* we have already Check-MK and Alerta for monitoring of resources, like disks, memory, CPUs...
 * What antivirus is used on the servers?
 ** {color:#de350b}Word - chapter 12.2.1 Controls against malware *TechOps*{color}
 * -There are two overdue vulnerabilities reported in VMT - PT-797; PT-802-
 ** {color:#4c9aff}*DEV PT-797 - XP-69, PT-802 XP-70{color} {color:#00875a} SOLVED{color}
 * Statement about segregation of networks should be added to the SC
 ** {color:#de350b}Word - chater 13.1.3 Segregation in networks *TechOps -* Do we have any approved inadequate special firewall rules? ** {color}
 * -What mailserver is used and how is it secured?-
 ** {color:#de350b}Describe our Mail server (security, version etc). *TechOps*{color}
 * -HP Fortify reports 6 critical and 226 high findings in the source code.-
 ** {color:#de350b}Is this report related also to Production?{color}  {color:#4c9aff}*DEV* - HP fortify resets false positive findings with every new version. Thus, these findings are not related to the production version{color}

Security concept should be updated, to include the information that is listed above, or that was requested during todays meeting.

 

As we discussed, since two week deadline is too steep for you, please try to deliver all evidences by Friday 17^th^ April. I will then go forward with the RA, and any evidence that was not delivered might result in an additional risk being identified.",,iv732,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/20 11:43;zi174;AID292_M7 XBID_SSD_v0.2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/82527/AID292_M7+XBID_SSD_v0.2.xlsx","14/Apr/20 11:43;zi174;Security Concept - XBID V2.docx;https://jira.deutsche-boerse.com/secure/attachment/82526/Security+Concept+-+XBID+V2.docx","17/Apr/20 14:24;yo218;XBID_COLT_MPLS_intel_architecture.pdf;https://jira.deutsche-boerse.com/secure/attachment/82760/XBID_COLT_MPLS_intel_architecture.pdf","17/Apr/20 14:24;yo218;XBID_ORANGE_MPLS_intel_architecture.pdf;https://jira.deutsche-boerse.com/secure/attachment/82758/XBID_ORANGE_MPLS_intel_architecture.pdf","17/Apr/20 14:24;yo218;XBID_intel_architecture.pdf;https://jira.deutsche-boerse.com/secure/attachment/82759/XBID_intel_architecture.pdf",,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,26784000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1665,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s3r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/20 12:05;iv732;What tool is used for capacity monitoring of the servers?
 * {color:#de350b}Word - chapter 12.1.3 Capacity management *TechOps:   we have already Check-MK and Alerta for monitoring of resources, like disks, memory, CPUs...*{color}

 ","17/Apr/20 13:55;yo218;What mailserver is used and how is it secured?
 * {color:#de350b}Describe our Mail server (security, version etc). *TechOps*{color}

MTA is Postfix v2.10.1 running on RHEL 7.5
dovecot 2.2.36 handles local delivery on the server plus serves as an IMAP server
Postfix receives incoming emails from DBAGs global mail server as well as inside and determines whether to accept or reject them based on the destination email address (for inbound messages) and client source IP and sender address (for outbound messages).
Connection to the servers (Postfix and Dovecot ports) is limited for respective networks:
- test and OA for test cluster
- xb prod network for XB prod cluster
plus DBAG mail GW 

The servers are not connected to the internet, all outbound messages are relayed through DBAGs mail gateway which does its own checks. ","17/Apr/20 14:15;yo218;Network diagram and interface table should be updated in the SC
 * {color:#de350b}Word - chapter 9.1.2. fill this table with all servers mentioned in AIP 110 {color}*{color:#4c9aff}DEV{color}/{color:#de350b}TechOps{color}?*

|XBIDPRODCOR1|
|XBPRODSOB1|
|XBPRODCMM1|
|XBPRODCMI1|
|XBPRODSMC1|
|XBPRODSMI1|
|XBPRODECP1|
|XBPRODEHA1|
|XBPRODEDB1|
|XBPRODAMQ1|
|XBPRODAMQ3|
|XBIDPRODCOR2|
|XBPRODSOB2|
|XBPRODCMM2|
|XBPRODCMI2|
|XBPRODSMC2|
|XBPRODSMI2|
|XBPRODECP2|
|XBPRODEHA2|
|XBPRODAMQ2|
|XBPRODAMQ4|
|XBPRODCTP1|
|XBPRODCTP2|
|XBPRODREP1|
|XBPRODREP2|
|XBPRODSSL1|
|XBPRODSSL2|
|XBPRODSSL3|
|XBPRODSSL4|
|XBPRODSSL5|
|XBPRODSSL6|
|XBPRODWEB1|
|XBPRODWEB2|
|XBPRODWEB3|
|XBPRODWEB4|
|XBPRODWEB5|
|XBPRODWEB6|
|XBPRODSSC1|
|XBPRODSSC2|
|XBPRODSSC3|
|XBPRODSSC4|
|XBPRODSSC5|
|XBPRODSSC6|
|XBPRODWBC1|
|XBPRODWBC2|
|XBPRODWBC3|
|XBPRODWBC4|
|XBPRODWBC5|
|XBPRODWBC6|
|XBPRODCOM1|
|XBPRODCOM2|
|XBPRODCOM3|
|XBPRODCOM4|
|XBPRODCOM5|
|XBPRODCOM6|
|XBPRODCHA1|
|XBPRODCHA2|
|XBPRODCBN1|
|XBPRODCBN2|
|XBPRODIDM1|
|XBPRODIDM2|
|XBPRODPMI1|
|XBPRODPMI2|
|XBPRODPRX1|
|XBPRODPRX2|
|XBPRODSLA1|
|XBPRODSLA2|
|XBPRODAMS1|
|XBPRODAMS2|
|XBPRODPDB1|
|XBPRODPDB2|
|XBPRODPDB3|
|XBPRODPDB4|","17/Apr/20 14:17;yo218;Are there TechOPS procedures in place? Where are they stored?

--> Yes, they are in place and are available on confluence

(this answer should be good enough for the SC)","17/Apr/20 14:21;yo218;What antivirus is used on the servers? --> Just ClamAV on the SFTP servers, all our servers are running with RHEL which is considered as securewithout running any additional software on it","17/Apr/20 14:22;yo218;Statement about segregation of networks should be added to the SC
 * {color:#de350b}Word - chater 13.1.3 Segregation in networks *TechOps -* Do we have any approved inadequate special firewall rules? ** {color}

{color:#172b4d}Yes, but they are about to be removed very soon (Andrei Nazarenko is on it){color}","17/Apr/20 14:23;yo218;I think that's it [~zi174]","17/Apr/20 14:24;zi174;[~yo218] thank you, I really appreciate it, might you please send me a link to a confluence page (maybe you've already sent it but I forget :))

 

It's related to:

Are there TechOPS procedures in place? Where are they stored?

--> Yes, they are in place and are available on confluence

(this answer should be good enough for the SC)","17/Apr/20 14:24;yo218;attached all network diagrams","17/Apr/20 14:26;yo218;[https://confluence.energy.svc.dbgcloud.io/display/ET/Energy+TechOps]","17/Apr/20 14:30;zi174;Great, Thank you [~yo218]! ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace expiring root CA,XP-2884,94439,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,iv732,yo218,yo218,09/Apr/20 14:31,13/Aug/20 19:41,22/Feb/21 13:26,02/Jun/20 10:56,,,3.1.0,,,,,,,,,,,"The AddTrust External Root CA is about to expire in May 2020 (30th). We need to find out where it is still used like server certificates for webservers, haproxies, LDAP, (confluence?).

It need to be replaced for all environments",,ei349,iv732,pd122,yo218,,,,,,,,,,,,,,,,,,,,,,,,,XP-3030,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23328000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ar3i:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/May/20 15:22;ei349;Issue split into:
|XP-3030|Replace expiring root CA|
","14/May/20 12:31;iv732;[~yo218] on which server did you see that? I think the chain ends with Usertrust RootCA, not sectigo CA? So if the new Usertrust RootCA is in the truststore then it will be fine. Without it there will be problem.","14/May/20 19:19;iv732;# Playbook to deploy Wildcard Cert to all instances
 [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/Deploy%20wildcard%20cert/67/console]
 # Playbook to deploy Web&SSL:
[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/32749/console]","19/May/20 14:02;pd122;LDAP trust stores updated (server certs removed, new CAs put in): [https://github.deutsche-boerse.de/dev-confidential/energy-mkt-production/pull/45]

Note:  I found that the *LDAP_TRUST_STORE* password (from xbid_prod_passwd.xml)  does not work with that trust store, used test password instead.  Potential issue perhaps.

 

New store content:
{code:java}
Owner: CN=USERTrust RSA Certification Authority, O=The USERTRUST Network, L=Jersey City, ST=New Jersey, C=US
Issuer: CN=USERTrust RSA Certification Authority, O=The USERTRUST Network, L=Jersey City, ST=New Jersey, C=US
Valid from: Mon Feb 01 01:00:00 CET 2010 until: Tue Jan 19 00:59:59 CET 2038
---
Owner: CN=COMODO RSA Certification Authority, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Issuer: CN=COMODO RSA Certification Authority, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Valid from: Tue Jan 19 01:00:00 CET 2010 until: Tue Jan 19 00:59:59 CET 2038
{code}
 ","22/May/20 12:28;iv732;[~yo218] [~ei349]

One issue with the certificate for Profiles.

The URL is: prod1.profiles.xbid.deutsche-boerse.com, which will not be included by the wildcard cert

Suggestion: change the servername setting in Apache to prod1_profiles.xbid.deutsche-boerse.com

Question: do we need to inform customer about the change? Do we need to update Comtrader?","27/May/20 14:41;iv732;Will not update profiles web cert",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check LDAP certificate expiration date for XBID environments,XP-2883,94426,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ub113,ub113,ub113,09/Apr/20 11:38,13/Aug/20 19:47,22/Feb/21 13:26,04/Aug/20 10:29,,,3.1.0,,LDAP,,,,,,,,,"Hi all, 

Please check the expiration dates for XBID environments.

We will develop a plan for renewal once we have all the dates visible. 

XBID PROD LDAP should have higher priority.

*AC:*
 * add certificates to vault
 * integrate it with checkMk
 * inform Ana about expiration dates",,ei349,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17884800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000000003000400006020r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Apr/20 13:21;ub113;LDAP certificate for PROD valid until  *Oct 22  2021*","29/Jul/20 18:24;ei349;Dear [~ub113]: is this ticket still valid? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reporting engine - do not load all data into memory when generating a report,XP-2880,94333,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eg288,eg288,07/Apr/20 16:55,04/Aug/20 19:53,22/Feb/21 13:26,27/May/20 12:46,,,3.1.0,,Reporting Engine,,,,,,,,,"To generate a report the reporting engine loads all needed data from database into memory. Then all the data are transformed itno JAXB objects and only then written as one chunk into a XML file. It is very demanding on memory, especially for ADMIN member, where the resulting XML report TC540 can have around 70MB .

The production instance runs with 8 GB of memory and it fails with OutOfMemory on busy days.

Optimize the report generation to decrease memory consuption.

Info:
 * fails during night, day ok
 * 25 minutes -> 18min data load
 * query returns 1_800k of lines
 * (/) one option is add memory +4 GB - Ask Niklas -> memory added, the application uses 12GB, it works for now
 * another is change query run by hour than day
 * analyse

SQL query for report TC540 reads table cx_101_order_history. The query selects data according to colums last_update_time. There is an index in place. See XP-2882 for further details.",,eg288,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3073,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23414400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aw24:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/20 12:03;eg288;See suggestions in XP-2882 how to speed up the query, especially the change of join clause for contractHistory should be implemented and also remove distinct which is not need it when the table join is done correctly. The result is provided roughly 15x times faster by database.

The same optimization should be done for TC830, I see the same inefficiency there as well, ideally to avoid distinct all together.","27/May/20 12:45;uv683;Issue split into:
|XP-3073|(Split) Reporting engine - do not load all data into memory when generating a report|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve CheckMK Monitoring to send critical notifications,XP-2868,94225,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,ei349,ei349,06/Apr/20 10:05,31/Aug/20 15:38,22/Feb/21 13:26,23/Apr/20 09:48,,,3.1.0,,,,,,,,,,,"*+ORIGINAL SLACK CONVERSAION+ :*
 
[Steffen Englert|https://app.slack.com/team/U7BU3EE12]  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585904960083300]

@here [@7tops|https://dbg-devops.slack.com/admin/user_groups] good morning, we discovered some issues on m7simupdb3 today in the morning.
https://jira.deutsche-boerse.com/browse/M7P-5897at the moment all M7-Simu patroni clusters are running with 3 primary nodes (""*m7simupdb1*, *m7simupdb2*, *m7simupdb4*)
*m7simupdb3* is currently out of the cluster. [@Lambert|https://dbg-devops.slack.com/team/U40MPJ1EH] is investigating and discovered some failed disk. More details will come.
 
!https://ca.slack-edge.com/T12FM9C21-U7BU3EE12-9ce03a3e5435-48!
[Steffen Englert|https://app.slack.com/team/U7BU3EE12]  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585909045083400?thread_ts=1585904960.083300&cid=G3X4L43GW]

machine is back and part of the cluster again.
properly disk-replace will come soon.
 
!https://ca.slack-edge.com/T12FM9C21-U1HQX41D2-a3405de90eb3-48!
[Antoine Vigues|https://app.slack.com/team/U1HQX41D2]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F10.2%2Fgoogle-small%2F1f3e1%402x.png!  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585911104083600?thread_ts=1585904960.083300&cid=G3X4L43GW]

[@KaaN|https://dbg-devops.slack.com/team/U6SA38LGP] [@Steffen|https://dbg-devops.slack.com/team/U7BU3EE12]: how would we notice failed disk (or other hardware component) on Production after migration on 14/4?
 
!https://ca.slack-edge.com/T12FM9C21-U7BU3EE12-9ce03a3e5435-48!
[Steffen Englert|https://app.slack.com/team/U7BU3EE12]  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585911502083800?thread_ts=1585904960.083300&cid=G3X4L43GW]

[@antoine.vigues|https://dbg-devops.slack.com/team/U1HQX41D2]
that was also my question. I just noticed it while i was trying to ssh the machine today in the morning. I will investigate that with the guys who have more knowledge about the our current monitorring. At the moment it seems like that we have to replace a disk, at [@Lambert|https://dbg-devops.slack.com/team/U40MPJ1EH] has more details about issue what happened on the machine.
 
!https://ca.slack-edge.com/T12FM9C21-U6SA38LGP-1f05d84c00d2-48!
[Kadir Kaan Evren|https://app.slack.com/team/U6SA38LGP]  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585912299084000?thread_ts=1585904960.083300&cid=G3X4L43GW]

Hi Antoine, with the current setup we would not have noticed outside of office hours at all unless databse go down. If any failover happens it would be visible on Alerta and generate a call. Though the event was caught by CheckMK [https://englobmon2.deutsche-boerse.de/energy/check_mk/index.py?start_url=%2Fenergy%2Fcheck_mk%2Fview.py%3Fhost%3Dm7simupdb3%26site%3Denergy%26view_name%3Dhostsvcevents] it is not pushing the alerts currently neither to alerta nor to opsgenie. I will get tickets created in XBID backlog and speak with [@Jiriik|https://dbg-devops.slack.com/team/U2U900AUT] so that Tuan can continue to work on it. Peter also be back from vacation next week and we can act very fast on missing infrastructure alerting.
 
!https://ca.slack-edge.com/T12FM9C21-U2U900AUT-a9113e8c08f9-48!
[Jiri Vlasimsky|https://app.slack.com/team/U2U900AUT]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F10.2%2Fgoogle-small%2F1f3e1%402x.png!  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585914013084200?thread_ts=1585904960.083300&cid=G3X4L43GW]

Hi, thanks for the information. How urgent is this topic for xbid? SHould I reshuffle the scope of current sprint or is it enough to start works on it next srpint starting 16th April?
 
!https://ca.slack-edge.com/T12FM9C21-U2U900AUT-a9113e8c08f9-48!
[Jiri Vlasimsky|https://app.slack.com/team/U2U900AUT]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F10.2%2Fgoogle-small%2F1f3e1%402x.png!  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1585916521086000?thread_ts=1585904960.083300&cid=G3X4L43GW]

small update: I will schedule it for [@Tuan Nguyen|https://dbg-devops.slack.com/team/U4FURHR17] when he's back on Monday.
!https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-small/1f44d-1f3fb@2x.png!3
 ",,ei349,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,26352000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aluw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,Alpha Sprint 7 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/20 11:03;iv732;Basically, this will not affect just hard disks issues. All critical notifications will not be sent by CheckMK now to Opsgenie because currently it is disabled.

Last time I had problem to connect to Opsgenie servers. As I am told that the firewall requests to Opsgenie servers are now accepted. I will continue on that.","16/Apr/20 13:44;iv732;Notification sent over Slack & AlarmTilt is working.

Now fixing issue with Opsgenie and classify alerts into different groups together with Kapacitor alerts

 ","21/Apr/20 09:40;iv732;CheckMK Opsgenie built-in plugin has a big bug which doesn't allow user to enter proxy settings from the UI.

Had to hard-coded change in the library config file. This change will not be retained if we restore a backup. Will open a ticket to CheckMK.

 ","23/Apr/20 09:47;iv732;Change the following settings:
 
/omd/versions/default/lib/python/cmk/notification_plugins/opsgenie_issues.py
 
 
def configure_authorization(key):
    configuration.api_key['Authorization'] = key
    configuration.api_key_prefix['Authorization'] = 'GenieKey'
    configuration.host = '[https://api.eu.opsgenie.com|https://slack-redir.net/link?url=https%3A%2F%2Fapi.eu.opsgenie.com]
'
    configuration.debug = True
    configuration.proxy = '[http://webproxy.deutsche-boerse.de:8080|https://slack-redir.net/link?url=http%3A%2F%2Fwebproxy.deutsche-boerse.de%3A8080]
'

Set up 5 slack notifactions:
xbid + prod: xbid_prod_alerts
xbid + !prod: xbid_alerts
m7 + prod: m7_prod_alerts
m7 + !prod: m7_alerts
!m7 + !xbid: energy_glob_alerts



OMD[energy]:~/etc$ cat /omd/sites/energy/etc/environment
# Custom environment variables
#
# Here you can set environment variables. These will
# be set in interactive mode when logging in as site
# user and also when starting the OMD processes with
# omd start.
#
# This file has shell syntax, but without 'export'.
# Better use quotes if your values contain spaces.
#
# Example:
#
# FOO=""bar""
# FOO2=""With some spaces""
#https_proxy=""http://webproxy.deutsche-boerse.de:8080""3:48http_proxy=""http://webproxy.deutsche-boerse.de:8080""
https_proxy=""http://webproxy.deutsche-boerse.de:8080""
ftp_proxy=""http://webproxy.deutsche-boerse.de:8080""
no_proxy="".deutsche-boerse.de,.pnrad.net,.cedelgroup.com,.dbgcloud.io,localhost,127.0.0.1""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
provide SLA reports for March,XP-2857,94138,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,zi174,zi174,02/Apr/20 16:01,13/Aug/20 19:40,22/Feb/21 13:26,08/Apr/20 12:19,,,3.1.0,,,,,,,,,,,Business as usual,,gd553,uv683,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-1005,,,,,,,"06/Apr/20 15:50;uv683;XBID Performance and SM SLA Reporting March 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/82319/XBID+Performance+and+SM+SLA+Reporting+March+2020.xlsx","06/Apr/20 15:50;uv683;XBID Service Boundary Reporting March 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/82317/XBID+Service+Boundary+Reporting+March+2020.xlsx","06/Apr/20 15:50;uv683;XBID_Credit_points_report_March_2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/82318/XBID_Credit_points_report_March_2020.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,27648000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0akx3:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/20 15:50;uv683;Dear [~qm925],[~zi174] and [~gd553],

please find reports for March attached. Please note that that are block order transactions and block trades in sust. load seconds which inflated boudary report 4

J.","08/Apr/20 11:14;gd553;[~uv683] and [~zi174] - can it be that the Service Boundary report still contains data for older RTS scenarios? Can you please update and upload the report to SP? Let me know once I can review the report. Thanks.","08/Apr/20 11:19;gd553;[~uv683] - regarding your comment above - you mean that the tab ""sust. load seconds"" contains now much more data (lines)? Or do you mean something else? What do you mean with inflated boundary report 4? So you fixed the bug discovered last month?","08/Apr/20 11:32;zi174;Hi [~gd553],

these reports are not consolidated yet. Please work with the versions on sharepoint once I let you know. These are not final from our side. 

 

Regarding the second questions, yes the bug was fixed. ","08/Apr/20 11:34;gd553;[~zi174] - ok, waiting for your go.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Maven OWASP dependency plugin for xbid/develop,XP-2855,94107,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,02/Apr/20 12:32,04/Aug/20 19:53,22/Feb/21 13:26,15/Apr/20 09:52,,,3.1.0,XBID 2.0,,,,,,SECURITY,,,,"The {{org.owasp:dependency-check-maven}} plugin was implemented only in {{xbid-3.0.x}} branch.

 

Merge commits from {{xbid-3.0.x}} branch from XP-1261 to *{color:#0747a6}develop{color}*.

Fix if needed, try to minimize suppressions.

Integrate into Jenkins PR check.",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0al3z:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4211-perf-analysis-jh,XP-2903,XP-3055,master-xbid-2.0.36.x,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,XP-3233-acceptance-jgitflow,hotfix,prod,master-prod,XP-4122-perf-analysis,develop,master-acceptance,master,XP-2476,XP-2843-BR01,acceptance,XP-4250,XP-3233-prod-jgitflow,XP-4526-resource-managment-fix,XP-222-acceptance,xbid-2.0.36.x,XP-2843-BR07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UAT Agile Pilot support,XP-2851,94092,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tm431,tm431,02/Apr/20 09:29,13/Aug/20 19:41,22/Feb/21 13:26,16/Apr/20 15:09,,,3.1.0,,,,,,,,,,,"This is just first draft, where I will store some points for the smooth UAT phase. I will polish or add some steps later.

 

1) CHECK CERTIFICATES ON CUTEPX

we will do the time travel to 22/10/2020 and I think that most we will stay at cca 11/11/2020 we need to check if  during that time some certificates will not be expired. IF yes, can we prolong them?

2) Before the deployment on 6/4/2020 wee need to save CutePX DB snapshot, and have it ready for possible restora even. after 60days. So save it somewhere :)

3) We will have SIMU for one week 10/4 - 16/4 2020 we can test anything. For sure we will test 1.4 DC unavailable. And we can test e.g. anything on DB etc. anything what is needed. Any ideas?

4) Iona from network team must be ready, or any other members which can support the 1.4 testcases I will update the dates after I have the cofnirmation from clients

5) They requested LDIF from SIMU wiht SIMU db Restore to CutPX is this possible? Or we should force them that we will set pwds to default value.

 ",,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000000000030004000061r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),HOT Sprint 7,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Randomly failing CMM test in core module,XP-2850,94076,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,eh941,eh941,01/Apr/20 14:51,04/Aug/20 19:53,22/Feb/21 13:26,16/Apr/20 10:03,,,3.1.0,,,,,,,,,,,"Tests that inherits from {{AbstractAsyncBroadcastIntegrationTest}} randomly fail because of async broadcasts collection.

There must be some racing condition for that. Typical failure can be found in the attachment 
[^failing_test.txt]",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/20 14:50;eh941;failing_test.txt;https://jira.deutsche-boerse.com/secure/attachment/82137/failing_test.txt",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0albo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4211-perf-analysis-jh,XP-2903,XP-3055,master-xbid-2.0.36.x,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,XP-3233-acceptance-jgitflow,hotfix,prod,master-prod,XP-4122-perf-analysis,develop,master-acceptance,master,XP-2476,XP-2843-BR01,XP-4250,acceptance,XP-3233-prod-jgitflow,XP-4526-resource-managment-fix,XP-222-acceptance,xbid-2.0.36.x,XP-2843-BR07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze and fix Sonar configuration,XP-2847,94020,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,qo794,qo794,01/Apr/20 08:50,06/Nov/20 11:10,22/Feb/21 13:26,06/Apr/20 14:26,,,3.1.0,,,,,,,,,,,"Sonar reports 0% code coverage for AMS. Analyze and fix it. Also check that xbid project is configured properly and kotlin tests are correctly taken into account.

https://sonar.energy.dev.dbgcloud.io/projects?sort=-analysis_date",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/20 12:41;ll664;Screenshot_20200406_123935.png;https://jira.deutsche-boerse.com/secure/attachment/82306/Screenshot_20200406_123935.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,27820800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0akx3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Apr/20 12:41;ll664;Ad Kotlin tests - this was already verified and works with surefire/jacoco - see XP-1952.

 

Coverage (jacococ) has been added:

 

!Screenshot_20200406_123935.png!

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID CTPG cert is expired,XP-2840,93972,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,iv732,iv732,iv732,31/Mar/20 15:58,31/Aug/20 15:39,22/Feb/21 13:26,01/Apr/20 11:41,,,3.1.0,,,,,,,,,,,,,iv732,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28252800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0akd4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/20 15:58;iv732;Cert is requested.

ITSR:  5B3574","01/Apr/20 11:41;iv732;New cert is installed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add server certificates for CUTE environments to the Vault,XP-2839,93971,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,iv732,ub113,ub113,31/Mar/20 15:10,31/Aug/20 15:38,22/Feb/21 13:26,01/Apr/20 14:51,,,3.1.0,,,,,,,TechOpsBoard,,,,"Dear XBID TechOps,

Please download server certificates for XBID test environments and place them in Vault.

We need to monitor their expiry so that we prevent issues as described in XBID-5027 or XBID-5022

Thanks",,iv732,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2834,XP-2838,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0akcw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe A,,,CUTE A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/20 16:03;iv732;I have checked. The next expired one (except ctpg/h/j) is CTPK, on Aug 15 23:59:59 2020 GMT

Will import all of them in vault to monitor.","01/Apr/20 14:51;iv732;All certificates of XBID CUTE envs are now monitored in Vault",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve SFTP docker container for testing,XP-2831,93909,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,qo794,qo794,30/Mar/20 10:55,04/Aug/20 19:53,22/Feb/21 13:26,11/May/20 15:37,,,3.1.0,,,,,,,,,,,"Implement several improvements in docker containers to support better testing:
* sftp/scp - (semi)automatic sftp/scp configuration and users creation in CMI/SPM

Other improvements done:
* automatic http proxy setup for docker images build based on a local setup
* packages installation directly from internet, no packages in the project needed
* jenkins pull request job building images",,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24710400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040000f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,HOT Sprint 6 (S),HOT Sprint 8 (S),,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4211-perf-analysis-jh,XP-2903,XP-3055,XP-3230,master-xbid-2.0.36.x,XP-3161-develop,XP-3094-sonar-gate,XP-3070,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,fixing-failover,XP-3233-acceptance-jgitflow,hotfix,prod,master-prod,XP-2979-postgresql,XP-3264,XP-4122-perf-analysis,develop,XP-2232,master-acceptance,master,XP-2476,XP-4273-owasp-zap-enable,XP-2843-BR01,XP-4250,XP-3233-prod-jgitflow,acceptance,inline-tomcat-params,XP-3161-pom-cleanup-develop,XP-4526-resource-managment-fix,XP-222-acceptance,xbid-2.0.36.x,XP-2843-BR07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/May/20 15:37;od044;Test passed
- the script creates and imports SFTP/SCP configuration settings for specific TSO into CMI and SM 
- the script prepares folder in SFTP docker container for the TSO 

Detail of usage can find in README (in xbid-test project)

e.g.
{code}
> cd test-common
> ./src/main/resources/configure_party_sftp_scp.sh 10XDE-RWENET---W SFTP
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Installation of HIDS in XBID,XP-2829,93883,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,yo218,yo218,27/Mar/20 15:07,12/Aug/20 13:56,22/Feb/21 13:26,11/May/20 10:14,,,3.1.0,,,,,,03/Apr/20 00:00,,,,,"One of the missing security tools of XBID is HIDS. It need to be installed on all internet facing hosts:

XBCUTSCHA1
XBCUTSCOM1
XBCUTSPRX1
XBCUTSSSL1
XBCUTSWEB1
XBSIMUCHA1-2
XBSIMUCOM1-6
XBSIMUPRX1-2
XBSIMUSSL1-6
XBSIMUWEB1-6
XBPRODCHA1-2
XBPRODCOM1-6
XBPRODPRX1-2
XBPRODSSL1-6
XBPRODWEB1-6

internal and performance environments are also marked as to be onboarded in mega, but this should be challenged as they are not available via internet ",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/20 17:33;yo218;RE_ HIDS onboarding XBID.msg;https://jira.deutsche-boerse.com/secure/attachment/82440/RE_+HIDS+onboarding+XBID.msg",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24796800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s3s9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),HOT Sprint 7,HOT Sprint 8 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 06:53;yo218;I checked the existing firewall permissions and it looks like all required ports are open already","07/Apr/20 06:54;yo218;Onboarding process description: [https://confluence.energy.svc.dbgcloud.io/display/ET/4.6.3+HIDS+Onboarding]","07/Apr/20 07:41;yo218;Checked the available disk space for the required filesystem. For xbcutsssl1, xbsimussl1-6 and xbsimuweb1-6 I had to request another 10GB disk:
{noformat}
 [yo218@enprodauto1 ~/ansible/hids_agent]$ ansible -i test all -m shell -a ""vgs"" -b -k -K
SSH password:
SUDO password[defaults to SSH password]:
XBCUTSPRX1 | UNREACHABLE! => {
    ""changed"": false,
    ""msg"": ""Failed to connect to the host via ssh: Authentication failed.\r\n"",
    ""unreachable"": true
}
XBCUTSSSL1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   1   7   0 wz--n- 19.80g 1.01gXBCUTSCOM1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   7   0 wz--n- <59.51g 15.49gXBCUTSCHA1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   2   7   0 wz--n- 39.50g <18.43gXBCUTSWEB1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   9   0 wz--n- <39.80g 10.74g

[yo218@enprodauto1 ~/ansible/hids_agent]$ ansible -i simu all -m shell -a ""vgs"" -b -k -K
SSH password:
SUDO password[defaults to SSH password]:
XBSIMUCHA2 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   2   7   0 wz--n- 29.50g <10.43gXBSIMUCOM2 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g 10.40gXBSIMUCOM1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g <10.41gXBSIMUCHA1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   2   7   0 wz--n- 29.50g <10.43gXBSIMUCOM3 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g 10.40gXBSIMUCOM4 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g 10.40gXBSIMUCOM5 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g 10.40gXBSIMUPRX1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   1   7   0 wz--n- 29.80g <18.33gXBSIMUCOM6 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   7   0 wz--n- <24.80g 10.40gXBSIMUPRX2 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   1   7   0 wz--n- 29.80g <18.33gXBSIMUSSL2 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUSSL3 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUSSL1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUSSL4 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUSSL5 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUSSL6 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g 1.96gXBSIMUWEB1 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90gXBSIMUWEB3 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90gXBSIMUWEB2 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90gXBSIMUWEB4 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90gXBSIMUWEB5 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90gXBSIMUWEB6 | SUCCESS | rc=0 >>
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   2   8   0 wz--n- <24.80g <7.90g
{noformat}","07/Apr/20 13:42;yo218;After receiving the disk I made it available on the hosts:
{noformat}
ansible -i test all -m shell -a ""pvcreate /dev/sdb && vgextend rootvg /dev/sdb"" -b -k -K{noformat}
Installed hids on all cute machines:
{noformat}
ansible-playbook playbooks/os_agents.yml --limit @test.txt --tags hids -k -K {noformat}","07/Apr/20 14:06;yo218;Installed it on all Simu hosts in scope:
{noformat}
ansible-playbook playbooks/os_agents.yml --limit @simu.txt --tags hids -k -K {noformat}
I will monitor the behavior today and will check with GIS tomorrow whether is everything is running as expected before I proceed with production hosts","15/Apr/20 16:08;yo218;Installing the agents was not enough, those guys need to have a SAP CR in order to activate the agent. Raised it for Simu, waiting for a resolution now","15/Apr/20 17:57;yo218;I was not allowed to expedite the CR - it will just be implemented at the 24th of April. Prod will follow two weeks later I guess","24/Apr/20 15:10;yo218;Onboarding for Simu finished. I will verify the results next week and then proceed with Prod","30/Apr/20 08:56;yo218;Everything on Simu, Prod activation has been requested. CR: 44021322, scheduled for may the force","05/May/20 13:50;yo218;Activation on Prod was successful. Waiting for the confirmation inside the next report before I will close the ticket ","05/May/20 13:52;yo218;""internal and performance environments are also marked as to be onboarded in mega, but this should be challenged as they are not available via internet ""

I learned from GIS that they are planning to add the requirement but it is not official yet. So I just performed the installation and they activated the agents for those environments already","11/May/20 10:14;yo218;I checked the latest report which confirmed that HIDS onboarding finished successfully ",,,,,,,,,,,,,,,,,,,,,,,,,,
Agree on Development Framework with Customers,XP-2821,93868,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,27/Mar/20 12:35,02/Nov/20 13:06,22/Feb/21 13:26,28/Oct/20 12:47,,,3.1.3,,,,,,,XBID_Strategy,,,,,,jj069,rg535,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10108800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2779,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ajqg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/20 12:47;rg535;The customers decided to go back to the waterfall method and integrate some aspects of the agile model, such as: ad hoc calls, small changes in the scope without timeline impact, product progress demonstrations. They decided that they did not want to work in a completely agile way.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create Jenkins pipeline/playbook for ansible deployment,XP-2794,93808,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,qo794,qo794,26/Mar/20 14:17,04/Aug/20 19:53,22/Feb/21 13:26,08/Jul/20 13:15,,,3.1.0,,,,,,,,,,,"The current Jenkins pipeline [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy-ansible/] allows deploying only one component at a time, it is not possible to deploy the whole xbid. And other features are missing too. In general in this shape it's not possible to use it. See all possibilities we have with the current Jenkins deploy job: [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy%20form/]

Maybe something similar to M7? {{jenkins/deploy_full.groovy}}

 

Pipeline will contain env, dataset, infrastructure, modules, etc. 

This can be enriched when other modules are onboarded to ansible. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3262,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28684800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool - enhance SLA/KPI jobs to report processed records,XP-2793,93798,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,ll664,ll664,26/Mar/20 13:02,05/Nov/20 10:32,22/Feb/21 13:26,05/Nov/20 10:32,,,3.1.x,,SLA Report Tool,,,,,,,,,"Those jobs does not report total processed rows metric, in the dashboard, it's always zero.

https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/report-tool-jobs?orgId=4

See
{code}
collect-boundary-sla-data
collect-spm-files-generation-data
collect-performance-kpi-data
{code}",,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/20 10:14;tr866;screenshot-grafana.energy.svc.dbgcloud.io-2020.11.05-09_59_33.png;https://jira.deutsche-boerse.com/secure/attachment/89440/screenshot-grafana.energy.svc.dbgcloud.io-2020.11.05-09_59_33.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9417600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2531,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:ti",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Nov/20 12:05;ll664;Implemented and merged to {{develop}}, ready to test. I guest just a small shakedown would be fine, deploy to syt1, run the jobs and check total counts are reported in the dashboard:

https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/report-tool-jobs?orgId=4&var-environment=syt1&var-instance=All&from=now-24h&to=now","03/Nov/20 16:12;tr866;Tested on docker with versions XB 3.2.0-SNAPSHOT-ae1b8ce5bec3f3b74ae29fdd187ff716624e9c7e, Report Tool 2.50-SNAPSHOT-8714db2ae6a73ba8d65eca284f87bb7890abcc3a

As described on Confluence
 [https://confluence.energy.svc.dbgcloud.io/display/XBID/Testing+with+Docker#TestingwithDocker-ReportTool-SLA/KPIjobs-Verifyprocessedrecords]
 data could be verified for 2 import jobs *collect-boundary-sla-data* and *collect-spm-files-generation-data*
h4. Following data was entered as input data:
 # 1 cross-border trade for hourly contract
 # 1 local block trade
 # 1 unmatched order
 # 1 explicit allocation
 # 1 explicit participant ATC Data Request

h4. Resulting numbers were the following:
*computed_total* table filled by *collect-boundary-sla-data*: Comparison of Report Tool data with Records from Database
     
|collect-topology-data|{color:#00875a}*6*{color}|MAX_BORDERS
MAX_MARKET_AREAS|{color:#00875a}*3+3*{color}|
|collect-market-halt-data|{color:#00875a}*2*{color}|MARKET_HALT|{color:#00875a}*2*{color}|
|collect-added-orders-data|{color:#00875a}*7*{color}|ALL_ORDERS|{color:#00875a}*7*{color}|
|collect-order-transactions-data|{color:#00875a}*7*{color}|ALL_ORDERS_TRANSACTIONS|{color:#00875a}*7*{color}|
|collect-block-orders-data|{color:#00875a}*4*{color}|BLOCK_ORDERS|{color:#00875a}*4*{color}|
|collect-block-order-transactions-data|{color:#00875a}*4*{color}|BLOCK_ORDERS_TRANSACTIONS|{color:#00875a}*4*{color}|
|collect-trades-data|{color:#00875a}*4*{color}|ALL_TRADES|{color:#00875a}*4*{color}|
|collect-block-trades-data|{color:#00875a}*3*{color}|BLOCK_TRADES|{color:#00875a}*3*{color}|
|collect-explicit-allocation-requests-data|{color:#ff8b00}*0(?)*{color}|?(?)|{color:#ff8b00}*?(?)*{color}|
|collect-explicit-allocations-data|{color:#00875a}*3*{color}|EXPLICIT_CAPACITY_ALLOCATIONS|{color:#00875a}*3*{color}|

 
*computed_percentile* table filled by *collect-spm-files-generation-data* Comparison of Report Tool data with records from Database
     
|collect-spm-files-generation-data|{color:#00875a}*8*{color}|SPMFilesGeneration|{color:#00875a}*8*{color}|

 
Result:
need to check why collect-explicit-allocation-requests-data number was 0 when multiple types of ampq request were sent by explicit participant via Catrina test client

To do:
# make the the test on Syt1 environment
## version 2.51 of Report tool version deployed to Syt1
## same actions taken described above for docker as input data for Syt1 too. Input data entered 03.11.2020 around 16:20 CEST
## Waiting for tomorrow for execution of import jobs
# reproduce 0 numbers on older version of Report tool on docker
 ","04/Nov/20 15:48;tr866;Successfully reproduced on docker with version Report Tool 2.49 (/)
When the above mentionned jobs collect-boundary-sla-data and collect-spm-files-generation-data were ran records were successfully imported into the respective tables. Nevertheless the ""Written"" counter in the jobs' steps remained always 0.

Then retried again with the same data in XBID and with latest Report Tool  (/) 2.51-9131e12cc84160b497c9a479f41b50e66f4c8629 and this time the ""Written"" records were containing the number of rows again.

To do: (on)
Syt1 - Last time a zombie process of old report-tool was most probably overwriting the data so the values stayed 0 in Grafana. Couple of actions for input data were taken, again. Re-deployment of monitoring tool might be needed.","05/Nov/20 10:26;tr866;Successfully tested on Syt1 with version Report Tool 2.51
 As seen on the screenshot from Grafana, the 2 collector jobs that were executed successfully and collected data don't have 0 values for *totalProcessedRecords* anymore

!screenshot-grafana.energy.svc.dbgcloud.io-2020.11.05-09_59_33.png!

Also when checking records from Report Tool DB following can be observed:
 # collect-spm-files-generation-data job: in computed_percentile table number of records found for last day
{code:sql}
SELECT COUNT(*) AS ""Number of records for yesterday"" FROM computed_percentile WHERE row_inserted >= '2020-11-05 00:00:00' and row_inserted < '2020-11-06 00:00:00';
{code}
||Number of records for yesterday||
|25|
# collect-boundary-sla-data job: in computed_total table number of records found for last day
{code:sql}
SELECT COUNT(*) AS ""Number of records for yesterday"" FROM computed_total WHERE row_inserted >= '2020-11-05 00:00:00' and row_inserted < '2020-11-06 00:00:00';
{code}
||Number of records for yesterday||
|106|
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing server to be onboarded with Cyberark,XP-2783,93771,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,26/Mar/20 09:01,31/Aug/20 15:38,22/Feb/21 13:26,27/Mar/20 08:04,,,3.1.0,,,,,,31/Oct/19 00:00,SECURITY,,,,"|-XBSIMUAMQ3-|
|-XBSIMUAMQ1-|
|-XBSIMUAMQ4-|
|-XBSIMUAMQ2-|
|XBSIMUECP2|
|XBSIMUECP1|
|XBSIMUEHA1|
|XBSIMUEHA2|
|XBSIMURTS1|
|XBSIMURTS2|",,yo218,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2907,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28684800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aj5c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/20 08:04;yo218;Changed the root password on the hosts and send the list to PAM group. All hosts are onboarded now",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SCP on docker not working out of the box,XP-2780,93708,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,qo794,qo794,24/Mar/20 15:24,31/Aug/20 15:38,22/Feb/21 13:26,24/Mar/20 16:12,,,3.1.0,,CMM,,,,,,,,,In order to make SCP work out of the box in our docker ecosystem without any manual step it's necessary to add a xbid-sftp docker image ssh public key to known_hosts to the cmi docker image.,,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28857600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0air4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Mar/20 16:12;od044;Test passed on docker 2.0.36-SNAPSHOT-c43f21e25f9858d1a85345ea00b71869f7f9e0a1
- ssh key is added into known_host in cmi container ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Include Report Tool logs in Kibana,XP-2776,93638,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,23/Mar/20 09:22,31/Aug/20 15:38,22/Feb/21 13:26,25/Mar/20 14:22,,,3.1.0,,,,,,,,,,,"Hosts:
{code}
xbprodsla1
xbprodsla2
{code}

Instances:
{code}
xbid-prod-report-tool1
xbid-prod-report-tool2
{code}
",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28771200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000000003000400002",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/20 14:15;qo794;It's already there, only a different index as it's not a tomcat instance, you have to select *xbid-sla\** index:
https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-12h,mode:quick,to:now))&_a=(columns:!(logline,beat.hostname),index:xbid-sla,interval:auto,query:(language:lucene,query:'beat.hostname:xbprodsla2+OR+beat.hostname:xbprodsla1'),sort:!('@timestamp',desc))","25/Mar/20 14:22;ll664;Thanks Kamil, didn't there's a separate index, closing then.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove obsolete CapacityType#ATC,XP-2772,93587,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,qo794,qo794,20/Mar/20 08:45,04/Aug/20 19:53,22/Feb/21 13:26,01/Apr/20 08:53,,,3.1.0,,CMM,,,,,,,,,"{{com.deutscheboerse.energy.cmminteg.api.file.ContainsCapacities.CapacityType#ATC}} is obsolete, never used, it can be removed together with the whole enum {{CapacityType}} and also related enum in core:
{code:java}
com.deutscheboerse.energy.m7.cmm.CapacityInput.CapacityType
{code}",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29289600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ai00:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Access to email address expiration_alert@xbid-test.deutsche-boerse.com and expiration_alert@deutsche-boerse.com,XP-2768,93563,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,19/Mar/20 12:36,13/Aug/20 19:41,22/Feb/21 13:26,24/Mar/20 10:36,,,3.1.0,,,,,,,,,,,"Please create an access to the email address mentioned in the summary.

 

Thanks",,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/20 15:25;yo218;image-2020-03-23-15-25-35-733.png;https://jira.deutsche-boerse.com/secure/attachment/81797/image-2020-03-23-15-25-35-733.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28944000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahv4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/20 15:25;yo218;The mail server has been setup to forward all mails to this account to the mailboxes which requested access:
{noformat}
expiration_alert@xbid-test.deutsche-boerse.com          niklas.albers@deutsche-boerse.com, jakub.musil@deutsche-boerse.com, malina.raluca.solomon@deutsche-boerse.com, patrik.cupak@deutsche-boerse.com, ana.kovacevic@deutsche-boerse.com, alexandr.radecky@deutsche-boerse.com, simona.hristova@deutsche-boerse.com {noformat}
I created a jenkins job which will give you the opportunity to send the customer an email with [expiration_alert@xbid-test.deutsche-boerse.com|mailto:expiration_alert@xbid-test.deutsche-boerse.com] as senders address: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-Dev/job/XBID-AMS-Undeliverable-Notification/]

!image-2020-03-23-15-25-35-733.png!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Finish Guardium integration ,XP-2766,93561,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ei349,ei349,19/Mar/20 11:37,12/Aug/20 13:56,22/Feb/21 13:26,08/Apr/20 17:53,,,3.1.0,,,,,,,,,,,"XBPRODEDB1

XBPRODPDB1

XBPRODPDB2

XBPRODPDB3

XBPRODPDB4

XBPRODSLA1

XBPRODSLA2",,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,27561600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000000000030004000063",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Apr/20 15:47;yo218;XBPRODEDB1
XBPRODPDB1
XBPRODPDB2
XBPRODPDB3
XBPRODPDB4 

are already onboarded. Only outstanding hosts are xbprodsla1/2","08/Apr/20 17:52;yo218;[Ionut Alexandru|https://app.slack.com/team/U48P67UQH] confirmed via Slack that the hosts xbprodsla1/2 are onboarded now",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automatic Jenkins/Ansible DB-Scan for CMS (XBID Databases),XP-2761,93550,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ei349,ei349,19/Mar/20 10:50,13/Aug/20 20:12,22/Feb/21 13:26,01/Apr/20 18:10,,,3.1.0,,,,,,,,,,,"FYI: *[~cs687]* did the same for m7

*Original wording:* 

In the past we created a whole overview about all XBID/M7 Databases in a manually way. 
 Updated List is currently uploaded in ticket 
 https://jira.deutsche-boerse.com/browse/TECHLOG-3213

In the future we need an automatic way via Jenkins/Ansible to detect all the databases which are currently running in M7 and generate a csv-file out of these collected information's.

The csv file has to upload to the
 * Server: lux-ftpoa.oa.pnrad.net
 * Location: /Databases/In
 * User: batchmonft

The private key will be provided from the IT Asset Management Team.

*Why we are doing that?*
 The plan is to provide them daily these generated information´s. When they are receiving this csv.file from us they will load the information´s to ""CMS"". In case we will not upload it, they will expect that the Databases are decommissioned and label them as ""not in use""

*How we could do it?*
 all our database hosts are supposed to detect via ""hosts: postgres"". So we have to prepare a ansible-job (for example db-report) which are detecting all the necessary information´s.
 An related solution can be also found with the role ""vm-report""

So we could collect all the necessary information´s and create yml file and with a script we can convert it afterwards in a csv-file and upload it.

The whole job can be triggered with Jenkins.

Once we have a proper solution we will also have it for XBID.
 It´s more an shared product ticket.",,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/20 18:07;yo218;Asset_Inventory_DB_from_EGXB.csv;https://jira.deutsche-boerse.com/secure/attachment/82147/Asset_Inventory_DB_from_EGXB.csv",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahvb:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/20 15:03;yo218;{noformat}
[yo218@enprodauto1 {db_scan L | +2} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/report_db.yml --limit xb*pdb* -k -K {noformat}
 ","01/Apr/20 18:10;yo218;[https://github.deutsche-boerse.de/dev/energy.automation.deployments/compare/db_scan?expand=1]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OpsGenie - provide estimate for full migration from AlarmTilt,XP-2760,93549,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qm925,ei349,ei349,19/Mar/20 10:48,13/Aug/20 19:41,22/Feb/21 13:26,01/Apr/20 10:56,,,3.1.0,,,,,,,,,,,"[~rg535] added a comment - 03/Mar/20 14:37 - edited
Dear Jiri,
Please could you coordinate this item with Malina. See my comment from 31. January. We need to get the overall, rough estimates so we can run through the business case for this item. Thanks, Suzanna",,eh941,ei349,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,26352000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2649,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeyv:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/20 15:09;eh941;I had to do more detailed analysis in order to do the estimation.

I have to say first that *opsgenie is very different* and it *impossible to migrate from AlarmTilt to opsgenie without noticing*. To be more precise I put down the main features and how they differ when using opsgenie.
h2. AlarmTilt used features

AlarmTilt itself is able to:
 * Trigger an event by it's name
 * Trigger individual or all PXs events - they differ by the recipients - AlarmTilt provides rules which are used to determine the recipient of the messages.
 * Send and email with pre-defined subject and body. There is a template for that and it's very versatile.
 * Defining user groups - these are assigned to the events instead of individual emails/users
 * There is other protection against overwhelming on AlramTilt side. It's defined in the UI. This feature is used for the cases in which so called _Flooding Protection_ doesn't work well - e.g. throttling limit alerts which are affected by the both inquiry nodes and each of them has it's own _Flooding Protection_.

In opsgenie there is simply no exact reproduction of this process. In order to accomplish as similar as possible result I suggest following setup.
h2. Recommended Setup

Each PX has a single user with role {{User}}. This user has assigned multiple email addresses and phone numbers and specifies the notification rules - which emails should be used, what numbers SMSed or called. This user is able to login and see the alerts listed in the system and their history. Alternatively it's possible to create more such users instead of just assigned emails in order to allow each particular person to log in with their own credentials.

The users should be assigned to a team. I suggest to create a team for each PXs and one extra team for all PXs.

There must be a new so called *Integration created*. Using JSON API should be the right approach.

In order to get the notification all team member immediately *it's crucial to change the settings of the escalation*. It is done in Team section -> On-call.
h3. Creating Alerts

When creating alerts in the application there must be filled in:
 * Alert name
 * Alert description
 * Recipients - either a team representing individual PX or a team for all PXs

There is an existing SDK for java. It doesn't support the full blown API functionality (I suppose that via the API it's possible to change literally everything that is possible via the Web GUI) but the alerting part is there.
h3. Covering the features

Following table shows how the features described in the beginning are covered by opsgenie.
||Feature Name||How to handle it with opsgenie||Resolution||
|Trigger an event by it's name|An Alert with whatever name can be called|{color:#00875a}OK{color}|
|Trigger individual or all PXs events - they differ by the recipients|Each PX can be represented as a team. When a new alert is called there can be specified recipients via teams or individuals. For individual PXs only the matching team would be filled in, for all PXs events a All PXs team can be filled.|{color:#00875a}OK{color}|
|Send and email with pre-defined subject and body. This matches the procedure's name|The email body nor subject can be changed. The incoming message looks like shown bellow|{color:#de350b}Impossible {color}|
|Defining user groups - these can be assigned to the events|Each PX can be represented as a team|{color:#00875a}OK{color}|
|There is other protection against overwhelming on AlramTilt side. It's defined in the UI. This feature is used for the cases in which so called _Flooding Protection_ doesn't work well - e.g. throttling limit alerts which are affected by the both inquiry nodes and each of them has it's own _Flooding Protection_.|There is no such mechanism|{color:#de350b}Impossible{color}|

There are some {color:#de350b}non-covered features{color}. It could be partly done using different concept of opsgenie setup.
h3. Alternative setup covering (almost) all features

For the both - protection against overwhelming and for email formatting, incidents might be used.

Incident is grouping entity for multiple alerts. If an alert with matching criteria is created multiple times only one incident is created until the incident is closed. The downside of this solution is a need for closing the incidents - either automatically or manually - otherwise only one alert is created for the specific event. This can be done automatically via API but there is a problem - the API Java client doesn’t support it - but the API itself does. It would lead to custom implementation.

When using incidents *stakeholders* for which the email template can be changed can be used. On the other hand stakeholders don't support voice call alerts. The template is editable but there are still some things that *can't be changed* - there is always opsgenie logo.

{color:#de350b}*Using this concept the estimate would increase by 21 story points - is its really that important?*{color}
h2. What needs to be done to migrate

Following steps must be done in order to fully migrate to opsgenie:
||Description||Story Points||
|Setup the users, teams and escalations in opsgenie|3|
|Create a clone of alarmtilt-adapter that uses opsgenie SDK. There are some technical features features like flooding protection, multiproxy support and persistent event calls which needs to be adopted|8|
|Update all modules that use alarmtilt-adapter to use the opsgenie. It's 5 modules.|2|
|Create an alternative to AlarmTilt-client. It's a fat jar client used for operations' base events|2|
|Create a script that setup opsgenie. With AlarmTilt all setup is done in Web GUI. Even though the setup with opsgenie is much more intensive on the web gui side it would be good to have this done by some script or rather application. Now pretty much every environment account has very different setup - different group name, rule names. It's very error prone. 
  
 It would be nice to have let's say yaml file with the setup - users, teams, emails - and with one command execution setup the opsgenie - this wasn't possible with AlarmTilt|5 (Optional)|
|Testing|5|
||Total||~ 21+ (25 as sum)||
||When using alternative approach (see above)||~ 40 +||
h2. Others
h3. How opsgenie Alert looks like

As said before *{color:#de350b}this can't be changed.{color}*

The following alert was created using
 * Name = Test Alert 12
 * Description = This is a description of test alert 12

*Subject*
 Opsgenie Alert: Test Alert 12

*Body*
 Description: This is a description of test alert 12
 Responders: 
 Details: 
 Source: frantisek.odehnal.ext@deutsche-boerse.com
 Integration: Franta-Testing_API (API)
 Created At: 27.3.2020 13:46:15
 Tags: 
 Id: e741a039-e74a-4b22-ad02-97bdccbc57df-1585313175387
 TinyId: 5251
 Show Alert

 ","30/Mar/20 11:25;eh941;h2. Impact Analysis

There is no way that we migrate to opsgenie and the customers don't notice it.

Here's a list of changes:
 * The customers' users must be migrated. The customers have typically one PX user in AlarmTilt. This user must be created in opsgenie.
 * The customers' users will use different interface for logging in
 * The email and SMS notifications will be different - there is *no way how to customize the emails nor SMS text bodies*, nor subjects. The example how the email looks like with opsgenie is listed bellow.
 * *The sender* of the emails and SMS messages is different - it might be important if they have any automatic rules based on sender for email management
 * *Some notifications can be triggered 2-3 times* instead of once - AlarmTilt has a feature for that they call ""Simultaneous launches"". This affects only events on double sided environments that are triggered on multiple nodes - like SOB Short throttling limit exceeded, RabbitMQ broadcast queue has exceeded threshold value etc. This feature was introduced with AlarmTilt (or has been used by us) only for an year now.

h2. Estimation

The time needed for the migration is estimated to +*25 story points.*+

It includes:
 * Setup the users, teams and escalations in opsgenie
 * Create a clone of alarmtilt-adapter that uses opsgenie SDK. There are some technical features features like flooding protection, multiproxy support and persistent event calls which needs to be adopted
 * Update all modules that use alarmtilt-adapter to use the opsgenie. It's 5 modules.
 * Create an alternative to AlarmTilt-client. It's a fat jar client used for operations' base events
 * Create a script that setup opsgenie.
 * Testing

h3. How opsgenie Alert looks like

As said before *{color:#de350b}this can't be changed.{color}*

The following alert was created using
 * Name = Test Alert 12
 * Description = This is a description of test alert 12

*Subject*
Opsgenie Alert: Test Alert 12

*Body*
Description: This is a description of test alert 12
Responders: 
Details: 
Source: frantisek.odehnal.ext@deutsche-boerse.com
Integration: Franta-Testing_API (API)
Created At: 27.3.2020 13:46:15
Tags: 
Id: e741a039-e74a-4b22-ad02-97bdccbc57df-1585313175387
TinyId: 5251
Show Alert","22/Apr/20 16:01;ei349;[~gd553], [~rg535], [~qm925]please check the output from the team regarding the OpsGenie. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GIANT ANTEATER monitoring,XP-2759,93548,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,19/Mar/20 10:45,13/Aug/20 19:41,22/Feb/21 13:26,07/Apr/20 15:31,,,3.1.0,,,,,,,,,,,"We need to find enduring solution for monitoring and restoration of *GIANT ANTEATER*. 
 * Change default endpoint of GA to check all data sources like DB, LDAP (it's implemented - reuse) and return 1/0 values if up or down. 
 * include slack channel alert to xbid_prod_alerts

[~ek176] have already some ideas. ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29376000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2531,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000000000030004000061i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,HOT Sprint 6 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2759,netbackup-role,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New jenkins node label for parallel job executions,XP-2758,93540,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eh941,eh941,19/Mar/20 09:44,13/Aug/20 19:41,22/Feb/21 13:26,28/Apr/20 15:21,,,3.1.0,,,,,,,,,,,"Currently when a pipeline job is executed it's executed on quite _expensive_ node englobwkr. This job doesn't do anything but waits until the pipeline stages/steps finish. 

For this there could be a special worker label that allows let's say 150 parallel jobs. There is no need to have there docker installed since it would execute any real stuff (maybe maven would be handy though)",,eh941,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29376000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300044",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),Alpha Sprint 6,Alpha Sprint 7 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
(Split 1) P3P5-V1 - Lacking validation of the server certificate,XP-2757,93539,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,zi174,zi174,19/Mar/20 09:39,04/Aug/20 19:53,22/Feb/21 13:26,27/May/20 13:50,,,3.1.0,,,,,,,PenetrationTest,,,,"|FINDING: P3P5-V1|
|LOCATION: Client component|
|RISK: High|

|Description:
The assessment showed that an attacker is able to intercept the communication between the ComTrader client and the profile server. This way, he can obtain login credentials and thus gain unauthorized access to the application.
 The data transmitted between the client and the server is protected with TLS to ensure confidentiality and integrity. However, it is possible to perform a man-in-the-middle attack as the client does not verify the server certificate. Therefore, an attacker can present a fake certificate to the client to then intercept the communication between the client and the server.
 Consequently, the attacker is able to obtain the following information:
 • username
 • password
 Example
 Intercepted request containing the base64-encoded application username and password:
 POST /xbid-simu/services/RemoteProfileServiceV3 HTTP/1.1
 Content-Type: text/xml; charset=UTF-8
 Accept: */*
 Authorization: Basic VUxUUkFCT0I6Q2██████████████
 SOAPAction: """"
 User-Agent: Apache-CXF/3.1.14
 Cache-Control: no-cache
 Pragma: no-cache
 Host: simu1.profiles.xbid.deutsche-boerse.com:60104
 Connection: close
 Content-Length: 278
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfile xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><arg0>XSOBv1</arg0><arg1>ULTRABOB</arg1><arg2>simu</arg2></ns2:loadProfile></soap:Body></soap:Envelope>
 

|*Threat:* As an attacker is able to intercept the communication between the client and the server, the login credentials for the ComTrader application are exposed to the attacker. He is thus able to access the ComTrader application and query data depending on the role of the targeted user without being authorized.|

|*Recommendation:* We recommend validating the TLS certificate of the server in the client component when establishing the connection. To do so, the client should check whether the server certificate
 • has been issued by the CA known to the client,
 • if it has been issued to the host name of the server
 • and if it is still valid.
 To also ensure the integrity and confidentiality of the connection in case the CA is compromised or if an attacker manages to obtain a certificate in the server’s name from the CA, we recommend carrying out an additional “pinning” of the server certificate. In practice, this can lead to the fact that the client has to be updated every time the server certificate is changed.
 For more information on certificate pinning, please refer to:
 • https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning|
|

 ",,ek176,zi174,,,,,,,,,,,,,,,,,,,XP-3205,,,,,,,,XP-3071,,,XP-3350,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21081600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ar3j:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,comtrader-2.5.x,master-comtrader-2.5.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"27/May/20 10:29;ek176;So far, the CN check is disabled by default (to preserve current behavior and not break CT).

 

To turn *ON* the CommonName TLS check, use:

{{ *-Djavaws.com.deutscheboerse.comxerv.comtrader.ctpSslCertCommonNameCheckDisable=false* }}

 

The TLS CN check enabling should be done in more steps:
 # Make sure the ProfileStorage DNS name conforms to the certificate. Currently NOT TRUE for: syt2, SIMU
 ## If *yes*,
 ### Disable the {{*ctpSslCertCommonNameCheckDisable* }}settting in JNLP for the correct env
 ### Release new CT and verify
 ## If *NOT*, there is a window when the ProfileStorige might not work (but local will be used) 
 ### After consulting with [~iv732], we should use wildcard cert{{ *.xbid.deutsche-boerse.com }}
 ### The ProfileStorage's cert can be changed with no impact, as no CN check is performed so far.
 ### We need to change the server's name to conform to cert's wildard CN (Note:{{ syt2.profile.xbid.deutsche-boerse.com}} is not correct, has to be {{syt2_profile.xbid-deutsche-boerse.com}}) (Note: Issuing another cert and/or changing DNS record is external dependency – takes a long time)
 ### Update ComTrader's JNLP config with correct ProfileStorage endpoints, release and verify
 ### Disable the {{*ctpSslCertCommonNameCheckDisable* }}setting in the JNLP config for the env
 ### Release and verify

 ","27/May/20 14:05;ek176;Connection to SIMU: CN Check disabled:

 
{code:java}
2020-05-27T13:58:01.189+0200 [trader-Worker-9] WARN c.d.c.c.s.r.RemoteServiceProxy - [INSECURE] SSL Profile Storage CommonName check is disabled. Certificate issued for another endpoint will be accepted.
2020-05-27T13:58:01.238+0200 [trader-Worker-9] INFO c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://simu1.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/services/RemoteProfileServiceV3
2020-05-27T13:58:01.308+0200 [trader-Worker-9] INFO o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-05-27T13:58:02.376+0200 [trader-Worker-9] INFO c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-05-27T13:58:02.430+0200 [trader-Worker-9] INFO c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-27T13:58:02.434+0200 [trader-Worker-9] INFO c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/DBAGSOBR exists, attempting to load it.
2020-05-27T13:58:02.524+0200 [trader-Worker-9] INFO c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
{code}
With check enabled (local profile is used):
{noformat}
2020-05-27T14:03:33.760+0200 [rader-Worker-48] ERROR c.d.c.c.s.p.LocalAndRemoteProfileService - Could not load profile.
com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.ProfileServiceException: Remote profile service connection error: 
Check the connection settings or remote service status.


Caused by: java.io.IOException: IOException invoking https://simu2.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/services/RemoteProfileServiceV3: The https URL hostname does not match the Common Name (CN) on the server certificate in the client's truststore.  Make sure server certificate is correct, or to disable this check (NOT recommended for production) set the CXF client TLS configuration property ""disableCNCheck"" to true.
{noformat}","09/Jun/20 13:33;ek176;Tested on SYT2 with the following scenario:
||Scenario||-D profileStorageUrl||-D ctpSslCert
 CommonName
 CheckDisable||CTP||CT GUI||CT Logs||
|Current (should proceed, as CN check is off)|https://xbinteweb1:60806/profile-storage/services/|true|Remote|OK|2020-06-09T13:21:33.084+0200 [trader-Worker-2] WARN c.d.c.c.s.r.RemoteServiceProxy - [INSECURE] SSL Profile Storage CommonName check is disabled. Certificate issued for another endpoint will be accepted.
 2020-06-09T13:21:33.850+0200 [trader-Worker-2] INFO c.d.c.c.s.r.WebServiceFactory - Remote operation \{[http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/]}
ping returned 200|
|Enable CN check (should fail as the CN does not match)|https://xbinteweb1:60806/profile-storage/services/|false|Local (fallback)|Caused by: java.io.IOException: IOException invoking [https://xbinteweb1:60806/profile-storage/services/RemoteProfileServiceV3:] The https URL hostname does not match the Common Name (CN) on the server certificate in the client's truststore. Make sure server certificate is correct, or to disable this check (NOT recommended for production) set the CXF client TLS configuration property ""disableCNCheck"" to true.|Caused by: java.io.IOException: The https URL hostname does not match the Common Name (CN) on the server certificate in the client's truststore. Make sure server certificate is correct, or to disable this check (NOT recommended for production) set the CXF client TLS configuration property ""disableCNCheck"" to true.
 at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.onFirstWrite(HTTPConduit.java:1309)
 at org.apache.cxf.transport.http.URLConnectionHTTPConduit$URLConnectionWrappedOutputStream.onFirstWrite(URLConnectionHTTPConduit.java:307)
 at org.apache.cxf.io.AbstractWrappedOutputStream.write(AbstractWrappedOutputStream.java:47)
 at org.apache.cxf.io.AbstractThresholdOutputStream.write(AbstractThresholdOutputStream.java:69)
 at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.close(HTTPConduit.java:1358)
 ... 29 common frames omitted|
|CT endpoint NXDOMAIN (should fail as the endpoint is not reachable)|https://syt2.xbid.m7.deutsche-boerse.com:60806/profile-storage/services/|false|Local (fallback)|Caused by: java.net.UnknownHostException: UnknownHostException invoking [https://syt2.xbid.m7.deutsche-boerse.com:60806/profile-storage/services/RemoteProfileServiceV3:] syt2.xbid.m7.deutsche-boerse.com|Caused by: java.net.UnknownHostException: UnknownHostException invoking [https://syt2.xbid.m7.deutsche-boerse.com:60806/profile-storage/services/RemoteProfileServiceV3:] syt2.xbid.m7.deutsche-boerse.com|
|CT: Added host to /etc/hosts (should proceed and check CN)|https://syt2.xbid.m7.deutsche-boerse.com:60806/profile-storage/services/|false|Remote|OK|2020-06-09T13:07:54.769+0200 [rader-Worker-23] INFO c.d.c.c.s.r.WebServiceFactory - Remote operation \{[http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/]}
loadProfile returned 200|

 ","09/Jun/20 13:37;ek176;Next steps:
 * Wait for the syt2_profiles.xbid.deutsche-boerse.de (internal env; .com is not possible) DNS record
 * Wait for [simu|prod][12]_profiles.xbid.deutsche-boerse.com DNS record
 * Update configs (seamless)
 * Release CT
 * Verify the new CTP storage endpoints work for simu/prod/syt2
 * Enable CN check on SYT2 (verify)
 * Prepare for SIMU and PROD to enable CN check (when customer is to get new CT release).
 ** Change/verify endpoints
 ** Verify CTP Remote works
 ** Enable CN check (-D param)
 ** Verify CTP Remote works
 ** Change default config

Last step: CN check enabled by default (remove ctpSslCertCommonNameCheckDisable from configs).","09/Jun/20 14:18;ek176;Possible improvement (visible by customer): The GUI message is misleading on CN check fail: _Invalid username or password._

The correct should be: _Invalid certificate_ or _Cannot accept certificate_.

This can be changed to reflect the fact. However,
 * the correct info is in the _Details_
 * Customers should never get an incorrect CT release with incorrect CN

Resolution: Won't fix","22/Jun/20 15:59;ek176;ComTrader 2.5.1.64 was released, contains:
 * new endpoints for:
 ** SIMU
 ** PROD
 ** SYT2 (.de)
 * certificate check enabled for:
 ** SIMU

Please test connection (Profile server) on:
 * SIMU (check CN of the cert)
 * SYT2 (CN check disabled – cert issued for .com domain, not .de)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix failing test RefdataServiceImplTest#shouldFetchBordersIds,XP-2753,93500,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,qo794,qo794,18/Mar/20 12:49,04/Aug/20 19:53,22/Feb/21 13:26,20/Mar/20 15:01,,,3.1.0,,CMM,,,,,,,,,"The following test is failing after moving from H2 to Postgresql testcontainer, however locally executed as a single test it works:

com.deutscheboerse.energy.cmminteg.service.RefdataServiceImplTest#shouldFetchBordersIds",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29462400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeyv:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Technical LDAP user invalid credentials after default pwds are set ENDURING solution,XP-2751,93488,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tm431,tm431,tm431,18/Mar/20 07:23,13/Aug/20 19:41,22/Feb/21 13:26,25/Mar/20 09:48,,,3.1.0,,,,,,,,,,,"When executing setting of default PWDs fro all users for customer facing envs. (which is standard DB service under e.g. ASR015, or during DST tests) technical LDAP users in both XBID and SPM trees get invalid credentials and applications (xbid and spm) cannot change pwds for users. This happens quite often. There is sometime also problem with *{color:#1d1c1d}Sounds like missing acl{color}* which I have no idea what that is, some policy? But this should be also prevented

 

 
 * we need to find some enduring solution it could be e.g. Confluence page with description because not all guys can find out the technical users, or does not know their pwd which application uses. Or introduce some one click solution (jenkyns job? ) depends how much time we want to invest into it. For me simple Confluence wiki page will be ok (sorry if it exists already)
 * This should be done for following envs. SIMU, LIPA, LIPB, CUTEPX, CTSO
 * Part of this must be also test, executed for e.g. standard users SADMIN01 in Xbid, and SPMADM01 in spm, where pwd will be changed and then by jenkyns job se again to default pwd.

 

*smthing like this should be spred between all techps*

 
 Changed the passwords of the user xbid-cute-adm in xbid and sm tree to test01. And added the missing aci line to both trees:
{noformat}
(targetattr = ""*"")(target=""ldap:///ou=cute,o=xbid,dc=energy,dc=test"") (version 3.0;acl ""acl-xbid-cute-adm"";allow (all)(userdn = ""ldap:///uid=xbid-cute-adm,ou=cute,o=xbid,dc=energy,dc=test"");)

(targetattr = ""*"")(target=""ldap:///ou=cute,o=sm,dc=energy,dc=test"") (version 3.0;acl ""acl-xbid-cute-adm"";allow (all)(userdn = ""ldap:///uid=xbid-cute-adm,ou=cute,o=sm,dc=energy,dc=test"");){noformat}
 *{color:#1d1c1d}AC:{color}* 

{color:#1d1c1d}- summarize tutorial to confluence page visible for other colleagues {color}",,ek176,qo794,tm431,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28857600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahvb:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Mar/20 16:10;yo218;[https://confluence.energy.svc.dbgcloud.io/display/ET/Customer+LDAP] 

I just decided to modify a ldap jenkins job in order to allow modifying all passwords at once automatically. The above mentioned confluence page (chapter 6) just describes how to use it:

In case we have to reset all passwords to a default one and to change the expiration date (it happens for example during DST tests), we can use a jenkins job for it: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/XBID%20Customer%20LDAP/]

The job has to be executed twice (for both trees, sm and xbid).

Example for CuTe PX:

!https://confluence.energy.svc.dbgcloud.io/download/attachments/10460896/image2020-3-24_16-5-25.png?version=1&modificationDate=1585062326047&api=v2|height=250!

!https://confluence.energy.svc.dbgcloud.io/download/attachments/10460896/image2020-3-24_16-5-50.png?version=1&modificationDate=1585062350397&api=v2|height=250!","24/Mar/20 16:12;yo218;You will also be able to execute this job now. Would you like to try it tomorrow during DST rollback?","25/Mar/20 07:35;tm431;Wow, looks very good. And it is perfect that also we can use this. Unfortunately they did not request to set deafualt pwds for today :( so we cannot try.

 

just to be sure. technical users are not affected right?","25/Mar/20 09:48;yo218;the ldap admin ""xbid-\{env}-adm"" and HEALTH_CHECKER (used for AlarmTilt) won't be touched with this job",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Quartz table zombies CMI deployment and ENDURING solution,XP-2750,93487,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hj444,tm431,tm431,18/Mar/20 07:14,04/Aug/20 19:53,22/Feb/21 13:26,30/Mar/20 11:03,,,3.1.0,,,,,,,,,,,"More info has Jakob Hesoun or Kamil Nezval

 

When there is deployment of xbid > 2.0.25.9 or > or agile pilot xbid > 2.32 and some Zombies in Quarz tables exists. We need to delete the tables by attached quartz.sql

But these tables could be delete only by *DEDICATED DB user*, not the standard one. *{color:#403294}script should be run as ""xbcutcmi"" user and not as general ""postgres"".{color}*

We need to find out some enduring solution

We faced the situation that deploymnet to CutePX was not successful (CMI did not start) as the tables were not properly deleted, we needed then another DB restore (due to time travel) and next deployment.

 
 * analyze how this situation can be prevented forever
 * introduce some solution at first it can be e.g. confluence page what user must be used with wihich credentials or just use standard DB user?
 * should we do it with new property which will always run the script or should we just analyze why zombies exists?

 

 

*Acceptance Criteria:* 
 * identify zombie records in quartz tables
 * create script to delete just zombie jobs

 

 

Dedicated DB user",,ek176,hj444,ll664,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Mar/20 07:10;tm431;quartz.sql;https://jira.deutsche-boerse.com/secure/attachment/81650/quartz.sql",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28598400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeyv:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Mar/20 13:32;ll664;The root cause of the problem was that two DB tables got out of sync:
- {{tbxi010_distribution_scheduler_map}} - stores periodic scheduling mapping for files
- {{qrtz_triggers}} - stores Quartz (scheduling framework) triggers that corresponds to out scheduler mappings

So our scheduler mapping got (somehow) deleted, but the record in {{qrtz_triggers}} remained. After the domain model change in 2.0.25.5, the deserialization errors started to appear.

The measure to militate this was to that CMI on startup deletes those zombies that cannot be deserialized.

Test steps:

1. Start XBID 2.0.25.4 and create scheduler mapping
2. Stop XBID and delete that mapping manually from DB table  {{tbxi010_distribution_scheduler_map}}. The corresponding (now zombie) trigger remains in {{qrtz_triggers}}.
3. Start latest develop.
4. Check logs that no deserialization errors occured on startup.
5. Check {{qrtz_triggers}} tables, the zombie trigger should be gone.


","27/Mar/20 15:41;hj444;tested docker :
XBID :
-- xbid-test project : in pom xbid version :  2.0.25.4_ - build, run dockers
- File management - create new File configurations - with Event (DE-FR) scheduler and Distribution scheduler (AMP-APG, DE-FR)
- Verify in DB CMI tables _
** tbxi010_distribution scheduler_map =>2 new configured schedulers added
** tbxi010_distribution event_map => 1 new configured event added
** tbxi_011_distribution scheduler_map_history =>2 new configured schedulers added
** qrtz_triggers : 2 rows for distribution schedulers added
- STOP_ xbid-cmi-1 
- Delete from : tbxi010_distribution scheduler_map =>both rows - 2 new configured schedulers 
- Verify 
** tbxi_011_distribution scheduler_map_history =>2 configured schedulers are present
** qrtz_triggers : 2 rows for distribution schedulers are present
- xbid-test project : change version in pom to latest snapshot for xbid : 2.0.36-SNAPSHOT-c8dbef71bc5083e2ecc65fb5d39fb0e09f0a7a10
- mvn clean install
- do changes in docker_ss file  only xbid-cmi-1 stays present 
- run docker via docker_ss file
- Cmi is up and running with new version : snapshot version
** verify via : 'docker ps' 
- check DB:
** tbxi010_distribution event_map => 1 configured event stays present
** tbxi_011_distribution scheduler_map_history =>2 configured schedulers are present
** qrtz_triggers : is empty

TODO - logs check
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Artifactory unavailable ,XP-2749,93486,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,tm431,tm431,18/Mar/20 07:02,11/Sep/20 14:12,22/Feb/21 13:26,23/Mar/20 10:56,,,3.1.0,,,,,,,,,,,"Last week we faced 2x situation when deployments to customer facing envs. were not possible because artifactory was returning 500. *We need to prevent this situation for the case when there will be scheduled deployment for PROD, with some tight schedule e.g. 30min and we will realize that artifactory is not reachable.*

 
 * analyse what happened
 * prepare some alerting tools which will prevent this situation to happen, or responsible teams will be notified
 * this alerts should be introduced for ALL XBID facing envs. incl PROD
 * who can help is #artifactory email &artifactory_support1 and Jakub Slatinsky

 

more info in slack channel xbid_emergency 16 March 2020 10:35 and in comments in SERVICE-5656

 
{code:java}
Hello everybody.Currently I am unable to complete the deployment task on ""XBID CUTE"" environment due the problem to download artifactory located packages.Artifactory server responds with ""HTTP ERROR 500"". Do anybody has clue, who can fix this issue?David Siro  {code}
{code:java}
10:36guys at `&artifactory_support"" <&artifactory_support@deutsche-boerse.com>`{code}
{code:java}
Michal Plewka  10:36Slack channel #artifactory email &artifactory_support1{code}
{code:java}
Tuan Nguyen  16:37@Lambert is the problem solved? I got the same issue. I can download manually, but the Jenkins job says error 500 (edited) Lambert Neky  16:55{code}
{code:java}
Hello Tuan.I believe not. Later, I run additional partial deployment jobs and it had to be repeated for three times, until I was finally successful. I have no idea, what can be the reason of this issue. {code}
 

 ",,ei349,tm431,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29030400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahvb:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/20 15:30;ei349;[~yo218]: please put the information about the fix here in the comment and close the ticket. ","23/Mar/20 10:56;yo218;The IP of artifactory changed and we had to raise new firewall requests. This had be done for https reqeuests only, not for http. Some parts of the old pearl deployment were still relying on http which was the reason that it didn't work. Roman changed the scripts and now files are fetched via https",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reporting Engine - Upgrade actuator API to 2.x,XP-2746,93414,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eg288,eg288,16/Mar/20 16:52,04/Aug/20 19:53,22/Feb/21 13:26,30/Mar/20 15:37,,,3.1.0,,Reporting Engine,,,,,,,,,"{{Spring-boot-starter-actuator}} dependency introduced an API change between {{1.x}} and {{2.x}} versions. Within XP-1261 an attempt to upgrade to {{2.x}} was made, however, the actuator API has changed and resulted in NoClassDef found. Thus a revert to 1.5.22 (originally was 1.4.4) has been performed (commit 26420b79c33ba221152b07429f543ab7dfb9a12a). 

 

AC:
 * Works with 2.x with no OWASP objections.
 * Actuators work (needed for Ansible deploy: XP-2695)
 * (To be decided): Cover the actuator endpoint w. test",,eg288,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29289600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ai8s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Mar/20 08:52;ek176;The dependency: spring-boot-actuator is not propagated to actuator-servlet.xml (NoClassDef found)","17/Mar/20 09:37;ek176;Quick fix is:
{code:java}
$ git diff reporting-web-spring-mvc/pom.xml
diff --git a/reporting-web-spring-mvc/pom.xml b/reporting-web-spring-mvc/pom.xml
index de4451eb..1b25ca59 100644
--- a/reporting-web-spring-mvc/pom.xml
+++ b/reporting-web-spring-mvc/pom.xml
@@ -174,6 +174,11 @@
             <artifactId>spring-boot-starter-actuator</artifactId>
             <version>${spring-boot-plugin.version}</version>
         </dependency>
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-actuator</artifactId>
+            <version>1.5.22.RELEASE</version>
+        </dependency>
 
         <!-- dependency for quartz and use on websphere application server -->
         <dependency>
{code}
However, we should decide about upgrading the actuators from 1.x to 2.x version.","17/Mar/20 10:30;ek176;spring-boot-starter-actuator: Works with versions 1.4.7 and 1.5.22 (was 1.4.4 before XP-1261).

Current state: 1.5.22 is used (to unblock XP-2695)","19/Mar/20 15:33;ei349;probable estimate 5

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verification of 2 trades,XP-2745,93413,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,tj898,tj898,16/Mar/20 16:39,31/Aug/20 15:39,22/Feb/21 13:26,20/Mar/20 16:41,,,3.1.0,,,,,,,,,,,"Hi.

While investigating an issue with M7, we would like to know if those 2 trades below ever got involved with m7

External trade IDs :
 * 37496819
 * 37496820

Thanks.",,lt112,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29203200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0agyw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Mar/20 16:41;lt112;none of the trades is involved with m7",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resolve CRITICAL and HIGH findings on HP Fortify,XP-2742,93372,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,13/Mar/20 15:26,21/Jan/21 13:45,22/Feb/21 13:26,03/Nov/20 10:24,,,3.1.x,,,,,,,,,,,,,dm700,ei349,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4370,XP-4372,XP-4349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,10022400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0btj8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 20 (S),HOT Sprint 21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3394_flyway_standard_implementation,XP-3394_acceptance_flyway_standard_implementation,XP-4354,XP-4349_acceptance_fix_hp_fortify_issues,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,XP-3394_acceptance_remove_unused_maven_properties,XP-4234,master-acceptance,master,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,acceptance,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-3394_remove_schema_version,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4349_set_default_page,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Aug/20 11:24;dm700;[~dm700] - final goal of ""Fortify security rating"" should be 4 (see HP tool version overview)","29/Oct/20 08:48;lt112;UPDATE TODO (new findings/incorrect fixes)
* ComTrader (1 critical - too broad certificates)
* Reporting engine (introduced bug, needs fixing)
* Report tool (does not seem to reflect new changes)
** for some reason {{Last measured on     10/24/2020 12:00:21 AM}}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Transfer all XBID database users/passwords into vault,XP-2740,93359,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,eg288,eg288,13/Mar/20 12:48,04/Aug/20 19:53,22/Feb/21 13:26,16/Mar/20 10:47,,,3.1.0,,,,,,,TechOps,,,,"Transfer all XBID database users/passwords into vault,. Then it can be utilised by ansible scripts",,eg288,yo218,,,,,,,,,,,,,,,,,,,XP-2695,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29635200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ag3w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/20 10:47;yo218;All passwords are available in vault now.

Example:

[https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/xb/xbid/syt1/db/xbsyt1cor]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Agile pilot - update specifications and user manuals to latest development,XP-2738,93313,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,ei349,ei349,12/Mar/20 13:52,12/Jan/21 10:09,22/Feb/21 13:26,12/Jan/21 10:09,,,Agile Pilot,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29894400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,12/Mar/20 13:52,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220082r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,HOT Sprint 6 (S),HOT Sprint 7,HOT Sprint 8 (S),HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),HOT Sprint 15,HOT Sprint 16 (S),HOT Sprint 17,HOT Sprint 18 (S),HOT Sprint 19,HOT Sprint 20 (S),,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Production DB Replica read queries errors,XP-2737,93307,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eh941,eh941,12/Mar/20 13:02,04/Aug/20 19:53,22/Feb/21 13:26,12/May/20 09:17,,,3.1.0,,,,,,,,,,,"h1. Long running queries issue

When trying to read production replica {{xbproddbr1:25101}} it's very typical to get following error:
{noformat}
ERROR: canceling statement due to conflict with recovery
{noformat}
Please fix it.",,eh941,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,25228800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ap2v:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 7 (S),Alpha Sprint 8,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/20 13:54;ei349;[~eh941], [~yo218]: can you please have a look if this ticket is valid and resolve it? Also lower estimate if 3 is not needed. ","04/May/20 13:17;eh941;Successfully executed SQL from reporting engine TC540:
{{took 390 seconds}}
 {code:sql}
SELECT distinct orderHistory.REV                  as orderHistoryId,
                orderHistory.ORDER_ID             as orderId,
                orderHistory.INITIAL_ORDER_ID     as initialOrderId,
                orderHistory.PARENT_ID            as parentOrderId,
                orderHistory.LAST_UPDATE_TIME     as lastUpdateTime,
                orderHistory.BALANCING_GROUP_EIC  as traderBgEic,
                orderHistory.ACTION               as modificationType,
                contractHistory.PRODUCT_LONG_NAME as productLongName,
                product.PRODUCT_DISPLAY_NAME      as productDisplayName,
                product.CURRENCY_CODE             as currencyCode,
                product.DECIMAL_SHIFT_COMMODITY   as decimalShiftCommodity,
                product.DECIMAL_SHIFT_PRICE       as decimalShiftPrice,
                balancingGroup.MEMBER_ID          as memberId,
                USER_CODE                         as traderId,
                EXECUTION_PRICE                   as priceCent,
                orderHistory.VERSION              as revision,
                orderHistory.CONTRACT_ID          as contractId,
                DELIVERY_STARTDATE                as contractStartDate,
                DELIVERY_ENDDATE                  as contractEndDate,
                TSO_AREA_EIC                      as tsoEicAreaCode,
                BUY_CODE                          as buy,
                QUANTITY                          as quantity,
                TEXT                              as text,
                orderHistory.LAST_UPDATE_USER     as lastUpdateUser,
                contractHistory.LONG_NAME         as contractLongName,
                RESTRICTION_CODE                  as restriction,
                TARGET_BG_EIC                     as targetBgEicPartyCode,
                ORDER_ENTRY_TIME                  as creationTime,
                orderHistory.ORDER_TYPE_CODE      as orderTypeCode,
                orderHistory.HIDDEN_QUANTITY      as hiddenQuantity,
                orderHistory.PEAK_SIZE_QUANTITY   as peakSizeQuantity,
                orderHistory.VALIDITY_RESTRICTION as validityRestriction,
                orderHistory.EXPIRATION_DATE      as expirationTime,
                orderHistory.LIST_EXEC_INST       as listExecInst,
                orderHistory.BASKET_ID            as basketId,
                orderHistory.PEAK_PRICE_DELTA     as peakPriceDelta,
                orderHistory.BROKER_USER_ID       as brokerUserId,
                orderHistory.EX_GDT               as exGtd
from xbprodcor.CX_101_ORDER_HISTORY as orderHistory,
     xbprodcor.CX_200_PRODUCT as product,
     xbprodcor.CX_211_CONTRACT_HISTORY as contractHistory,
     xbprodcor.CX_270_BALANCING_GROUP as balancingGroup
where orderHistory.CONTRACT_ID = contractHistory.CONTRACT_ID
  and contractHistory.HALT = 'N'
  and contractHistory.PRODUCT_LONG_NAME in ('Intraday_Power_D', 'Continuous_Power_Base', 'Continuous_Power_Peak', 'Half_Hour_Power', 'Quarterly_Hour_Power')
  and orderHistory.REVTYPE in (0, 1)
  and orderHistory.LAST_UPDATE_TIME >= 'Sat May 02 00:00:00 CEST 2020'
  and orderHistory.LAST_UPDATE_TIME < 'Sun May 03 00:00:00 CEST 2020'
  and orderHistory.BALANCING_GROUP_EIC in (select BALANCING_GROUP_EIC from xbprodcor.CX_270_BALANCING_GROUP where MEMBER_ID = 'TRM03')
  and orderHistory.ORDER_TYPE_CODE in ('O', 'B', 'I', 'L')
  and orderHistory.ACTION in ('UADD', 'AADD', 'UMOD', 'UDEL', 'ADEL', 'AMOD', 'FEXE', 'PEXE', 'IADD', 'AHIB', 'UHIB', 'SHIB', 'SDEL')
  and product.PRODUCT_LONG_NAME = contractHistory.PRODUCT_LONG_NAME
  and balancingGroup.BALANCING_GROUP_EIC = orderHistory.BALANCING_GROUP_EIC
order by contractHistory.PRODUCT_LONG_NAME desc, orderHistory.USER_CODE asc, orderHistory.CONTRACT_ID asc, orderHistory.INITIAL_ORDER_ID asc,
         orderHistory.LAST_UPDATE_TIME asc, orderHistory.REV asc

{code}","04/May/20 13:19;eh941;Successfully executed report TC810:

{{took 14 seconds}}

{code:sql}

SELECT distinct tradeHistory.TRADE_ID              as tradeId,
                tradeHistory.ORDER_ID_SELL         as sellOrderId,
                tradeHistory.ORDER_ID_BUY          as buyOrderId,
                tradeHistory.TSO_AREA_EIC_SELL     as sellOrderTsoEicAreaCode,
                tradeHistory.TSO_AREA_EIC_BUY      as buyOrderTsoEicAreaCode,
                tradeHistory.LAST_UPDATE_TIME      as lastUpdateTime,
                tradeHistory.USER_CODE_BUY         as buyerUserCode,
                tradeHistory.USER_ID_BUY           as buyerUserId,
                tradeHistory.BG_EIC_BUY            as buyerBgEic,
                tradeHistory.USER_CODE_SELL        as sellerUserCode,
                tradeHistory.USER_ID_SELL          as sellerUserId,
                tradeHistory.BG_EIC_SELL           as sellerBgEic,
                tradeHistory.MATCH_QUANTITY        as quantity,
                tradeHistory.MATCH_PRICE           as priceCent,
                tradeHistory.CONTRACT_PHASE        as contractPhase,
                tradeHistory.VERSION               as revision,
                tradeHistory.CONTRACT_ID           as contractId,
                tradeHistory.TEXT_SELL             as sellOrderText,
                tradeHistory.TEXT_BUY              as buyOrderText,
                tradeHistory.LAST_UPDATE_USER      as lastUpdateUser,
                tradeHistory.MOD_TYPE_CODE         as modificationType,
                tradeHistory.ACTION                as action,
                tradeHistory.DELIVERY_START_DATE   as deliveryStartDate,
                tradeHistory.DELIVERY_END_DATE     as deliveryEndDate,
                contractHistory.LONG_NAME          as contractLongName,
                contractHistory.SHORT_NAME         as contractShortName,
                contractHistory.DELIVERY_STARTDATE as contractStartDate,
                contractHistory.PRODUCT_LONG_NAME  as productName,
                product.PRODUCT_DISPLAY_NAME       as productDisplayName,
                product.CURRENCY_CODE              as currencyCode,
                product.DECIMAL_SHIFT_COMMODITY    as decimalShiftCommodity,
                product.DECIMAL_SHIFT_PRICE        as decimalShiftPrice,
                seller.MEMBER_ID                   as sellerMemberId,
                buyer.MEMBER_ID                    as buyerMemberId
from xbprodcor.CX_111_TRADE_HISTORY as tradeHistory,
     xbprodcor.CX_211_CONTRACT_HISTORY as contractHistory,
     xbprodcor.CX_200_PRODUCT as product,
     xbprodcor.CX_282_USER as seller,
     xbprodcor.CX_282_USER as buyer
where tradeHistory.CONTRACT_ID = contractHistory.CONTRACT_ID
  and tradeHistory.MOD_TYPE_CODE in ('SADD', 'ACTI', 'UMOD', 'RREJ', 'RGRA', 'RREQ', 'CNCL', 'AMOD')
  and contractHistory.HALT = 'N'
  and contractHistory.PRODUCT_LONG_NAME IN ('XBID_Hour_Power', 'XBID_Half_Hour_Power', 'XBID_Quarter_Hour_Power')
  and tradeHistory.LAST_UPDATE_TIME >= 'Sat May 02 00:00:00 CEST 2020'
  and tradeHistory.LAST_UPDATE_TIME <= 'Sun May 03 00:00:00 CEST 2020'
  and (tradeHistory.BG_EIC_BUY in (select BALANCING_GROUP_EIC from xbprodcor.CX_270_BALANCING_GROUP where MEMBER_ID = 'TRM03') or
       tradeHistory.BG_EIC_SELL in (select BALANCING_GROUP_EIC from xbprodcor.CX_270_BALANCING_GROUP where MEMBER_ID = 'TRM03'))
  and contractHistory.PRODUCT_LONG_NAME = product.PRODUCT_LONG_NAME
  and seller.USER_ID = tradeHistory.USER_ID_SELL
  and buyer.USER_ID = tradeHistory.USER_ID_BUY
order by tradeHistory.TRADE_ID DESC 
{code}","06/May/20 14:09;eh941;I've tried to execute the last report query:

{code:sql}
select DISTINCT th.TRADE_ID            as tradeId,
                th.ORDER_ID_SELL       as sellOrderId,
                th.ORDER_ID_BUY        as buyOrderId,
                th.TSO_AREA_EIC_SELL   as sellOrderTsoEicAreaCode,
                th.TSO_AREA_EIC_BUY    as buyOrderTsoEicAreaCode,
                th.MATCH_PRICE         as priceCent,
                th.CONTRACT_ID         as contractId,
                th.MOD_TYPE_CODE       as modificationType,
                th.DELIVERY_START_DATE as deliveryStartDate,
                th.DELIVERY_END_DATE   as deliveryEndDate,
                th.VERSION             as revision,
                th.MATCH_QUANTITY      as matchQuantity,
                th.MATCH_TIME          as matchTime,
                ch.PRODUCT_LONG_NAME   as productName,
                cah.ID                 as reservationId,
                cah.REV                as rev,
                cch.DELIVERY_START     as deliveryStart,
                cch.DELIVERY_END       as deliveryEnd,
                cah.allocated_quantity as quantity,
                CASE WHEN cah.direction = '1->2' THEN cih.area_2_eic ELSE cih.area_1_eic END
                                       as areaIn,
                CASE WHEN cah.direction = '1->2' THEN cih.area_1_eic ELSE cih.area_2_eic END
                                       as areaOut,
                CASE WHEN cah.direction = '1->2' THEN cih.area_2_eic ELSE cih.area_1_eic END
                                       as inParty,
                CASE WHEN cah.direction = '1->2' THEN cih.area_1_eic ELSE cih.area_2_eic END
                                       as outParty
from xbprodcor.cmm_101_ALLOCATION_HISTORY as cah,
     xbprodcor.cmm_131_CONTRACT_HISTORY as cch,
     xbprodcor.cmm_231_INTER_CONNECTOR_HISTORY as cih,
     xbprodcor.CX_117_TRADE_ALLOCATION_HISTORY as tcr,
     xbprodcor.CX_111_TRADE_HISTORY as th,
     xbprodcor.CX_211_CONTRACT_HISTORY as ch
where cah.CONTRACT_ID = cch.CONTRACT_ID
  and cch.CONNECTOR_ID = cih.CONNECTOR_ID
  and cah.ID = tcr.ALLOCATIONID
  and tcr.TRADE_ID = th.TRADE_ID
  and th.CONTRACT_ID = ch.CONTRACT_ID
  and th.MOD_TYPE_CODE in ('ACTI', 'RREQ', 'RREJ', 'RGRA', 'CNCL')
  and cch.DELIVERY_START >= 'Fri May 01 00:00:00 CEST 2020'
  and cch.DELIVERY_END <= 'Sat May 02 00:00:00 CEST 2020'
limit 200
{code}

I added the limit there in order to avoid huge result set. But anyway - *{color:#DE350B}it never finishes{color}*. I'v let it run for more than 2 hours. It's unclear what the reason behind is - there might be a timeout, the query might really take very long or the database might endup with an error which I don't receive.","06/May/20 14:11;eh941;As summary - the original error message is gone but I wasn't able to execute one of the reporting engine queries",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CyberArk - move remaining servers behind CyberArk,XP-2734,93224,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,ei349,ei349,11/Mar/20 14:04,04/Aug/20 19:53,22/Feb/21 13:26,22/Jul/20 13:36,,,3.1.0,,,,,,,,,,,,,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,18576000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay6n:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 7,HOT Sprint 8 (S),HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jun/20 14:59;yo218;[~ei349] what about this ticket? Which servers should be the ""remaining""?","22/Jul/20 13:36;ei349;It looks that all should be onboarded already. I will close the ticket. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze effort needed for SIEM onboarding,XP-2731,93219,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,11/Mar/20 13:20,31/Aug/20 15:38,22/Feb/21 13:26,12/May/20 16:54,,,3.1.0,,,,,,,,,,,,,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24624000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3346,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000000003000401i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/May/20 16:54;yo218;1 day of work, x days of waiting for GIS and firewall rules",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Onboard Symantec CCS,XP-2730,93218,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ei349,ei349,11/Mar/20 13:20,04/Aug/20 19:53,22/Feb/21 13:26,25/Mar/20 17:07,,,3.1.0,,,,,,,,,,,,,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2900,TECHLOG-2903,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28771200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2728,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahva:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/20 14:18;yo218;Started with Simulation. Some networks are not able to communicatio with the server. Requested a firewall rule and then I will proceed with the registration","24/Mar/20 16:45;yo218;Registration was not successful, I am now in contact with Matic Lukas. He suggested to try the registration in a slightly different way, so I executed the following ansible command:
{noformat}
 ansible -i xbid_simu_ccs all -m shell -a ""rm -f /opt/esm/system/xb*/db/agtcert.dat && /opt/esm/bin/lnx-x64/register -m 10.246.0.16 -p 5600 -E -v -u"" -b -k -K -o{noformat}
Now I am waiting for his feedback whether the registration was successful this time","25/Mar/20 13:09;yo218;I received the reply that most of the hosts have been imported successfully. Just ecp1/2 and dbr1/2 were missing because of missing firewall rules. I raised the request to open the fw today.

 ","25/Mar/20 13:09;yo218;I started a new registration for all listed production hosts:
{noformat}
ansible -i xbid_prod_ccs all -m shell -a ""rm -f /opt/esm/system/xb*/db/agtcert.dat && /opt/esm/bin/lnx-x64/register -m 10.246.0.16 -p 5600 -E -v -u"" -b -k -K -o {noformat}
Matic Lukas confirmed via sky that all hosts have been imported successfully","25/Mar/20 17:06;yo218;Firewall rule for the outstanding hosts has been implemented and the registration was triggered. Onboarding of CCS is finished",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PROD DB Replicas Access,XP-2723,93072,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,10/Mar/20 08:44,13/Aug/20 19:41,22/Feb/21 13:26,19/Mar/20 16:13,,,3.1.0,,,,,,,,,,,"I need PROD DB Replicas access. In ideal world the both sync and async. For now the async one is more important.

I've already tried it with xbproddbr1:25101 and my LDAP credentials. The server is pingable but I got an error: {{FATAL: no pg_hba.conf entry for host ""10.250.2.163"", user ""eh941"", database ""xbprodcor"", SSL off}}

I was already in touch with [~cs687] and he said:

{quote}
i checked the config.yml of patroni and it seems like we are connecting to entest ldap which might be the root cause that not everybody can connect to the replica hosts.
so we need to change it to the prod-ldap

in patroni config.yml from entestldap to englobldap1.oa.pnrad.net
with port 389
{quote}

It would be fine if it worked for all developers not only me. But please try my account first :-) 
",,eh941,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29289600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeyo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Mar/20 13:10;yo218;I changed the configuration in order to use the production ldap host. However, it still doesn't work out of the box because postgres doesn't support ldap groups, so we still have to add the users manually to the db:
{noformat}
CREATE USER eh941;
GRANT dev_users TO eh941; {noformat}
 Has been done for both clusters (async and sync)","19/Mar/20 16:13;ei349;fixed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SYT1, SYT3 - certificate, Patroni issue",XP-2719,93039,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,09/Mar/20 14:30,13/Aug/20 19:41,22/Feb/21 13:26,10/Mar/20 14:17,,,3.1.0,,,,,,,TechOps,,,,"Syt1 and Syt 3 envs are not working and we are not able to work on these envs.
Job what is failing for both envs:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-Dev/job/XBID-Patroni-List-Switch/123/console

Could you please fix this issue. Thank you.",,hj444,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30067200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aers:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Mar/20 07:49;yo218;server certificate on consul expired:
{noformat}
[root@entestcons1 ssl]# openssl x509 -in server.crt -text -noout
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:eb:74:d1:7d:f2:ce:09:ae:50:6d:db:e9:75:03:53
    Signature Algorithm: ecdsa-with-SHA256
        Issuer: C=US, ST=CA, L=San Francisco/street=101 Second Street/postalCode=94105, O=HashiCorp Inc., CN=Consul Agent CA 44165242489416134775268322771154671053
        Validity
            Not Before: Mar  4 08:20:34 2019 GMT
            Not After : Mar  3 08:20:34 2020 GMT
        Subject: CN=server.energy-shrd-test.consul
        Subject Public Key Info:
            Public Key Algorithm: id-ecPublicKey
                Public-Key: (256 bit)
                pub:
                    04:82:e1:85:cb:a0:30:db:08:2f:cd:8b:4b:11:ed:
                    7e:03:22:68:02:4a:6a:d6:a4:c2:a7:f2:ac:51:cf:
                    cc:0d:fe:43:04:70:cb:a7:1b:f6:11:41:18:2f:8f:
                    d2:5e:a3:2d:78:61:97:6d:e9:0f:c9:2e:5a:9e:b9:
                    0e:ca:8d:e0:e9
                ASN1 OID: prime256v1
                NIST CURVE: P-256
        X509v3 extensions:
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage:
                TLS Web Server Authentication, TLS Web Client Authentication
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Subject Key Identifier:
                64:63:3A:38:65:3A:35:64:3A:63:62:3A:31:34:3A:39:64:3A:32:66:3A:32:30:3A:35:33:3A:65:63:3A:66:36:3A:30:63:3A:61:62:3A:65:31:3A:38:62:3A:32:34:3A:31:38:3A:30:31:3A:62:35:3A:32:63:3A:30:32:3A:32:30:3A:31:63:3A:34:33:3A:62:35:3A:62:31:3A:65:36:3A:33:65:3A:30:66:3A:65:62:3A:37:36:3A:36:30
            X509v3 Authority Key Identifier:
                keyid:65:36:3A:63:30:3A:36:32:3A:32:61:3A:61:33:3A:34:63:3A:39:31:3A:35:39:3A:66:65:3A:61:37:3A:65:36:3A:34:30:3A:31:63:3A:31:30:3A:30:62:3A:36:38:3A:64:32:3A:63:33:3A:34:36:3A:36:32:3A:33:65:3A:38:31:3A:35:34:3A:30:65:3A:36:61:3A:63:39:3A:36:32:3A:62:32:3A:33:63:3A:33:32:3A:34:62:3A:38:65            X509v3 Subject Alternative Name:
                DNS:server.energy-shrd-test.consul, DNS:localhost, IP Address:127.0.0.1
    Signature Algorithm: ecdsa-with-SHA256
         30:44:02:20:33:7a:fe:f7:fa:b7:df:64:60:bb:1e:18:69:d9:
         50:4a:6d:f9:d2:6b:01:f0:31:3f:63:12:5b:d6:72:16:6d:c6:
         02:20:53:c8:ce:96:ba:72:6b:36:e9:ee:1d:7a:38:6e:08:96:
         bf:43:ea:a2:07:eb:a3:47:a0:8c:e5:9b:95:dd:8a:13
 {noformat}","10/Mar/20 07:50;yo218;[~ub113] please add consul server certificate to your list of required (and to be monitored) XBID certificates ","10/Mar/20 08:53;yo218;we added the consul server certificates to the tool that checks the expiration date. Result (just the ones for xbid):
{noformat}
CN=server.energy-shrd-test.consul;Mar  3 08:20:34 2020 GMT;secret/global/consul/energy-shrd-test/server_cert (used for xbid internal test environments) 
CN=server.xb-xbid-prod.consul;Jun 19 08:07:33 2020 GMT;secret/global/consul/xb-xbid-prod/server_cert
CN=server.xb-xbid-simu.consul;Mar 26 09:20:53 2020 GMT;secret/global/consul/xb-xbid-simu/server_cert {noformat}
 ","10/Mar/20 14:16;yo218;Certificates have been replaced on shared test cluster and patroni clusters are working fine again:
{noformat}
[root@xbtestpdb2 ssl]# patronictl -c /etc/patroni_xbsyt3async/config.yml list
+-------------+------------+---------------+--------+---------+-----------+
|   Cluster   |   Member   |      Host     |  Role  |  State  | Lag in MB |
+-------------+------------+---------------+--------+---------+-----------+
| xbsyt3async | xbtestpdb1 | 10.139.40.225 | Leader | running |       0.0 |
| xbsyt3async | xbtestpdb2 | 10.139.40.224 |        | running |       0.0 |
+-------------+------------+---------------+--------+---------+-----------+
[root@xbtestpdb2 ssl]# patronictl -c /etc/patroni_xbsyt1async/config.yml list
+-------------+------------+----------------+--------+---------+-----------+
|   Cluster   |   Member   |      Host      |  Role  |  State  | Lag in MB |
+-------------+------------+----------------+--------+---------+-----------+
| xbsyt1async | xbtestdbr1 | 10.136.161.122 |        | running |       0.0 |
| xbsyt1async | xbtestdbr2 | 10.136.33.122  |        | running |       0.0 |
| xbsyt1async | xbtestpdb1 | 10.139.40.225  | Leader | running |       0.0 |
| xbsyt1async | xbtestpdb2 | 10.139.40.224  |        | running |       0.0 |
+-------------+------------+----------------+--------+---------+-----------+
[root@xbtestpdb2 ssl]#
 {noformat}
Executed steps: there is a script and a description in [https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/consul_instance:|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/consul_instance]

{{create keys and certificates for the cluster by editing and running:}}
 * {{Export variables to define cluster name and consul binary path {{export CONSUL_DC=energy-shrd-test && \
 export CONSUL_BINARY=/usr/local/bin/consul && \
 roles/consul_instance/create-consul-cluster.sh}}}}
 * {{this will save them in vault folder {{secret/global/consul/<dc_name>/}} - make sure they are there afterwards {{vault list secret/global/consul/energy-shrd-test}}}}

I cloned the repo on enprodauto1 and updated the mentioned script:
 * commented out the creation of a ca
 ** #$CONSUL tls ca create

#vault_write_safe secret/global/consul/$DC/ca_key value=@consul-agent-ca-key.pem
 #vault_write_safe secret/global/consul/$DC/ca_cert [value=@consul-agent-ca.pem|mailto:value=@consul-agent-ca.pem]

Then I removed the existing entries in vault:
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/client_cert]
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/client_key|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/client_cert]
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/server_cert|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/client_cert]
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/server_key|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/client_cert]

I copied the ca from vault into the working directory
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/ca_cert] --> consul-agent-ca.pem
 * [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/ca_key] --> consul-agent-ca-key.pem

And executed the script:
{noformat}
export CONSUL_DC=energy-shrd-test
export CONSUL_BINARY=/usr/local/bin/consul
roles/consul_instance/create-consul-cluster.sh {noformat}
The server certificates (energy-shrd-test-server-consul.pem + energy-shrd-test-server-consul-key.pem) need to be copied to all nodes of the consul cluster, the client certs need to be copied to the database server --> /etc/consul/ssl/ 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Overview of all TSOs with ECP access,XP-2706,92941,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qm925,qm925,06/Mar/20 09:16,31/Aug/20 15:39,22/Feb/21 13:26,25/Mar/20 13:15,,,3.1.0,,,,,,,,,,,Please provide information how many TSOs have ECP access,,qm925,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30240000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ae6o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/20 09:20;uv683;I checked all the TSOs from CMI prod database that have ECP distribution scheduler set up. This is the result 
||tso_eic_party_code||long_name||short_name||
|10XDE-RWENET---W|Amprion GmbH|AMP|
|10XCZ-CEPS-GRIDE|CEPS a.s.|CEPS|
|10XSI-ELES-----1|ELES d.o.o.|ELES|
|10X1001A1001A094|Elia System Operator S.A.|ELIA|
|10XHR-HEP-OPS--A|Croatian Transmission System Operator Ltd|HOPS|
|10XPL-TSO------P|Polskie Sieci Elektroenergetyczne Spółka Akcyjna|PSE|
|10XFR-RTE------Q|Reseau de Transport d'Electricite|RTE|
|10X1001A1001A38Y|STATNETT SF|SN|

There is also one data intermediary that also have given setup and it is
||eic_code||long_name||short_name||
|10V1001C--00001O|Nordic Operational Information System|NOIS|","09/Mar/20 12:14;qm925;Thank you for the information. 
The ticket can be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansibe - SLA Report Tool ,XP-2704,92913,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ei349,ei349,05/Mar/20 13:37,04/Aug/20 19:53,22/Feb/21 13:26,31/Jul/20 12:28,,,3.1.0,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30499200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xzx:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 13 (S),Alpha Sprint 14,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - SMI Deployment ,XP-2703,92912,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,05/Mar/20 13:37,04/Aug/20 19:53,22/Feb/21 13:26,08/Jul/20 12:28,,,3.1.0,,,,,,,,,,,"Hint:
 * Similar to CMI/Xbid Core. 
 * use basic role XBID Tomcat with working scripts.

 

 ",,eh941,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3261,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19785600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2703-ecp_props,XP-2703-remove_catalina_opts,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Jul/20 12:28;eh941;Split to XP-3261",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - ECP deployment,XP-2702,92911,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,05/Mar/20 13:36,07/Oct/20 08:48,22/Feb/21 13:26,18/Sep/20 11:38,,,3.1.2,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30499200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000xzp:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 17,HOT Sprint 18 (S),,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - SMC,XP-2701,92910,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,05/Mar/20 13:36,04/Aug/20 19:53,22/Feb/21 13:26,07/Jul/20 10:31,,,3.1.0,,,,,,,,,,,"Hint:
 * Similar to CMI/Xbid Core. 
 * use basic role XBID Tomcat with working scripts.

 

 ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30499200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b3xj:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Ansible - PMI Logger, Archiver and query deployment",XP-2700,92909,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,05/Mar/20 13:36,04/Aug/20 19:53,22/Feb/21 13:26,24/Jun/20 11:16,,,3.1.0,,,,,,,,,,,,,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3182,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,20995200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040005",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Jun/20 11:16;eg288;role for pmi logger is on review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - Core deployment,XP-2699,92908,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,05/Mar/20 13:35,04/Aug/20 19:53,22/Feb/21 13:26,12/Jun/20 14:39,,,3.1.0,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30499200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - Trading Inquiry,XP-2698,92907,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,ei349,ei349,05/Mar/20 13:35,04/Aug/20 19:53,22/Feb/21 13:26,01/Apr/20 17:58,,,3.1.0,,,,,,,,,,,"* prepare playbook

get inspired by other team scripts",,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2891,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28166400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ahvb:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,netbackup-role,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Apr/20 17:57;eg288;implemented, see pull requests:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/784
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1714",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - CMI,XP-2697,92906,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,05/Mar/20 13:34,04/Aug/20 19:53,22/Feb/21 13:26,17/Jun/20 15:26,,,3.1.0,,,,,,,,,,,,,eh941,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24796800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y14:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,Alpha Sprint 7 (S),Alpha Sprint 8,Alpha Sprint 9 (S),Alpha Sprint 10,Alpha Sprint 11 (S),,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/May/20 12:58;eh941;Put to waiting due to pending decision how to structure inventory and deployments and share it between multiple projects.

CMI in it's own fashion is prepared: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/808 and https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1764",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - CMM,XP-2696,92905,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,05/Mar/20 13:34,04/Aug/20 19:53,22/Feb/21 13:26,24/Jun/20 14:49,,,3.1.0,,,,,,,,,,,,,ei349,jj069,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22809600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s3o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 5,HOT Sprint 6 (S),HOT Sprint 7,HOT Sprint 8 (S),HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/Apr/20 10:34;lt112;stuck on review for several weeks","02/Jun/20 14:31;jj069;To whom is the review assigned?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ansible - Reporting engine ,XP-2695,92904,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eg288,ei349,ei349,05/Mar/20 13:34,04/Aug/20 19:53,22/Feb/21 13:26,20/Mar/20 15:11,,,3.1.0,,,,,,,,,,,,,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29203200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a9h9:zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Mar/20 15:11;eg288;Implemented for envs syt1 and syt2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stabilize Failover Test and Nightly pipeline,XP-2694,92903,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,05/Mar/20 13:24,04/Aug/20 19:53,22/Feb/21 13:26,17/Mar/20 10:53,,,3.1.0,,,,,,,,,,,"For failover tests there are some identified issues - 
* https://github.deutsche-boerse.de/dev/xbid-test/pull/226
* https://github.deutsche-boerse.de/dev/xbid/pull/593


Make Nightly Pipeline green again",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30585600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0adbb:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2633,xbid-losses-poc,XP-2942-losses-perf,XP-456,XP-2979-postgresql,XP-3264,XP-2694-xbid-3.0.x-latest-tag-fix,develop,XP-3230,XP-2232,XP-2694,master,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,fixing-failover,master-xbid-losses-poc,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing explicit element id on XBID GUI,XP-2684,92719,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hj444,od044,od044,02/Mar/20 14:32,08/Dec/20 14:15,22/Feb/21 13:26,08/Dec/20 14:15,,,3.2.x,,,,,,,,,,,"h1. {color:#00875a}Explicit naming of IDs in Tobago{color}

Actual: 
 Preview NTC modal window: #page:details_upload:filePublishPreviewPopupId-filePublishPreviewPopup0-uUploadBox0:j_id_n1
 Cancel button on Reset password page in CMM: #page:j_id_j
 Preferences menu and suboptions in CMM : j_id_13, j_id_14, j_id_15

Expect:
 Replace ID e.g. j_id_n1 to explicit ID",,hj444,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,6480000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,02/Mar/20 14:32,,,,,,,,,,,,,,,,,,,,,,,"1|y0c1w3:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 23 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Dec/20 13:48;hj444;Docker : Version R3.2.4-SNAPSHOT (Build 7aff46febe3d073628b14687a964e5ec8b6fe9f9)
ID verifications :

* * NTC file(s) publish preview   - pop up window ID : {code}//*[@id=""page:details_upload:filePublishPreviewPopupId-filePublishPreviewPopup0-uUploadBox0""]{code}

* Cancel Btn at Change password page : {code}//*[@id=""page:changePasswdCancelBtn""]{code}
* Preferences Menu : 
** {code}//*[@id=""page:preferencesMenu""]{code}
* options in Preferences Menu :
** {code}//*[@id=""page:preferences_form:onBehalfMenu""]{code}
** {code}//*[@id=""page:preferences_form:h2hMenu""]{code}
** {code}//*[@id=""page:preferences_form:displayTimeUTC""]{code}
** {code}//*[@id=""page:preferences_form:displayTimeLocal""]{code}
** {code}//*[@id=""page:preferences_form:displayTimeCET""]{code}
** {code}//*[@id=""page:preferences_form:timeLocalMenu""]{code}
** {code}//*[@id=""page:preferences_form:mMenuCommandPreferencesFilterContracts""]{code}","08/Dec/20 14:15;hj444;Requested IDs are updated.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate Black Duck into pipeline,XP-2682,92696,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,dm700,dm700,02/Mar/20 10:45,13/Aug/20 19:41,22/Feb/21 13:26,02/Apr/20 09:34,,,3.1.0,,,,,,,,,,,"IMHO 3 SPs (but can be 2 if we get lucky, but even 5 if not)

Tomas Zdara already works on M7P-5748 (we can get inspired)

Q: Should we start within Ansible already?

Deutsche Boerse has integrated another tool to improve security of delivered products. On page [https://blackduck.shrd.dbgcloud.io|https://blackduck.shrd.dbgcloud.io/] is not accessible a solution to be integrated into build process. 

 

For generic integration guideline see attachment.",,dm700,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Mar/20 10:45;dm700;Black_Duck_scanning_best_practices.pdf;https://jira.deutsche-boerse.com/secure/attachment/80951/Black_Duck_scanning_best_practices.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,19180800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2601,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeyu:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2942-losses-perf,xbid-losses-poc,XP-2979-postgresql,XP-3361,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_reporting_tools_upgrade_hpfortify,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Mar/20 10:45;dm700;usable details will be delivered after activity kick-off 5.3.","20/Mar/20 07:50;dm700;access to the site [https://blackduck.shrd.dbgcloud.io|https://blackduck.shrd.dbgcloud.io/]  can be requested by Christian Tueffers

another source of information is his tool page: [https://teams.deutsche-boerse.de/sites/sp1147/SitePages/Home.aspx] 

implementation hints also on #blackduck Slack channel","30/Mar/20 10:16;ek176;Blackduck login now integrated to LDAP/IIQ.

Added Confluence page.

[http://confluence.energy.svc.dbgcloud.io/display/XBID/BlackDuck+integration]

 

Implemented into hp-fortify-prod and hp-fortify-nightly XBID pipelines.","30/Mar/20 10:16;ek176;Blackduck login now integrated to LDAP/IIQ.

Added Confluence page.

[http://confluence.energy.svc.dbgcloud.io/display/XBID/BlackDuck+integration]

 

Implemented into hp-fortify-prod and hp-fortify-nightly XBID pipelines.","30/Mar/20 12:46;ek176;Security concerns were summarized in the
 * Confluence page: [http://confluence.energy.svc.dbgcloud.io/display/XBID/BlackDuck+integration]
 * #blackduck Slack channel

The nightly pipelines executed OK.

 

Note: The Dev/nightly builds #522 and #523 failed due to inavailability of HP Fortify (today, #524 executed OK): 
{noformat}
[Pipeline] {
[Pipeline] sh (hide)
+ curl --retry 5 --noproxy '*' --insecure -H 'Authorization: FortifyToken **********************' https://frpfortifyssc.dwain.infra/ssc/api/v1/cloudjobs/94e4dd94-22d2-4c9e-a98d-fd48533c6d04
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
curl: (35) TCP connection reset by peer
[Pipeline] }
[Pipeline] // waitUntil
[Pipeline] }
[Pipeline] // timeout
[Pipeline] }
[Pipeline] // dir
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage{noformat}","30/Mar/20 12:51;ek176;Note: The convention (m7, xbid) is to prefix our projects with 'xbid-' to avoid confusion/organize the dashboard.","30/Mar/20 14:26;ek176;Moved to 'Testing' phase: Will observe pipelines in the next 2-3 days to make sure it runs ok.

2020-03-31: Both pipelines ran OK: (46 min runtime)

2020-04-01: Both pipelines ran OK: (45/46 min runtime)

2020-04-02: Prod ran OK, Dev did not finish (but a blackduck server was announced). After 'Build now' all went fine.","02/Apr/20 09:34;ek176;AFAIK (#blackduck channel) we are not allowed to generate PDF reports (trigger generating via API). Might be allowed in future.

On 2020-03-30 raised concern (#blackduck Slack channel) with a chain of execution of untrusted (unverified) code (curl ... |bash), that further downloads 1) Java JRE (if openjdk-11-jre is not available), and 2) JAR file and executes it. There is a high risk of data extrusion, code and infrastructure info leakage.  No reactions so far.

 

Overall: The SW provides nice way to work with sec findings, IMO from dev prespective it's wise to keep the OWASP plugin that blocks HIGHLY vulnerable builds/commits. The BlackDuck is useful for PO/MGMT level for planning/monitoring.

 

A clear drop-down of HIGH vulns can be seen between xbid-2.0.x (0/1/2/6) and xbid-3.0 (0/10/54/22) [Critical/High/Medium/Low], when the OWASP maven plugin was introduced.","15/Jul/20 14:08;ek176;With the server upgrade on 2020-07-10, the following changes to pipelines were made:
 * JAR file from artifactory is downloaded and run (6.3.0 version), no BASH script executed anymore
 * AID292 used instead of xbid (as in HP Fortify) in the project name
 * Only DEVELOP/PROD version are held (as in HP Fortify)
 * Still no reports can be generated: returns 403 
 * SIGNATURE_SCAN was disabled: Conn error: Can't download from the server
 * Buildless mode activated (Maven). Does not detect version from pom.xml (maven-help-plugin might be used): Runtime dropped to 20 sec (was 10 minutes)
 * Excluded unused detectors
 * Excluded unused tools
 * Project search depth increased (default is 0)
 * Nightly pipelines updated (hp-fortify nightly, prod): [https://github.deutsche-boerse.de/dev/xbid-pipeline]
 * Confluence updated: [https://confluence.energy.svc.dbgcloud.io/display/XBID/BlackDuck+integration]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMXBID CLONE: Open network connections for our new servers ,XP-2675,92587,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yn731,lw641,lw641,26/Feb/20 10:43,13/Aug/20 19:41,22/Feb/21 13:26,19/Mar/20 16:11,,,3.1.0,,,,,,,TO4XBID,,,,"Hello Xbid Service desk,
we are currently in the process of moving our production servers from amsterdam DC to paris DC. As a preparation we would like to open the network connection from and to these servers in the excel sheet. 

Is the excel sheet clear, and is this request placed at the right department?

thanks in advance,
Walter de Neve Epex Spot
w.deneve-external@epexspot.com
tel +31653312869",,ei349,lw641,yn731,yo218,,,,,,,,,,,,,,,,,,,,SMXBID-1756,,,,,,,,,,,,,,,,,,,"26/Feb/20 10:43;lw641;dtt dbag preprod prd dtt3 flows request.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80769/dtt+dbag+preprod+prd+dtt3+flows+request.xlsx","03/Mar/20 10:30;yn731;image1.png;https://jira.deutsche-boerse.com/secure/attachment/81010/image1.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,XBID Service Desk (IMT) Questions & Issues,,,,,,29289600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ac4o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),HOT Sprint 5,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Mar/20 10:31;yn731;[~yn731] added a comment - 03/Mar/20 09:49
  
 Dear 
 Could you please provide the correct single source and single destination IPs? 

Kind regards,

Ramiro.
----
Response from customer:

!image1.png!

 

 ","10/Mar/20 14:44;yo218;FW request for opening access to SFTP server from  154.42.64.49 has been raised (tufin: 503436)

All https connections should already be available (whole EPEX MPLS range has been opened). Same applies for connection to the SFTP server from 195.254.158.52. ","19/Mar/20 16:12;ei349;Niklas confirmed with Ioanna that this has been fixed yesterday",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check load on XBID PROD against contractual boundaries,XP-2647,92304,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,rg535,ei349,ei349,19/Feb/20 14:24,13/Aug/20 19:41,22/Feb/21 13:26,21/Feb/20 08:04,XBID 2.0,,3.1.0,,,,,,,,,,,"h2. Check the following: 
 # peak activity in respect to contract
 # max order management transaction in respect to contract

h2. Grafana with data: 

[- https://grafana.energy.svc.dbgcloud.io/d/jFqkrihik/orders-transactions-all?orgId=5|https://grafana.energy.svc.dbgcloud.io/d/jFqkrihik/orders-transactions-all?orgId=5]
h2. Additional info:  


For Sustainable load we have these boundaries, * Orders Transactions (hourly, 15/30 mins) per second: 40.
 * Trade transactions (hourly, 15/30 mins) per second: n/a.
 * Average number of Block Order Transactions per second: 0,22.
 * Average number of Block Trade Transactions per second: n/a.
 * Average explicit capacity requests per minute: 21.
 * Average explicit Allocations per minute: 21.

  * The maximum daily number of Block Order Transactions (subset of Order Transactions) is 20.000.
 * The maximum number of Daily Block Trades (subset of Daily Trades) is 2.500.

And for Peaks we have * Order Transactions per second (hourly, 15/30 mins): 350.
 * Trade transactions per second (hourly, 15/30 mins): n/a.
 * Peak Block Order Transactions per second: 7.
 * Peak Block Trade Transactions per second: 2.
 * Daily maximum of Order Transactions in peak: 15% (<=1 500 000 Order Transactions) and 11,25% (>1 500 000 Order Transactions).
 * Explicit capacity requests per minute: 120.
 * Explicit Allocations per minute: 120.

 
Check EX 20 stored here
[https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/08%20XBID%20ACM/02_Contracts%20and%20Change%20Requests/01_MSA/06_Fifth%20Amendment%20to%20MSA/DBAG/12_Sanity%20Check%20DBAG] (edited) 
 
h2. Acceptance Criteria 
- We need to know if the load experienced on XBID neared or breached any of our boundaries.",,ei349,rg535,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/20 07:56;rg535;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/80611/screenshot-1.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31708800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000000000030004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 2 (S),HOT Sprint 3,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/20 15:14;zi174;Hello,

I checked the service boundary report from January and grafana for February and the result is that the boundary breach is still far away. 

Order Transactions per day
 * In January, we had 1.14mil (in average) - maximum 1.40mil - Boundary 2mil
 * until 17th February, we had 1.10mil (in average) - maximum 1.25mil -  Boundary 2mil

Trades per day
 * In January, we had 90k (in average) - maximum 109k - Boundary 200k
 * until 17th February, we had 87k (in average) - maximum 131.5k -  Boundary 200k

 ","19/Feb/20 15:49;ei349;Dear Suzanna, can you please have a look on Kuba's analysis? Thank you,. ","19/Feb/20 15:55;rg535;[~ei349], what about the peaks? And what about the volumes today? ","21/Feb/20 08:03;rg535;See attached screen shot. The overall peak trend has not changed significantly over the past 30 days. Several PXs had increased activity over the past 30 days.","21/Feb/20 08:04;rg535;analysis complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update of guardium,XP-2645,92272,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,yo218,yo218,19/Feb/20 08:36,31/Aug/20 15:38,22/Feb/21 13:26,06/Apr/20 10:23,,,3.1.0,,,,,,,,,,,"Mail from Steffen Englert:
{noformat}
Hello, 
I was informed this week about coming planned maintenance for Security-Tool “Guardium”.
The following Hosts will be affected 
-xbperfpdb1.deutsche-boerse.de
-xbperfpdb2.deutsche-boerse.de
-xbprodedb1.deutsche-boerse.de
-xbsimuedb1.deutsche-boerse.de
-xbsimupdb1.deutsche-boerse.de
-xbsimupdb2.deutsche-boerse.de
-xbsimupdb3.deutsche-boerse.de
-xbsimupdb4.deutsche-boerse.de 
Security Team planned to do that maintenance on the coming weekend (22.2/23.2) what I rejected, because it´s to late communicated and besides that I am not really sure if there is already a CR existing in SAP.We came to that conclusion that we first run this planned maintenance on the hosts (“xbperfpdb1.deutsche-boerse.de”|”xbperfpdb2.deutsche-boerse.de”), before we are doing it for Simu- and Prod-Hosts.The Dry-Run on the performance-hosts could happen this week and the real maintenance will happen in the next two weeks during a weekend.
 No impact is expected on Database level – more information’s  is available in the email from Ionut Alexandru.
 Since it is only XBID Database Machines, I guess the current XBID Product-Support Team @Tuan Nguyen & @Niklas Albers can take over the coordination, contact Persons will be @Ionut Alexandru EXT and @Thorsten GessnerAnd we can use the channel m7-guardium. 
Thanks in Advance. 
Cheers,Steffen{noformat}
 ",,iv732,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/20 08:37;yo218;Affected_STAPs_by_patchp1202.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80532/Affected_STAPs_by_patchp1202.xlsx","19/Feb/20 08:36;yo218;FW_ IBM Guardium FFM Insfrastructure maintenence window .msg;https://jira.deutsche-boerse.com/secure/attachment/80531/FW_+IBM+Guardium+FFM+Insfrastructure+maintenence+window+.msg",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,27820800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0aeys:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 3 (S),Alpha Sprint 4,Alpha Sprint 5 (S),Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/20 13:34;iv732;CR number: : 44020916","02/Apr/20 12:40;iv732;Will be done on 3.April","06/Apr/20 10:23;iv732;Implemented successfully",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Peaks in PROD 17.2.,XP-2643,92263,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,18/Feb/20 17:12,31/Aug/20 15:38,22/Feb/21 13:26,20/Feb/20 13:39,,,3.1.0,,,,,,,,,,,"The most busy minute of the day is 6:30 UTC. It is caused by closing contract 08-09_XB for busy delivery areas including Germany and France. There are many active orders for the contract which gets deleted (action SDEL).

*the most busy hours (order transaction per hour):*
2020-02-17 17:00:00	139238
2020-02-17 06:00:00	133161
2020-02-17 21:00:00	122862
2020-02-17 22:00:00	119277
2020-02-17 11:00:00	118284
2020-02-17 20:00:00	116714
2020-02-17 14:00:00	114258
2020-02-17 23:00:00	107363
2020-02-17 10:00:00	106476
2020-02-17 18:00:00	104899
2020-02-17 15:00:00	102978
2020-02-17 19:00:00	98515

*analasyse of time 6:00 - 7:00 UTC (order transaction per minute):*
date_trunc	count
2020-02-17 06:30:00	19609
2020-02-17 06:00:00	6654
2020-02-17 06:15:00	4456
2020-02-17 06:03:00	2808
2020-02-17 06:05:00	2473

*order transaction per minute and bg:*
2020-02-17 06:30:00	BG-EPEX-------01	13699
2020-02-17 06:30:00	BG-NP---------01	5871
2020-02-17 06:00:00	BG-EPEX-------01	3706
2020-02-17 06:15:00	BG-EPEX-------01	2998
2020-02-17 06:03:00	BG-NP---------01	2356
2020-02-17 06:05:00	BG-NP---------01	2158
2020-02-17 06:04:00	BG-NP---------01	2004

*order transaction per minute,  bg and action:*
2020-02-17 06:30:00	BG-EPEX-------01	SDEL	13015
2020-02-17 06:30:00	BG-NP---------01	SDEL	4333
2020-02-17 06:15:00	BG-EPEX-------01	SDEL	2684
2020-02-17 06:03:00	BG-NP---------01	UADD	1180
2020-02-17 06:03:00	BG-NP---------01	UDEL	1174
2020-02-17 06:05:00	BG-NP---------01	UADD	1079
2020-02-17 06:05:00	BG-NP---------01	UDEL	1075
2020-02-17 06:04:00	BG-NP---------01	UADD	1001
2020-02-17 06:04:00	BG-NP---------01	UDEL	974
2020-02-17 06:57:00	BG-EPEX-------01	UADD	924


",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31881600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a9ha:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 2 (S),HOT Sprint 3,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stabilize E2E tests,XP-2635,92086,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,12/Feb/20 10:43,04/Aug/20 19:53,22/Feb/21 13:26,03/Mar/20 08:53,,,3.1.0,,,,,,,,,,,"Redesign e2e pipeline in order to contain two pipeline

The first pipeline takes wanted version (e.g. xbid SHA or version), build the docker image if necessary and executes the second pipeline

The second pipeline takes docker versions of all prepared docker images (from the first pipeline) and executes the tests.

Having this it should be easy to execute e2e tests for whatever versions pragmatically.

Update docker_control.py in order to have retry mechanism for starting docker containers.

",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,32486400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a99c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 2,Alpha Sprint 3 (S),,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XBID-4909,selenide-poc,xbid-losses-poc,XP-PULL-TEST,XP-2694-xbid-3.0.x-latest-tag-fix,XP-3230,XP-3094-sonar-gate,XP-3161-develop,XP-3070,XP-3942-acceptance,sm-2.0.10.x,xbid-2.0.25.x,fixing-failover,master-xbid-losses-poc,XP-3233-acceptance-jgitflow,XP-2633,XP-2635-redo-fix-3.0,plewmic-scripts,XP-3922,master-sm-2.0.10.x,fixing-owasp,fixing-hp-fortify-acceptance-2021-02-15,XP-2942-losses-perf,XP-456,XP-2979-postgresql,XP-3264,develop,XP-2694,XP-2232,master-acceptance,master,XP-4273-owasp-zap-enable,acceptance,XP-3161,XP-4371_upgrade_dataset_version,inline-tomcat-params,XP-3161-pom-cleanup-develop,XP-4526-resource-managment-fix,XP-2635-2.0.10.x,XP-3161-pom-cleanup,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Password expiratio date modification - US-XBID-4876,XP-2631,91999,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,zi174,zi174,10/Feb/20 10:50,13/Aug/20 19:41,22/Feb/21 13:26,13/Feb/20 11:25,,,3.1.0,,,,,,,TechOps,,,,Please change an expiration date of password for the users in attachment in LDAP on SIMu environment due to password warning testing. ,,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Feb/20 10:47;zi174;ListOfUsers.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80329/ListOfUsers.xlsx","10/Feb/20 11:12;yo218;image-2020-02-10-11-12-03-147.png;https://jira.deutsche-boerse.com/secure/attachment/80249/image-2020-02-10-11-12-03-147.png","10/Feb/20 11:12;yo218;simu_expiration_1.ldif;https://jira.deutsche-boerse.com/secure/attachment/80250/simu_expiration_1.ldif",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,32400000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a8q0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 2 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Feb/20 11:12;yo218;Set the expiration date of the mentioned user to 3rd of February. Example:

!image-2020-02-10-11-12-03-147.png!","13/Feb/20 11:25;yo218;changed it as requested to 21st of April for all mentioned users",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
EBSM storage (capacity request),XP-2629,91907,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,dm700,dm700,06/Feb/20 16:11,13/Aug/20 19:47,22/Feb/21 13:26,27/Feb/20 15:43,,,3.1.0,,,,,,,,,,,"There is a running activity about future of EBSM 

The task is to identify *WHAT* and *FOR HOW LONG* XBID needs any kind of data EBSM to be stored in EBSM (mostly for reporting and troubleshooting purposes).

New disks and storage will be created and it should be aligned with this capacity need. Current growth and maintenance of EBSM storage is not longer acceptable and is a topic of  change.

Link to EBSM topic recapitulation:

[https://confluence.energy.svc.dbgcloud.io/display/EDW/Re-assessment+of+Data+Lake+Purpose]

 

 

First list why we need EBSM on XBID
 * Journal
 ** Fill our usage: TODO 
 ** no alternative
 * DB Dumps
 ** Fill our usage 
 ** I.e. Patroni cannot be used because of only up to date data 
 * Application Logs
 ** Kibana has limited time frame
 ** Cannot download logs 

Second compare EBSM features with alternative solutions like Kibana and Patroni. Why we need/don't need each feature on EBSM. ",,dm700,,,,,,,,,,,,,,,,,,,,,,,M7P-5534,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31104000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000000003006",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Feb/20 15:42;dm700;* PROD (DB Dump, Logs, Journals) - 15 month
 * xSIMU+CUTEx+CTPx (DB Dump, Logs, Journals) - 6 months

for usage of DB Dump SSH/SCP needed 

keep backup frequency - last month each day, older per week (DB Dump, Journals)

 

Open point - how to ensure continuity when new storage will be created (eg. new logs on one place and old logs in EBSM)? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate Anteater automated mails with OpsGenie notifications,XP-2619,91830,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ei349,ei349,05/Feb/20 13:15,13/Aug/20 19:41,22/Feb/21 13:26,17/Feb/20 13:39,,,3.1.0,,,,,,,OpsGenie,,,,"Scenario: 
 # anteater sends mail to non existing mail address (from: sth like anteater@dbag.com)
 # recipient mail doesnt exist -> automatic reply to [anteater@dbag.com|mailto:anteater@dbag.com]
 # OpsGenie listens on mail address above and sends message to the team (your call how - Slack channel?) 

 ",,ei349,jy268,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2486,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31968000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2649,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ezwx",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 2 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Feb/20 11:21;lt112;h2. Notes
h3. Slack
* https://www.atlassian.com/software/opsgenie/slack
* apparently we all have rights to create webhook in slack (no TO needed, maybe just for approval)

h3. New e-mail
* must be {{<something>@deutsche-boerse.com}} ({{giant.anteater@deutsche-boerse.com}}, coz e.g. {{elia@xbid-test.deutsche-boerse.com}} does not receive notifications about failed delivery
* Roman should know whom to ask","17/Feb/20 11:49;jy268;POC Results:
* Integration was created, opsgenie was connected both to email and slack
* anteater_opsgenie_poc slack channel was created where all received emails are published
* following integrations were created, email: https://deutsche-boerse.app.eu.opsgenie.com/settings/integration/edit/Email/3e9c6a72-54dc-41b6-a031-b6c3e3a30ab3 slack: https://deutsche-boerse.app.eu.opsgenie.com/settings/integration/edit/SlackApp/a28e01c0-0cf9-4970-ba5d-ab6f99be39e1

Caveats:
* According to discussion with Hugo it is required to use email in domain deutsche-boerse.eu.opsgenie.net . It means that we will need to change how email notification works. In case of an automatic response our mailbox in deutsche-boerse.com domain will need to automatically forward message to anteater@deutsche-boerse.eu.opsgenie.net . It can be achieved using default mechanisms like autoforward.","17/Feb/20 12:59;lt112;Works like a charm

We have two options now:
- try setting {{anteater@deutsche-boerse.eu.opsgenie.net}} as {{fromAddress}} for anteater and trigger emails to non-existing addresses, check if failure message is received
- OR create new email address at {{@deutsche-boerse.com}} and forward failed deliveries to {{anteater@deutsche-boerse.eu.opsgenie.net}}","17/Feb/20 13:23;jy268;I would choose the 2nd option not to reveal our opsgenie domain.","17/Feb/20 13:38;lt112;Tested and working, great job

Option 1 works, {{anteater@deutsche-boerse.eu.opsgenie.net}} has received an email about failed delivery and sent a message to slack","17/Feb/20 13:39;lt112;Up for discussion, but both options work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Reporting Eng]: Update xbid dependency,XP-2615,91810,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ek176,ek176,05/Feb/20 10:28,04/Aug/20 19:53,22/Feb/21 13:26,04/Mar/20 13:00,,,3.1.0,,,,,,,Reporting_Engine,,,,"Remove the dependency on obsolete library. 

 

Reporting engine has an obsolete dependency to xbid: <xbid.project.version>1.4.18</xbid.project.version>

 ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33091200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0acgk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 3 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Penetration Tests Planning 2020 ,XP-2599,91617,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,,ei349,ei349,29/Jan/20 14:00,13/Aug/20 20:12,22/Feb/21 13:26,04/Mar/20 14:16,,,3.1.0,,,,,,,PenetrationTest,,,,,,ei349,rl336,,,,,,,,,,,144000,144000,,0%,144000,144000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30585600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a6l4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/20 14:08;rl336;pentest request for 2020 filled out together in the Meeting
[~ei349] please attache the Report to this JIRA 
","04/Mar/20 14:16;rl336;Report can be found
https://confluence.energy.svc.dbgcloud.io/pages/resumedraft.action?draftId=29917490&draftShareId=61060cb4-422b-4b53-8bdc-b7d0e2ba445a",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid-test - split tests into smaller chunks,XP-2593,91573,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,28/Jan/20 16:03,04/Aug/20 19:53,22/Feb/21 13:26,30/Jan/20 12:53,,,3.1.0,,,,,,,,,,,Currently management tests run for about an hour. It should be split at least into 2 smaller chunks.,,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33696000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a6bc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1261-guava-28,selenide-poc,XP-3777,xbid-losses-poc,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-3230,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-3070,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,xbid-2.0.25.x,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,fixing-failover,XP-4505_ct_sloth_hpfortify_upgrade,plewmic-scripts,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,XP-2942-losses-perf,XP-456,XP-2979-postgresql,XP-3264,XP-3361,develop,XP-2232,XP-2694,XP-4505_xbid_develop_hpfortify_upgrade,XP-4273-owasp-zap-enable,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,inline-tomcat-params,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,versions,XP-4526-resource-managment-fix,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA service bounday report - Sustainable load sheet ,XP-2586,91480,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zi174,zi174,zi174,27/Jan/20 16:50,31/Aug/20 15:38,22/Feb/21 13:26,04/Feb/20 15:33,,,3.1.0,,,,,,,,,,,"In the service boundary report, we use one parameter of time for Sustainable Load Seconds and Sustainable Load Minutes.

This needs to be fixed as due to 2nd wave and changing the values for Sustainable load, we have to distinguish between Seconds and Minutes

* For Orders and Trades - Peak load is 10s
* For Explicit capacity requests and Explicit allocation - Peak load is 1 minute
",,lt112,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Feb/20 09:10;lt112;XBID Service Boundary Reporting December 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80029/XBID+Service+Boundary+Reporting+December+2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33264000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a698:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2549,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/Jan/20 09:18;lt112;Note:
- MORE than 10 seconds (thus 11+)
- MORE than 1 minute (thus 2+)","30/Jan/20 09:34;lt112;https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/235","03/Feb/20 09:52;lt112;Redo for December",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID: DST Test in CuTe PX Environment,XP-2584,91452,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,gd553,gd553,27/Jan/20 10:10,31/Aug/20 15:39,22/Feb/21 13:26,27/Jan/20 13:04,,,3.1.0,,,,,,,,,,,"Information from customers:
 * In September 2019 we discussed an options of the DST test on Simulation environment – DBAG provided us with quotation and indicated that due to complexity of simulation environment DBAG would need 6 weeks for preparation of the environment.
 * We would like to ask DBAG how the quotation and preparation time changes if DST test is executed CuTe PX environment

*Thus I would like to know the following:*

1) Effort estimation (including person days and infrastructure) for setting CuTe PX environment up for the DST test

2) Timeline (number of working days, weeks) that you need to set up CuTe PX for DST test",,gd553,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-913,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33868800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a5xc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/20 13:04;gd553;Topic closed by the customers, DST test can be done in CuTe PX. If DBAG support is necessary, 3PS tickets will be opened and invoiced accordingly.

Ticket can be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
January 2020 SLA Reports  - send to ACM by 8th February for check,XP-2563,91341,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,zi174,ei349,ei349,22/Jan/20 16:35,13/Aug/20 19:45,22/Feb/21 13:26,04/Feb/20 15:34,,,3.1.0,,,,,,,,,,,,,ei349,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2549,,,,,,,"03/Feb/20 14:11;lt112;XBID Performance and SM SLA Reporting January 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80004/XBID+Performance+and+SM+SLA+Reporting+January+2020.xlsx","03/Feb/20 14:11;lt112;XBID Service Boundary Reporting January 2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80005/XBID+Service+Boundary+Reporting+January+2020.xlsx","03/Feb/20 14:11;lt112;XBID_Credit_points_report_January_2020.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80006/XBID_Credit_points_report_January_2020.xlsx","03/Feb/20 14:11;lt112;credit-points-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80001/credit-points-report.xlsx","03/Feb/20 14:11;lt112;kpi-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80002/kpi-report.xlsx","03/Feb/20 14:11;lt112;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/80003/sla-report.xlsx",,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33177600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a59y:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/20 16:52;lt112;* Issues solved in XP-2549
* Will wait for new report, which should be generated automatically","28/Jan/20 12:04;lt112;Fixed reporting tool deployed https://jira.deutsche-boerse.com/browse/SERVICE-5446","03/Feb/20 14:12;lt112;Added reports",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate Comtrader delivery server to HTTPS,XP-2554,91207,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,20/Jan/20 10:20,04/Aug/20 19:19,22/Feb/21 13:26,03/Feb/20 14:32,,,Pre2020,,,,,,,,,,,"Details to be discussed at Devops COP - https://confluence.energy.svc.dbgcloud.io/display/ED/DevOps+CoP

Remarks:

* make sure the webstart points to HTTPS - this should be already the case, as we had to manually repackage CT to use plain HTTP during XBID PROD deploy
* HTTP version would stop working - inform clients?",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34473600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ezxi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,comtrader-2.5.x,XP-69,XP-2583,XP-2554,master-comtrader-2.5.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - AST request for sFTP access,XP-2553,91129,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,Konstantins.Serafimovs@ast.lv,yn731,16/Jan/20 11:35,31/Aug/20 15:38,22/Feb/21 13:26,25/Mar/20 13:17,,,3.1.0,,,,,,,SFTP,TO_InfraDCNetwork,,,"Latvian TSO Augstsprieguma tikls (AST). Currently using e-mail for communication, planning to move to sFTP.

This is a request to create sFTP access with filled template attached. We first need a test mode or test environment.

Attached:
- Our public key in PEM format (DER possible if needed)
- filled request from
",,cv524,tr866,yn731,,,,,,,,,,,,,,,,,,,,,XBID-4900,SMXBID-1703,,,,,,,,,,,,,,,,,,"03/Feb/20 15:12;tr866;CTSO SFTP SQL CMI DB;https://jira.deutsche-boerse.com/secure/attachment/80009/CTSO+SFTP+SQL+CMI+DB","03/Feb/20 15:12;tr866;CTSO SFTP SQL SPM DB;https://jira.deutsche-boerse.com/secure/attachment/80010/CTSO+SFTP+SQL+SPM+DB","03/Feb/20 15:12;tr866;CUTE SFTP SQL CMI DB;https://jira.deutsche-boerse.com/secure/attachment/80011/CUTE+SFTP+SQL+CMI+DB","03/Feb/20 15:12;tr866;CUTE SFTP SQL SPM DB;https://jira.deutsche-boerse.com/secure/attachment/80012/CUTE+SFTP+SQL+SPM+DB","03/Feb/20 15:12;tr866;LIPA SFTP SQL CMI DB;https://jira.deutsche-boerse.com/secure/attachment/80013/LIPA+SFTP+SQL+CMI+DB","03/Feb/20 15:12;tr866;LIPA SFTP SQL SPM DB;https://jira.deutsche-boerse.com/secure/attachment/80014/LIPA+SFTP+SQL+SPM+DB","03/Feb/20 15:12;tr866;LIPB SFTP SQL CMI DB;https://jira.deutsche-boerse.com/secure/attachment/80015/LIPB+SFTP+SQL+CMI+DB","03/Feb/20 15:12;tr866;LIPB SFTP SQL SPM DB;https://jira.deutsche-boerse.com/secure/attachment/80016/LIPB+SFTP+SQL+SPM+DB","03/Feb/20 15:12;tr866;SIMU SFTP SQL CMI DB;https://jira.deutsche-boerse.com/secure/attachment/80017/SIMU+SFTP+SQL+CMI+DB","03/Feb/20 15:12;tr866;SIMU SFTP SQL SPM DB;https://jira.deutsche-boerse.com/secure/attachment/80018/SIMU+SFTP+SQL+SPM+DB","16/Jan/20 11:47;yn731;rsa.public;https://jira.deutsche-boerse.com/secure/attachment/79258/rsa.public","16/Jan/20 11:48;yn731;sftp connection template_ver3.docx;https://jira.deutsche-boerse.com/secure/attachment/79259/sftp+connection+template_ver3.docx",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,XBID Service Desk (IMT) Questions & Issues,,,,,,33177600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a44g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jan/20 15:40;tr866;Dear Techops,

 new user is requesting access to our SFTP, for following XBID environments: SIMU, LIPA, LIPB, CTSO, CUTE.
He will use same source IP for all these envs. 80.70.19.10 He plans to use same public certificate for all of these environments (which is attached to this ticket).
Can you please start with FW requests (I believe there will be two, one for SIMU sftp server other for LIPA, LIPB, CTSO and CUTE sftp server) and user names (his name is lappastlv) creation including cert upload into relevant servers?","27/Jan/20 10:28;cv524;Monday 27.01.2020 10:22
Created and inserted new account patterns to inventory according to involved environments
xbid_ast_lipa
xbid_ast_lipb
xbid_ast_ctso
xbid_ast_cute
xbid_ast_simu
Pull request: https://github.deutsche-boerse.de/dev/energy.xbid.sftp/pull/12
Pull request #12 was successfully merged into master branch
 nekylam merged commit 03f59ec into master now","27/Jan/20 10:56;cv524;Monday 27.01.2020 10:55
Public SSH key was inserted into required VAULT records","27/Jan/20 11:12;cv524;Monday 27.01.2020 11:07
Required accounts were created in LDAP and FTP server structures.

{noformat}
xbid_ast_lipa
xbid_ast_lipb
xbid_ast_ctso
xbid_ast_cute
xbid_ast_simu
{noformat}


{color:#00875A}*SFTP access was successfully enabled for all requested environments.*{color}","27/Jan/20 15:48;cv524;Monday 27.01.2020 15:37
Firewall request ""320197"" was generated to set up network access permission for involved hosts.



{noformat}
Source IP	Comment Source	Target IP	Comment Target	Protocol	Service
80.70.19.10	AST_SFTP_CLIENT	10.136.152.190	xbcutscha1	TCP	sftp (40200)
80.70.19.10	AST_SFTP_CLIENT	""10.136.152.222,10.136.24.222""	""xbsimucha1, xbsimucha2""	TCP	sftp (40100)
{noformat}

","30/Jan/20 10:35;cv524;Wednesday 29.01.2020 20:49
The firewall request was processed and passed to test.
{quote}=========================================================================================
From: Mail-In CCI <cci@deutsche-boerse.com> 
Sent: Wednesday, January 29, 2020 8:49 PM
To: Lambert Neky <lambert.neky@deutsche-boerse.com>
Subject: Firewall Request: To be reviewed / tested by Requestor (320197)


A firewall request has been sent to you as requestor for test.

------------------
Request-Information:

Request-Type: Addition
Company: Deutsche B?rse AG
Requester: Lambert Neky

Request-Description:
SFTP access for XBID customer ""Augstsprieguma tikls"" XP-2553
------------------

See document details ->  
Notes://NSGDBA1/gdb/dbs/firewall_req2.nsf/0/6AC2FEA1E3CD0189C12584FC004EC14E

(This mail was automatically generated by the Firewall Request Application)
========================================================================================={quote}","31/Jan/20 16:03;tr866;Waiting for customers to confirm the requested mapping of EIC was correct and to verify the SFTP connectivity is working from their side.","03/Feb/20 15:26;tr866;Dear Techops, 

can we please proceed to the last point of assigning sftp user login names to their EIC codes in CMI and SPM?
I.e. we need to run the attached SQL files for each environment once for CMI and once for SPM.
As those are just INSERT commands this can be done on fly with core and smc up and running.

Following attached files need to be run for the following environments:
||Environment Name||SFTP User||DB||Attached filename||
|Cute LipA|xbid_ast_lipa|CMI|[^LIPA SFTP SQL CMI DB]|
|Cute LipA|xbid_ast_lipa|SPM|[^LIPA SFTP SQL SPM DB]|
|Cute LipB|xbid_ast_lipb|CMI|[^LIPB SFTP SQL CMI DB]|
|Cute LipB|xbid_ast_lipb|SPM|[^LIPB SFTP SQL SPM DB]|
|Cute TSO|xbid_ast_ctso|CMI|[^CTSO SFTP SQL CMI DB]|
|Cute TSO|xbid_ast_ctso|SPM|[^CTSO SFTP SQL SPM DB]|
|Cute PX|xbid_ast_cute|CMI|[^CUTE SFTP SQL CMI DB]|
|Cute PX|xbid_ast_cute|SPM|[^CUTE SFTP SQL SPM DB]|
|SIMU|xbid_ast_simu|CMI|[^SIMU SFTP SQL CMI DB]|
|SIMU|xbid_ast_simu|SPM|[^SIMU SFTP SQL SPM DB]|","03/Feb/20 16:27;cv524;Monday 03.02.2020 16:26
Processed ""xblipacmi"", ""xblipaspm"" tables
{noformat}
##########################################################################
-bash-4.2$ psql -p 25016 -d xblipacmi
psql (9.5.9)
Type ""help"" for help.

xblipacmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xblipacmi-#   VALUES (nextval('hibernate_sequence'), 0, 'SFTP_USER', '10X1001A1001B54W', 'xbid_ast_lipa');
INSERT 0 1
xblipacmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xblipacmi-#   VALUES (nextval('hibernate_sequence'), 0, 'PARTY_DEFAULT_TRANSPORT_TYPE', '10X1001A1001B54W', 'SFTP');
INSERT 0 1
xblipacmi=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xblipacmi=# \q
-bash-4.2$ psql -p 25016 -d xblipaspm
psql (9.5.9)
Type ""help"" for help.

xblipaspm=# INSERT INTO ftp_config (party_eic, ftp_user)
xblipaspm-#   VALUES ('10X1001A1001B54W', 'xbid_ast_lipa');
INSERT 0 1
xblipaspm=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xblipaspm=# \q
-bash-4.2$
##########################################################################
{noformat}
","03/Feb/20 16:31;cv524;Monday 03.02.2020 16:30
Processed ""xblipbcmi"", ""xblipbspm"" tables
{noformat}
##########################################################################
-bash-4.2$ psql -p 25017 -d xblipbcmi
psql (9.5.9)
Type ""help"" for help.

xblipbcmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xblipbcmi-#   VALUES (nextval('hibernate_sequence'), 0, 'SFTP_USER', '10X1001A1001B54W', 'xbid_ast_lipb');
INSERT 0 1
xblipbcmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xblipbcmi-#   VALUES (nextval('hibernate_sequence'), 0, 'PARTY_DEFAULT_TRANSPORT_TYPE', '10X1001A1001B54W', 'SFTP');
INSERT 0 1
xblipbcmi=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xblipbcmi=# \q
-bash-4.2$ psql -p 25017 -d xblipbspm
psql (9.5.9)
Type ""help"" for help.

xblipbspm=# INSERT INTO ftp_config (party_eic, ftp_user)
xblipbspm-#   VALUES ('10X1001A1001B54W', 'xbid_ast_lipb');
INSERT 0 1
xblipbspm=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xblipbspm=# \q
-bash-4.2$
##########################################################################
{noformat}
","03/Feb/20 16:35;cv524;Monday 03.02.2020 16:33
Processed ""xbctsocmi"", ""xbctsospm"" tables
{noformat}
##########################################################################
-bash-4.2$ psql -p 25024 -d xbctsocmi
psql (9.5.9)
Type ""help"" for help.

xbctsocmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbctsocmi-#   VALUES (nextval('hibernate_sequence'), 0, 'SFTP_USER', '10X1001A1001B54W', 'xbid_ast_ctso');
COMMIT;INSERT 0 1
xbctsocmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbctsocmi-#   VALUES (nextval('hibernate_sequence'), 0, 'PARTY_DEFAULT_TRANSPORT_TYPE', '10X1001A1001B54W', 'SFTP');
INSERT 0 1
xbctsocmi=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbctsocmi=# \q
-bash-4.2$ psql -p 25024 -d xbctsospm
psql (9.5.9)
Type ""help"" for help.

xbctsospm=# INSERT INTO ftp_config (party_eic, ftp_user)
xbctsospm-#   VALUES ('10X1001A1001B54W', 'xbid_ast_ctso');
INSERT 0 1
xbctsospm=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbctsospm=# \q
-bash-4.2$
##########################################################################
{noformat}
","03/Feb/20 16:45;cv524;Monday 03.02.2020 16:43
Processed ""xbcutecmi"", ""xbcutespm"" tables
{noformat}
##########################################################################
-bash-4.2$ psql -p 25003 -d xbcutecmi
psql (9.5.9)
Type ""help"" for help.

xbcutecmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbcutecmi-#   VALUES (nextval('hibernate_sequence'), 0, 'SFTP_USER', '10X1001A1001B54W', 'xbid_ast_cute');
INSERT 0 1
xbcutecmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbcutecmi-#   VALUES (nextval('hibernate_sequence'), 0, 'PARTY_DEFAULT_TRANSPORT_TYPE', '10X1001A1001B54W', 'SFTP');
INSERT 0 1
xbcutecmi=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbcutecmi=# \q
-bash-4.2$ psql -p 25003 -d xbcutespm
psql (9.5.9)
Type ""help"" for help.

xbcutespm=# INSERT INTO ftp_config (party_eic, ftp_user)
xbcutespm-#   VALUES ('10X1001A1001B54W', 'xbid_ast_cute');
INSERT 0 1
xbcutespm=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbcutespm=# \q
-bash-4.2$
##########################################################################
{noformat}
","03/Feb/20 16:53;cv524;Monday 03.02.2020 16:52
Processed ""xbsimucmi"", ""xbsimuspm"" tables
{noformat}
##########################################################################
-bash-4.2$ psql -p 25202 -d xbsimucmi
psql (9.5.9)
Type ""help"" for help.

xbsimucmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbsimucmi-#   VALUES (nextval('hibernate_sequence'), 0, 'SFTP_USER', '10X1001A1001B54W', 'xbid_ast_simu');
INSERT 0 1
xbsimucmi=# INSERT INTO tbxi035_config (id, version, config_key, party_id, config_value)
xbsimucmi-#   VALUES (nextval('hibernate_sequence'), 0, 'PARTY_DEFAULT_TRANSPORT_TYPE', '10X1001A1001B54W', 'SFTP');
INSERT 0 1
xbsimucmi=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbsimucmi=# \q
-bash-4.2$ psql -p 25202 -d xbsimuspm
psql (9.5.9)
Type ""help"" for help.

xbsimuspm=# INSERT INTO ftp_config (party_eic, ftp_user)
xbsimuspm-#   VALUES ('10X1001A1001B54W', 'xbid_ast_simu');
INSERT 0 1
xbsimuspm=# COMMIT;
WARNING:  there is no transaction in progress
COMMIT
xbsimuspm=# \q
-bash-4.2$
##########################################################################
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,
Shipping is loading all trades/trade flows/sync packages during startup,XP-2550,91183,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qo794,jy268,jy268,17/Jan/20 14:31,04/Aug/20 19:53,22/Feb/21 13:26,22/Jan/20 14:57,,,3.1.0,,Shipping,,,,,,,,,"When starting shipping module all trades / trade flows / sync packages are loaded to the memory.

In method initializeSyncPackageCaches in StartupTask we are loading everything we have in a DB, but only last 2 days are necessary. Unfortunately data in DB is removed after 40 days, but shipping needs only last 2 days in memory to generate files properly.

Current situation can cause following issues:
* Very long startup or failover
* Out of memory if data is bigger than available memory

Solution:
* During startup we should load only data which is 2 days older than last event_log available.",,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34646400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042200825",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-3161-pom-cleanup-develop,XP-PULL-TEST,develop,XP-3094-sonar-gate,XP-3161-develop,XP-TEST,master,XP-TEST2,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ESO-226 - Pen Tests 2019 lessons learnt ,XP-2537,90977,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ei349,ei349,13/Jan/20 09:16,06/Nov/20 09:32,22/Feb/21 13:26,29/Oct/20 13:17,,,XBID 2.0,,CMM,Shipping,Trading,,,PenetrationTest,,,,"Check the external Jira and prepare lessons learnt input for the meeting with Cirosec. 

SP Link: 

https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Penetration%20Test/Penetration%20Tests%20in%202019%20lessons%20learned.xlsx?d=w98e79c3f9e9c43d68a6d96d87dd9a4c1",,ei349,rl336,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ESO-226,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,33609600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4088,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a39k:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jan/20 13:06;rl336;please fill your comments into the sheet on SharePoint: 
https://teams.deutsche-boerse.de/sites/sp0232/_layouts/15/WopiFrame.aspx?sourcedoc{98E79C3F-9E9C-43D6-8A6D-96D87DD9A4C1}&file=Penetration%20Tests%20in%202019%20lessons%20learned.xlsx&action=default

    
 

 


 ","29/Jan/20 14:15;ei349;Couldn't open the URL on SP. I assume this is the correct one: 

https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Penetration%20Test/Penetration%20Tests%20in%202019%20lessons%20learned.xlsx?d=w98e79c3f9e9c43d68a6d96d87dd9a4c1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Define Grafana dashboards for SLA/KPI jobs,XP-2533,90929,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,09/Jan/20 16:17,13/Aug/20 19:41,22/Feb/21 13:26,26/Mar/20 12:49,,,3.1.0,,,,,,,,,,,"Once we have job data, define the dashboards to visualize statuses.

 

For jobs list - see XP-2532 

 

AC: dashboard in Grafana",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,28771200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2531,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000000000030004c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/20 12:49;ll664;Dashboard created - https://grafana.energy.svc.dbgcloud.io/d/pnomLF9Zz/report-tool-jobs?orgId=4
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA/KPI reporting - ingest job data into InfluxDB,XP-2532,90924,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ll664,ll664,09/Jan/20 15:14,13/Aug/20 19:41,22/Feb/21 13:26,20/Feb/20 11:01,,,3.1.0,,,,,,,,,,,"Monitoring (no alerts)

We should setup a data ingestion (Telegraf extension??) of the jobs statuses into InfluxDB, so we can later create dashboards/alerts.

Let's begin with following jobs:
{code:java}
collect-boundary-sla-data
collect-performance-kpi-data                   
collect-spm-files-generation-data              
credit-points                                  
generate-boundary-sla-report                   
generate-performance-kpi-report  
{code}
ReportTool has a REST API that reports jobs status data, insert them into InfluxDB.

 

AC: 
 * data in influx. 
 * data prepared to XP-2533 (dashboard in grafana with status of jobs)",,ek176,ll664,,,,,,,,,,,,,,,,,,,XP-2534,XP-2533,,,,,,,,,,,,,,XP-2759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31622400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2531,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000etw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-ams,netbackup-role,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Feb/20 08:48;ll664;Telegraf collector script is ready here: [https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/blob/develop/report-tool/src/scripts/telegraf_job_status_collector.py]

It also part of the application tar package, so it's deployed to the host together with the app.

 

What is missing:
 # Create an Telegraf exec plugin confuguration, something like:
{code}
[[inputs.exec]]
 command = ""/home/ll664/workspace/m7.xbid-report-tool/report-tool/src/scripts/telegraf_job_status_collector.py --report-rest-api-url http://localhost:8080 --influx-measurement report_tool_jobs""
 data_format = ""influx""
# name_suffix = ""_custom""
 interval = ""60s""
 {code}
The plugin could execute the script in short interval, as the collected job statuses are idempotent (the same job status won't insert a new metric).
# Deploy the Report Tool/Telegraf configuration to syt1 ({{xbsyt1sla1}} / {{xbsyt1sla2}} hosts) and test the data ingestion (via Influx CLI probably).
 

 ","19/Feb/20 14:40;ek176;The data for xbsyt1sla1 are in ingested by Telegraf and InfluxDB
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=trade-volume-hour-to-delivery-import,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582006260000000000
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=trade-volume-hour-to-delivery-report,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582013700000000000
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=weighted-average-price-import,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582006320000000000
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=weighted-average-price-last-trading-hour-import,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582006380000000000
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=weighted-average-price-last-trading-hour-report,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582015500000000000
> report_tool_jobs,client=xbid,client_environment=syt1,datacenter=equinix,group=sla,host=xbsyt1sla1,host_group_module=xbsyt1sla1\ -\ sla\ -\ xbid_syt1,instance=sla1,jobName=weighted-average-price-report,machine=sla,module=xbid_syt1,product=xb jobRuntimeSec=0i,status=0i,totalProcessedRecords=0i 1582014600000000000","21/Feb/20 14:19;ek176;Used the http plugin (Telegraf). Did not use JSON data format (converts everything to floats). Used 'influx' data format
{code:java}
[[inputs.http]]
  urls = [
    ""http://localhost:8080/telegraf-stats-influx""
  ]
  method = ""GET""
  headers = {""X-Special-Header"" = ""telegraf""}
  timeout = ""10s""  
  data_format = ""influx""
  interval = ""60s""
{code}","21/Feb/20 14:23;ek176;Note that status=0 means OK, status=1 means error","21/Feb/20 17:07;ek176;Presentation about TICK prepared: [https://github.deutsche-boerse.de/ek176/shared/tree/master/200219_TICK]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze penetration tests finding s for SPM ,XP-2525,90880,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,ei349,ei349,09/Jan/20 09:08,13/Aug/20 20:12,22/Feb/21 13:26,09/Jan/20 18:38,,,3.1.0,,Shipping,,,,,,,,,"Please check the related Jira, briefly analyze the tasks in the epic and provide description of fix and fill SP estimate. ",,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35337600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000006",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/20 17:00;jy268;Please review my comments and estimates in the ticket. If you agree with them, close the ticket.","09/Jan/20 18:38;ei349;Thank you [~jy268]. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze penetration tests findings for CMM ,XP-2524,90879,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,09/Jan/20 09:08,04/Aug/20 19:53,22/Feb/21 13:26,20/Jan/20 16:00,,,3.1.0,,,,,,,,,,,,,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34387200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ezy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/20 16:00;ll664;Went through all of the issues listed in the linked JIRA, added comments whether the finding is valid/implementation possible. Further work to be done in the respective tasks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze penetration tests findings for SOB,XP-2523,90878,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,09/Jan/20 09:07,04/Aug/20 19:53,22/Feb/21 13:26,21/Jan/20 13:20,,,3.1.0,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35424000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ezr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application labeling: Reports,XP-2521,90852,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,zi174,ek176,08/Jan/20 12:54,01/Sep/20 12:45,22/Feb/21 13:26,02/Mar/20 16:44,,,3.1.0,,,,,,,,,,,"According to the data leakage standard, it's necessary to label all documents, reports, GUI etc. which are visible/send to the customer. We have to provide an information of the security classification (public, internal, confidential, strictly confidential)

· All DBG documents, physical and electronic, must be labelled based on the confidentiality of included information.

· DBG strictly confidential and confidential information shall only be disclosed outside DBG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement.

!screenshot-1.png!

Affected areas:



*Reports*
 * SLA reports - (Performance, XBID availability, Service Boundaries, Credit points -1SP)
 * ACER Reports - 1SP
 * CMM/CMI reports - ATC, TAR, RCA, NSF, NetP, RID, IAR, OCC, BG Allocation, Results Document, Right Document, Messages Report, Allocated Capacity Report, ATC Values report, Activity Report, Balancing Group Report, User - 5SP
 * Report
 * SOB reports - TC540, TC810, TC830 - 1SP
 * SM reports - SHC, SXC, SHS, XBR, XBN, HNS, HNT, CTS - 2SP

*If applicable",,ek176,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30758400,,,,,,,,,,,,,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ev",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1 (S),Alpha Sprint 2,Alpha Sprint 3 (S),,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,xbid-losses-poc,XP-PULL-TEST,XP-2521-labeling-cmi-leftovers,develop,XP-2694-xbid-3.0.x-latest-tag-fix,XP-3094-sonar-gate,XP-TEST,XP-3161-develop,master-acceptance,master,XP-TEST2,acceptance,XP-3161-pom-cleanup-develop,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 15:53;tr866;Regarding SM don't forget about Reports downloaded by Central Admin.
Also what about Acknowledgement file(ACK file)?","02/Mar/20 16:44;tr866;All subtasks were done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application labeling: e-mails,XP-2520,90851,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,ek176,08/Jan/20 12:54,01/Sep/20 10:45,22/Feb/21 13:26,12/Aug/20 18:22,,,3.1.1,,,,,,,,,,,"According to the data leakage standard, it's necessary to label all documents, reports, GUI etc. which are visible/send to the customer. We have to provide an information of the security classification (public, internal, confidential, strictly confidential)

· All DBG documents, physical and electronic, must be labelled based on the confidentiality of included information.

· DBG strictly confidential and confidential information shall only be disclosed outside DBG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement.

!screenshot-1.png!

Affected areas:

*Emails*
 * all emails sent to the customer need labeling - preliminary consideration is to set this label in email client - just keep in mind that the email must have a same classification as sent file/document

 - 5SPs

*If applicable

 

-Note: This might be solved on the e-mail server level. See M7P-4732-

Note2: Tell BizOps ([~ub113], [~yn731]) to include it in the list for informing our customers. 

------------------------------------------------------
Affected projects and modules:
* xbid (core, cmm, cmi, sob)
* access-management (AMS aka GA)
* m7-shipping (smc, smi)",,ne232,od044,qo794,rl336,zi174,,,,,,,,,,,,,,,,,,,,,,,,XP-3375,,,,,,,,,,,,,,"24/Jul/20 08:39;ne232;DBG_GS_Crypto_Guideline_v0.10_200428_handover.docx;https://jira.deutsche-boerse.com/secure/attachment/85991/DBG_GS_Crypto_Guideline_v0.10_200428_handover.docx","12/Aug/20 15:15;od044;Screenshot 2020-08-11 at 18.50.28.png;https://jira.deutsche-boerse.com/secure/attachment/86434/Screenshot+2020-08-11+at+18.50.28.png","12/Aug/20 18:20;od044;am-cert-expiring.png;https://jira.deutsche-boerse.com/secure/attachment/86447/am-cert-expiring.png","12/Aug/20 18:20;od044;am-pwd-expiring.png;https://jira.deutsche-boerse.com/secure/attachment/86446/am-pwd-expiring.png","12/Aug/20 18:20;od044;cmi-file.png;https://jira.deutsche-boerse.com/secure/attachment/86448/cmi-file.png","13/Aug/20 11:45;od044;cmm-new-user.png;https://jira.deutsche-boerse.com/secure/attachment/86454/cmm-new-user.png","12/Aug/20 18:20;od044;cmm-reset-pwd.png;https://jira.deutsche-boerse.com/secure/attachment/86445/cmm-reset-pwd.png","12/Aug/20 18:20;od044;sm-file.png;https://jira.deutsche-boerse.com/secure/attachment/86443/sm-file.png","13/Aug/20 11:45;od044;sm-new-user.png;https://jira.deutsche-boerse.com/secure/attachment/86455/sm-new-user.png","12/Aug/20 18:20;od044;sm-reset-pwd.png;https://jira.deutsche-boerse.com/secure/attachment/86444/sm-reset-pwd.png","13/Aug/20 11:45;od044;sob-new-user.png;https://jira.deutsche-boerse.com/secure/attachment/86453/sob-new-user.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16675200,,,,,,,,,,,,,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b9on:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Jul/20 08:37;ne232;[~ei349] [~zi174]: This is still requierd, further information can be found in the attached crypto guideline.","28/Jul/20 12:34;zi174;It's not set how to approach it. I could imagine that we will have some disclaimer at the end of the email (e.g. The above email is classified as Confidential)

[~ne232] might you please check and let us know if the proposed approach above is ok from security point of view?","30/Jul/20 11:21;rl336;[~zi174] it is defined in the data leakage prevention Standard, see new risk assessment tool: 
772Data Leakage Prevention StandardAll outgoing emails must be labelled. ISO A.8.2.2
773Data Leakage Prevention StandardAll outgoing emails, physical and printable electronic documents must be labelled immediately when they are created. If the document already exists without a label, it must be labelled additionally. ISO A.8.2.2

I have uploaded it to SharePoint: https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/IT%20Policies%20and%20Standards/DBG_GS_Data_Leakage_Prevention_Standard_ISF_v2.0.pdf

see page 8, 3.1Labelling of information(ISO A.8.2.2) - confidentiality Label must be seen at the beginning of the email (or title page) - to put it at the end of the email is not sufficient","30/Jul/20 12:02;zi174;[~rl336], thank you for information. So, if I understand correctly we can use the same text I mentioned (i.e. The below email is classified as Confidential) and jut put it at the beginning of the email.

 

[~qo794] so please use some wording like ""The below email is classified as Confidential"" which we use at DBAG.

Example:

--------------------------------------

The below email is classified: Confidential

bla bla bla

bla bla

Best regards

Jakub

----------------------","05/Aug/20 10:18;qo794;Issue split into:
|XP-3375|(Split 1) Application labeling: e-mails|
","06/Aug/20 08:23;qo794;Text ""The below email is classified as Confidential"" added at the beginning of all emails in:
* core
* sob
* cmi
* cmm
* smc
* smi
* GA aka AMS","12/Aug/20 18:22;od044;Test passed on XBID version 3.1.2 and SM 3.1.1
- all emails contains label 'The below email is classified as Confidential'
- verified on the following emails :
-- SOB reset password
-- CMM reset password
-- CMI mail with file
-- AMS password and certificate email warning about expiring 
-- SM reset password
-- SM email with file 

Here are some screenshots of email
 !sm-file.png!  !sm-reset-pwd.png!  !cmm-reset-pwd.png!  !am-pwd-expiring.png!  !am-cert-expiring.png!  !cmi-file.png! ","13/Aug/20 08:24;qo794;[~od044] please also test an email sent when a new user gets created as it is a different code (at least in xbid project), thanks.","13/Aug/20 11:45;od044;Emails for new users within SOB, CMM, SM modules are fine as well 
 !sob-new-user.png!  !cmm-new-user.png!  !sm-new-user.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V4 TLS client certificates not bound to user,XP-2518,90845,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,08/Jan/20 12:18,04/Aug/20 19:53,22/Feb/21 13:26,04/Jun/20 10:03,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V4|
|LOCATION: Web application|
|RISK: Medium|
|DESCRIPTION: To access the SM application it is necessary to have a valid client certificate as well as a valid combination of user name and password. However, the certificates are not bound to user accounts on the server side. Therefore, any valid client certificate can be used to login to arbitrary user accounts (the corresponding username and password are still required). So overall the client certificate does not serve its purpose as a second factor.|
|THREAT: This procedure makes it easier for an attacker to successfully launch an attack in such a way that he only needs to have a valid client certificate. If the attacker has a certificate, he can use it to attack valid combinations of username and password for every other user in the system.|
|RECOMMENDATION: During the login the server should verify that the username inside the TLS client certificate matches the requested account’s username.|",,ek176,iO924,jy268,ll664,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s0004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/20 16:53;jy268;Has to be verified, if it is really an issue, from quick code inspection I have noticed that it could be a problem. It should be managed somehow on apache level or in
{code}
com.deutscheboerse.m7.shipping.web.X509CustomFilter
{code}","23/Jan/20 15:07;iO924;https://vmt.deutsche-boerse.de/browse/PT-1567","04/Jun/20 09:56;ll664;This was just an environment misconfiguration, the check is enabled in PROD, but was disabled in SIMU ({{X509_ENABLED}} property). The confluence page has been create with the checklist of what should be configured has been created (see chapter _Penetration test configuration checklist_).

https://confluence.energy.svc.dbgcloud.io/display/XBID/Pentest+2020+findings+elimination+fahrplan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V10 Multiple logons/concurrent sessions,XP-2516,90843,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,08/Jan/20 12:18,04/Aug/20 19:53,22/Feb/21 13:26,04/Jun/20 08:54,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V10|
|LOCATION: Web application (session mechanism)|
|RISK: None|
|DESCRIPTION: Users are able to log on to the web application multiple times, which means they may have several concurrent sessions. If this is not explicitly desired, it should be prevented.
 Furthermore, the application lacks a mechanism that allows the user to control existing sessions – i.e. to view active sessions and to end other, either outdated or potentially fraudulent sessions.|
|THREAT: Due to the possibility to establish multiple concurrent sessions with one account, an attacker who acquires a session ID can be logged on at the same time as the normal user without the user noticing it.|
|RECOMMENDATION: We recommend preventing multiple concurrent sessions for the same user in the application. A new session should terminate existing sessions. Alternatively, the application could display active sessions in order to let the user terminate them. However, to implement such a mechanism the sessions ID needs to be checked as explained in section 7.3.|",,ek176,iO924,jy268,ll664,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2io:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/20 15:26;jy268;SMI does not allow concurrent sessions. The only thing which worries me is statement that
{code}
an attacker who acquires a session ID can be logged on at the same time
{code}
which has to be verified. It might be an issue, so in this case we have to find what is the industry standard which has the smallest impact possible.","23/Jan/20 16:01;iO924;https://vmt.deutsche-boerse.de/browse/PT-1563","19/Mar/20 10:35;ek176;Relates to session mgmt: XP-2517","04/Jun/20 08:51;ll664;This is false positive, SM does not allow concurrent sessions. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V9 Missing Referrer-Policy header,XP-2515,90842,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,zi174,zi174,08/Jan/20 12:18,05/Aug/20 09:11,22/Feb/21 13:26,05/Jun/20 10:59,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V9|
|LOCATION: Web server configuration|
|RISK: None|
|DESCRIPTION: The referrer policy mentioned in section 8.1.1 can also be set without CSP as the dedicated Referrer-Policy header. This allows to control information disclosure caused by the Referer header. 
 (Note: The word “referrer” has been misspelled in Referer header, while the spelling in Referrer-Policy header is correct. )
 The Referer header is sent along in requests by many browsers – for example, after clicking on a link or when requesting embedded resources – without the user having to take any specific action. Usually, the value (origin) is the full URI of the website where the link has been clicked or the resource been embedded, including any GET parameters. 
 This provides referenced third-party pages not only with information about which website the user has visited but also which specific subpage, thus greatly easing user profiling (e.g. via tracking mechanisms). If the page transfers sensitive information as GET parameters, this information is disclosed to third parties as well. Moreover, the Referer header is usually recorded in the access logs of web servers by default.
 Using the Referrer-Policy header, this kind of information disclosure can be reduced – provided that the header is supported by the respective browser, which is the case for all common browsers (for Edge and Internet Explorer at least partly) .|
|THREAT: The Referer header transmits the URL of the calling page, therefore making it easier for third parties to create a profile of the application’s users. 
 In case the application transfers sensitive information in the URL, this information is also transmitted to third parties.|
|RECOMMENDATION: We recommend setting the Referrer-Policy header to a proper value if it is not already covered by the CSP.
 To be precise, the following values are valid for the header; the domain of the source URI is being referred to as the origin. All resources served from the same domain/origin are “internal”, whereas all other (sub)domains are “external”:
 • no-referrer:
 The Referer header is not sent along with any resource – neither internal nor external.
 • no-referrer-when-downgrade:
 The Referer header is generally sent along with the full URI to internal and external domains. Only if the source uses HTTPS but the target is only available via HTTP, the Referer header is not sent along.
 • same-origin:
 The Referer header is only sent to resources of the source domain but not to any others. If the URI scheme changes from HTTPS to HTTP (or vice versa), those URIs are regarded as two different origins.
 • origin:
 The Referer header only contains the source domain but not the full URI. This behavior is the same for internal and external targets.
 • strict-origin:
 The Referer header only contains the source domain but not the full URI. This behavior is the same for internal and external targets; however, HTTPS origins are not transmitted to HTTP domains.
 • origin-when-cross-origin:
 The Referer header contains the full source URI for internal resources but is shortened to the source domain for external ones.
 • strict-origin-when-cross-origin:
 The Referer header contains the full source URI for internal resources but is shortened to the source domain for external ones. If the URI scheme changes from HTTPS to HTTP (or vice versa), no Referer header is sent along.
 • unsafe-url:
 The Referer header contains the full source URI for all internal and external targets and therefore does not provide any protection.
 Moreover, some browsers (e.g. IE 11 and Edge) do not support the full specification, but only an older draft version with the following directives:
 • never:
 Equivalent to no-referrer
 • always:
 Equivalent to unsafe-url
 • origin:
 Equivalent to origin above
 • default:
 Equivalent to no-referrer-when-downgrade
 From a data protection perspective, no-referrer is to be preferred. For internal use of the Referer header, we recommend same-origin. If external resources are embedded that rely on the presence of the Referer header (e.g. to set CORS headers to proper values), we recommend using strict-origin or at least strict-origin-when-cross-origin.
 For maximum compatibility or if the application is mainly used with Microsoft browsers, we recommend the origin option, provided that the headers are not dynamically set in dependence on the User-Agent header.
 Note: Depending on the implementation, some browsers always send along the Referer header; it might, however, not contain any value.|",,ek176,hj444,iO924,jy268,ll664,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22636800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2ig:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,xbid-dev-env,traversal-XP-2485,XP-2506-xbid-dev-env,XP-2515-prod,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Jan/20 15:20;jy268;One has to check if above header is present in the application. If not identify possible impact and implement.","23/Jan/20 15:58;iO924;[https://vmt.deutsche-boerse.de/browse/PT-1572|https://vmt.deutsche-boerse.de/browse/PT-1550]","19/Mar/20 10:22;ek176;See comments in XP-2504. Might be configurable in Apache.","03/Jun/20 19:59;ll664;Configured 'no-referrer' policy for all webservers, it was actually easier than doing that separately for CMM/SOB/SPM.

{code}
Header always set Referrer-Policy ""no-referrer""
{code}

Deployed to syt1, all UIs seems to be working fine, but check by additional pair of eyes would be nice.

PR for future deployements (to be added to respective SERVICE ticket):
NON-PROD: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/664
PROD: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/663

Once sucesfully tested, following could be also closed:
XP-2504

PRs added to respective future deployments: SERVICE-3669, SERVICE-2640, SERVICE-2664

","04/Jun/20 07:17;ll664;Please do some basic smoke tests on UIs in SYT1, Apaches have been redeployed there.","05/Jun/20 11:00;hj444;UI Smoke test done :
CMM, SOB, CMI, SPM logins - done.
Allocations done.
Trades done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V8 Missing Content-Security-Policy header,XP-2514,90841,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,zi174,08/Jan/20 12:18,05/Aug/20 10:54,22/Feb/21 13:26,04/Jun/20 13:28,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V8|
|LOCATION: Web server configuration|
|RISK: None|
|DESCRIPTION: Modern web applications often consist of numerous individual elements, such as scripts, style sheets or images. Like in the present case, not only self-developed components but also third-party scripts or frameworks are used. Complex requirements and short release cycles can sometimes result in relevant security flaws. Such security flaws facilitate well-known attacks like cross-site scripting (XSS), clickjacking and other code injection attacks as well as the associated theft of sensitive data or website defacement.
 One way of making it harder to perform such attacks successfully is the use of the Content Security Policy concept. Content security policies are sent as part of the server response in the form of an HTTP response header (CSP header) and are enforced by the browser. The various CSP directives allow the administrator of an application/a web or application server to specify the sources allowed for different web page contents a browser may load and execute, for example.
 For instance, there are source directives for JavaScript, CSS, HTML frames, fonts, images, audio and video files, embedded objects such as Java applets, ActiveX and other HTML5 features. The respective goal is to make it harder for an attacker to inject contents into the legitimate page. Regarding JavaScript/XSS, for example, CSP offers the option of restricting the execution to defined external code modules or ensuring the JavaScript code’s integrity with hash sums or random tokens.
 Thus, the CSP header does not fix any server-side security flaws like incomplete output encoding, but it can complicate the client-side exploitation of such vulnerabilities.|
|THREAT: The application does not enable some very helpful browser-based protective mechanisms. One aim of these mechanisms is to make the execution of script code injected into the application more difficult (cross-site scripting). This attacking technique allows an attacker to steal sensitive cookies, for example. For this purpose, JavaScript code is often injected into the web application and executed in the user’s browser.|
|RECOMMENDATION: The Content-Security-Policy header can prevent the successful exploitation of certain types of attack, particularly cross-site scripting, effectively. The use of some CSP directives (e.g. script-src) sometimes requires adjustment to the existing web application. We thus recommend checking compatibility of your own web applications thoroughly before deploying any CSP. The Content-Security-Policy-Report-Only header combined with the report-uri directive serve this purpose, for example. It may be necessary to allow scripts and CSS information again using the unsafe-inline option. Even if CSP does not allow restricting scripts, directives may be set to forbid unused media and plug-in types or to specify target addresses allowed for XMLHttpRequest with the aim to improve the security level.
 CSP version 2 is supported by almost all common browsers except Internet Explorer. Full support for CSP version 1 and version 2 is, for example, provided by the Google Chrome (desktop and mobile), Mozilla Firefox, Opera and Apple Safari (desktop and mobile) browsers in their latest versions. As of version 15, Microsoft Edge largely supports the CSP version 2 directives.
 Among the many CSP directives, we recommend particularly considering the following directives:
 “upgrade-insecure-requests” directive
 The upgrade-insecure-requests CSP directive tells the browser to interpret potentially insecure HTTP links to internal and external resources as well as domain-internal hyperlinks in the source code as HTTPS URLs, so they will be accessed encrypted. Before applying this directive to the productive environment, make sure your own contents and linked third-party contents can be accessed both via HTTP and HTTPS at the same host and path name. Otherwise, individual web pages or linked resources may possibly no longer be accessed. The CSP directive is then set using the following syntax:
 Content-Security-Policy: upgrade-insecure-requests
 Internet Explorer does not support this CSP directive and requests the linked resources as indicated in the web page’s source code (HTTP or HTTPS).
 “frame-ancestors” directive
 The frame-ancestors directive specifies whether a page/resource may be embedded in the web pages of third-party websites using <frame>, <iframe>, <object>, <embed> or <applet>. To complicate clickjacking and cross-frame scripting attacks, we recommend setting this CSP directive in addition to the X-Frame-Options header, as this header is gradually replaced with the new CSP directive. Using both headers ensures the best possible browser support, since Microsoft Internet Explorer does not yet support the frame-ancestors directive but respects the X-Frame-Options header instead.
 The syntax for setting the CSP directive is as follows:
 Content-Security-Policy: frame-ancestors [source list]
 Equivalent to X-Frame-Options, there are three possible values for frame-ancestors:
 • frame-ancestors 'none': (equivalent to “X-Frame-Options: DENY”)
 The page cannot be displayed in a frame/iframe, regardless of the site attempting to do so.
 • frame-ancestors 'self': (equivalent to “X-Frame-Options: SAMEORIGIN”)
 The page can only be displayed in a frame/iframe if the embedding page comes from the same domain.
 • frame-ancestors uri: (equivalent to “X-Frame-Options: ALLOW-FROM uri”)
 The page can only be displayed in a frame/iframe on the specified origin.
 Referrer policy
 The referrer policy allows determining the value used in the Referer request header for links and resource requests. By default, without the referrer policy, the entire path from which the user has accessed the resource, including GET parameters, is transmitted when requests are made to web resources. The referrer policy can in fact also be set as a CSP directive. Due to recent browser compatibility, however, we recommend using the referrer policy in the <head> tag of the web page. As an independent referrer policy, the values set here are considered by all common browsers except Internet Explorer:
 <meta name=""referrer"" content=""value"">
 Valid values are: no-referrer, no-referrer-when-downgrade, origin, origin-when-cross-origin and unsafe-url. Microsoft Edge does not support these values but requires the older keywords never, always, origin and default, which other browsers also still accept.
 Example of use
 The CSP header can be set in a number of different ways, as is shown in the following example for the default-src directive. Several directives may also be specified, which have to be separated by semicolons.
 • Apache HTTP Server: 
 o In httpd.conf or alternatively in an .htaccess file:
 § Header set Content-Security-Policy ""default-src 'self'""
 o After adding this line, the web server must be restarted.
 • Via <meta> tag in the source code of an HTML page (not supported by all CSP directives):
 <head>
   <meta http-equiv=""Content-Security-Policy"" content=""default-src 'self';"">
 </head>
 Important: <meta> must be the first element in the <head> element.|",,ek176,iO924,jy268,ll664,od044,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0al3z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 6 (S),,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2514-adding-content-security-policy-header-SPM-prod,xbid-dev-env,traversal-XP-2485,XP-2942,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,XP-2514-adding-content-security-policy-header-SPM,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Jan/20 15:12;jy268;One has to check all those headers provided if those are applicable in our application. If yes it has to be implemented, the only risk is the difference between modern applications and microsoft edge.","23/Jan/20 15:56;iO924;[https://vmt.deutsche-boerse.de/browse/PT-1571|https://vmt.deutsche-boerse.de/browse/PT-1549]","19/Mar/20 10:21;ek176;See comments in  XP-2501: Might be configurable in Apache","06/Apr/20 15:47;jy268;https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/624 <- PROD MR
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/625 <- NON PROD MR","06/Apr/20 15:50;jy268;Please deploy application to one of sytX (already deployed to syt2) and check if header Content-Security-Policy is present in the response. Please do a smoke test on SMI and check if no errors when downloading resources are present in browser console log.","07/Apr/20 20:21;od044;Test passed on SYT2
- smoke test on browser Chrome, Firefox, Edge - all gui funcionality works properly, no error in console - ok
- all request-response contains - ok
{code:java}
Content-Security-Policy: default-src 'none'; script-src 'self' 'unsafe-inline'; connect-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline'; base-uri 'self'; form-action 'self'; font-src 'self'; {code}
- WS API - ok
{code}
curl -ki --noproxy 10.136.142.20 -u DNMSPM01:xbidtest01 -X GET https://10.136.142.20:60803/spm/wsapi/v1/files/search/findByAck?ack=true
HTTP/1.1 200 200
Date: Tue, 07 Apr 2020 16:09:48 GMT
Server: Apache
Strict-Transport-Security: max-age=63072000; includeSubdomains;
Content-Security-Policy: default-src 'none'; script-src 'self' 'unsafe-inline'; connect-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline'; base-uri 'self'; form-action 'self'; font-src 'self'; 
Set-Cookie: JSESSIONID=B1D10CC399D9428D7932813C69C15061; Path=/spm; Secure; HttpOnly
Set-Cookie: last-user=DNMSPM01; Path=/; Secure
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
Strict-Transport-Security: max-age=31536000 ; includeSubDomains
X-Frame-Options: DENY
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
Content-Type: application/hal+json;charset=UTF-8
Transfer-Encoding: chunked

{
  ""_embedded"" : {
    ""files"" : [ {
      ""id"" : 221648,
      ""creationTime"" : ""2020-04-06T22:00:06.487Z"",
      ""name"" : ""20200408_SHC_300_11XID-CAPACITY-9_SATS01_TSDA1_100_2.xml"",
      ""type"" : ""SHC"",
      ""eventTime"" : ""2020-04-06T22:00:00.000Z"",
      ""deliveryDate"" : ""2020-04-07T22:00:00.000Z"",
      ""mId"" : ""f6cf6c81e94d99f5d59b6e4b712e7324"",
      ""mVersion"" : 100,
      ""sequence"" : 2,
      ""sentThroughTransport"" : ""WS"",
      ""size"" : 423,
      ""ackCheckRequired"" : false,
      ""nameWithoutSeq"" : ""20200408_SHC_300_11XID-CAPACITY-9_SATS01_TSDA1_100"",
      ""ack"" : true,
      ""ackPositive"" : true
    } ]
  },
  ""_links"" : {
    ""self"" : {
      ""href"" : ""https://10.136.142.20:60803/spm/wsapi/v1/files/search/findByAck?ack=true&page=0&size=10""
    }
  },
  ""page"" : {
    ""size"" : 10,
    ""totalElements"" : 1,
    ""totalPages"" : 1,
    ""number"" : 0
  }

{code}","04/Jun/20 12:47;jy268;I am reopening as following pull requests are still not merged:

https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/624 <- PROD MR
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/625 <- NON PROD MR","04/Jun/20 13:20;ll664;I think the ticket itself can be closed, I'll update the future deployments with PRs.","04/Jun/20 13:28;ll664;PRs added to respective future deployments: SERVICE-3669, SERVICE-2640, SERVICE-2664",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V3 Lacking password policy,XP-2513,90840,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,zi174,zi174,08/Jan/20 12:18,28/Aug/20 14:22,22/Feb/21 13:26,28/Aug/20 14:22,,,3.1.1,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V3|
|LOCATION: Web application, affected URL: https://spm-simu1.xbid.deutsche-boerse.com/spm/changePassword|
|RISK: Medium|
|DESCRIPTION: Within the application the password can be changed by the user by providing the previous password. During the assessment it was possible to change the password to a single character and successfully log in to the application afterwards.|
|THREAT: The application does not implement a password policy, allowing users to choose trivial passwords. However, in addition to the password, a client certificate is necessary to successfully log in to the application. This significantly reduces the risk that a user is compromised because he has chosen a trivial password.|
|RECOMMENDATION: A strong password policy should be implemented in the application. We recommend keeping the requirements on the password configurable to be able to adapt the password policy without having to modify the code at a later time.|",,ei349,ek176,iO924,jy268,ll664,od044,qo794,ub113,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2473,,,,,,,"28/Aug/20 14:18;od044;Screenshot 2020-08-28 at 14.15.14.png;https://jira.deutsche-boerse.com/secure/attachment/86822/Screenshot+2020-08-28+at+14.15.14.png","28/Aug/20 14:18;od044;Screenshot 2020-08-28 at 14.16.14.png;https://jira.deutsche-boerse.com/secure/attachment/86823/Screenshot+2020-08-28+at+14.16.14.png","28/Aug/20 14:18;od044;Screenshot 2020-08-28 at 14.16.42.png;https://jira.deutsche-boerse.com/secure/attachment/86824/Screenshot+2020-08-28+at+14.16.42.png","28/Aug/20 14:18;od044;Screenshot 2020-08-28 at 14.17.46.png;https://jira.deutsche-boerse.com/secure/attachment/86825/Screenshot+2020-08-28+at+14.17.46.png",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bbbp:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,Alpha Sprint 11 (S),HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/20 15:03;jy268;One has to verify if there is password policy in production. Maybe it is switched off on simu only. If there is none on prod, it has to be implemented.","23/Jan/20 15:06;iO924;https://vmt.deutsche-boerse.de/browse/PT-1566","04/Jun/20 13:24;ll664;[~ub113], please check with customers, this is the same as linked XP-2473. Assigning to you just for the sake of the process, since it's the same problem, and the answer to XP-2473 from customer would apply to this one as well.","07/Aug/20 11:21;ub113;Communicated in XBID-5195 ","19/Aug/20 14:29;ei349;Approved for 3.1.1 on beginning of September. ","25/Aug/20 12:30;od044;Please keep in mind to have the same policy among all modules CMM,SOB and SM. ","25/Aug/20 13:39;qo794;Password policy changes will be implemented and tested within XP-2473.","27/Aug/20 16:50;yo218;I just had a short look into the LDAP server and password policies for SPM tree exist. Further testing is required","28/Aug/20 14:19;od044;Test passed 
- verified on SYT1 
- a new policy has been updated in LDAP 
- SPM reflect a new policy 
!Screenshot 2020-08-28 at 14.15.14.png!  
!Screenshot 2020-08-28 at 14.16.14.png!  
!Screenshot 2020-08-28 at 14.16.42.png!  
!Screenshot 2020-08-28 at 14.17.46.png! 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P4-V5 TIT Insufficient protection of sensitive information (storage in Local Storage),XP-2512,90839,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,08/Jan/20 12:17,04/Aug/20 19:53,22/Feb/21 13:26,06/Apr/20 08:43,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240, FINDING:  P4-V5|
|LOCATION: Web application|
|RISK: Low|
|DESCRIPTION: The SM application stores sensitive data in the Local Storage of the browser. This data can be read using JavaScript code and might be disclosed to an attacker in conjunction with XSS vulnerabilities.
 In the present case, detailed information about a user and the content of the displayed tables within the application are stored in the Local Storage.|
|THREAT: The Local Storage is used for the storage of sensitive information. In case of a cross-site scripting vulnerability, an attacker can read the stored information and plan further attacks based on it.|
|RECOMMENDATION: We recommend checking whether this information indeed needs to be stored on the client side.|",,ek176,iO924,jy268,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29376000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0akx2:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-3161-pom-cleanup-develop,develop,XP-3161-develop,XP-3094-sonar-gate,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Jan/20 15:02;jy268;According to my knowledge, we are not using localStorage in SM. It has to be checked again, I just found one place where it is used, but it seems to be part of external library. One has to check if it is used at all, my optimistic assumption is that it is not used explicitly in the app.","23/Jan/20 15:20;iO924;https://vmt.deutsche-boerse.de/browse/PT-1568","19/Mar/20 10:10;ek176;IMO it's about web browser's web storage (localStorage/sessionStorage). 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
implementation due 31/3 - Analyze effort and needed actions to migrate remaining environments to AZUL JDK & upgrade OS to RH 7.6,XP-2508,90825,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,ei349,ei349,08/Jan/20 09:42,04/Aug/20 19:53,22/Feb/21 13:26,10/Mar/20 07:37,XBID 2.0,,3.1.0,,,,,,,Azul,waiting-techops,,,"h1. {color:#00875a}Obsolete JDK removal from XBID environments{color}
h2. Current Situation

[~cv524] together with [~rehapav] did analysis of remaining Oracle JDK installations on XBID environments and there are still a lot of Oracle JDK usages. 
{panel:title=Lambert's mail from 12 December 2019 14:03}
Hello everybody,

 

according to agreement I completed short information about presence of separate versions of java on hosts belonging to “Energy” section.
 Please, keep in mind currently there are several versions of “ORACLE” based java packages. Even those with “SRVOPS” naming identification are “ORACLE” java packages in reality.

 

The background excel sheet with background data is attached

 
|Package|Environment|
|Hostname|M7|XBID|Energy|Total|
|XBID-zulu-8-8.36.0.2-1|51|108|0|159|
|java-1.8.0-oracle-1.8.0.111-1jpp.4.el7|12|0|0|12|
|java-1.8.0-oracle-1.8.0.121-1jpp.1.el7_3|8|1|0|9|
|java-1.8.0-oracle-1.8.0.141-1jpp.1.el7_3|5|94|1|100|
|java-1.8.0-oracle-1.8.0.65-1jpp.3.el7_1|0|1|0|1|
|java-1.8.0-oracle-1.8.0.71-1jpp.1.el7|2|4|0|6|
|java-1.8.0-oracle-devel-1.8.0.121-1jpp.1.el7_3|0|1|0|1|
|java-1.8.0-oracle-devel-1.8.0.141-1jpp.1.el7_3|0|38|1|39|
|java-1.8.0-oracle-devel-1.8.0.65-1jpp.3.el7_1|0|3|0|3|
|java-1.8.0-oracle-devel-1.8.0.71-1jpp.1.el7|0|2|0|2|
|java-1.8.0-oracle-jdbc-1.8.0.121-1jpp.1.el7_3|0|1|0|1|
|java-1.8.0-oracle-jdbc-1.8.0.141-1jpp.1.el7_3|0|25|0|25|
|java-1.8.0-oracle-jdbc-1.8.0.65-1jpp.3.el7_1|0|1|0|1|
|java-1.8.0-oracle-jdbc-1.8.0.71-1jpp.1.el7|0|2|0|2|
|SRVOPS-java-jdk-1.7.0_99-1-1.el7|37|11|0|48|
|SRVOPS-java-jdk-1.8.0_192-1-1.el6|2|0|0|2|
|SRVOPS-java-jdk-1.8.0_192-1-1.el7|56|1|31|88|
|SRVOPS-java-jdk-1.8.0_65-1-1.el7|50|122|1|173|
|SRVOPS-java-jdk-1.8.0_72-1-1.el6|6|0|0|6|
|SRVOPS-java-jdk-1.8.0_74-1-1.el6|0|7|0|7|
| | | | | |
|Packages to be processed|178|314|34|526|

 

 
|Hosts already processed|M7|51|
| |XBID|108|
| | | |
| | | |
|Hosts to be processed|M7|121|
| |XBID|150|
| |Energy|33|

 
{panel}
h2. Proposed Solution

Analyze all remaining Oracle JDK installations & Operating System version used for XBID and prepare plan how to migrate them to Azul. 
h2. Acceptance Criteria
 * ticket (task or epic) with clear vision how to migrate all remaining XBID dependencies from Oracle Java to JDK. 
 * ticket (task or epic) must include also plan to upgrade all the machines to RedHat 7.6
 * plan ending with no Oracle JDK installations on XBID environments. 
 *",,ei349,rehapav,ub113,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jan/20 14:57;rehapav;JAVA_installed_20191211.xlsx;https://jira.deutsche-boerse.com/secure/attachment/79003/JAVA_installed_20191211.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24624000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09wda:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 4 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/20 10:05;rehapav;description
 * in attached excel generated 8/12/2019 by Lambert you can find list of all available machines and used java version
 * some machines could be listed in several columns -> means it has more java versions installed
 * for the scope of this ticket take into the consideration XBID machines only, machine naming convention:
 ** XBID machines start with XB
 ** M7 machines start with M7
 ** techops internal machines starts with EN
 * additional handy input is file located in 
 ** for M7 S:\Energie\Prod_DEVELOP\001 M7\Infrastructure 
 *** M7_Environments_2019-11-19(AutoRecovered)
 *** sheet Env. Details
 ** for XBID S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\Infrastructure\Environments
 *** XBID_Environments_2019-05-16
 *** sheet Env. Details

approach 
 * take all machines on which we have installed ZULU and verify if some other old JDK is not installed there
 ** if only AZUL is on that machine its good
 ** if not please consider machine in next steps
 * take all machines with at least 1 JDK installation
 * group them by the environments (XBID PROD / SIMU / CUTE / CUTE A - E ..  etc)
 ** use sheet from above to identify to which environment such a machine belongs
 * for all environments with at least 1 machine with JDK please organize technical redeployment
 ** scope of the redeployment would be same software delivery, installation of AZUL and removal of JDKs from all the machines on the environment

 ","13/Jan/20 08:37;rehapav;While analysing individual machines, please ensure that every single machine is update to RedHat 7.6

 

Please take into consideration while planning that certain machines are shared across serveral environments and either seamless upgrade must be executed

or whole group of shared machines downtime should be announced.","20/Jan/20 16:13;ub113;As we discussed, we can work with clear instructions what environments are affected (their names and components) + what actions are needed to be performed. 
List provided or the excel attached do not contain sufficient information.","24/Jan/20 10:55;rehapav;summary telco 24/1:
 * m7_environemnts and xbid_environments sheets are no longer maintained by techops
 * the only way to tell which machine belongs to which environment is combination of [https://cloudweb.prod.ci.dom/] and inventory
 * it was agreed that BIZOPs will well in advance (1 month+) prepare
 ** downtime windows for group of environments / group of shared environments
 ** TechOps (Lambert) will review the provided plan and provide feedback which services will be impacted by this downtime
 ** dev review the final plan
 ** BIZOPs to inform clients about final impact
 ** TechOps execute the plan

Pavel Rehak suggests to start with few envs:
 * wave 1 XBID CUTE A,B (4 hours
 * wave 2 XBID CUTE c, d, e, f (4 hours)
 * wave 3 XBID CUTE g,h,i,j (4 hours)
 * wave 4 XBUD CUTE k,l, PX, TSO
 * wave 5 XBID test shared infrastructure + LIP A + LIP B
 * wave 6 XBID SIMU
 * wave 7 XBID PROD with XBID 3.0 (should have been already finished with XBID 2.0) 

 

 ","24/Jan/20 10:55;rehapav;Timeline wave 6 to be finished until 31/3","24/Jan/20 14:36;ub113;Hello [~rehapav] [~cv524]

I found this deployment ticket - SERVICE-3080

It seems that we already migrated from java jdk in may 2019, at least for SIMU, LIPA, LIPB, CuteC.

From the excel sheet it seems that PROD is migrated too.

I will dig more and probably find other deployments that were performed on xbid environments.","03/Feb/20 09:37;ub113;Hi [~cv524],

 

Please take a look at [~rehapav]  proposal from January 24th and let us know if that works for you.

Thanks.","24/Feb/20 10:13;ub113;Hello [~cv524]

Please review [~rehapav]  Proposal so that we can initiate the conversation with OPSCOM.

Thank you,

 

Ana","09/Mar/20 10:54;yo218;The following hosts are still using old oracle java:
{noformat}
Simulation:
xbsimurep1
xbsimurep2
xbsimuctp1
xbsimuctp2
xbsimuecp1
xbsimuecp2
xbsimusla1
xbsimusla2

Shared CuTe's
xbcutsctp1
xbcutsrep1

CuTe PX
xbcutecor1
xbcutedow1
xbcuteecp1
xbcuteenq1

CuTe TSO
xbctsocor1
xbctsodow1
xbctsoecp1
xbctsoenq1

CuTe A,B,D,E
xbctpaenq1
xbctpadow1
xbctpacor1
xbctpbenq1
xbctpbdow1
xbctpbcor1
xbctpdenq1
xbctpddow1
xbctpdcor1
xbctpecor1
xbctpedow1
xbctpeenq1

Performance
xbidperfcor1
xbperfcmi1
xbperfcmm1
xbperfctp1
xbperfecp1
xbperfsla1
xbperfsmc1
xbperfsmi1
xbperfsob1

DST
xbdst1app1

Shared Internal
xbinterep1 {noformat}
Downtime for java migration is required for CuTe PX, Cute TSO, CuTe PX A,B,D,E and Perf, as well as downtime of ECP for Simulation. IMHO rep, ctp and sla instances could be done without downtime as the risk of having customer impact is rather low.

30 minutes per environment should be good enough ","10/Mar/20 07:38;yo218;[~ub113] or [~ei349] ([~rehapav])

Analysis is done. Please schedule required deployments ","20/Mar/20 13:25;rehapav;Outstanding are non-PROD only, to be scheduled by PRODUCT team during the upcoming acceptance period

[~ub113] [~ei349] if you would please.","11/May/20 14:50;ei349;If we have a such unique opportunity so we can restart all our customer facing test environments - don't we want to resolve this old ticket as well?

[~ub113], [~rehapav], [~yn731], [~sw455]?","11/May/20 15:01;rehapav;Yes, this is still pending to be delivered to test environments - please include this into the deployment on Wed 13/5 - [~ub113]","13/May/20 09:51;yo218;done for all CuTes",,,,,,,,,,,,,,,,,,,,,,,,
P2-V16 – Protective mechanisms for cookies go unused,XP-2506,90820,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,07/Jan/20 17:03,11/Aug/20 16:35,22/Feb/21 13:26,09/Jun/20 12:40,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h2. Protective mechanisms for cookies go unused

The assessed application uses cookies to transmit data like session IDs persistently.

Ideally, sensitive data like session IDs should only be transmitted using a TLS channel. This can be indicated to the browser by setting the cookie option Secure.

Moreover, the HttpOnly cookie option allows preventing JavaScript code from accessing the cookie within the browser. This mechanism offers some degree of protection against certain attack scenarios in combination with cross-site scripting.

In addition, using the SameSite option, it can be prevented that sensitive cookies (such as session cookies) are sent to the server when the request is triggered by a third party, e.g. in an iframe or an XMLHttpRequest (XHR) via JavaScript. Setting the SameSite flag thus effectively prevents CSRF attacks as long as the browser supports this option. This is currently the case in recent versions of Chrome (as of version 51) and Firefox (as of version 60) as well as in Edge (as of version 16) and Internet Explorer 11 as of Windows 10[[1]|#_ftn1]. For Chrome, starting with Chrome 80, the browser enables the SameSite=Lax option by default if it is not set by the server[[2]|#_ftn2].

In the present case, the Secure and HttpOnly options have been set, while the SameSite option has not.

*Example*

Server response to an HTTP request:
|HTTP/1.1 200 200
Date: Wed, 11 Dec 2019 14:46:23 GMT
Server: Apache
Strict-Transport-Security: max-age=63072000; includeSubdomains;
Set-Cookie: JSESSIONID=E141A7092443616D236342F8ABFD659A.xbid-simu-cmm1; Path=/cmm; Secure; HttpOnly
Accept-Ranges: bytes
ETag: W/""109-1573051096000""
Last-Modified: Wed, 06 Nov 2019 14:38:16 GMT
Content-Type: text/html; charset=UTF-8
Content-Length: 109
Connection: close|

As can be seen from the output, the SessionID cookie has been set without the SameSite option.

*Threat*

Cookies can disclose sensitive information as the SameSite option has not been set.
|Vulnerability:|*P2-V16* – Insufficient protection of session cookies| |
|*Threat:* Simplified hijacking of valid sessions, bypassing authentication|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 5.0|
|Attack vector:
Network|Confidentiality impact:
Low|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
Low|Availability impact:
None|
|User interaction:
None|Scope:
Changed|
|*Score:* 3.1|*Score:* 1.4|
|*Location:* Web application (Session management)|
|*OWASP Top Ten:* A2 - Broken Authentication|
|*ASVS 3.0.1 requirement:*  3.12|
|*Recommendation:* Set the SameSite option for the session cookie.|

*Recommendations*

The Secure, SameSite and HttpOnly options should be set when cookies are issued.

The value SameSite=lax provides a reasonable balance between security and usability. In this case, cookies are only sent along in cross-site requests that the browser considers safe. They are not sent along in POST requests or when the site is embedded in an iframe. If the session cookie is set with the value SameSite=strict, it is never sent along in any cross-site requests.

[[1]|#_ftnref1] https://caniuse.com/#search=samesite

[[2]|#_ftnref2] [https://www.chromestatus.com/feature/5088147346030592]

_For the original finding files please see XP-2460._",,ek176,iO924,jy268,ll664,od044,radeale,,,,,,,,,,,,,,,,,,,,,XP-2489,,,,,,,,,,,,,,,,"09/Jun/20 12:38;od044;Screenshot 2020-06-09 at 10.47.42.png;https://jira.deutsche-boerse.com/secure/attachment/84565/Screenshot+2020-06-09+at+10.47.42.png","09/Jun/20 12:38;od044;Screenshot 2020-06-09 at 11.10.40.png;https://jira.deutsche-boerse.com/secure/attachment/84564/Screenshot+2020-06-09+at+11.10.40.png","09/Jun/20 12:38;od044;Screenshot 2020-06-09 at 11.14.54.png;https://jira.deutsche-boerse.com/secure/attachment/84563/Screenshot+2020-06-09+at+11.14.54.png","09/Jun/20 12:38;od044;Screenshot 2020-06-09 at 12.37.45.png;https://jira.deutsche-boerse.com/secure/attachment/84562/Screenshot+2020-06-09+at+12.37.45.png",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22291200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2e0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,xbid-dev-env,XP-2506-xbid-dev-env,XP-2484,XP-2506-prod,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 15:44;ll664;The _SameSite_ flag for JSESSIONID cookies can be implemented in:

* the app modules - every module that has web UI needs to be adjusted
* Apache webserver - add rule to add the flag to given cookie","23/Jan/20 13:17;iO924;https://vmt.deutsche-boerse.de/browse/PT-1551","08/Jun/20 14:36;jy268;SameSite flag for JSESSION id added for all applications (CMM, CMI, SOB, SMI)","08/Jun/20 15:15;jy268;[~od044] please do a smoketest on syt1. You should find SameSite=Lax when setting JSESSIONID.","08/Jun/20 15:16;jy268;PROD PR: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/670
NON PROD PR: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/671","09/Jun/20 12:39;od044;Test passed on SYT1
- Set-cookies header contains value SameSite=Lax.
 !Screenshot 2020-06-09 at 10.47.42.png! 
 !Screenshot 2020-06-09 at 11.10.40.png! 
 !Screenshot 2020-06-09 at 11.14.54.png! 
 !Screenshot 2020-06-09 at 12.37.45.png! 
- smoke test passed ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V15 – Missing Referrer-Policy header,XP-2504,90817,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,radeale,radeale,07/Jan/20 14:58,31/Aug/20 15:39,22/Feb/21 13:26,05/Jun/20 14:11,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h3. Missing Referrer-Policy header/Referrer control not enabled

The referrer policy mentioned in section 8.1.3 can also be set without CSP as the dedicated Referrer-Policy header. This allows to control information disclosure caused by the Referer header. 
 (Note: The word “referrer” has been misspelled in Referer header, while the spelling in Referrer-Policy header is correct.[[1]|#_ftn1])

The Referer header is sent along in requests by many browsers – for example, after clicking on a link or when requesting embedded resources – without the user having to take any specific action. Usually, the value (origin) is the full URI of the website where the link has been clicked or the resource been embedded, including any GET parameters.

This provides referenced third-party pages not only with information about which website the user has visited but also which specific subpage, thus greatly easing user profiling (e.g. via tracking mechanisms). If the page transfers sensitive information as GET parameters 7.8, this information is disclosed to third parties as well. When the session ID is included, for instance, third parties might thereby be able to take over sessions and access internal areas. Moreover, the Referer header is usually recorded in the access logs of web servers by default.

Using the Referrer-Policy header, this kind of information disclosure can be reduced – provided that the header is supported by the respective browser, which is the case for all common browsers (for Edge and Internet Explorer at least partly)[[2]|#_ftn2].

*Threat*

The Referer header transmits the URL of the calling page, therefore making it easier for third parties to create a profile of the application’s users.
|Vulnerability:|*P2-V15* – Missing Referrer-Policy header| |
|*Threat:* Facilitated information disclosure to third parties|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 0|
|Attack vector:
Network|Confidentiality impact:
None|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
None|Availability impact:
None|
|User interaction:
None|Scope:
Unchanged|
|*Score:* 3.9|*Score:* 0|
|*Location:* Web server configuration|
|*OWASP Top Ten:* A6 - Security Misconfiguration|
|*ASVS 3.0.1 requirement:* not relevant|
|*Recommendation:* Set a proper Referrer-Policy header.|

*Recommendations*

We recommend setting the Referrer-Policy header to a proper value if it is not already covered by the CSP.

To be precise, the following values are valid for the header; the domain of the source URI is being referred to as the origin. All resources served from the same domain/origin are “internal”, whereas all other (sub)domains are “external”:
 * no-referrer:
 The Referer header is not sent along with any resource – neither internal nor external.
 * no-referrer-when-downgrade:
 The Referer header is generally sent along with the full URI to internal and external domains. Only if the source uses HTTPS but the target is only available via HTTP, the Referer header is not sent along.
 * same-origin:
 The Referer header is only sent to resources of the source domain but not to any others. If the URI scheme changes from HTTPS to HTTP (or vice versa), those URIs are regarded as two different origins.
 * origin:
 The Referer header only contains the source domain but not the full URI. This behavior is the same for internal and external targets.
 * strict-origin:
 The Referer header only contains the source domain but not the full URI. This behavior is the same for internal and external targets; however, HTTPS origins are not transmitted to HTTP domains.
 * origin-when-cross-origin:
 The Referer header contains the full source URI for internal resources but is shortened to the source domain for external ones.
 * strict-origin-when-cross-origin:
 The Referer header contains the full source URI for internal resources but is shortened to the source domain for external ones. If the URI scheme changes from HTTPS to HTTP (or vice versa), no Referer header is sent along.
 * unsafe-url:
 The Referer header contains the full source URI for all internal and external targets and therefore does not provide any protection.

Moreover, some browsers (e.g. IE 11 and Edge) do not support the full specification, but only an older draft version with the following directives:
 * never:
 Equivalent to no-referrer
 * always:
 Equivalent to unsafe-url
 * origin:
 Equivalent to origin above
 * default:
 Equivalent to no-referrer-when-downgrade

From a data protection perspective, no-referrer is to be preferred. For internal use of the Referer header, we recommend same-origin. If external resources are embedded that rely on the presence of the Referer header (e.g. to set CORS headers to proper values), we recommend using strict-origin or at least strict-origin-when-cross-origin.

For maximum compatibility or if the application is mainly used with Microsoft browsers, we recommend the origin option, provided that the headers are not dynamically set in dependence on the User-Agent header.

Note: Depending on the implementation, some browsers always send along the Referer header; it might, however, not contain any value. 

[[1]|#_ftnref1] [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy]

[[2]|#_ftnref2] [https://caniuse.com/#feat=referrer-policy|https://caniuse.com/#https://caniuse.com/]

_For the original finding files please see XP-2460._",,ek176,iO924,ll664,radeale,,,,,,,,,,,,,,,,,,,,XP-2501,,,XP-2515,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2dc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/20 15:20;ll664;Configurable in Apache, but we should probably tackle this with CSP (https://jira.deutsche-boerse.com/browse/XP-2501).
","23/Jan/20 16:19;iO924;[https://vmt.deutsche-boerse.de/browse/PT-1550|https://vmt.deutsche-boerse.de/browse/PT-1549]","04/Jun/20 08:15;ll664;Fixed, within XP-2515. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V8 - Weak encryption algorithm for the JSF ViewState,XP-2502,90815,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,07/Jan/20 14:55,31/Aug/20 15:38,22/Feb/21 13:26,23/Jan/20 08:42,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V8|
|LOCATION: Framework configuration|
|RISK: Medium|
|THREAT: With special hardware or adequate resources, DES is prone to brute-force attacks. However, the attack complexity on 3DES is noticeably higher.
 A successful attack allows an attacker to read and manipulate the ViewState.|
|DESCRIPTION: Regarding JSF applications, the ViewState has a key role to store the session-bound state of the application. With many applications, the ViewState is deserialized and transferred to the browser with the web page. With any user action, the ViewState is transferred back to the server, where it is serialized again. To prevent manipulation by an attacker, it is good practice to encrypt the ViewState.
 In the present case, the algorithm for the encryption of the ViewState delivered to the browser is either Data Encryption Standard (DES) or Triple DES (3DES).
 DES uses 56-bit keys at 64-bit block size. With special hardware or sufficiently large resources, brute-force attacks on DES are possible in less than one day. 3DES uses three layers of DES encryption and thus has an effective key size of 112 bits. However, due to the discovery of various attacks on 3DES, it was deprecated by NIST in 2017 .
 Contrary to DES and 3DES, the Advanced Encryption Standard (AES) uses 128-, 192- or 256-bit keys at 128-bit block size, which meets current requirements.
 Example
 We observed base64-encoded ViewStates within the application. After decoding some exemplary ViewStates, we observed that the similar part is exactly 8 bytes long:
 5854723d8738e990d9fe8d9b95a90395095917ae7f6b7d0b4d25ac612cd2938085b03d1a
 5854723d8738e990e15f7e98bca24be3f73f953e83117bf1c18479c22f2e7e534e3d0dc7
 5854723d8738e990847265e8beba260149e51fd58bd3ccbede612fd3dc9e5d806bfd5fe6
 5854723d8738e9907e32aa8b7c652e128dc7a2e7f2a90c97b6dfc5300312cf6e91a8c07f
 5854723d8738e9902361efe162fbbe0f969f37d6b62fb1bf4d2941780d704c3dbf4b1753
 
 This implies a block size of 64 bits or smaller, which means that it is not possible that AES was used; therefore, we assume that either DES or 3DES is in place as encryption algorithm.|
|RECOMMENDATION: We recommend using an encryption algorithm that is up to date, such as the Advanced Encryption Standard (AES).|",,ek176,iO924,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34214400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2cw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,master-xbid-losses-poc,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/20 11:23;iO924;https://vmt.deutsche-boerse.de/browse/PT-1534",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V14 – Missing Content-Security-Policy header,XP-2501,90814,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,07/Jan/20 14:55,11/Aug/20 16:36,22/Feb/21 13:26,08/Jun/20 15:36,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h3. Content Security Policy (CSP)

Modern web applications often consist of numerous individual elements, such as scripts, style sheets or images. Like in the present case, not only self-developed components but also third-party scripts or frameworks are used. Complex requirements and short release cycles can sometimes result in relevant security flaws. Such security flaws facilitate well-known attacks like cross-site scripting (XSS), clickjacking and other code injection attacks as well as the associated theft of sensitive data or website defacement.

One way of making it harder to perform such attacks successfully is the use of the Content Security Policy concept. Content security policies are sent as part of the server response in the form of an HTTP response header (CSP header) and are enforced by the browser. The various CSP directives allow the administrator of an application/a web or application server to specify the sources allowed for different web page contents a browser may load and execute, for example.

For instance, there are source directives for JavaScript, CSS, HTML frames, fonts, images, audio and video files, embedded objects such as Java applets, ActiveX and other HTML5 features. The respective goal is to make it harder for an attacker to inject contents into the legitimate page. Regarding JavaScript/XSS, for example, CSP offers the option of restricting the execution to defined external code modules or ensuring the JavaScript code’s integrity with hash sums or random tokens.

Thus, the CSP header does not fix any server-side security flaws like incomplete output encoding, but it can complicate the client-side exploitation of such vulnerabilities.

*Threat*

The application does not enable some very helpful browser-based protective mechanisms. One aim of these mechanisms is to make the execution of script code injected into the application more difficult (cross-site scripting). This attacking technique allows an attacker to steal sensitive cookies, for example. For this purpose, JavaScript code is often injected into the web application and executed in the user’s browser.
|Vulnerability:|*P2-V14* – Missing Content-Security-Policy header| |
|*Threat:* Facilitated cross-site scripting and code injection attacks|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 0|
|Attack vector:
 Network|Confidentiality impact:
 None|
|Attack complexity:
 Low|Integrity impact:
 None|
|Privileges required:
 None|Availability impact:
 None|
|User interaction:
 None|Scope:
 Unchanged|
|*Score:* 3.9|*Score:* 0|
|*Location:* Web server configuration|
|*OWASP Top Ten:* A6 - Security Misconfiguration|
|*ASVS 3.0.1 requirement:* 11.7|
|*Recommendation:* Set a proper Content-Security-Policy header.|

*Recommendations*

The Content-Security-Policy header can prevent the successful exploitation of certain types of attack, particularly cross-site scripting, effectively. The use of some CSP directives (e.g. script-src) sometimes requires adjustment to the existing web application. We thus recommend checking compatibility of your own web applications thoroughly before deploying any CSP. The Content-Security-Policy-Report-Only header combined with the report-uri directive serve this purpose, for example. It may be necessary to allow scripts and CSS information again using the unsafe-inline option. Even if CSP does not allow restricting scripts, directives may be set to forbid unused media and plug-in types or to specify target addresses allowed for XMLHttpRequest with the aim to improve the security level.

CSP version 2 is supported by almost all common browsers except Internet Explorer. Full support for CSP version 1 and version 2 is, for example, provided by the Google Chrome (desktop and mobile), Mozilla Firefox, Opera and Apple Safari (desktop and mobile) browsers in their latest versions. As of version 15, Microsoft Edge largely supports the CSP version 2 directives.

Among the many CSP directives, we recommend particularly considering the following directives:

*“upgrade-insecure-requests” directive*

The upgrade-insecure-requests CSP directive tells the browser to interpret potentially insecure HTTP links to internal and external resources as well as domain-internal hyperlinks in the source code as HTTPS URLs, so they will be accessed encrypted. Before applying this directive to the productive environment, make sure your own contents and linked third-party contents can be accessed both via HTTP and HTTPS at the same host and path name. Otherwise, individual web pages or linked resources may possibly no longer be accessed. The CSP directive is then set using the following syntax:

Content-Security-Policy: upgrade-insecure-requests

Internet Explorer does not support this CSP directive and requests the linked resources as indicated in the web page’s source code (HTTP or HTTPS).

*“frame-ancestors” directive*

The frame-ancestors directive specifies whether a page/resource may be embedded in the web pages of third-party websites using <frame>, <iframe>, <object>, <embed> or <applet>. To complicate clickjacking and cross-frame scripting attacks, we recommend setting this CSP directive in addition to the X-Frame-Options header, as this header is gradually replaced with the new CSP directive. Using both headers ensures the best possible browser support, since Microsoft Internet Explorer does not yet support the frame-ancestors directive but respects the X-Frame-Options header instead.

The syntax for setting the CSP directive is as follows:

Content-Security-Policy: frame-ancestors [source list]

Equivalent to X-Frame-Options, there are three possible values for frame-ancestors:
 * frame-ancestors 'none': (equivalent to “X-Frame-Options: DENY”)
 The page cannot be displayed in a frame/iframe, regardless of the site attempting to do so.
 * frame-ancestors 'self': (equivalent to “X-Frame-Options: SAMEORIGIN”)
 The page can only be displayed in a frame/iframe if the embedding page comes from the same domain.
 * frame-ancestors uri: (equivalent to “X-Frame-Options: ALLOW-FROM uri”)
 The page can only be displayed in a frame/iframe on the specified origin.

*Referrer policy*

The referrer policy allows determining the value used in the Referer request header for links and resource requests. By default, without the referrer policy, the entire path from which the user has accessed the resource, including GET parameters, is transmitted when requests are made to web resources. The referrer policy can in fact also be set as a CSP directive. Due to recent browser compatibility, however, we recommend using the referrer policy in the <head> tag of the web page. As an independent referrer policy, the values set here are considered by all common browsers except Internet Explorer:

<meta name=""referrer"" content=""value"">

Valid values are: no-referrer, no-referrer-when-downgrade, origin, origin-when-cross-origin and unsafe-url. Microsoft Edge does not support these values but requires the older keywords never, always, origin and default, which other browsers also still accept.

*Example of use*

The CSP header can be set in a number of different ways, as is shown in the following example for the default-src directive. Several directives may also be specified, which have to be separated by semicolons.
 * Apache HTTP Server:
 ** In conf or alternatively in an .htaccess file:
 *** Header set Content-Security-Policy ""default-src 'self'""

After adding this line, the web server must be restarted.

_For the original finding files please see XP-2460._",,ek176,iO924,jy268,ll664,od044,radeale,,,,,,,,,,,,,,,,,,,,,XP-2514,XP-2492,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22291200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2co:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,XP-2501-to-xbid-dev-env,xbid-dev-env,traversal-XP-2485,acceptance,XP-2506-xbid-dev-env,XP-2501-prod-env,XP-2484,develop,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,master-acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 15:15;ll664;Configurable in Apache.","23/Jan/20 16:10;iO924;[https://vmt.deutsche-boerse.de/browse/PT-1549]","27/Apr/20 09:37;ek176;Might be resolved by XP-2514 (Apache cfg change). Please check","04/Jun/20 14:49;jy268;Yes, I am going to implement it in the same way as in the following ticket https://jira.deutsche-boerse.com/browse/XP-2514","05/Jun/20 14:51;jy268;Configured header for all webservers
{code}
Header always set Content-Security-Policy ""default-src 'none'; script-src 'self' 'unsafe-inline'; connect-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline'; base-uri 'self'; form-action 'self'; font-src 'self'; ""
{code}
[~od044] do some smoke testing on sytX environments.

Following pull requests created for PROD and NON PROD envs:
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/667
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/666

","05/Jun/20 15:58;jy268;What is more, CSP was configured in trading in bad way, it is disabled now, all headers are configured on apache only. [~od044] please test with new xbid version.","08/Jun/20 15:36;od044;Test passed on XBID 2.0.41 
- all response headers in all modules CMI, CMM, SPM contain 
{code}
Content-Security-Policy: default-src 'none'; script-src 'self' 'unsafe-inline'; connect-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline'; base-uri 'self'; form-action 'self'; font-src 'self';{code}
- smoke test over all module passed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V4 - Unused default application server components are reachable TECHOPS,XP-2499,90812,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,zi174,zi174,07/Jan/20 14:55,31/Aug/20 15:38,22/Feb/21 13:26,07/Jul/20 09:36,,,3.1.0,,,,,,,PenetrationTest,TechOps,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V4|
|LOCATION: Application server configuration|
|RISK: Medium|
|THREAT: The standard components that have been found unnecessarily increase the application server’s attack surface. The example applications could potentially allow bypassing security restrictions.|
|DESCRIPTION: Several default components of the application server have not been removed, although they are most likely not required for operating the application. They can be accessed using the path traversal described in section 6.1.1.
 Examples
 The folder containing example applications has not been removed and can be accessed with the following URL:
 https://10.103.128.23:60100/intraday/..;/examples/
 
 This directory contains multiple risky applications. For example, there is an application that allows a user to view and edit session details. This could be abused to bypass security restrictions in an application that stores user information in a session. This sample application can be accessed using the URL:
 https://10.103.128.23:60100/intraday/..;/examples/servlets/servlet/SessionExample
 
 Likewise, the application server’s manual has not been removed and can be accessed with the following URL:
 https://10.103.128.23:60100/intraday/..;/docs/
 
 The profile server is affected likewise, which can be verified using the following URL:
 https://simu1.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/..;/examples/|
|RECOMMENDATION: We recommend removing the application server’s manual and the example directory.|",,ei349,iO924,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"Marked as done: Implemented in XP-2485. 
Closing as the XP-2485 is Done",,,,,,,,,,,,,,22204800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2c8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/20 11:21;iO924;https://vmt.deutsche-boerse.de/browse/PT-1530","10/Jun/20 13:40;ei349;nothing to be done. Will be fixed by fixing Traversal issue from other ticket and will be fully removed with Ansible deployment","10/Jun/20 13:40;ei349;no impact on customer
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V14 - TLS client certificates not bound to user,XP-2498,90811,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,zi174,zi174,07/Jan/20 14:55,31/Aug/20 15:39,22/Feb/21 13:26,04/Jun/20 08:54,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V14|
|LOCATION: TLS component|
|RISK: Medium|
|THREAT: Since client certificates are not bound to users, compromising a single certificate allows to completely bypasses the requirement of a second factor, e.g. by simply using the default certificate stored in the client.|
|DESCRIPTION: In addition to username and password, each user receives a TLS client certificate for authentication. However, the certificates are not bound to user accounts on the server side. Therefore, any valid client certificate can be used to log in to arbitrary user accounts (the corresponding username and password are still required). So overall, the client certificate does not serve its purpose as a second factor. Besides, some valid client certificates are publicly available because they are embedded in the ComTrader fat client.
 Example
 The certificate for the reporting user XBCRSC01 has the following properties:
 PS> certutil.exe -v -dump .\XBCRSC01.p12
 Antragsteller:
     CN=XBCRSC01
     OU=XBID-TEST
 […]
 
 The assessment showed that this certificate can also be used to log in to the super administrator account XBCRSC07.
 Example
 The standalone versions of ComTrader can be downloaded at https://m7trading-test.deutsche-boerse.com/xbid-simu/.
 It allows login to SOB using an embedded TLS client certificate or by specifying a custom certificate.
 The downloaded archive contains the application at the path app/ComTrader.jar. This archive can be extracted. It contains a client certificate in the file certificate.p12 and the passphrase of the certificate in the file certificate.pass in the subdirectory ssl/XSOBv1/simu/ of the file ComTrader.jar.
 This certificate can be used to access the SOB WebGUI and to log in as any user (the corresponding username and password are still required).|
|RECOMMENDATION: During the login, the server should verify that the username inside the TLS client certificate matches the requested account’s username. In addition, the embedded client certificate of ComTrader should be removed.|",,eh941,ek176,iO924,jy268,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2472,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s0001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/20 09:42;eh941;Already described in XP-2472 ","23/Jan/20 11:15;iO924;https://vmt.deutsche-boerse.de/browse/PT-1522","04/Jun/20 08:54;jy268;I confirm, already implemented in
{code}
com.deutscheboerse.energy.m7.security.X509CustomFilter
{code}
enabled on production, but disabled on any other environment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V13 - POST requests containing sensitive data accepted as GET requests,XP-2496,90809,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,zi174,zi174,07/Jan/20 14:54,04/Aug/20 19:53,22/Feb/21 13:26,09/Jun/20 15:19,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V13|
|LOCATION: Web application|
|RISK: Low|
|THREAT: Threat
 The fact that POST requests with sensitive data are accepted as GET requests makes eavesdropping on sensitive data easier.|
|DESCRIPTION: Clients usually use two HTTP methods to send a request to an application: GET or POST. Both methods differ in how parameters are transmitted. GET requests append parameters directly to the URL, POST requests transmit parameters as part of the message body.
 When transmitting sensitive or confidential data like session IDs or passwords in parameters, the POST method is preferred from a security perspective. HTTP requests usually pass a variety of network devices, such as routers, proxy servers or web application firewalls (WAF), on their way from the browser to the server. Both proxy servers and WAFs as well as the web server often store the requested URLs including the appended parameters in an access log. This makes it easier for an attacker to access sensitive information (e.g. session cookies, …). 
 POST requests are also beneficial on the client side because they are not stored in the browsing history and can still be saved as bookmarks.
 Examining the SOB WebGUI, we noted that data from the client to the application is sent almost exclusively in the form of POST requests; therefore, application data is transmitted in the body of the message. During the assessment, however, it was found that a manual conversion of a POST request in a similar GET request is also accepted and processed by the application logic.
 Example
 Affected URL:
 https://10.103.128.23:60100/intraday/faces/jsp/changePasswd.xhtml
 
 Example POST request usually sent to the application:
 POST /intraday/faces/jsp/changePasswd.xhtml HTTP/1.1
 Host: 10.103.128.23:60100
 […]
 
 page::form-action=page:j_id_h&page::context-path=/intraday&page::action-position=1521px,103px,120px,20px&page::form-clientDimension=1900;817&page::scrollbarWeight=15;15&org.apache.myfaces.tobago.webapp.Secret=kUW2A-jBdON6kP2ZG7aaMw&page:j_id_9_tx_field=Cirosec1234$&page:newPasswdInput_tx_field=Cirosec123$&page:newPasswdRepeatInput_tx_field=Cirosec123$&page::messagesClientIds=page:j_id_l&javax.faces.ViewState=rtQTZEipw1ykdN4O304+UKquPRbvNAX5bwIrUG4IdrjkMUye&javax.faces.RenderKitId=tobago
 
 The change password functionality can also be called successfully if the POST request is converted to GET, i.e. all parameters are appended to the URL:
 GET /intraday/faces/jsp/changePasswd.xhtml?page::form-action=page:j_id_h&page::context-path=/intraday&page::action-position=1521px,103px,120px,20px&page::form-clientDimension=1900;817&page::scrollbarWeight=15;15&org.apache.myfaces.tobago.webapp.Secret=kUW2A-jBdON6kP2ZG7aaMw&page:j_id_9_tx_field=Cirosec1234$&page:newPasswdInput_tx_field=Cirosec123$&page:newPasswdRepeatInput_tx_field=Cirosec123$&page::messagesClientIds=page:j_id_l&javax.faces.ViewState=rtQTZEipw1ykdN4O304+UKquPRbvNAX5bwIrUG4IdrjkMUye&javax.faces.RenderKitId=tobago HTTP/1.1
 Host: 10.103.128.23:60100
 […]
 
 The converted GET request is handled by the application:
 […]
 <label title='Error. Unable to change password. password in history' class='tobago-messages-item tobago-messages-item-markup-error'
 >Error. Unable to change password. password in history</label><br>
 […]|
|RECOMMENDATION: Sensitive information like session IDs or confidential data in request parameters should exclusively be sent to the server as POST parameters. The application should not accept these calls via GET.|",,ek176,hj444,iO924,ll664,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22204800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a2bk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3048-only-two-ts-in-case-of-no-atc-in-requested-time-range,acceptance,develop,XP-3015,XP-3079,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/20 11:25;iO924;https://vmt.deutsche-boerse.de/browse/PT-1521","19/Mar/20 09:22;ek176;Already described in XP-2481","08/Jun/20 12:55;ll664;Merged into develop, the testing is quite cumbersome as you need to sniff the submitted change password form and the convert it to query params. Contact me and I can provide assitance.
","09/Jun/20 15:18;hj444;Test done docker : Version R2.0.42-SNAPSHOT (Build 8495691e29d045a852f0f54ff3ebba408bcd5c34)
Scenario tested : After sending GET - 404 is returned. 
Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V5 - Outdated RabbitMQ version with known vulnerabilities (e.g. CVE-2019-11287),XP-2495,90808,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,07/Jan/20 14:54,04/Aug/20 19:53,22/Feb/21 13:26,15/Apr/20 09:26,,,3.1.0,,,,,,,PenetrationTest,,,,"Upgrade to 3.8.x if possible otherwise to the latest 3.7.x. 

 
|ORIGINAL: ESO-240 - FINDING: P3P5-V5|
|LOCATION: Application server software (RabbitMQ)|
|RISK: Medium|
|THREAT: The publicly known vulnerabilities in the RabbitMQ version used could allow denial-of-service attacks or cross-site scripting (requires administrative privileges).|
|DESCRIPTION: The RabbitMQ version 3.7.7 disclosed in the server banner is outdated and contains publicly known vulnerabilities (e. g. CVE-2019-11287). The most recent version at the time of the assessment was RabbitMQ version 3.7.23. 
 For further information on the individual vulnerabilities, check the manufacturer’s site ([https://www.rabbitmq.com/changelog.html]).
 The installed software version is 1.5 years old.|
|RECOMMENDATION: We recommend deploying the most recent version of RabbitMQ. Moreover, a patch management process should be established that ensures the regular and timely installation of security updates.|",,ei349,ek176,iO924,ll664,tm431,ub113,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17452800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0alv0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4211-perf-analysis-jh,XP-2903,XP-3055,XP-3230,master-xbid-2.0.36.x,XP-3070,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,fixing-failover,XP-3233-acceptance-jgitflow,hotfix,prod,master-prod,XP-2979-postgresql,XP-3264,XP-4122-perf-analysis,develop,XP-2232,master-acceptance,master,XP-2476,XP-4273-owasp-zap-enable,XP-2843-BR01,XP-3233-prod-jgitflow,acceptance,XP-4250,inline-tomcat-params,XP-4526-resource-managment-fix,XP-222-acceptance,xbid-2.0.36.x,XP-2843-BR07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/20 11:22;iO924;https://vmt.deutsche-boerse.de/browse/PT-1531","10/Apr/20 10:52;ll664;RabbitMQ upgraded to *3.8.3*, Erlang to *22.1* on XBID SYT1 and Docker. Tested and works without issues.","14/Apr/20 08:53;tm431;Customers have following questions:

Project Parties cannot accept DBAG’s request for the time being due to the current lack of understanding around this proposed upgrade. An assessment should be done first among project parties, and most likely not by the testing experts which are part of this call during Go Live preparation, before being able to provide DBAG with a clear position on that matter. As a starting point for this clarification process, we would like to ask DBAG for the following details

*Could DBAG indicate us what are the test cases/scenarios DBAG is planning to execute in SIMU environment (and to provide us with the related results after the execution)?*

*Could you please inform us why do DBAG need to upgrade both items, since so far it was not needed? (please note that this is just the conclusion that can be reached reading the release notes, no reference to any formal DBAG announcement)*

*Could DBAG specify, if any, what are the detailed impacts of the Rabbit MQ and Erling upgrade on XBID, in order to let us retrieve the possible impacts on our systems?*

 

*[~ei349] fyi*

 ","14/Apr/20 11:07;ll664;*Could DBAG indicate us what are the test cases/scenarios DBAG is planning to execute in SIMU environment (and to provide us with the related results after the execution)?*

For a RabbitMQ upgrade, just a basic shakedown right?

*Could you please inform us why do DBAG need to upgrade both items, since so far it was not needed? (please note that this is just the conclusion that can be reached reading the release notes, no reference to any formal DBAG announcement)*

Pentest finding - current version has security issues. Part of standard patch management process or whatever security measures we have in place. To keep their systems secure and unhackable.

*Could DBAG specify, if any, what are the detailed impacts of the Rabbit MQ and Erling upgrade on XBID, in order to let us retrieve the possible impacts on our systems?*

No impact expected.
","25/Jun/20 15:37;ei349;This answer is fine for me. ","25/Jun/20 16:23;ei349;[~ub113], [~yn731] - this is also another topic we need to inform our customers about. ","04/Aug/20 13:28;ei349;Communicated already on 4-Aug 20 to Jiri Zavada via e-mail: 

Dear Jiri,

 

it will be RabbitMQ 3.8.5.

 

For more information see below:
 * [https://www.rabbitmq.com/changelog.html]
 * [https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.5]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V3 - Outdated Apache Tomcat version with known vulnerabilities (e.g. CVE-2019-0199),XP-2493,90806,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,07/Jan/20 14:54,12/Aug/20 17:09,22/Feb/21 13:26,15/Apr/20 09:26,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V3|
|LOCATION: Application server software (Apache Tomcat)|
|RISK: Medium|
|THREAT: The publicly known vulnerabilities in the Apache Tomcat version used allow denial-of-service attacks.|
|DESCRIPTION: The Apache Tomcat version 8.5.35 disclosed in the standard page (see section 6.1.1) is outdated and contains publicly known vulnerabilities (e. g. CVE-2019-0199). The most recent version at the time of the assessment was Apache Tomcat version 8.5.49. 
 For further information on the individual vulnerabilities, check the manufacturer’s site (https://tomcat.apache.org/security-8.html).
 The installed software version is twelve months old.|
|RECOMMENDATION: We recommend deploying the most recent version of Apache Tomcat. Moreover, a patch management process should be established that ensures the regular and timely installation of security updates.|",,ek176,iO924,ll664,lt112,qo794,zi174,,,,,,,,,,,,,,,XP-2489,,,,,,,,,,,,,,,XP-3307,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,27043200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000000000000300040000609",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2942,tomcat-rollback,XP-4211-perf-analysis-jh,XP-3025-catalina-timezone,XP-2903,XP-3055,XP-2484,XP-3110-deprecated-log,XP-3230,master-xbid-2.0.36.x,XP-3094-sonar-gate,XP-3161-develop,XP-3070,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,fixing-failover,XP-3233-acceptance-jgitflow,hotfix,prod,master-prod,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-2979-postgresql,XP-3264,XP-4122-perf-analysis,develop,XP-2232,master-acceptance,master,XP-2476,XP-2501-to-xbid-dev-env,XP-2843-BR01,XP-4273-owasp-zap-enable,xbid-dev-env,traversal-XP-2485,XP-3233-prod-jgitflow,acceptance,XP-4250,inline-tomcat-params,XP-3161-pom-cleanup-develop,XP-4526-resource-managment-fix,XP-222-acceptance,xbid-2.0.36.x,XP-2488-xbid-dev-env,XP-2843-BR07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 14:05;ll664;We should do a Tomcat upgrade, first in the internal envs. It should be straightforward and no obstacles are expected.","23/Jan/20 11:20;iO924;https://vmt.deutsche-boerse.de/browse/PT-1529","10/Feb/20 16:43;lt112;Upgraded for internal environments https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/580","12/Feb/20 11:59;qo794;[~lt112] I would also suggest to upgrade a tomcat version in our custom docker image.","12/Feb/20 13:51;lt112;https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/581
https://github.deutsche-boerse.de/dev/m7.custom-docker-images/pull/74","13/Apr/20 16:00;ll664;The upgrade was reverted as it didn't work for some reason. I was too long ago, but SYT1 was not in working state, hence the upgrade was reverted without further investigation.

So, working on this again, I've got the Docker/xbid-test pipeline green for all projects - XBID, SM, Reporting Engine with Tomcat *8.5.54*. SYT1 will follow, as soon as techops upload the Tomcat version to  https://cmqaart.deutsche-boerse.de/artifactory/clip-dev-local/borg/tomcat/ .","14/Apr/20 11:18;ll664;The deployment to SYT1 sucessfull, but I had to strip whitespaces/newlines from CATALINA_OPTS as new tomcat does not like them and fails to start - see [here|https://github.deutsche-boerse.de/dev/energy-mkt-shared/blob/fd3b4e614e902ddf91fafb70014866b780408b84/scripts/energy_deploy_pmi.pl#L650]. I wonder whether similar needs to be done for Ansible.","15/Apr/20 09:23;ll664;Tomcat's AJP configuration has to be adjusted as well. Since 8.5.x the AJP connector by default listens only on loopback and prevents connection from reverse proxies that does not send predefined secret key. This needs to be disabled so our Apache are able to connect. See configuration [here|https://github.deutsche-boerse.de/dev/energy-mkt-shared/blob/2bb3103865bc36d4f35d954b990569a9f7b386ac/templates/tomcat/8.5.54/ds_HTTP_AJP__server.xml#L90].

The relevant snippet is following:
{code:java}
<Connector port=""@(SERVER_CONN_PORT_AJP)"" address=""0.0.0.0"" protocol=""AJP/1.3"" redirectPort=""@(SERVER_REDIR_PORT)"" connectionTimeout=""10000""
           keepAliveTimeout=""70000"" maxThreads=""256"" secretRequired=""false""/>
{code}
h2. Summary - what needs to be adjusted when upgrading to 8.5.54
 * no line breaks in {{CATALINA_OPTS}}
 * AJP connector configuation (see above)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V16 - Missing Content-Security-Policy header TECHOPS,XP-2492,90805,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,zi174,07/Jan/20 14:53,04/Aug/20 19:53,22/Feb/21 13:26,11/Jun/20 14:18,,,3.1.0,,,,,,,PenetrationTest,TechOps,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V16|
|LOCATION: Web server configuration|
|RISK: None|
|THREAT: The application does not enable some very helpful browser-based protective mechanisms. One aim of these mechanisms is to make the execution of script code injected into the application more difficult (cross-site scripting). This attacking technique allows an attacker to steal sensitive cookies, for example. For this purpose, JavaScript code is often injected into the web application and executed in the user’s browser.|
|DESCRIPTION: Modern web applications often consist of numerous individual elements, such as scripts, style sheets or images. Like in the present case, not only self-developed components but also third-party scripts or frameworks are used. Complex requirements and short release cycles can sometimes result in relevant security flaws. Such security flaws facilitate well-known attacks like cross-site scripting (XSS), clickjacking and other code injection attacks as well as the associated theft of sensitive data or website defacement.
 One way of making it harder to perform such attacks successfully is the use of the Content Security Policy concept. Content security policies are sent as part of the server response in the form of an HTTP response header (CSP header) and are enforced by the browser. The various CSP directives allow the administrator of an application/a web or application server to specify the sources allowed for different web page contents a browser may load and execute, for example.
 For instance, there are source directives for JavaScript, CSS, HTML frames, fonts, images, audio and video files, embedded objects such as Java applets, ActiveX and other HTML5 features. The respective goal is to make it harder for an attacker to inject contents into the legitimate page. Regarding JavaScript/XSS, for example, CSP offers the option of restricting the execution to defined external code modules or ensuring the JavaScript code’s integrity with hash sums or random tokens.
 Thus, the CSP header does not fix any server-side security flaws like incomplete output encoding, but it can complicate the client-side exploitation of such vulnerabilities.
 In the present case, the following CSP has been set:
 Content-Security-Policy-Report-Only: default-src 'self';
 
 As can be seen, no object-src directive has been set. Moreover, the CSP is used in report-only mode. However, no report-uri has been defined. This makes the given CSP useless to both the user and Deutsche Börse, as no CSP violations can be reported by the browser.|
|RECOMMENDATION: The Content-Security-Policy header can prevent the successful exploitation of certain types of attack, particularly cross-site scripting, effectively. The use of some CSP directives (e.g. script-src) sometimes requires adjustment to the existing web application. We thus recommend checking compatibility of your own web applications thoroughly before deploying any CSP. The Content-Security-Policy-Report-Only header combined with the report-uri directive serve this purpose, for example. It may be necessary to allow scripts and CSS information again using the unsafe-inline option. Even if CSP does not allow restricting scripts, directives may be set to forbid unused media and plug-in types or to specify target addresses allowed for XMLHttpRequest with the aim to improve the security level.
 CSP version 2 is supported by almost all common browsers except Internet Explorer. Full support for CSP version 1 and version 2 is, for example, provided by the Google Chrome (desktop and mobile), Mozilla Firefox, Opera and Apple Safari (desktop and mobile) browsers in their latest versions. As of version 15, Microsoft Edge largely supports the CSP version 2 directives.
 Among the many CSP directives, we recommend particularly considering the following directives:
 “upgrade-insecure-requests” directive
 The upgrade-insecure-requests CSP directive tells the browser to interpret potentially insecure HTTP links to internal and external resources as well as domain-internal hyperlinks in the source code as HTTPS URLs, so they will be accessed encrypted. Before applying this directive to the productive environment, make sure your own contents and linked third-party contents can be accessed both via HTTP and HTTPS at the same host and path name. Otherwise, individual web pages or linked resources may possibly no longer be accessed. The CSP directive is then set using the following syntax:
 Content-Security-Policy: upgrade-insecure-requests
 Internet Explorer does not support this CSP directive and requests the linked resources as indicated in the web page’s source code (HTTP or HTTPS).
 “frame-ancestors” directive
 The frame-ancestors directive specifies whether a page/resource may be embedded in the web pages of third-party websites using <frame>, <iframe>, <object>, <embed> or <applet>. To complicate clickjacking and cross-frame scripting attacks, we recommend setting this CSP directive in addition to the X-Frame-Options header, as this header is gradually replaced with the new CSP directive. Using both headers ensures the best possible browser support, since Microsoft Internet Explorer does not yet support the frame-ancestors directive but respects the X-Frame-Options header instead.
 The syntax for setting the CSP directive is as follows:
 Content-Security-Policy: frame-ancestors [source list]
 Equivalent to X-Frame-Options, there are three possible values for frame-ancestors:
 • frame-ancestors 'none': (equivalent to “X-Frame-Options: DENY”)
 The page cannot be displayed in a frame/iframe, regardless of the site attempting to do so.
 • frame-ancestors 'self': (equivalent to “X-Frame-Options: SAMEORIGIN”)
 The page can only be displayed in a frame/iframe if the embedding page comes from the same domain.
 • frame-ancestors uri: (equivalent to “X-Frame-Options: ALLOW-FROM uri”)
 The page can only be displayed in a frame/iframe on the specified origin.
 Referrer policy
 The referrer policy allows determining the value used in the Referer request header for links and resource requests. By default, without the referrer policy, the entire path from which the user has accessed the resource, including GET parameters, is transmitted when requests are made to web resources. The referrer policy can in fact also be set as a CSP directive. Due to recent browser compatibility, however, we recommend using the referrer policy in the <head> tag of the web page. As an independent referrer policy, the values set here are considered by all common browsers except Internet Explorer:
 <meta name=""referrer"" content=""value"">
 Valid values are: no-referrer, no-referrer-when-downgrade, origin, origin-when-cross-origin and unsafe-url. Microsoft Edge does not support these values but requires the older keywords never, always, origin and default, which other browsers also still accept.
 Example of use
 The CSP header can be set in a number of different ways, as is shown in the following example for the default-src directive. Several directives may also be specified, which have to be separated by semicolons.
 • Apache HTTP Server: 
 o In httpd.conf or alternatively in an .htaccess file:
 § Header set Content-Security-Policy ""default-src 'self'""
 o After adding this line, the web server must be restarted.
 • Via <meta> tag in the source code of an HTML page (not supported by all CSP directives):
 <head>
   <meta http-equiv=""Content-Security-Policy"" content=""default-src 'self';"">
 </head>
 Important: <meta> must be the first element in the <head> element.|",,ei349,ek176,iO924,jy268,od044,zi174,,,,,,,,,,,,,,,,,,,,,XP-2514,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22118400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azym:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/20 11:27;iO924;https://vmt.deutsche-boerse.de/browse/PT-1524","27/Apr/20 09:36;ek176;Might be resolved by XP-2514 (Apache cfg change). Please check","05/Jun/20 14:25;jy268;it will be resolved when this one is ready https://jira.deutsche-boerse.com/browse/XP-2501","10/Jun/20 13:37;ei349;Fixed on CMM already - please retest. ","10/Jun/20 13:37;ei349;no impact on customers.","11/Jun/20 14:17;od044;Test passed within ticket XP-2501
- verified on SYT1
- all SOB request's response contains the following CSP
{code}
Content-Security-Policy: default-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'; connect-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline'; base-uri 'self'; form-action 'self'; font-src 'self';
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V12 - Lacking authorization checks for profile access,XP-2490,90802,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,zi174,zi174,07/Jan/20 14:53,04/Aug/20 19:53,22/Feb/21 13:26,25/May/20 13:46,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V12|
|LOCATION: Web service|
|RISK: High|
|THREAT: An attacker who has login credentials for the application might view and manipulate GUI profiles of any other user. As a result, login using the ComTrader fat client is permanently blocked for the affected users.|
|DESCRIPTION: When we assessed the user separation on the profile server, we noted that it is not given in functions to load and store user profiles. The implementation of this function does not check whether the user authenticating with HTTP Basic auth is actually authorized to access the profile requested.
 It was thus possible to view and edit the profiles of other users. These profiles contain information about the personal ComTrader GUI layouts of the users, but they do not include sensitive information. However, storing invalid data in another user’s profile causes an error in ComTrader on logon. As a result, the affected user cannot login anymore.
 Example
 The following legitimate request (loadProfile) contains the vulnerable parameter (arg1), which is set to the user ID XBCRSC07 belonging to a super administrator user. The request is sent using the credentials of the low-privileged user CIROSEC1 (base64-encoded as HTTP Basic auth header):
 POST /xbid-simu/services/RemoteProfileServiceV3 HTTP/1.1
 Content-Type: text/xml; charset=UTF-8
 Accept: */*
 Authorization: Basic Q0lST1NFQzE█████████████████
 SOAPAction: """"
 User-Agent: Apache-CXF/3.1.14
 Cache-Control: no-cache
 Pragma: no-cache
 Host: simu1.profiles.xbid.deutsche-boerse.com:60104
 Connection: close
 Content-Length: 278
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfile xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><arg0>XSOBv1</arg0><arg1>XBCRSC07</arg1><arg2>simu</arg2></ns2:loadProfile></soap:Body></soap:Envelope>
 
 The server responds with the profile of the user XBCRSC07:
 HTTP/1.1 200 200
 Date: Mon, 09 Dec 2019 08:34:52 GMT
 Server: Apache
 Content-Type: text/xml;charset=UTF-8
 Content-Length: 3112
 Connection: close
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfileResponse xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><return><content>&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;ProfileContentWithFormatVersion&gt;&lt;settings&gt;&lt;entry&gt;&lt;string&gt;tradingMouseActions&lt;/string&gt;&lt;string&gt;&amp;lt;?xml version='1.0' encoding='UTF-8'?&gt;
 
 […]
 
 &lt;/ProfileContentWithFormatVersion&gt;</content><environmentId>simu</environmentId><exchangeId>XSOBv1</exchangeId><formatVersion>1000000</formatVersion><lastProfileSaveTimeStamp>0</lastProfileSaveTimeStamp><userName>XBCRSC07</userName></return></ns2:loadProfileResponse></soap:Body></soap:Envelope>
 
 Example
 The following request (storeProfile) is sent with the credentials of the user CIROSEC1. As a result, the profile content of the different user LOWBOBXX is set to “Cirosec war hier!!!”, which is not valid XML syntax.
 POST /xbid-simu/services/RemoteProfileServiceV3 HTTP/1.1
 Content-Type: text/xml; charset=UTF-8
 Accept: */*
 Authorization: Basic Q0lST1NFQzE6████████████████
 SOAPAction: """"
 User-Agent: Apache-CXF/3.1.14
 Cache-Control: no-cache
 Pragma: no-cache
 Host: simu1.profiles.xbid.deutsche-boerse.com:60104
 Connection: close
 Content-Length: 473
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:storeProfile xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><arg0><content>Cirosec war hier!!!</content><environmentId>simu</environmentId><exchangeId>XSOBv1</exchangeId><formatVersion>1000000</formatVersion><lastProfileSaveTimeStamp>1575883399306</lastProfileSaveTimeStamp><userName>LOWBOBXX</userName></arg0></ns2:storeProfile></soap:Body></soap:Envelope>
 
 If the user LOWBOBXX tries to log in, the ComTrader fat client requests the profile using the following request (with the base64-encoded credentials of the user LOWBOBXX):
 POST /xbid-simu/services/RemoteProfileServiceV3 HTTP/1.1
 Content-Type: text/xml; charset=UTF-8
 Accept: */*
 Authorization: Basic TE9XQk9CWFg6Q███████████████
 SOAPAction: """"
 User-Agent: Apache-CXF/3.1.14
 Cache-Control: no-cache
 Pragma: no-cache
 Host: simu1.profiles.xbid.deutsche-boerse.com:60104
 Connection: close
 Content-Length: 278
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfile xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><arg0>XSOBv1</arg0><arg1>LOWBOBXX</arg1><arg2>simu</arg2></ns2:loadProfile></soap:Body></soap:Envelope>
 
 The server response contains the manipulated profile:
 HTTP/1.1 200 200
 Date: Mon, 09 Dec 2019 09:26:20 GMT
 Server: Apache
 Content-Type: text/xml;charset=UTF-8
 Content-Length: 479
 Connection: close
 
 <soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/""><soap:Body><ns2:loadProfileResponse xmlns:ns2=""http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/""><return><content>Cirosec war hier!!!</content><environmentId>simu</environmentId><exchangeId>XSOBv1</exchangeId><formatVersion>1000000</formatVersion><lastProfileSaveTimeStamp>0</lastProfileSaveTimeStamp><userName>LOWBOBXX</userName></return></ns2:loadProfileResponse></soap:Body></soap:Envelope>
 
 The login fails with the following error:
  
 Figure 2: Targeted user cannot log in because of unknown error
 The log file of the ComTrader application shows that the error is caused by the invalid XML syntax of the manipulated profile:
 2019-12-09T10:32:07.651+0100 [rader-Worker-41] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation \{http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
 2019-12-09T10:32:07.652+0100 [rader-Worker-41] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/LOWBOBXX exists, attempting to load it.
 2019-12-09T10:32:07.886+0100 [rader-Worker-41] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation \{http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
 2019-12-09T10:32:07.890+0100 [rader-Worker-41] ERROR c.d.c.c.s.p.ProfileSerializer - Could not parse value.
 com.thoughtworks.xstream.io.StreamException:
 
 […]
 
 Caused by: com.ctc.wstx.exc.WstxUnexpectedCharException: Unexpected character 'C' (code 67) in prolog; expected '<'
  at [row,col \{unknown-source}]: [1,1]
 
 […]|
|RECOMMENDATION: The web service should restrict users in such a way that they can only access their own profile. This should be implemented by matching the username used for HTTP Basic authentication with the selected user profile. Furthermore, specifying the targeted user profile as a parameter in the request body is not required because the username is already transmitted as a part of the authentication. Therefore, this argument is unnecessary and should be removed.|",,ek176,iO924,tr866,uv683,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,PD-425,,,,,,,"25/May/20 13:22;tr866;ComTrader Logs - SADMIN02 - 2020-05-25.zip;https://jira.deutsche-boerse.com/secure/attachment/84118/ComTrader+Logs+-+SADMIN02+-+2020-05-25.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,23587200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0auks:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,comtrader-2.5.x,profile-storage-1.8.x,master-comtrader-2.5.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/20 11:09;iO924;https://vmt.deutsche-boerse.de/browse/PT-1520","22/May/20 16:08;uv683;Profile storage and CT 2.5.1.63 deployed to SYT2. Could you please test, that profile storage works as expected. Thanks","25/May/20 13:24;tr866;Successfully tested with versions ComTrader 2.5.1.63 ,XB R2.0.37-7740c6f1583cc710c00781d25e60ae8f6d5c2b39

ComTrader is able to save the modified profile and when the local profile is deleted ComTrader loads it successfully from the remote profile (/)

Some exceptions occur in the ComTrader log attached [^ComTrader Logs - SADMIN02 - 2020-05-25.zip] that are not related to the profile server. Otherwise it's visible from the records in the ComTrader logs that connection to Profile server is working correctly.

h4. Steps to reproduce:
# 1st Login to ComTrader and do not save the Profile
## Login to ComTrader
## Make some changes in the UI
## Logout from ComTrader
## Delete the local profile from .comtrader-profiles folder
# Login back to ComTrader and save the Profile
## Login to ComTrader
## Make some changes in the UI
## in ComTrader Meneu bar>Profile>Save Profile save manually the changes
## Logout from ComTrader
## Delete the local profile from .comtrader-profiles folder
# Login to ComTrader again and verify the changes were kept
## Logint to ComTrader
## Check the GUI for the saved changes
## Logout from ComTrader
# Login to ComTrader on different machine(e.g. Citrix)
## Login to ComTrader
## Very if saved changes got loaded
## Logout from ComTrader

h4. Observed behaviour:
# ComTrader got successfully logged in (/)
# Changes from the previous point didn't get preserved if Profile wasn't stored manually (/)
# Profile saved manually got successfully loaded from the profile server even if the local profile was deleted (/)
# The saved profile got loaded also on different machine (/)

h4. Extracts from the log files:
# 1st login: 
{code:xml|title=2020-05-25_12-36-21-525_comtrader_logfile.0.log|borderStyle=solid}2020-05-25T12:36:58.604+0200 [trader-Worker-4] INFO  c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://10.136.143.246:60806/profile-storage/services/RemoteProfileServiceV3
2020-05-25T12:36:58.737+0200 [trader-Worker-4] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-05-25T12:36:59.305+0200 [trader-Worker-4] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-05-25T12:36:59.960+0200 [trader-Worker-4] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-05-25T12:37:00.056+0200 [trader-Worker-4] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-25T12:37:00.058+0200 [trader-Worker-4] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/SADMIN02 does not exist.
2020-05-25T12:37:00.058+0200 [trader-Worker-4] INFO  c.d.c.c.s.p.ProfileManagerImpl - Attempting to create a new default profile.
2020-05-25T12:37:00.175+0200 [trader-Worker-4] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-25T12:37:00.283+0200 [trader-Worker-4] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}createProfile returned 200
2020-05-25T12:37:00.390+0200 [rader-Worker-37] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest2 TS A (XBID): SADMIN02@10.136.142.20:50800/ext/XSOBv1
{code}
# 2nd login
{code:xml|title=2020-05-25_12-40-02-109_comtrader_logfile.0.log|borderStyle=solid}2020-05-25T12:40:21.020+0200 [trader-Worker-6] INFO  c.d.c.c.s.r.WebServiceFactory - Creating web service client for https://10.136.143.246:60806/profile-storage/services/RemoteProfileServiceV3
2020-05-25T12:40:21.157+0200 [trader-Worker-6] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-05-25T12:40:21.681+0200 [trader-Worker-6] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-05-25T12:40:22.527+0200 [trader-Worker-6] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-05-25T12:40:22.618+0200 [trader-Worker-6] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-25T12:40:22.619+0200 [trader-Worker-6] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/SADMIN02 exists, attempting to load it.
2020-05-25T12:40:22.719+0200 [trader-Worker-6] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
2020-05-25T12:40:22.723+0200 [trader-Worker-6] ERROR c.d.c.c.s.p.LocalAndRemoteProfileService - Could not load profile.
com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.ProfileServiceException: Profile doesn't exist.
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalProfileService.loadProfile(LocalProfileService.java:52)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.lambda$loadProfile$5(LocalAndRemoteProfileService.java:58)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.lambda$runLocalForResult$11(LocalAndRemoteProfileService.java:128)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.withHandledException(LocalAndRemoteProfileService.java:177)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.runLocalForResult(LocalAndRemoteProfileService.java:128)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.runLocalForResult(LocalAndRemoteProfileService.java:124)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.loadProfile(LocalAndRemoteProfileService.java:61)
	at com.deutscheboerse.comxerv.comtrader.service.profile.ProfileManagerImpl.loadProfileInternal(ProfileManagerImpl.java:86)
	at com.deutscheboerse.comxerv.comtrader.service.profile.ProfileManagerImpl.lambda$loadOrCreateProfile$0(ProfileManagerImpl.java:110)
	at com.deutscheboerse.ui.jfx.util.LoggingCallable.call(LoggingCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-05-25T12:40:22.850+0200 [trader-Worker-3] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest2 TS A (XBID): SADMIN02@10.136.142.20:50800/ext/XSOBv1{code}
## 2.3 Saving Profile after the changes
{code:xml|title=2020-05-25_12-40-02-109_comtrader_logfile.0.log|borderStyle=solid}2020-05-25T12:43:40.329+0200 [rader-Worker-25] ERROR c.d.c.c.j.ComtraderBase - Comtrader-Worker-25
java.lang.IllegalStateException: This operation is permitted on the event thread only; currentThread = Comtrader-Worker-25
	at com.sun.glass.ui.Application.checkEventThread(Application.java:443)
	at com.sun.glass.ui.Window.setTitle(Window.java:829)
	at com.sun.javafx.tk.quantum.WindowStage.setTitle(WindowStage.java:476)
	at javafx.stage.Stage$5.invalidated(Stage.java:736)
	at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:109)
	at javafx.beans.property.StringPropertyBase.bind(StringPropertyBase.java:171)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.lambda$new$3(TabPanel.java:146)
	at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:349)
	at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)
	at javafx.beans.property.ReadOnlyObjectPropertyBase.fireValueChangedEvent(ReadOnlyObjectPropertyBase.java:74)
	at javafx.beans.property.ReadOnlyObjectWrapper.fireValueChangedEvent(ReadOnlyObjectWrapper.java:102)
	at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112)
	at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146)
	at javafx.scene.control.SelectionModel.setSelectedItem(SelectionModel.java:102)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:717)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:735)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:656)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.selectTab(TabPanel.java:342)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.lambda$forceDisplayAllTabs$9(TabPanel.java:333)
	at com.deutscheboerse.ui.jfx.util.LoggingRunnable.run(LoggingRunnable.java:21)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-05-25T12:43:40.330+0200 [rader-Worker-25] INFO  c.d.c.c.j.c.TabPanel - Selected tab: New Tab
2020-05-25T12:43:40.432+0200 [trader-Worker-4] ERROR c.d.c.c.j.ComtraderBase - Comtrader-Worker-4
java.lang.IllegalStateException: This operation is permitted on the event thread only; currentThread = Comtrader-Worker-4
	at com.sun.glass.ui.Application.checkEventThread(Application.java:443)
	at com.sun.glass.ui.Window.setTitle(Window.java:829)
	at com.sun.javafx.tk.quantum.WindowStage.setTitle(WindowStage.java:476)
	at javafx.stage.Stage$5.invalidated(Stage.java:736)
	at javafx.beans.property.StringPropertyBase.markInvalid(StringPropertyBase.java:109)
	at javafx.beans.property.StringPropertyBase.bind(StringPropertyBase.java:171)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.lambda$new$3(TabPanel.java:146)
	at com.sun.javafx.binding.ExpressionHelper$Generic.fireValueChangedEvent(ExpressionHelper.java:349)
	at com.sun.javafx.binding.ExpressionHelper.fireValueChangedEvent(ExpressionHelper.java:81)
	at javafx.beans.property.ReadOnlyObjectPropertyBase.fireValueChangedEvent(ReadOnlyObjectPropertyBase.java:74)
	at javafx.beans.property.ReadOnlyObjectWrapper.fireValueChangedEvent(ReadOnlyObjectWrapper.java:102)
	at javafx.beans.property.ObjectPropertyBase.markInvalid(ObjectPropertyBase.java:112)
	at javafx.beans.property.ObjectPropertyBase.set(ObjectPropertyBase.java:146)
	at javafx.scene.control.SelectionModel.setSelectedItem(SelectionModel.java:102)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:717)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:735)
	at javafx.scene.control.TabPane$TabPaneSelectionModel.select(TabPane.java:656)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.selectTab(TabPanel.java:338)
	at com.deutscheboerse.comxerv.comtrader.jfx.components.TabPanel.lambda$selectTab$10(TabPanel.java:343)
	at com.deutscheboerse.ui.jfx.util.LoggingRunnable.run(LoggingRunnable.java:21)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-05-25T12:43:40.432+0200 [trader-Worker-4] INFO  c.d.c.c.j.c.TabPanel - Selected tab: Admin Overview
2020-05-25T12:43:40.433+0200 [lication Thread] INFO  c.d.c.c.j.c.ContentTab - Storing component: com.deutscheboerse.comxerv.comtrader.jfx.components.OrderbookPanel
2020-05-25T12:43:40.434+0200 [lication Thread] INFO  c.d.c.c.j.c.ContentTab - Storing component: com.deutscheboerse.comxerv.comtrader.jfx.components.AllTradePanel
2020-05-25T12:43:40.434+0200 [lication Thread] INFO  c.d.c.c.j.c.ContentTab - Storing component: com.deutscheboerse.comxerv.comtrader.jfx.components.MessagePanel
2020-05-25T12:43:40.434+0200 [lication Thread] INFO  c.d.c.c.j.c.ContentTab - Storing component: com.deutscheboerse.comxerv.comtrader.jfx.components.OrderbookPanel
2020-05-25T12:43:40.530+0200 [rader-Worker-29] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-25T12:43:40.637+0200 [rader-Worker-29] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}storeProfile returned 200{code}
# 3rd login with the saved changes
{code:xml|title=2020-05-25_12-51-46-929_comtrader_logfile.0.log|borderStyle=solid}2020-05-25T12:52:35.533+0200 [rader-Worker-23] INFO  o.a.c.w.s.f.ReflectionServiceFactoryBean - Creating Service {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}RemoteProfileServiceService from class com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.RemoteProfileService
2020-05-25T12:52:36.054+0200 [rader-Worker-23] WARN  o.a.c.p.PhaseInterceptorChain - Skipping interceptor com.deutscheboerse.comxerv.comtrader.service.remote.WebServiceFactory$LoggingInterceptor: Phase pre-invoke specified does not exist.
2020-05-25T12:52:36.679+0200 [rader-Worker-23] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}ping returned 200
2020-05-25T12:52:36.763+0200 [rader-Worker-23] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}profileExists returned 200
2020-05-25T12:52:36.765+0200 [rader-Worker-23] INFO  c.d.c.c.s.p.ProfileManagerImpl - Profile XSOBv1/SADMIN02 exists, attempting to load it.
2020-05-25T12:52:36.880+0200 [rader-Worker-23] INFO  c.d.c.c.s.r.WebServiceFactory - Remote operation {http://v3.profilestorage.remote.comtrader.m7.deutscheboerse.com/}loadProfile returned 200
2020-05-25T12:52:36.884+0200 [rader-Worker-23] ERROR c.d.c.c.s.p.LocalAndRemoteProfileService - Could not load profile.
com.deutscheboerse.m7.comtrader.remote.profilestorage.v3.ProfileServiceException: Profile doesn't exist.
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalProfileService.loadProfile(LocalProfileService.java:52)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.lambda$loadProfile$5(LocalAndRemoteProfileService.java:58)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.lambda$runLocalForResult$11(LocalAndRemoteProfileService.java:128)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.withHandledException(LocalAndRemoteProfileService.java:177)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.runLocalForResult(LocalAndRemoteProfileService.java:128)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.runLocalForResult(LocalAndRemoteProfileService.java:124)
	at com.deutscheboerse.comxerv.comtrader.service.profile.LocalAndRemoteProfileService.loadProfile(LocalAndRemoteProfileService.java:61)
	at com.deutscheboerse.comxerv.comtrader.service.profile.ProfileManagerImpl.loadProfileInternal(ProfileManagerImpl.java:86)
	at com.deutscheboerse.comxerv.comtrader.service.profile.ProfileManagerImpl.lambda$loadOrCreateProfile$0(ProfileManagerImpl.java:110)
	at com.deutscheboerse.ui.jfx.util.LoggingCallable.call(LoggingCallable.java:23)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-05-25T12:52:37.081+0200 [rader-Worker-45] INFO  c.d.c.c.a.c.c.AbstractComXervExchangeConnection - attempting to createConnection to: Systemtest2 TS A (XBID): SADMIN02@10.136.142.20:50800/ext/XSOBv1{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V18 - Insufficient protection of session cookies TECHOPS,XP-2489,90801,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,zi174,07/Jan/20 14:53,04/Aug/20 19:53,22/Feb/21 13:26,11/Jun/20 14:41,,,3.1.0,,,,,,,PenetrationTest,TechOps,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V18|
|LOCATION: Web application (Session management)|
|RISK: None|
|THREAT: Cookies can disclose sensitive information as the SameSite option has not been set.|
|DESCRIPTION: The assessed application uses cookies to transmit data like session IDs persistently. 
 Ideally, sensitive data like session IDs should only be transmitted using a TLS channel. This can be indicated to the browser by setting the cookie option Secure. 
 Moreover, the HttpOnly cookie option allows preventing JavaScript code from accessing the cookie within the browser. This mechanism offers some degree of protection against certain attack scenarios in combination with cross-site scripting.
 In addition, using the SameSite option, it can be prevented that sensitive cookies (such as session cookies) are sent to the server when the request is triggered by a third party, e.g. in an iframe or an XMLHttpRequest (XHR) via JavaScript. Setting the SameSite flag thus effectively prevents CSRF attacks as long as the browser supports this option. This is currently the case in recent versions of Chrome (as of version 51) and Firefox (as of version 60) as well as in Edge (as of version 16) and Internet Explorer 11 as of Windows 10 . For Chrome, starting with Chrome 80, the browser enables the SameSite=Lax option by default if it is not set by the server .
 In the present case, only the Secure and HttpOnly options have been set, while the SameSite option has not.
 Example
 Server response to an HTTP request:
 HTTP/1.1 302 302
 Date: Wed, 04 Dec 2019 07:38:26 GMT
 Server: Apache
 Strict-Transport-Security: max-age=63072000; includeSubdomains;
 Set-Cookie: JSESSIONID=DA25229F76C449E43700F1C03BFFAB31.xbid-simu-sob1; Path=/intraday; Secure; HttpOnly
 Cache-Control: no-cache, no-store, max-age=0, must-revalidate
 Pragma: no-cache
 Expires: 0
 Strict-Transport-Security: max-age=31536000 ; includeSubDomains
 X-XSS-Protection: 1; mode=block
 X-Frame-Options: DENY
 X-Content-Type-Options: nosniff
 Location: faces/jsp/welcome.xhtml
 Content-Type: text/html;charset=ISO-8859-1
 Content-Length: 0
 Connection: close
 […]
 
 As can be seen from the output, the JSESSIONID cookie has been set without the SameSite option.|
|RECOMMENDATION: The Secure, SameSite and HttpOnly options should be set when cookies are issued.
 The value SameSite=lax provides a reasonable balance between security and usability. In this case, cookies are only sent along in cross-site requests that the browser considers safe. They are not sent along in POST requests or when the site is embedded in an iframe.
 If the session cookie is set with the value SameSite=strict, it is never sent along in any cross-site requests.
 In the present case, we recommend the SameSite=strict setting, as long as there are no external sites linking to the internal area of the application.|",,eh941,ei349,ek176,iO924,od044,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 14:23;od044;Screenshot 2020-06-09 at 11.14.54.png;https://jira.deutsche-boerse.com/secure/attachment/84791/Screenshot+2020-06-09+at+11.14.54.png","11/Jun/20 14:36;od044;sob-login.png;https://jira.deutsche-boerse.com/secure/attachment/84792/sob-login.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22032000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0azyn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/20 15:02;eh941;It can be done on Apache's level or on Tomcat. From my point of view it would make more sense to do it on Apache because security is one of the Apache's responsibility.

How to set it up on Apache is a bit described there - https://geekflare.com/httponly-secure-cookie-apache/

If you choose to do it on Tomcat:

In order to add sameSiteCookies add following tag:
{code:xml}
<Context>
    <CookieProcessor sameSiteCookies=""strict"" />

<!-- THE REMAING-->
</Context>
{code}

to {{conf/context.xml}}

{color:#DE350B}*Please note that this feature was added in Tomcat Version  8.5.42*{color} - see [this stackoverflow post|https://stackoverflow.com/questions/57505939/how-to-set-samesite-cookie-in-tomcats-cookie-processor]

To add Secure and HttpOnly add:

{code:xml}

    <session-config>
        <cookie-config>
            <http-only>true</http-only>
            <secure>true</secure>
        </cookie-config>
<!-- THE REST -->
    </session-config>
{code}

to {{conf/web.xml}}

","23/Jan/20 11:29;iO924;https://vmt.deutsche-boerse.de/browse/PT-1526","10/Jun/20 13:35;ei349;please retest","11/Jun/20 14:40;od044;Test passed
- ticket solved within another ticket XP-2506
- verified on SYT1 again 
- Set-Cookies header contain parameter SameSite=lax
 !sob-login.png!  
!Screenshot 2020-06-09 at 11.14.54.png! 

Step to reproduce
1. Open browser as incognito with web console (open via inspect web element in context menu)
2. Open Network tab in web console and check Preserve log 
3. Open and login SOB open 
4. Find Set-Cookies header in one of first request and verify that it contains SameSite=lax",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V13 – Protection against cross-site scripting,XP-2488,90800,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,07/Jan/20 14:53,31/Aug/20 15:39,22/Feb/21 13:26,09/Jun/20 12:28,,,3.1.0,,Capacity,,,,,PenetrationTest,TechOps,,,"h3. Protection against cross-site scripting (X-XSS-Protection header)

Internet Explorer and Google Chrome have integrated filters that may detect and prevent common XSS attacks. Nevertheless, users can disable those filters. To disable the XSS filter for Chrome, the browser must be started using the command line “—disable-xss-auditor”; for Internet Explorer, the filter can be disabled in the security settings:

!image-2020-01-07-14-54-13-904.png!

_Disabled XSS filter for Internet Explorer_

The X-XSS-Protection header instructs the browser explicitly to use the filter for the given website (even though the user might have disabled the filter). Simple XSS attacks are thus no longer successful. All common browsers support this header, except Firefox.

*Threat*

Without using the X-XSS-Protection header, any user can disable the XSS filter in his browser. This increases the probability of cross-site scripting vulnerabilities to be exploited.
|Vulnerability:|*P2-V13* – Missing X-XSS-Protection header| |
|*Threat:* Ease of cross-site scripting attacks|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 0|
|Attack vector:
Network|Confidentiality impact:
None|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
None|Availability impact:
None|
|User interaction:
None|Scope:
Unchanged|
|*Score:* 3.9|*Score:* 0|
|*Location:* Web server configuration|
|*OWASP Top Ten:* A6 - Security Misconfiguration|
|*ASVS 3.0.1 requirement:*  11.8|
|*Recommendation:* Set the X-XSS-Protection header.|

*Recommendations*

We recommend setting the X-XSS-Protection header:
 * X-XSS-Protection: 1; mode=block

In browsers supporting this header, the filter is also enabled by default. Setting the header will thus have no consequences for most users, which means that negative influence on functionality is rather unlikely.

_For the original finding files please see XP-2460._",,ek176,iO924,jy268,od044,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/20 14:54;radeale;image-2020-01-07-14-54-13-904.png;https://jira.deutsche-boerse.com/secure/attachment/78977/image-2020-01-07-14-54-13-904.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22291200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a28k:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,xbid-dev-env,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,XP-2488-X-XSS-Protection-PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jan/20 14:16;qo794;Configurable in Apache web server.","23/Jan/20 16:13;iO924;https://vmt.deutsche-boerse.de/browse/PT-1548","09/Jun/20 10:44;jy268;Header added on apache level and deployed to sy1. [~od044] please test.","09/Jun/20 10:45;jy268;NON PROD PR: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/674
PROD PR: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/675","09/Jun/20 12:28;od044;Test passed on SYT1 

- response header contains 
{code}
X-XSS-Protection: 1; mode=block
{code}
- checked for all module CMI, CMM, SM, SOB
- smoke test - ok",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
V2 - Directory traversal on the application's server TECHOPS,XP-2485,90797,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,zi174,07/Jan/20 14:51,04/Aug/20 19:53,22/Feb/21 13:26,15/Jun/20 16:48,,,3.1.0,,,,,,,PenetrationTest,TechOps,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V2|
|LOCATION: Reverse proxy, Application server configuration|
|RISK: Medium|
|THREAT: The path traversal vulnerability allows an attacker to leave the application’s subdirectory and access other applications on the same server (e. g. default components of the server). This increase the application server’s attack surface.|
|DESCRIPTION: The URL https://10.103.128.23:60100/intraday/ is redirected to a subdirectory on an Apache Tomcat server by a reverse proxy. This prevents an attacker from accessing the root path of the Tomcat server. However, differences in the path normalization behavior of the reverse proxy and the Tomcat server allow an attacker to leave the subdirectory using a so-called directory or path traversal attack. The reverse proxy does not normalize the pattern /..;/ but passes it to the Tomcat server, which parses the pattern and switches to the parent directory, allowing a path traversal. 
 Example
 The following URL allows an external attacker to access the default Apache Tomcat page in the web root:
 https://10.103.128.23:60100/intraday/..;/
 
 When this URL is opened in a browser, the default Tomcat page is shownThe profile server is vulnerable to the same path traversal using the following URL:
 https://simu1.profiles.xbid.deutsche-boerse.com:60104/xbid-simu/..;/|
|RECOMMENDATION: We recommend blocking URLs that contain the character “;” using the reverse proxy. In addition the default page of the Tomcat application server should be removed.|",,eh941,ei349,ek176,iO924,od044,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2499,XP-2493,,,,,,"15/Jun/20 16:47;od044;after-fix.png;https://jira.deutsche-boerse.com/secure/attachment/84857/after-fix.png","15/Jun/20 16:47;od044;tomcat-default.png;https://jira.deutsche-boerse.com/secure/attachment/84858/tomcat-default.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,21686400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ay7m:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Jan/20 14:20;eh941;Prior to this please consider doing XP-2493

I see 2 things that needs to be done:
- remove default Tomcat applications from tomcat package that is deployed
- forbid user to browse the relative path using {{..;/}} in URL as suggested in the recommendation

Please apply those changes to all deployed applications","23/Jan/20 11:18;iO924;https://vmt.deutsche-boerse.de/browse/PT-1528","05/Jun/20 17:20;yo218;removal of the default Tomcat applications will be solved with future ansible deployments (webapps directory is excluded):
{noformat}
- name: Extract tomcat
  unarchive:
    src: 'artifacts/apache-tomcat-{{ tomcat_version }}.tar.gz'
    dest: '{{ tomcat_directory }}/'
    exclude:
    - ""conf/context.xml""
    - ""conf/server.xml""
    - ""webapps""
    extra_opts: ""--strip-components=1"" {noformat}
I just tried to adopt the proposal from pentesters by using rewrite engine:
{noformat}
<IfModule rewrite_module>
RewriteEngine On
RewriteRule ; - [F]
</IfModule> {noformat}
MR for xbid-dev-env repo: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/668]","10/Jun/20 13:32;ei349;no impact on customer","11/Jun/20 15:00;od044;[~yo218] on which SYT env did you put the configuration?
I have tested on SYT1 and checked the configuration on web server and it seems that the setting has not been applied yet. ","15/Jun/20 09:28;yo218;I just provided a PR but it has not been merged yet","15/Jun/20 16:47;od044;Test passed on SYT1 

- cannot access to default tomcat page via URL with '..;/' anymore

Reproduced:
 !tomcat-default.png! 

After fix:  
!after-fix.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V12 – Missing Expect-CT header TECHOPS,XP-2484,90796,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,07/Jan/20 14:49,11/Aug/20 16:35,22/Feb/21 13:26,03/Aug/20 15:59,,,3.1.0,,Capacity,,,,,PenetrationTest,TechOps,,,"h3. Missing Expect-CT header

TLS certificate-based encryption between the browser and server relies on trust. Usually, it is possible for a CA to create a certificate for an arbitrary domain, even multiple times. With Certificate Transparency, it is very likely that a domain owner notices when a new certificate for his domain is issued.

This is realized by the browser evaluating so-called Certificate Transparency Logs of the CA. The Expect-CT header indicates the browser to check whether the server certificate is listed in such a log.

To be precise, the Expect-CT header tells a browser to also check the certificate in future (for the period of time indicated in the header), and report issues to the URL contained in the header as well.

For details please see [https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Expect-CT] .

*Threat*

In the present case, the Expect-CT header is not sent in server responses. This makes it easier to use certificates that have been issued for the server improperly.
|Vulnerability:|*P2-V12* – Missing Expect-CT header| |
|*Threat: Makes using improperly issued certificates easier*|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 0|
|Attack vector:
Network|Confidentiality impact:
None|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
None|Availability impact:
None|
|User interaction:
None|Scope:
Unchanged|
|*Score:* 3.9|*Score:* 0|
|*Location:* Web server configuration|
|*OWASP Top Ten:* A3 - Sensitive Data Exposure|
|*ASVS 3.0.1 requirement:*  not relevant|
|*Recommendation:* Set the Expect-CT header.|

*Recommendations*

We recommend setting the Expect-CT header as follows:
|Expect-CT: enforce, max-age=7776000, report‑uri=""https://deutsche-boerse.com/report""|

The max-age parameter should not be set too short, the example value of 7776000 means about three months. The report-uri must differ from the application URL deutsche-boerse.com and process corresponding messages of browsers, so that indications of invalid certificates can be investigated.

We recommend first omitting the enforce option for testing during the introduction of this header until the correct functioning of the header has been proven. During this time, certificate issues that occur when accessing the application are reported to the indicated URI; however, access is not completely blocked in such cases. Once any potential problems during the introduction and configuration of Certificate Transparency have been removed, the enforce option can be added.

_For the original finding files please see XP-2460._",,ei349,ek176,iO924,od044,qo794,radeale,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/20 15:59;od044;Screenshot 2020-08-03 at 15.58.56.png;https://jira.deutsche-boerse.com/secure/attachment/86184/Screenshot+2020-08-03+at+15.58.56.png","03/Aug/20 15:18;yo218;image-2020-08-03-15-18-34-466.png;https://jira.deutsche-boerse.com/secure/attachment/86180/image-2020-08-03-15-18-34-466.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17452800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,xbid-dev-env,XP-2484,XP-3110-deprecated-log,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jan/20 14:16;qo794;Configurable in Apache web server.","23/Jan/20 15:47;iO924;https://vmt.deutsche-boerse.de/browse/PT-1547","09/Jun/20 15:02;yo218;Proper Apache config item:
{noformat}
<IfModule mod_headers.c>
  <Directory />
    Header always set Expect-CT: enforce, max-age=7776000, report‑uri=""https://deutsche-boerse.com/report""
  </Directory>
</IfModule> {noformat}","09/Jun/20 15:08;yo218;Merged [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/678] into xbid-dev-env.

Redeployment of apache is required.

Please verify [~od044]","10/Jun/20 13:45;ei349;No impact customers. ","11/Jun/20 09:41;od044;The configuration does not work in httpd.conf. It seems it should be set in apache template for individual env resp. xbid.conf. 

For reference this PR https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/671/files

- add configuration to xbid.conf
{code}
Header always set Expect-CT 'enforce, max-age=7776000, report-uri=""https://deutsche-boerse.com/report""'
{code}

","15/Jun/20 07:34;yo218;Changed the templates as suggested by [~od044]. Please redeploy and retest","25/Jun/20 15:54;od044;[~yo218] It still does not work, It seems the format <IfModule mod_headers.c> does not work in xbid.conf 

Could you just add the 
{code}
Header always set Expect-CT 'enforce, max-age=7776000, report-uri=""https://deutsche-boerse.com/report""'
{code}

to # HSTS header section like other header?","30/Jul/20 09:47;yo218;Happened already forgot to mention it here. [~od044] you verified it already, right?","30/Jul/20 11:36;od044;hi [~yo218], on which SYT is it configured? Is it SYT1? I have just redeploy SYT1 to double check it again, but I do not see the header there.

Anyway, what changes have been made exactly? ","31/Jul/20 10:47;yo218;added the following part into the apache template:
{noformat}
    # XP-2484 enforcing Expect-CT
    <IfModule mod_headers.c>
      <Directory />
        Header always set Expect-CT ""enforce,max-age=7776000,report-uri='https://deutsche-boerse.com/report'""
      </Directory>
    </IfModule>
{noformat}","03/Aug/20 11:29;od044;I have verified it again by manually adding the configuration line (see below) into /shrd/xbid-syt3-cmm-web1/config/conf.d/xbid.conf
{code}
Header always set Expect-CT 'max-age=7776000, report-uri=""https://deutsche-boerse.com/report""'
{code}
and it works.

Note: the format <IfModule mod_headers.c> does not work.

[~yo218] Please update those template for NON-PROD and PROD env accordingly. ","03/Aug/20 15:18;yo218;Final change can be seen here:

[https://github.deutsche-boerse.de/dev/energy-mkt-shared/commit/8343745af037f5fc86c5e875368912d066e406a7#diff-c4458e578cdf7ad4e28677bb8d21bc7a]

!image-2020-08-03-15-18-34-466.png!","03/Aug/20 15:59;od044;Test passed on SYT3
- all request within modules SM, CMM,CMI,SOB contain Expect-CT header
 !Screenshot 2020-08-03 at 15.58.56.png! ",,,,,,,,,,,,,,,,,,,,,,,,
V11 - Comments in HTML source code,XP-2482,90794,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,zi174,zi174,07/Jan/20 14:42,04/Aug/20 19:53,22/Feb/21 13:26,14/Feb/20 15:35,,,3.1.0,,,,,,,PenetrationTest,,,,"|ORIGINAL: ESO-240 - FINDING: P3P5-V11|
|LOCATION: Web application, affected URL: [https://10.103.128.23:60100/intraday/logout.html]|
|RISK: Medium|
|THREAT: Source code comments can unintentionally disclose sensitive data.
 In many cases, the information poses no immediate threat. It can, however, help an attacker to plan and launch subsequent attacks or to carry out social engineering attacks.
 The comment discloses a username, therefore the confidentiality impact is rated as low.|
|DESCRIPTION: Generally, the term information disclosure refers to the disclosure of sensitive data. Sensitive information is unnecessarily revealed quite often. The disclosure itself is sometimes not a threat and does not have to be rated as security-related. However, an attacker might use apparently harmless information for planning attacks if he combines it with further information or other vulnerabilities.
 Example
 The HTML source code contains a comment with an internal username.
 URL:
 [https://10.103.128.23:60100/intraday/logout.html]|

Excerpt from the HTML code:
 <!-- 
     Document   : logout
     Created on : 16-Sep-2008, 14:44:30
     Author     : hvizmar
 -->|
|RECOMMENDATION: Information disclosure in HTML comments should be prevented. Therefore, we recommend completely removing all comments.|",,ei349,ek176,iO924,tr866,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,32227200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ew",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,Alpha Sprint 1 (S),Alpha Sprint 2,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/20 11:14;iO924;https://vmt.deutsche-boerse.de/browse/PT-1519","06/Feb/20 14:52;ei349;to test","14/Feb/20 15:35;tr866;Successfully tested in docker with version XB R3.0.18-SNAPSHOT-d53078199c2b03659f1fe3b39c9b47d618c79fa2
Source code of the SOB logout page looks as following:
the comment from the beginning was removed
{code:html|title=http://localhost:24081/xbid-trading/logout.html}
<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"">
<html>
    <head>
        <title></title>
        <meta http-equiv=""Content-Type"" content=""text/html; charset=windows-1252"">
        
    </head>
    <body>
        <h2>You are now logged out...</h2>
        <a href=""./"">login</a>
    </body>
</html>{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V11 – POST requests containing sensitive data accepted as GET requests,XP-2481,90792,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,radeale,radeale,07/Jan/20 14:38,11/Aug/20 16:36,22/Feb/21 13:26,10/Jun/20 11:35,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h2. POST requests containing sensitive data accepted as GET requests

Clients usually use two HTTP methods to send a request to an application: GET or POST. Both methods differ in how parameters are transmitted. GET requests append parameters directly to the URL, POST requests transmit parameters as part of the message body.

When transmitting sensitive or confidential data like session IDs or passwords in parameters, the POST method is preferred from a security perspective. HTTP requests usually pass a variety of network devices, such as routers, proxy servers or web application firewalls (WAF), on their way from the browser to the server. Both proxy servers and WAFs as well as the web server often store the requested URLs including the appended parameters in an access log. This makes it easier for an attacker to access sensitive information (e.g. session cookies, …).

POST requests are also beneficial on the client side because they are not stored in the browsing history and can still be saved as bookmarks.

Examining CMM, we noted that sensitive data from the client to the application is sent almost in the form of GET requests.

*Example*

Affected URL:
|https://cmi-simu1.xbid.deutsche-boerse.com/cmminteg/cmm/public/portal|

Example GET request usually sent to the application when logging in:
|*{color:#de350b}GET{color}* /cmminteg/cmm/public/portal HTTP/1.1
 Host: cmi-simu1.xbid.deutsche-boerse.com
 Connection: close
 {color:#de350b}*Authorization: Basic WEJxxxxxxxxxx16aHM7eWxjNHR6*{color}
 Upgrade-Insecure-Requests: 1
 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36
 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
 Referer: [https://cmi-simu1.xbid.deutsche-boerse.com/cmminteg/pages/index.faces]
 Accept-Encoding: gzip, deflate
 Accept-Language: en-US,en;q=0.9
 Cookie: JSESSIONID=158082BCE51B1A881A200BDB1E887C7E.xbid-simu-cmi1|

*Threat*

The fact that the application uses GET requests makes eavesdropping on sensitive data or session IDs easier.
|Vulnerability:|*P2-V11* – Sensitive data is transferred using GET requests| |
|*Threat:* Makes eavesdropping on sensitive data or session IDs easier|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 2.6|
|Attack vector:
 Network|Confidentiality impact:
 Low|
|Attack complexity:
 High|Integrity impact:
 None|
|Privileges required:
 Low|Availability impact:
 None|
|User interaction:
 Required|Scope:
 Unchanged|
|*Score:* 1.2|*Score:* 1.4|
|*Attacker profile:* Expert|
|*Location: Web application*|
|*OWASP Top Ten:* A3 - Sensitive Data Exposure|
|*ASVS 3.0.1 requirement:* 9.3|
|*Recommendation:* Only transfer sensitive data using POST requests.|

*Recommendations*

Sensitive information like session IDs or confidential data in request parameters should exclusively be sent to the server as POST parameters. The application should not accept these calls via GET.

_For the original finding files please see XP-2460._",,ek176,iO924,ll664,tr866,,,,,,,,,,,,,,,,,,,,,,,XP-2496,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22204800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a27s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,XP-3048-only-two-ts-in-case-of-no-atc-in-requested-time-range,acceptance,develop,XP-3015,XP-3079,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 14:51;ll664;I don't see how this would be an issue:

* the shown URL does not contain any query parameters
* the  Authorization header is standard header valid for GET requests as well
* HTTPS channel does not even reveal the requested URLs, hence the argument with routers sniffing on the way is invalid.

I suggest to close as 'not a bug'.","23/Jan/20 16:27;iO924;https://vmt.deutsche-boerse.de/browse/PT-1546","19/Mar/20 08:56;ek176;On the SSL terminators, the params might be a part of logs or debugging msgs (either on our/customer side).

The Basic auth string is easy to decode: Only base64 enc is used.

 

As it's Low impact, I'd leave it as: Nice to have, or do not spend more than 1-2 storypts.","09/Jun/20 16:09;tr866;Tested on docker with version R2.0.42-SNAPSHOT (Build d3f7c64e87c32420dccb2dd7b6ecdec8e7e9aaba)
When the url with GET data is entered with up-to-date string in form of 
{noformat}
http://localhost:24082/cmm-inquiry/jsp/changePasswd.faces?page%3A%3Aform-action=page%3Aj_id_h&page%3A%3Acontext-path=%2Fcmm-inquiry&page%3A%3Aaction-position=1048px%2C103px%2C120px%2C20px&page%3A%3Aform-clientDimension=1427%3B516&page%3A%3AscrollbarWeight=17%3B17&org.apache.myfaces.tobago.webapp.Secret=CRoOeCTHvhYdkJ76MzbOaw&page%3Aj_id_9_tx_field=a&page%3AnewPasswdInput_tx_field=bbbbbbbbb&page%3AnewPasswdRepeatInput_tx_field=bbbbbbbb&page%3Aj_id_l%3A%3AmessagesExists=true&page%3A%3AmessagesClientIds=page%3Aj_id_l&javax.faces.ViewState=QUM2QTMyODdGQTIzQTk0QjAwMDAwMDY0&javax.faces.RenderKitId=tobago%0A{noformat} then a blank empty white page is displayed instead of the page informing about the connection attempt to LDAP.

In Web Developer > Network panel 404 code was received.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V10 – Outdated Tomcat version,XP-2480,90791,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,radeale,radeale,07/Jan/20 14:29,31/Aug/20 15:38,22/Feb/21 13:26,20/Jan/20 14:04,,,3.1.0,,Capacity,,,,,PenetrationTest,TechOps,,,"h2. Outdated Tomcat version

The Tomcat version 8.5.35 announced in default pages (see section 7.8) is outdated and contains publicly known vulnerabilities. The most recent version at the time of the assessment was Tomcat 9.0.29.

Moreover, the version in use is subject to various publicly known vulnerabilities including the following:
 * CVE-2019-0199[[1]|#_ftn1]
 * CVE-2019-0221[[2]|#_ftn2]
 * CVE-2019-10072[[3]|#_ftn3]

*Note*

Unix systems and Linux distributions often use their own versioning scheme for their packages while only roughly considering the versioning of the original software vendor. We always check the status based on the reported banner against information of the original software vendor. Therefore, the encountered installation with the reported version 8.5.35 respectively 9.0.29 might already include all the necessary security updates. However, this can only be verified by having interactive access to the system.

*Threat*

CVE-2019-10072 potentially allows an attacker to conduct a denial-of-service attack.

In general, it is not recommended to use a software version that contains known vulnerabilities and is not supported by the manufacturer anymore. Even though the vendor might be aware of security-related issues in the software, he might only patch them in recent, “supported” versions. Furthermore, potential fixes from the vendor that improve the functionality and stability are not available.
|Vulnerability:|*P2-V10* – Outdated Tomcat version with known vulnerabilities (e.g. CVE-2019-10072)| |
|*Threat:* Denial of service|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Severe|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 7.5|
|Attack vector:
Network|Confidentiality impact:
None|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
None|Availability impact:
High|
|User interaction:
None|Scope:
Unchanged|
|*Score:* 3.9|*Score:* 3.6|
|*Attacker profile:* Expert|
|*Location:* Application server software|
|*OWASP Top Ten:* A9 - Using Components with Known Vulnerabilities|
|*ASVS 3.0.1 requirement:*  1.11, 19.1|
|*Recommendation: Update Tomcat to the most recent version*.|

*Recommendations*

We recommend deploying the most recent version of Tomcat.

[[1]|#_ftnref1] https://www.cvedetails.com/cve/CVE-2019-0199/

[[2]|#_ftnref2] https://www.cvedetails.com/cve/CVE-2019-0221/

[[3]|#_ftnref3] https://www.cvedetails.com/cve/CVE-2019-10072/

_For the original finding files please see XP-2460._",,ek176,iO924,ll664,radeale,,,,,,,,,,,,,,,,,,,,,,,XP-2493,,,,,,,,,PD-425,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34214400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a27k:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/20 14:04;ll664;Closing as duplicete.","23/Jan/20 13:14;iO924;https://vmt.deutsche-boerse.de/browse/PT-1545",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V9 – Unused default application server components are reachable TECHOPS,XP-2479,90790,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,radeale,radeale,07/Jan/20 14:24,31/Aug/20 15:38,22/Feb/21 13:26,08/Jun/20 11:15,,,3.1.0,,Capacity,,,,,PenetrationTest,TechOps,,,"h2. Unused default application server components

Several default components of the Tomcat application server have not been removed, although they are most likely not required for operating the application.

*Examples*

The Tomcat default web page has not been removed and can be accessed with the following URL:
|https://cmm-simu1.xbid.deutsche-boerse.com/cmm/pages/admin/admin.faces/..;//..;//..;///..;/|

The following figure shows the page accessible via the URL given above:

!image-2020-01-07-14-26-07-233.png!

*Threat*

The standard components unnecessarily increase the application server’s attack surface.
|Vulnerability:|*P2-V9* – Unused default application server components are reachable| |
|*Threat:* Increased attack surface|
|*Threat Exposure:*  Internet DMZ|*Threat Level:*  Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 4.3|
|Attack vector:
Network|Confidentiality impact:
Low|
|Attack complexity:
Low|Integrity impact:
None|
|Privileges required:
Low|Availability impact:
None|
|User interaction:
None|Scope:
Unchanged|
|*Score:* 2.8|*Score:* 1.4|
|*Attacker profile:* Script kiddie|
|*Location:* Application server configuration|
|*OWASP Top Ten:* A6 - Security Misconfiguration|
|*ASVS 3.0.1 requirement:*  19.1|
|*Recommendation:* Remove the application server components that are not used.|

*Recommendations*

We recommend removing the Tomcat application server’s default applications.

 

_For the original finding files please see XP-2460._",,ek176,iO924,jy268,ll664,radeale,yo218,,,,,,,,,,,,,,,,,,,,,XP-2499,,,,,,,,,,,,,,,,"07/Jan/20 14:26;radeale;image-2020-01-07-14-26-07-233.png;https://jira.deutsche-boerse.com/secure/attachment/78972/image-2020-01-07-14-26-07-233.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22377600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a27c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/20 14:44;ll664;Default Tomcat webapps should be removed.","23/Jan/20 13:53;iO924;https://vmt.deutsche-boerse.de/browse/PT-1560","19/Mar/20 08:30;ek176;Verify if not vuln to directory traversal attack.","05/Jun/20 15:16;jy268;Please fix the same way as https://jira.deutsche-boerse.com/browse/XP-2485","08/Jun/20 09:30;yo218;Issue will be fixed with ansible migration. Can we wait for it or do I have to update all available tomcat packages? Maybe someone could try to update the perl script instead and exclude the directories?","08/Jun/20 10:08;jy268;[~yo218] Can't we use rewrite engine mechanism you have proposed in XP-2485 in the meantime?","08/Jun/20 10:12;yo218;Those changes are already in place (in dev branch) and it block accessing the default page using the traversal thing. But the default applications are still there, even if they are not accessible anymore (at least not in this way)","08/Jun/20 11:06;jy268;So I believe that as for now it can be closed? Doesn't it? If application is not reachable pentesters can't find this vulnerability.","08/Jun/20 11:14;yo218;Well, depends on what is the DoD of this ticket? Following the recommendation like ""removing the Tomcat application server’s default applications"" or ""make sure that Pentesters are not able to access the default pages"" :) 

But anyway, I would close it as well as the default pages will vanish with ansible anyway, so no need to spend additional effort here",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V7 – Server status pages reveal information,XP-2477,90788,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,radeale,radeale,07/Jan/20 14:08,11/Aug/20 16:35,22/Feb/21 13:26,09/Jun/20 14:55,,,3.1.0,,Capacity,,,,,PenetrationTest,TechOps,,,"h2. Information disclosure – Server status pages

Generally, the term information disclosure refers to the disclosure of sensitive data. Sensitive information is unnecessarily revealed quite often. The disclosure itself is sometimes not a threat and does not have to be rated as security-related. However, an attacker might use apparently harmless information for planning attacks if he combines it with further information or other vulnerabilities.

It has been found that two available URLs can be used to retrieve additional information from the servers. Here it is possible to see the status as well as the build version used.

Sample URLs:
|https://cmm-simu1.xbid.deutsche-boerse.com/cmm/info
 [https://cmm-simu1.xbid.deutsche-boerse.com/cmm/health]|

The following snippet shows the request and response when using the URL [https://cmm-simu1.xbid.deutsche-boerse.com/cmm/info:]
|csaudit@DESKTOP-D2DHCRC:~$ curl -k --proxy [http://127.0.0.1:8080|http://127.0.0.1:8080/] [https://cmm-simu2.xbid.deutsche-boerse.com/cmm/info]
 *{color:#de350b}{""build"":\\{""version"":""2.0.25.5""}}{color}*|

*Threat*

An attacker can gain information on the build version used.
|Vulnerability:|*P2-V7* – Server status pages reveal information| |
|*Threat:* Information disclosure|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 4.3|
|Attack vector:
 Network|Confidentiality impact:
 Low|
|Attack complexity:
 Low|Integrity impact:
 None|
|Privileges required:
 Low|Availability impact:
 None|
|User interaction:
 None|Scope:
 Unchanged|
|*Score:* 2.8|*Score:* 1.4|
|*Attacker profile:* Script kiddie|
|*Location:* Application server configuration|
|*OWASP Top Ten:* Others|
|*ASVS 3.0.1 requirement:* 8.1|
|*Recommendation:* Disable status pages.|

*Recommendations*

We recommend disabling these status pages if not needed.

For the original finding files please see XP-2460.",,ek176,iO924,jy268,qo794,radeale,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22204800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a26w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jan/20 13:52;qo794;The access to the end-points in question can be denied for users in Apache configuration, but we still need to have access to them for internal monitoring systems.","23/Jan/20 13:52;iO924;https://vmt.deutsche-boerse.de/browse/PT-1558","04/Jun/20 12:44;jy268;Hi [~yo218] I agree with solution proposed by Kamil, could you please investigate this issue and let [~ei349] know if it is doable or should be added to exceptions list? Maybe it will be easier to restrict access to health and info from the outside?","04/Jun/20 18:25;yo218;the solution would be quite easy. Example for SOB:
{noformat}
<Location /*/info>
        Order allow,deny
</Location>
<Location /*/health>
        Order allow,deny
        Allow from 10.139.54.203/32
</Location>
{noformat}
As far as I know, having the health url available for apache is required by alarmtilt only. Monitoring tools are checking the health URL on the hosts itself, not on the webservers. Same for the version collector in regards to the /info page. [~qo794] or [~jy268] do you have any other parts in mind which would require that /info or /health are available via apaches?","05/Jun/20 08:40;qo794;I don't know about any other tool/system/module requiring access to the health and info end-points.

I believe there should rather be ""Allow from 127.0.0.1"", right?","05/Jun/20 12:25;yo218;I pushed the changes to xbid-dev-env branch. Feel free to deploy in all internal environments

 ","08/Jun/20 08:33;qo794;* the new apache configuration deployed on Syt1, tested on CMM https://10.136.142.19:60701/cmm/health, result:
{quote}
Forbidden
You don't have permission to access /cmm/health on this server.
{quote}
* the old apache configuration tested on Syt2 https://10.136.142.20:60801/cmm/health, result:
{quote}
\{""status"":""UP""\}
{quote}

Test successful (/)","08/Jun/20 10:37;qo794;[~yo218] please prepare a pull request to master branch and add it as a comment into SERVICE-3669, thanks","09/Jun/20 14:54;yo218;done. 

PR for single sided environments: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/676]

PR for double sided environments: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/677]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V6 – Lacking file type validation for the upload of XML files,XP-2476,90787,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,radeale,radeale,07/Jan/20 14:00,11/Aug/20 16:36,22/Feb/21 13:26,08/Jun/20 16:18,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h2. File upload vulnerabilities - Lacking file type validation regarding file content

The application allows users to upload XML files which are then processed by the XML parser. The assessment revealed that these files are not validated properly. For example, it is not validated if file extensions match the actual file type and its content. This allows an attacker to generate error messages which reveal further information about the environment.

During the assessment, many renamed files were successfully uploaded as xml files. To be precise, some PDF files, text files and XML bombs have been used and could successfully be uploaded. This proves that there has been no validation if file extensions match file content (e.g. by using so-called “magic bytes”).

The following snippet shows an exemplary error message when uploading an invalid file:
|>Invalid value : File was not recognized: {color:#de350b}*JAXB unmarshalling exception; nested exception is javax.xml.bind.UnmarshalException<br*{color}
 {color:#de350b}*> - with linked exception:<br*{color}
 {color:#de350b}*>[com.sun.org.apache.xerces.internal.impl.io.MalformedByteSequenceException*{color}
 […]|

The security assessment included many more tests, which were not successful except for the disclosure of information. It should be noted that this circumstance may change in the future depending on the attack and the time required, so that future vulnerabilities cannot be completely ruled out.

*Threat*

An attacker is able to get further information about the environment by uploading files that are not accepted by the system.
|Vulnerability:|*P2-V6* – Lacking file type validation for the upload of XML files| |
|*Threat:* Information disclosure, Upload of files with malicious content|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 5.0|
|Attack vector:
 Network|Confidentiality impact:
 Low|
|Attack complexity:
 Low|Integrity impact:
 None|
|Privileges required:
 Low|Availability impact:
 None|
|User interaction:
 None|Scope:
 Changed|
|*Score:* 3.1|*Score:* 1.4|
|*Attacker profile:* Script kiddie|
|*Location:* Web application, upload of XML files|
|*OWASP Top Ten:* Others|
|*ASVS 3.0.1 requirement:* 16.3|
|*Recommendation:* Implement file type validation.|

*Recommendations*

In addition to the existing checks, the file type should be checked against the file extension by validating the “magic bytes”.

If one of these validations fails, the upload should be denied, and possible temporary copies of the file should be deleted.

For the original finding files please see XP-2460.",,ek176,hj444,iO924,ll664,od044,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Apr/20 13:09;tr866;50MB Upload File - screenshot-2020.04.23-12_18_18.png;https://jira.deutsche-boerse.com/secure/attachment/82961/50MB+Upload+File+-+screenshot-2020.04.23-12_18_18.png","28/Apr/20 10:11;hj444;XP-297_SHC,SHS Files_CR ID 18.xlsx;https://jira.deutsche-boerse.com/secure/attachment/83107/XP-297_SHC%2CSHS+Files_CR+ID+18.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22291200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s000000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),Alpha Sprint 6,Alpha Sprint 7 (S),HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,acceptance,develop,XP-2476-change-label-to-universal-one,master-acceptance,master,XP-2476,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Jan/20 14:37;ll664;To me, the only problem is that we disclose JAXB error message, this should be fixed. Otherwise application works fine. Even the fact that it does not look at the file extensions should not be considered as an issue - as long as input file forms a valid XML, the extension is irrelevant.","23/Jan/20 13:51;iO924;https://vmt.deutsche-boerse.de/browse/PT-1557","19/Mar/20 08:25;ek176;1) Not checking for extension might allow to store malicious .pdf/.exe/.js/.scr/autorun files on the system. These can be further exploited (renamed, copied, linked; exploited ToCTToU attacks), or might present a problem for person downloading it to his/her PC.

2a) XML validation/processing might lead to DoS (XML bombs).

2b) Check for XXE vulnerability.

3) Verify the max-size policy for the upload.

 ","22/Apr/20 08:53;ll664;Discussed with [~ek176], we decided to:

* not disclose the JAXB Exception messages when uploading invalid files
* magic bytes are checked already by JAXB parser
* *not* implement extension validation - this is a functional change that may have impact in customer systems. Needs specification update etc. The benefit is questionable since we store only validated XMLs in the DB, hence the attack vectors from the finding does not apply.

I've also checked for the rest of vulnerabilities mentioned by Mira:

XML Bombs/XEE - rejected by default by JAXB parser.
Max file uploads - limited to 10MB.

Generally, I'd like to point on poor quality of finding report here. 

{quote}
To be precise, some PDF files, text files and XML bombs have been used and could successfully be uploaded. This proves that there has been no validation if file extensions match file content (e.g. by using so-called “magic bytes”).
{quote}

This is simply false statement, such a files are rejected by the system. Even if it was true, I would expect the file that could be uploaded to be attached with more detailed reproduction steps.","24/Apr/20 11:27;hj444;tested SY2

h4. Upload files
TSO Admin : Upload files CBS/NTS

#   with not in xml structure and extension <> xml (like png, txt. xls,...) : Validation message appears : {color:blue} _Invalid value : File was not recognized: File is not valid XML_ {color}
#   with xml structure and extension .xml : files are successfully uploaded
#   xml file structure with other extension like .csv, .txt files successfully uploaded
#   file >10MB : navigate us at the page
    !50MB Upload File - screenshot-2020.04.23-12_18_18.png!
#  bombs : Invalid value : File was not recognized: File is not valid XML

h4. Import files 
  #  Import files <> xml - *not consistent validation messages:*
-- xls file: Validation message : {color:red}System Error. null{color}
--  txt file: {color:blue}Invalid value : \\res07\ndrive\hj444.OAAD\XBID_new\Automation_regression\reg_models.txt is not importable{color}
-- png file : {color:blue}Invalid value : \\res07\ndrive\hj444.OAAD\Pictures\save1.png is not importable {color}
 

-- *for import by the specification csv file and xml file are valid formats for BG request file*
","28/Apr/20 10:40;hj444;Import files - retest - I was not able to repro the System Error. null validation message.
Also for xml files I got a validation : Invalid value : \\res07\ndrive\hj444.OAAD\XBID_new\XP-297_SHC,SHS Files_CR ID 18.xlsx is not importable
Logs verified too.

I close this jira.","03/Jun/20 15:30;tm431;Please just change the wording of the error message to the text in external tickets last comment.","08/Jun/20 16:17;od044;Test passed on XBID 2.0.41
- validation error message has been changed in case file are invalid and application cannot parsed it
{code}
Invalid value : File was not recognized: XSD Validation Failure - check your input against agreed XSD document
{code}
- verified with file type xlxs, png, cvs 
- smoke tested it on CBS, CAS and NTC file transfer configuration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V4 – Insufficient verification of user input during password change,XP-2474,90783,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,07/Jan/20 13:44,31/Aug/20 13:21,22/Feb/21 13:26,28/Aug/20 13:52,,,3.1.1,,Capacity,,,,,PenetrationTest,,,,"h2. Password with overlength

A user can change his password at the URL [https://cmm-simu1.xbid.deutsche-boerse.com/cmm/pages/allocation/overview.faces] . The server itself does not check whether the length of the data entered can be processed by the server during login. As a result, a password with 9,604 characters was used during the security assessment.

When trying to log in later, the length of the password resulted in the following error message telling the user that the server cannot understand such long requests:

!image-2020-01-07-13-52-49-213.png!

Error message because header exceeds server limit

*Threat*

The possibility of preventing the login to a user account by means of a password with overlength indicates that the server does not fully check the user’s input before processing it.
|Vulnerability:|*P2-V1* – Insufficient verification of user input during password change| |
|*Threat:* Denial of service of the user’s own account|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 4.3|
|Attack vector:
 Network|Confidentiality impact:
 None|
|Attack complexity:
 Low|Integrity impact:
 None|
|Privileges required:
 Low|Availability impact:
 Low|
|User interaction:
 None|Scope:
 Unchanged|
|*Score:* 2.8|*Score:* 1.4|
|*Attacker profile:* Script kiddie|
|*Location:* Web application|
|*OWASP Top Ten:* Others|
|*ASVS 3.0.1 requirement:* not relevant|
|*Recommendation:* Check the length before accepting the password.|

*Recommendations*

We recommend checking the length of the password entered by the user on the server side before adopting it. If the user chooses a password that is too long, the server should reject it, if necessary.

For the original finding files please see XP-2460.",,ei349,ek176,iO924,jy268,od044,qo794,radeale,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/20 13:52;radeale;image-2020-01-07-13-52-49-213.png;https://jira.deutsche-boerse.com/secure/attachment/78968/image-2020-01-07-13-52-49-213.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bbbp:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,XP-3443-rounding,why-optional,cpm,XP-3829-routing-integration,acceptance,ramping-analysis,develop,XP-3520-ramping_analysis,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jan/20 13:36;qo794;Easy to fix","23/Jan/20 13:50;iO924;https://vmt.deutsche-boerse.de/browse/PT-1555","04/Jun/20 12:04;jy268;I suggest add maxLength constraint on this field in the application limiting length to 64 characters. [~ub113] could you please discuss it with customer as it impacts application behavior?","07/Aug/20 11:21;ub113;Communicated in XBID-5194 ","19/Aug/20 14:37;ei349;Approved for R3.1.1","27/Aug/20 17:33;od044;Test passed on SYT1 XBID 3.1.4
- password field is limited to 64 characters 
- verified on CMM, CMI, SOB
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
P2-V3 – Insufficient password policy,XP-2473,90782,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,radeale,radeale,07/Jan/20 13:38,28/Aug/20 13:51,22/Feb/21 13:26,28/Aug/20 13:51,,,3.1.1,,Capacity,,,,,PenetrationTest,TechOps,,,"h2. Insufficient password policy

Users can change their password using a function in the CMM application via the exemplary URL [https://cmm-simu1.xbid.deutsche-boerse.com/cmm/pages/allocation/overview.faces].

Even though a password policy obviously exists, it only forces the user to choose a password with at least 8 characters. This can also be seen from the following screenshot:

!image-2020-01-07-13-39-16-452.png!
  
 Even though the usage of rather complex passwords with 1 uppercase letter, 1 lowercase letter and a special character is enforced, the length of the password is not sufficient anymore.

*Threat*

The existing password policy allows users to choose short passwords. Passwords with a length of only 8 characters can no longer be considered as sufficiently secure today. Although the CMM application implements a protective mechanism against brute force attacks, guessing correct passwords is made easier due to the rather poor password policy.

If an attacker has a valid password as well as a valid certificate, a related username, he will have access to the application with the appropriate privileges of the account.
|Vulnerability:|*P2-V3* – Insufficient password policy| |
|*Threat:* Unauthorized access by guessing trivial passwords|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Severe|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 6.5|
|Attack vector:
 Network|Confidentiality impact:
 High|
|Attack complexity:
 Low|Integrity impact:
 None|
|Privileges required:
 Low|Availability impact:
 None|
|User interaction:
 None|Scope:
 Unchanged|
|*Score:* 2.8|*Score:* 3.6|
|*Attacker profile:* Script kiddie|
|*Location:* Web application|
|*OWASP Top Ten:* A2 - Broken Authentication|
|*ASVS 3.0.1 requirement:* 2.27|
|*Recommendation:* Implement a strong password policy.|

*Recommendations*

A strong password policy should be implemented in the application. We recommend keeping the requirements on the password configurable to be able to adapt the password policy without having to modify the code at a later time.

Today, passwords with a length of at least 12 characters are considered secure. In addition, users should be prevented from choosing passwords that contain generic or context-specific keywords (e.g. “password”), or similar known compromised passwords.

A list of hashes of known compromised passwords is offered by various online services, e.g. the “Have I been pwned?”[[1]|#_ftn1] platform.

 [[1]|#_ftnref1] [https://haveibeenpwned.com/Passwords]

For the original finding files please see XP-2460.",,ei349,ek176,iO924,jy268,ll664,od044,qo794,tm431,ub113,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/20 13:39;radeale;image-2020-01-07-13-39-16-452.png;https://jira.deutsche-boerse.com/secure/attachment/78966/image-2020-01-07-13-39-16-452.png","27/Aug/20 17:06;od044;sm-min-12chars.png;https://jira.deutsche-boerse.com/secure/attachment/86803/sm-min-12chars.png","27/Aug/20 17:06;od044;sob-min-12chars.png;https://jira.deutsche-boerse.com/secure/attachment/86804/sob-min-12chars.png",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0b2dj:x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),HOT Sprint 15,HOT Sprint 16 (S),,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,acceptance,develop,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jan/20 13:33;qo794;The password policy is defined in LDAP with the following rules (production, might differ on some environments):
{code:title=USM700 Password Regime Document}
•	Personal passwords of end users have to be changed every 90 days.
If the password has expired, the user must request a password reset from his central admin.
A password shall be changed immediately if its owner suspects the password to be disclosed to unauthorized persons or malicious software.
•	Passwords have to be at least 8 characters long
•	At least one character from each of the following 4 categories has to be used: numeric characters (0-9), uppercase letters (A-Z), lowercase letters (a-z), special characters ($%&,.;:?=!)
•	A password has to differ from the last 5 used passwords of that user account
•	It is recommended to avoid using the same password as for other applications
{code}
","20/Jan/20 13:55;ll664;Since this finding is only for CMM I just wonder if we have different policies per LDAP tree. 

Anyway, this should be easy to fix, we just need to agree when/how to rollout to production.","20/Jan/20 16:00;qo794;I believe the finding is from SIMU where the configuration might differ from what we have on production. The same finding must be present also for SOB, but the penetration test was probably done by someone else, hence not revealed. ","23/Jan/20 13:49;iO924;https://vmt.deutsche-boerse.de/browse/PT-1554","04/Jun/20 10:12;jy268;I suggest changing min password length to 12 characters as described in this ticket. It requires two steps:
1. Currently validation in the application is hardcoded that allows 8 characters only. It will be changed.
2. LDAP policy has to be updated by techops team to reflect minimum length of 12 characters.","04/Jun/20 10:33;jy268;[~ub113]please communicate with the client","07/Aug/20 11:20;ub113;Communicated in XBID-5195 ","07/Aug/20 11:22;ub113;Communicated in XBID-5195","19/Aug/20 14:36;ei349;Approved for R3.1.1 to Simu","24/Aug/20 07:47;tm431;Couple of thinks to consider:
 1) will there be any migration of old PWDs? what will be the procedure? Or sill old short PWDs will work?
 2) What will be then the default PWD for testing envs?
 3) PWD Jenkyns reset job must be amended, please note that this functionality will be roled only for SIMU, and then to CUTEPX, this must be taken in account!
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/XBID%20Customer%20LDAP/
 4) What about technical LDAP users pwds lenght? This will change as well? Analyzes for this must be done upfront, so e.g. customers can reset their PWDs
 5) Other internal users will be affected? e.g. User for Reporting engine? (to log into RE cron page)","25/Aug/20 14:10;qo794;1) no migration possible and I think not needed since the new rules should affect only new passwords not existing
4) technical users without pwd expiration will not be affected, see point 1
5) the user for accessing RE cron page is not defined in LDAP, hence not affected","25/Aug/20 14:13;qo794;Additional findings:
* pwd policy definition is shared for all test envs, meaning there is only one ""record"" for our SYT envs and customers envs
* pwd policy for testing envs is not properly defined for SM LDAP tree","27/Aug/20 11:59;qo794;GUI changes implemented - the minimum pwd length set to 12 in CMM and SOB, SPM does not have validation on GUI level.","27/Aug/20 16:45;yo218;Created a new temporary policy called nsPWPolicyEntryNew which expects 12 characters. Applied it to SADMIN02 and SPMADM01","27/Aug/20 17:08;od044;Test on XBID 3.1.4 on SYT1
- new policy of min 12 character works 
!sm-min-12chars.png!  
!sob-min-12chars.png!  

- the change of policy does not affect an old password 
- SM does not have max length limitation",,,,,,,,,,,,,,,,,,,,,,,
P2-V2 - TLS client certificates not bound to user,XP-2472,90775,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,radeale,radeale,07/Jan/20 11:33,31/Aug/20 15:39,22/Feb/21 13:26,04/Jun/20 08:54,,,3.1.0,,Capacity,,,,,PenetrationTest,,,,"h2. TLS client certificates not bound to user

To access the CMM application it is necessary to have a valid client certificate as well as a valid combination of username and password. However, the certificates are not bound to user accounts on the server side. Therefore, any valid client certificate can be used to login to arbitrary user accounts (the corresponding username and password are still required). So overall the client certificate does not serve its purpose as a second factor.

*Threat*

This procedure makes it easier for an attacker to successfully launch an attack because he only needs to have a valid client certificate. If the attacker has a certificate, he can use it to attack valid combinations of username and password for every other user in the system.

*Recommendations*

During the login the server should verify that the username inside the TLS client certificate matches the requested account's username.
|Vulnerability:|*P2-V2*- TLS client certificates not bound to user| |
|*Threat:* Bypassing the TLS certificate as a second factor|
|*Threat Exposure:* Internet DMZ|*Threat Level:* Noticeable|
|CVSS3:|Exploitability:|Impact:|*Base Score:*
 4.8|
|Attack vector:
 Network|Confidentiality impact:
 Low|
|Attack complexity:
 High|Integrity impact:
 Low|
|Privileges required:
 None|Availability impact:
 None|
|User interaction:
 None|Scope:
 Unchanged|
|*Score:* 2.2|*Score:* 2.5|
|*Attacker profile:* Expert|
|*Location: Web application*|
|*OWASP Top Ten:* A2 - Broken Authentication|
|*ASVS 3.0.1 requirement:* not relevant|
|*Recommendation:* Verify that the certificate belongs to the requested account during login.|

For the original finding files please see XP-2460.",,ek176,iO924,jy268,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,XP-2518,XP-2498,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22723200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0t:s0002",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 10 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/20 13:24;qo794;Already implemented in
{code}
com.deutscheboerse.energy.m7.security.X509CustomFilter
{code}
but the validation is enabled only on production ({{x509.filter.enabled}}) since no other envs require certificates to log in into modules.","23/Jan/20 13:49;iO924;https://vmt.deutsche-boerse.de/browse/PT-1553","04/Jun/20 08:01;jy268;I confirm, already implemented in
{code}
com.deutscheboerse.energy.m7.security.X509CustomFilter
{code}
enabled on production, but disabled on any other environment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Zero in Maximum number of borders (interconnectors),XP-2450,90717,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,qo794,qo794,06/Jan/20 13:56,13/Aug/20 19:40,22/Feb/21 13:26,23/Jan/20 08:08,,,3.1.0,,SLA Report Tool,,,,,,,,,"""XBID Service Boundary"" report for December 2019 (see XP-2445) contains 0 in the ""Maximum number of borders (interconnectors)"" field the topology sheet. Investigate and fix.

h2. Root cause
An invalid SQL query for collecting a number of current interconnector, a deleted IC complete breaks the query and leads to 0.

h2. Steps to reproduce
# delete an interconnector
# execute SLA data collection (see {{--actions=sla-collect}} parameter in README.md in the source code) or wait till it's executed automatically ({{collect.boundary.sla.cron}} in application.properties)
# check the last value in {{computed_total}} table in SLA DB for {{sla_type = MAX_INTERCONNECTORS}}, it should reflect the number of IC in the system, the deleted IC should not be included in the number. It was 0 instead (x)",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35596800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,06/Jan/20 13:56,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220082c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbidsimucor1 - Permission denied when trying to view app logs,XP-2449,90715,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ei349,ei349,06/Jan/20 13:40,04/Aug/20 19:53,22/Feb/21 13:26,19/Mar/20 09:14,,,3.1.0,,,,,,,,,,,"In the TECHLOG-2407 is written from [~pd122] that:
{panel:title=Urban Grena added a comment - 13/Jun/19 14:31}
sudo to technical user on prod-like environments is currently not allowed, please try to use Kibana instead. 
{panel}
Please remove this limitation to allow developers access to xbidsimucor1 logs from cyberark. ",,ei349,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29376000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,06/Jan/20 13:40,,,,,,,,,,,,,,,,,,,,,,,"1|y0a9h9:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 3,HOT Sprint 4 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 15:56;yo218;sudo to technical user won't be possible but the logs can be made world readable","06/Mar/20 11:24;yo218;[https://stackoverflow.com/questions/41975808/set-umask-for-tomcat8-via-tomcat-service]
{noformat}
Try adding UMASK as Environment variable into tomcat's service file:[Service]
...
Environment='UMASK=0022'
... {noformat}
{{}}","19/Mar/20 09:14;yo218;During test we found out that the mentioned templates are not used at all. The actual change for the start.sh was done in the deployment script scripts/energy_deploy_pmi.pl:
{noformat}
# Create the Tomcat start script 
my $tomcat_startscript = ""#!/bin/bash\n""
. ""export CATALINA_PID="" . $instance_base_dir . ""/"" . $instance_name . ""/tomcat/pid\n""   . ""export CATALINA_OPTS=\"""" . $tomcat_catalina_opts . ""\""\n"" 
. ""export CATALINA_TMPDIR=\""/tmp\""\n"" 
. ""export UMASK=\""0022\""\n"" 
. $instance_base_dir . ""/"" . $instance_name . ""/tomcat/bin/startup.sh\n""; write_content_to_file( $working_dir . ""/bin/start.sh"", $tomcat_startscript, ""750"" );{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Alter performance pipeline to generate report as artifact,XP-2448,90714,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,eh941,eh941,06/Jan/20 13:39,04/Aug/20 19:53,22/Feb/21 13:26,20/Jan/20 09:42,,,3.1.0,,,,,,,,,,,"Performance pipeline should be changed in order to:
 - use report tool to collect data from elastic
 - generate internal report
 - result report publish as job's artifact

 

Please provide demo on review to the team at the end. ",,eh941,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34646400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220082g",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jan/20 14:32;jy268;Please review performance-test-report-generate in xbid-pipeline . Jenkinsfile is present in current develop branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool - make generated report always consistent - valid report or error thrown,XP-2447,90682,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eh941,eh941,03/Jan/20 14:52,04/Aug/20 19:53,22/Feb/21 13:26,27/Mar/20 15:25,,,3.1.0,,SLA Report Tool,,,,,,,,,"Right now the data's journey from source database to XML or Excel file is divided into multiple steps and each of the following steps rely on success of the previous one.

E.g.
Collect data from elastic -> transform it into local DB table (like computed_total) -> generate Excel report

If the very first step keeps failing the final report is empty (or contain zeros only) and the middle step contains zero which must be deleted manually in order to get the valid report.

My suggestion is to repeat the previous step before the current step. Using this approach the middle table (like computed_total) will always contain only valid data and no empty report will be generated.",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35856000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,03/Jan/20 14:52,,,,,,,,,,,,,,,,,,,,,,,"1|y0a99g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 3 (S),Alpha Sprint 4,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2447-2,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool - Bid-ask spread is always collected using joins to history tables,XP-2446,90681,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eh941,eh941,03/Jan/20 14:45,04/Aug/20 19:53,22/Feb/21 13:26,20/Jan/20 15:59,,,3.1.0,,SLA Report Tool,,,,,,,,,"This code doesn't work as expected:

{code:java}               .from(bidAskSpreadContainsContractTypeStep).on(ExitStatus.NOOP.exitCode).to(checkIfBiddingZoneIsInSchema).next(generateBidAskSpreadReportStep).next(markBidAskSpreadReportAsGenerated)
                //if there is, take it from bid_ask_spread table
                .from(bidAskSpreadContainsContractTypeStep).on(ExitStatus.COMPLETED.exitCode).to(checkIfBiddingZoneIsInSchema).next(generateBidAskSpreadReportWithoutContractHistoryJoinStep).next(markBidAskSpreadReportAsGenerated)
{code}

Even though the {{bidAskSpreadContainsContractTypeStep}} exits with code completed {{generateBidAskSpreadReportStep}} is used.

Here's CLI steps for a job that should be collected by  {{generateBidAskSpreadReportWithoutContractHistoryJoinStep}}

{noformat}
shell:>steps 2473
╔═══════════════════════════════════════════════╤══════════════════════════════╤══════════════════════════════╤═══════════╤═══════════╤══════╤══════════╤═════════╤══════════════╤═══════════════╤═════════════════╤═════════════╤═══════════╤══════════════╗
║ Step Name                                     │ Start Time                   │ End Time                     │ Status    │ Committed │ Read │ Filtered │ Written │ Read Skipped │ Write Skipped │ Process Skipped │ Rolled-back │ Exit Code │ Exit Message ║
╠═══════════════════════════════════════════════╪══════════════════════════════╪══════════════════════════════╪═══════════╪═══════════╪══════╪══════════╪═════════╪══════════════╪═══════════════╪═════════════════╪═════════════╪═══════════╪══════════════╣
║ retrieve-last-generated-month                 │ Fri Jan 03 13:47:01 CET 2020 │ Fri Jan 03 13:47:01 CET 2020 │ COMPLETED │ 1         │ 0    │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟───────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼──────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ bid-ask-spread-contains-contract-type         │ Fri Jan 03 13:47:01 CET 2020 │ Fri Jan 03 13:47:01 CET 2020 │ COMPLETED │ 1         │ 0    │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟───────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼──────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ check-if-bidding-zone-is-used                 │ Fri Jan 03 13:47:01 CET 2020 │ Fri Jan 03 13:47:01 CET 2020 │ COMPLETED │ 1         │ 0    │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟───────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼──────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ generate-bid-ask-spread-report                │ Fri Jan 03 13:47:01 CET 2020 │ Fri Jan 03 13:47:02 CET 2020 │ COMPLETED │ 1         │ 0    │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟───────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼──────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ mark-bid-ask-spread-report-month-as-generated │ Fri Jan 03 13:47:02 CET 2020 │ Fri Jan 03 13:47:02 CET 2020 │ COMPLETED │ 1         │ 0    │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╚═══════════════════════════════════════════════╧══════════════════════════════╧══════════════════════════════╧═══════════╧═══════════╧══════╧══════════╧═════════╧══════════════╧═══════════════╧═════════════════╧═════════════╧═══════════╧══════════════╝

{noformat}

With the commented out:

{code:java}
                //if there is not, calculate contract_type from contract_history
//                .from(bidAskSpreadContainsContractTypeStep).on(ExitStatus.NOOP.exitCode).to(checkIfBiddingZoneIsInSchema).next(generateBidAskSpreadReportStep).next(markBidAskSpreadReportAsGenerated)
                //if there is, take it from bid_ask_spread table
                .from(bidAskSpreadContainsContractTypeStep).on(ExitStatus.COMPLETED.exitCode).to(checkIfBiddingZoneIsInSchema).next(generateBidAskSpreadReportWithoutContractHistoryJoinStep).next(markBidAskSpreadReportAsGenerated)
{code}

{noformat}
shell:>steps 2480
╔══════════════════════════════════════════════════════════════╤══════════════════════════════╤══════════════════════════════╤═══════════╤═══════════╤═══════╤══════════╤═════════╤══════════════╤═══════════════╤═════════════════╤═════════════╤═══════════╤══════════════╗
║ Step Name                                                    │ Start Time                   │ End Time                     │ Status    │ Committed │ Read  │ Filtered │ Written │ Read Skipped │ Write Skipped │ Process Skipped │ Rolled-back │ Exit Code │ Exit Message ║
╠══════════════════════════════════════════════════════════════╪══════════════════════════════╪══════════════════════════════╪═══════════╪═══════════╪═══════╪══════════╪═════════╪══════════════╪═══════════════╪═════════════════╪═════════════╪═══════════╪══════════════╣
║ retrieve-last-generated-month                                │ Fri Jan 03 14:17:18 CET 2020 │ Fri Jan 03 14:17:18 CET 2020 │ COMPLETED │ 1         │ 0     │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟──────────────────────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼───────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ bid-ask-spread-contains-contract-type                        │ Fri Jan 03 14:17:18 CET 2020 │ Fri Jan 03 14:17:18 CET 2020 │ COMPLETED │ 1         │ 0     │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟──────────────────────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼───────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ check-if-bidding-zone-is-used                                │ Fri Jan 03 14:17:18 CET 2020 │ Fri Jan 03 14:17:18 CET 2020 │ COMPLETED │ 1         │ 0     │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟──────────────────────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼───────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ generate-bid-ask-spread-report-without-contract-history-join │ Fri Jan 03 14:17:18 CET 2020 │ Fri Jan 03 14:17:19 CET 2020 │ COMPLETED │ 1         │ 25660 │ 0        │ 25660   │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╟──────────────────────────────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────┼───────────┼───────┼──────────┼─────────┼──────────────┼───────────────┼─────────────────┼─────────────┼───────────┼──────────────╢
║ mark-bid-ask-spread-report-month-as-generated                │ Fri Jan 03 14:17:19 CET 2020 │ Fri Jan 03 14:17:19 CET 2020 │ COMPLETED │ 1         │ 0     │ 0        │ 0       │ 0            │ 0             │ 0               │ 0           │ COMPLETED │ []           ║
╚══════════════════════════════════════════════════════════════╧══════════════════════════════╧══════════════════════════════╧═══════════╧═══════════╧═══════╧══════════╧═════════╧══════════════╧═══════════════╧═════════════════╧═════════════╧═══════════╧══════════════╝


{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35856000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,03/Jan/20 14:45,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA Reports - December 2019 - Validate and send to ACM for further publication,XP-2445,90669,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,zi174,ei349,ei349,02/Jan/20 14:43,13/Aug/20 19:45,22/Feb/21 13:26,13/Jan/20 12:53,,,3.1.0,,,,,,,,,,,,,ei349,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2450,,,,,,,"02/Jan/20 15:24;qo794;XBID Performance and SM SLA Reporting December 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78877/XBID+Performance+and+SM+SLA+Reporting+December+2019.xlsx","02/Jan/20 15:24;qo794;XBID Service Boundary Reporting December 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78878/XBID+Service+Boundary+Reporting+December+2019.xlsx","02/Jan/20 15:24;qo794;XBID_Credit_points_report_December_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78876/XBID_Credit_points_report_December_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35942400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,02/Jan/20 14:43,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220082a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jan/20 15:27;qo794;All 3 reports were successfully generated on SLA2 PROD server without any error:
*  [^XBID Performance and SM SLA Reporting December 2019.xlsx] 
*  [^XBID Service Boundary Reporting December 2019.xlsx] 
*  [^XBID_Credit_points_report_December_2019.xlsx] 

As XP-2413 has still not been tested (hence not released and deployed on the production) it is necessary to manually replace DEGRADED to RTS3B in the Credit points report. [~zi174] please do that and also validate the reports. Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increased SM generation time percentile,XP-2443,90598,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,23/Dec/19 10:59,06/Nov/20 10:41,22/Feb/21 13:26,30/Dec/19 09:32,,,XBID 2.0,,Shipping,,,,,,,,,"As a side effect of XP-2404, the shipping module genearation time (98-th percentile in the SLA perf reports) worsened in November. See attached plots.

 

Note that the reason for increase in Oct (XBID 1.x) the suspect is the SAN disk performance (unsure, see XP-2404).

 

We should be ready when customer asks.

 

The plots are generated from the SLA reports (XLS).",,ek176,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Dec/19 10:59;ek176;SLA_SM_files_gen_time_98_0_percentile.png;https://jira.deutsche-boerse.com/secure/attachment/78839/SLA_SM_files_gen_time_98_0_percentile.png","23/Dec/19 10:59;ek176;SLA_SM_files_gen_time_boxplots.png;https://jira.deutsche-boerse.com/secure/attachment/78838/SLA_SM_files_gen_time_boxplots.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,irrelevant,,,,,,,,,,,,,,36288000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a14g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Dec/19 09:23;jy268;After 2.0 we have introduced new parties with new TCs, due to that we are generating more files which impacts SP files generation time. In my opinion everything is as expected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increased no of FAILED perf-sender events in CORE,XP-2442,90597,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ek176,ek176,23/Dec/19 10:55,04/Aug/20 19:53,22/Feb/21 13:26,16/Jan/20 15:50,,,3.1.0,XBID 2.0,Trading,,,,,,,,,"As a side effect of XP-2404, it has been discovered a higher number of 'Failed' events after go-live of XBID 2.0 (using {{zcat *.gz |grep "" INFO  perf-sender "" | grep -e "",O:N,F$"" |wc -l}} ): 

 

{{2019-10-02:  980}}
 {{2019-11-13: 5457}}

 

See also the graph attached (the values are not aggregated, just plotted). The Y-axis shows the event's list of orders. Source: CORE prod log files.",,ek176,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Dec/19 10:55;ek176;perf-send_events_failed_events_not_aggregated_2019-09-14_2019-11-14.png;https://jira.deutsche-boerse.com/secure/attachment/78837/perf-send_events_failed_events_not_aggregated_2019-09-14_2019-11-14.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,34732800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a458:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/20 15:48;lt112;From the November logs It appears that user {{EPQINC01}} attempted to send around 25 000 {{AllocationReq}} requests receiving {{SERVICE_IN_HALT}}. No more significant errors found.

See data below (I had to do 2 runs, as I ran out of space during the first). There may be some duplicate data due to that, but not significant.
#1
{noformat}
=========================================== ERRORS =========================================================:
OrdrModify-None: 247
LoginPrivateReq-trader_already_logged_in: 225
None-None: 93
None-DUPLICATE_AUTOPUBLISH_ATTEMPT: 50
None-SERVICE_IN_HALT: 8750
AllocationReq xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" type=""IOC""-DELIVERY_INTERVAL_DISABLED: 1
None-REF_DATA_USER_ERR_CANNOT_DELETE: 1
None-REF_DATA_USER_ERR_ALREADY_EXISTING_USER_CODE: 4
None-REF_DATA_INVALID_CONFIG_START_DATE: 1
AllocationReq-SERVICE_IN_HALT: 15840
ContractInfoReq-DELIVERY_INTERVAL_DISABLED: 1
ModifyAllOrdrs-None: 2
None-WRONG_CAPACITY_INPUTS_COUNT: 25
LoginPrivateReq-WRONG_CAPACITY_INPUTS_COUNT: 1
AllocationReq-None: 29
None-REF_DATA_BG_CONF_PARAMETER_BLANK: 2
LoginPrivateReq-access_denied_exchange_user_webgui: 9
None-REF_DATA_USER_ROLES_EMPTY: 1
None-REF_DATA_INTERCONNECTOR_NOT_SUSPENDED: 1
DeactOrdersForExchange-user_is_not_authenticated: 1
LogoutPrivateReq-user_is_not_authenticated: 11
PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 46
None-user_is_not_authenticated: 223
LogoutPrivateReq-trader_is_not_allowed_to_logout_other_traders_session: 1
====================================== USERS AND ERRORS ========================================================
<unknown>:
 - OrdrModify-None: 247
 - None-None: 26
 - ModifyAllOrdrs-None: 2
XBOMIEAR:
 - LoginPrivateReq-trader_already_logged_in: 11
XBOMIEA1:
 - LoginPrivateReq-trader_already_logged_in: 48
XBEPEX08:
 - LoginPrivateReq-trader_already_logged_in: 6
XBEPEXR4:
 - LoginPrivateReq-trader_already_logged_in: 7
SYSTEM:
 - None-DUPLICATE_AUTOPUBLISH_ATTEMPT: 50
 - None-None: 26
 - None-WRONG_CAPACITY_INPUTS_COUNT: 21
EPQINCO1:
 - None-SERVICE_IN_HALT: 8750
 - None-None: 37
 - AllocationReq-SERVICE_IN_HALT: 15840
 - AllocationReq-None: 29
XBOMIER1:
 - LoginPrivateReq-trader_already_logged_in: 8
EPQPOM01:
 - AllocationReq xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema"" type=""IOC""-DELIVERY_INTERVAL_DISABLED: 1
JAO00020:
 - None-REF_DATA_USER_ERR_CANNOT_DELETE: 1
 - None-REF_DATA_USER_ERR_ALREADY_EXISTING_USER_CODE: 4
 - None-REF_DATA_INVALID_CONFIG_START_DATE: 1
 - None-REF_DATA_BG_CONF_PARAMETER_BLANK: 1
 - None-REF_DATA_USER_ROLES_EMPTY: 1
 - None-REF_DATA_INTERCONNECTOR_NOT_SUSPENDED: 1
XBOMIEA2:
 - LoginPrivateReq-trader_already_logged_in: 13
XBEPEXR8:
 - LoginPrivateReq-trader_already_logged_in: 6
XBOMIER2:
 - LoginPrivateReq-trader_already_logged_in: 2
XBEPEX34:
 - LoginPrivateReq-trader_already_logged_in: 11
XBEPEX44:
 - LoginPrivateReq-trader_already_logged_in: 7
TGEADM01:
 - LoginPrivateReq-trader_already_logged_in: 12
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBNPA003:
 - LoginPrivateReq-trader_already_logged_in: 9
EPRHBW21:
 - ContractInfoReq-DELIVERY_INTERVAL_DISABLED: 1
OTESADM1:
 - LoginPrivateReq-trader_already_logged_in: 1
NPADSOB2:
 - LoginPrivateReq-trader_already_logged_in: 7
XBEPEX14:
 - LoginPrivateReq-trader_already_logged_in: 3
XBRTE001:
 - None-WRONG_CAPACITY_INPUTS_COUNT: 4
 - LoginPrivateReq-WRONG_CAPACITY_INPUTS_COUNT: 1
CROADM01:
 - LoginPrivateReq-trader_already_logged_in: 8
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBOTEA02:
 - LoginPrivateReq-trader_already_logged_in: 10
 - LogoutPrivateReq-user_is_not_authenticated: 1
OTESADM3:
 - LoginPrivateReq-trader_already_logged_in: 2
XBOTER01:
 - LoginPrivateReq-trader_already_logged_in: 1
XBOTER04:
 - LoginPrivateReq-trader_already_logged_in: 5
XBTGEX02:
 - LoginPrivateReq-access_denied_exchange_user_webgui: 6
XBOTEA06:
 - LoginPrivateReq-trader_already_logged_in: 6
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBTGEX01:
 - LoginPrivateReq-access_denied_exchange_user_webgui: 1
 - None-None: 3
XBOTEA07:
 - LoginPrivateReq-trader_already_logged_in: 8
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBOTER03:
 - LoginPrivateReq-trader_already_logged_in: 1
IBEXADM1:
 - LoginPrivateReq-trader_already_logged_in: 2
XBOTEX01:
 - LoginPrivateReq-access_denied_exchange_user_webgui: 1
XBOTEX02:
 - LoginPrivateReq-access_denied_exchange_user_webgui: 1
XBOTEA10:
 - LoginPrivateReq-trader_already_logged_in: 4
XBOTEA11:
 - LoginPrivateReq-trader_already_logged_in: 3
XBEPEXX1:
 - DeactOrdersForExchange-user_is_not_authenticated: 1
JAO00018:
 - None-REF_DATA_BG_CONF_PARAMETER_BLANK: 1
XBNPA001:
 - LoginPrivateReq-trader_already_logged_in: 3
IBEXEXC1:
 - PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 23
CROEXC01:
 - PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 23
NPADM002:
 - None-user_is_not_authenticated: 223
 - None-None: 1
 - LogoutPrivateReq-trader_is_not_allowed_to_logout_other_traders_session: 1
XBOTEA03:
 - LoginPrivateReq-trader_already_logged_in: 4
 - LogoutPrivateReq-user_is_not_authenticated: 2
CROADM04:
 - LoginPrivateReq-trader_already_logged_in: 1
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBOTEA05:
 - LoginPrivateReq-trader_already_logged_in: 1
XBOTEA01:
 - LoginPrivateReq-trader_already_logged_in: 1
 - LogoutPrivateReq-user_is_not_authenticated: 1
NPREP001:
 - LoginPrivateReq-trader_already_logged_in: 1
TGEADM04:
 - LoginPrivateReq-trader_already_logged_in: 1
 - LogoutPrivateReq-user_is_not_authenticated: 1
CROADM03:
 - LoginPrivateReq-trader_already_logged_in: 7
 - LogoutPrivateReq-user_is_not_authenticated: 1
XBTGER03:
 - LoginPrivateReq-trader_already_logged_in: 1
NPREP002:
 - LoginPrivateReq-trader_already_logged_in: 2
CROADM02:
 - LoginPrivateReq-trader_already_logged_in: 2
{noformat}
#2
{noformat}
=========================================== ERRORS =========================================================:
OrdrModify-None: 102
LoginPrivateReq-trader_already_logged_in: 40
None-DELIVERY_INTERVAL_DISABLED: 2
None-DUPLICATE_AUTOPUBLISH_ATTEMPT: 14
None-None: 22
AllocationReq-SERVICE_IN_HALT: 1123
None-SERVICE_IN_HALT: 44
AllocationReq-None: 1
LogoutPrivateReq-trader_is_not_allowed_to_logout_other_traders_session: 1
LogoutPrivateReq-user_is_not_authenticated: 1
PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 2
====================================== USERS AND ERRORS ========================================================
<unknown>:
 - OrdrModify-None: 102
 - None-None: 8
XBEPEX34:
 - LoginPrivateReq-trader_already_logged_in: 3
XBEPEXR4:
 - LoginPrivateReq-trader_already_logged_in: 3
XBOTEA06:
 - LoginPrivateReq-trader_already_logged_in: 2
XBEPEXR8:
 - LoginPrivateReq-trader_already_logged_in: 2
XBOMIEA2:
 - LoginPrivateReq-trader_already_logged_in: 3
EPELEC03:
 - None-DELIVERY_INTERVAL_DISABLED: 1
SYSTEM:
 - None-DUPLICATE_AUTOPUBLISH_ATTEMPT: 14
 - None-None: 6
XBOMIEA1:
 - LoginPrivateReq-trader_already_logged_in: 13
EPQINCO1:
 - AllocationReq-SERVICE_IN_HALT: 1123
 - None-None: 8
 - None-SERVICE_IN_HALT: 44
 - AllocationReq-None: 1
XBOMIER1:
 - LoginPrivateReq-trader_already_logged_in: 4
XBOMIEAR:
 - LoginPrivateReq-trader_already_logged_in: 3
XBXRPMX1:
 - LogoutPrivateReq-trader_is_not_allowed_to_logout_other_traders_session: 1
TGEADM01:
 - LoginPrivateReq-trader_already_logged_in: 3
 - LogoutPrivateReq-user_is_not_authenticated: 1
IBEXADM1:
 - LoginPrivateReq-trader_already_logged_in: 1
NPREP002:
 - LoginPrivateReq-trader_already_logged_in: 1
EPNOPO01:
 - None-DELIVERY_INTERVAL_DISABLED: 1
CROREP03:
 - LoginPrivateReq-trader_already_logged_in: 1
SADMIN01:
 - LoginPrivateReq-trader_already_logged_in: 1
CROEXC01:
 - PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 1
IBEXEXC1:
 - PblcOrdrBookProductPrivateReq-trader_is_not_allowed_to_access_product_with_da: 1
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Gartner statistics 2019 - end of year,XP-2435,90392,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zi174,dm700,dm700,13/Dec/19 14:47,31/Aug/20 15:38,22/Feb/21 13:26,06/Jan/20 12:37,,,3.1.0,,,,,,26/Aug/19 00:00,,,,,"We need input for Gartner statistics. Please provide figures for 2019 for support and development:
||Support (overall)||Explanation||
|kLOC| * _Application code_
 * _Test code (core of automated testing/QA – coded but not delivered to customer/BU)_
 * _Deployment code (code to put app into prod environment *done by DEV team*)_
 * _Custom tools/apps included in QA or SDLC_
 * _Code developed for POC of losses - _for the tab development__
 * _Release 2.0 - for the tab development_

{color:#FF0000}*_For counting use this reporting method:_*{color}
_[https://github.deutsche-boerse.de/dev/m7.development-scripts/tree/master/loc-reporting|https://slack-redir.net/link?url=https%3A%2F%2Fgithub.deutsche-boerse.de%2Fdev%2Fm7.development-scripts%2Ftree%2Fmaster%2Floc-reporting&v=3]_|
|Number of Logical Tables/Structures|
|Number of Screens|
|Number of Reports|
|Number of Interfaces| - _do not include internal interfaces_
 - _request interface is one, response interface is another one_|
|Number of Background Processes| - _We count all processes that are requested for the business of the application. So if, for example, you have a daily housekeeping job to keep your data structures up to date or “reset” the application for a fresh start, we count that. If you are requested to support additional data for SLA reporting as a business requirement, we count that_
 - internal interpretation: _number of processes triggered by timer_|
|Number of defects| * Internal interpretation of Gartner guideline: _defects that are just resulting in code change and belong to development_|
|Cost of team| |",,dm700,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/20 14:03;dm700;ENERGY_AppBM_NFUR and Team Profile_v03_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78935/ENERGY_AppBM_NFUR+and+Team+Profile_v03_2019.xlsx","16/Dec/19 12:08;dm700;Gartner 2019 - extract of values.png;https://jira.deutsche-boerse.com/secure/attachment/78662/Gartner+2019+-+extract+of+values.png","13/Dec/19 16:01;dm700;TradingClearingRisk StatistiX - RCA-Discussion_v1s.pdf;https://jira.deutsche-boerse.com/secure/attachment/78638/TradingClearingRisk+StatistiX+-+RCA-Discussion_v1s.pdf",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35596800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a07k:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Dec/19 14:51;dm700;gitCommitsReferenced is not EMPTY AND issuetype not in (Story) AND project = ""XBID Agile Development"" AND resolved >= startOfYear() AND ""[Environment]"" = PROD ORDER BY issuetype ASC, resolution DESC

result is *10* issues in 2019

it is resulting roughly in *1 percent* of the overall costs/spent","13/Dec/19 16:01;dm700;for Gartner initial evaluation values see old values see attachment","23/Dec/19 13:22;dm700;RUN THE SAME SCRIPT AS M7

_[https://github.deutsche-boerse.de/dev/m7.development-scripts/tree/master/loc-reporting|https://slack-redir.net/link?url=https%3A%2F%2Fgithub.deutsche-boerse.de%2Fdev%2Fm7.development-scripts%2Ftree%2Fmaster%2Floc-reporting&v=3]_|

eg. difference between shipping in delivered values is - LOC: 613501

and the script done by M7T reports fro shipping roughly 87k 

Shipping is bigger by delivered values bigger than XBID  core","03/Jan/20 14:56;dm700;the final number for bugs in production code fixed in 2019 (after discussion with [~tm431]) is 7","06/Jan/20 14:04;dm700;final values send for 2019 evaluation send to Gartner attached as : 

[^ENERGY_AppBM_NFUR and Team Profile_v03_2019.xlsx]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Email certificate on XBID LIP A,XP-2430,90350,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Incomplete,,ub113,ub113,12/Dec/19 11:22,31/Aug/20 15:39,22/Feb/21 13:26,07/Jan/20 13:34,,,3.1.0,,,,,,,,,,,"It seems that the mail server certs for XBID LIPA/B expire on 23.12. Can you please check?
{code:java}
Certificate                                                                                                   Serial                                              Policy ID  Issue date  Expiry date   Revocation date   Remaining days

email=xblipa-cor@xbid.deutsche-boerse.com,cn=xblipa-cor,ou=Mail,ou=XBID,ou=Energy,o=Deutsche Boerse AG,c=DE   281690469683243419386973935705793937080111448033    243        23/12/2016   23/12/2019                      14
{code}",,ei349,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35510400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09zyw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,LIP-A,,,LIP-A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/20 13:44;ei349;Dear [~ub113], 

did it really expired? Should we still investigate? ","06/Jan/20 13:47;ub113;Hi [~ei349]

This is probably duplicate of TECHLOG-3025","06/Jan/20 13:50;ei349;it looks like different certificate. (expiring 21/12 vs 23/12)","07/Jan/20 13:34;ub113;Hi [~ei349]
I checked with techops and it seems that current SMIME cert is still valid. Eg for cmi lipa until 7/12/2021 5:25:52 PM and with a different SerialNumber: CEST0x31DDFA65DE4A42FC5ABF5094A74E0910CA953A6B

We can ignore that email at the moment. It must have been requested twice. So that the newer ones are used, while the old ones were still valid. (edited) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Customer support] XBID Prod service degradation analysis,XP-2428,90160,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Cannot Reproduce,yo218,ek176,ek176,06/Dec/19 10:30,13/Aug/20 19:51,22/Feb/21 13:26,16/Dec/19 10:32,,,Pre2020,,,,,,17/Dec/19 00:00,PROD,TO4XBID,XBID,,"Dear Techops, 

customer observed performance degradation from Oct 14 on and requests clarification. 

In our logs, we have observed increased waiting time for order journalling operations. Diving into Grafana, the following irregularities have been observed. Please provide more information wrt to the XP-2404 that can be communicated to the customer. 

See attached PDF for more information, observed irregularities:
* 2019-10-14 between 01:30 and 05:00 (AM), most of the hosts have experienced high IOWAIT use (up to 37 %), disk IO time peaked up to 2.000 ms (xbprodcmm1), even to 11.000 ms (xbprodpmi3 logger). See the PDF for more info.
* In similar time, the disk usage pattern changed. On the xbprodcbn2 (nfs) the Disk IO requests and Disk IO bytes significantly dropped, on the other hand the requests/bytes raiesd on xbprodcbn1 (nsf) host.
* Finally, in the similar time, the GlusterFS hosts have experienced Disk IO lags raise from about 300 to 5.900 ms

",,ek176,yo218,,,,,,,,,,,,,,,,,,,XP-2404,,,,,,,,,,,,,,,,,,,,,,"06/Dec/19 10:29;ek176;XP-2404-protocol_short_v07.pdf;https://jira.deutsche-boerse.com/secure/attachment/78362/XP-2404-protocol_short_v07.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,37497600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s8",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/19 09:49;yo218;I just send an email to the storage team, asking them for any known issues on that day","16/Dec/19 10:32;yo218;We are not able to find the reason for the disk behavior. The storage team could not detect any errors on their side, just some strange behavior from the ESX hosts. The ESX team don't have any logs from that date (just from the last 30 days). 

answer from storage guys:
{noformat}
Hi Niklas. Ok, we had no problems on the dwdm between the datacenters in this timeframe. But even if yes, it shouldn’t be a problem because these esx-cluster are not stretched. The only thing we can see is, that the esx-server in question had an unusual IO-Pattern in the mentioned timeframe on the SAN. Before and after we can see a nice cozy heartbeat-like pattern and in the night from Sunday to Monday all the machines mentioned produced an increased load. But still marginal in numbers. So no overload. Just out of the ordinary. That means, we also don’t have really substantial data. We see no errors but an unusual (no overload) io-pattern from the esx-servers from these clusters. We cannot say where that came from. We can only see it while we don’t see any errors in our environment. Cheers {noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Syt1 - AMQP connection failing with certificate error,XP-2427,90324,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,tr866,tr866,11/Dec/19 15:01,13/Aug/20 19:51,22/Feb/21 13:26,11/Dec/19 15:55,,,Pre2020,,,,,,,,,,,"Connection via AMQP not working with following error:
java.security.cert.CertificateExpiredException: NotAfter: Fri Feb 01 00:59:59 CET 2019

It's happening when trying to connect to both load balancers:
LB:10.136.142.19:50700 and LB:10.136.14.19:50700

The issue looks the same as older ticket
https://jira.deutsche-boerse.com/browse/TECHLOG-2582

Ansible AMQP deployment failing too
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Ansible-Deploy-XBID-AMQP/48/console",,tr866,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,37843200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:sc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/19 15:53;yo218;added the missed certificate. Now deployment finished successfully:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Ansible-Deploy-XBID-AMQP/50/console]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Syt1 - Problem with access to Core DB - Deployments Failing,XP-2426,90320,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,tr866,tr866,11/Dec/19 14:38,13/Aug/20 19:51,22/Feb/21 13:26,11/Dec/19 15:41,,,Pre2020,,,,,,,,,,,"Deployments failing with errors like
{quote}ERROR: Unable to lock table ""xbsyt1cor"".""schema_version""
 ERROR: Caused by: org.postgresql.util.PSQLException: ERROR: cannot execute SELECT FOR UPDATE in a read-only transaction
{quote}
 
 Connection to xbsyt1cor database on xbtestpdb1.deutsche-boerse.de and xbtestpdb2.deutsche-boerse.de by SQL client failing too, where as for the others xbsyt1cmi and xbsyt1spm still working

Example of failed deployment:
[https://englobjci1.deutsche-boerse.de/job/Energy/job/XBID-sysX-deploy-all/1416/console]",,tr866,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,switched master node to xbtestpdb1,,,,,,,,,,,,,,37843200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:sa",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/19 15:31;tr866;When tried deployment for Shipping Module only (SMC,SMI modules), deyploment failed too, so may-be it's not about about Core DB only.

https://englobjci1.deutsche-boerse.de/job/Energy/job/XBID-sysX-deploy-all/1419/console","11/Dec/19 15:38;yo218;node 2 was leader, need to be switched to node 1 for deployments
{noformat}
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1async/config.yml list
+-------------+------------+----------------+--------+---------+-----------+
|   Cluster   |   Member   |      Host      |  Role  |  State  | Lag in MB |
+-------------+------------+----------------+--------+---------+-----------+
| xbsyt1async | xbtestdbr1 | 10.136.161.122 |        | running |           |
| xbsyt1async | xbtestdbr2 | 10.136.33.122  |        | running |       0.0 |
| xbsyt1async | xbtestpdb1 | 10.139.40.225  |        | running |           |
| xbsyt1async | xbtestpdb2 | 10.139.40.224  | Leader | running |       0.0 |
+-------------+------------+----------------+--------+---------+-----------+
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml list
+------------+------------+----------------+--------------+---------+-----------+
|  Cluster   |   Member   |      Host      |     Role     |  State  | Lag in MB |
+------------+------------+----------------+--------------+---------+-----------+
| xbsyt1sync | xbtestdbr1 | 10.136.161.122 |              | running |       0.0 |
| xbsyt1sync | xbtestdbr2 | 10.136.33.122  |              | running |       0.0 |
| xbsyt1sync | xbtestpdb1 | 10.139.40.225  | Sync standby | running |           |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224  |    Leader    | running |       0.0 |
+------------+------------+----------------+--------------+---------+-----------+
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1sync/config.yml switchover
Master [xbtestpdb2]:
Candidate ['xbtestpdb1'] []:
When should the switchover take place (e.g. 2015-10-01T14:30)  [now]:
Current cluster topology
+------------+------------+----------------+--------------+---------+-----------+
|  Cluster   |   Member   |      Host      |     Role     |  State  | Lag in MB |
+------------+------------+----------------+--------------+---------+-----------+
| xbsyt1sync | xbtestdbr1 | 10.136.161.122 |              | running |           |
| xbsyt1sync | xbtestdbr2 | 10.136.33.122  |              | running |           |
| xbsyt1sync | xbtestpdb1 | 10.139.40.225  | Sync standby | running |       0.0 |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224  |    Leader    | running |       0.0 |
+------------+------------+----------------+--------------+---------+-----------+
Are you sure you want to switchover cluster xbsyt1sync, demoting current master xbtestpdb2? [y/N]: y
2019-12-11 15:36:15.53575 Successfully switched over to ""xbtestpdb1""
+------------+------------+----------------+--------+---------+-----------+
|  Cluster   |   Member   |      Host      |  Role  |  State  | Lag in MB |
+------------+------------+----------------+--------+---------+-----------+
| xbsyt1sync | xbtestdbr1 | 10.136.161.122 |        | running |       0.0 |
| xbsyt1sync | xbtestdbr2 | 10.136.33.122  |        | running |       0.0 |
| xbsyt1sync | xbtestpdb1 | 10.139.40.225  | Leader | running |           |
| xbsyt1sync | xbtestpdb2 | 10.139.40.224  |        | stopped |   unknown |
+------------+------------+----------------+--------+---------+-----------+
[root@xbtestpdb1 ~]# patronictl -c /etc/patroni_xbsyt1async/config.yml switchover
Master [xbtestpdb2]:
Candidate ['xbtestpdb1'] []:
When should the switchover take place (e.g. 2015-10-01T14:30)  [now]:
Current cluster topology
+-------------+------------+----------------+--------+---------+-----------+
|   Cluster   |   Member   |      Host      |  Role  |  State  | Lag in MB |
+-------------+------------+----------------+--------+---------+-----------+
| xbsyt1async | xbtestdbr1 | 10.136.161.122 |        | running |       0.0 |
| xbsyt1async | xbtestdbr2 | 10.136.33.122  |        | running |       0.0 |
| xbsyt1async | xbtestpdb1 | 10.139.40.225  |        | running |       0.0 |
| xbsyt1async | xbtestpdb2 | 10.139.40.224  | Leader | running |       0.0 |
+-------------+------------+----------------+--------+---------+-----------+
Are you sure you want to switchover cluster xbsyt1async, demoting current master xbtestpdb2? [y/N]: y
2019-12-11 15:36:26.67341 Successfully switched over to ""xbtestpdb1""
+-------------+------------+----------------+--------+---------+-----------+
|   Cluster   |   Member   |      Host      |  Role  |  State  | Lag in MB |
+-------------+------------+----------------+--------+---------+-----------+
| xbsyt1async | xbtestdbr1 | 10.136.161.122 |        | running |       0.0 |
| xbsyt1async | xbtestdbr2 | 10.136.33.122  |        | running |       0.0 |
| xbsyt1async | xbtestpdb1 | 10.139.40.225  | Leader | running |           |
| xbsyt1async | xbtestpdb2 | 10.139.40.224  |        | stopped |   unknown |
+-------------+------------+----------------+--------+---------+-----------+
[root@xbtestpdb1 ~]#
 {noformat}
The jenkins job [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID-Dev/job/XBID-Patroni-List-Switch/] should be used to fix this situation","11/Dec/19 15:41;yo218;Deployment was successful now:

[https://englobjci1.deutsche-boerse.de/job/Energy/job/XBID-sysX-deploy-all/1420/console]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix failling end-to-end test,XP-2423,90212,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,qo794,qo794,09/Dec/19 12:55,13/Aug/20 20:16,22/Feb/21 13:26,31/Jan/20 11:03,,,3.1.0,,,,,,,,,,,"The test ""{{OBK depth for hourly contracts is 100 and better price order is sent}}"" in *orderBookDepth.feature* is constantly failing, therefore it was marked as ignored within XP-2422. Review the test and fix.",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38102400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a59y:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 0 (S),HOT Sprint 1,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
End-to-end pipeline docker logs copy failing,XP-2422,90191,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,09/Dec/19 10:03,06/Nov/20 10:59,22/Feb/21 13:26,11/Dec/19 10:14,,,Pre2020,,,,,,,,,,,"End-to-end pipeline is constantly failing with the following error:
{code}
Logs saved in target/management-tests-logs
Moving all logs from xbid-logs to upper directory
Removing directory xbid-logs
Copying log to: target/management-tests-logs/xbid-reporting
Copying log to: target/management-tests-logs/xbid-core-1
Traceback (most recent call last):
  File ""target/classes/docker_control.py"", line 371, in <module>
    main(args)
  File ""target/classes/docker_control.py"", line 363, in main
    get_copier().copy_logs(args['<docker-compose-file-path>'], args['--logs-path'])
  File ""target/classes/docker_control.py"", line 256, in copy_logs
    self.copy_container_output_log(container, target_dir)
  File ""target/classes/docker_control.py"", line 265, in copy_container_output_log
    file.write(log_content.decode('utf-8'))
UnicodeEncodeError: 'ascii' codec can't encode character '\xb5' in position 101816: ordinal not in range(128)
{code}",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38102400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09z3c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Dec/19 12:56;qo794;One failing test ignored, see XP-2423",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Estimate effort spend per XBID environment,XP-2420,90128,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,dm700,dm700,05/Dec/19 13:54,31/Aug/20 15:37,22/Feb/21 13:26,14/May/20 16:40,,,3.1.0,,,,,,,,,,,"As part of https://jira.deutsche-boerse.com/browse/INIT-442 there has been a question raised about effort we (=dev) we spend to run an environment. 

Purpose of this exercise:
*ACM is selling new environments and we have only very limited overview how each environment has impact to spent MDs. 
*

Se we would like to have some rough overview about how much does cost the run of each type of customer facing environment (= can be clustered to ""member testing environment"", ""customer internal testing environment"" etc.). Categorization of environments up to the team.

So counted should be costs of bulding, maintaning and patch the environment itself. Include also reocurring actions done this enviroment type (deployment etc.). And also include effort on environment specific issues (bugs in configuration, datasets, etc.). 

Environment nonspecific issues should not be included. So answering the question - is this bug on all environments with this version should provide some rough guideline.

Time period up to the team. Output ideal in MDs, just spent in Scrum team.",,dm700,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,24451200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 16:40;dm700;for 2019 +/- fulfilled",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Replace mount for XBID Reporting Engine,XP-2416,90091,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,04/Dec/19 14:29,12/Aug/20 13:56,22/Feb/21 13:26,05/Dec/19 08:37,,,Pre2020,,Reporting Engine,,,,,,,,,"Impacted ENVs:

XBID Prod

----------------------------------------------------------

The reporting Engine is currently using a NFS share from the old database host. As we would like to decommission this host as part of the patroni migration, we need to replace the mountpoint. GlusterFS is already used for all internal test environments and for Simulation. A new GlusterFS volume need to be created on xbprodglfs1/2 and need to be mounted on xbprodrep1/2. Reporting Engine need to be stopped during this operation which will take less than 10 minutes

EDIT: change can be performed on one host after another to ensure the availability of the reports at any time",,yo218,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5157,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,ub113,wn626,Old and obsolete database host is used for the NFS share. Host will be decommissioned as soon as the migration happened.,,18/Nov/19 15:24,,,,,,,18/Nov/19 15:15,,,,eg288,qo794,,,,38448000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,04/Dec/19 15:30,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09yj4:",9223372036854775807,,,,,,,,,,unmount glusterfs mount and remount old nfs mount,,,,,,,,,,,,,Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,The same change has been performed successfully today on all systemtest environments. Simulation is already using a GlusterFS volume,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/19 08:36;yo218;All reporting engines are now using glusterfs as shared drive",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reporting tool infrastructure issues,XP-2415,90087,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,qo794,qo794,04/Dec/19 13:35,13/Aug/20 19:41,22/Feb/21 13:26,21/Feb/20 09:19,,,3.1.0,,,,,,,waiting-3rdparty,,,,"* no logs on ebsm server
* same log lines displayed several times in Kibana (sometime twice but usually three times), for instance:
https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-30d,mode:quick,to:now))&_a=(columns:!(log_level,logline),index:xbid-sla,interval:auto,query:(language:lucene,query:'beat.hostname:xbprodsla2+AND+logline:%22Taking+fromTo+for+ALL_ORDERS%22'),sort:!('@timestamp',desc))
* no DB dumps of SLA databases created",,iu252,qo794,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,31708800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a9h9:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,Christmasprint,HOT Sprint 3,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/19 16:02;yo218;* no logs on ebsm server
 * same log lines displayed several times in Kibana (sometime twice but usually three times), for instance:
[https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-30d,mode:quick,to:now))&_a=(columns:!(log_level,logline),index:xbid-sla,interval:auto,query:(language:lucene,query:'beat.hostname:xbprodsla2+AND+logline:%22Taking+fromTo+for+ALL_ORDERS%22'),sort:!('@timestamp',desc]))
 * -no DB dumps of SLA databases created-

added the Prod SLA databases to the daily copy job
{noformat}
-bash-4.2$ ls -ltr /opt/data/transfer/dbdumps/xbid_prod/ | grep sla
-rw-rw-r-- 1 transfer transfer  157863600 Dec  4 15:56 xbprodsla1.191204-1555.dump.gz
-rw-rw-r-- 1 transfer transfer  318766703 Dec  4 15:57 xbprodsla2.191204-1555.dump.gz {noformat}","05/Dec/19 13:23;yo218;* no logs on ebsm server
 * -same log lines displayed several times in Kibana (sometime twice but usually three times), for instance:-
-[https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:now-30d,mode:quick,to:now))&_a=(columns:!(log_level,logline),index:xbid-sla,interval:auto,query:(language:lucene,query:'beat.hostname:xbprodsla2+AND+logline:%22Taking+fromTo+for+ALL_ORDERS%22'),sort:!('@timestamp',desc]))-
 * -no DB dumps of SLA databases created-

 

I redeployed the monitoring client as I saw some changes in inventory like ""removing duplicate monitoring entries"" currently there are no double entries visible in Kibana. Will doublecheck again tomorrow whether the mentioned entries at 04:00 will occur only once","09/Dec/19 08:46;yo218;files are available on EBSM now:
{noformat}
[root@m7shrdebsm1 xb_xbid]# ls -la /home/logmover/2currentDay/prod/xb_xbid/ | grep rpt
-rw-r--r--  1 logmover logmover    190669 Dec  9 07:00 xb_xbid_prod_rpt-1_standard_ixe.log
-rw-r--r--  1 logmover logmover    424440 Dec  9 07:03 xb_xbid_prod_rpt-2_standard_hau.log {noformat}","09/Dec/19 08:49;yo218;There are still double entries for the mentioned kibana filter. [~iu252] is looking into it","17/Dec/19 08:57;iu252;Opened a case with elastic support (Case 00468654).","21/Feb/20 07:27;iu252;After investigation with Elastic support, we upgraded filebeat to the newest version and changed some setting in filebeat configuration.
There are no duplicates anymore.","21/Feb/20 09:15;yo218;[~iu252] told me that the issue with the duplicate lines should be resolved after the lates update of the elastic database. Can you confirm [~qo794]?","21/Feb/20 09:19;qo794;At first glance it looks good, no duplicate lines, thanks, closing the ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Heap dump is generating to non-existing directory for reporting engine,XP-2414,90083,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,yo218,yo218,04/Dec/19 12:52,04/Aug/20 19:36,22/Feb/21 13:26,09/Dec/19 10:35,,,Pre2020,,,,,,,TO-JOB,,,,"We had an issue XP-1812 which was caused by insufficient amount of memory on LipA reporting engine. The applicastion crashed on {{out of memory}} error but the heap dump wasn't there. *It's configured to be generated to {{/xbid/logs/xbid-lipa-rep1/}} but the directory doesn't exist*
{noformat}
tomcat@xbcutsrep1:[/shrd/logs/xbid-lipa-rep1/rollover]$ ll /
total 70
lrwxrwxrwx   1 root   root       7 Aug 28  2018 bin -> usr/bin
dr-xr-xr-x   5 root   root    1024 Aug 28  2018 boot
drwxr-xr-x  19 root   root    3240 Mar 31 03:00 dev
lrwxrwxrwx   1 root   root       8 Mar  8  2017 esm -> /opt/esm
drwxr-xr-x 104 root   root   12288 Jun 21 10:12 etc
drwxr-xr-x  24 root   root    4096 Jun 20 16:56 home
lrwxrwxrwx   1 root   root       7 Aug 28  2018 lib -> usr/lib
lrwxrwxrwx   1 root   root       9 Aug 28  2018 lib64 -> usr/lib64
drwx------   2 root   root   16384 Oct 29  2015 lost+found
drwxr-xr-x   2 root   root    4096 Dec 14  2017 media
drwxr-xr-x   2 root   root    4096 Dec 14  2017 mnt
drwxr-xr-x   7 root   root    4096 Dec 14  2017 opt
dr-xr-xr-x 184 root   root       0 Mar 31 03:00 proc
dr-xr-x---   9 root   root    4096 Apr  1 11:58 root
drwxr-xr-x  32 root   root     960 Jun 21 08:26 run
lrwxrwxrwx   1 root   root       8 Aug 28  2018 sbin -> usr/sbin
drwxr-xr-x  43 tomcat tomcat  4096 Jun 21 09:23 shrd
drwxr-xr-x   2 root   root    4096 Dec 14  2017 srv
dr-xr-xr-x  13 root   root       0 Mar 25 09:56 sys
drwxrwxrwt  11 root   root    4096 Jun 21 10:22 tmp
drwxr-xr-x  13 root   root    4096 Aug 28  2018 usr
drwxr-xr-x  22 root   root    4096 Aug 28  2018 var
{noformat}
In order to change that the change in the template would be needed - see file [energy-mkt-shared/templates/tomcat/start.sh_with_catalina_opts|https://github.deutsche-boerse.de/dev/energy-mkt-shared/blob/master/templates/tomcat/start.sh_with_catalina_opts]

I suggest to change the base directory ({{baseDir}}) of the reporting engine modules for all shared environment. Currently *it is configured for {{/shrd}} directory although it's kind of standard to have the root directory set to {{xbid}}*.

Lipa reporting engine tomcat configuration
{code:xml}
         <name>xbid-lipa-rep1</name>
         <host>xbcutsrep1</host>
         <!-- File name or IP address --><baseDir>/shrd</baseDir>
         <!-- Absolute path --><appLogDir>logs/xbid-lipa-rep1/</appLogDir>
{code}

Lipa core tomcat configuration
{code:xml}
         <name>xbid-lipa-cor1</name>
         <host>xblipacor1</host>
         <!-- File name or IP address --><baseDir>/xbid</baseDir>
         <!-- Absolute path --><appLogDir>logs/xbid-lipa-cor1/</appLogDir>
{code}

Please fix it for all affected environments which are defined in:
* xbid_cute_ctpa.xml
* xbid_cute_ctpb.xml
* xbid_cute_ctpc.xml
* xbid_cute_ctpd.xml
* xbid_cute_ctpe.xml
* xbid_cute_ctpf.xml
* xbid_cute_ctpg.xml
* xbid_cute_ctph.xml
* xbid_cute_ctpi.xml
* xbid_cute_ctpj.xml
* xbid_cute_ctpk.xml
* xbid_cute_ctpl.xml
* xbid_cute_ctso.xml
* xbid_cute_cute.xml
* xbid_cute_lipa.xml
* xbid_cute_lipb.xml",,yo218,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2525,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38102400,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:400000000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/19 10:35;yo218;The reconfiguration from using /shrd to /xbid should be done during ansible migration. It is the same for all shared cute components (rep, web + haproxy) and should be done at the same time to be consistent.

As cheap workaround I created a link on /xbid/logs which is pointing to /shrd/logs:
{noformat}
[root@xbcutsrep1 xbid]# ls -la /xbid/
total 28
drwxr-xr-x  4 tomcat tomcat  4096 Dec  9 10:11 .
dr-xr-xr-x 20 root   root    4096 Dec  9 09:51 ..
drwxr-xr-x 12 tomcat tomcat  4096 Dec  9 10:00 data
lrwxrwxrwx  1 root   root      10 Dec  9 10:11 logs -> /shrd/logs
drwx------  2 tomcat tomcat 16384 Dec  9 09:50 lost+found
root@xbcutsrep1 xbid]# ls -la /xbid/logs/xbid-lipa-rep1/
total 336
drwxrwxr-x  2 tomcat tomcat   4096 Dec  9 10:31 .
drwxr-xr-x 18 tomcat tomcat   4096 Dec  9 10:31 ..
-rw-r-----  1 tomcat tomcat   7874 Dec  9 10:31 catalina.2019-12-09.log
-rw-r-----  1 tomcat tomcat 268688 Dec  9 10:31 catalina.out
-rw-r-----  1 tomcat tomcat      0 Dec  9 10:31 host-manager.2019-12-09.log
-rw-r-----  1 tomcat tomcat   1365 Dec  9 10:31 localhost.2019-12-09.log
-rw-r-----  1 tomcat tomcat    373 Dec  9 10:31 localhost_access_log.2019-12-09.log
-rw-r-----  1 tomcat tomcat      0 Dec  9 10:31 manager.2019-12-09.log
-rw-r-----  1 tomcat tomcat   1839 Dec  9 10:31 xb_xbid_lipa_rep-1_database_ixe.log
-rw-r-----  1 tomcat tomcat      0 Dec  9 10:31 xb_xbid_lipa_rep-1_database-sql_ixe.log
-rw-r-----  1 tomcat tomcat  20543 Dec  9 10:31 xb_xbid_lipa_rep-1_gc-pid5791_ixe.log.0.current
-rw-r-----  1 tomcat tomcat  17314 Dec  9 10:31 xb_xbid_lipa_rep-1_standard_ixe.log
 {noformat}
FYI: [~eh941]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename DEGRADED to RTS3B in Credit points report,XP-2413,90066,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,qo794,qo794,04/Dec/19 09:22,13/Aug/20 19:41,22/Feb/21 13:26,23/Jan/20 08:09,,,3.1.0,,SLA Report Tool,,,,,,,,,Rename DEGRADED to RTS3B in Credit points report - required after 2nd wave go live changes.,,qo794,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,37929600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,04/Dec/19 09:22,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220083",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,Christmasprint,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Dec/19 09:14;qo794;The current implementation supports 2 SLA levels - RTS and DEGRADED based on a total amount of orders per day. If the amount is higher than 400.000 DEGRADED SLA level is chosen, RTS otherwise.
[~zi174] Is the above feature described above correct assuming the DEGRADED level will be renamed to RTS3B? Should it stay in the application at all?","11/Dec/19 10:40;zi174;Yep, as we discussed the renaming from Degraded to RTS3B is sufficient. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMXBID CLONE: New IP-address to prod and testing environments,XP-2405,89899,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,ub113,ub113,29/Nov/19 11:29,12/Aug/20 13:56,22/Feb/21 13:26,11/Dec/19 07:16,,,Pre2020,,CMM,,,,,,,,,"Hi,

we are currently updating our systems and replacing our current IP-address with a new one. 
New: 195.234.135.131 
Current: 195.234.135.130

PLEASE NOTICE: please allow both addresses in your system. 

Accessing impacts both prod and testing environments.

Best regards,
Niko Korhonen",,ub113,yo218,,,,,,,,,,,,,,,,,,,,,,SMXBID-1641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,, Minor Incident,,,,,,37929600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09xfs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/19 11:30;ub113;Details:

_sftp user name (if it exists, please include it): xbid_finngrid_prod, xbid_finngrid_lipa, xbid_finngrid_lipb, xbid_finngrid_simu, xbid_finngrid_cute, xbid_finngrid_ctso_
_public ssh key: no change on our public key. Will use same as defined and in use today_

_source IP address of the connection: 195.234.135.131 and 195.234.135.130_

_via which communication channel you want to access PROD: same as today_","09/Dec/19 11:12;yo218;Firewall rule has been raised:  320096","11/Dec/19 07:16;yo218;I escalated the request as the customer raised the ticket already two weeks ago.

Rule has been implemented now",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Two OrdrExeRprts with same ordrId,XP-2403,89888,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Not a Bug,dp007,dp007,dp007,29/Nov/19 09:01,06/Nov/20 09:27,22/Feb/21 13:26,29/Nov/19 10:08,,,7tops_pre-sprint0_cleanup,,,,,,,,,,,"EPEX ASIM received two different order execution reports with the same order ID 7270780 - please investigate why.

./m7_epex_asim_cor-1_standard_ixe_2_2019-10-23.log:2019-10-23T08:55:39.334Z
{code:sql}
<OrdrExeRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
<StandardHeader marketId=""XSOB""/>
<OrdrList>
    <Ordr ordrId=""7270780"" initialOrdrId=""7270780"" acctId=""BG-EPEX-------01"" contractId=""128910"" side=""BUY"" px=""-62""
          qty=""1000"" initialQty=""1000"" ordrExeRestriction=""NON"" txt=""-TM -  situation maker(2019-10-23T10:55:39.188)""
          dlvryAreaId=""10YDE-VE-------2"" clOrdrId=""124070679"" preArranged=""false"" type=""O"" state=""ACTI"" usrCode=""TRD001""
          revisionNo=""1"" timestmp=""2019-10-23T08:55:39.254Z"" validityDate=""2019-10-23T20:30:00.000Z"" validityRes=""GFS""
          action=""UADD"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001"" exGTD=""2019-10-23T20:00:00.000Z""/>
</OrdrList>
</OrdrExeRprt>
{code}
./m7_epex_asim_cor-1_standard_ixe_4_2019-10-23.log:2019-10-23T13:59:56.759Z
{code:sql}
<OrdrExeRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"" listExecInst=""NONE"" listId=""7270780"">
<StandardHeader marketId=""XSOB""/>
<OrdrList>
    <Ordr ordrId=""7270780"" initialOrdrId=""7270780"" acctId=""BG-EPEX-------01"" contractId=""128911"" side=""BUY"" px=""500""
          qty=""1000"" initialQty=""1000"" ordrExeRestriction=""NON""
          txt=""32.0-ENOBOT-phm (2019-10-23T15:59:57.129)#7643752b-4cbe-4073-a8c0-bfee92ed025e#ST""
          dlvryAreaId=""10YDE-ENBW-----N"" clOrdrId=""124080575"" preArranged=""false"" type=""O"" state=""ACTI"" usrCode=""TRD001""
          revisionNo=""1"" timestmp=""2019-10-23T13:59:56.703Z"" validityDate=""2019-10-23T20:45:00.000Z"" validityRes=""GFS""
          action=""UADD"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001"" exGTD=""2019-10-23T20:15:00.000Z""/>
</OrdrList>
</OrdrExeRprt>{code}",,dp007,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-4859,SERVICE-4805,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38966400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,29/Nov/19 09:01,,,,,,,,,,,,,,,,,,,,,,,"1|y09xdc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe TSOs,,,CUTE TSOs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/19 09:55;tm431;No activities should be performed on CTSO on 23/10/2019 as XBID reqeusted to have dry run more info in  XBID-4771  related SERVICE-4700",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ContractInfoRprt broadcast revision number 1 missing for blocks,XP-2400,89845,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hj444,qo794,qo794,28/Nov/19 08:45,03/Feb/21 13:01,22/Feb/21 13:26,03/Feb/21 13:01,,,3.2.x,Pre2020,Trading,,,,,,,,,"When a new block contract is created, a {{ContractInfoRprt}} broadcast with revision number 0 is sent out. A next {{MaintainContractsTask}} triggers another {{ContractInfoRprt}} broadcast with revision number 2.
* a broadcast with revision number 1 is missing
** root cause: {{NewBlockContract::update}} is called in {{com.deutscheboerse.energy.m7.trade.OrderEntryResult#build}} when {{ContractInfo}} is already created with version number 0
* {{MaintainContractsTask}} triggers a new {{ContractInfoRprt}} broadcst even though there was no change on the block contract - this bug is a result of the point above: {{ContractInfo}} contains version 0 whereas {{Contract}} bears version 1, so point one will fix also this bug

See example below for the situation in XP-2390, first 2 broadcast are relevant for this issue:  [^contract_broadcasts]
{code:xml}
2019-11-16 18:32:47.732: REQUEST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><OrdrEntry xmlns=""http://www.deutsche-boerse.com/m7/v1"" listExecInst=""NONE""><StandardHeader marketId=""XSOB""/><OrdrList><Ordr acctId=""BG-EPEX-------01"" prod=""XBID_Hour_Power"" side=""SELL"" px=""10000"" ppd=""0"" qty=""10000"" ordrE
xeRestriction=""AON"" txt="""" dlvryAreaId=""10YDE-RWENET---I"" clOrdrId=""10566895819"" type=""B"" dlvryStart=""2019-11-17T06:00:00.000Z"" dlvryEnd=""2019-11-17T16:00:00.000Z"" validityDate=""2019-11-17T16:00:00.000Z"" validityRes=""GFS"" state=""ACTI"" exGTD=""2019-11-17T05:00:00.000Z""/></OrdrList></OrdrEntry>. MessageProperties [heade
rs={timestamp_in_ms=1573929167731, server-timestamp=1573929167730}, timestamp=Sat Nov 16 18:32:47 UTC 2019, messageId=null, userId=null, receivedUserId=XBEPEXX1, appId=m7-EPEX, clusterId=null, type=com.deutscheboerse.m7.trading.api.v1.OrdrEntry, correlationId=[50, 48, 48, 50, 56, 55, 48, 51, 56, 49, 51, 57, 53, 54, 4
8, 57, 48, 95, 49], correlationIdString=null, replyTo=amq.gen-zqy8MKtksNJlckQ9EWpvWQ, contentType=x-m7/request; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.requestExchange.XBEPEXX1, r
eceivedRoutingKey=comxerv.request.management, receivedDelay=null, deliveryTag=94906663, messageCount=0, consumerTag=amq.ctag-5MxE2KA3oDu6SRVJyZEG8w, consumerQueue=xbid.monitoring.1]

2019-11-16 18:32:47.764:
<Contract contractId=""104795"" prod=""XBID_Hour_Power"" name=""T07-T17_XB"" longName=""20191117 07:00-20191117 17:00"" dlvryStart=""2019-11-17T06:00:00.000Z""
          dlvryEnd=""2019-11-17T16:00:00.000Z"" predefined=""false"" revisionNo=""0"" state=""ACTI"" tradingPhase=""CONT"" duration=""10.0""
          actPoint=""2019-11-16T07:00:00.000Z"" expPoint=""2019-11-17T06:00:00.000Z"">
    <DlvryAreaState dlvryAreaId=""10YCA-BULGARIA-R"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YPT-REN------W"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YFI-1--------U"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YPL-AREA-----S"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YMA-ONE------O"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YHR-HEP------M"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDOM-1001A084H"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YRO-TEL------P"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YAT-APG------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YBE----------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:55:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YCZ-CEPS-----N"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDE-VE-------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YFR-RTE------C"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YLT-1001A0008Q"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDE-ENBW-----N"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A44P"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A39I"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDK-1--------W"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YNO-1--------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YNO-2--------T"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A45N"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A46L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDE-RWENET---I"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YNL----------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:55:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YNO-3--------J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YNO-4--------9"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A48H"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDE-EON------1"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YDK-2--------M"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YSI-ELES-----O"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YHU-MAVIR----U"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YES-REE------0"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10Y1001A1001A47J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
    <DlvryAreaState dlvryAreaId=""10YLV-1001A00074"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
</Contract>

2019-11-16 18:35:00.057:
<Contract contractId=""104795"" prod=""XBID_Hour_Power"" name=""T07-T17_XB"" longName=""20191117 07:00-20191117 17:00"" dlvryStart=""2019-11-17T06:00:00.000Z""
          dlvryEnd=""2019-11-17T16:00:00.000Z"" predefined=""false"" revisionNo=""2"" state=""ACTI"" tradingPhase=""CONT"" duration=""10.0""
          actPoint=""2019-11-16T07:00:00.000Z"" expPoint=""2019-11-17T06:00:00.000Z"">
<DlvryAreaState dlvryAreaId=""10YCA-BULGARIA-R"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YPT-REN------W"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YFI-1--------U"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YPL-AREA-----S"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YMA-ONE------O"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YHR-HEP------M"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDOM-1001A084H"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YRO-TEL------P"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YAT-APG------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YBE----------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:55:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YCZ-CEPS-----N"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDE-VE-------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YFR-RTE------C"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YLT-1001A0008Q"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDE-ENBW-----N"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A44P"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A39I"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDK-1--------W"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YNO-1--------2"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YNO-2--------T"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A45N"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A46L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDE-RWENET---I"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YNL----------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:55:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YNO-3--------J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YNO-4--------9"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A48H"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDE-EON------1"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T17:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:30:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YDK-2--------M"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YSI-ELES-----O"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YHU-MAVIR----U"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2019-11-16T14:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YES-REE------0"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10Y1001A1001A47J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
<DlvryAreaState dlvryAreaId=""10YLV-1001A00074"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2019-11-16T13:00:00.000Z"" tradingPhaseEnd=""2019-11-17T05:00:00.000Z""/>
</Contract>
{code}",,hj444,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/19 08:45;qo794;contract_broadcasts;https://jira.deutsche-boerse.com/secure/attachment/77805/contract_broadcasts",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,1641600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,28/Nov/19 08:45,,,,,,,,,,,,,,,,,,,,,,,"1|y0c4g3:zoc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,HOT Sprint 25 (S),HOT Sprint 26,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4155-npe-fix,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Feb/21 12:32;hj444;retest of versioning Block orders in ContractInfoRprt
Docker : 
 XBID: Version R3.2.5-SNAPSHOT (Build 1547082ca2582d5167ada7d4f80cab06743df566)

Steps :
* *Login into Test client*
* *Create a block order* (Hourly - 14-19)
{code}<?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrEntry xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr acctId=""BG-EPEX-------01"" prod=""XBID_Hour_Power"" side=""BUY"" px=""500"" qty=""50000"" ordrExeRestriction=""AON"" dlvryAreaId=""10YBE----------2"" clOrdrId=""d95c7847-906c-4ddc-b2ca-660aad63467d"" type=""B"" dlvryStart=""2021-02-03T13:00:00.000Z"" dlvryEnd=""2021-02-03T18:00:00.000Z"" validityRes=""GFS"" state=""ACTI""/>
    </OrdrList>
</OrdrEntry>

<?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrExeRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr ordrId=""3"" initialOrdrId=""3"" acctId=""BG-EPEX-------01"" contractId=""651"" side=""BUY"" px=""500"" qty=""50000"" initialQty=""50000"" ordrExeRestriction=""AON"" txt="""" dlvryAreaId=""10YBE----------2"" clOrdrId=""d95c7847-906c-4ddc-b2ca-660aad63467d"" preArranged=""false"" type=""B"" state=""ACTI"" usrCode=""TRD002"" revisionNo=""1"" revisionNoTime=""2021-02-03T09:56:37.919Z"" timestmp=""2021-02-03T09:56:37.919Z"" validityDate=""2021-02-03T12:00:00.000Z"" validityRes=""GFS"" action=""UADD"" lastUpdateUsrInfo=""BG-EPEX-------01TRD002""/>
    </OrdrList>
</OrdrExeRprt>{code}

* *ContractInfoRprt  is generated*
** Revison : revisionNo=""0""
{code}<?xml version=""1.0"" encoding=""UTF-8""?>
<ContractInfoRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <ContractList>
        <Contract contractId=""651"" prod=""XBID_Hour_Power"" name=""14-19"" longName=""20210203 14:00-20210203 19:00"" dlvryStart=""2021-02-03T13:00:00.000Z"" dlvryEnd=""2021-02-03T18:00:00.000Z"" predefined=""false"" revisionNo=""0"" state=""ACTI"" tradingPhase=""CONT"" duration=""5.0"" actPoint=""2021-02-02T13:00:00.000Z"" expPoint=""2021-02-03T13:00:00.000Z"">
            <DlvryAreaState dlvryAreaId=""10YMA-ONE------O"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10YCH-SWISSGRIDZ"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TSDA9----------J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TS-DA3---------9"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10YAT-APG------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            ...
        </Contract>
    </ContractList>
</ContractInfoRprt>{code}
* *SOB : Set Service Halt/Active* - ContractInfoRprt will be gerated
** verify revisionNo=""1""
{code}<Contract contractId=""651"" prod=""XBID_Hour_Power"" name=""14-19"" longName=""20210203 14:00-20210203 19:00"" dlvryStart=""2021-02-03T13:00:00.000Z"" dlvryEnd=""2021-02-03T18:00:00.000Z"" predefined=""false"" revisionNo=""1"" state=""HIBE"" tradingPhase=""CLSD"" duration=""5.0"" actPoint=""2021-02-02T13:00:00.000Z"" expPoint=""2021-02-03T13:00:00.000Z"">
            <DlvryAreaState dlvryAreaId=""TS-DA2---------K"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10YDK-2--------M"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10Y1001A1001D582"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10Y1001A1001A45N"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10Y1001A1001A46L"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TSDA13---------Y"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""IT-NORD--------N"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TSDA11---------J"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10Y1001A1001A44P"" state=""HIBE"" tradingPhase=""CLSD"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
         ...
            {code}
** verify revisionNo=""2""
{code}<Contract contractId=""651"" prod=""XBID_Hour_Power"" name=""14-19"" longName=""20210203 14:00-20210203 19:00"" dlvryStart=""2021-02-03T13:00:00.000Z"" dlvryEnd=""2021-02-03T18:00:00.000Z"" predefined=""false"" revisionNo=""2"" state=""ACTI"" tradingPhase=""CONT"" duration=""5.0"" actPoint=""2021-02-02T13:00:00.000Z"" expPoint=""2021-02-03T13:00:00.000Z"">
            <DlvryAreaState dlvryAreaId=""10YMA-ONE------O"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10YCH-SWISSGRIDZ"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TSDA9----------J"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TS-DA3---------9"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""10YAT-APG------L"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""TSDA16---------1"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""IT-MALT0-------R"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            <DlvryAreaState dlvryAreaId=""IT-CSUD--------B"" state=""ACTI"" tradingPhase=""CONT"" tradingPhaseStart=""2021-02-02T13:00:00.000Z"" tradingPhaseEnd=""2021-02-03T12:00:00.000Z""/>
            ...
{code}


* Do modification of Block order contract : change price and quantity
* No ContractInfoRprt is generated and also it has no impact at versioning",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMXBID CLONE: Shipping module issues,XP-2395,89705,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,yo218,wn626,wn626,26/Nov/19 10:06,13/Aug/20 19:51,22/Feb/21 13:26,20/Dec/19 15:14,,,Pre2020,,,,,,,waiting-customer,,,,"Around 6.30 AM UTC and 3.30 PM UTC today we had
 503 HTTP error while trying to access DBAG Shipping module.

 

 

Example of errors

 

com.nordpool.shipbridge.error.ShipbridgeException:
 <503,<!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">

org.springframework.web.client.ResourceAccessException:
 I/O error on GET request for ""https://10.103.1.11:60003/spm/wsapi/v1/files/search/findByAck"":
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target; nested exception is
 javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException:
 PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:
 unable to find valid certification path to requested target

Caused by: javax.net.ssl.SSLHandshakeException:
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target

        at
 sun.security.ssl.Alerts.getSSLException(Alerts.java:192) ~[?:1.8.0_202]

Caused by: sun.security.validator.ValidatorException:
 PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:
 unable to find valid certification path to requested target

Caused by:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target

org.springframework.web.client.ResourceAccessException:
 I/O error on GET request for ""https://10.103.1.11:60003/spm/wsapi/v1/files/search/findByAck"":
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target; nested exception is
 javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException:
 PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:
 unable to find valid certification path to requested target

Caused by: javax.net.ssl.SSLHandshakeException:
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to request

 

 

org.springframework.web.client.ResourceAccessException:
 I/O error on GET request for ""https://10.103.1.11:60003/spm/wsapi/v1/isAlive"":
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target; nested exception is javax.net.ssl.SSLHandshakeException:
 sun.security.validator.ValidatorException: PKIX path building failed:
 sun.security.provider.certpath.SunCertPathBuilderException: unable to find
 valid certification path to requested target

Caused by: javax.net.ssl.SSLHandshakeException:
 sun.security.validator.ValidatorException: PKIX path building fail",,qo794,wn626,yo218,,,,,,,,,,,,,,,,,,,,,SMXBID-1643,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,Critical Incident,,,,,,37065600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,25/Nov/19 20:26,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:sm",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],Home Office Team Sprint 40,Christmasprint,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/19 10:07;wn626;What is the UserID which you are using?","26/Nov/19 10:07;markus.laine@nordpoolgroup.com;Dear Laroslav,

The User ID is NPADM002

Best regards,

Markus Laine","26/Nov/19 10:25;qo794;h2. Summary of investigation during oncall shift
All times below are from Kibana thus in CET
* 3 time slots on 25.11.2019 when user {{NPADM002}} received plenty of {{503}} when accessing SPM WS API: 7:30, 16:20 and 17:10, some examples from Kibana
{code:title=/xbid/logs/xbid-prod-spm-wbc1/xb_xbid_prod_web-spm-1_access_ixe_2019-11-25_00.log}
November 25th 2019, 17:11:03.41710.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:03.417 +0100 3811 ""GET /spm/wsapi/v1/isAlive HTTP/1.1"" 503 299
November 25th 2019, 17:11:03.18910.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:03.189 +0100 4022 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 17:11:03.01810.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:03.018 +0100 3391 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 17:11:02.42510.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:02.425 +0100 4096 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 17:11:02.25510.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:02.255 +0100 3622 ""GET /spm/wsapi/v1/files/2226269024/content HTTP/1.1"" 503 299
November 25th 2019, 17:11:01.66710.103.4.2 - NPLTSSM2 25/Nov/2019 17:11:01.667 +0100 3882 ""GET /spm/wsapi/v1/files/2226274024/content HTTP/1.1"" 503 299
{code}
{code:title= /xbid/logs/xbid-prod-spm-wbc5/xb_xbid_prod_web-spm-5_access_ixe_2019-11-25_00.log}
November 25th 2019, 16:20:56.85410.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:56.854 +0100 4351 ""GET /spm/wsapi/v1/files/2223050024/content HTTP/1.1"" 503 299
November 25th 2019, 16:20:56.30010.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:56.300 +0100 3867 ""GET /spm/wsapi/v1/files/2223036024/content HTTP/1.1"" 503 299
November 25th 2019, 16:20:56.06210.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:56.062 +0100 3620 ""GET /spm/wsapi/v1/files/2223037024/content HTTP/1.1"" 503 299
November 25th 2019, 16:20:54.50510.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:54.505 +0100 4304 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 16:20:53.91810.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:53.918 +0100 3832 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 16:20:53.73110.103.4.2 - NPLTSSM2 25/Nov/2019 16:20:53.731 +0100 3548 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
{code}
{code:title=/xbid/logs/xbid-prod-spm-wbc5/xb_xbid_prod_web-spm-5_access_ixe_2019-11-25_00.log}
November 25th 2019, 07:31:04.29510.103.4.2 - IBEXSM02 25/Nov/2019 07:31:04.295 +0100 4160 ""GET /spm/wsapi/v1/isAlive HTTP/1.1"" 503 299
November 25th 2019, 07:31:04.05110.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:04.051 +0100 4061 ""GET /spm/wsapi/v1/isAlive HTTP/1.1"" 503 299
November 25th 2019, 07:31:03.87310.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:03.873 +0100 4432 ""POST /spm/wsapi/v1/files/ack HTTP/1.1"" 503 299
November 25th 2019, 07:31:03.31910.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:03.319 +0100 3691 ""GET /spm/wsapi/v1/files/2199945024/content HTTP/1.1"" 503 299
November 25th 2019, 07:31:03.12710.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:03.127 +0100 3774 ""GET /spm/wsapi/v1/files/2199956024/content HTTP/1.1"" 503 299
November 25th 2019, 07:31:02.56610.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:02.566 +0100 4507 ""GET /spm/wsapi/v1/files/2199951024/content HTTP/1.1"" 503 299
November 25th 2019, 07:31:02.36910.103.4.2 - NPLTSSM2 25/Nov/2019 07:31:02.369 +0100 3615 ""GET /spm/wsapi/v1/files/2199948024/content HTTP/1.1"" 503 299
{code}

* But some of the requests were processed correctly even during the time slots with problems:
{code:title=/xbid/logs/xbid-prod-smi1/xb_xbid_prod_smi-1_standard_ixe.log}
November 25th 2019, 17:11:02.957 INFO Processing acknowledgement for file header 2226155024, incomingAck Ack{3b94c3ce771baab34849ed68ea2f6380,752,Pos} with reason code A01. NPLTSSM2
{code}

* no similar symptoms like in TECHLOG-783 found, ""{{ajp_ilink_receive failed}}"" appeared only once (and not during the problems):
{code:title=/xbid/logs/xbid-prod-spm-wbc5/xb_xbid_prod_web-spm-5_error_ixe_2019-11-25_00.log}
November 25th 2019, 17:20:11.572E RROR AH00992: ajp_read_header: ajp_ilink_receive failed
{code}

* no issues found on SMI1/2 during the time slots in question","26/Nov/19 15:59;yo218;My first assumption is that we could have reached the thread limit of 150 for tomcat. Just NP fetched 153 files within that minute:
{noformat}
 tomcat@xbprodsmi1:[/xbid/logs/xbid-prod-smi1]$ zcat rollover/xb_xbid_prod_smi-1_standard_ixe_0_2019-11-25.log.gz | grep NPLTSSM2 | grep 25T15:10  | wc -l
153
{noformat}","27/Nov/19 09:34;wn626;Guys, we already breached SLA for this issue. Anything we can do to prioritize the issue?","27/Nov/19 10:28;yo218;It has already priority. We are currently working on improving the monitoring to be able to view the thread usage which would proof my theory. In parallel we can prepare a pr for increasing the limit which will need to be staged from test to prod","27/Nov/19 10:40;wn626;We got a new comment from the customer with details, maybe it will help somehow - https://jira.deutsche-boerse.com/browse/SMXBID-1643?focusedCommentId=254786&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel\#comment-254786","27/Nov/19 12:53;yo218;Ticket for monitoring improvement: TECHLOG-3042 

The limit of threads is 256, so without monitoring I can't tell whether this was really reached. I would propose to increase the loglevel of the webservers in order to receive more details. I would propose one of the following options:
 * Move the analysis to a non prod environment and increase the loglevel there (is the customer able to reproduce this behavior in any non prod environment?)
 * Customer will use URL of datacenter 2 and we will increase the loglevel only on those webservers. It would decrease the risk of impacting anyone else who is using the primary webservers. This can be done without any downtime","27/Nov/19 13:08;wn626;I don't think that first option can help somehow. You are saying ""reproduce this behavior"", but they are not doing anything specific, they are just trying to connect to SM and getting message that it's unavailable.

If everybody else are fine, let's try to do second option. Can you tell me the URL of datacenter 2 to provide it to the customer?","27/Nov/19 13:16;yo218;They are not ""just trying to connect to SM and getting message that it's unavailable"" but they are opening hundreds of connections with their client within one minute in order to retrieve the files one by one. And then, probably after exceeding some limits (at least that is our current assumption), SM or the webserver blocks connections for a while. So with ""reproduce this issue"" I was referring to create the same amount of files and fetching them in the same manner in a different environment

 

Second URL is 10.103.1.11:60003/spm","27/Nov/19 13:25;wn626;Ok, thanks. Let me discuss with them","27/Nov/19 16:24;wn626;Hi [~qo794],

 

Customer said that this issue was raised previously in https://jira.deutsche-boerse.com/browse/SMXBID-1207, and they expect it to be fixed in XBID 2.0.

Do you know anything about it?

Maybe fix was not successful?","27/Nov/19 16:27;wn626;They also want to know what kind of limits we are breaching. Can you please advise? Do we have it in the documentation somewhere?","28/Nov/19 07:00;yo218;It is about maximum allowed parallel connections, it is nothing which was described or specified somewhere, just some basic system limits of apache and tomcat modules. With 2.0 we increased the limit to 256 as it fixed the issue when it happened in LIP A. But it seems that they have even more requests in Prod environment now. This issue seems to be limited to the used client of the customer, we were not able to reproduce it yet. The best solution would be the customer would change the way how the client is connecting and fetching the files, but I understand that this won't happen in a day or two.","28/Nov/19 11:48;wn626;[~yo218], see latest reply from NordPool:

""Shipbridge has 2 URLs, one primary and one secondary. It is using the primary by default. When this error (503 Service unavailable) is received, we/Nord Pool tries to switch over to the secondary URL - and we are having issues with it.

The question would be: if the service is temporarily blocked due to a throttling breach (too much REST calls), do they block both URLs, or only the one that has been used (the primary)? And, in this situation, how much time the blocking lasts? Is it 1 minute?""

 

Can you advise?","28/Nov/19 12:57;yo218;Yes, it seems to be blocked for one minute. It looks like only the single used webserver is blocking connections from the single user only after reaching this limit. I could see successfully connections for different usernames while the NP user was blocked and at the same time successfully connections from the NP user on the other two webservers (we have three per dc). So switching to the different datacenter should be a proper workaround until either the client behaves different or until we updated the limits to a proper limit (impact analyzes and tests would be required).    ","04/Dec/19 14:05;wn626;Hi [~yo218],

 

Can we try to increase the logging in Private Cute 8 (Cute H) to try to catch the issue?","04/Dec/19 14:07;yo218;yes, this would be possible [~wn626]. But it will cause a short interruption of the service as we have only one webserver on CuTe environments. Just confirm and I will do it (or raise a deployment request)","05/Dec/19 11:05;wn626;HI [~yo218], please go ahead and let me know once done","05/Dec/19 11:15;yo218;Loglevel has been increased:
{noformat}
apache@xbcutsweb1:[/shrd]$ cat /shrd/xbid-ctph-spm-web1/config/httpd.conf | grep LogLevel
# LogLevel: Control the number of messages logged to the error_log.
LogLevel debug
apache@xbcutsweb1:[/shrd]$ /shrd/xbid-ctph-spm-web1/stop.sh
apache@xbcutsweb1:[/shrd]$ /shrd/xbid-ctph-spm-web1/start.sh
 {noformat}","09/Dec/19 07:57;yo218;Hi [~wn626], please ask the customer whether they are already trying to reproduce the error in Cute H. The filesystem is growing quite heavily due to the log level increase and we can't keep it this way forever. There are no 503 errors in CuTe H yet but I don't know whether they are trying already. And the last occurrence of the 503 in Prod is from 25th of November. Please ask them whether they changed something on their side","11/Dec/19 15:25;wn626;Hi [~yo218],

 

First of all, please decrease log level to normal value.

 

And the question. Can we increase the maximum allowed parallel connection From 256 to 512 per minute on the CuTe H ENV?","12/Dec/19 08:44;yo218;Decreased the loglevel back to the initial level. 

And yes, we can decrease the amount on this environment anytime. Restart of the Shipping Module backend is required.","17/Dec/19 12:32;yo218;Hi [~wn626],

I don't like the approach from the customer to just increase the value on all environments. Right now it is just an assumption that it could help. I would propose to stick to our plan that the customer should try to reproduce the error on their environment, then we could increase it there and see whether it helps. What do you think? ","17/Dec/19 15:10;wn626;Hi [~yo218],

 

I also think that it would be good to reproduce the error on any environment first, but we cannot force Nordpool to do it. It's our software and we should be able to tell if it's going to work with new value correctly or not.

And of course, we are not going just to increase the value on all environments.

I already talked to [~ei349] regarding this issue. I expect OPSCOM to contact DBAG officially with confirmation that they want to implement this change, and after it XBID DEV team will do a full round of testing before updating it in prod.

 ","20/Dec/19 15:14;yo218;external ticket has been closed",,,,,,,,,,,,
SMXBID CLONE - SM Module: Missing ACK,XP-2389,89603,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ub113,yo218,yo218,22/Nov/19 11:17,13/Aug/20 19:41,22/Feb/21 13:26,16/Mar/20 11:01,,,3.1.0,,,,,,01/Oct/19 00:00,TO4XBID,XBID-ServiceDesk,,,"
TransnetBW uploaded new email certificates for communication with Shipping Module PROD.

They encrypt the certificate with ""RSASSA-PSS (1.2.840.113549.1.1.10)"" due to regulation of the German NRA we

They receive the CTS Files via mail form the Address ""xbprod-spm@xbid.deutsche-boerse.com"" and send the ACK back to this Mail Address.

When checked the File Exchange View of the SM Prod environment, there is a message ""Missing ACK""

Can you check if we receive TransnetBW ACK?


",,qo794,ub113,yo218,,,,,,,,,,,,,,,,,,,,,TECHLOG-2840,,,,,,,,,,,,SMXBID-1454,,,,,,,"22/Nov/19 11:17;yo218;20191108_A01_11XID-CAPACITY-9_10XDE-ENBW--TNGX_167_ACK_2019-11-08T09-50-25Z.xml;https://jira.deutsche-boerse.com/secure/attachment/77562/20191108_A01_11XID-CAPACITY-9_10XDE-ENBW--TNGX_167_ACK_2019-11-08T09-50-25Z.xml","22/Nov/19 11:17;yo218;20191108_A01_11XID-CAPACITY-9_10XDE-ENBW--TNGX_167_ACK_2019-11-08T09-50-26Z.xml;https://jira.deutsche-boerse.com/secure/attachment/77563/20191108_A01_11XID-CAPACITY-9_10XDE-ENBW--TNGX_167_ACK_2019-11-08T09-50-26Z.xml","22/Nov/19 11:17;yo218;20191108_CTS_4018_11XID-CAPACITY-9_TNG_TNG_167_2.xml;https://jira.deutsche-boerse.com/secure/attachment/77564/20191108_CTS_4018_11XID-CAPACITY-9_TNG_TNG_167_2.xml","22/Nov/19 11:17;yo218;20191108_CTS_4021_11XID-CAPACITY-9_TNG_TNG_167_2.xml;https://jira.deutsche-boerse.com/secure/attachment/77565/20191108_CTS_4021_11XID-CAPACITY-9_TNG_TNG_167_2.xml","11/Dec/19 14:45;ub113;Dok1.docx;https://jira.deutsche-boerse.com/secure/attachment/78484/Dok1.docx","27/Nov/19 10:00;ub113;XBID_SM_fehlende_ACK.docx;https://jira.deutsche-boerse.com/secure/attachment/77740/XBID_SM_fehlende_ACK.docx","28/Nov/19 16:05;ub113;XBID_SM_fehlende_ACK_Answer_IT.docx;https://jira.deutsche-boerse.com/secure/attachment/77836/XBID_SM_fehlende_ACK_Answer_IT.docx","22/Nov/19 11:17;yo218;XBid_FileList.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77566/XBid_FileList.xlsx","22/Nov/19 11:17;yo218;fahrplan_transnetbw-hsl.de.pem;https://jira.deutsche-boerse.com/secure/attachment/77567/fahrplan_transnetbw-hsl.de.pem",,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29635200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a9h9:zzr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],Home Office Team Sprint 40,Christmasprint,HOT Sprint 4 (S),,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/19 11:30;yo218;Imported the CA to the spm.jks. Uploaded the keystore to xbprodsmi1/2, alligned on arestart with dev/bizops/acm and restarted the tomcat processes","27/Nov/19 10:01;ub113;Hi [~yo218]

We got an update that the issue is still there:

 

_When I looked in the Send File View of the SM Module the ACK of TransnetBW are still missing._
_See atteced sreen shot_

[^XBID_SM_fehlende_ACK.docx]","27/Nov/19 10:32;qo794;SMI is till not able to process emails from {{fahrplan@transnetbw-hsl.de}}, they are not signed correctly:
{code:java}
November 27th 2019, 10:06:29.801Was not able to process incoming email message [ message: [fahrplan@transnetbw-hsl.de] 20191127_A01_11XID-CAPACITY-9_10XDE-ENBW--TNGX_164_ACK_2019-11-27T09-05-21Z.xml [sign] [encrypt] ]
java.lang.IllegalStateException: The email message signature is not valid
	at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverter.decryptAndVerify(SMIMEConverter.java:80)
	at com.deutscheboerse.m7.shipping.ack.AckReceiverEmail.processMessages(AckReceiverEmail.java:99)
	at com.deutscheboerse.m7.shipping.ack.AckReceiverEmail.readAndProcess(AckReceiverEmail.java:83)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:93)
{code}
Ask the customer what certificate (s)he uses when signing emails, a private key associated with the public key uploaded to SPM must be used.","28/Nov/19 16:05;ub113;Hi [~qo794]

 

This is the answer we got from Transnet:

[^XBID_SM_fehlende_ACK_Answer_IT.docx]","29/Nov/19 09:57;qo794;The fingerprints are the same as the uploaded certificate in SPM, so it seems correct.
BTW emails from the customer are neither processed by CMI as they are not signed:
{code:java}
2019-11-28T13:00:46.010Z [TaskScheduler-7][][] INFO  c.d.e.c.t.m.MimeMessageTransformer - From : fahrplan@transnetbw-hsl.de, subject: 20191129_RID_TNG-RTE_001_ACK_2019-11-28T13-00-23Z.xml [not signed]
2019-11-28T13:00:46.012Z [TaskScheduler-7][][] INFO  c.d.e.c.t.m.MimeMessageTransformer - Email encryption is enabled for 10XDE-ENBW--TNGX, email being processed is required to be encrypted and signed
2019-11-28T13:00:46.012Z [TaskScheduler-7][][] INFO  c.d.e.c.t.m.SMIMEConverter - Email message decrypting
2019-11-28T13:00:46.015Z [TaskScheduler-7][][] INFO  c.d.e.c.t.m.SMIMEConverter - Email message signature veryfing
2019-11-28T13:00:46.019Z [TaskScheduler-7][][] ERROR c.d.e.c.t.m.SignedMailUtils - Failed to verify e-mail signature. Reason: [The certificate path is invalid.]
2019-11-28T13:00:46.022Z [TaskScheduler-7][][] ERROR c.d.e.c.t.m.MailHandler - Could not process message 20191129_RID_TNG-RTE_001_ACK_2019-11-28T13-00-23Z.xml [not signed] from [fahrplan@transnetbw-hsl.de]
java.lang.IllegalStateException: The email message signature is not valid
        at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverter.decryptAndVerify(SMIMEConverter.java:80)
        at com.deutscheboerse.energy.cmminteg.transport.mail.MimeMessageTransformer.createFileDescriptor(MimeMessageTransformer.java:77)
        at com.deutscheboerse.energy.cmminteg.transport.mail.MailHandler.receive(MailHandler.java:103)
        at sun.reflect.GeneratedMethodAccessor353.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)
        at com.deutscheboerse.energy.failover.aop.SkipExecutionIfNotMasterAspect.aroundHandler(SkipExecutionIfNotMasterAspect.java:41)
        at sun.reflect.GeneratedMethodAccessor351.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
        at com.sun.proxy.$Proxy169.receive(Unknown Source)
        at sun.reflect.GeneratedMethodAccessor366.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:93)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{code}","05/Dec/19 09:40;ub113;Client cannot extract the email that they are sending to SM.

 ","09/Dec/19 09:02;yo218;[~ub113] How to proceed here? We just can see that the customer is doing it wrong, but we don't see what exactly they are doing. We can't check the mail on the mail gateway as the application is fetching (and deleting) them directly. So we can't help them at the moment but to advise to compare the current situation and the current certificates with the one that has been used before as it was working for them already  ","10/Dec/19 11:10;yo218;EDIT: that's probably just related to the mentioned issue in CMI. But the original issue is about SMI...

I can't see their public cert in the CMI database. Can you please ask the customer to confirm that they uploaded it in the WebGUI and to provide a screenshot?

Details as provided in the Email Communication Guide: 
 # Log in to CMM with a user having the Reference Data Admin role assigned
 # Navigate to _Reference Data Management -> Market Setup -> TSO Management_, select the TSO and press _Modify_
 # _(...)_

 ","10/Dec/19 11:29;yo218;Our system is just providing the following error: ""The email message signature is not valid"" which sounds like a problem with the used certificate or with the configuration of customers mail client, that's all we can tell for now.

What about the test or simulation environments? Do they have new certificates for them as well? If we could try to reproduce this issue in some other environment, we would be able to react faster in case restarts etc are required on our side and customer would be able to send more testmails or try around on their side with signing the email properly","11/Dec/19 14:45;ub113;Hello [~yo218]

We received the update from Transnet:

_Could you send us a detailed report to this error?_

_I updated the certificate in te Shipping module._
 _The certificate has the file Type ""cer""._
 _Is this the correct Filte Type?_
 _The configuration in the Shipping Module see atteched file._

_Its correct that you can not see our public certificate in the CMI Database._
 _TransnetBW has no function ""leading interconnetor"" at any actuall XBID Border._ 
 _Due to this we dit not receive any Filles from the CMI._

_Kind regared_ 
 [^Dok1.docx]","11/Dec/19 14:52;yo218;Hi [~ub113]

here the latest error message (timestamp: December 11th 2019, 14:49:37.091):
{noformat}
Was not able to process incoming email message [ message: [fahrplan@transnetbw-hsl.de] 20191211_TPS_11XEEX--MIA----J_10XDE-ENBW--TNGX_182_ANO_2019-12-11T13-48-52Z.xml [sign] ]
java.lang.IllegalStateException: The email message signature is not valid
	at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverter.decryptAndVerify(SMIMEConverter.java:80)
	at com.deutscheboerse.m7.shipping.ack.AckReceiverEmail.processMessages(AckReceiverEmail.java:99)
	at com.deutscheboerse.m7.shipping.ack.AckReceiverEmail.readAndProcess(AckReceiverEmail.java:83)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:93)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748) {noformat}","11/Dec/19 14:52;yo218;the certificate type should be ok","12/Dec/19 10:00;qo794;This is actually not correct:
{quote}
Its correct that you can not see our public certificate in the CMI Database.
TransnetBW has no function ""leading interconnetor"" at any actuall XBID Border.
Due to this we dit not receive any Filles from the CMI.
{quote}
I can see in logs that CMI sends RID files to *fahrplan@transnetbw-hsl.de* and the customer sends *not-signed* ACKs back - these ACKs are discarded and not processed at all as they are not signed:
{code}
December 12th 2019, 05:38:51.015 INFO From : fahrplan@transnetbw-hsl.de, subject: 20191212_RID_TNG-RTE_008_ACK_2019-12-12T04-38-28Z.xml [not signed]
{code}
If the customer does not want to receive files, please tell them to delete the outbound file configuration in CMI. Thanks.","16/Mar/20 10:57;yo218;[~ub113] can we please close the ticket? Customer doesn't seem to have any interest in proceeding on this topic anymore...","16/Mar/20 11:00;ub113;Hi [~yo218]

Let's close internal ticket. ",,,,,,,,,,,,,,,,,,,,,,,
Fix Copy dumps jop for individual cutes,XP-2387,89598,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,yo218,yo218,22/Nov/19 10:24,06/Nov/20 09:26,22/Feb/21 13:26,25/Nov/19 12:51,,,Pre2020,,,,,,,TechOps,,,,"[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-Copy%20journal%20and%20dumps%20to%20EBSM/329/console]

For some environments it still tries to connect to the old DB host: 
{noformat}
+ ssh -o StrictHostKeyChecking=no umgrcopy@xbidtestpg12-ctsoall.deutsche-boerse.de
Pseudo-terminal will not be allocated because stdin is not a terminal.
ssh: connect to host xbidtestpg12-ctsoall.deutsche-boerse.de port 22: No route to host {noformat}",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39312000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09w30:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Nov/19 12:51;yo218;Fixed invalid configuration and executed the job manually. It finished with status ""Success"" and I couldn't find any errors

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/EBSM/job/XBID-Copy%20journal%20and%20dumps%20to%20EBSM/333/console]","25/Nov/19 12:52;yo218;[~qo794] FYI",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[XBID PROD]sFTP access request for PMI logger ,XP-2386,89597,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ub113,yo218,yo218,22/Nov/19 10:09,12/Aug/20 13:56,22/Feb/21 13:26,10/Dec/19 09:29,,,Pre2020,,,,,,29/Nov/19 00:00,TO4XBID,,,,"TWG FTF would like to ask DBAG for creation of access to sFTP server on PROD environment for PMI LAT operated by Minsait.
 * For creation of the user and prividing the access is needed:
 * User name:  *xbid_minsait_prod* 
 * SSH key and IP: attached
 * {color:#172b4d}source IP address of the connection - 194.140.78.155{color}",,yo218,,,,,,,,,,";16/Dec/19 16:14;ub113;1800",,,0,1800,,,0,1800,,,,,TECHLOG-3026,,,,,,,,,,,,,,,,,,,"22/Nov/19 10:25;yo218;production.pub;https://jira.deutsche-boerse.com/secure/attachment/77555/production.pub",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38016000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010422008s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/19 11:04;yo218;raised FW-request #320068","22/Nov/19 14:32;yo218;User has been created with the provided key, PMI log file distribution is enabled. Now we are just waiting for the implementation of the firewall rule","09/Dec/19 09:15;yo218;CCI breached the SLA, I've sent an email to them just now","10/Dec/19 09:28;yo218;FW rule has been implemented",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA reports - November,XP-2369,89377,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,19/Nov/19 15:03,06/Nov/20 09:27,22/Feb/21 13:26,09/Dec/19 09:58,,,Pre2020,,,,,,,,,,,"Please provide SLA reports as usual
*Please check linked Jira ticket - the templates have been modified*

*Please keep in mind, we would be able to provide Public Order Book Delta report since November*",,ek176,qo794,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/19 13:03;qo794;XBID Performance and SM SLA Reporting November 2019-sla2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78001/XBID+Performance+and+SM+SLA+Reporting+November+2019-sla2.xlsx","03/Dec/19 13:04;qo794;XBID Performance and SM SLA Reporting November 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78002/XBID+Performance+and+SM+SLA+Reporting+November+2019.xlsx","02/Dec/19 12:44;qo794;XBID Service Boundary Reporting November 2019-localhost-sla-1.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77939/XBID+Service+Boundary+Reporting+November+2019-localhost-sla-1.xlsx","03/Dec/19 09:05;qo794;XBID Service Boundary Reporting November 2019-localhost.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77960/XBID+Service+Boundary+Reporting+November+2019-localhost.xlsx","02/Dec/19 12:44;qo794;XBID Service Boundary Reporting November 2019-sla1.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77938/XBID+Service+Boundary+Reporting+November+2019-sla1.xlsx","03/Dec/19 15:59;qo794;XBID Service Boundary Reporting November 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78012/XBID+Service+Boundary+Reporting+November+2019.xlsx","03/Dec/19 15:50;qo794;XBID_Credit_points_report_November_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/78009/XBID_Credit_points_report_November_2019.xlsx",,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38534400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09wiu:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/19 12:32;qo794;Problems encountered regarding reports generation:
* no logs from xbprodsla1/2 on ebsm server
* collect-added-orders-data job is failing every day on xbprodsla2 - XP-2366
{code:java}
2019-12-01T03:03:13.461Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-added-orders-data in job collect-boundary-sla-data
java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}
* due to the point above data for Explicit Allocation Requests sheet is not collected on xbprodsla2
* credit points report generation (collect-credit-points-data job) failed:
{code:java}
2019-12-01T05:04:09.746Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-credit-points-data in job credit-points
java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}
The root cause is the same as in the first point, see XP-2366","02/Dec/19 12:39;qo794;h3. Generated reports on PROD
* Complete [^XBID Performance and SM SLA Reporting November 2019-sla2.xlsx]  from xbprodsla2 - missing 30.11. (x)
* Incomplete   [^XBID Service Boundary Reporting November 2019-sla1.xlsx]  from xbprodsla1 - missing 2nd wave boundaries (x)
* Credit points report missing (x)

h3. TODO manually on localhost
* generate Service Boundary report from xbprodsla1 DB -  [^XBID Service Boundary Reporting November 2019-localhost-sla-1.xlsx] (/)
* collecting data from Elastic to local DB for the whole month (/)
* computing values for Explicit Allocation Request sheet (/)
* generating Service Boundary report with Explicit Allocation Requests sheet only -  [^XBID Service Boundary Reporting November 2019-localhost.xlsx]  (/)
* compose final Service Boundary report by copying the sheet from the previous step and the report generated locally from xbprodsla1 -  [^XBID Service Boundary Reporting November 2019.xlsx] (/)
* generate Performance and SM SLA report from xbprodsla2 DB -  [^XBID Performance and SM SLA Reporting November 2019.xlsx]  (/)
* import xbprodcor DB (/)
* collect ALL_ORDERS_TRANSACTIONS data (/)
* generate Credit points report from xbprodsla2 DB -  [^XBID_Credit_points_report_November_2019.xlsx] (/)","03/Dec/19 12:23;qo794;h2. Final reports
* [^XBID_Credit_points_report_November_2019.xlsx] (/) - only rename DEGRADED to RTS3B
*  [^XBID Performance and SM SLA Reporting November 2019.xlsx] (/)
*  [^XBID Service Boundary Reporting November 2019.xlsx] (/)

[~zi174] please review them, if they are correct, send them out. thanks.","04/Dec/19 09:27;zi174;From development point of view (export from the application) the reports are OK",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Core down with block orders,XP-2367,89332,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,18/Nov/19 17:38,06/Nov/20 11:00,22/Feb/21 13:26,19/Nov/19 19:00,,,Pre2020,,,,,,,,,,,"Core fails when inserting block order.

 

During the block order entry persistence:
 # A new block contract is inserted
 # An order referencing that contract is inserted

 

For some reason, the Contract insert did not work and DB fails on FK constraint check:
{code:java}
Caused by: java.sql.BatchUpdateException: Batch entry 2 insert into xbperfcor.CX_100_ORDER (VERSION, INITIAL_ORDER_ID, MOD_TYPE_CODE, LAST_UPDATE_TIME, LAST_UPDATE_USER, ACTION, ORDER_TYPE_CODE, BUY_CODE, CONTRACT_ID, QUANTITY, HIDDEN_QUANTITY, PEAK_SIZE_QUANTITY, EXECUTION_PRICE, VALIDITY_RESTRICTION, EXPIRATION_
DATE, RESTRICTION_CODE, TEXT, ORDER_ENTRY_TIME, BALANCING_GROUP_EIC, USER_ID, USER_CODE, TARGET_BG_EIC, TSO_AREA_EIC, DELIVERY_START_DATE, DELIVERY_END_DATE, CLIENT_ORDER_ID, INITIAL_QUANTITY, PARENT_ID, LIST_EXEC_INST, BASKET_ID, PEAK_PRICE_DELTA, EX_GDT, ORDER_ID) values (1, 63123, 'ACTI', '2019-11-18 15:01:59.3
18+00', 'BG-BGPX-------01TRD001', 'UADD', 'B', 'B', 855, 40000, 0, 0, 5000, 'GFS', '2019-11-18 23:00:00+00', 'AON', 'Hub L|ADD|B02Bas', '2019-11-18 15:01:59.318+00', 'BG-BGPX-------01', 5, 'TRD001', NULL, '10Y1001A1001A46L', '2019-11-18 23:00:00+00', '2019-11-19 01:00:00+00', 'rtsp4|rts3-|H01A0HrlB02Bas|1627|k34jv
vvw', 40000, NULL, 'NONE', 0, 0, NULL, 63123) was aborted: ERROR: insert or update on table ""cx_100_order"" violates foreign key constraint ""fk_srbbra5iqh37shn6ni4d9rjtl"" {code}
 

The problem is easily reproducible, just run core with {{losses-15min-perf-data}} and replay the attached journal. Full logs available on {{xbidperfcor1}}

There's also misleading NPE in the logs raised when Persister falls back to sequential method, which is a bug also, but probably not a root cause.

{code}
2019-11-18 17:19:08.150  INFO 7238 --- [      Persister] .d.e.m.c.p.e.SequencePersistenceExecutor : Executing com.deutscheboerse.energy.m7.trade.order.modify.task.OrderModifyByIdsTask@3cfff8c1
2019-11-18 17:19:08.151 ERROR 7238 --- [      Persister] .d.e.m.c.p.e.SequencePersistenceExecutor : Tx failed, rolling back. Detail:

java.lang.NullPointerException: null
	at com.deutscheboerse.energy.m7.core.persistance.executor.SequencePersistenceExecutor.persistInTransaction(SequencePersistenceExecutor.java:69) ~[classes/:na]
	at com.deutscheboerse.energy.m7.core.persistance.executor.BatchPersistenceExecutor.persistInTransaction(BatchPersistenceExecutor.java:73) [classes/:na]
	at com.deutscheboerse.energy.m7.core.persistance.HibernatePersistService.save(HibernatePersistService.java:18) [classes/:na]
	at com.deutscheboerse.energy.m7.core.out.Persister.persistContextData(Persister.java:91) [classes/:na]
	at com.deutscheboerse.energy.m7.core.out.Persister.doOnEvent(Persister.java:72) [classes/:na]
	at com.deutscheboerse.energy.m7.core.out.Persister.doOnEvent(Persister.java:26) [classes/:na]
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:72) [classes/:na]
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:29) [classes/:na]
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128) [disruptor-3.3.2.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_202]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_202]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_202]
{code}
 

 

 

 

 

 

 ",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/19 17:39;ll664;jnrl.bkp.zip;https://jira.deutsche-boerse.com/secure/attachment/77244/jnrl.bkp.zip",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,18/Nov/19 17:38,,,,,,,,,,,,,,,,,,,,,,,"1|y09umw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 39,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Nov/19 09:22;qo794;Replied locally and working fine, DB entries are in the correct order - the contract for the block order is inserted first, the order is the last entry.","19/Nov/19 14:27;qo794;After discussion it's clear that the core down was caused by the NPE.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix memory leak on Report Tool,XP-2366,89293,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,uv683,uv683,18/Nov/19 09:37,06/Nov/20 10:25,22/Feb/21 13:26,06/Dec/19 08:48,,,Pre2020,,SLA Report Tool,,,,,,,,,"When Report Tool collects computed totals every day in the night, it fails on all orders metrics with some heap space issue. It is visible in logs on xbprodsla2. Version 2.18 running on xbprodsla1 is fine in this aspect so this issue occured somewhere after that. I have tried to add vm arguments to collect heap dump after memory error but it is not working because only one task of spring batch fails and not the whole program.

I would try to reproduce this issue on localhost and found out what is wrong like this.",,qo794,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5172,SERVICE-5182,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38361600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/19 12:41;qo794;The issue is easily reproducible on localhost having a prod core DB and a clean SLA DB. It fails due to a huge amount of records in {{cx_101_order_history}} table. The same has been happening on PROD as the job requests every day the whole table with millions of records. It's been failing since 15.9.2019:
{code:java}
2019-11-04T03:00:02.612Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Found last record for ALL_ORDERS at 2019-09-14T00:00Z[UTC]
2019-11-04T03:00:02.612Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Taking fromTo for ALL_ORDERS. From: 2019-09-14T00:00Z[UTC], To: 2019-11-04T00:00Z[UTC]
2019-11-04T05:59:54.713Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-added-orders-data in job collect-boundary-sla-data
java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}
Then on 15.11.2019 it suddenly found a newer record from 1.11.2019 event though the job failed the day before:
{code:java}
2019-11-14T07:09:44.312Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - No last record found for ALL_ORDERS. Taking default 2018-10-01T00:00Z[UTC]
2019-11-14T07:09:44.312Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Taking fromTo for ALL_ORDERS. From: 2018-10-01T00:00Z[UTC], To: 2019-11-14T00:00Z[UTC]
2019-11-14T07:13:04.179Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-added-orders-data in job collect-boundary-sla-data
java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}
{code:java}
2019-11-15T03:00:00.266Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Found last record for ALL_ORDERS at 2019-11-01T00:00Z[UTC]
2019-11-15T03:00:00.266Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Taking fromTo for ALL_ORDERS. From: 2019-11-01T00:00Z[UTC], To: 2019-11-15T00:00Z[UTC]
2019-11-15T03:22:45.912Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-added-orders-data in job collect-boundary-sla-data
java.lang.OutOfMemoryError: Java heap space
{code}
Then on 16.11. no record is found:
{code:java}
2019-11-16T03:00:00.322Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - No last record found for ALL_ORDERS. Taking default 2018-10-01T00:00Z[UTC]
2019-11-16T03:00:00.322Z [h-jobs-thread-1][][] INFO  c.d.e.x.r.b.DataCollector$Companion - Taking fromTo for ALL_ORDERS. From: 2018-10-01T00:00Z[UTC], To: 2019-11-16T00:00Z[UTC]
2019-11-16T03:02:48.164Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step collect-added-orders-data in job collect-boundary-sla-data
java.lang.OutOfMemoryError: GC overhead limit exceeded
{code}","04/Dec/19 12:44;qo794;A quick fix is to set the following parameter in {{application.properties}} on *xbprodsla2*:
{code:java}
default.period.from=2019-11-01T00:00:00
{code}
This setup will collect also data for November, it took around 5 min on my local machine.","05/Dec/19 09:36;qo794;The fix did not help, {{collect-added-orders-data}} failed again with the same error, setting the default period to 1.12.2019 - SERVICE-5182","06/Dec/19 08:48;qo794;Report tool (SLA) is working without any problem again on *xbprodsla2*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update XBID Connectivity Details,XP-2364,89266,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qm925,yo218,yo218,15/Nov/19 13:21,06/Nov/20 10:14,22/Feb/21 13:26,15/Nov/19 13:25,,,Pre2020,,,,,,,,,,,"Dear Simona, DBAG colleagues,

 

OTE informed us they were having difficulties connecting to SPM WebGUI via MPLS and that it was solved once DBAG suggested to use adjusted links to SPM:

 

[https://10.103.0.11:60003/spm]

[https://10.103.1.11:60003/spm]

 

These are slightly difference from the links from latest v1.14 connectivity details. Does it mean all parties should use the links you provided to OTE? If that is so, can you generate new version of PROD connectivity details document?

 

Link to the document: https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fps0080%2FShared%20Documents%2F04%20XBID%20Legal%20Framework%2F05%20Technical%20Documents%2FUSM990%20XBID%20Connectivity%20Details%20Production&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44&View=%7B6C81558C%2DB2AA%2D42D3%2DA854%2DB2860B7C1829%7D",,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Changed the link for SPM webgui,,,,,,,,,,,,,,40176000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09u7o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Nov/19 13:25;yo218;Created new version .16",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CLONE - Update core clean_jourjournal script (test,simu,prod)",XP-2362,89254,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,pd122,cs687,pd122,15/Nov/19 12:00,31/Aug/20 15:38,22/Feb/21 13:26,10/Dec/19 10:12,,,7tops_pre-sprint0_cleanup,,,,,,29/Nov/19 00:00,TO4XBID,,,,"For Systemtest1 (xbsyt1cor1) we already updated the clean_journal.ksh script successfully. 

ticket https://jira.deutsche-boerse.com/browse/TECHLOG-2818

for all the test-env´s/simulation and prod we need to update the script like it was done for systemtest1 
Necessary SERVICE-Tickets should be created.

We should also create an ansible role (energy.automation.deployment) to deploy the prodscripts like ""clean_jorunal.ksh"" etc. 

",,pd122,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-3004,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,38016000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09u74:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 40 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Dec/19 10:12;pd122;playbook _deploy_core_prodscripts.yml_ (role _prodscripts_) were created in _dev/energy.automation.deployments.git_ repo",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update SLA reporting according to 2nd wave ,XP-2357,89195,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,zi174,zi174,14/Nov/19 13:05,06/Nov/20 09:36,22/Feb/21 13:26,04/Dec/19 10:17,,,Pre2020,,,,,,,,,,,"Templates update according to new SLA limits of 2nd wave. 

It's necessary to modify the templates for SLA reporting in order to be complaint with new values defined based on 2nd wave. 

+Credit points report+ - not impacted, no changes necessary

*template SLA-REPORT.xlsx - tabs ""Sustainable Load Second"" and ""Sustainable Load Minutes""*
replace these values:
            .put(SlaType.ALL_ORDERS,                    200D)   // per second
            .put(SlaType.ALL_ORDERS_TRANSACTIONS,       350D)   // per second
            .put(SlaType.ALL_TRADES,                    76D)    // per second
            .put(SlaType.EXPLICIT_CAPACITY_ALLOCATIONS, 120D)   // per minute
            .put(SlaType.EXPLICIT_ALLOCATION_REQUESTS,  120D)   // per minute

            .put(SlaType.ALL_ORDERS,                    16.54)  // per second
            .put(SlaType.ALL_ORDERS_TRANSACTIONS,       16.54)  // per second
            .put(SlaType.ALL_TRADES,                    6.36)   // per second
            .put(SlaType.BLOCK_ORDERS,                  0.22)   // per second - 24h average
            .put(SlaType.BLOCK_TRADES,                  0.01)   // per second - 24h average
            .put(SlaType.EXPLICIT_CAPACITY_ALLOCATIONS, 21.0)   // per minute - 24h average
            .put(SlaType.EXPLICIT_ALLOCATION_REQUESTS,  21.0)   // per minute - 24h average

By:
            .put(SlaType.ALL_ORDERS,                    200D)   // per second
            .put(SlaType.ALL_ORDERS_TRANSACTIONS,       350D)   // per second
            .put(SlaType.ALL_TRADES,                    *N/A*)    // per second
            .put(SlaType.EXPLICIT_CAPACITY_ALLOCATIONS, 120D)   // per minute
            .put(SlaType.EXPLICIT_ALLOCATION_REQUESTS,  120D)   // per minute

            .put(SlaType.ALL_ORDERS,                    *40*)  // per second
            .put(SlaType.ALL_ORDERS_TRANSACTIONS,       *40*)  // per second
            .put(SlaType.ALL_TRADES,                    *N/A*)   // per second
            .put(SlaType.BLOCK_ORDERS,                  0.22)   // per second - 24h average
            .put(SlaType.BLOCK_TRADES,                  *N/A*)   // per second - 24h average
            .put(SlaType.EXPLICIT_CAPACITY_ALLOCATIONS, 21.0)   // per minute - 24h average
            .put(SlaType.EXPLICIT_ALLOCATION_REQUESTS,  21.0)   // per minute - 24h average
",,qo794,zi174,,,,,,,,,,,,,,,,,,,XP-2369,,,,,,,,,,,,,,,XP-2399,XP-2413,,,,,,"14/Nov/19 13:06;zi174;Appendix 20A - List of SLB  KPIs_v.1.2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77100/Appendix+20A+-+List+of+SLB++KPIs_v.1.2.xlsx","14/Nov/19 13:06;zi174;Attachment 5B - SLA - Hosting_v.3.2.docx;https://jira.deutsche-boerse.com/secure/attachment/77098/Attachment+5B+-+SLA+-+Hosting_v.3.2.docx","14/Nov/19 13:06;zi174;Exhibit 20 - Boundaries of Service_v.2.2.docx;https://jira.deutsche-boerse.com/secure/attachment/77099/Exhibit+20+-+Boundaries+of+Service_v.2.2.docx","15/Nov/19 13:03;zi174;credit-points-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77159/credit-points-report.xlsx","19/Nov/19 10:30;zi174;kpi-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77253/kpi-report.xlsx","25/Nov/19 13:43;zi174;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/77639/sla-report.xlsx",,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39225600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104220081",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],Home Office Team Sprint 40,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Nov/19 11:18;zi174;The following parameters define the Service Boundaries of the XBID Solution regarding the work-load and usage of the XBID Solution. They define the limits of DBAG’s performance commitment based on the following parameters.

(a)	Sustainable load
Workload and usage rates as defined in this Section 3.3.53.3.5(a) are considered as sustainable load. 
Orders Transactions (hourly, 15/30 mins) per second: 40.
Trade transactions (hourly, 15/30 mins) per second: n/a.
Average number of Block Order Transactions per second: 0,22.
Average number of Block Trade Transactions per second: n/a.
Average explicit capacity requests per second: 0,35.
Average Explicit Allocations per second: 0,35.

(b)	Peak load (two (2) seconds for Orders and trades, one (1) minute for explicit capacity requests and Explicit Allocations):
Order Transactions per second (hourly, 15/30 mins): 350.
Trade transactions per second (hourly, 15/30 mins): n/a.
*Peak Block Order Transactions: 7.*
*Peak Block Trade Transactions: 2*","25/Nov/19 13:44;zi174;[~qo794] the fixed template uploaded

thanks,
Jakub","25/Nov/19 15:38;qo794;These 2 metrics are not collected at all:
* Peak Block Order Transactions: 7
* Peak Block Trade Transactions: 2

To be analyzed (and implemented) within a different Jira: [~zi174] please create a new jira for that and link it to this one, thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Update all but CTP-F individual cutes to XBID 2.0.25.5, SPM 2.0.10.1, CT 2.5.1.58 on Wednesday 20/11",XP-2340,89055,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tm431,ei349,ei349,12/Nov/19 14:17,09/Jan/20 14:10,22/Feb/21 13:26,22/Nov/19 13:06,,,XBID 2.0,,,,,,,,,,,"h1. {color:#00875a}Individual Customer Facing Environments Consistency {color}

After Release 2.0 to production DBAG suggest to move all remaining client facing environments into new DB infrastructure which was introduced with R2.0.

List of environments which still remain on R1.5.x to be updated to 2.0.x:

1.CutePX

2.CTPD

3.CTPE

 

 

Fyi: [~L.Noble@epexspot.com] and [~jzavada@minsait.com]

 

Acceptance Criteria: 

-  updated all but CTP-F individual cutes to XBID 2.0.25.5, SPM 2.0.10.1, CT 2.5.1.58 on Wednesday 20/11.",,eg288,ei349,tm431,,,,,,,,,,,,,,,,,,,,,XBID-4780,,,,,,,,,,,,,,,,,,,"12/Nov/19 14:17;ei349;image-2019-11-12-11-24-35-968.png;https://jira.deutsche-boerse.com/secure/attachment/76971/image-2019-11-12-11-24-35-968.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39571200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09un1:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/19 14:17;jzavada@minsait.com;Dear Patrik, dear DBAG,

thank you for your suggestion. 3rd PS members will align regarding the upgrade of Individual CuTes (preliminary scheduled to Wednesday 20/11) - the conclusion will be informed to DBAG by Tuesday 12/11. (We are omitting the deployment timeslot on Wed 13/11 not because of being superstitious, but because OMIE has got scheduled a training in this whole week).

Let me a question: the SIDC version proposed to be deployed on the Individual CuTes CTPD, CTPE (unless there will be available some newer till then) is 2.0.25.2, correct ?

Best regards

Jiri","12/Nov/19 14:17;tm431;Dear [~jzavada@minsait.com] thank you for your proposal. DBAG suggest to update CTPD and CTPE on 6/11/2019 together with CUTEPX (as [~martin.vencelik@cz.ey.com] suggested in XBID-4782). As of the latest versions please consult last RCB slides where the overview of latest released version is (e.g. LIPA and LIPB is on x.25.3), or the email in which PROD versions scheduled to be deployed on 7/11 are being discuss (x.25.4 or x.25.5 depending on OPSCOM decission). Let me know exactly what versions you have decided to deploy.Please confirm all envs. deployment by today EOB. ","12/Nov/19 14:17;martin.vencelik@cz.ey.com;Dear Patrik,

 

thank you for moving OPSCOM request here, for CuTe PX detailed upgrade should be to:

Release 2.0.25.2

SM 2.0.10

CT 2.5.1.58

 

I confirm 06/11 si fine for OPSCOM. Can I consider the plan as agreed? Further, could you please provide me your estimation when (from-to) will be CuTe PX unavailable?

 

Thanks!

KR,

Martin","12/Nov/19 14:17;tm431;[~martin.vencelik@cz.ey.com] as there are no SLAs for testing envs. standard is that the env. can be unavailable the whole day during the deployment.","12/Nov/19 14:17;tm431;Dear [~martin.vencelik@cz.ey.com] please be informed that

 

XBID 2.0.25.2

SPM 2.0.10

CT 2.5.1.58

 

were deployed into CutePX","12/Nov/19 14:17;jzavada@minsait.com;Dear Patrik, dear DBAG,

what regards to the Individual CuTes, the PXs are still aligning, the plan to inform DBAG by 12/11 which Individual CuTes to be upgraded on 20/11 is still valid.

Best regards

Jiri","12/Nov/19 14:17;jzavada@minsait.com;Dear Patrik, dear DBAG,

3^rd^ PS members would like to ask DBAG for upgrade of the  Individual CuTes on Wednesday 20/11:

!image-2019-11-12-11-24-35-968.png!

What regards to the version to be deployed, we will stick to the version deployed on PROD actually:

*XBID 2.0.25.5*

*SPM 2.0.10.1*

*CT 2.5.1.58*

Note: request has been sent also via mail.

Best regards

Jiri

 ","12/Nov/19 14:17;jzavada@minsait.com;Dear Patrik, dear DBAG,

let me *+to correct the position+* communicated above:
 * the version requested stays intact (*XBID 2.0.25.5,* *SPM 2.0.10.1,* *CT 2.5.1.58*)
 * the Individual CuTes to be upgraded: CTPA till CTPL, except CTPF (*all but CTPF*).

I have received the confirmation later than sent the statement to you.

Best regards

Jiri","18/Nov/19 15:55;eg288;Implemented as MR:
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/541","22/Nov/19 13:06;tm431;Done. everything was deployed",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Database column rev of type int4 can overflow,XP-2325,88917,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ek176,eg288,eg288,08/Nov/19 10:11,06/Nov/20 09:33,22/Feb/21 13:26,25/Nov/19 12:42,,,Pre2020,,Trading,,,,,,,,,"h1. {color:#00875a}DB ID Overflow Prevention{color}

History tables cmm_101_allocation_history and cx_101_order_history still use rev column filled from sequence enverse_sequence. The column is of type int4. The current sequence value in PROD database is close to 1_000_000_000, i.e. it is roughly in the middle between 0 and MAX_INT. It took us 18 months to get there so we would get value overflow database error at some point in 2021.

The rev column was removed from all other tables already. But for the two mentioned table it is used in reporting to sort the values.

Proposed solution:
 * change type of the column to bigint
 * verify the application if some changes are required, for example hibernate mapping files etc.",,ek176,,,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,XP-3990,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39571200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n32:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 39,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,xbid-losses-poc,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Nov/19 10:21;ek176;Tested locally: 
{noformat}
m7core=# SELECT id, user_code, rev FROM cmm_101_allocation_history;  
SELECT order_id, last_update_user, rev, action FROM cx_101_order_history ;

 id | user_code |    rev      
----+-----------+------------
  1 | API001    |          2
  2 | USR032    |          6
  3 | USR032    |  214783653
  4 | API001    |  644350947
  5 | API001    | 1288701890
  6 | API001    | 1288701891
  7 | API001    | 1288701892
  8 | API001    | 1288701893
  9 | API001    | 1288701894
 10 | USR032    | 1288701898
(10 rows)


 order_id |    last_update_user    |    rev     | action  
----------+------------------------+------------+--------
        1 | TMEPEX-BG1-----XOPEPEX |          1 | UADD
        2 | TMEPEX-BG1-----XOPEPEX |          3 | UADD
        2 | TMEPEX-BG1-----XOPEPEX |          4 | FEXE
        1 | TMEPEX-BG1-----XOPEPEX |          5 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX |  429567300 | UADD
        4 | TMEPEX-BG1-----XOPEPEX |  859134594 | UADD
        4 | TMEPEX-BG1-----XOPEPEX | 1073918241 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX | 1288701888 | FEXE
        5 | TMEPEX-BG1-----XOPEPEX | 1288701889 | UADD
        6 | TMEPEX-BG1-----XOPEPEX | 1288701895 | UADD
        6 | TMEPEX-BG1-----XOPEPEX | 1288701896 | FEXE
        5 | TMEPEX-BG1-----XOPEPEX | 1288701897 | FEXE

{noformat}
Sequence was alrady a bigint:
{code:java}
core: sequence is a bigintm7core-# \dS+ public.envers_sequence
            Sequence ""public.envers_sequence""
    Column     |  Type   |        Value        | Storage 
---------------+---------+---------------------+---------
 sequence_name | name    | envers_sequence     | plain
 last_value    | bigint  | 1                   | plain
 start_value   | bigint  | 1                   | plain
 increment_by  | bigint  | 1                   | plain
 max_value     | bigint  | 9223372036854775807 | plain
 min_value     | bigint  | 1                   | plain
 cache_value   | bigint  | 1                   | plain
 log_cnt       | bigint  | 0                   | plain
 is_cycled     | boolean | f                   | plain
 is_called     | boolean | f                   | plain

{code}","22/Nov/19 13:00;ek176;Tested for xbid 3.0
{noformat}
m7core=# SELECT id, user_code, rev FROM cmm_101_allocation_history; SELECT order_id, last_update_user, rev, action FROM cx_101_order_history ;

 id | user_code | rev  
----+-----------+-----
  1 | API001    |   2
  2 | API001    |   3
(2 rows)

 order_id |    last_update_user    | rev | action  
----------+------------------------+-----+--------
        1 | TMEPEX-BG1-----XOPEPEX |   1 | UADD
        2 | TMEPEX-BG1-----XOPEPEX |   4 | UADD
        1 | TMEPEX-BG1-----XOPEPEX |   5 | FEXE
        2 | TMEPEX-BG1-----XOPEPEX |   6 | FEXE
(4 rows)


m7core=# ALTER SEQUENCE envers_sequence RESTART WITH 214783647;
ALTER SEQUENCE
m7core=# ALTER SEQUENCE envers_sequence INCREMENT BY  100000000;
ALTER SEQUENCE

m7core=# SELECT id, user_code, rev FROM cmm_101_allocation_history; SELECT order_id, last_update_user, rev, action FROM cx_101_order_history ;

 id | user_code |    rev     
----+-----------+-----------
  1 | API001    |         2
  2 | API001    |         3
  3 | API001    | 314783647
  4 | API001    | 414783647
  5 | API001    | 514783647
  6 | API001    | 614783647
  7 | API001    | 714783647
(7 rows)

 order_id |    last_update_user    |    rev     | action  
----------+------------------------+------------+--------
        1 | TMEPEX-BG1-----XOPEPEX |          1 | UADD
        2 | TMEPEX-BG1-----XOPEPEX |          4 | UADD
        1 | TMEPEX-BG1-----XOPEPEX |          5 | FEXE
        2 | TMEPEX-BG1-----XOPEPEX |          6 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX |  214783647 | UADD
        4 | TMEPEX-BG1-----XOPEPEX |  814783647 | UADD
        4 | TMEPEX-BG1-----XOPEPEX |  914783647 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX | 1014783647 | FEXE
(8 rows)

m7core=# SELECT id, user_code, rev FROM cmm_101_allocation_history; SELECT order_id, last_update_user, rev, action FROM cx_101_order_history ;

 id | user_code |    rev      
----+-----------+------------
  1 | API001    |          2
  2 | API001    |          3
  3 | API001    |  314783647
  4 | API001    |  414783647
  5 | API001    |  514783647
  6 | API001    |  614783647
  7 | API001    |  714783647
  8 | API001    | 1214783647
  9 | API001    | 1314783647
 10 | API001    | 1414783647
(10 rows)

 order_id |    last_update_user    |    rev     | action  
----------+------------------------+------------+--------
        1 | TMEPEX-BG1-----XOPEPEX |          1 | UADD
        2 | TMEPEX-BG1-----XOPEPEX |          4 | UADD
        1 | TMEPEX-BG1-----XOPEPEX |          5 | FEXE
        2 | TMEPEX-BG1-----XOPEPEX |          6 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX |  214783647 | UADD
        4 | TMEPEX-BG1-----XOPEPEX |  814783647 | UADD
        4 | TMEPEX-BG1-----XOPEPEX |  914783647 | FEXE
        3 | TMEPEX-BG1-----XOPEPEX | 1014783647 | FEXE
        5 | TMEPEX-BG1-----XOPEPEX | 1114783647 | UADD
        6 | TMEPEX-BG1-----XOPEPEX | 1514783647 | UADD
        6 | TMEPEX-BG1-----XOPEPEX | 1614783647 | FEXE
        5 | TMEPEX-BG1-----XOPEPEX | 1714783647 | FEXE
(12 rows)


{noformat}","22/Nov/19 13:02;ek176;Searching for references to cmm_101, cx_101 and envers_sequence, various PSQL functions refer to the following tables:

cx_117, cx_119, cx_215, cx_431, cx_441, cx_443, cx_671

 

However, these do not exist anymore in current DB scheme revision. 

_Note:_ This can easily be found in export: pg_dump --schema-only ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Update pg_watch deployment to include database prepare job,XP-2324,88908,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,hw120,hw120,07/Nov/19 23:40,31/Aug/20 15:39,22/Feb/21 13:26,07/Nov/19 23:45,,,Pre2020,,,,,,,,,,,https://jira.deutsche-boerse.com/browse/TECHLOG-3002,,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40780800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09sag:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup monitoring for single postgres instances on all CUTE envs,XP-2320,88853,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,07/Nov/19 10:36,04/Aug/20 19:35,22/Feb/21 13:26,07/Nov/19 22:26,,,Pre2020,,,,,,,,,,,"On XBID we have patroni postgres cluster only for SYT[13], perf, simu and prod.

The rest of the postgres instances are single ones and the setup is different.
 * We have to modify pg_watch configuration and deployment ( possibly also postgres config ) for Postgres single instances and deploy it.
 * Deploy filebeat to all test db instances to apply new log pattern
 * Update all CUTEs postgres instances with
 ** new log_line_prefix '<time=%m user=%u db=%d host=%h pid=%p > '
 ** missing config option for monitoring, pg_stat_statements.track = 'all'
 ** Add \{{ hostvars[inventory_hostname]['ansible_default_ipv4']['address'] }}/32 to pg_hba.conf instead of 127.0.0.1/32
 *** Because postgres single instances has configuref in posgresql.conf listen_address of hostname instead of 0.0.0.0 on patroni
 **** We should unify it to avoid confusion

 ",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40867200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ryg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CORE module, AckSender fails with NPE when processing a message",XP-2317,88749,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,MG726,eg288,eg288,06/Nov/19 14:03,19/Jan/21 16:25,22/Feb/21 13:26,19/Jan/21 16:25,,,Pre2020,,Trading,,,,,,,,,"In prod env there are several errors per day in AckSender. It fails when processing a message without correlationId:
{code}
Handling error on event 'com.deutscheboerse.energy.m7.core.in.RequestEvent@3dc5b6f4[error=<null>,input=Input:Message{receivedTime=1573039778267, rabbitReceivedTime=1573039778266, appId=m7-EPEX, userId=XBEPEXX1, applicationUserId=null, messageId=null, contentEncoding=gzip, contentType=x-m7/request; version=1, messageSource=TRADING_PMI, replyTo=amq.gen-8vf2275hwzoqm0SHIhpH3w, correlationId=null, classId=null, contentClassId=null, keyClassId=null},request=<null>]'
java.lang.NullPointerException: null
{code}

XBID response is :
{code}
2019-11-06 11:29:38.280: BROADCAST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><ErrResp xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><Error err=""Unknown validation error."" errCode=""107""/></ErrResp>. MessageProperties [headers={timestamp_in_ms=1573039778279, x-m7-group-sequence=71, x-m7-group-id=1.XBEPEXX1, server-timestamp=1573039778279}, timestamp=Wed Nov 06 11:29:38 UTC 2019, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=ErrResp, correlationId=null, correlationIdString=null, replyTo=null, contentType=x-m7/broadcast; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.broadcastExchange, receivedRoutingKey=1.XBEPEXX1, receivedDelay=null, deliveryTag=38975039, messageCount=0, consumerTag=amq.ctag-5MxE2KA3oDu6SRVJyZEG8w, consumerQueue=xbid.monitoring.1]
{code}

Expected behaviour is to recognize an invalid message (missing attribute) and respond with an error message that the attribute is not populated and thus the request will not be processed. And thus avoid ERROR lines CORE log.

",,eg288,MG726,pg759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2851200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c927:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,HOT Sprint 25 (S),,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,XP-2478-tobago-upgrade,XP-4277-develop-sonar-test,XP-2478-tobago-upgrade-clean01,develop,XP-2400,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Dec/20 16:41;pg759;AckSender runs parallel to Unmarshaller and Validation so the missing correlation-id must be handled in both flows in following way:

1. AckSender will send acknowledgement without correlation-id - this prevents NPE
2. Unmarshaller will check presence of correlation-id
   - can't be done in Validator as it has only access to unmarshalled payload not the AMPQ message
   - the check throws MissingMessagePropertyException with error message giving name of missing property (now only correlation-id)
   - the check is done only for TM_V1 messages
","19/Jan/21 16:22;MG726;Tested successfully in docker version 3.2.4-SNAPSHOT with RabbitMQ version 3.8.3

Order entry was sent for the user XBTSTR01 directly to Rabbit without correlationID:
{code:json}
curl -v -i -u XBTSTR01:a -X POST http://localhost:24674/api/exchanges/%2fm7%2fxbid/comxerv.requestExchange.XBTSTR01/publish \
        -d '{​​​​
                ""properties"":{​​​​
                        ""content_type"":""x-m7/request; version=1"",
                        ""user_id"":""XBTSTR01"",
                        ""reply_to"":""cmm.response.CXAPI003"",
                        ""app_id"":""DB-TestClient""
                }​​​​,
                ""routing_key"":""comxerv.request.management"",
                ""payload"":""<OrdrEntry xmlns=\""http://www.deutsche-boerse.com/m7/v1\""> <StandardHeader marketId=\""XSOB\""/> <OrdrList> <Ordr acctId=\""TMEPEX-BG1-----X\"" contractId=\""10\"" prod=\""Intraday_Power_D\"" side=\""SELL\"" px=\""100\"" qty=\""1000\"" ordrExeRestriction=\""NON\"" dlvryAreaId=\""10YAT-APG------L\"" clOrdrId=\""1532355281482\"" type=\""O\"" validityRes=\""GFS\"" state=\""ACTI\""/> </OrdrList> </OrdrEntry>"",
                ""payload_encoding"":""string""
        }​​​​'
{code}
Correct error message received instead of null pointer exception:
{code:java}
2021-01-19T12:44:08.774Z [AckSender][][11b6ae33] TRACE c.d.e.m.t.M.outcomingMessage - <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><AckResp xmlns=""http://www.deutsche-boerse.com/m7/v1""><Sta
ndardHeader marketId=""XSOB""/></AckResp>
2021-01-19T12:44:08.801Z [Unmarshaller][][] DEBUG c.d.e.m.c.e.XbidExceptionHandler - Validation error during com.deutscheboerse.energy.m7.core.in.RequestEvent@796b2783[error=<null>,input=Input:Messag
e{receivedTime=1611060248770, rabbitReceivedTime=-1, appId=DB-TestClient, userId=XBTSTR01, applicationUserId=null, messageId=null, contentEncoding=null, contentType=x-m7/request; version=1, messageSo
urce=TRADING_PMI, replyTo=cmm.response.CXAPI003, correlationId=null, classId=null, contentClassId=null, keyClassId=null},request=<null>]: Missing property correlation-id
com.deutscheboerse.energy.m7.exception.MissingMessagePropertyException: Missing property correlation-id
        at com.deutscheboerse.energy.m7.core.in.Unmarshaller.doOnEvent(Unmarshaller.java:46)
        at com.deutscheboerse.energy.m7.core.in.Unmarshaller.doOnEvent(Unmarshaller.java:24)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
        at com.lmax.disruptor.BatchEventProcessor.processEvents(BatchEventProcessor.java:168)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:125)
        at java.lang.Thread.run(Thread.java:748)
2021-01-19T12:44:08.801Z [ResultTransform][][11b6ae33] DEBUG c.d.e.m.c.o.e.ExceptionTranslatorDispatcher - Translating exception {}
com.deutscheboerse.energy.m7.exception.MissingMessagePropertyException: Missing property correlation-id
        at com.deutscheboerse.energy.m7.core.in.Unmarshaller.doOnEvent(Unmarshaller.java:46)
        at com.deutscheboerse.energy.m7.core.in.Unmarshaller.doOnEvent(Unmarshaller.java:24)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
        at com.lmax.disruptor.BatchEventProcessor.processEvents(BatchEventProcessor.java:168)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:125)
        at java.lang.Thread.run(Thread.java:748)
{code}
Test {color:#008000}OK{color}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automated dumps to EBSM stopped working with new DB cluster,XP-2314,88702,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ll664,ll664,06/Nov/19 09:39,06/Nov/20 10:59,22/Feb/21 13:26,14/Nov/19 13:46,,,Pre2020,,,,,,,TO-JOB,,,,"There are no new dumps in {{/opt/data/transfer/dbdumps/xbid_prod/}} on EBSM since the change to new DB cluster.

Pls  fix the dumping jobs.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40953600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09rg0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve Flyway migrations,XP-2311,88689,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,05/Nov/19 16:33,10/Nov/20 10:43,22/Feb/21 13:26,10/Nov/20 10:43,,,3.2.x,,,,,,,,,,,"This is a feedback from XBID COP based on failed DB ugprade from XBID 1.5 to XBID 2.0.x.

Suggestions:
* enable migration checksums (currently disabled)
* introduce version prefix by branch convention:
** i.e. XBID 3.0.x migrations would have migrations:
*** {{V3_0_1__some_migration.sql}}
*** {{V3_0_2__another_migration.sql}}
* idempotent migrations (if possible)
* consider collapsing all DB change for the next development branch
** XBID 3.0.x would have all flyway scripts collapsed into a single one {{V3_0_0__init.sql}}
** Existing DBs needs to be _baselined_ to that versions, create a tutorial",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8985600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:vi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4076,develop,master,XP-2311,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Nov/20 09:30;ll664;I tried to elaborate a bit more on a problem and possible solution. We're running into the same compatibility issues as before, as we simply continue to increase Flyway versions in {{develop}} while leaving no space for possible UAT (or PROD) bugfixes.

Current state of {{develop}}/{{acceptance}}/{{prod}}:
h4. develop
{code:java}
V0093__publish_status_to_file_status.sql
V0094__add_atc_without_ramping_to_atc_log.sql
V0095__removing_holidays_and_product_fields.sql
V0096__removing_tso_dispute.sql
V0097__integer_overflow_fix.sql
{code}
h4. acceptance
{code:java}
V0093__publish_status_to_file_status.sql
V0094__add_atc_without_ramping_to_atc_log.sql
{code}
h4. prod
{code:java}
V0093__publish_status_to_file_status.sql
{code}
Now we already cannot easily cherry-pick any bugfix that comes from {{acceptance}}/{{prod}} branch back to {{develop}} without renaming the flyway script versions.

What is worse, backporting from {{prod}} to {{acceptance}} is even bigger nightmare, as we cannot drop DB in customer facing envs - it would require some manual flyway harakiri like baseline/repair.

 
h2. Proposal

Let's change our Flyway versioning conventions - instead of ever increasing sequence, we'll have:
{code}
V3.1.0__some_migration.sql
V3.1.1__another_migration.sql
V3.2.0__next_xbid_release_migration.sql
{code}

This would allow us to always have a space for possible bugfixes.

h3. How to get there

We'll do the changes only in {{develop}} branch, {{acceptace}}/{{prod}} would stay with current Flyway structure.

We'll take current DB state from {{acceptance}} - that is up to {{V0094__add_atc_.....}} migration script - and shrink it to a new single init script for XBID v3.1.0. 

The rest of the scripts in {{develop}} would be renamed to follow XBID 3.2 convention.

So, we'll end up with following scripts:
{code}
V3.1.0__init.sql
V3.2.0__removing_holidays_and_product_fields.sql
V3.2.1__removing_tso_dispute.sql
V3.2.2__integer_overflow_fix.sql
{code} 

h3. Backporting migrations

Say new bugfix comes to {{acceptance}} that introduces new migration script
{code}
V0095__fixes_another_uat_finding.sql
{code}

Merge into develop would need to rename the script to fit in between 3.1 and 3.2 versions:
{code}
V3.1.0__init.sql
V3.1.1__fixes_another_uat_finding.sql
V3.2.0__removing_holidays_and_product_fields.sql
V3.2.1__removing_tso_dispute.sql
V3.2.2__integer_overflow_fix.sql
{code}

The problem arises when we need to deploy to existing DB, the Flyway migration will obviously fail, because of new script in between. This is not new issue, the same happens with current way of working.

This could be simply solved by:

* applying the new script manually
* Flyway baseline to latest version (V3.2.2) so it does try to migrate again. Should be automated with Ansible. 

The procedure should be explicitly documented.

h3. Deploy XBID 3.2 to an env with old Flyway structure

This is only one off action. Say we're going to deploy XBID 3.2 to UAT, we merge it to {{acceptance}} branch, but we cannot clean the DB.

Hence the SIMU DB contains still old flyway migrations. We would only need to:

* Flyway baseline. We'll need to determine the baseline version, for example above, if the SIMU is in {{V0095}}, the corresponding version would be {{V3.1.1}}.
* Flyway migrate - it would apply the rest of the migrations

h3. Pros

* no compatibility problems in ""happy"" path - upgrade from XBID 3.1 to XBID 3.2  
* making space for backported fixed in between version explicit
* no more renaming of the scripts
* introduces explicit operational procedure for case where schemas are incompatible - there's no such thing at the moment






 

 ","10/Nov/20 10:05;ll664;Implemented and merged into {{develop}} of XBID and SM projects. 

Wiki here: https://github.deutsche-boerse.de/dev/xbid-tutorials/wiki/Flyway:-rollout-of-a-new-migrations-structure",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failing builds notifications,XP-2310,88688,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ll664,ll664,05/Nov/19 16:16,04/Aug/20 19:53,22/Feb/21 13:26,06/Apr/20 10:50,,,3.1.0,,,,,,,,,,,"Currently, we have (some) e-mail notifications when a particular build is failing that gets completely ignored.

Let's get rid of them a have a new way of dealing with this.

Suggestion:

* Slack channel for notification
* rules to see who is responsible for fixing (automated/git blame? )
* for all modules (XBID, Shipping, Report Tool, Comtrader?, routing etc.), include notifications for
**  continuous build
** nightly build
** e2e tests build

Do not include PR builds in the notification, those are reported to Github PR anyway.
",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40953600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ajf8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Add ElasticSearch datasource to grafana,XP-2307,88668,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,hw120,hw120,05/Nov/19 12:10,31/Aug/20 15:39,22/Feb/21 13:26,07/Nov/19 12:40,,,Pre2020,,,,,,,TO-JOB,,,,https://jira.deutsche-boerse.com/browse/TECHLOG-2962,,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41040000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09r94:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Split of GitHub user groups (separation of XBID),XP-2304,88630,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,dm700,dm700,05/Nov/19 08:10,13/Aug/20 19:41,22/Feb/21 13:26,13/Feb/20 11:59,,,3.1.0,,,,,,,,,,,"Energy team git admins add new employee into git team m7-developer (it gives them write access to most of Energy repos)

Based on need to know principle there should be a user group dedicated to each product (also XBID). It should also ensure right separation by giving the write access to only those who should have this right ",,dm700,ei349,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,32400000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1667,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a8q0:2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Sprint 2 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Dec/19 14:40;lt112;[~dm700] can externals be part of groups or is it still a no-go? Or at least having separate group for externals","17/Dec/19 10:36;lt112;Created groups {{xbid-developer-admins}} and {{xbid-developer}} and added them to somewhat relevant repositories. No group was removed from any repository.

What is the DoD here?","06/Feb/20 09:25;ei349;[~dm700]: can you please assist [~lt112]? ","06/Feb/20 09:43;dm700;[~lt112] and [~ei349] - the trick is now to remove all redundant groups from you repos (like m7-developer and M7-admins). SO that only XBID groups members can write to XBID repos.

Externals its a different topic - they can NOT be part of the generic developers group which has read access  to ALL repos in Dev GitHub organization. So basically all internal DBSS employees can read your (even private) repos. External are not added to this group but just added to particular repos manually. Thats the difference. Your private groups can include externals.

Or stop by I will explain it :). ","13/Feb/20 11:58;lt112;Removed {{m7-developer}} and {{m7-developer-admins}} from relevant Xbid repositories. There is a lot of remaining shared/unknown repositories. The unknown ones are usually old ones and not active for  years, thus should not contain confidential code or something. 

*NOTE:* There still might be false positives and false negatives. Do not hesitate to bring such cases up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"BidAskSpread handler error - duplicate key value violates unique constraint ""bid_ask_spread_pkey""",XP-2303,88624,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,eg288,eg288,05/Nov/19 07:57,06/Nov/20 09:37,22/Feb/21 13:26,19/Nov/19 15:49,,,Pre2020,,Trading,,,,,,,,,"{code}
Error while handling event com.deutscheboerse.energy.m7.orderbook.OrderBookEvent@6e1b25de[error=<null>,calculationTrigger=<null>,configurationReplicationTrigger=<null>,request=<null>,orderbookDeltas=[],h2HData=<null>,publication=<null>,orderVisibilityMatrix=102 items,command=com.deutscheboerse.energy.m7.orderbook.command.CollectBidAskSpreadCommand@4464671b,bidAskSpreadSize=424], {}
org.springframework.dao.DataIntegrityViolationException: could not execute batch; SQL [insert into xbprodcor.BID_ASK_SPREAD (BIDDING_ZONE_EIC, BIDDING_ZONE_LONG_NAME, CENT_SPREAD, COLLECTED_AT, CONTRACT_ID, CONTRACT_LONG_NAME, CONTRACT_TYPE, DELIVERY_ENDDATE, DELIVERY_STARTDATE, PRODUCT_LONG_NAME, id) values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]; constraint [bid_ask_spread_pkey]; nested exception is org.hibernate.exception.ConstraintViolationException: could not execute batch
	at org.springframework.orm.hibernate5.SessionFactoryUtils.convertHibernateAccessException(SessionFactoryUtils.java:247)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.convertHibernateAccessException(HibernateTransactionManager.java:798)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:634)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:533)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:304)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadService$$EnhancerBySpringCGLIB$$1adc6ebc.persistAll(<generated>)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:32)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:15)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.hibernate.exception.ConstraintViolationException: could not execute batch
	at org.hibernate.exception.internal.SQLStateConversionDelegate.convert(SQLStateConversionDelegate.java:112)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:42)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:128)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:104)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:147)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.executeBatch(JdbcCoordinatorImpl.java:212)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:633)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1454)
	at org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:511)
	at org.hibernate.internal.SessionImpl.flushBeforeTransactionCompletion(SessionImpl.java:3283)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2479)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:473)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:98)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:622)
	... 16 common frames omitted
Caused by: java.sql.BatchUpdateException: Batch entry 99 insert into xbprodcor.BID_ASK_SPREAD (BIDDING_ZONE_EIC, BIDDING_ZONE_LONG_NAME, CENT_SPREAD, COLLECTED_AT, CONTRACT_ID, CONTRACT_LONG_NAME, CONTRACT_TYPE, DELIVERY_ENDDATE, DELIVERY_STARTDATE, PRODUCT_LONG_NAME, id) values ('10YBE----------2', 'Elia System Operator', 156, '2019-11-04 09:10:00+00', 101718, '20191104 20:00-20191104 21:00', 'CAN', '2019-11-04 20:00:00+00', '2019-11-04 19:00:00+00', 'XBID_Hour_Power', -2131942108) was aborted: ERROR: duplicate key value violates unique constraint ""bid_ask_spread_pkey""
  Detail: Key (id)=(-2131942108) already exists.  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:148)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2184)
	at org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1299)
	at org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1324)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:467)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:840)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1538)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:118)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:104)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:147)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.executeBatch(JdbcCoordinatorImpl.java:212)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:633)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1454)
	at org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:511)
	at org.hibernate.internal.SessionImpl.flushBeforeTransactionCompletion(SessionImpl.java:3283)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2479)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:473)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:98)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:622)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:533)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:304)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadService$$EnhancerBySpringCGLIB$$1adc6ebc.persistAll(<generated>)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:32)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:15)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""bid_ask_spread_pkey""
  Detail: Key (id)=(-2131942108) already exists.
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2440)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2183)
	at org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1299)
	at org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1324)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:467)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:840)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1538)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:118)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:104)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:147)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.executeBatch(JdbcCoordinatorImpl.java:212)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:633)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1454)
	at org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:511)
	at org.hibernate.internal.SessionImpl.flushBeforeTransactionCompletion(SessionImpl.java:3283)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2479)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:473)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:98)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:622)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:533)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:304)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadService$$EnhancerBySpringCGLIB$$1adc6ebc.persistAll(<generated>)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:32)
	at com.deutscheboerse.energy.m7.acer.BidAskSpreadHandler.doOnEvent(BidAskSpreadHandler.java:15)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:75)
	at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:32)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
{code}",,eg288,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2315,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40953600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,05/Nov/19 07:57,,,,,,,,,,,,,,,,,,,,,,,"1|y09tan:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 39,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,XP-2635-redo-fix-3.0,XP-2626-2.0.25.x,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,xbid-losses-poc,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Nov/19 09:31;eg288;Entity BidAskSpread uses generated id from database sequence _bid_ask_spread_id_seq_. The id is of type java int.
|Current sequence value|3 521 920 261|
|Max int|2 147 483 647|

The sequence value is *above max int* and thus we are getting duplicate keys due to *int overflow*.

 

The databses sequence and hibernate generator are not set correclty. It results in rapid increase of sequence value. Also the ids are generated with huge gaps. From databse it shows that each new batch of 20 new ids increases the sequence by 20_000 causing gaps between ids of the size 400_000.

The application uses old hibernate SequnceHiLoGenerator which takes high value from database sequence and low value is defined by allocationSize set in the code (class BidAskSpread). The resulting id is then calculated a:
 * id = highVal * lowVal + i

where i is in range [0 .. lowVal].

The SequnceHiLoGenerator is used due to property _hibernate.id.new_generator_mappings_ set to false.

The database sequence _bid_ask_spread_id_seq_ has property _Increment By_ set to 20 which is not correct and causes gaps. It should be incremented by 1 only. But the setting should not cause gaps of 400_000 but only 400 (calculated as IncrementBy * lowVal).

Further investigation shows that xbid-2.0 causes expected gaps of 400 while xbid-1.5 causes gaps 400_000. There was hibernate upgrade from version 4 to 5 in xbid. It could explain the different behaviour.","05/Nov/19 16:22;eg288;Solution proposals:

Solution 1. (conservative approach):
 * change type of id in BidAskSpread entity to long including database column
 * change database sequence _bid_ask_spread_id_seq_: Increment By to 1, current value to (max integer + 1)
 * xbid core restart is needed

Solution 2. (master plan)
 * all curent ids where id > 0 multiply by -1, so all the ids will be negative, should be possible according to hotfix database, there are no conflicting ids, to verify run the SQL bellow

{code:java}
SELECT abs(id), count(*) from bid_ask_spread where date_trunc('day', collected_at) >= '2019-06-30 00:00:00' having count(*) > 1 group by abs(id)}

{code}
 * change database sequence _bid_ask_spread_id_seq_: Increment By to 1, current value to 1
 * xbid core restart is NOT needed

In both solutions delete old data before 30.6.2019",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upload source code to Escrow,XP-2293,88514,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,31/Oct/19 14:08,06/Nov/20 10:14,22/Feb/21 13:26,01/Nov/19 13:47,,,Pre2020,,,,,,,,,,,,,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41299200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09q33:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 38,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/19 13:47;jy268;source code imported to Deposix sftp
{code}
plewmic@plewmic-energy:~ $ date
Fr 1. Nov 13:45:43 CET 2019
plewmic@plewmic-energy:~ $ sftp deposix 
Deposix Software Escrow GmbH
Connected to deposix.
sftp> ls
checksum.md5                  xbid-source-code-export.gpg
{code}","01/Nov/19 13:52;jy268;Exported list:
{code}
comtrader-2.5.1.58
m7-shipping-2.0.10
pmiarchiving-1.0.19
pmilogger-1.1.0
rep-engine-5.0.45
xbid-2.0.25.2
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix of instance monitoring on production,XP-2287,88495,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,ei349,ei349,31/Oct/19 10:58,04/Aug/20 19:35,22/Feb/21 13:26,05/Nov/19 16:19,,,Pre2020,,,,,,,,,,,"After deployment of XBID 2.0 we checked monitoring of the new database servers and find out there are few problems with monitoring.
 * We need to fix db postgres instance monitoring, metrics are missing
 ** I have to update ansible deployment of pg_watch2 to prepare database environment of of patroni servers
 ** Also add missing tag host to pg_watch2 config for alert message to display correctly
 * Logs from postgres are in 2 different formats, has to be united
 ** Discuss with Steffen about updating patroni cluster deployment process",,ei349,hw120,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2991,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40953600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n3h:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Nov/19 17:12;hw120;Fixed posgres instance monitoring ansible deployment

https://github.deutsche-boerse.de/dev/energy.monitoring/issues/1104","05/Nov/19 16:17;hw120;Deployed changes to postgres instance monitoring.

Unified postgres log line prefix on all environments and also in patroni deployment ansible role and also updated elasticsearch pipeline.

New log line prefix changed on all environments but not applied on simu and prod, this will happen with update of ACLs for simu and with the next deployment on xbid prod.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update performance report template with SLA percentiles,XP-2285,88492,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ll664,ll664,31/Oct/19 10:40,06/Nov/20 09:37,22/Feb/21 13:26,13/Nov/19 09:47,,,Pre2020,,,,,,,,,,,"Add SLA percentiles to the template, i.e. for order exe/obk computation we have folowwing binding percentiles:

* 96.5
* 93

Add also SLA based event rates to the excel for quick reference, i.e. on a Order execution time tab add max/actual base/peak load.

Check the SLA docs for more.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41472000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09jtb:k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2285,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jolokia end-point not working in 2.0,XP-2283,88488,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,,qo794,qo794,31/Oct/19 09:27,06/Nov/20 10:59,22/Feb/21 13:26,07/Nov/19 09:16,,,Pre2020,,,,,,,,,,,"After migrating xbid 2.0 to Spring Boot 2 jolokia end-point stopped working on *CORE*:
http://127.0.0.1:8080/m7core/jolokia/

It works properly in CMM, CMI and SOB though.
Please investigate and fix.

The end-point is used by techops to gather JVM statistics for presenting them in Grafana. So we don't have statistics for CORE on PROD, SIMU, etc.",,eg288,ei349,ek176,gd553,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40867200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09q33:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 38,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2626-2.0.25.x,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/Oct/19 10:14;ei349;Dear Devs + TOs: can you please check the hotfix possibility via direct update on prod? ","31/Oct/19 15:40;eg288;It is not possible to change the configuration in runtime. The CORE module must be released and redeployed.

The fixed configuration has been merged into:
* xbid-2.0.x
* xbid-2.0.25.x
* xbid-3.0.x","01/Nov/19 11:06;gd553;[~eg288] [~ei349] - who brought up this topic? Is it important for Dev or for TechOps?","07/Nov/19 09:16;eg288;tested successfully with xbid-2.0.25.5 deployed in syt1 on 6. Nov 2019",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A code classification in GIThub ,XP-2282,88486,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,zi174,zi174,31/Oct/19 09:12,13/Aug/20 19:41,22/Feb/21 13:26,10/Jan/20 15:23,,,3.1.0,,,,,,,,,,,"According to SDLC standard, it's necessary to classify the XBID code (internal, confidential, strictly confidential etc.). 

Two proposals: 
# Create a repository which will be accessible only for authorized developers (XBID) and not accessible or readable for other users - this should be enough for ""confidential"" classification
# Don't do anything and classify the code as ""internal"" by file ""licence.md"" which will cover our repositories",,ek176,ll664,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35251200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1667,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ezi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,Alpha Sprint 0,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-2921-sm-2.0.10.x,XP-2626-2.0.25.x,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2583,XP-3230,XP-2694-xbid-3.0.x-latest-tag-fix,XP-3594-cpm-ramping,XP-3094-sonar-gate,XP-TEST,master-comtrader-2.5.x,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-3070,XP-2418-provide-SM-reports-PSE,XP-4505_pipeline_option_timestamps,XP-1261-owasp-sec-deps-update,XP-4505_ct_sloth_hpfortify_upgrade,plewmic-scripts,cpm,XP-4505_xbid_hpfortify_upgrade,master-sm-2.0.10.x,fixing-hp-fortify-acceptance-2021-02-15,XP-1211-confidential-label,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,XP-456,XP-3264,XP-2521-labeling-cmi-leftovers,develop,XP-3345,XP-4505_xbid_develop_hpfortify_upgrade,XP-2694,testing-new-stages-3.0,master-acceptance,XP-TEST2,XP-3243-report-tool-hp-fortify,inline-tomcat-params,acceptance,XP-4371_upgrade_dataset_version,XP-3233-prod-jgitflow,versions,XP-3161-pom-cleanup-develop,XP-2635-2.0.10.x,XP-4505_reporting_tools_upgrade_hpfortify,selenide-poc,XP-3777,XP-69,XP-PULL-TEST,xbid-losses-poc,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3161-develop,master-cpm,XP-2282,XP-3942-acceptance,xbid-2.0.25.x,sm-2.0.10.x,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,fixing-failover,master-xbid-losses-poc,XP-4505_pmi_tools_upgrade_hpfortify,XP-3233-acceptance-jgitflow,XP-2635-redo-fix-3.0,XP-3922,fixing-owasp,prod,master-prod,XP-2979-postgresql,XP-3345-version-bump,XP-3361,XP-3594-allocation-plans,XP-2345-adapt_benchmark_to_latest_routing_lib_0-4-14,XP-2232,XP-2554,master,XP-4273-owasp-zap-enable,cpm-compatibility-pack,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,comtrader-2.5.x,XP-3161,CPM-release-settings,XP-4526-resource-managment-fix,XP-3161-pom-cleanup,XP-139-xbid-3,true,"07/Jan/20 10:38;ek176;An example license.md file: [https://github.deutsche-boerse.de/dev/m7.energy-commons-process/blob/master/LICENSE.md]","10/Jan/20 15:22;ll664;Updated XBID repos, the rest (common projects) were already done by M7T team.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Comtrader Production Fix of deployment,XP-2278,88454,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Not a Bug,qo794,tm431,tm431,30/Oct/19 13:48,06/Nov/20 11:00,22/Feb/21 13:26,04/Nov/19 09:11,,,Pre2020,,,,,,,,,,,"*Check why proper index.html is not on production.* 

*Fix the missing antivirus check*

[http://m7trading.deutsche-boerse.com/xbid-prod/]
 [http://m7trading.deutsche-boerse.com/xbid-prod/comtrader-webstart-2.5.1.58-xbid-prod/index.html]
 [12:25|https://dbg-devops.slack.com/archives/C6KL30KM1/p1572434726273600]
 a webadmin guy Till Wiese (!https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/260e-fe0f.png!14000) created the index.html in the main folder with all the links pointing to subfolder
 [12:25|https://dbg-devops.slack.com/archives/C6KL30KM1/p1572434754274000]
 all http only; https will be solved later on",,qo794,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41126400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,30/Oct/19 13:48,,,,,,,,,,,,,,,,,,,,,,,"1|y09q33:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 38,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Nov/19 09:06;qo794;The jenkins deploy script (https://englobjci1.deutsche-boerse.de/job/Energy/job/ComTrader%20build%20uber%20package%20(2.1%20and%202.5%20only)/) seems to be correct, the generated file contains the main index.html file (see https://englobjci1.deutsche-boerse.de/job/Energy/job/ComTrader%20build%20uber%20package%20(2.1%20and%202.5%20only)/lastSuccessfulBuild/artifact/comtrader-webstart/target/comtrader-webstart-2.5.1.58-xbid-prod-uber-package.zip)

*Confirmed, everything is working fine, there was a manual step (https->http) during the last prod deployment and the package was not created correctly*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA reports - October,XP-2274,88366,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,zi174,zi174,29/Oct/19 11:02,06/Nov/20 10:25,22/Feb/21 13:26,05/Nov/19 13:37,,,Pre2020,,,,,,,,,,,"Please provide SLA reports as usual

Thanks",,uv683,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/19 13:36;uv683;XBID Performance and SM SLA Reporting October 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/76555/XBID+Performance+and+SM+SLA+Reporting+October+2019.xlsx","05/Nov/19 13:36;uv683;XBID Service Boundary Reporting October 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/76556/XBID+Service+Boundary+Reporting+October+2019.xlsx","05/Nov/19 13:36;uv683;XBID_Credit_points_report_October_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/76554/XBID_Credit_points_report_October_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40953600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n3h:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/19 13:36;uv683;Hello [~zi174],[~qm925] [~gd553],

 

please find reports for October attached.

Regards

Jakub ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Upgrade Elasticsearch/Kibana to 6.8,XP-2251,87925,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,hw120,zi174,zi174,17/Oct/19 14:28,04/Aug/20 19:35,22/Feb/21 13:26,01/Nov/19 15:02,,,Pre2020,,,,,,30/Sep/19 00:00,MONITORING,TechOpsBoard,,,https://github.deutsche-boerse.de/dev/energy.monitoring/issues/798,,hw120,zi174,,,,,,,,,,,,,,,,,,,TECHLOG-1186,,,TECHLOG-1187,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41299200,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n3h:z9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 37,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Nov/19 15:01;hw120;Cluster upgraded, updated ansible deployment and fixed many breaking changes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Clean up Consul Token,XP-2250,87924,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,zi174,zi174,17/Oct/19 14:23,31/Aug/20 15:39,22/Feb/21 13:26,31/Oct/19 20:53,,,Pre2020,,,,,,31/Oct/19 00:00,,,,," Currently we are using only the bootstrap token or acl_master/agent_token in our patroni config.yml file. 

Thats the wrong way to use it!
[https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/global/consul/xb-xbid-simu|https://slack-redir.net/link?url=https%3A%2F%2Fenglobvault.deutsche-boerse.de%2Fui%2Fvault%2Fsecrets%2Fsecret%2Flist%2Fglobal%2Fconsul%2Fxb-xbid-simu%2F&v=3]

We have to create a new token called ""acl_patroni_token"" and use this token with the right policy instead of the other one. 
We also have to clean up the vault entries, because currently its very messy. 

[~hw120] will create for us the acl_patroni_token for xbid-test, xbid-simu and xbid-prod and store it in vault. 


Before xbid deployment end of october we should already update the key for production. The other env´s should come step by step. A small downtime will be necessary because we have to restart patroni-services for all patroni-nodes. 

Once this is done we have to update energy.automation.deployment patroni-playbook to query the correct vault token.",,hw120,zi174,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41385600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 37,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/19 22:12;hw120;Created new ACL policy and tokens for XBID Prod. All applied and tested.","31/Oct/19 20:47;hw120;Created documentation for manual steps

https://confluence.energy.svc.dbgcloud.io/display/ET/Configuring+Consul+tokens+and+ACLs+for+cluster+and+client+agents","31/Oct/19 20:48;hw120;SIMU and TEST clusters will be done in the next ticket together with automation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE - Configure Replication to the DataLake (Simulation Patronic-Cluster) ,XP-2249,87923,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cs687,zi174,zi174,17/Oct/19 14:16,05/Feb/20 15:22,22/Feb/21 13:26,18/Oct/19 12:36,,,7tops_pre-sprint0_cleanup,,,,,,31/Aug/19 00:00,,,,,"The Following design will be configured for the Replication to DataLake.

We will increase the 4 patroni-node cluster in XBID simulation with 2 Virtual Machines (xbsimudbr1, xbsimudbr2) (only patroni-cluster member !no LEADER!) which will be placed in 2 different subnets (Datalake).
That means we will have to deal with 6 subnets!

2 for consul (later, currently running local!)
 2 for postgres (xbtestpdb1,3 | xbtestpdb2,4)
 2 for DBR/datalake every node must be able to talk to consul

All of these nodes must be able to communicate with consul, postgres and patroni must be able to talk between themselves.

+Firewallrequests:+

We should create the following Firewall-requests
1.) From VM´s (xbsimudbr1/2) in Datalake to +Consul-Simu+ with Port 8500 (to figure out who is currently the leader)

- xbsimudbr1 -> xbsimupdb1:8500 (consul)
- xbsimudbr1 -> xbsimupdb2:8500 (consul)
- xbsimudbr1 -> xbsimupdb3:8500 (consul)
- xbsimudbr1 -> xbsimupdb4:8500 (consul)
- xbsimudbr2 -> xbsimupdb1:8500 (consul)
- xbsimudbr2 -> xbsimupdb2:8500 (consul)
- xbsimudbr2 -> xbsimupdb3:8500 (consul)
- xbsimudbr2 -> xbsimupdb4:8500 (consul) 



2.) The Ports for +patroni+ (25302,25402) and +postgres+(25102, 25202) must be opened in both directions.
- xbsimudbr1 -> xbsimupdb1:25102|25202 (postgres)
 - xbsimudbr1 -> xbsimupdb2:25102|25202 (postgres) 
- xbsimudbr1 -> xbsimupdb3:25102|25202 (postgres) 
- xbsimudbr1 -> xbsimupdb4:25102|25202 (postgres) 

- xbsimudbr2 -> xbsimupdb1:25102|25202 (postgres)
 - xbsimudbr2 -> xbsimupdb2:25102|25202 (postgres) 
- xbsimudbr2 -> xbsimupdb3:25102|25202 (postgres) 
- xbsimudbr2 -> xbsimupdb4:25102|25202 (postgres)


- xbsimudbr1 -> xbsimupdb1:25302|25402 (patroni) 
- xbsimudbr1 -> xbsimupdb2:25302|25402 (patroni) 
- xbsimudbr1 -> xbsimupdb3:25302|25402 (patroni) 
- xbsimudbr1 -> xbsimupdb4:25302|25402 (patroni) 

- xbsimudbr2 -> xbsimupdb1:25302|25402 (patroni) 
- xbsimudbr2 -> xbsimupdb2:25302|25402 (patroni) 
- xbsimudbr2 -> xbsimupdb3:25302|25402 (patroni) 
- xbsimudbr2 -> xbsimupdb4:25302|25402 (patroni) 

- xbsimupdb1 -> xbsimudbr1:25302|25402 (patroni) 
- xbsimupdb2 -> xbsimudbr1:25302|25402 (patroni)
- xbsimupdb3 -> xbsimudbr1:25302|25402 (patroni)
- xbsimupdb4 -> xbsimudbr1:25302|25402 (patroni)

- xbsimupdb1 -> xbsimudbr2:25302|25402 (patroni) 
- xbsimupdb2 -> xbsimudbr2:25302|25402 (patroni)
- xbsimupdb3 -> xbsimudbr2:25302|25402 (patroni)
- xbsimupdb4 -> xbsimudbr2:25302|25402 (patroni)

We have in DataLake only PROD and ""Shared SIMU/TEST"", for this reason we should connect to Consul in Simu env from Datalake SIMU/TEST

FYI: [~wm282], [~yo218], [~du271]",,cs687,zi174,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2335,,,XP-2245,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,42595200,,,,,,,,,,,,,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 37 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/19 12:36;cs687;finished. Description in TECHLOG-Ticket 
https://jira.deutsche-boerse.com/browse/TECHLOG-2335",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CLONE - XBID LDAP, test envs - all users have expired password",XP-2248,87921,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,cs687,zi174,zi174,17/Oct/19 14:02,31/Aug/20 15:39,22/Feb/21 13:26,17/Oct/19 14:58,,,7tops_pre-sprint0_cleanup,,,,,,18/Oct/19 00:00,TO4XBID,TO-JOB,,,"In test LDAP xbdtldap1.deutsche-boerse.de all users have expired password.

Example:
uid=SADMIN01,ou=syt1,o=xbid,dc=energy,dc=test
uid=SYSOPS01,ou=syt1,o=xbid,dc=energy,dc=test

I can add more if needed.

No XBID test env can be used at the moment -> CRITICAL
",,cs687,zi174,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2926,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,42595200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 37 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Oct/19 14:58;cs687;https://jira.deutsche-boerse.com/browse/TECHLOG-2926
for all systemtest1/2/3, dst1 and perf users i changed the password-expiration from 2019 to 2028",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"DWH - Finalization: Presentation, Documentation",XP-2247,87913,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hw120,de698,ek176,17/Oct/19 12:30,04/Aug/20 19:36,22/Feb/21 13:26,24/Oct/19 14:40,,,Pre2020,,,,,,,,,,,"To be estimated/realized after: XP-810 XP-1245 XP-1459

The integration part of DWH PoC:
DoD: 
* E and T jobs are running (no manual intervention, manually deployed)
* Each (month/week) a new KPI report is saved to HDFS
* E job is maintaining it's status (last ID) in a HDFS file
* KPI report is correct
* Description in Confluence
* Presentation to the Energy (not only XBID)
* Describe monitoring and troubleshooting",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/19 15:46;ek176;190829_tests_performance_flink_yarn_flink_run.ods;https://jira.deutsche-boerse.com/secure/attachment/75965/190829_tests_performance_flink_yarn_flink_run.ods",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42076800,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5k:l",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 36 [S],Alpha Team Sprint 37,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/19 15:50;ek176;Added performance tests results (Flink vs Flink+Yarn) on WordCount example on larger files (freebase, up to 15 GiB) for {{entestdwh[1-5]}} hosts. Conclusions:

  * Use default parallelism of 8 

  * Use Flink (not flink-yarn)

  * For yarn, use -ys=1 for -p between 4..15; Use -ys=2 for higher parallelism

 

*Note*: The WordCount example is rather IO intensive, not computational.","23/Oct/19 20:37;ek176;Confluence docu: [http://confluence.energy.svc.dbgcloud.io/display/EDW/XBID+Report+PoC]

Presentation (Overview): [https://github.deutsche-boerse.de/dev/xbid-etl/blob/develop/doc/DWH_PoC_Overview.md]

Presentation (Tech): [https://github.deutsche-boerse.de/dev/xbid-etl/blob/develop/doc/DWH_PoC_Tech.md] 

Relevant README.md files were updated

xbid-etl repository was cleaned","23/Oct/19 20:40;ek176;energy.datalake ANsible update merged: [://github.deutsche-boerse.de/dev/energy.datalake/pull/4|https://github.deutsche-boerse.de/dev/energy.datalake/pull/4]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Preparing: Guardium on patroni-cluster machines (PROD-Databases),XP-2246,87912,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,jj069,jj069,17/Oct/19 12:29,31/Aug/20 15:39,22/Feb/21 13:26,07/Nov/19 15:35,,,7tops_pre-sprint0_cleanup,,,,,,,TO-JOB,waiting-3rdparty,,,,,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,Guardium agent was successfully installed on the database-hosts xbprodpdb1-4 without any issues. ,,,,,,,,,,,,,,42681600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09jtb:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 37 [S],Home Office Team 38,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Configure Replication to the DataLake (Simulation Patronic-Cluster),XP-2245,87911,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs687,jj069,jj069,17/Oct/19 12:28,05/Feb/20 15:22,22/Feb/21 13:26,18/Oct/19 12:38,,,7tops_pre-sprint0_cleanup,,,,,,,TO-JOB,,,,,,cs687,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,42595200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09jtb:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 37 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/19 12:38;cs687;finished.
Description in https://jira.deutsche-boerse.com/browse/TECHLOG-2335

seems to be like a duplicate 
https://jira.deutsche-boerse.com/browse/XP-2249

[~zi174]please create a Clone for TECHLOG-
https://jira.deutsche-boerse.com/browse/TECHLOG-2756

Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Investigate why was DB not accesible for more then 20s on XBID CUTE,XP-2244,87905,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Cannot Reproduce,,jj069,jj069,17/Oct/19 11:11,31/Aug/20 15:39,22/Feb/21 13:26,19/Nov/19 15:07,,,Pre2020,,,,,,,TO-JOB,,,,https://jira.deutsche-boerse.com/browse/TECHLOG-2839,,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042201w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 15:07;yo218;Nothing could be found but it didn't happen again",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: XBID PROD Network glitch,XP-2243,87904,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Cannot Reproduce,,jj069,jj069,17/Oct/19 11:11,31/Aug/20 15:38,22/Feb/21 13:26,19/Nov/19 15:08,,,Pre2020,,,,,,,TO-JOB,,,,https://jira.deutsche-boerse.com/browse/TECHLOG-2887,,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042201s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 15:08;yo218;linked ticket has bee closed already with the following comment:
""I will close the ticket with the resoluation: ""cannot reproduce"" , proberly it happened a network glitch.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Prod alerts from 12.10.,XP-2242,87903,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,hw120,jj069,jj069,17/Oct/19 11:11,13/Aug/20 19:41,22/Feb/21 13:26,08/Jan/20 12:43,,,3.1.0,,,,,,,TO-JOB,waiting-3rdparty,,,https://jira.deutsche-boerse.com/browse/TECHLOG-2888,,hw120,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,35510400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000000001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 37,Alpha Team Sprint 38 [S],Alpha Team Sprint 39,Alpha Team Sprint 40 [S],Christmasprint,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/19 21:06;hw120;Waiting for influxdata support to analyze the problem and came up with the solution.","08/Jan/20 12:42;hw120;Influxdata support wasn't able to identify the cause of the problem.

The only lead is to overloaded kapacitor instance, particularly memory usage, therefore I will be optimizing existing kapacitor tasks/alerts to use less memory.

Will be handled in https://jira.deutsche-boerse.com/browse/TECHLOG-3103",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: sFTP access for PROD,XP-2240,87901,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,17/Oct/19 11:10,04/Aug/20 19:35,22/Feb/21 13:26,19/Nov/19 14:57,,,Pre2020,,,,,,,TO-JOB,,,,"https://jira.deutsche-boerse.com/browse/TECHLOG-2871
",,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042201k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 14:57;yo218;already done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Enhance wiki page XBID timeouts in PROD with infrastructure timeouts,XP-2239,87900,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,17/Oct/19 11:10,31/Aug/20 15:38,22/Feb/21 13:26,19/Nov/19 14:58,,,Pre2020,,,,,,,TO-JOB,,,,https://jira.deutsche-boerse.com/browse/TECHLOG-2885,,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042201g",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 14:58;yo218;already done: [https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Timeouts+in+PROD+environment]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"CLONE: XBID prod, reporting engine - provide GC logs",XP-2238,87899,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,17/Oct/19 11:10,31/Aug/20 15:39,22/Feb/21 13:26,19/Nov/19 14:59,,,Pre2020,,,,,,,TO-JOB,,,,"https://jira.deutsche-boerse.com/browse/TECHLOG-2886
",,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042201c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 14:59;yo218;already done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CLONE: Update XBID SIMU SFTP config,XP-2236,87897,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,17/Oct/19 11:09,31/Aug/20 15:39,22/Feb/21 13:26,19/Nov/19 14:59,,,Pre2020,,,,,,,TO-JOB,,,,"https://jira.deutsche-boerse.com/browse/TECHLOG-2899
",,jj069,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,39744000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010422014",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/19 14:59;yo218;already done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hardcoded password in clear text,XP-2232,87828,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,zi174,zi174,16/Oct/19 13:59,31/Aug/20 13:23,22/Feb/21 13:26,13/Aug/20 15:09,,,3.1.1,,,,,,,,,,,"Please be complaint with a statement: 
 • Passwords must not be hardcoded in clear text in the source code or configuration files.

 

*Only reporting-engine remaining.* 

*Caution: spring security uses some password policy* 
h2. Acceptance Criteria

Fix reporting engine to not use hardcoded passwords

 ",,ei349,ne232,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17712000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bb93:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 15 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,cpm,why-optional,ramping-analysis,XP-3443-recursion,XP3421-david,develop,XP-3230,XP-2232,master,master-acceptance,XP-3443-rounding,XP-4273-owasp-zap-enable,XP-3421-david,XP-3829-routing-integration,acceptance,XP-4526-resource-managment-fix,XP-3520-ramping_analysis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Apr/20 13:32;ei349;(flag) Flag added

to refine","24/Jul/20 08:33;ne232;[~ei349], [~zi174]: the requirement in the new IS Access Control Standard is:
User passwords (including technical accounts) must not be stored in systems in plaintext format (i.e. configuration files) and should be suitably protected (i.e. hashed and salted).	
-> Are user credentials not stored in plaintext and are technical accounts stored in a vault?
","31/Jul/20 14:56;ei349;Dear [~ne232]: correct, our credentials are stored in Vault and application retrieves them. We identified that only remaining item is reporting-engine and we will do the migration for it in upcoming sprint. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Password history ,XP-2231,87824,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,zi174,zi174,16/Oct/19 13:52,31/Aug/20 15:38,22/Feb/21 13:26,28/Aug/20 13:50,,,3.1.1,,,,,,,,,,,"According to Access Control Standard, it's necessary to be complaint with a statement:

* New passwords must be different from the last 6 passwords.

TO has to change this on LDAP. Investagation from TO side needed.

Acceptance criteria: 
- syt1 ldap migrated to reflect new rules 
- validation against this rule in the application where password can be changed",,ei349,gd553,od044,qm925,tr866,ub113,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/19 16:45;tr866;sm_screenshot_11.12.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/78490/sm_screenshot_11.12.2019-001.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,15379200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 40,Christmasprint,HOT Sprint 0 (S),HOT Sprint 1,HOT Sprint 2 (S),HOT Sprint 3,HOT Sprint 4 (S),HOT Sprint 5,HOT Sprint 6 (S),HOT Sprint 7,HOT Sprint 8 (S),HOT Sprint 9,HOT Sprint 10 (S),HOT Sprint 11,HOT Sprint 12 (S),HOT Sprint 13,HOT Sprint 14 (S),HOT Sprint 15,HOT Sprint 16 (S),,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/19 15:05;zi174;As [~yo218] has started working on it, I added this task to current HOT sprint. ","09/Dec/19 15:08;yo218;values was changed from 5 (current value) to 6:
{noformat}
passwordInHistory: 6 {noformat}","10/Dec/19 11:46;tr866;in XBID the authentification looks working correctly, password can't be changed to any password which was in history 6 passwords back.
On the other hand I noticed that for user SADMIN01(which is used the most) the rules are set up differently and password must contain an uppercase with error
""error code 19 - invalid password syntax - password must contain at least 1 uppercase characters""

Regarding Shipping Module I am not able to get to LDAP with Apache Directory Studio and I am not able to login either with password xbidtest01 or xbidTest01! for example with user SPMADM01.","10/Dec/19 11:50;tr866;And also jenkins job for Syt1 for resetting password is not working
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID%20LDAP%20syt_perf/
{quote}ldap_bind: Server is unwilling to perform (53)
	additional info: Unauthenticated binds are not allowed{quote}
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/XBID%20LDAP%20syt_perf/31/console","11/Dec/19 08:51;yo218;""On the other hand I noticed that for user SADMIN01(which is used the most) the rules are set up differently and password must contain an uppercase with error""

correct, I added a new, proper policy for this user 

 

""Regarding Shipping Module I am not able to get to LDAP with Apache Directory Studio and I am not able to login either with password xbidtest01 or xbidTest01! for example with user SPMADM01""

the LDAP tree for SM in syt1 didn't exist for any reasons. I recreated it, it should work now. I also applied a new, proper policy for user SPMADM01 

 

""And also jenkins job for Syt1 for resetting password is not working""

Same reason as above - password reset didn't work because the entries (and the whole tree) didn't exist","11/Dec/19 15:10;tr866;I can connect to SM LDAP already, but I realised that the password field for all users is not accessible.
I am connecting in Apache Directory with uid=xbid-syt1-adm,ou=syt1,o=sm,dc=energy,dc=test and password test01.
","11/Dec/19 15:17;yo218;[~tr866] I will check what is the issue there.  But why is it required? Can't you just use the application for the verification?","11/Dec/19 15:22;tr866;I can't sadly at the moment :(. I entered another 2 techlog tickets for Syt1 today, because Shipping Module is not working and deployment is not possible, also amqp connection doesn't work. When the environment will work again I want to do it from the application too. Wanted to test it in Apache Directory instead as workaround.","11/Dec/19 15:24;yo218;I see. than I will rather start with fixing the env and then we can follow up on this issue","11/Dec/19 15:28;tr866;Ok, thank you.","11/Dec/19 16:54;tr866;After making Shipping Module to work it wasn't possible to change the password in the end. I guess it could be related to the same reason why I couldn't access the password fields in the Apache Studio.
!sm_screenshot_11.12.2019-001.png!


{code:xml|title=xb_xbid_syt1_smi-1_standard_ixe.log|borderStyle=solid}2019-12-11T15:46:57.329Z [nio-8010-exec-8][SPMADM01][] INFO  c.d.m.s.s.UserServiceImpl - Password change failed due to: 
com.deutscheboerse.passwd.service.PasswordException: Unable to change password, reason: insufficient access rights
        at com.deutscheboerse.passwd.service.impl.PasswdServiceLdapImpl.changePasswordInLdap(PasswdServiceLdapImpl.java:455)
        at com.deutscheboerse.passwd.service.impl.PasswdServiceLdapImpl.changePassword(PasswdServiceLdapImpl.java:282)
        at com.deutscheboerse.m7.shipping.service.UserServiceImpl.changePassword(UserServiceImpl.java:50)
        at com.deutscheboerse.m7.shipping.service.UserServiceImpl$$FastClassBySpringCGLIB$$9b60582d.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
        at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:749)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294)
        at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.cache.interceptor.CacheInterceptor.lambda$invoke$0(CacheInterceptor.java:53)
        at org.springframework.cache.interceptor.CacheAspectSupport.invokeOperation(CacheAspectSupport.java:365)
        at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:420)
        at org.springframework.cache.interceptor.CacheAspectSupport.execute(CacheAspectSupport.java:345)
        at org.springframework.cache.interceptor.CacheInterceptor.invoke(CacheInterceptor.java:61)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688)
        at com.deutscheboerse.m7.shipping.service.UserServiceImpl$$EnhancerBySpringCGLIB$$5975c53a.changePassword(<generated>)
        at com.deutscheboerse.m7.shipping.mvc.AuthController.changePassword(AuthController.java:57)
        at com.deutscheboerse.m7.shipping.mvc.AuthController$$FastClassBySpringCGLIB$$1e1cb2bc.invoke(<generated>)
        at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
        at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:684)
        at com.deutscheboerse.m7.shipping.mvc.AuthController$$EnhancerBySpringCGLIB$$891059a5.changePassword(<generated>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:189)
        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005)
        at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
{code}","12/Dec/19 08:26;yo218;found and fixed a typo in the aci. Please try again","12/Dec/19 10:38;tr866;Successfully tested in environment Syt1 with version XB R2.0.28-4b60c263c682fc6b91d76be7d2de72f1f486b140, SM 2.0.12
Tried to change password in SOB, CMM, CMI, SM WebGUIs and changing of password works as requested. Password can't be changed to any of the last 6 passwords. For example when changing from xbidtest01 to xbidtest02, xbidtest03..., it's needed to change passwords incrementally untill xbidtest08 so that xbidtest01 is not in history anymore and so that it's possible to change password back to xbidtest01.","12/Dec/19 11:50;zi174;[~yo218] [~tr866] So, as far as I understand that, activating this password policy doesn't have any impact on our system and no further development won't be necessary (regarding bugfix, code updates etc.), right? ","12/Dec/19 12:33;yo218;[~zi174]this is correct. Someone just have to decide how to proceed. We can either
 * Keep it on Simu on Prod with 5
or
 * Just change the value from 5 to 6 on all LDAP servers
or
 * Change the Password Regime where it is described, inform the customer about it, let them test in some customer environment and then proceed with Simu and Prod afterwards

 ","12/Dec/19 12:35;zi174;[~yo218] Thank you for the confirmation, we will discuss with [~ei349] and find which approach would be the best :).

","13/Dec/19 09:41;ei349;Thank you [~zi174] and [~yo218], I think the third option is the best for us:

""Change the Password Regime where it is described, inform the customer about it, let them test in some customer environment and then proceed with Simu and Prod afterwards""

Dear [~gd553], can you please check if we need to inform our customers and inform them if needed? Thank you. ","17/Jan/20 11:58;gd553;[~ei349] can we please discuss this in the next Core meeting - I would like to understand if this is a change, from where does it come and what impact it has on the customers.","23/Jan/20 16:09;gd553;I have discussed this ticket with [~ei349] and agreed on the following:
 * [~yo218] to inform us when the value can be changed from 5 to 6 on all LDAP servers;
 * [~yo218] or [~zi174] to update the password regime document accordingly;
 * Once the 2 AIs above are done, I can send out the updated password regime document and inform the clients when the change will take place.

 ","24/Jan/20 09:58;yo218;Please replace my name with something like ""one of the dedicated TO4XBID guys""","20/Feb/20 13:12;yo218;Who is now reviewing this ticket? It is still assigned to [~zi174]

In case you expect me to do something here, please update the status and I will start working on it.","12/May/20 15:56;zi174;Hi,
[~gd553] the document has been updated. Do we need any approval from customer side? If not, just let me and [~yo218] know to implement this modification on the production.
The document can be found [here|https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fps0080%2FShared%20Documents%2F04%20XBID%20Legal%20Framework%2F05%20Technical%20Documents%2FUSM700%20Password%20Regime%20Document&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44&View=%7B6C81558C%2DB2AA%2D42D3%2DA854%2DB2860B7C1829%7D ] - version 3.7","25/May/20 11:41;gd553;Hi [~zi174]

We need to inform the customers. But as stated in my comment on 23/01 - I would need to know when the value can be changed. Then we can send out the updated password regime document and inform the clients when the change will take place.

[~qm925]- fyi

 ","25/May/20 16:50;zi174;Hi [~gd553],

Basically that was my question if we need the approval before the change is implemented. I understand that we do not need any approval from the customer, so I will discuss with Niklas the date and let you know...

 

Jakub","26/May/20 08:07;gd553;Hi [~zi174]

What I was saying is that I would like to inform customers before we implement the change. But I would need to know when Niklas is able to make the change so I can include that detail in the communication.

Malina","26/May/20 15:40;zi174;Hi [~gd553],

The change has been planned on Wednesday 10.6.2020.

 

Jakub","28/May/20 12:09;gd553;Hi [~zi174] and [~yo218]

The change will not impact Production, right? You do not need any downtime? This can be done seamlessly?

Based on this, ACM can word the email informing customers of the change on 10.06.2020 and provide the updated document.

Thanks!","28/May/20 13:24;zi174;[~gd553] this change will impact the production. The parameter will be modified on the production environment. We do not need any downtime.

That was the reason why I've asked you if we need an approval before the change is implemented..... 

 

Jakub

 

 ","28/May/20 13:52;zi174;I created a deployment ticket for that - https://jira.deutsche-boerse.com/browse/SERVICE-6415","28/May/20 15:12;ei349;[~zi174]: i suggest to deploy this issue together with 3.1 release in autumn. Please do not forget to update [~rehapav]'s  future ticket with this request. 

[~qm925], [~gd553], [~ub113], [~yn731]: this is one of things which needs to be communicated to customers. 

Jiri","29/May/20 09:32;gd553;If the change can wait until the 3.1 Release launch, then I am fine with Jiri's proposal. We then just need to inform the clients beforehand.","04/Aug/20 19:57;ei349;Dear [~ub113] and [~qm925] , this ticket is also connected to password policies and needs to be communicated to customers. ","05/Aug/20 13:50;qm925;[~ub113], based on your initial draft I propose the following communication:

Dear Lindsay, dear Camilla, dear Vladimir,

Currently, all passwords need to be different from the last 5 passwords. According to a security standard regulation all new passwords must be different from the last 6 passwords.

*Solution:*
In order to be compliant with this requirement, DBAG will change the value of the LDAP parameter _passwordInHistory_ to 6.
**

*Impact:*
Users will not be allowed to reuse the last six passwords.
**

*Implementation:*
This change will be implemented with R.3.1

[~ei349] please confirm if this wording is fine with you.","05/Aug/20 16:31;ei349;well written. Fine for me","05/Aug/20 16:41;ub113;This is communicated in XBID-5197","19/Aug/20 13:37;ei349;Please align with all necessary people and make this change effective with 3.1.1 deployment to UATs. ","19/Aug/20 14:31;ei349;approved for 3.1.1","27/Aug/20 17:25;od044;Verified on SYT1 
- password cannot be the same as the last 6 one in history  - (/)
- password can be reused in case it is not within the last 6 - (/)"
Prepare Tech Ops onboarding to XBID teams,XP-2228,87771,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jj069,jj069,15/Oct/19 14:25,06/Nov/20 10:21,22/Feb/21 13:26,31/Oct/19 09:40,,,Pre2020,,,,,,,,,,,"*Benefit*
*{color:#00875A}Save time during each person rotating within XBID team as TO in upcomming 9 months (4 weeks than 6 weeks in JAN).

Enable TO people to work with us from as fast as possible. 
{color}*

*Current Solution*
- none

*Proposed Solution*
- Create checklist of steps to onboarding
- It should not contain reading list through all documents since there is no value in overloading TO guys :) 
- Some of items will require team ""buddy"" to assist newcommer going through some items
- Focus on our pipeline (TO) can help there a lot
- part of it is access to our communication channels
- the checklist will improve over time and can change at any time in future

*Acc Crit*
- our dev pipeline (anything before artifactory is black box for them)
- checklist is done


*Notes:*
some documents at Confluence are already created and can help us: https://confluence.energy.svc.dbgcloud.io/display/ED/New+Developer+Checklist
https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID
https://confluence.energy.svc.dbgcloud.io/display/TD/XBID+GIT+Workflow
https://confluence.energy.svc.dbgcloud.io/display/TD/_Commons
https://confluence.energy.svc.dbgcloud.io/display/TD/M7+NextGen+-+Brief+Overview
",,jj069,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41472000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09mpa:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 37,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/19 14:23;uv683;new confluence pages created

[https://confluence.energy.svc.dbgcloud.io/display/XBID/Modules+overview]

https://confluence.energy.svc.dbgcloud.io/display/XBID/Code+Changes+Pipeline",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace gs-collections with eclipse-collections,XP-2214,87640,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,11/Oct/19 13:44,04/Aug/20 19:53,22/Feb/21 13:26,22/Jan/20 14:37,,,3.1.0,,,,,,,,,,,"The lib is not maintained anymore and contains some nasty bugs (XP-2213). 

Replace it with its successor {{eclipse-collections}}.

We should do the same for SM, xbid.routing and any other project that uses it.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43200000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09lgw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,selenide-poc,xbid-losses-poc,XP-PULL-TEST,XP-3230,XP-2694-xbid-3.0.x-latest-tag-fix,XP-3094-sonar-gate,XP-TEST,XP-3161-develop,XP-3070,testing-new-stages,xbid-2.0.25.x,fixing-failover,master-xbid-losses-poc,plewmic-scripts,XP-2635-redo-fix-3.0,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,XP-456,XP-2979-postgresql,XP-3264,XP-2521-labeling-cmi-leftovers,develop,XP-2232,XP-2694,testing-new-stages-3.0,master,XP-TEST2,master-acceptance,XP-4273-owasp-zap-enable,inline-tomcat-params,acceptance,XP-3161-pom-cleanup-develop,XP-4526-resource-managment-fix,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Application labeling: GUI ,XP-2211,87563,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,zi174,zi174,10/Oct/19 12:53,13/Aug/20 20:12,22/Feb/21 13:26,27/Mar/20 10:47,,,3.1.0,,,,,,,,,,,"*UPDATE: only printable items needs to have label. Remove elsewhere.* 

 

According to the data leakage standard, it's necessary to label all documents, reports, GUI etc. which are visible/send to the customer. We have to provide an information of the security classification (public, internal, confidential, strictly confidential)

· All DBG documents, physical and electronic, must be labelled based on the confidentiality of included information.

· DBG strictly confidential and confidential information shall only be disclosed outside DBG to companies and individuals who have signed a Non-Disclosure / Confidentiality clauses or according to a regulatory requirement.

!screenshot-1.png!

Affected areas:
 *GUI* - for the apache login window - check the possibility of free text)
 * CMM (login page*, application - 1SP)
 * SOB (login page*, application - 1SP)
 * CMI (login page*, application - 1SP)
 * SM (login page*, application - 1SP)
 * ComTrader (login page*, application - 1SP)

*Reports (XP-2521)*
 * SLA reports - (Performance, XBID availability, Service Boundaries, Credit points -1SP)
 * ACER Reports - 1SP
 * CMM/CMI reports - ATC, TAR, RCA, NSF, NetP, RID, IAR, OCC, BG Allocation, Results Document, Right Document, Messages Report, Allocated Capacity Report, ATC Values report, Activity Report, Balancing Group Report, User - 5SP
 * Report
 * SOB reports - TC540, TC810, TC830 - 1SP
 * SM reports - SHC, SXC, SHS, XBR, XBN, HNS, HNT, CTS - 2SP

*Emails (XP-2520)*
 * all emails sent to the customer need labeling - preliminary consideration is to set this label in email client - just keep in mind that the email must have a same classification as sent file/document

 - 5SPs

*If applicable",,ei349,ek176,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2521,XP-2520,,,,,,,,,,,,,"29/Oct/19 09:02;zi174;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/76154/screenshot-1.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,29289600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2210,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0a99e:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,Alpha Sprint 1 (S),Alpha Sprint 2,Alpha Sprint 3 (S),Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-3161-pom-cleanup-develop,XP-2942-losses-perf,xbid-losses-poc,develop,XP-3094-sonar-gate,XP-3161-develop,master,master-acceptance,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/Oct/19 15:36;zi174;XML files doesn't have to be labeled. ""Insider info"" only printable reports need to be labeled. ","04/Dec/19 15:48;ei349;TODO split into subtasks","08/Jan/20 12:54;ek176;Issue split into:
|XP-2520|Application labeling: e-mails|
|XP-2521|Application labeling: Reports|
","20/Mar/20 08:09;ek176;FYI: I've noticed, that by mistake the old GUI (XBID/SPM) commits were tagged XP-1211 instad of XP-2211 (correct).

Not changing GIT history, as we're reverting anyway.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
The concept of Segregation of Duties (SoD) ,XP-2207,87552,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,10/Oct/19 10:07,01/Oct/20 12:51,22/Feb/21 13:26,27/Nov/19 10:40,,,Pre2020,,,,,,,,,,,Create the concept of Segregation of Duties (SoD) ,,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Oct/20 12:51;zi174;Segregation of Duties XBID.xlsx;https://jira.deutsche-boerse.com/secure/attachment/88115/Segregation+of+Duties+XBID.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43286400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010422008i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Authorization Concept,XP-2206,87551,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,th409,zi174,zi174,10/Oct/19 10:06,17/Dec/20 14:04,22/Feb/21 13:26,17/Dec/20 14:04,,,,,,,,,,,,,,Create the Authorization concept for XBID,,ne232,th409,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/20 15:54;zi174;Authorization_Concept_XBID.doc;https://jira.deutsche-boerse.com/secure/attachment/89456/Authorization_Concept_XBID.doc","20/Nov/20 15:17;th409;Draft_Authorization_Concept_XBID.docx;https://jira.deutsche-boerse.com/secure/attachment/90171/Draft_Authorization_Concept_XBID.docx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8035200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042200fr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/20 08:34;ne232;[~ei349], [~zi174]: This is still required ; i.e. also in the new version of the standards.","20/Nov/20 15:18;th409;See first draft here:  [^Draft_Authorization_Concept_XBID.docx] . needs to be reviewed, valid only for SOB system (not CMM).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID 2.0 go life - provide effort estimations for go life deployment,XP-2196,87423,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,08/Oct/19 15:28,06/Nov/20 10:14,22/Feb/21 13:26,14/Oct/19 15:02,,,Pre2020,,,,,,14/Oct/19 00:00,,,,,"based on
 * scope of the release
 * technical changes
 * duration results of conversion test of XBID PROD database 1.5.11 -> 2.0

 

provide final estimation for XBID 2.0 deployment duration

 

I work with the assumption it will take 3 hours

 

30/10 from 9:10 till 12;10",,ei349,hw120,rehapav,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-4568,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43286400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09k74:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/19 10:02;ei349;[~rehapav]: from development point of view max. 1 hour is expected. 

[~yo218], [~ox626]: can you please estimate TechOps part of R2.0 (Mainly the Patroni preparations)

[~hw120]: can you please check with infrastructure (Ioanna) how long will it take the WKA removal. 

[~rehapav]: can you please include those results in your release planning and coordinate needed people and resources? 

 

Thank you all. ","09/Oct/19 11:34;hw120;Ioana wrote that {color:#212121}changing the routing will have a 2 mins outage.{color}","10/Oct/19 08:43;yo218;* Migration of the main database to patroni: 2 hours 
 * Migration of the ECP database to postgres: 1 hour (can be done in parallel)
 * Kernel update of all internet facing VMs: 30 minutes (can be done in parallel)
 * Deployment with data migration: 10 minutes

So the three hours in total should be okay, four hours would be even better in case one step fail and need to be repeated

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
prepare MRs for XBID 2.0 deployment ,XP-2195,87422,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,rehapav,rehapav,08/Oct/19 15:23,06/Nov/20 10:14,22/Feb/21 13:26,30/Oct/19 10:20,,,Pre2020,,,,,,,,,,,"prepare all necessery MRs for XBID 2.0 deployment on 30/10

 

details for the deployment are in SERVICE-4568

 

 ",,eg288,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-4568,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41644800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09jt8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 37 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/19 08:53;rehapav;Due date is 23/10 EOB in order to have sufficient time for techops review.","23/Oct/19 10:01;eg288;See MR xbid-2.0 deployment configuration into PROD:
http://example.com]https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/511

What is missing:
* Apache config change done by Tuan on 23.4.2019 in SIMU (simu__xbid_ctp.conf --> simu__xbid_ctp_chain.conf xb_ds_cust.conf --> xb_ds_cust_chain.conf xb_spm_ds_cust.conf --> xb_spm_ds_cust_chain.conf)
** *No action required* according to Tuan, details below
**  This change was introduced due to expired certs in SIMU. New certs are from Sectigo. Thus the Apache config change was required.
** The PROD certs expires in March 2020. Then some change/action will be needed according to Tuan

PPROD cert valid till March 2020
{code}
issuer    CN = COMODO RSA Organization Validation Secure Server CA,O = COMODO CA Limited,L = Salford,ST = Greater Manchester,C = GB
Subject    CN = prod2.xbid.deutsche-boerse.com,OU = Multi-Domain SSL,OU = Hosted by Deutsche Borse Aktiengesellschaft,OU = Cash & Derivatives IT Operations,O = Deutsche Boerse AG,street = Mergenthalerallee 61,L = Eschborn,ST = Hessen,postalCode = 65760,C = DE
Valid From    10 Mar 2017, midnight
Valid To    9 Mar 2020, 11:59 p.m.
{code}

Questions:
* Cert can be updated now according to Tuan or we can wait till March 2020","25/Oct/19 12:55;rehapav;Link is 

[https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/511|http://example.com]https//github.deutsche-boerse.de/dev/energy-mkt-shared/pull/511]

 ","25/Oct/19 12:57;rehapav;As per agreement on 24/10 during XBID 2.0 MR preparation walk throu please
 * merge linked MR
 * run consistency check on it","28/Oct/19 18:59;rehapav;[Niklas Albers|https://app.slack.com/team/U3R89E90X]  [3 days ago|https://dbg-devops.slack.com/archives/G3X4L43GW/p1572019992128200?thread_ts=1572001115.121400&cid=G3X4L43GW]
I merged it and renamed the configs. New one isa called xbid_prod2.0, the old one is named xbid_prod. Just started the check_config and it failed with the following error:
## Missing variable / password / DB config issue summary :
ERROR : Connection test failed for 10.139.95.191 / xbprodctp / xbprodctp 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-ctp2
ERROR : Connection test failed for 10.139.95.191 / xbprodctp / xbprodctp 
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
ERROR : Connection test failed for 10.139.95.191 / xbprodcmi / xbprodcmi 
ERROR : Connection test failed for 10.139.95.191 / xbprodspm / xbprodspm 
ERROR : Connection test failed for 10.139.95.191 / xbprodspm / xbprodspm 
ERROR : Connection test failed for 10.139.95.191 / xbprodrep / xbprodrep 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-cor2
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-sob2
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-cmm2
ERROR : Connection test failed for 10.139.95.191 / xbprodcor / xbprodcor 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-cmi2
ERROR : Connection test failed for 10.139.95.191 / xbprodcmi / xbprodcmi 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-smc2
ERROR : Connection test failed for 10.139.95.191 / xbprodspm / xbprodspm 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-smi2
ERROR : Connection test failed for 10.139.95.191 / xbprodspm / xbprodspm 
WARNING : Secondary tomcat instances should not have DB migration scripts set - xbid-prod-rep2
ERROR : Connection test failed for 10.139.95.191 / xbprodrep / xbprodrep but it looks the same for simu, so maybe it is ok. [@Pavel Rehak|https://dbg-devops.slack.com/team/U4FV7JP6V] [@jiri.kuchta|https://dbg-devops.slack.com/team/U1G8XML5C]","29/Oct/19 10:37;eg288;After discussion with [~yo218] I beleive it *it is OK*, in other words the errors reported by check_config are false alarms.

Notes:
* database connection was tested by [~yo218] successfully, so the db migration should work
* the warnings _Secondary tomcat instances should not have DB migration  ..._ are regarding setup which is used in all our doublesided envs, so do not change it, let's stick with the working and proven configuration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change XBID 3.0.x API namespace and packages to v3,XP-2160,87190,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,01/Oct/19 13:58,06/Nov/20 11:34,22/Feb/21 13:26,08/Oct/19 10:46,,,Pre2020,,,,,,,,,,,Change the API so that {{com.deutscheboerse.m7.trading.api.v1}} is {{com.deutscheboerse.xbid.trading.api.v3}},,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44064000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ivs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,Alpha Team Sprint 36 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-1261-guava-28,master-3.0.x,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2160-api-rename,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,xbid-api-3.0.x,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA reports - September,XP-2159,87185,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,01/Oct/19 13:05,06/Nov/20 10:25,22/Feb/21 13:26,15/Oct/19 10:31,,,Pre2020,,,,,,,,,,,"Please provide SLA reports as usual

Thanks",,ei349,gd553,uv683,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-762,,,,,,,"02/Oct/19 13:38;uv683;XBID Performance and SM SLA Reporting September 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/74616/XBID+Performance+and+SM+SLA+Reporting+September+2019.xlsx","07/Oct/19 10:24;uv683;XBID Service Boundary Reporting September 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/74820/XBID+Service+Boundary+Reporting+September+2019.xlsx","02/Oct/19 13:38;uv683;XBID_Credit_points_report_September_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/74615/XBID_Credit_points_report_September_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43372800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ivw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,Alpha Team Sprint 36 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Oct/19 13:40;uv683;Hi [~qm925] [~gd553] [~zi174],

please find august reports attached. Do some sanity check if needed and use them. They are not uploaded into sharepoint yet. If you will find that they are fine, feel free to upload them. New template is used for SLA report.

Regards

Jakub Hesoun","07/Oct/19 08:50;ei349;Please see new growth estimates for this reports. ","07/Oct/19 09:07;zi174;[~uv683]
Might you please check:
XBID performance SLA report - Order execution Time tab - 2019-09-14 16:00:00	2019-09-14 17:00:00	1.56848E+12	1.56848E+12 (line 334)
RabbitMQ time - 2019-09-14 16:00:00	2019-09-14 17:00:00 (line 334)

Please can you generate the Service boundary report again with a template https://jira.deutsche-boerse.com/browse/XP-2005 I somehow attached a wrong version without formatting changes :( 

Thank you




","08/Oct/19 10:42;gd553;[~uv683]

Regarding [~zi174]comment above, please check the API Response Time tab as well for the same period it looks fishy.

Let me know when I can review the Performance Report.","09/Oct/19 12:44;uv683;*Why are there numbers such as 1568478387317 in Order Execution Time and API Response Time?*

These occured on 14.9. between 16 and 17 UTC. During that time Hausen DC power maintenance was ongoing and Core Down happened. Core in Equinix was not running and it was brought back online around 16:25:47 UTC. At first it checked out all messages from journal. These messages failed to process when core down happened. Core reprocessed them again and updated received timestamp to 0. When e.g  API response time is calculated this received timestamp is taken into account and is subtracted from a timestamp at which message ack was sent. Subtracting zero means that only message ack timestamp is used and it has a format of number of milliseconds from 1.1.1970. It will hugely impact the output. The same applies for Order Execution Time as well.

This issue will occur only when there is a failover and some messages are replayed by journal.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLAs: Growth Estimation Update,XP-2158,87178,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,qm925,qm925,01/Oct/19 10:51,06/Nov/20 10:25,22/Feb/21 13:26,07/Oct/19 12:30,,,Pre2020,,,,,,,,,,,"Dear DBAG,

Let me provide you with the monthly update for July 2019 growth estimation:
 * growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):
 * Number of Block Orders (daily), as a subset of the orders = -3%
 * Number of Explicit Requests (daily) = 0%
 * Number of Explicit Allocations (daily) = 0%
 * Number of Hubs = this is known to DBAG (2nd wave data set)
 * Number of Borders = this is known to DBAG (2nd wave data set)
 * Sustainable Load Items = 12%

*Please take into consideration while preparing the SLA reports for September 2019*",,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2159,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44064000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09itc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 35 [S],Home Office Team Sprint 36,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Go through backlog and search for techops related jiras,XP-2153,87141,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eh941,eh941,30/Sep/19 14:28,06/Nov/20 10:14,22/Feb/21 13:26,02/Oct/19 10:41,,,Pre2020,,,,,,,,,,,,,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44064000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ikc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID: Verification of the production configuration,XP-2151,87103,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,gd553,gd553,gd553,27/Sep/19 14:36,06/Nov/20 10:14,22/Feb/21 13:26,16/Oct/19 10:38,,,XBID 2.0,,,,,,,support_request,,,,Please check first comment in the ticket.,,gd553,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2832,M7ACM-743,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,42768000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09idc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/19 14:38;gd553;*+The customers came with the following request:+*

Dear DBAG,

Let me inform you that with regard to preparation for 2^nd^ GL the NOMOs and TSOs are considering verification of the production configuration related to the launch process.

For the time being we consider that copy of the production should be made into LIP B environment where we would carry out the test of the configuration.

*In this respect I would like you to confirm that a copy of the production environment in the dedicated testing environment can be executed. We expect that it will follow an agreed process  meaning that you need to be informed one week in advance and the copy of prod env will be executed on Wednesdays following the date or request and one week time for preparation.*

Please let me know by the end of week.

Best Regards,

Vlada

*+I have answered the following:+*

Dear Vladimir,

Before we can answer your question below, I would need to know exactly what configuration parameters do the Parties want to copy? As this is not a “normal” copy job and it is not covered by ASR015, I would like to have clarity on what exactly the Parties want to copy and for what do the Parties need this.

Best regards

Malina

*+Their answer again was:+*

Dear Malina,

The technical detail may be discussed with MSD. The principal idea is to ensure that the 2^nd^ GL configuration process works well. In order to do so we should have an environment which is as closed as possible to the production to identify potential issue in our configuration process. We are still discussing details of the process and we will come back to you next week.

What is clear we cannot copy the communication information otherwise we would impact operation in the local systems.

Best Regards,

Vlada

*+And their conclusion from today:+*

Dear Malina,

Referring to your request to clarify what configuration parameters do the Parties want to copy see the response of MSD below:
 * Reference data similarly as specified under ASR015 are to be copied *except for*
 * User accounts
 * Communication channels (PROD local systems shall not be polluted)
 * FTCs (PROD local systems shall not be polluted)

Please let me know if you have any further questions.

Kind regards

David","27/Sep/19 14:39;gd553;According to Niklas, the exception can be done for the communication channels, however somebody from the development team should confirm that the User Accounts and the FTCs can be left out. Thus please investigate and let me know

 ","30/Sep/19 16:21;gd553;[~ei349] - Any updates on this one? I would need an answer pretty fast. Thanks!","01/Oct/19 11:20;qo794;* User accounts - it's not possible to exclude users when copying DB from one env to another, we can only change (""fake"") their emails so customers do not receive emails (and it's also done within a DB copy script by techops - https://confluence.energy.svc.dbgcloud.io/display/ET/Copy+data+from+one+DB+to+another)
* FTCs - theoretically all FTCs can be changed to GUI (CMI) or WS (SPM) channels, but files will still be generated, only not sent out. Moreover if all communication channels are disabled (see the point below) this step will just ensure that really no file goes out.
* Communication channels:
** ECP - env specific, not configured in DB. If invalid ECP server configured in an application properties file, ECP won't be working (=disabled)  - {color:red}NOT PART OF THE TECHOPS SCRIPT AT THE MOMENT{color}
** Email - ""faking"" emails for users, TSOs and other entities should be sufficient - already included in the techops copy procedure https://confluence.energy.svc.dbgcloud.io/display/ET/Copy+data+from+one+DB+to+another
** Sftp - env specific, the sever is not configured in DB, only users - already included in the techops copy procedure https://confluence.energy.svc.dbgcloud.io/display/ET/Copy+data+from+one+DB+to+another
** SCP - must be ""disabled"" in DB manually - {color:red}NOT PART OF THE TECHOPS SCRIPT AT THE MOMENT{color}","16/Oct/19 10:38;gd553;Customer ticket closed, closing this ticket as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create XBID timeouts reference wiki page,XP-2141,86925,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,24/Sep/19 15:24,06/Nov/20 10:14,22/Feb/21 13:26,12/Nov/19 10:36,,,Pre2020,,,,,,,waiting-techops,,,,"Create XBID timeouts reference wiki page for production env.  Include also shipping and infrastructure timeouts.

https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID+Timeouts+in+PROD+environment",,eg288,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43200000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042393c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 35 [S],Home Office Team Sprint 36,Home Office Team 37 [S],Home Office Team 38,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Oct/19 16:37;jy268;SMC / SMI added",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test  improved journal file cleanup script,XP-2140,86900,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,eg288,eg288,24/Sep/19 10:12,06/Nov/20 10:14,22/Feb/21 13:26,12/Nov/19 10:44,,,Pre2020,,,,,,,,,,,The improved journal file cleanup script should delete whole directories not individual files. See TECHLOG-2818 for details.,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40435200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09j3q:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 35 [S],Home Office Team Sprint 36,Home Office Team 37 [S],Home Office Team 38,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/19 10:44;eg288;Tested in xbid syt1 env. Updated cleanup script works as expected. Only complete directories are removed, so the files in each journal directory are consistent all the time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve INFO logging for capacity publish,XP-2135,86837,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,ll664,ll664,23/Sep/19 11:01,11/Nov/20 10:50,22/Feb/21 13:26,11/Nov/20 10:50,,,3.1.x,,,,,,,,,,,"""No capacity issues"" are very frequently cause of production problems, see XP-2112.

Improved capacity publish logging so it clear:

* what interconnectors/delivery areas are involved
* what delivery days 
* what are the quantities (per delivery interval)
* whether it's default capacity publish or capacity based on submitted files
* whether it's automatic/manual publish

",,ek176,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,8899200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:v",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Oct/20 08:50;qo794;All details are basically already present in core logs, the only issue here is that dates/times are in long and require converting to a human readable format:
{code:title=prod-core-default-publish-example.log}
2020-10-18T15:45:00.792Z [Unmarshaller][][2dcfa500] TRACE c.d.e.m.t.M.incomingMessage - [simple type, class com.deutscheboerse.energy.m7.cmm.api.publish.DefaultCapacityPublishRequest] - {""userId"":""SYSTEM"",""automatic"":true,""interConnectorId"":43,""date"":1603058400000}
{code}
{code:title=prod-core-publish-example.log}
2020-10-18T15:52:29.680Z [Unmarshaller][][1b4d1e39] TRACE c.d.e.m.t.M.incomingMessage - [simple type, class com.deutscheboerse.energy.m7.cmm.api.publish.CapacityPublishRequest] - {""userId"":""SYSTEM"",""automatic"":false,""day"":1603058400000,""publishmentDataList"":[{""areaFrom"":""10YDK-2---
-----M"",""areaTo"":""10YDE-VE-------2"",""resolution"":60,""networkCapacities"":[{""prdStart"":1603058400000,""q"":0,""priority"":0},{""prdStart"":1603062000000,""q"":0,""priority"":0},{""prdStart"":1603065600000,""q"":0,""priority"":0},{""prdStart"":1603069200000,""q"":0,""priority"":0},{""prdStart"":1603072800000
,""q"":0,""priority"":0},{""prdStart"":1603076400000,""q"":0,""priority"":0},{""prdStart"":1603080000000,""q"":0,""priority"":0},{""prdStart"":1603083600000,""q"":0,""priority"":0},{""prdStart"":1603087200000,""q"":0,""priority"":0},{""prdStart"":1603090800000,""q"":0,""priority"":0},{""prdStart"":1603094400000,""q"":0
,""priority"":0},{""prdStart"":1603098000000,""q"":0,""priority"":0},{""prdStart"":1603101600000,""q"":0,""priority"":0},{""prdStart"":1603105200000,""q"":0,""priority"":0},{""prdStart"":1603108800000,""q"":0,""priority"":0},{""prdStart"":1603112400000,""q"":0,""priority"":0},{""prdStart"":1603116000000,""q"":0,""prio
rity"":0},{""prdStart"":1603119600000,""q"":0,""priority"":0},{""prdStart"":1603123200000,""q"":0,""priority"":0},{""prdStart"":1603126800000,""q"":0,""priority"":0},{""prdStart"":1603130400000,""q"":0,""priority"":0},{""prdStart"":1603134000000,""q"":0,""priority"":0},{""prdStart"":1603137600000,""q"":0,""priority"":
0},{""prdStart"":1603141200000,""q"":0,""priority"":0}]},{""areaFrom"":""10YDE-VE-------2"",""areaTo"":""10YDK-2--------M"",""resolution"":60,""networkCapacities"":[{""prdStart"":1603058400000,""q"":0,""priority"":0},{""prdStart"":1603062000000,""q"":0,""priority"":0},{""prdStart"":1603065600000,""q"":0,""priority"":
0},{""prdStart"":1603069200000,""q"":0,""priority"":0},{""prdStart"":1603072800000,""q"":0,""priority"":0},{""prdStart"":1603076400000,""q"":0,""priority"":0},{""prdStart"":1603080000000,""q"":0,""priority"":0},{""prdStart"":1603083600000,""q"":0,""priority"":0},{""prdStart"":1603087200000,""q"":0,""priority"":0},{""p
rdStart"":1603090800000,""q"":0,""priority"":0},{""prdStart"":1603094400000,""q"":0,""priority"":0},{""prdStart"":1603098000000,""q"":0,""priority"":0},{""prdStart"":1603101600000,""q"":0,""priority"":0},{""prdStart"":1603105200000,""q"":0,""priority"":0},{""prdStart"":1603108800000,""q"":0,""priority"":0},{""prdStar
t"":1603112400000,""q"":0,""priority"":0},{""prdStart"":1603116000000,""q"":0,""priority"":0},{""prdStart"":1603119600000,""q"":0,""priority"":0},{""prdStart"":1603123200000,""q"":0,""priority"":0},{""prdStart"":1603126800000,""q"":0,""priority"":0},{""prdStart"":1603130400000,""q"":0,""priority"":0},{""prdStart"":160
3134000000,""q"":0,""priority"":0},{""prdStart"":1603137600000,""q"":0,""priority"":0},{""prdStart"":1603141200000,""q"":0,""priority"":0}]}],""filesBeingPublished"":[51869800]}
{code}","10/Nov/20 14:16;ek176;Example: DefaultPublishRequest
{code:java}
2020-11-10 14:14:25.613  INFO 4087 --- [    CoreService] m.c.i.t.DefaultPublishRequestTransformer : DefaultCapacityPublishRequest for user: User [racfId=TSOADM01, traderId=01-XADMIN-ALL--LTSOAD1, balancingGroup=01-XADMIN-ALL--L], interConnector: AMP-APG, date: 2020-11-10T00:00:00.000+01:00, automatic: false
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Review the DB cleanup scripts,XP-2134,86836,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,iv732,ll664,ll664,23/Sep/19 10:56,23/Sep/20 15:41,22/Feb/21 13:26,23/Sep/20 15:41,,,3.2.x,,,,,,,,,,,"When invetigating XP-2112, we realized that {{cmm_233_inter_connector_status_history}} is needlessly cleaned up after 40 days, which prevented to see full IC halting history.

The cleanup is not necessary as the table does not contain that much data. Same goes for {{cx_002_market_state_history}}.

Review all tables in cleanup scripts, remove the potential tables dropped by R2.0 and submit the scripts to techops. They'll need to put them into their cleanup tools.

The scripts are located in {{src/main/db/history-cleanup}}.",,iv732,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,13046400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0bdql:zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 17 (S),Alpha Sprint 18,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,acceptance,XP-3550,develop,XP-2134,master-acceptance,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Sep/20 12:44;ll664;Removed following tables, as they do not contain much data and its content is helpful for troubleshooting:
{noformat}
cmm_233_inter_connector_status_history
cx_002_market_state_history
{noformat}

I've also reviewed if some tables weren't removed in the meantime (in some code cleanup etc.), but all DBs (cor/cmi/sm) looks OK.

[~iv732] could you please update XBID DB cleanup Jenkins job with new list of tables for COR DB:

https://github.deutsche-boerse.de/dev/xbid/blob/develop/src/main/db/history-cleanup/cor.sql

If you don't know which one it is, Niklas was the one maintaining this. ","23/Sep/20 15:40;iv732;[~ll664] 

I removed those tables from the Jenkins job:  [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID-Cleanup-DBs-Select/]

Now the list looks like this:

 
{code:java}
BEGIN;
DELETE FROM cmm_101_allocation_history WHERE id IN (SELECT id FROM cmm_101_allocation_history WHERE allocated_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_106_allocation_metadata_history WHERE id IN (SELECT id FROM cmm_106_allocation_metadata_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_121_capacity_history WHERE id IN (SELECT id FROM cmm_121_capacity_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cmm_131_contract_history WHERE contract_id IN (SELECT contract_id FROM cmm_131_contract_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_101_order_history WHERE order_id IN (SELECT order_id FROM cx_101_order_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_111_trade_history WHERE trade_id IN (SELECT trade_id FROM cx_111_trade_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_117_trade_allocation_history WHERE allocationid in (SELECT allocationid FROM cx_117_trade_allocation_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_151_messages_history WHERE message_id IN (SELECT message_id FROM cx_151_messages_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_211_contract_history WHERE contract_id IN (SELECT contract_id FROM cx_211_contract_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_296_session_history WHERE session_id IN (SELECT session_id FROM cx_296_session_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_441_contract_delivery_area_state_history WHERE id IN (SELECT id FROM cx_441_contract_delivery_area_state_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);
DELETE FROM cx_673_trade_flow_history WHERE trade_flow_id IN (SELECT trade_flow_id FROM cx_673_trade_flow_history WHERE last_update_time < '$OLDDATE' AND revtype = 2);COMMIT;
VACUUM cmm_101_allocation_history;
VACUUM cmm_106_allocation_metadata_history;
VACUUM cmm_121_capacity_history;
VACUUM cmm_131_contract_history;
VACUUM cx_101_order_history;
VACUUM cx_111_trade_history;
VACUUM cx_117_trade_allocation_history;
VACUUM cx_151_messages_history;
VACUUM cx_211_contract_history;
VACUUM cx_296_session_history;
VACUUM cx_441_contract_delivery_area_state_history;
VACUUM cx_451_holidays_history;
VACUUM cx_673_trade_flow_history;
EOF
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failover tests pipeline reports success even though the tests are failing,XP-2131,86782,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,20/Sep/19 14:34,04/Aug/20 19:36,22/Feb/21 13:26,15/Oct/19 14:55,,,Pre2020,,,,,,,TO-JOB,,,,"Currently all tests are green, but if one fails, the build is green anyway.

There is a problem with Extended Cucumber Runner we use to retry test scenarion. It doesn't report test results correctly.

The idea is to check the test results in {{verify}} phase manually - via bash script?",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44928000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09gi0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 36 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH PoC Execute and verify outcome,XP-2125,86700,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,19/Sep/19 10:42,04/Aug/20 19:36,22/Feb/21 13:26,03/Oct/19 11:12,,,Pre2020,,,,,,,,,,,"Our task is to be as close to streaming mode as possible. 

* Refactor T task (Beam) to use the saved Parquet file
* Connect both E and T tasks (data passing)
* Trigger the E task (Flink) and subsequently the T task
 ",,ek176,,,,,,,,,,,,,,,,,,,,XP-812,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45100800,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09dbr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,poc_finalized_with_scratches,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PMIs go down when waitng for queue,XP-2123,86694,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,tm431,tm431,19/Sep/19 09:22,06/Nov/20 11:12,22/Feb/21 13:26,03/Oct/19 12:13,,,Pre2020,,,,,,,,,,,"After env. is started,  all 6 PMI Loggers go up as well but  it takes some time for rabbitmq to get created because CMI and core are starting. PMI logger cannot connect to given queues where it should listen to and probably times out after some time. It will not reconnect without restart . Therefore it is not logging no messages and we have a gap in them until someone notice.

 

*{color:#57d9a3}We should define telly improve PMI loggers.{color}*

 

Jakube Hesoun has more info.

 

Workarond is to restart them after 5min the env. is restarted or rabbits are restarted.",,eh941,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43891200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09dbr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,tomcat-rollback,traversal-XP-2485,XP-2942,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,trailing-slash-syt1,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Oct/19 12:56;eh941;Before LIPA, LIPB or SIMU deployment please do [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/485]

To use it on other environments the following must be changed for PMI instance:

* {{LOCAL_ADDR}} must be set
* {{AMQP_ADMIN_PORT}} must be set - note that on some envs this is a global env
* Change template to {{standalone/pmi-logger/application_1-1-TEMPLATE.properties}} 

If it isn't clear check the MR above

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Investigate why journal files were incoplete in SIMU and one DB not in cluster,XP-2121,86691,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,tm431,tm431,19/Sep/19 09:18,06/Nov/20 11:12,22/Feb/21 13:26,24/Sep/19 10:22,,,Pre2020,,,,,,,,,,,"*{color:#57d9a3}SUPPORT TECHOPS with investigation{color}*

 

TECHLOG-2793

This is issue is for investigation why this happen and what solution can prevent occurance of this in the future. Also some monitoring layer could be introduced.

 

1) What happend August 28th 2019, 10:29:07., there was DC1->DC2 switch over.... But COR2 refused to start because of inconsistent journal, some files were missing.

Why? How can we prevent this. Can some monitoring layer be introduced which will check this.
{code:java}
August 28th 2019, 10:29:07.426ERROR
Unexpected error occurred in scheduled task.
java.lang.AssertionError: java.io.FileNotFoundException: /xbid/journal/m7-msgs/20190824/data-2739-0
    at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.index(VanillaChronicle.java:412)
    at net.openhft.chronicle.VanillaChronicle$AbstractVanillaExcerpt.nextIndex(VanillaChronicle.java:426)
    at com.deutscheboerse.energy.m7.core.in.journal.Replayer.next(Replayer.java:36)
    at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.replayMessagesIfAny(M7LifecycleManagerImpl.java:300)
    at com.deutscheboerse.energy.m7.M7LifecycleManagerImpl.replayMessagesFromJournal(M7LifecycleManagerImpl.java:349) {code}
 

 

2) There was one DB which was not in cluster but was running xbsimupdb1. It looks like that it was only in read only mode, and our applications could write there. We need to investigate why this DB was not in clustered mode. How to prevent it. Or introduce some monitoring layer which will check this.

 
{code:java}
here are quite some connections on xbsimupdb1David Siro 14:14what? that machine is not even a cluster memberNiklas Albers 14:14for example:291741 | xbsimuspm | 26689 |    16425 | uapp01xbsimusla | PostgreSQL JDBC Driver | 10.139.43.233 |                 |       40652 | 2019-08-28 13:54:24.471991+02 |                               | 2019-08-28 13:54:24.475104+02 | 2019-08-28 13:54:24.475117+02 | f       | idle   |             |              | SET application_name = 'PostgreSQL JDBC Driver'
 293679 | xbsimucmi |  8332 |    16387 | uapp01xbsimucmi |                        | 10.139.43.42  |                 |       42682 | 2019-08-28 12:32:00.815317+02 | 2019-08-28 12:32:06.545235+02 | 2019-08-28 12:32:06.559518+02 | 2019-08-28 12:32:06.559519+02 | f       | active |   123735745 |              | COMMIT
 293679 | xbsimucmi |  8427 |    16387 | uapp01xbsimucmi |                        | 10.139.43.42  |                 |       42698 | 2019-08-28 12:32:51.581579+02 | 2019-08-28 12:32:51.601476+02 | 2019-08-28 12:32:51.604511+02 | 2019-08-28 12:32:51.604511+02 | t       | active |             |    123735745 | SELECT * FROM QRTZ_LOCKS WHERE SCHED_NAME = 'persistentScheduler' AND LOCK_NAME = $1
FOR UPDATE
David Siro 14:14this is nice  {code}
 

more info can be found in  slack channel failover-xmq-1-3-down*. I also attach the whole communication into this ticket. [^SIMU incoplete journal techlog-2793]

 

*3) THERE WAS CORE FAILOVER ALSO on 15/09/2019 this has something to do with*  *GlusterFS and SFTP FIREWALL problems???*
 Please confirm. How should this be prevented? New monitoring etc.

 
{code:java}
Environment: Mgmt_Simulation Launched: 2019/09/15 - 17:54:03 XBID
 FR_AE_007: XBID core is down, failover has been initiated. All orders 
of global products are hibernated in LTS and all orders are removed from
 XBID. Follow procedure XBID_NEMO_BUP_01, case 3: ""SOB is down"".SMSMgmt_Simulation: 2019/09/15 - 17:54:03 XBID FR_AE_007: XBID core is down, failover has been initiated. {code}",,eg288,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2793,,,,,,,"19/Sep/19 09:19;tm431;SIMU incoplete journal techlog-2793;https://jira.deutsche-boerse.com/secure/attachment/74135/SIMU+incoplete+journal+techlog-2793",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45014400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042396i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 35 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/19 16:38;eg288;ad 3) timeline
 2019-09-13T13:23:55.584Z *CORE-2* stop - errors unable to connect to rabbitmq cluster: Attempting to connect to: [xbsimubha2:51100, xbsimubha4:51100], because the cluster had been shutdown before, CORE-1 was OK no errors around that time

2019-09-15T15:54:07.401Z *CORE-1* stop - no errors in the log, it looks like the shutdown was triggered manually
 2019-09-15T16:00:16.947Z *CORE-1* start - started as a SLAVE, it did not become MASTER although there was no other CORE running 
 2019-09-15T17:53:48.676Z *CORE-2* start - the node become MASTER immediately

 *NOTES:*
 * CORE-2 had been stopped manually on Friday before Hausen power maintenace
 * there is no journal file related error in SIMU CORE-1 (there was one issue on PROD at 15.9. 13:58 UTC, see TECHLOG-2818 explaining why we have FileNotFound exceptions in journal handler from time to time)
 * not possible to explain why CORE-1 started as SLAVE, while CORE-2 started 2 hours later elected itself immediately as a master -> there was an issue reported for database on following Monday that all datetimes stored are in CET timezone (it should be UTC), it could be related",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM is not working on XBID CTPB,XP-2109,86581,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,17/Sep/19 13:34,06/Nov/20 10:59,22/Feb/21 13:26,01/Oct/19 12:53,,,Pre2020,,,,,,,,,,,"Patrik Cupak informed me that SM is not working on XBID CTPB

All other environments seem to be fine.

Please have a look

No external ticket created yet.",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45273600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09fe0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integration test with OPSGENIE,XP-2108,86553,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,radeale,radeale,16/Sep/19 16:46,13/Aug/20 19:47,22/Feb/21 13:26,03/Mar/20 09:59,,,3.1.0,,AlarmTilt,Capacity,Trading,,,AlarmTILT,,,,"Task is to validate whether OpsGenie application can replace AlarmTilt to what is needed for XBID (XP-1996).

It is important to perform an API integration test, i.e.:
 # Configure OpsGenie so that when an external event comes via the API, a message is sent to configured recipients (basically a AT event).
 # Trigger the event from XBID.
 # Validate the event was correctly triggered.

Currently OpsGenie is used extensively by the BizOps and they can create additional users on the go (contact Hugo).

The lint to the application:

https://deutsche-boerse.app.eu.opsgenie.com/",,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,30758400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2649,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Mar/20 09:59;radeale;Testing done in XP-1996.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor validations for new Orders,XP-2102,86527,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eh941,eh941,16/Sep/19 13:56,18/Feb/21 13:24,22/Feb/21 13:26,25/Oct/19 14:59,,,Pre2020,,,,,,,,,,,"Create a new validator set for creating a new order (OrderEntryRequest). It involves also {{ValidationService}}.

Don't use anything like {{ErrorKey}} to {{ErrorCodeAndKey}} map like it does now.

Reason: Improve code readability, make it easy to maintain and debug",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45360000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09mpb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 36 [S],Alpha Team Sprint 37,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-4530,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,master-xbid-losses-poc,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Simplify ConfigServiceImpl values loading,XP-2101,86526,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,eh941,eh941,16/Sep/19 13:52,04/Aug/20 19:53,22/Feb/21 13:26,20/Nov/19 09:06,,,3.1.0,,,,,,,,,,,"{{ConfigServiceImpl}} loads values from multiple places - there is a default XML file, then _platform_ XML file and then database values.

My suggestion is to have only DB values. Feel free to follow this suggestion or come up with other idea

Reason: Make the configuration transparent. Now it's very difficult to say which value is actually used.",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45360000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09j3r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 38,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,xbid-losses-poc,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,develop,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove or refactor RequestProcessor,XP-2100,86525,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eh941,eh941,16/Sep/19 13:47,04/Aug/20 19:35,22/Feb/21 13:26,02/Oct/19 10:36,,,Pre2020,,,,,,,,,,,"{{RequestProcessor}} uses {{EventHandler}} interface even though it's no event handler in any disruptor. Change that.

Please redesign also the method interface ({{onEvent}} - the name, parameters and maybe even the content.

Reason: increase code readability, reduce confusion",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45360000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09fj0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze existing TCs in cucumber end to end tests and prepare TC for Order entry,XP-2097,86431,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,13/Sep/19 10:52,12/Feb/21 12:11,22/Feb/21 13:26,12/Feb/21 12:11,,,Pre2020,,,,,,,TestAutomation,,,,"1. compare existing end to end tests scenarios for order entry vs RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
Order-Entry sheet
2. prepare new additional TCs and create a new tasks for them.
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/21 12:11;hj444;RTM-03-05-10_Matcher_and_Order_Maintenance_0.32_automation.xlsx;https://jira.deutsche-boerse.com/secure/attachment/92781/RTM-03-05-10_Matcher_and_Order_Maintenance_0.32_automation.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,864000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09eko:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/21 12:11;hj444;RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx reviewed sheet Order Entry.
comments in added excel v32_automation sheet Order Entry - added 2 columns :
   *Automation Jira* with a Jira where the TC is covered
*Automation Cucumber feature file* the name of feature file if TC is already covered in tests
Under Epic XP-60: Testing and Automation
New tasks created : 
XP-4542
XP-4545
XP-4551
XP-4570
XP-4571
XP-4572
XP-4573

Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve logging in core module's tests,XP-2096,86426,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,13/Sep/19 09:51,06/Nov/20 11:34,22/Feb/21 13:26,16/Sep/19 13:42,,,Pre2020,,,,,,,,,,,"There are these unnecessary messages:

{noformat}
Error executing DDL ""create index public.IDX110_001 IDX110_002 on public.CX_110_TRADE (CONTRACT_ID)"" via JDBC Statement
	at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlString(SchemaCreatorImpl.java:440) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlStrings(SchemaCreatorImpl.java:424) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.createFromMetadata(SchemaCreatorImpl.java:336) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.performCreation(SchemaCreatorImpl.java:166) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:135) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:121) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:155) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:310) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:467) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:708) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:724) [hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at com.deutscheboerse.energy.m7.failover.MasterSessionFactoriesFactory.buildDefaultSessionFactory(MasterSessionFactoriesFactory.java:59) [classes/:na]
	at com.deutscheboerse.energy.m7.failover.MasterSessionFactoriesFactory.create(MasterSessionFactoriesFactory.java:48) [classes/:na]
	at com.deutscheboerse.energy.m7.configuration.PersistenceConfiguration.persistenceProvider(PersistenceConfiguration.java:89) [classes/:na]
	at com.deutscheboerse.energy.m7.configuration.PersistenceConfiguration$$EnhancerBySpringCGLIB$$49713b20.CGLIB$persistenceProvider$0(<generated>) [classes/:na]
	at com.deutscheboerse.energy.m7.configuration.PersistenceConfiguration$$EnhancerBySpringCGLIB$$49713b20$$FastClassBySpringCGLIB$$562799d0.invoke(<generated>) [classes/:na]
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:244) [spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:363) [spring-context-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at com.deutscheboerse.energy.m7.configuration.PersistenceConfiguration$$EnhancerBySpringCGLIB$$49713b20.persistenceProvider(<generated>) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_202]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_202]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_202]
{noformat}


and 

{noformat}
2019-09-12 16:53:32.576 [main] WARN  - o.h.o.deprecation:87 - HHH90000014: Found use of deprecated [org.hibernate.id.SequenceHiLoGenerator] sequence-based id generator; use org.hibernate.id.enhanced.SequenceStyleGenerator instead.  See Hibernate Domain Model Mapping Guide for details.
{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45619200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ej0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,xbid-losses-poc,XP-2521-labeling-cmi-leftovers,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,XP-139-xbid-3,master-xbid-losses-poc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool - Analyze and implement minor issues,XP-2078,86034,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,05/Sep/19 08:49,04/Aug/20 19:35,22/Feb/21 13:26,11/Nov/19 15:50,,,Pre2020,,SLA Report Tool,,,,,,,,,"There are still few minor hiccups in order for the report tool to run smoothly and effortesly on production. 

Analyze and implement the following:
 * PERFORMANCE report: When report is generated on 1st of every month, it is missing the last day data (i.e. the last day of previous month). It is probably not collected yet for some reason.
 * PERFORMANCE report: in Excel template there is wrong conditional formatting rule on Trade sheet which highlight cells if number of trades is > 50000 instead of > 50000
 * BOUNDARY report: report is not generated because generation fails on memory. [~eh941] already implemented a fix for it which is merged in develop. Deployment of last version should fix this (will be done at the end of all these tasks)
 * BOUNDARY report: prognosion tab has broken links to other sheet, check if this works in Libre and regular Office and if there is difference between these two
 * When a job (collect, generate, acer...) is finished RUN_TIME is logged into log, however it is in seconds or nanosecond format. Change this to something human readable.
 * Analyze if cleaning of raw tables and old computed totals works on production as expected, if not fix it. I got an impression that it is not cleaned as it supposed to be (or not at all).
 * During performance, boundary and credit point report generation generator version is not added into the report on the Info tab.

 

After all these items are done, create a new release a prepare deployment on SIMU first and then PROD.

 ",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46310400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042200zzo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 36 [S],Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Compare results of performance testing vs current SLAs,XP-2076,86013,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,ei349,ei349,04/Sep/19 16:17,06/Nov/20 10:14,22/Feb/21 13:26,06/Sep/19 15:46,,,Pre2020,,,,,,,,,,,"*Order execution time output:*
+losses default rts wave 3:+
 !screenshot-3.png! 

+losses orderbook 30 rts wave 3:+
 !screenshot-4.png! 

*Public order books reports response output:*
+losses default rts wave 3:+
 !screenshot-1.png! 

+losses orderbook 30 rts wave 3:+
 !screenshot-2.png! ",,ei349,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/19 13:59;zi174;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/73473/screenshot-1.png","06/Sep/19 13:59;zi174;screenshot-2.png;https://jira.deutsche-boerse.com/secure/attachment/73474/screenshot-2.png","06/Sep/19 14:03;zi174;screenshot-3.png;https://jira.deutsche-boerse.com/secure/attachment/73475/screenshot-3.png","06/Sep/19 14:03;zi174;screenshot-4.png;https://jira.deutsche-boerse.com/secure/attachment/73476/screenshot-4.png","06/Sep/19 14:04;zi174;xbid_losses_default_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73477/xbid_losses_default_rts_wave3.xls","06/Sep/19 14:04;zi174;xbid_losses_orderbook_30_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73478/xbid_losses_orderbook_30_rts_wave3.xls",,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46224000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,04/Sep/19 16:17,,,,,,,,,,,,,,,,,,,,,,,"1|y09bz2:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 33 [S],Home Office Team Sprint 34,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/19 14:09;zi174;Order execution time for losses - *SLA not passed*
Public order book report resp - Degraded scenario passed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance RTS perf dataset for SM entities ,XP-2070,85999,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,od044,od044,04/Sep/19 14:11,06/Nov/20 11:34,22/Feb/21 13:26,25/Sep/19 10:56,,,Pre2020,,,,,,,,,,,"Enhance perf ""rts3-slicebperf-data-fake"" dataset for SM entities as CCP, SA, Exchange member settings for new parties. 

Reference to [^XTG - XBID_Configuration_R2.0 - v1.1.xlsx]

NOTE: It is due to issue SM ignores all trades come from SOB due to Exchange member configuration in SM has been properly set",,od044,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XBID-4663,,,,,,,"25/Sep/19 10:34;radeale;Dataset_rts3-slicebperf-data-fake_v1.3.60.xlsx;https://jira.deutsche-boerse.com/secure/attachment/74311/Dataset_rts3-slicebperf-data-fake_v1.3.60.xlsx","04/Sep/19 15:45;od044;XTG - XBID_Configuration_R2.0 - v1.1.xlsx;https://jira.deutsche-boerse.com/secure/attachment/73394/XTG+-+XBID_Configuration_R2.0+-+v1.1.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44582400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09bz0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 33 [S],Home Office Team Sprint 35 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Sep/19 11:53;od044;PR: [https://github.deutsche-boerse.de/dev/m7.m7-dataset/pull/112]","19/Sep/19 16:36;radeale;Please provide an updated version (1.2) so we can send it to the customers for the changes discussed for the ATPs.","25/Sep/19 10:56;od044;Done : [^Dataset_rts3-slicebperf-data-fake_v1.3.60.xlsx]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test internal ECP on new postgres DB [6.9.2019],XP-2068,85970,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,yo218,yo218,04/Sep/19 09:32,06/Nov/20 10:14,22/Feb/21 13:26,10/Sep/19 13:55,,,Pre2020,,,,,,30/Sep/19 00:00,,,,,"*Deadline by 6/9 because of the same migration on Cutes in CW37.*

In order to migrate from EnterpriseDB to Postgres, we started to migrate all ECP databases. Please verify whether ECP is still functional on SYT3 using xbinteedb1 on port 25508 (name of the databases: xbsyt3ecp+xbsyt3ecn)

 

 ",,od044,qo794,yo218,,,,,,,,,,,,,,,,,,,,,TECHLOG-2719,,,,,,,,,,,,,,,,,,,"10/Sep/19 13:54;od044;ecp-module-tso1.png;https://jira.deutsche-boerse.com/secure/attachment/73603/ecp-module-tso1.png","10/Sep/19 13:54;od044;ecp-module-xbid.png;https://jira.deutsche-boerse.com/secure/attachment/73604/ecp-module-xbid.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45878400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09chg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 34,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/19 08:18;yo218;Hi [~ei349], can you please push this ticket? I need some updates asap","10/Sep/19 11:42;qo794;The node is not working, invalid DB configuration for {{uapp01xbsyt3ecn}}:
{code}
Caused by: org.postgresql.util.PSQLException: FATAL: password authentication failed for user ""uapp01xbsyt3ecn""
{code}
[~yo218] please fix it.","10/Sep/19 12:25;yo218;[~qo794], it is fixed","10/Sep/19 13:54;od044;Test passed on SYT3
 * new ECP DB has been configured 
 * 
{code:java}
xbinteedb1.deutsche-boerse.de:25508/xbsyt3ecn {code}

- Files have been properly sent via ECP channel from CMI and SM module.

e.g. 
{code:java}
2019-09-10T11:41:31.792Z [ecpExec-1][][] INFO  c.d.m.s.s.EcpSender - Sending file 20190910_HNS_410001_11XID-CAPACITY-9_NOIS_ALL_DAs_100_1.xml through Ecp to 10V1001C--00001O (endpoint 11V0000000000064)nnn/
.
.
.
2019-09-10T11:44:32.157Z [TaskScheduler-2][][] WARN  c.d.m.s.s.CheckAcknowledgmentWithFallbackTask - Ack wasn't received on time for 20190910_HNS_410001_11XID-CAPACITY-9_NOIS_ALL_DAs_100_1.xml by ECP transport, will try secondary channel{code}
!ecp-module-tso1.png!!ecp-module-xbid.png!

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Deliver August KPI,SLA reports",XP-2067,85961,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,uv683,uv683,uv683,04/Sep/19 08:43,06/Nov/20 09:40,22/Feb/21 13:26,04/Sep/19 08:48,,,Pre2020,,,,,,,,,,,,,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/19 08:47;uv683;XBID Performance and SM SLA Reporting August 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/73362/XBID+Performance+and+SM+SLA+Reporting+August+2019.xlsx","04/Sep/19 08:47;uv683;XBID Service Boundary Reporting August 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/73363/XBID+Service+Boundary+Reporting+August+2019.xlsx","04/Sep/19 08:47;uv683;XBID_Credit_points_report_August_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/73361/XBID_Credit_points_report_August_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46396800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099nm:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/19 08:47;uv683;Hi [~qm925] [~gd553] [~zi174],

please find august reports attached. Do some sanity check if needed and use them. They are not uploaded into sharepoint yet. If you will find that they are fine, feel free to upload them.

Regards

Jakub Hesoun",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Step review : expect_buy_and_sell_orders_in_orderbook,XP-2065,85926,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,hj444,hj444,03/Sep/19 13:33,13/Aug/20 19:41,22/Feb/21 13:26,10/Jan/20 11:23,,,3.1.0,,,,,,,TestAutomation,,,,"* PblcOrdrBooksReqSteps: review step:_ expect_buy_and_sell_orders_in_orderbook._
-- *The problem is that the method counts only contracts and not orders in contract*

* After change all test using this step has to pass.

-- For more see already changed step :  verifyOrderBookDepth",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46483200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:v",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,HOT Sprint 0 (S),,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allocations Scenario After Hook to get ATC with initial values,XP-2063,85913,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tr866,tr866,03/Sep/19 11:43,04/Aug/20 19:35,22/Feb/21 13:26,20/Nov/19 11:08,,,Pre2020,,,,,,,,,,,"h5. Description:
Currently every scenario in Cucumber that executes either explicit(AllocationReq) or implicit(cross-border trade) allocation in one direction(DA1->DA2) keeps the ATC values in imbalanced state between the scenarios.

h5. Current behaviour:
After every scenario the capacity is re-published as a part of clean-up process, but already done allocations always stay in the system which leaves the ATC values with unpredictable numbers for following tests. Currently the quickest easiest way is to make a counter-allocation after such every test to have allocation of same value in both directions to get ATC value to its initial state. In longterm it will make feature files growing and difficult to maintain. 
Using the XBID functionality re-publishing of capacity, or uploading of NTC,ATC files doesn't overwrite the already done allocations.

h5. Expected behaviour:
Scenario After Hook could be improved in the way that it would reset already made allocations to 0, by cleaning it from Database for example. Or some method could be part of After Clean-Up that would make an allocation in the opposite direction for every contract and interconnector where any allocation was done to have Allocation values the same in both direction.

_Note: Here is the list of scenarios where currently the counter AllocationReq was added so far as a workaround to keep the tests running and that can be removed in the future after better solution will be found:_
explicitAllocation.feature:
# Scenario: Send AllocationReq and then verify with AllocationDataReq that initial AllocationReq is present in AllocationDataResp
#   Scenario: Send AtcDataReq to request existing available capacity, then sends AllocationReq and verify AllocationResp is received,
  then sends  AtcDataReq again and verify that available capacity has changed according to previously sent AllocationReq
# Scenario: When sending IOC AllocationReq then all allocation should be allocated fully or partially if there is some capacity available
# Scenario: Send ACE AllocationReq and verify that same minimal qty has been allocated for all allocation requests
# Scenario: Send AON AllocationReq and verify capacity smaller than ATC can be allocated
# Scenario: Send AON AllocationReq and verify capacity equal to maximum available ATC can be allocated
# Scenario: Send AON AllocationReq and verify capacity equal to minimum lot size can't be allocated when 0 is available on one of the contracts
# Scenario: Send AON AllocationReq and verify capacity can't be allocated when only the smallest lot size is missing on one of the contracts
# Scenario: Send AON AllocationReq and verify capacity can be allocated with different allocation for one contract
# Scenario: Verify ACE allocation by trader. Missing ATC of minimum size on one contract
# Scenario: Verify ACE allocation by trader. Make allocation of minimum size with 0 ATC only on one contract

internalCmmRequests.feature:
# Scenario: Send AllocationRequest (normally sent by CMM to core) and verify response.

icebergOrdersMatching.feature:
# Scenario: Verify that auction is possible for ICB slice when PPD = 0
# Scenario: Verify that auction is possible for ICB sell slice when PPD < 0
# Scenario: Verify that auction is possible for ICB sell slice when PPD > 0

regularOrderMatching.feature:
# Scenario: Trade time priority rule is applied -  TradeCaptureRprt, PblcTradeConfRprt, PblcOrdrBooksDeltaRprt broadcasts are delivered to traders
# Scenario: Trade with partial SELL execution -  TradeCaptureRprt, PblcTradeConfRprt, PblcOrdrBooksDeltaRprt broadcasts are delivered to traders
# Scenario: Trade with partial BUY execution -  TradeCaptureRprt, PblcTradeConfRprt, PblcOrdrBooksDeltaRprt broadcasts are delivered to traders
# Scenario:Verify that block order matching is possible.
# Scenario: Verify that the matching price is calculated in auction process - the price determination happens
# Scenario: Verify that the matching price is calculated in auction process - the price determination happens for multiple orders
# Scenario: Verify that the matching price is calculated in auction process - the price determination happens for the UDB
# Scenario: Verify that orders get matched from the ""longest"" to the ""shortest""
# Scenario: Verify that orders in auction got matched based on time priority

tradeCancel.feature:
# Scenario: Two traders with different member (exchange) will both send an order for different delivery areas and these will match and create a cross-border trade. Admin sends TradeCancelProcessRequest via public API canceling the trade.  We expect the trade to be unchanged because capacity could not be recalled.
# Scenario: Verify that it is not possible to cancel block trade in case there are no capacity in CMM. We expect error.
# Scenario: Verify that it is NOT possible to cancel block trade between two different member in case there are no capacity in CMM. We expect error.

tradeRecall.feature:
# Scenario: One trader from an exchange will sends two orders for different delivery areas and these will match and create a cross-border trade. Then trader requests a TradeRecall.  We expect recall rejected immediately without the need for acceptation because both traders have the same member and it is a local trade and capacity could not be recalled.
# Scenario: Two traders with different member (exchange) will both send an order for different delivery areas and these will match and create a cross-border trade. Then trader requests a TradeRecall.  Admin sends TradeRecallProcess via public API accepting the TradeRecall request.  We expect recall to be rejected.
# #10 admin accept cross-border no-change NO_REQ
 Scenario: Two traders with different member (exchange) will both send an order for different delivery areas and these will match and create a cross-border trade. Then trader requests a TradeRecall.  Admin sends TradeRecallProcess via public API accepting the TradeRecall request.  We expect recall to be not changed because recall was not requested.
# #12 admin reject cross-border no-change NO_REQ
Scenario: Two traders with different member (exchange) will both send an order for different delivery areas and these will match and create a cross-border trade. Then trader requests a TradeRecall.  Admin sends TradeRecallProcess via public API rejecting the TradeRecall request.  We expect recall to be not changed because recall was not requested.
# Scenario: Admin rejects recall request.Trader repeats Recall request on trade in status RREJ
# Scenario: Recall request for trade in Auction should not be possible
# Scenario: Trader repeats recall request for order in status RRQE
# Scenario: Recall a user defined block orders trade cross border trade,two exchanges and trader1 sends repeated request recall for RREJ
# Scenario: Recall of block trade is rejected.No cancel,recall right of one member
# Scenario: Trader repeats recall request for block trade in status RRQE
# Scenario: Recall request for block trade in Auction should not be possible
# Scenario: Admin sends reject cross-border block trade, Error response is received because of not requesting the recall by trader
# Scenario: Admin accept cross-border block trade recall request but is rejected NO_CAP",,ek176,lt112,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/19 11:39;tr866;capacity_overview_screenshot_03.09.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/73318/capacity_overview_screenshot_03.09.2019-001.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40867200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09j3r:6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 38,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Nov/19 14:04;lt112;h3. Suggested solution [~od044]

# Create ultimate user with correct rights for all inter-connectors, explicit allocations and stuff
# send {{AllocationDataReq}} for all inter-connectors to get information on existing allocations
# aggregate allocations in a map per inter-connector and find out what the resulting allocated quantity is and in which direction
# send explicit allocation in the opposite direction for all the inter-connectors with allocated quantity > 0",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Modify - automation - add new TCs for block orders modification,XP-2057,85840,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,02/Sep/19 13:48,04/Aug/20 19:36,22/Feb/21 13:26,05/Nov/19 09:41,,,Pre2020,,,,,,,TestAutomation,,,,"# Add new TCs for block order modification

h5. Verify that it is possible to modify block order and and Order ID is not changed (can be checked in Order Execution Report)
 - Verify that it is possible to modify a submitted block order. (179_FN_blockOrders_020)

h5. Verify that it is possible to modify block order and Order ID is increased (can be checked in Order Execution Report)
 - Verify it is possible to modify the price of a buy block order.(181_FP_blockOrders_022)
 - Verify it is possible to modify the price of a sell block order.(182_FP_blockOrders_023)
 - Verify it is possible to modify the quantity of a buy block order.((183_FP_blockOrders_024)
 - Verify it is possible to modify the quantity of a sell block order.(188_FP_blockOrders_029)

h5. Negative scenarios:
 - Verify that it is not possible to modify parameter - Exe Res (AON -> NON) (180_FN_blockOrders_021)
 - {color:#FF0000}Verify it is not possible to modify the time of the block order. (189_FN_blockOrders_030) - moved into XP-2157{color}

 
 * Use :

 ** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\Automation\Cucumber\RTM-03-05-10_Matcher_and_Order_Maintenance_0.31_automation.xlsx
 ** (copy of  S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
 RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx with notes about automation)
 ** Block Orders sheet",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,41040000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042019o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Sep/19 09:43;hj444;subtask of XP-2054 has to be done for possibility to work with ordrId","04/Nov/19 13:21;hj444;* moved into XP-2157 jira : Verify it is possible to modify the time of the block order. (189_FN_blockOrders_030)","04/Nov/19 13:40;hj444;pull req : https://github.deutsche-boerse.de/dev/xbid-test/pull/198","05/Nov/19 09:41;hj444;merge done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Modify  - automation - add new TCs for iceberg order modification,XP-2056,85835,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,02/Sep/19 12:51,04/Aug/20 19:36,22/Feb/21 13:26,11/Nov/19 09:53,,,Pre2020,,,,,,,TestAutomation,,,,"# create new fetaure file: icebergOrdersOrderModify.fetaure
# add new TC for order modification

h5. Verify that it is possible to modify order ICB and Order ID is unchanged  (can be checked in Order Execution Report)
- ICB peak size - decrease (134_FP_icbOrders_025)
- ICB order - Decrease TQty size (136_FP_icbOrders_027)
- ICB order - Decrease delta size (PPD) (138_FP_icbOrders_029)
-  ICB order - Increase Delta size (PPD) (139_FP_icbOrders_030)


h5. Verify that it is possible to modify order ICB and Order ID is increased  (can be checked in Order Execution Report)
- ICB peak size - increase (135_FP_icbOrders_026)
- Increase TQty size (137_FP_icbOrders_028)

{color:#DE350B}h5. Negative scenarios: moved XP-2326
- Verify that it is not possible to Modify ICB order - wrong delta sign. (140_FN_icbOrders_031)
- Verify that it is not possible to Modify ICB order: 
PPD > Max value  (141_FN_icbOrders_032)
- Verify that it is not possible to Modify ICB order: 
PPD < Min value) (142_FN_icbOrders_033)
- Verify that it is not possible to Modify ICB order: 
Peak quantity over total quantity (PQ < TQ ) (143_FN_icbOrders_034)
{color}

* Use :
** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\Automation\Cucumber\*RTM-03-05-10_Matcher_and_Order_Maintenance_0.31_automation.xlsx*
*** it is a copy of  S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
** Iceberg Orders sheet",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2327,XP-2326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,40521600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s0001042019i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 38 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Sep/19 09:42;hj444;subtask of XP-2054 has to be done for possibility to work with ordrId","11/Sep/19 08:50;hj444;{color:#00875A}*see also prepared unimplemented feature file*
_/xbid-test/test-models/unimplemented/sob/order-management/iceber-order/iceberg-order-status.feature_{color}
*and add to the modification TCs.*
_After adding to end to end test remove the feature fiel from unimplemented._

{color:#00875A}Added into modification feature file{color}","08/Nov/19 10:11;hj444;Negative scenarios moved :
https://jira.deutsche-boerse.com/browse/XP-2326","11/Nov/19 09:54;hj444;pull request created and merged :
https://github.deutsche-boerse.de/dev/xbid-test/pull/199
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Modify - automation - negative scenarios,XP-2055,85828,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,02/Sep/19 11:38,04/Aug/20 19:35,22/Feb/21 13:26,30/Sep/19 07:50,,,Pre2020,,,,,,,TestAutomation,,,,"h5. Add Modify order scenarios negative and verify received messages.
add tcs into : regularOrdersOrderModify.fetaure
 * negative scenarios 
-- Verify that it is not possible to modify Order - Invalid Qty - zero Qty. (056_FN_orderModify_007) {color:blue}automated{color}
-- Verify that it is not possible to modify Order - Invalid Qty - below min. (setup dependend) {color:blue}automated{color}
(056_FN_orderModify_008)
-- Verify that it is not possible to modify Order - Invalid Qty - above max.  (setup dependend) (056_FN_orderModify_009) {color:blue}automated{color}
-- Verify that it is not possible to modify Order - Invalid Price - below min. (setup dependend) (059_FN_orderModify_010) {color:blue}automated{color}
-- Verify that it is not possible to modify Order - Invalid Price - above max.  (setup dependend) (060_FN_orderModify_011) {color:blue}automated{color}
-- Verify that it is not possible to modify Order - GTD invalid date format. (061_FN_orderModify_012)
-- Verify that it is not possible to modify Order - GTD invalid date - in past. (061_FN_orderModify_013) {color:blue}automated{color}
-- Verify that it is not possible to modify Order - GTD invalid date - after trading end. (061_FN_orderModify_014) {color:blue}automated{color}
-- Verify that it is not possible to modify - Change Contract ID of the existing Order (061_FN_orderModify_015)
-- Verify that it is not possible to modify - Change Buy to Sell parameter of the existing order. (061_FN_orderModify_016)
-- Verify that it is not possible to modify - Exe Res (NON->AON)  {color:blue}automated{color}
in predefined market (= not block order). (061_FN_orderModify_017)


 

* Use :
** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
** _RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx_
** *Order-Modify sheet*",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44064000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09dbr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 35,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Sep/19 09:41;hj444;subtask of XP-2054 has to be done for possibility to work with ordrId","24/Sep/19 09:32;hj444;Negative scenarios added into orderModify.feature
* Verify that it is not possible to modify Order - Invalid Qty - zero Qty. (056_FN_orderModify_007)
* Verify that it is not possible to modify Order - Invalid Qty - below min. (setup dependend) 
(056_FN_orderModify_008)
* Verify that it is not possible to modify Order - Invalid Qty - above max.  (setup dependend) (056_FN_orderModify_009)
* Verify that it is not possible to modify Order - Invalid Price - below min. (setup dependend) (059_FN_orderModify_010)
* Verify that it is not possible to modify Order - Invalid Price - above max. (setup dependend) (060_FN_orderModify_011)
*  Verify that it is not possible to modify Order - GTD invalid date - in past. (061_FN_orderModify_013)
* Verify that it is not possible to modify Order - GTD invalid date - after trading end. (061_FN_orderModify_014)
* Verify that it is not possible to modify - Exe Res (NON->AON)




https://github.deutsche-boerse.de/dev/xbid-test/pull/192","30/Sep/19 07:50;hj444;pull request merged.
Done","01/Oct/19 10:44;hj444;TCs not automated in this Task - moved : https://jira.deutsche-boerse.com/browse/XP-2157",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Modify - automation - add new TCs for regular order modification with/without ordrId change,XP-2054,85824,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,02/Sep/19 11:28,04/Aug/20 19:35,22/Feb/21 13:26,17/Sep/19 09:19,,,Pre2020,,,,,,,TestAutomation,,,,"1. create new feature file orderModify.fetaure
2. add TCs for Order modification 
h5. Verify that it is possible to modify Order  and  Order ID is not changed (can be checked in Order Execution Report)
-- Quantity decrease. 
-- Val Res change (GFS-> GTD). 
-- Verify that it is possible to modify order in deactivated state. (055_FP_orderModify_006)

h5. Verify that it is possible to modify Order  and  Order ID is increased (can be checked in Order Execution Report)
-- Quantity increase. 
-- Price decrease. 
-- Price increase.


* Use :
** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
** _RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx_
** *Order-Modify sheet* ",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2055,XP-2056,XP-2057,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45273600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420196",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,develop,XP-3230,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Sep/19 11:59;hj444;created : https://github.deutsche-boerse.de/dev/xbid-test/pull/191","17/Sep/19 09:19;hj444;merged","17/Sep/19 09:21;hj444;Notes about changes in automation :
\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\Automation\Cucumber\
RTM-03-05-10_Matcher_and_Order_Maintenance_0.31_automation.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare step for adding more orders for one contract and verify receiving OrdrExeRprt+PblcOrdrBookDelta,XP-2048,85721,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,29/Aug/19 10:23,04/Aug/20 19:35,22/Feb/21 13:26,12/Sep/19 10:18,,,Pre2020,,,,,,,TestAutomation,,,,"* Actual behaviour :
TC for orderbook depth - I'm adding 50,100 the same orders.
Verification of received OrdrExeRprt+PblcOrdrBookDelta has to be done after each added order

* New step should be able to 
-- add more the same orders to one contract
-- verification OrdrExeRprt is received for added order
-- verification PblcOrdrBookDelta is received for added order

* Expected : After new step is prepared :
 actual TCs for OBK depth will be rewritten and input of 100/50 orders will be replaced by one new step.

",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45705600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099if:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,develop,XP-3230,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/Aug/19 13:00;hj444;feature file orderBookDepth.feature contains TCs for OBK verification.
Actually is not verified PblcOrdrBookDelta receiving after each order.
Actual methods allow only verification after each sent order one by one.
TCs with sending 100 orders and checking PblcOrdrBookDelta will have about +-700 lines.
100x
{Send 1 order
verify OrdrExeRprt
verify PblcOrdrBookDelta}

In TCs actual only verification done is to verify the Orderbook depth.","10/Sep/19 13:17;hj444;https://github.deutsche-boerse.de/dev/xbid-test/pull/189 created","12/Sep/19 10:18;hj444;merged",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update user's login that doesn't match 8 chars format in dataset rts3-sliceb-internal-data-fake,XP-2039,85694,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,od044,od044,28/Aug/19 14:02,06/Nov/20 11:14,22/Feb/21 13:26,28/Aug/19 15:19,,,Pre2020,,,,,,,,,,,"Some user's login doesn't match 8 chars format.

- Update user's login to match 8 chars format ",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46915200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09am0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 33 [S],,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"28/Aug/19 15:19;od044;PR [https://github.deutsche-boerse.de/dev/m7.m7-dataset/pull/111]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse potential impact of Hausen DC power maintenance 14/15.9 on PROD env.,XP-2037,85665,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ei349,rehapav,rehapav,27/Aug/19 16:24,06/Nov/20 10:14,22/Feb/21 13:26,19/Sep/19 10:46,,,Pre2020,,,,,,,,,,,"Idea: talk with techops (e.g. Roman Krewer) and check last year errors if the issue was resolved properly.

I got this info from slack from Tuan Nguyen 27/8:

on 14/15.9 we will have a Power Maintenance for Hausen, meaning all servers there will be turned off

 

as part of this ticket please perform impact analysis if such an DC power maintenance has any impact on XBID production

focus especially on
 * are all XBID servcies running in Equinox?
 * Last year for same DC maintenance we inform XBID customer that there will be no impact but after all we had problems with routing - is this still potential problem?
 * etc ..",,lt112,rehapav,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46569600,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099if:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Aug/19 16:46;rehapav;Pavel Rehak [16:46]
 gentlemen, I create XP ticket to analyse potential impact of Hausen DC maintenance 14/15.9 -> https://jira.deutsche-boerse.com/browse/XP-2037
please can you find as part of the analysis problems which we had with XBID during same winodw last year 1-2/9/2018 ?","28/Aug/19 10:42;zi174;TechOps cooperation necessary","28/Aug/19 10:44;lt112;# discuss definition of output
# contact TO:
** everything running on EQUI?
** analysis of previous issues from TO side
# find analysis of previous issues
# aggregate and create output
","02/Sep/19 09:46;zi174;Information from Pavel Rehak:

There is small impact:
let me inform you that we have identified as part of the technical preparation for Hausn DC maintenance event on *14-15/9 following XBID environemnts*
ctpbxbid
ctpaxbid
ctpexbid
ctpcxbid
where we will *require downtime* prior 10/9 in order to *switch DB from Hausen to EQNX*
I will request cca 1/2 day downtime for these environments. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Rename Sonar 2.0 to develop,XP-2031,85542,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,jj069,jj069,22/Aug/19 15:25,06/Nov/20 11:08,22/Feb/21 13:26,26/Aug/19 14:19,,,Pre2020,,,,,,,,,,,,,eg288,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,47174400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099vq:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 33 [S],,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/19 14:12;eg288;Done. The renamed project  can be found in sonar here :

https://sonar.energy.dev.dbgcloud.io/dashboard?id=com.deutscheboerse.energy.xbid%3Axbid%3Adevelop",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID licences check,XP-2019,85454,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,dm700,dm700,20/Aug/19 15:44,06/Nov/20 10:14,22/Feb/21 13:26,29/Aug/19 12:07,,,Pre2020,,,,,,,,,,,"*THE TASK*
 - run mvn licence plugin and gather the results (and attach as part of this task). 

*Context:*
DGAG has currently valid licencing policy - http://intranet.deutsche-boerse.de/INTRANET/ihp.nsf/embWebNewsDE/3D61F1CD4E336875C12580FE00295471?openDocument&language=de

this policy is telling that licences may be split between 4 types:
- Permissive
- Bounded Copyleft
- Unbounded Copyleft
- Prohibited

for the ciritical systems and separeted open source software, only firts 3 mentioned licence policies are allowed. 

As the last one is bringing this - _require the source-code to be made available to any
third party accessing the OSS_ 

IT would ""de jure"" mean that XBID source code using this licence should be available for all users of open source software.

*Next steps*
Next steps (task) will be to look into mentioned licences and check which of them belong to prohibited and evaluate which dependencies belong to this licence.  

*Additional info:*
DBAG plans to have Black Duck tool to do this licence scan automatically (eg. from Jenkins).  

*as XBID is according to GIS major criticality application permisive and bounded licences are allowed in embeded SW (in form of linked libraries)*

overview of assignement of licences to category 
http://intranet.deutsche-boerse.de/INTRANET/departments/ci_policies.nsf/0/837D569EB48F8F9EC1257E300034A116/$file/OSS%20licenses%20categorisation.pdf
",,dm700,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MGMT-259,,,,,,,"29/Aug/19 15:10;dm700;XBID licence.xlsx;https://jira.deutsche-boerse.com/secure/attachment/73179/XBID+licence.xlsx","29/Aug/19 11:35;ll664;licenses-comtrader.txt;https://jira.deutsche-boerse.com/secure/attachment/73170/licenses-comtrader.txt","29/Aug/19 12:04;ll664;licenses-pmi-archiving.txt;https://jira.deutsche-boerse.com/secure/attachment/73173/licenses-pmi-archiving.txt","29/Aug/19 11:55;ll664;licenses-pmi-logger.txt;https://jira.deutsche-boerse.com/secure/attachment/73172/licenses-pmi-logger.txt","29/Aug/19 11:44;ll664;licenses-report-tool.txt;https://jira.deutsche-boerse.com/secure/attachment/73171/licenses-report-tool.txt","29/Aug/19 11:26;ll664;licenses-reporting-engine.txt;https://jira.deutsche-boerse.com/secure/attachment/73169/licenses-reporting-engine.txt","29/Aug/19 11:22;ll664;licenses-shipping-module.txt;https://jira.deutsche-boerse.com/secure/attachment/73168/licenses-shipping-module.txt","29/Aug/19 11:17;ll664;licenses-xbid.txt;https://jira.deutsche-boerse.com/secure/attachment/73167/licenses-xbid.txt",,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46828800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099lr:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2019,XP-2546,XP-2546-added-latest,XP-69,XP-3345-version-bump,XP-2583,develop,XP-3345,XP-2554,master,master-comtrader-2.5.x,master-acceptance,comtrader-2.5.x,acceptance,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Aug/19 14:24;dm700;check the ""polishing configuration"" in https://jira.deutsche-boerse.com/browse/M7A-649","29/Aug/19 12:06;ll664;License merging conf adopted from linked jira. Listed licenses with:
{code:java}
mvn license:aggregate-add-third-party
{code}
 

All licenses for all XBID modules attached.

 ","29/Aug/19 15:11;dm700;aggregation made and attachment with marked problematic licences 

the solution of the dependency can be various:

- the licence from the dependency is not ""relevant"" because we dont distribute the libraries with the SW package
- moving to new version of library might lead to dependency on higher version of licence which could be ok
- check the code which depends on the library is still caled/relevant

As really ""last"" step is to cut out valid dependency",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automated performance testing on XBID,XP-2015,85438,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,20/Aug/19 12:56,06/Nov/20 12:18,22/Feb/21 13:26,09/Oct/19 09:38,,,Pre2020,,,,,,,,,,,"We should be able to run e2e performance tests in automated fashion.

That means:

* deploy of specific versions/custom build to perf env
* scenario generation based on input XLS
* test execution
* report generation

There's existing unmaintained pipeline that was intented to do most of above - https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-performance-test


",,ei349,jy268,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,43372800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4094,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104239",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 33 [S],Home Office Team Sprint 34,Home Office Team Sprint 35 [S],Home Office Team Sprint 36,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,XP-3777,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-4505_xbid_develop_hpfortify_upgrade,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,versions,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_reporting_tools_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Sep/19 11:12;jy268;What was done:
* sshagent added
* scripts are used from xbid-pipeline project
* energy-mkt-shared decommissioned (check commented out part of code)
* scp is used to copy scripts to testing node
* ssh sh is used to execute scripts on testing node

What has to be done:
* implement stage which will be killing running java perf test client on testing node (/)
* extract scripts which are currently on xbinterts only (follow scripts which are in xbid-pipeline and check what can be extracted) (/)
* get testing application (jar) from artifactory. Now it is deployed to xbinterts manually. (/)
* think about extracting scenario xmls to some repository (/)","12/Sep/19 10:59;qo794;Deployment is broken, see https://jira.deutsche-boerse.com/browse/TECHLOG-2754","04/Oct/19 12:11;jy268;Deployment works fine.","09/Oct/19 09:38;jy268;From now please use following jenkins build:
https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-performance-test/

where scenarios are stored in:
https://github.deutsche-boerse.de/dev/m7.test-client/tree/develop/test-scenario-creator/src/main/resources/pipeline-perf-scenarios",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove PREARRANGED order volume 2,XP-2009,85335,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,uv683,uv683,15/Aug/19 15:42,06/Nov/20 11:34,22/Feb/21 13:26,22/Aug/19 08:23,,,Pre2020,,,,,,,,,,,There are leftovers of this feature including PnC orders and OTC trades in Trading module.,,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Aug/19 15:49;uv683;removing-otc-trading-balancing-group.jpg;https://jira.deutsche-boerse.com/secure/attachment/72688/removing-otc-trading-balancing-group.jpg","15/Aug/19 15:42;uv683;removing-pnc-trades.jpg;https://jira.deutsche-boerse.com/secure/attachment/72687/removing-pnc-trades.jpg",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48038400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y098jw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 32 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1261-guava-28,selenide-poc,xbid-losses-poc,XP-PULL-TEST,XP-2694-xbid-3.0.x-latest-tag-fix,XP-3230,XP-3070,xbid-2.0.25.x,fixing-failover,master-xbid-losses-poc,XP-2635-redo-fix-3.0,plewmic-scripts,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,XP-2942-losses-perf,XP-456,XP-2979-postgresql,XP-3264,XP-2521-labeling-cmi-leftovers,develop,XP-2232,XP-2694,testing-new-stages-3.0,master,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,XP-139-xbid-3,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Aug/19 15:45;uv683;When user log into Trading module as System Operations User, he is able to see operations screen displayed below. This user is unknown to the customers and is only for DBAG. Market checkbox has been deleted. PnC orders are private and confidential orders which are not supported anyway.

!removing-pnc-trades.jpg!","15/Aug/19 15:51;uv683;In case that enableOTCOrders configuration key in cx_600_configuration table would be set to true, user would see ""OTC trading"" with checkbox as below and could set that some balancing group can be used for OTC trading. However mentioned configuration key is false on production, OTC orders are not supported and thus this element will not render. I have deleted it as well

!removing-otc-trading-balancing-group.jpg!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Contracts being generated for deactivated Product with status HIBE,XP-2006,85281,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,tr866,tr866,14/Aug/19 11:47,05/Nov/20 14:50,22/Feb/21 13:26,05/Nov/20 14:50,,,3.2.x,,,,,,,,,,,"h5. Description:
New contracts keep to get generated for a deactivated product contradictory to specs.

h5. Steps to reproduce:
# Login to WebGui as Refdata Admin
# Navigate to Reference Data Management>Product Setup>Product Management
# Pick a Product
# In DB in cx_210_contract table identify the last generated contract for the chosen Product
# In Reference Data Gui Deactivate the chosen Product and verify the Status changed to HIBE
# In DB in cx_210_contract table check if new contracts are appearing for product_long_name of the chosen Product

h5. Expected result:
According the specifications, DFS700 - Reference Data Module GUI v30.00; Chapter 4.1.3 De-activate Existing Product:
{quote}
Step 4: The User can select ‘Yes’ to confirm the action or ‘No’ to cancel it.
Once the user deactivates a product, all the existing active contracts will be deactivated. No new contracts would be generated. All the order book contracts will be deactivated. All orders will be removed (inactivated) from the order books of the affected contract. The trade book will be unaffected. Note: The traders can request recalls for the trades in the trade book.{quote}

h5. Current result:
Contracts for deactivated Products in Status HIBE keep to be generated.",,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/20 13:03;tr866;HIBE-Docker-Restart-cx_210_contract_XBID_Half_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89451/HIBE-Docker-Restart-cx_210_contract_XBID_Half_Hour_Power.csv","05/Nov/20 13:03;tr866;HIBE-Docker-Restart-cx_210_contract_XBID_Quarter_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89452/HIBE-Docker-Restart-cx_210_contract_XBID_Quarter_Hour_Power.csv","05/Nov/20 13:03;tr866;HIBE-cx_210_contract_XBID_Half_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89449/HIBE-cx_210_contract_XBID_Half_Hour_Power.csv","05/Nov/20 13:03;tr866;HIBE-cx_210_contract_XBID_Quarter_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89450/HIBE-cx_210_contract_XBID_Quarter_Hour_Power.csv","04/Nov/20 16:03;tr866;cx_210_contract_XBID_Half_.Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89425/cx_210_contract_XBID_Half_.Hour_Power.csv","04/Nov/20 16:03;tr866;cx_210_contract_XBID_Quarter_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89426/cx_210_contract_XBID_Quarter_Hour_Power.csv","04/Nov/20 16:03;tr866;cx_211_contract_history_XBID_Half_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89427/cx_211_contract_history_XBID_Half_Hour_Power.csv","04/Nov/20 16:03;tr866;cx_211_contract_history_XBID_Quarter_Hour_Power.csv;https://jira.deutsche-boerse.com/secure/attachment/89428/cx_211_contract_history_XBID_Quarter_Hour_Power.csv",,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,9331200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y0l:u",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 21 (S),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"04/Nov/20 16:09;tr866;Testing on Docker with version 3.2.0-SNAPSHOT-5d7a5891f4a93a108a81523de83bb1cdb685b25f
Deactivated product: XBID_Quarter_Hour_Power - Generated contracts on 1st day attached: [^cx_210_contract_XBID_Quarter_Hour_Power.csv] [^cx_211_contract_history_XBID_Quarter_Hour_Power.csv]
Deactivated and activated back Product: XBID_Half_Hour_Power - Generated contracts on 1st day attached: [^cx_211_contract_history_XBID_Half_Hour_Power.csv] [^cx_210_contract_XBID_Half_.Hour_Power.csv]","05/Nov/20 13:03;tr866;Successfully tested on docker with version 3.2.0-SNAPSHOT-5d7a5891f4a93a108a81523de83bb1cdb685b25f

As seen in the attached exported contracts from DB:
# XBID_Quarter_Hour_Power - Deactivated Product - After ""2020-11-04 14:40:10"" UTC when the Product was deactivated not a single contract got generated. Same after docker restart.
 [^HIBE-cx_210_contract_XBID_Quarter_Hour_Power.csv] , [^HIBE-Docker-Restart-cx_210_contract_XBID_Quarter_Hour_Power.csv] 
# XBID_Half_Hour_Power - Active Product - After 2020-11-04 14:40:10 UTC when the product was deactivated, but then activated back the contracts kept being generated and new ones got generated again after docker restart
 [^HIBE-cx_210_contract_XBID_Half_Hour_Power.csv] ,  [^HIBE-Docker-Restart-cx_210_contract_XBID_Half_Hour_Power.csv] ","05/Nov/20 14:50;tr866;After Product is Activated back, the contracts are getting generated again and orders can be entered for such contracts and get matched.(/)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Service boundaries - template modification,XP-2005,85218,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,zi174,zi174,13/Aug/19 10:07,06/Nov/20 09:41,22/Feb/21 13:26,02/Oct/19 10:41,,,Pre2020,,,,,,,,,,,"*Current situation*
* The template used for Service boundaries is developed with ""user-unfriendly"" prognosis sheet. In case of changing prognosis, it's necessary to change the formulas which may be connected with making some mistakes. 
* The template contains a wrong formatting of scenario - we highlight values for a wrong scenario

*Preferred solution*
* To sort out the template by modification of formulas. 
* Fix the formatting with a correct scenario

*Result*
* The new template will contain possibility to change prognosis just by changing the growth estimation number.
* only degraded scenario will be highlighted 

+Benefits+
* prognosis change will be done automatically
* change may be done by anyone
* correct formatting",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Oct/19 09:01;zi174;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/74816/sla-report.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,45360000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0980g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 32,Home Office Team 33 [S],Home Office Team Sprint 34,Home Office Team Sprint 35 [S],,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Sep/19 12:04;zi174;[~uv683] might you please check an attached template and use it for next report (September)? I have updated the prognosis and the formatting.

Thank you
Jakub",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"PROD Capacity Allocation requests & allocations - EP, NTC, AAC",XP-2002,85192,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,radeale,radeale,12/Aug/19 15:10,12/Aug/20 13:56,22/Feb/21 13:26,21/Aug/19 15:02,,,Pre2020,,Capacity,,,,,,,,,"For the purpose of the XBID Service Boundary Reporting we measure the following explicit allocations-related categories:
||Category||What DBAG includes in the #||Current daily limit||Source||
|Number of daily explicit capacity requests|EP, NTC, AAC|30000|Logs|
|Number of explicit capacity allocations|EP, AAC|25000|Database|

For the purpose of XP-106/XBID-3777 we need to get some PROD statistics how many there are on average in these categories:

Number of daily explicit capacity requests:
 1. Explicit participant allocation requests
 2. NTC-relates capacity requests
 3. AAC-related capacity requests

Number of explicit capacity allocations:
 1. Explicit participant capacity allocations
 2. AAC-related capacity allocations",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,47692800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y097uw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Aug/19 09:23;qo794;Statistics from period between 2019-07-02 00:00:00 UTC and 2019-08-02 00:00:00 UTC :
* Allocations (extracted from prod copy DB):
||Allocation type||Amount||Percentage||
|Implicit allocation and explicit via GUI|2530830|97.95|
|Publish|51742|2.00|
|Explicit allocation (API)|1336|0.05|
|On behalf allocation|0|0|
|SUM|2583908|100|

* Allocation requests (extracted from logs from ebsm server):
||Request type||Amount||Percentage||
|CapacityPublishRequest (NTC+AAC)|3156|55.4|
|AllocationRequest (GUI)|1932|34.0|
|AllocationReq (API)|605|10.6|
|OnbehalfAllocationRequest|0|0|
|SUM|5693|100|","20/Aug/19 10:09;radeale;Number of explicit capacity allocations:
 1. Explicit participant capacity allocations
 2. AAC-related capacity allocations
||EP Allocation type||Amount||Percentage||
|Publish (AAC)|51742|97,5|
|Explicit allocation|1336|2,5|
|On behalf allocation|0|0|
|Total|53078|100|",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AlarmTilt SMS statistics - 2019 till the 9th of August,XP-1999,85158,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,radeale,radeale,09/Aug/19 17:27,06/Nov/20 10:14,22/Feb/21 13:26,09/Aug/19 17:27,,,Pre2020,,AlarmTilt,,,,,,,,,"We got the AlarmTilt SMS statistics for the period of from the start of 2019 till the 9th of August.

So just to keep them somewhere, it may come handy.

Obtained from [customer_care@alarmtilt.com|mailto:customer_care@alarmtilt.com].",,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/19 17:27;radeale;Stats_SMS_XBID_2019-January-August.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72453/Stats_SMS_XBID_2019-January-August.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48211200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y097nc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Aug/19 10:33;radeale;SIMU - SMSs - August 1st - 14th = ~980.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Evaluate whether AlarmTilt can be replaced by OpsGenie - Application Level,XP-1996,85114,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,rg535,rg535,08/Aug/19 10:34,31/Aug/20 15:38,22/Feb/21 13:26,12/Jun/20 10:45,,,3.1.0,,AlarmTilt,,,,,,,,,"Dear [~ei349],

Please could you (scrum team) evaluate whether the functionality offered by AlarmTilt can be replaced by the Services / Functionality offered by OpsGenie.  If you have questions about OpsGenie and its features, please contact [~sw455]. He can provide guidance on the respective expert in the Business Operations team.

Kind regards,

Suzanna
",,ei349,gd553,lw641,qo794,radeale,rg535,sw455,tj898,ub113,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2760,SERVICE-3714,M7ACM-644,,,,,"23/Aug/19 10:32;rg535;MFG500 - Events and Notifications_V3.6.docx;https://jira.deutsche-boerse.com/secure/attachment/72982/MFG500+-+Events+and+Notifications_V3.6.docx","08/Aug/19 12:07;zi174;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/72413/screenshot-1.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,22032000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2649,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09q5g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 32,Home Office Team 33 [S],Home Office Team Sprint 34,Home Office Team Sprint 35 [S],Home Office Team Sprint 36,Home Office Team 37 [S],,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/19 11:14;radeale;By the XBID (DEV) needed functionality (not tested):

SMS alerts sending (/)
email alerts sending (/)
JIRA intergation (/)
internal alerts triggering (XBID integration) (?) 
- the product specs state ""API integration"", but it is unsure whether it can be really inetegrated
necessary levels of rights (?)
- the application offers ""owner"", ""admin"" and ""user"" roles

Bizops needed functionality (?)
- Bizops need to clarify, they surely need the JIRA inegration, call triggering...

Notes:
- Still need to find out, how exactly is the application heaving, so far the Alerts settings is somewhat strange, for example it is unclear how to edit the Alerts...
- I think it works like Events -> Alerts, but the demo version offers only Alerts?

I think it should be considered developing a custom tailored application for the XBID needs.","08/Aug/19 12:07;zi174;From my point of view  - the Internal alerts triggering - should work as well (based on the demo). For sure it needs testing. Based on a demo it seems that they support that functionality

 !screenshot-1.png! ","08/Aug/19 12:12;zi174;I don't know how the Alarmtilt works exactly, but OPSgenie offers integration to Jira, Grafana etc. So, from this point of view, it could be a good benefit. ","09/Aug/19 08:36;ub113;We use AlarmTilt to trigger ICC call when the critical issue has been raised. 

In practice, that means that we send out a lot of emails, sms and voice messages at the same time.

For this to work, Ops Genie shoud support quite large contacts list and the trigger that is coming from Jira, once the critical or major issue is raised.","09/Aug/19 10:12;radeale;Hi Ana,

thanks for the comment. As Serhii said, the idea of using OpsGenie comes from the bizops, therefore can we assume you already evaluated it as fulfilling your needs?

KR, Alexandr","09/Aug/19 10:13;tj898;Hi guys. My contribution:

[~ub113] - number of emails/sms/call to be generated is not a problem

[~zi174]/ [~radeale] - if you guys want to test our production instance we can create you a couple of accounts

all:

- the ICC call feature from Opsgenie is actually very nice. Graphical, with colors for different stakeholders connected (easy identification of everyone in the call, status section, voice/text recorded session, etc. Needs some attention while being setup, but it looks really cool.

- like Jakub mentioned, the list of possible integrations is huge. And the best part is that each one can be assigned to a different team, so per example techops/bizops won't be affected by alarms coming from DEV integrations (unless the use case requires differently). Very customizable, indeed.","23/Aug/19 10:32;rg535;[~radeale], does OpsGenie also fulfill the requirements of the attached document [^MFG500 - Events and Notifications_V3.6.docx] for the external XBIB customers?","23/Aug/19 11:43;radeale;Hello Suzanna,

we are unsure, we are waiting for Hugo to return from vacation, as he is told to be the most proficient with OpsGenie, he shall also provide us with more details and demo accounts.

The application offers API integration, but unless an actual test is performed, we can't be sure. For that it would be needed for our DEVs to try to trigger some events in the OpsGenie as I see it. Next week I'm on vacation, but Jakub Musil will take over and I hope the time permits to do a small test together with Hugo and probably Frantisek Odehnal (or other AT-proficient DEV).

Regards
Alexandr","19/Sep/19 08:47;rg535;[~radeale], when will this topic be addressed? Is Hugo back from vacation? Thanks, Suzanna","19/Sep/19 08:52;zi174;Hello Suzanna,
yes, Hugo is already back and we already spoke to him about that. We also used test users to check if OpsGenie is suitable for us or not. We consider it should be possible to replace the AlarmTilt by OpsGenie, however we need a confirmation from development point of view - Thus, we created a ticket XP-2108.

After our analysis it seems OpsGenie offers functionalities (sending sms to customer etc.) which we need and we could be able to used it instead of AlarmTilt, but we will be sure after performing some tests and discussion with dev. 

Jakub","31/Oct/19 13:40;rg535;Hello Jakub,

Thank you for your feedback. Let me know when you are finished with the tests and development work. Kind regards, Suzanna","04/Dec/19 14:40;gd553;[~zi174] - due to recent development on this topic, I would like to know what the status is? Can you please prioritize so we can get an answer as soon as possible? This is of course not as critical as the Losses PoC.","04/Dec/19 16:13;zi174;[~gd553] Currently, no update - basically we are waiting for prioritizing a task XP-2108 which should come more information. If the priority shall be increased please let me or [~ei349] know.

Jakub ","05/Dec/19 09:24;gd553;[~zi174]and [~ei349] as mentioned yesterday, I would like to prioritize this. Thanks.","30/Jan/20 15:44;radeale;A result of the Frantisek Odehnal's investigation and the question whether OpsGenie can replace the AlarmTilt currently used by the XBID project.

Short story:
{color:#00875A}It can.{color}

Long story:

The concept of OpsGenie differs from the in AlarmTilt. In AlarmTilt a superadmin user defines events (name, subject of the notification, the notification/email body etc.), assigns to them lists of users and on the XBID site a module (Core) calls AlarmTilt with only the basic information included - the name of the event (the only mandatory information to be provided by such trigger) and some additional optional info.

In OpsGenie there has to be create an integration for an app with a given API key which is then used in the application (XBID). There the configuration in OpsGenie ends, the rest is being taken care by the application and the users. In case a situation happens an application (the XBID Core) calls the OpsGenie and with all the information - the API key, the name of the event, its description, additional labels and can define recipients or a team (not sure) to receive the notification. Users can define (on the level of a profile or a team) under which circumstances should they receive which notifications.

Subjectively speaking OpsGenie seems like 1000 years ahead of AlarmTilt and really looks well.

Further analysis may be done is the test users are somehow separated from the bunch of currently used notifications (the test users are actually able to touch the currently used notifications and alarms.","31/Jan/20 13:56;rg535;I have read the comment from AR. Please could you provide and expand on the following info:

What would the effort be to change over to OpsGenie. 
*Effort required for Development, documentation changes, testing, changes to operational procedures, contractual changes, customer training and negotiation, and any other*

What is the  effort for switching to OG and what would it entail to switch to OG?
*Description required of what would need to be done from development, contractual and operational perspectives.*

What are the pros and cons of OG vs. AT. 
*According to BizOps, OG has better functionality for handling incidents and the overall incident process - see comment from 3-March.*

Description required of  customer impact? 
*Training on new features and usage, update of operational procedures and associated contract (see below), legal amendment, update to specs (define which ones)*

Would the process defined in the customer facing specs need to be changed?
*Results of initial contract evaluation: Exhibit 21 and Exhibit 5, Attachment 5D would need to be changed.*
","03/Mar/20 07:19;rg535;Extract from Serhii Botulinskyi EMAIL from  <serhii.botulinskyi@deutsche-boerse.com> on 28-Feb 2020.

Prepare ground for AlarmTilt decommission and switching over to OpsGenie over the course of 2020.
OpsGenie  has:
* better conferencing technologies and ICC handling, 
* features like incident timeline, escalations, live chat for ICC participants, normal post-mortem reporting and many other nice things.
* modern and very functional incident bridge with optional video-conferencing

Another thing is we could think of giving OPSCOM higher permissions in OpsGenie – so they add / remove / edit member’s users and contacts without asking us to maintain them – and we should always have up-to-date list during the outage.

As a “side-effect” of this transition, following changes to the contract are proposed:

1)	Page 4, 3.2.2 – The ICCC is initiated as follows:
a.	Introduce a “minimum qualified” ticket details for major / critical incidents. It should contain logs, userID, timestamp with timezone, clear statement of business impact etc.
Should help to avoid having tickets like attached.
b.	We (OpsGenie) send invitation to ICCC call. Can be either email, phone call invitation from a robot or text message (you can configure it via OpsGenie)

2)	Page 5, 3.2.3 – E-Mail communication channel
Replace email with IMT tool – we would like to have everything in the IMT.

3)	Page 6 – Diagram:
a.	Merge together major and critical ticket paths (same as minor/trivial) – there is no difference in their treatment
b.	Add DBG helpdesk as an alternative option (to call ONLY when IMT is not available).
Why? Because our alerting mechanism is the same when major/critical ticket is created in Jira and when a person calls hotline. We don’t need both of them at the same time.

4)	Page 7 – 3.3.1
1.	Add about minimum qualified ticket details
a.	If … identify an incident… inform DBG via IMT tool, public ticket (we stress they shouldn’t use private one). If IMT tool is not available – call to emergency hotline.
b.	- is not needed if a. is done.
","03/Mar/20 08:25;gd553;[~radeale] any progress on Suzanna's questions from 31/01?","03/Mar/20 10:12;radeale;Dear Suzanna,

from the functional side it is sure we would have to completely rewrite MFG500 and probably customers have to accept an application where they have not the same level of access (as implies František's response). I foresee no other HLS, DFS or MFG documents to be affected.

I cannot comment on the needed updates of the business/contractual documents, I think the input from people more familiar with them would be great (Malina, Jakub?).

As for to further elaborate on the needed steps to migrate from the AT to OpsGenie there need to be a clearly defined ticket to be put into the XP backlog requesting to migrate from AT to OpsGenie, discussed, refined and put into a sprint. I believe that as we are closely working with the BizOps there should be no obstacles to handle this in the regular way, please coordinate with Jirka about it.

As for the specific questions:

_What would the effort be to change over to OpsGenie._
 _Effort required for Development, documentation changes, testing, changes to operational procedures, contractual changes, customer training and negotiation, and any other_
 As the the dev-related changes a task needs to undergo the standard review/refinement process. Regarding documentation a new MFG500 has to be created and it is my believe that most of the functions which could be handled by the customers in the AT would have to be handled by the XBID (but it depends probably on the approach to the OpsGenie implementation for the AT purposes, so in general on the refinement).

_What is the effort for switching to OG and what would it entail to switch to OG?_
 _Description required of what would need to be done from development, contractual and operational perspectives._
 As for the development side in needs to follow the process described above. I cannot comment on the contractual and operational perspectives much.

_What are the pros and cons of OG vs. AT._
 _According to BizOps, OG has better functionality for handling incidents and the overall incident process - see comment from 3-March._
 Please see the František's comment above.

_Description required of customer impact?_
 _Training on new features and usage, update of operational procedures and associated contract (see below), legal amendment, update to specs (define which ones)_
 From the functional point of view MFG has to be remade.

_Would the process defined in the customer facing specs need to be changed?_
 _Results of initial contract evaluation: Exhibit 21 and Exhibit 5, Attachment 5D would need to be changed._
 I believe the ACM's input is needed here.

Best regards
 Alexandr","03/Mar/20 14:37;rg535;Dear Jiri, 
Please could you coordinate this item with Malina. See my comment from 31. January. We need to get the overall, rough estimates so we can run through the business case for this item. Thanks, Suzanna","12/Jun/20 10:44;ei349;Estimations provided in https://jira.deutsche-boerse.com/browse/XP-2760.",,,,,,,,,,,,,,,,,
Supress hibernate log warnings - CriteriaApi,XP-1994,85089,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ei349,ei349,07/Aug/19 16:12,06/Nov/20 11:34,22/Feb/21 13:26,09/Aug/19 13:56,,,Pre2020,,,,,,,configuration,,,,,,eg288,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48643200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010423c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 32,,,,,,,,,,,,,,,,,,,,,,,,0.356,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2942,traversal-XP-2485,tomcat-rollback,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Aug/19 13:25;eg288;Implemented with pull requests:
||Branch||Pull request||Status||
|xbid-dev-env|[https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/431]|Merged|
|master| [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/432]|Merged|

Pull request into master branch can be merged anytime. It affects all environments including production. But the change is compatible with all xbid versions including 1.5.x and 2.0.x",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update UAT II Performance scenarios,XP-1993,85075,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,radeale,radeale,07/Aug/19 14:08,11/Aug/20 16:36,22/Feb/21 13:26,22/Aug/19 10:31,,,Pre2020,,Capacity,Trading,,,,UAT2.0,,,,"h1. {color:#00875a}UAT II Performance Phase preparation{color}

Please update the current performance scenarios according to the discussion in XBID-4574 (XP-1828).",,od044,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Aug/19 10:30;od044;xbid-rts3b-2019-sc01-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72895/xbid-rts3b-2019-sc01-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc03-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72896/xbid-rts3b-2019-sc03-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc04-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72894/xbid-rts3b-2019-sc04-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc06-v01_wave3_final_O.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72890/xbid-rts3b-2019-sc06-v01_wave3_final_O.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc07-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72893/xbid-rts3b-2019-sc07-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc08-v01_wave3_final_O.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72889/xbid-rts3b-2019-sc08-v01_wave3_final_O.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc09-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72897/xbid-rts3b-2019-sc09-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc10-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72892/xbid-rts3b-2019-sc10-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc11-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72898/xbid-rts3b-2019-sc11-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc12-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72891/xbid-rts3b-2019-sc12-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc13-v01_wave3_final_O.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72888/xbid-rts3b-2019-sc13-v01_wave3_final_O.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc14-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72899/xbid-rts3b-2019-sc14-v01_wave3_final.xlsx","22/Aug/19 10:30;od044;xbid-rts3b-2019-sc15-v01_wave3_final.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72900/xbid-rts3b-2019-sc15-v01_wave3_final.xlsx",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,47520000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010423b",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 32,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Aug/19 10:30;od044;Scenarios have been updated

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance testing of integrated XBID and new routing library ,XP-1988,85065,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,07/Aug/19 10:49,06/Nov/20 12:19,22/Feb/21 13:26,04/Sep/19 16:00,,,Pre2020,,,,,,,Losses,,,,"* OBK depth performance impact? try with lower OBK depths and check the difference. 
 * Compare results of current losses solution with xbid 2.0 performance. Are we passing SLAs? old vs new with losses and without losses
 ** remove blocks and explicit allocations from the RTS3Sb
 ** light integration might be needed
 ** Measure with the higher expected load after the 2nd wave go live
 * nice graphs like with Stefan? - consult and prepare new task if needed",,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2076,,,,,,,"04/Sep/19 12:58;jy268;xbid_2_0_25_default_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73379/xbid_2_0_25_default_rts_wave3.xls","04/Sep/19 12:58;jy268;xbid_2_0_25_orderbook_30_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73380/xbid_2_0_25_orderbook_30_rts_wave3.xls","04/Sep/19 12:58;jy268;xbid_losses_default_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73381/xbid_losses_default_rts_wave3.xls","04/Sep/19 12:58;jy268;xbid_losses_orderbook_30_rts_wave3.xls;https://jira.deutsche-boerse.com/secure/attachment/73382/xbid_losses_orderbook_30_rts_wave3.xls",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,46396800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4094,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010423e",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 32,Home Office Team 33 [S],,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/19 13:00;jy268;[^xbid_2_0_25_default_rts_wave3.xls] - xbid 2.0.25 with default orderbook depth
[^xbid_2_0_25_orderbook_30_rts_wave3.xls] - xbid 2.0.25 with orderbook depth 30
[^xbid_losses_default_rts_wave3.xls] - xbid XP-1917 branch with default orderbook depth
[^xbid_losses_orderbook_30_rts_wave3.xls] - xbid XP-1917 with orderbook depth 30","04/Sep/19 13:50;jy268;Short summary for default orderbook depth:

percentile 99.50 for order execution time:
xbid 2: *2284ms*
losses: *5863ms*

percentile 99.50 for orderbook computation time:
xbid 2: *469ms*
losses: *2926ms*

","04/Sep/19 13:53;jy268;Short summary for orderbook with depth 30:

percentile 99.50 for order execution time:
xbid 2: *2159ms*
losses: *5038ms*

percentile 99.50 for orderbook computation time:
xbid 2: *397ms*
losses: *2424ms*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM UI errors in log,XP-1986,85052,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,qo794,qo794,07/Aug/19 09:14,06/Nov/20 11:14,22/Feb/21 13:26,07/Aug/19 10:59,,,Pre2020,,Capacity,,,,,,,,,"The following errors are present in CMM log:
{code:java}
o.a.m.t.l.LayoutTokens: Unknown layout token '160'! Using 'auto' instead.
o.a.m.t.i.c.RenderersConfigImpl: Calling isMarkupSupported('tabGroup', 'twoLines'), but no configuration found.
{code}",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48816000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0973s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 31 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove PREARRANGED order and all the related features - VOLUME 1,XP-1963,84956,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,05/Aug/19 10:11,06/Nov/20 11:34,22/Feb/21 13:26,08/Aug/19 10:45,,,Pre2020,,,,,,,,,,,Just make sure that requests that are being removed are indeed blocked by XbidRequestValidator already.,,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3060,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48988800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pr:zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2635-redo-fix-3.0,XP-2102-xbid-3,XP-2521-cmm-cmi-labeling,XP-PULL-TEST,xbid-losses-poc,XP-2942-losses-perf,XP-2521-labeling-cmi-leftovers,develop,XP-2694-xbid-3.0.x-latest-tag-fix,testing-new-stages-3.0,master,master-xbid-losses-poc,XP-139-xbid-3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM - Synchronization events still remain in SYNCHRONIZED state,XP-1954,84779,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,29/Jul/19 15:57,06/Nov/20 12:40,22/Feb/21 13:26,30/Jul/19 13:43,,,Pre2020,,,,,,,,,,,"Synchronization events still remain in SYNCHRONIZED state.

 [^select_from_event_log_201907291555.csv] 

Step to reproduce 
1. Start XBID and SPM application 
2. Check that SM files are generated 
3. Check the state of events in even_log table in DB 

Impact: SLA report doesn't generate a SM Files Generation Time report properly due to missing a timestamp of persisted and received time. 
",,jy268,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/19 15:59;od044;select_from_event_log_201907291555.csv;https://jira.deutsche-boerse.com/secure/attachment/72090/select_from_event_log_201907291555.csv",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,49507200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3109,,,,,,,,,,,,,,29/Jul/19 15:57,,,,,,,,,,,,,,,,,,,,,,,"1|y095kg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/19 17:33;jy268;Event log was moved to DONE after generation of all files was completed. Not a bug.","30/Jul/19 13:43;od044;Invalid bug - close",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sonar analysis for Kotlin code,XP-1953,84743,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,ll664,ll664,29/Jul/19 11:10,06/Nov/20 11:10,22/Feb/21 13:26,27/Aug/19 07:57,,,Pre2020,,,,,,,,,,,Check/configure Sonar so it's able to analyze Kotlin code.,,eh941,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/19 11:58;eh941;github-sonar-kotlin.png;https://jira.deutsche-boerse.com/secure/attachment/72228/github-sonar-kotlin.png","05/Aug/19 15:32;eh941;product-covered.png;https://jira.deutsche-boerse.com/secure/attachment/72342/product-covered.png","05/Aug/19 15:32;eh941;product-not-covered.png;https://jira.deutsche-boerse.com/secure/attachment/72341/product-not-covered.png","05/Aug/19 09:22;eh941;xbid-sonar-analysis-xbid-core.png;https://jira.deutsche-boerse.com/secure/attachment/72310/xbid-sonar-analysis-xbid-core.png",,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48902400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y097fj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/19 11:58;eh941;It actually does work for report tool:

 !github-sonar-kotlin.png! ","01/Aug/19 12:00;eh941;I deleted obsolete project in sonar called m7-xbid-report-tool and added explicit name for report-tool-parent with the same value as the old one","05/Aug/19 09:22;eh941;I removed {{<sonar.language>java</sonar.language>}} from the xbid's project parent pom.  By this some new findings appeared - XML files like {{web.xml}} are now validated as well. I fixed them all.

The analysis is now performed also on kotlin source codes.

 !xbid-sonar-analysis-xbid-core.png! ","05/Aug/19 15:32;eh941;Added test {{ProductTest.kt}} which tests uncovered code:

 !product-not-covered.png! 

after the analysis with the new Test class is done:

 !product-covered.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kotlin tests - verify they're run and counted into code coverage,XP-1952,84742,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,ll664,ll664,29/Jul/19 11:09,04/Aug/20 19:36,22/Feb/21 13:26,23/Aug/19 13:21,,,Pre2020,,,,,,,,,,,"Are we sure the kotlin tests are run during the maven build (this wasn't always the case)?

Check the code coverage as well.

This should be done for all of the projects.",,eh941,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/19 11:37;eh941;failed-ctx-and-unit-test.png;https://jira.deutsche-boerse.com/secure/attachment/72321/failed-ctx-and-unit-test.png","05/Aug/19 11:37;eh941;failed-integration-test.png;https://jira.deutsche-boerse.com/secure/attachment/72322/failed-integration-test.png","05/Aug/19 13:23;eh941;product-not-covered.png;https://jira.deutsche-boerse.com/secure/attachment/72329/product-not-covered.png",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48988800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y097fi:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Aug/19 11:37;eh941;Kotlin unit and integration tests are now explicitly covered by surefire and failsafe. It worked before but the {{*.kt}} files weer always executed by surefire.

I created a special MR with failing:

# Unit test
# CTX test
# Integration test

Unit tests are executed together with CTX tests as {{Unit Tests}} test suite in github

Integration tests are executed separately as {{Integration Tests}}  test suite in github

Now it looks fine:
 !failed-ctx-and-unit-test.png! 
 !failed-integration-test.png! ","05/Aug/19 13:23;eh941;Added a kotlin test to cover Product.java code: 
!product-not-covered.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare SLA reports for July 2019,XP-1943,84566,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ei349,ei349,25/Jul/19 10:20,06/Nov/20 09:42,22/Feb/21 13:26,08/Aug/19 13:37,,,Pre2020,,,,,,,,,,,,,ei349,uv683,,,,,,,,,,,,,,,,,,,,,,XP-1834,,,,,,,,,,,,,,,,,,,"05/Aug/19 09:07;uv683;XBID Performance and SM SLA Reporting July 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72306/XBID+Performance+and+SM+SLA+Reporting+July+2019.xlsx","05/Aug/19 09:07;uv683;XBID Service Boundary Reporting July 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72307/XBID+Service+Boundary+Reporting+July+2019.xlsx","05/Aug/19 09:07;uv683;XBID_Credit_points_report_July_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72305/XBID_Credit_points_report_July_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48988800,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:2uw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/19 09:12;uv683;Hi [~gd553], [~qm925],

 

please do a sanity check on July reports and feel free to distribute them to the customers. They are uploaded in sharepoint as well.

J.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
NEMOs request - alarmtilt ,XP-1931,84531,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,zi174,zi174,24/Jul/19 14:50,06/Nov/20 09:43,22/Feb/21 13:26,24/Sep/19 10:15,,,Pre2020,,,,,,,,,,,"Dear DBAG,

Let me start my question by pasting a text from MFG500 AlarmTilt user manual:
h2. 8.5  Production Configuration

The assignment of TRM Codes for the Member ID variable:

 
|*Values*|*PXs*|
|TRM01| OMIE|
|TRM02| NP|
|TRM03|EPEX|
|TRM04|GME|

 
We need to add 2^nd^ wave NEMOs to this table in order to allow AlarmTilt send these NEMOs the individual alerts (FR_IE_1, 2, 4, 5, 6).

The code “TRMXX” resembles the code “Member ID” from SOB Member Configuration so I assume there’s a link. We plan to configure members with the following codes:

 
|*Values*|*PXs*|
|TRM06|HUPX|
|TRM04|OTE|
|TRM07|CROPEX|
|TRM05|OPCOM|
|TRM08|BSP|
|TRM09|IBEX|
|TRM10|TGE|

 

*Can you please confirm you can update the “internal” configuration of AlarmTilt with these codes?* We can discuss the specifics (when to do it, if down time is needed, etc.) later, perhaps in next RCB call.

We will update the underlying AT procedures and AT directory ourselves.",,qm925,radeale,zi174,,,,,,,,";01/Aug/19 13:57;radeale;28800",,,0,28800,,,0,28800,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/19 09:08;qm925;NEMOs1.png;https://jira.deutsche-boerse.com/secure/attachment/72308/NEMOs1.png","05/Aug/19 09:08;qm925;NEMOs2.png;https://jira.deutsche-boerse.com/secure/attachment/72309/NEMOs2.png","01/Aug/19 10:52;radeale;Screenshot from 2019-08-01 10-53-29.png;https://jira.deutsche-boerse.com/secure/attachment/72212/Screenshot+from+2019-08-01+10-53-29.png","01/Aug/19 10:53;radeale;Screenshot from 2019-08-01 10-54-40.png;https://jira.deutsche-boerse.com/secure/attachment/72213/Screenshot+from+2019-08-01+10-54-40.png","01/Aug/19 10:54;radeale;Screenshot from 2019-08-01 10-55-41.png;https://jira.deutsche-boerse.com/secure/attachment/72214/Screenshot+from+2019-08-01+10-55-41.png","01/Aug/19 10:56;radeale;Screenshot from 2019-08-01 10-57-21.png;https://jira.deutsche-boerse.com/secure/attachment/72215/Screenshot+from+2019-08-01+10-57-21.png","01/Aug/19 10:56;radeale;Screenshot from 2019-08-01 10-57-48.png;https://jira.deutsche-boerse.com/secure/attachment/72216/Screenshot+from+2019-08-01+10-57-48.png","01/Aug/19 10:58;radeale;Screenshot from 2019-08-01 10-59-21.png;https://jira.deutsche-boerse.com/secure/attachment/72217/Screenshot+from+2019-08-01+10-59-21.png","01/Aug/19 10:59;radeale;Screenshot from 2019-08-01 11-00-06.png;https://jira.deutsche-boerse.com/secure/attachment/72218/Screenshot+from+2019-08-01+11-00-06.png","01/Aug/19 10:59;radeale;Screenshot from 2019-08-01 11-00-53.png;https://jira.deutsche-boerse.com/secure/attachment/72219/Screenshot+from+2019-08-01+11-00-53.png","01/Aug/19 11:03;radeale;Screenshot from 2019-08-01 11-04-59.png;https://jira.deutsche-boerse.com/secure/attachment/72220/Screenshot+from+2019-08-01+11-04-59.png","01/Aug/19 11:06;radeale;Screenshot from 2019-08-01 11-07-22.png;https://jira.deutsche-boerse.com/secure/attachment/72221/Screenshot+from+2019-08-01+11-07-22.png","01/Aug/19 11:07;radeale;Screenshot from 2019-08-01 11-08-15.png;https://jira.deutsche-boerse.com/secure/attachment/72223/Screenshot+from+2019-08-01+11-08-15.png","01/Aug/19 11:08;radeale;Screenshot from 2019-08-01 11-09-06.png;https://jira.deutsche-boerse.com/secure/attachment/72224/Screenshot+from+2019-08-01+11-09-06.png","01/Aug/19 11:13;radeale;Screenshot from 2019-08-01 11-14-58.png;https://jira.deutsche-boerse.com/secure/attachment/72225/Screenshot+from+2019-08-01+11-14-58.png","01/Aug/19 11:14;radeale;Screenshot from 2019-08-01 11-15-38.png;https://jira.deutsche-boerse.com/secure/attachment/72226/Screenshot+from+2019-08-01+11-15-38.png","01/Aug/19 11:15;radeale;Screenshot from 2019-08-01 11-16-22.png;https://jira.deutsche-boerse.com/secure/attachment/72227/Screenshot+from+2019-08-01+11-16-22.png",,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,44668800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094k0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,Home Office Team Sprint 31 [S],Home Office Team Sprint 32,Home Office Team 33 [S],Home Office Team Sprint 34,Home Office Team Sprint 35 [S],,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jul/19 08:53;zi174;We're waiting for clarification from RCB side.","01/Aug/19 11:16;radeale;All the steps should be configured by the customers. The only step for the XBID is to update the _MFG500_, chapter _8.5 Production Configuration_.

Steps to configure (screenshots from the XBID test env):

1. Configure the members in the SOB Trading WebGUI reference data:

 !Screenshot from 2019-08-01 10-53-29.png! 

2. In the AlarmTilt login with an _Administrator_ or _Directory Manager_ user role select _Directory_ and Add group(s) for the new members the same way the groups are configured for the current members (EPEX, GME, NP, OMIE...)

 !Screenshot from 2019-08-01 11-04-59.png! 

3. In the AlarmTilt login with a _Procedure Manager_ user role, click on Procedures:

 !Screenshot from 2019-08-01 10-54-40.png! 

4. Choose the procedure to edit (for example _XBID detected LTS connection-loss to RabbitMQ_)

 !Screenshot from 2019-08-01 10-55-41.png! 

5. Select _Workflow_ and click _Launching from_:

 !Screenshot from 2019-08-01 10-57-21.png! 

6. Click on the edit button next to the PX member field:

 !Screenshot from 2019-08-01 10-57-48.png! 

7. Add the new TRM0X codes to the _Values_ list, click on _Save & Continue_:

 !Screenshot from 2019-08-01 10-59-21.png! 

8. Click on the Step in the Workflow (_S001..._ in this case):

 !Screenshot from 2019-08-01 11-00-06.png! 

9. Click on the _Message_ name:

 !Screenshot from 2019-08-01 11-00-53.png! 

10. On the Destinations tab check _Advanced Options_  and the last option - _Add a selection of destinations_:

 !Screenshot from 2019-08-01 11-07-22.png! 

11. There add a newly added member to the list (IBEX in this example), confirm by pressing the _Validate_ button:

 !Screenshot from 2019-08-01 11-08-15.png! 

12. Click on the _Add conditions_ next to the new Destination:

 !Screenshot from 2019-08-01 11-09-06.png! 

13. Configure the Conditions as shown on the screen (the condition check has to adhere to the configuration in the SOB Trading WebGUI reference data, save with the _Validate_ button:

 !Screenshot from 2019-08-01 11-14-58.png! 

14. Save the message editions with the _Validate_ button:

 !Screenshot from 2019-08-01 11-15-38.png! 

15. Save all the changes with the _Save & Close_ (or _Save & Continue_) button:

 !Screenshot from 2019-08-01 11-16-22.png! ","01/Aug/19 13:47;zi174;Seems it should be understandable for the customer. Thanks Alex
","05/Aug/19 09:09;qm925;Feedback from XBID PMO:

Dear Simona,

Before going into JIRA, let my try to clarify it further in e-mail. Please forward it to your AT experts.

We are aware how to configure “NEMO related / individual” AT alarms. We are aware of the following AT screens and logic behind it:

!NEMOs1.png!

!NEMOs2.png!

From your hint that we could do the configuration ourselves I deduct the following:

- DBAG has the underlying link between AT and XBID in place in generic way so adding new TRM codes in the XBID_SOB_Member reference data settings makes the codes also usable in AT.

- we can add new TRM codes we added to XBID_SOB_Member reference data also to settings of each NEMO-specific alarm in AT ourselves

- we can update the forwarding logic / conditions of NEMO-specific alarm in AT ourselves

 

If you can confirm my assumptions I think no support request would be needed.","05/Aug/19 13:13;radeale;- DBAG has the underlying link between AT and XBID in place in generic way so adding new TRM codes in the XBID_SOB_Member reference data settings makes the codes also usable in AT.
{color:#00875a}YES{color}

 - we can add new TRM codes we added to XBID_SOB_Member reference data also to settings of each NEMO-specific alarm in AT ourselves
{color:#00875a}YES{color}

 - we can update the forwarding logic / conditions of NEMO-specific alarm in AT ourselves
{color:#00875a}YES{color}

{color:#172b4d}No support ticket, no support, no guarantees :){color}","24/Sep/19 08:54;qm925;Ticket can be closed. Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update the grid screen of the Shipping Module to Wave 2,XP-1913,84479,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,tr866,radeale,radeale,23/Jul/19 16:05,06/Nov/20 11:34,22/Feb/21 13:26,05/Aug/19 11:41,XB-1.6.0.13,,Pre2020,,Shipping,,,,,,,,,"The background picture of the Shipping Module needs to be update to reflect the Wave 2 countries added:
 * Poland
 * Czechia
 * Hungary
 * Slovenia
 * Croatia
 * Bulgaria?
 * Romania?

These countries have to be removed:
 * Morocco

  !SM-Background.PNG!",,ll664,radeale,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/19 16:05;radeale;SM-Background.PNG;https://jira.deutsche-boerse.com/secure/attachment/71924/SM-Background.PNG","05/Aug/19 11:36;tr866;screenshot-localhost-24086-2019.08.05-11-31-39.png;https://jira.deutsche-boerse.com/secure/attachment/72320/screenshot-localhost-24086-2019.08.05-11-31-39.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48988800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pr:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Aug/19 14:52;ll664;Implemented. [~tr866] pls test, available as {{latest}} version in Docker.","05/Aug/19 11:39;radeale;Very nice! :)

!screenshot-localhost-24086-2019.08.05-11-31-39.png!","05/Aug/19 11:40;tr866;Successfully tested in environment Docker with version Shipping Module 2.0.10-SNAPSHOT
All the countries on list were added and Morocco removed.
Tried to login with couple of users from different User Groups and with different Roles like:
- SUPER ADMIN
- CENTRAL ADMIN
- CCP ADMIN READ ONLY
- CCP ADMIN, CCP OPERATINS
- SA ADMIN
- SA OPERATIONS
- TSO ADMIN
- TSO OPERATIONS
- WS API, TSO OPERATIONS
- WS API
screenshot attached:
[!screenshot-localhost-24086-2019.08.05-11-31-39.png|width=400!|^screenshot-localhost-24086-2019.08.05-11-31-39.png]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add  Iceberg Orders basic validations - automation end to end tests,XP-1910,84425,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,22/Jul/19 14:29,04/Aug/20 19:35,22/Feb/21 13:26,25/Jul/19 08:46,,,Pre2020,,,,,,,,,,,"*Update addOrder.feature file and* 
Add TCs for validation of *ICEBERG (ICB)* orders Order Entry.
* Iceberg orders - type = I
*BUY ICB orders*
** DFS510 document about ICB order and displayQty: Used to define display quantity of an Iceberg Order. This field is required only in the case of type='I'.
* TC :  ICB order BUY-without peakQty(displayQty)
* TC: ICB order BUY-not valid buy order-display qty is not in allowed interval,error message is received
 ** DFS510 document about BUY ppd: The ppd of buy orders must be smaller or equal than zero.
* TC : ICB order BUY-not valid buy order-display qty>qty
* TC : ICB order BUY-not valid buy order-ppd>0 in buy order
* TC:  Verify qty in Order Entry: Contains the total quantity of the order. In case of an Iceberg order this field corresponds to the hidden quantity + display quantity
* TC : ICB order BUY-OK buy order-ppd==0 in buy order
* TC : ICB order-valid buy order,ppd smaller than 0 in buy order,the ppd of buy orders must be smaller or equal than zero.
 ** DFS510 document about ppd: ""If it is omitted the system will assume a value of ""0,00"".""
*  TC:  ICB order BUY-OK valid buy order, with not sent ppd,optional attribute, in Order Entry.
*SELL ICB orders*
** DFS510 document about SELL ppd: The ppd of sell orders must be greater or equal than zero.
* TC: ICB order SELL-not valid sell order ppd<0
* TC: ICB order SELL-OK buy order ppd==0
* TC: ICB order-valid SELL order,ppd greater than 0 in sell order
** DFS510 document about ppd: ""If it is omitted the system will assume a value of ""0,00"".""
* TC:  ICB order SELL-OK valid sell order, with not sent ppd,optional attribute,in Order Entry.
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,49939200,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y093xs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 30 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jul/19 13:54;hj444;TCs added into addOrder.feature
pull request created : https://github.deutsche-boerse.de/dev/xbid-test/pull/178","25/Jul/19 08:46;hj444;Pull request - merged.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Order Matching - Regular orders matching - FOK, IOC restriction",XP-1892,84196,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,hj444,hj444,16/Jul/19 12:23,04/Aug/20 19:35,22/Feb/21 13:26,07/Aug/19 17:25,,,Pre2020,,,,,,,,,,,"# Add new TC into end-to-end-tests regularOrdersMatching.feature for restriction FOK, IOC :
    ( Order-Matching sheet)
* To test to create a trade using 1 partial order against  FOK order.
(094_FN_orderMatching_015)
* To test to create a trade from NON and IOC orders. (095_FP_orderMatching_016)
* To test to create a partial trade from NON and IOC orders.(096_FP_orderMatching_017)
* Verify that Order is deleted if no matching order in Order book.(086_FP_orderMatching_007)


Use :
        S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
        RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
        Order-Matching sheet",,hj444,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48816000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pr:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Aug/19 11:33;tr866;In the existing regularOrdersMatching.feature added the following scenarios:
# {color:#00875A}*094_FN_orderMatching_015*{color} - Verify FOK order can't be matched partially
# {color:#00875A}*095_FP_orderMatching_016*{color} - Verify NON and IOC orders can get matched for trade execution
# {color:#00875A}*096_FP_orderMatching_017*{color} - Verify IOC order can get matched partially against NON order
# {color:#00875A}*Scenario: Verify IOC order can get matched against 2 NON orders and the residue doesn't get matched with order entered later*{color}
# {color:#00875A}*086_FP_orderMatching_007*{color} - Verify that FOK Order is deleted if no matching order in Order book
# {color:#00875A}*Scenario: Verify that IOC Order is deleted if no matching order in Order book*{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for multiple line format in Report Tool,XP-1878,84045,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eh941,eh941,10/Jul/19 10:56,06/Nov/20 11:34,22/Feb/21 13:26,07/Aug/19 09:37,,,Pre2020,,,,,,,,,,,"Line parsing is causing problems because each xbid version has it's own unique {{perf-raw-*}}  format.

Add support for multiple formats which would be easy to add.",,eh941,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,49334400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420101c01",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 29,Alpha Team Sprint 30 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/Jul/19 14:56;ei349;Can you please do the review? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM -AMQP Allocations - not valid allocations requests,XP-1875,84015,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,hj444,hj444,09/Jul/19 14:12,04/Aug/20 19:36,22/Feb/21 13:26,17/Sep/19 16:28,,,Pre2020,,,,,,,,,,,"Use: Use : RTM-11_AMQP Allocation broadcast tool_v1.1.xlsx
S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression

  #  endtoendtest/capacity/explicitAllocation.feature - add new TCs for allocation request validation of requested quantity
** Verify passing decimal number(not valid number) to request (026_FN_AMQP_CMM)
** Verify passing letters to request (027_FN_AMQP_CMM)
** Verify error message when you are sending allocation to wrong contract (063_FN_AMQP_CMM)
** Send allocation request without mandatory fields (062_FN_AMQP_CMM)
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51321600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099if:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,develop,XP-3230,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM -AMQP Allocations - ACE allocations,XP-1874,84013,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,hj444,hj444,09/Jul/19 13:50,04/Aug/20 19:36,22/Feb/21 13:26,04/Sep/19 10:46,,,Pre2020,,,,,,,,,,,"Use: Use : RTM-11_AMQP Allocation broadcast tool_v1.1.xlsx
 S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression

 # endtoendtest/capacity/*explicitAllocation.feature* - add new TCs for ACE allocation
** Verify ACE allocation by trader. More ATC than available on few contract at once (017_FP_AMQP_CMM)
** Try to allocate capacity for  3 contracts in one transaction ACE when ATC one of them is 0 (018_FP_AMQP_CMM)",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51321600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099lr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM -AMQP Allocations - AON allocations ,XP-1873,84012,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,hj444,hj444,09/Jul/19 13:44,04/Aug/20 19:35,22/Feb/21 13:26,04/Sep/19 10:46,,,Pre2020,,,,,,,,,,,"Use: Use : RTM-11_AMQP Allocation broadcast tool_v1.1.xlsx
S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression

# endtoendtest/capacity/explicitAllocation.fetaure - add new TC for AON allocation
** Allocate less than ATC in one direction, one contract, restriction AON (011_FP_AMQP_CMM)
** Allocate Quantity  = ATC using AON restriction (012_FP_AMQP_CMM)
** Try to allocate 1 MW for all 3 contracts in one transaction  restriction AON(014_FN_AMQP_CMM)
** Try to allocate 99 MW for all 3 contracts in one transaction  restriction AON (016_FN_AMQP_CMM)
*** there is ATC 
*** ATC contract1 = 100  MW
*** ATC contract2 = 99 MW
*** ATC contract3 = 100MW


note : TC : Allocate more than ATC using AON restriction (013_FN_AMQP_CMM+015_FN_AMQP_CMM) is already covered in explicitAllocation.fetaure
_Scenario: Send AON AllocationReq and verify that if there is not enough capacity at least for one of the allocations then none should be allocated_",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51321600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099lr:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Update KPI,SLA reports to highlight breaches",XP-1869,83967,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,08/Jul/19 13:02,06/Nov/20 10:25,22/Feb/21 13:26,10/Jul/19 14:52,,,Pre2020,,SLA Report Tool,,,,,,,,,"There is already a highlighting of boundary breaches so that the cell background is yellow and value is bold. However this only works on some columns. Review and add it to all of them in credit point, boundary and performance reports.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51408000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08zvg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 29,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM -AMQP Allocations - ATC updates messages,XP-1868,83965,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,hj444,hj444,08/Jul/19 12:46,04/Aug/20 19:35,22/Feb/21 13:26,13/Dec/19 15:31,,,Pre2020,,,,,,,,,,,"# Create new feature file for cmm - atc updates TCs

 Use : RTM-11_AMQP Allocation broadcast tool_v1.1.xlsx
S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
# Add scenarios for ACT updates:
## Verify ATC broadcasts subscription (004_FP_AMQP_CMM)
## Verify if trader is able to recieve ATC updates (005_FP_AMQP_CMM)
## Verify if trader doesn't recieve ATC updates for border which he doesn't subscribe (006_FN_AMQP_CMM)
## Border opening case (007_FP_AMQP_CMM)

inquiry responses :
--  verify only exchange user can receive ATC response
",,hj444,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,37670400,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010422008r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],Home Office Team Sprint 40,Christmasprint,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Dec/19 15:31;od044;Done

amqpAllocationBroadcast.feature file ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enriching SLA reports with Equal Treatment attributes,XP-1867,83964,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,ei349,ei349,08/Jul/19 12:37,06/Nov/20 10:25,22/Feb/21 13:26,29/Jul/19 17:00,,,Pre2020,,SLA Report Tool,,,,,XBID,,,,"h1. {color:#00875a}*SLA reports alignment with requirements*{color}
h2. Current situation

During the JSC was discovered that „Service Level for the Maximum Time Difference in Receiving Public Order Books Delta Report “ is not included in the SLA reports.  This was most probably part of the SLA reports already and was removed in the past. 
h2. Proposed solution

SLA reports should include _Service Level for the Maximum Time Difference in Receiving Public Order Books Delta Report_ as it was already in the past. 

*Functional Requirements*:
According to our Contract with the customer, we have to be able to measure the maximum difference between the first and last user receiving public order books delta report (PblcOrdrBooksDeltaRprt - Section 5.5.4, DFS510 AMQP Public Message Interface – Trading). Thus, we need to implement a modification which allows us to generate a report sheet with information of receiving public order books delta report value. The value needs to be measured for the 99% cases. The report sheet should be part of SLA performance report.

+Notes:+
* We will be able to measure it for August as a first month
* During July it's necessary to turn on a ""module"" for logging necessary data
* the 10ms criteria is set for 4 LTS connected to XBID and 42 Delivery areas only
* In case additional LTS(s) - the maximum increase is 2ms per LTS


h2. Acceptance criteria 

Generated SLA reports contain _Maximum Time Difference in Receiving Public Order Books Delta Report._ ",,ei349,gd553,od044,qo794,radeale,zi174,,,,,,,,,,,,,,,,,,XBID-4613,,,,,,,,,,,,,,,,,,,"29/Jul/19 16:59;od044;XBID Performance and SM SLA Reporting July 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/72099/XBID+Performance+and+SM+SLA+Reporting+July+2019.xlsx","18/Jul/19 12:50;zi174;XBID Performance and SM SLA Reporting_example.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71739/XBID+Performance+and+SM+SLA+Reporting_example.xlsx","18/Jul/19 10:19;qo794;kpi-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71725/kpi-report.xlsx","18/Jul/19 12:56;zi174;kpi-report_18072019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71740/kpi-report_18072019.xlsx","17/Jul/19 15:46;qo794;performance-report_tmp.xls;https://jira.deutsche-boerse.com/secure/attachment/71711/performance-report_tmp.xls","17/Jul/19 15:56;qo794;source_data.csv;https://jira.deutsche-boerse.com/secure/attachment/71713/source_data.csv",,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,49507200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08jzc:f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,Home Office Team Sprint 31 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Jul/19 12:37;gd553;Answer during JSC:
 * DBAG will respond by 25/06.

Answer during RCB on 25/06:
 * DBAG is currently looking into this topic and several other SLA reporting topics and will come back until the next RCB.","08/Jul/19 12:37;gd553;Update from RCB status report on 05/07:

During initial discussions on the KPIs for the monthly SLA reporting, this service level has been omitted.

DBAG is currently assessing the effort and time to add this service level to the existing reports and also analysing the possibility to deliver the information retroactively.","12/Jul/19 13:41;zi174;According to discussion with developers, the first steps should be:
* use systest 1 for testing purpose of this task
* turn on an attribute for logging necessary data
* test current implementation if works or not

after an initial test will be done, we decide additional steps","15/Jul/19 14:59;radeale;Kamil, please add the following info along with any other you see fit:
 # The parameter to be changed and where
 # The name of the (internal?) report to be generated and if you know how, when and where it is generated

Thanks! :)","15/Jul/19 15:09;qo794;1.  in core application.properties: m7.log.broadcast.types=PblcOrdrBooksDeltaRprt
2.  it's PublicOrderbookReportGenerator and should be inside an internal performance-report.xls tab ""(6) Equal Treatment""","16/Jul/19 10:35;radeale;ls -d $PWD/*
/xbid/xbid-syt1-cor1/tomcat/lib/application-env.properties
/xbid/xbid-syt1b-cor1/tomcat/lib/application-env.properties","16/Jul/19 11:04;radeale;{code}#Ansible: CRON_ELASTIC_COLLECT
#5 * * * * /xbid/report_tool/elastic_collect.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml
#Ansible: CRON_SPM_COLLECT
#8 2 * * * /xbid/report_tool/spm_collect.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml
#Ansible: CRON_SLA_COLLECT
#8 3 * * * /xbid/report_tool/sla_collect.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml
#Ansible: CRON_SLA_GENERATE
#8 4 1 * * /xbid/report_tool/sla_generate.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml
#Ansible: CRON_KPI_GENERATE
#9 4 1 * * /xbid/report_tool/kpi_generate.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml
#Ansible: CRON_CREDIT_POINTS
#0 5 2 * * /xbid/report_tool/credit_points.sh /xbid/report_tool/application.properties ""-Dfile.encoding=UTF-8 -Duser.timezone=UTC"" /xbid/report_tool /xbid/report_tool/logback.xml{code}","16/Jul/19 11:04;radeale;Check the app log, whether it contains something like this:

{code}2017-07-28T04:27:20.919Z [Sender] INFO  c.d.e.m.t.M.outcomingMessage - Exchange: comxerv.broadcastExchange, Type: PblcOrdrBooksDeltaRprt, RoutingKey: 1.prdmbr.Intraday_Power_D.TRM05, Correlation: [49, 97, 49, 53, 53, 55, 52, 48, 45, 102, 48, 48, 100, 45, 52, 101, 53, 50, 45, 98, 102, 99, 51, 45, 49, 57, 99, 102, 101, 99, 53, 54, 51, 49, 56, 100]{code}","16/Jul/19 11:14;radeale;Supposedly the report can be generated with this, ""only"" need to change ""some"" parameters:
{code}java -jar m7-xbid-report-tool-1.6.jar --spring.profiles.active=perf-file \
   --report=AllUat2 \
   --outputDir=results
   --template=/opt/custom-template.xlsx
   --from=2017-05-26T12:00:00  \
   --to=2017-05-27T00:00:00 \
   --orderNotLike=Pre \
   --dir=/home/user/logs{code}

Or this?

{code}java -jar m7-xbid-report-tool-1.6.jar --spring.profiles.active=perf \
       --report=EqualTreatment \
       --from=2017-05-26T12:00:00  \
       --to=2017-05-27T00:00:00 \
       --filenames=/home/user/logs/xb_xbid_perf_cor-1_standard_ixe_1_2017-05-26.log.log,
               /home/user/logs/xb_xbid_perf_cor-1_standard_ixe_2_2017-05-26.log.gz,
               /home/user/logs/xb_xbid_perf_cor-1_standard_hau_1_2017-05-26.log.gz,
               /home/user/logs/xb_xbid_perf_cor-1_standard_hau_2_2017-05-26.log.gz{code}

Also something:
https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=14026765","16/Jul/19 15:43;radeale;Currently blocked by TECHLOG-2579 and hindered by TECHLOG-2580.","17/Jul/19 15:46;qo794;Example of the current report (see sheet ""(6) Equal Treatment""):  [^performance-report_tmp.xls], generated from  [^source_data.csv].  [~radeale][~zi174] Is that what the customer requested (assuming that the charts will be removed)? Please update the current SLA template [^kpi-report.xlsx]  with the required sheet for equal treatment data. Thanks.","18/Jul/19 10:28;zi174;[~qo794] please see the template. This is how I may imagine that we will provide a report to the customer.   [^XBID Performance and SM SLA Reporting_example.xlsx] ","19/Jul/19 09:13;qo794;Manual report generation:
{code}
java -jar report-tool.jar --actions=kpi-collect,kpi-generate --yearMonth=2019-07
{code}
or 
{code}
java -jar report-tool.jar --from=2017-05-26T12:00:00 --to=2019-12-26T12:00:00 --actions=internal-collect-from-elastic
java -jar report-tool.jar --actions=kpi-generate --yearMonth=2019-07
{code}","29/Jul/19 17:00;od044;Test passed on report-tool-2.19-SNAPSHOT
- tab Public Order Books Delta Report is included in SLA report

 [^XBID Performance and SM SLA Reporting July 2019.xlsx] 
",,,,,,,,,,,,,,,,,,,,,,,,
EcpSender: Add more logging ,XP-1860,83915,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,qo794,qo794,04/Jul/19 14:45,04/Aug/20 19:36,22/Feb/21 13:26,16/Jul/19 09:20,,,Pre2020,,Shipping,,,,,,,,,"h1. {color:#00875a}Better problems analysis{color}
h2. {color:#172b4d}Current situation{color}

There is no single log line generated by EcpSender when sending is successful, hence we cannot say whether ECP messages are coming out if there are no problems. See for instance SftpSender
h2. Proposed solution 

Enrich logging for the ECPSender to allow further analysis of problems.
h2. Acceptance criteria 
 - possibility to retrieve data necessary for the EcpSender analysis. ",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51667200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08jzc:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Matching - Iceberg orders matching - 'auction'  scenarios,XP-1858,83909,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,04/Jul/19 13:29,04/Aug/20 19:35,22/Feb/21 13:26,20/Aug/19 15:06,,,Pre2020,,,,,,,,,,,"# Add new TC into end-to-end-tests iceberOrdersMatching.feature for 'auction' scenarios:
* Verify that auction is possible for ICB slice when PPD = 0. (240_FP_Auction_006)
* Verify that auction is possible for ICB sell slice when PPD > 0. (241_FP_Auction_007)
* Verify that auction is possible for ICB buy slice when PPD < 0. (242_FP_Auction_008)
Use:
 **   S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
  **  RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
  ** Auction sheet
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,47779200,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420101c004o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 32 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Aug/19 14:20;hj444;https://github.deutsche-boerse.de/dev/xbid-test/pull/183 created. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Matching - Iceberg orders matching - basic scenarios,XP-1857,83908,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,hj444,hj444,04/Jul/19 13:25,04/Aug/20 19:35,22/Feb/21 13:26,06/Aug/19 10:56,,,Pre2020,,,,,,,,,,,"# Add feature file  *icebergOrdersMatching.feature* into end-to-end-tests
# Add new TC into end-to-end-tests iceberOrdersMatching.feature  
* Verify that it is adjusted peak price for the new ICB order slice (PPD+) for a sell ICB order.
(149_FP_icbOrders_040)
* Verify that it is adjusted peak price for the new ICB order slice (PPD-) for a buy ICB order.
(150_FP_icbOrders_041)
* Verify the evaluation of peak price delta in case of BUY ICB orders. (151_FN_icbOrders_042)
* To test the evaluation of peak price delta in case of BUY ICB orders (152_FN_icbOrders_043)
* To test the DisplayQuant validation at Order Entry. (153_FN_icbOrders_044)
* To test to match the ICB orders - trades (154_FP_icbOrders_045)


Use:
 *   S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
 *   RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
 *   Iceberg Orders sheet
",,hj444,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,49248000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pr:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Aug/19 10:45;tr866;Created new file icebergOrdersMatching.feature
 # added there following 2 test cases:
 {color:#00875a}*149_FP_icbOrders_040*{color} - Verify that it is adjusted peak price for the new ICB order slice (PPD+) for a sell ICB order.
 {color:#00875a}*150_FP_icbOrders_041*{color} - Verify that it is adjusted peak price for the new ICB order slice (PPD-) for a buy ICB order.
 # ignored the 2 test cases
 {color:#de350b}*151_FN_icbOrders_042*{color} - Verify the evaluation of peak price delta in case of BUY ICB orders. - Covered already in addOrder.feature
 {color:#de350b}*152_FN_icbOrders_043*{color} - To test the evaluation of peak price delta in case of BUY ICB orders - Covered already in addOrder.feature
 as they were duplicating test cases from addOrder.feature where they would belong anyway rather to test of matching functionnality
 # created and moved {color:#ff8b00}*153_FN_icbOrders_044*{color} - To test the DisplayQuant validation at Order Entry.
 moved in addOrder.feature as it's order operation, not trade execution. Other 2 parts of the scenario are covered in addOrder.feature by Scenario: ICB order BUY-not valid buy order-display qty>qty,error message is received and Scenario: ICB order BUY-OK,ppd<0
 # added {color:#00875A}*154_FP_icbOrders_045*{color} - To test to match the ICB orders - trades
# Then added the new own scenarios:
{color:#00875A}*Scenario:  Test full execution of order matching one REG Sell order against one ICB Buy order*
*Scenario:  Test matching of two ICB orders with different Peak Sizes and PPD*
*Scenario:  Test price-time priority of orders when matching of ICB and REG orders on one side and REG order on second*
*Scenario:  Test price-time priority of iceberg slices when matching two ICB orders against one REG order*{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Matching - Regular orders matching - 'auction' scenarios,XP-1855,83905,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,hj444,hj444,04/Jul/19 13:05,04/Aug/20 19:35,22/Feb/21 13:26,21/Aug/19 13:36,,,Pre2020,,,,,,,,,,,"# Add new TC into end-to-end-tests regularOrdersMatching.feature for 'auction' cases:
** Verify that the matching price is calculated in auction process - the price determination happens. (235_FP_Auction_001)
** Verify that the matching price is calculated in auction process - the price determination happens for multiple orders. (236_FP_Auction_002)
** Verify that auction doesn't happen when the increase of ATC is sufficient only for partial matching of a UDB order. (237_FP_Auction_003)
** Verify that the matching price is calculated in auction process - the price determination happens for the UDB (user defined blocks). (238_FP_Auction_004)
** Verify that orders get matched from the ""longest"" to the ""shortest"". (239_FP_Auction_005)
** Verify that orders in auction got matched based on time priority.
(243_FN_Auction_009)

Use :
   *  S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
  *  RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
 *  Auction sheet

",,hj444,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,47606400,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pp:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 32 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Aug/19 13:36;tr866;New test cases added to regularOrdersMatching.feature file and reviewed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Matching - Regular orders matching - orders do not match cases,XP-1854,83861,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,03/Jul/19 10:54,04/Aug/20 19:35,22/Feb/21 13:26,17/Jul/19 08:12,,,Pre2020,,,,,,,,,,," #   Add new TC into end-to-end-tests regularOrdersMatching.feature for Negative cases:
( Order-Matching sheet)
*    Verify that orders for different contracts don't match.
  (091_FN_orderMatching_012)
Block Orders matching: 9 Block Orders sheet)
 * Verify that partial block order matching is not possible.
(185_FP_blockOrders_026)
* Verify that  is not possible to match regular orders and UDB sell order
(186_FN_blockOrders_027)
* Verify that  is not possible to match regular orders and UDB sell order
(187_FN_blockOrders_028)


* Use :
 **  S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
  **  RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
  **  Order-Matching sheet
*for block Orders* 
 ** Block Orders sheet
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,50630400,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08zoe:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 30 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-2979-postgresql,XP-456,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"16/Jul/19 12:11;hj444;Added 1 case for FOK order - 093_FP_orderMatching_014.
FOR other FOK cases will be new task created.
","17/Jul/19 08:13;hj444;Pull request created https://github.deutsche-boerse.de/dev/xbid-test/pull/177 .
Pull request merged.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order Matching - Regular orders matching - matching with order price modification,XP-1853,83860,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,03/Jul/19 10:38,04/Aug/20 19:35,22/Feb/21 13:26,13/Aug/19 08:51,,,Pre2020,,,,,,,,,,,"# Prepare methods for order modification - *price modification*.
# Add new TC into end-to-end-tests _regularOrdersMatching.feature_ :
*Order-Matching sheet*
 * Verify that a buy order gets correctly matched after price modification. (089_FP_orderMatching_010)
 * Verify that a buy order gets correctly matched after price modification.
 (090_FP_orderMatching_011)
*Block Orders sheet*
 * Verify block order deactivation, price modification, activation and matching afterwards.
 (190_FN_blockOrders_031)
Use :
 ** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
 ** RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx
 ** Order-Matching sheet
 ** Block Orders sheet",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48297600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pp:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 32 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jul/19 12:08;hj444;Maybe could be used for price modification:
 from  PblcOrdrBooksReqSteps.java
 steps : 
 When(... pick last order and modifies price to (\d+) EUR)
 Then(... expects last modified order to have price (\d+) for area ...)","12/Aug/19 13:43;hj444;https://github.deutsche-boerse.de/dev/xbid-test/pull/181","13/Aug/19 08:51;hj444;Done - merged.
Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Order Matching - Regular orders matching - basic scenarios -match orders, best price, time based rule,partial execution",XP-1846,83768,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,01/Jul/19 14:20,04/Aug/20 19:36,22/Feb/21 13:26,04/Jul/19 11:48,,,Pre2020,,,,,,,,,,,"# Add feature file for *regularOrdersMatcher* into end-to-end-tests
# Add scenarios :.
-- Matching orders create a trade.
-- Best price order is matched first.
-- Time based matching rule: If more orders with the same price then oldest order is matched first.
-- Partial Execution is possible for passive sell order.
-- Partial Execution is possible for passive buy order.
-- Order is rejected if ExeRes=FOK and validity restriction is not GFS.

* Use :
** S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression
** _RTM-03-05-10_Matcher_and_Order_Maintenance_0.31.xlsx_
** *Order-Matching sheet*",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51753600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104201c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 29,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-2979-postgresql,XP-456,XP-3264,develop,XP-3230,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Jul/19 09:59;hj444;pull request with order matching feature file created
https://github.deutsche-boerse.de/dev/xbid-test/pull/176","04/Jul/19 11:48;hj444;pull request merged.
Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Delombok xbid.routing,XP-1843,83764,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,ll664,01/Jul/19 14:06,06/Nov/20 11:34,22/Feb/21 13:26,12/Jul/19 09:50,,,Pre2020,,,,,,,,,,,"[https://github.deutsche-boerse.de/dev/xbid.routing] should be free from Lombok.  Delombok and remove the dependency.

 

Agreed on Losses alignment meeting (1.7.2019 13:00)",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52012800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08jzc:o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare SLA reports for June 2019,XP-1834,83671,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,26/Jun/19 15:57,06/Nov/20 10:25,22/Feb/21 13:26,08/Jul/19 11:10,,,Pre2020,,,,,,,,,,,- new report shall include updated prognosis sheet --> XP-1780,,eh941,ei349,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1780,,,,,,,"03/Jul/19 13:59;eh941;XBID Performance and SM SLA Reporting June 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71111/XBID+Performance+and+SM+SLA+Reporting+June+2019.xlsx","04/Jul/19 08:51;eh941;XBID Service Boundary Reporting June 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71133/XBID+Service+Boundary+Reporting+June+2019.xlsx","03/Jul/19 13:59;eh941;XBID_Credit_points_report_June_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/71110/XBID_Credit_points_report_June_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51408000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104201012",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 29,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,memory-usage-fix,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Jul/19 14:00;eh941;Please review it - just download the older reports and verify there isn't anything missing. I also copy-pasted the prognosis tab from the new proposed template. Please verify it looks ok.

The older ones can be found there - https://projects.deutsche-boerse.de/sites/ps0080/_layouts/15/start.aspx#/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fps0080%2FShared%20Documents%2F03%20XBID%20SLA%20Reporting&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44&View=%7B6C81558C-B2AA-42D3-A854-B2860B7C1829%7D","03/Jul/19 16:21;tr866;In XBID Service Boundary Reporting June 2019.xlsx in the last tab 'Prognosis"" there are too many 0 in the table.
Mainly in the column Current month (max) I can see that there's some weird formula in the cells like
=MAX('C:\Users\tr866\AppData\Local\Temp\142\home\odehfra\Downloads\[sla-report.xlsx]Explicit cap. alloc. requests'!F6:F65536) in Citrix
or =MAX('file:///home/bendtom/Plocha/home/odehfra/Downloads/sla-report.xlsx'#$'Explicit cap. alloc. requests'.F6:F65536) in Ubuntu
instead of formula like =MAX('Explicit cap. alloc.'!F6:F65536) being used in previous month
that causes that all values in column 'Current mont(max)' are 0 and because of that also the rows 'Number of Explicit Requests (daily) = 0%' and 'Number of Explicit Allocations (daily) = 0%' are also all 0
weirdly then I wasn't able to save that file in Citrix or even copy it from Ubuntu to Citrix","03/Jul/19 16:39;tr866;Then only 1 ridiculous small thing about cell not being highlighted in yellow compared to previous month at the following place :) :
file 'XBID Performance and SM SLA Reporting June 2019.xlsx', sheet 'API Response Time', values in column 'Percentile 95% [ms]' are highlighted in yellow if 'Threshold breached?'=yes in files for previous months, but not for the latest one attached here","04/Jul/19 09:02;eh941;Please re-review :-) 

I do believe I fixed the prognosis sheet - very nice catch, thank you.

I didn't _fix_ the coloring though. I don't know the rule for it. We should point it out when it's delivered to account management and ask them how to proceed.","04/Jul/19 10:42;tr866;Looks good to me now too. The coloring is unsignificant I guess. What makes me still bit nervous is that only the 'XBID Service Boundary Reporting June 2019.xlsx' out of the 3 files is not possible to be saved locally on Citrix. Not sure if it's only because of some confidential security settings in Citrix or it might caus troubles on any Windows machine.
Anyway same is happening when downloading this type of file for previous months from sharepoint, so no change from last month.
To sum it up, all good from me too.
","04/Jul/19 15:17;eh941;Reports are uploaded to sharepoint. I've sent an email to Simona and Ana:

{quote}
Hi Simona and Ana,


I've managed to get 3 reports which we provide every month. Jakub Hesoun usually (or always) does it but he's on vocation. I did my best and uploaded them to sharepoint https://projects.deutsche-boerse.de/sites/ps0080/_layouts/15/start.aspx#/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fps0080%2FShared%20Documents%2F03%20XBID%20SLA%20Reporting&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44&View=%7B6C81558C-B2AA-42D3-A854-B2860B7C1829%7D


I hope everything is fine.


There are 2 things to point out:

- I noticed that in older Performance SLA reports API Response Time sheet there are some values highlighted by yellow background. I wasn't sure what is the rule for that if any so I didn't do any manual corrections there.

- I also updated the prognosis sheet as it was prepared in https://jira.deutsche-boerse.com/browse/XP-1780

I don't know the procedure well so I don't know if any further action from my side is needed.


If anything was wrong or unclear don't hesitate to contact me.


Frantisek
{quote}

Putting to waiting.","08/Jul/19 11:10;eh941;Reports uploaded to sharepoint",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Interconnector management - VDA - Operational time unit  - not possible to create VDA interconnector,XP-1825,83595,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,25/Jun/19 13:29,06/Nov/20 11:15,22/Feb/21 13:26,26/Jun/19 11:50,,,Pre2020,,,,,,,,,,," HUT-SKT border

Create VDA (HUT-HUTVDA1 ) with interconnector  configuration values :
Capacity Resolution : 1
Contract Resolution : 30
Operational Unit Time : 60

Navigate into Interconnector Management and create 
Border HUT-SKT
DA1 : HUTVDA1
DA2: SKTDA2
Add configuration
*Expected Values*
_Capacity Resolution : 1_
_Contract Resolution : 30_
_Operational Unit Time : 60_

*Actual non editable values*:
_Capacity Resolution : 1_
_Contract Resolution : 30_
*Operational Unit Time : 30*

Set all other values  click  OK
Create
 
_validation message appears :_
{color:red}Operational time unit 30 of virtual interconnector HUTVA1---------K-SK2DA----------- (valid from 25.06.2019 00:00:00) is not the same as the value 60 of interconnector HUTVA1-HUT (valid from 25.06.2019 00:00:00){color}",,hj444,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52444800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,25/Jun/19 13:29,,,,,,,,,,,,,,,,,,,,,,,"1|y08z5c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 28,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/19 10:48;hj444;retest started

docker env.

Latest version of XBID develop with fix.

 ","26/Jun/19 11:50;hj444;Test passed.

Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID SLAs and monthly service credit points,XP-1821,83521,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,21/Jun/19 15:51,06/Nov/20 10:25,22/Feb/21 13:26,27/Jun/19 09:34,,,Pre2020,,,,,,,SLA,,,,"discuss XBID SLAs and monthly service credit points as specified in Attachment 5B and possibilities to automate report creation.

 

Agenda

1 SLAs and credit points related to the service

2 discussion about current state and reporting possibilities

3 follow up actions

 ",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/19 09:31;tz118;XBID_Credit points_20190626.pptx;https://jira.deutsche-boerse.com/secure/attachment/70906/XBID_Credit+points_20190626.pptx","27/Jun/19 09:31;tz118;XBID_Credit_points_report_June_2018_BIZOPS_example.xls;https://jira.deutsche-boerse.com/secure/attachment/70905/XBID_Credit_points_report_June_2018_BIZOPS_example.xls",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52358400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08yqw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jun/19 09:33;tz118; attached presentation and SLA report template proposal
 * Ppt presentation provides basic overview about credit points and requirements described in Attachment 5B
 * Excel file provides a solution proposal how to report monthly credit points (performance and service) together in one monthly report

1 SLAs and credit points related to the service DONE

2 discussion about current state and reporting possibilities DONE

3 follow up actions - DONE, template discussed and updated wit overall CPs tab, BizOps asked for review, new scrum team contact person - Jakub Musil",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mismatch in orderbook calculation for BLOCK trades,XP-1816,83458,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,od044,od044,od044,20/Jun/19 16:50,06/Nov/20 12:40,22/Feb/21 13:26,02/Jul/19 14:01,,,Pre2020,,,,,,,,,,,"Mismatch in orderbook calculation for BLOCK trades.

It occurred during the perf run of scenario sc14-v09.

{code}
2019-06-20T13:33:35.504Z [Orderbook][XBDBX001][85d9569] ERROR c.d.e.m.t.v.XbidSoftAsserts - 
Crossed OrderBook detected - Contract row 18-T10_XB (id=846) and column key OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A44P', memberId=Optional.empty} has best buy price 5400 

(ExposedOrderQty{orderId=51806, isBuy=true, price=5400, orderCreationTime=Thu Jun 20 15:31:07 CEST 2019, contractId=846, lastUpdateTime=null, orderbookTsoEicCode='10Y1001A1001A44P', orderTsoEicCode='10YNL----------L', exposedQuantity=35000, hiddenQuantity=0, orderRestriction=ALL_OR_NOTHING, orderType=BLOCK, orderModificationType=ACTIVE, balancingGroupId='BG-BGPX-------01', peakSizeQty=0, sourceMemberId='DBM01'}) and best sell price 5300 

(ExposedOrderQty{orderId=54913, isBuy=false, price=5300, orderCreationTime=Thu Jun 20 15:33:21 CEST 2019, contractId=846, lastUpdateTime=null, orderbookTsoEicCode='10Y1001A1001A44P', orderTsoEicCode='10YDE-VE-------2', exposedQuantity=40000, hiddenQuantity=0, orderRestriction=ALL_OR_NOTHING, orderType=BLOCK, orderModificationType=ACTIVE, balancingGroupId='BG-BGPX-------01', peakSizeQty=0, sourceMemberId='DBM01'}).
{code}",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1838,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51926400,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,20/Jun/19 16:50,,,,,,,,,,,,,,,,,,,,,,,"1|y08yd4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/19 13:32;eg288;It is false alarm. The two orders differs in quantity and have restriction All or Nothing thus cannot be matched. The crossed ordderbook is valid outcome in this scenario. At the same time it is not acceptable that log files are polluted with the false error.

*Solution:*
 Improve crossed orderbook detector to take into account order restriction and exposed quantity. It has drawback though, the following scenario will not be detected as the detector checks only orderbook top.
||Sell Price/Qty||Buy Price/Qty||
|40/35|42/70|
|42/70| |","02/Jul/19 14:01;od044;Test passed on XBID v 2.0.22",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New H2H Matrix screen - No areas selected,XP-1806,83347,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Cannot Reproduce,radeale,radeale,radeale,18/Jun/19 14:55,06/Nov/20 12:40,22/Feb/21 13:26,25/Jun/19 10:21,,,Pre2020,,Capacity,,,,,,,,,"There is a non-deterministic and difficult to reproduce error in the new H2H Matrix page - {color:#DE350B}No areas selected{color}.

1. Click on the H2H Configuration button
2. Select several areas and a Delivery Interval
3. Confirm
4. Click on the H2H Configuration button
5. Add or remove an area
6. Confirm
=> In some rare cases an error {color:#DE350B}No areas selected{color} is shown",,hj444,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52531200,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,18/Jun/19 14:55,,,,,,,,,,,,,,,,,,,,,,,"1|y08xvc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 28,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/19 10:43;radeale;Still unable to reproduce :(","21/Jun/19 14:47;hj444;Test envs : *Syt2* : _Version R2.0.20_ (Build 260aad0b1046b681ae4bcfe072a03f482a659092)

*Docker env* TCs with creation of new DAs assigned/not assigned to TSO BG, ...

So far not reproduced.","25/Jun/19 09:46;hj444;Retest again on Monday - SYT2.

Not reproduced.

I would leave this issue and if this behavior happens again, more presize steps-what DAs were set, unset, actions what btns were cliked, also some pictures of misbehavior would be nice to have from customer.

Or logs.","25/Jun/19 10:22;radeale;Thanks for trying to reproduce it, I also had no luck, so let's be on watch if anything happens.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New H2H Matrix screen - Scrollbar too long,XP-1805,83345,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,radeale,radeale,radeale,18/Jun/19 14:51,06/Nov/20 12:40,22/Feb/21 13:26,20/Jun/19 09:46,,,Pre2020,,Capacity,,,,,,,,,"The vertical scrollbar on the new H2H Matrix page is way too too long - overdone, both in the Internet Explorer as well is in Firefox.",,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1806,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52963200,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,18/Jun/19 14:51,,,,,,,,,,,,,,,,,,,,,,,"1|y08xuw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 28,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jun/19 14:10;radeale;Test OK in XBID 2.0.22 in Docker, Firefox, Internet Explorer.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove old XBID email domains,XP-1804,83337,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Resolved,ei349,wn626,wn626,18/Jun/19 11:13,06/Nov/20 11:34,22/Feb/21 13:26,11/Jul/19 13:16,,,Pre2020,,,,,,,support_request,,,,"Hi XBID Dev,

Please confirm that below email domain is not in use and can be decommissioned:

xbid.comxerv.com           10.136.140.254, 10.136.12.254",,ei349,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-3088,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52444800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08xt4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/19 13:50;ei349;There is no usage of this address from the XBID developement point of view. Maybe TechOps have some evidence? ","21/Jun/19 14:01;wn626;Thanks, TechOps just want confirmation from your side, will work with them further.","26/Jun/19 13:16;ei349;[~wn626]: can we close this task now? ","26/Jun/19 13:21;wn626;yes, you can close it, thanks. I needed only the conformation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test XP-1793,XP-1796,83281,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,eh941,eh941,14/Jun/19 16:06,06/Nov/20 10:14,22/Feb/21 13:26,24/Jun/19 15:18,,,Pre2020,,,,,,,,,,,,,eh941,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52531200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,14/Jun/19 16:06,,,,,,,,,,,,,,,,,,,,,,,"1|y08xd0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/19 18:05;tr866;Tested on environment Docker with version XB R2.0.16-SNAPSHOT-a9454a0a1d06ce8cca68ffe52e1f54e5adf5a5cd and Comtrader v2.5.1.53
When -Drequest.delay=2000 parameter was set in Idea login process in Comtrader was slower, but it didn't seem that there would be delay 2s between every request. Whole login process took less than 1 minute. In record messages I could notice that couple of times about 3 requests were sent the same second, but for most of other request it looked there is a 2s delay. So not sure if the delay works as expected. Login process in AMQP Test Client was much slower. Nevertheless login to ComTrader was successfull even if there was a load running from AMQP Test Client(Tools>Test Automation) and T-1 filter was available in All Trades panel. I didn't have any trades from previous day tho, that I'll see next day 19.06.2019.
When I set in Idea the parameter to -Drequest.delay=5000 AMQP Test Client wasn't able to connect anymore with connection timeout. Login via Comtrader took longer, almost 2 minutes and T-1 filter was still available.
With parameter -Drequest.delay=7000 login to Comtrader from LoginReq to last TradeCaptureReq took about 3,5 minutes and Comtrader still could successfully login and T-1 filter was available.","19/Jun/19 14:29;tr866;Having some data for trades for T-1 day and testing with the same versions as above:
- With the delay -Drequest.delay=4100 it was still possible to login to AMQP Test Client and run load via Tools>Test Automation(2000 loops with 2 OrdrEntry with 50-100ms delays). Login process took about 1 sec more than 2 minutes and login to ComTrader was successfull with T-1 trades visible in All Trades Panel
- With the delay -Drequest.delay=7000 login to AMQP Test Client wasn't possible and login process to Comtrader took more than 4 minutes and the login also finished successfully with T-1 trades still visible
","19/Jun/19 15:06;tr866;Note:
to use special version of tradin inquiry with the delays following has to be changed in /xbid-test/test-common/target/classes/docker_ss_quick_run.sh:
image: xbid-docker-dev-local.artifactory.dbgcloud.io/xbid/xbid-trading:latest
has to be changed to
image: xbid-docker-dev-local.artifactory.dbgcloud.io/xbid/xbid-trading:2.0.16-SNAPSHOT-delayed-2

to set other delay thant the default 1s add the following(in ms):
-Drequest.delay=2000","24/Jun/19 15:18;tr866;The fix for T-1 contracts was introduced already in ComTrader 2.5.1.53 and it was working properly as described above.
With the newest version ComTrader 2.5.1.57 it was possible to have it ran from webstart and login against XBID R2.0.20-260aad0b1046b681ae4bcfe072a03f482a. The T-1 filter was also available and All trades panel could be switched to T-1 trades.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New scenario runner revise threading,XP-1786,83202,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eh941,eh941,13/Jun/19 09:24,06/Nov/20 09:48,22/Feb/21 13:26,14/Jun/19 15:27,,,Pre2020,,,,,,,,,,,"{color:#00875a}*Clarification of threading in new test runner*{color}

Make sure we use correct schedulers in new scenario runner",,eh941,,,,,,,,,,,,60,60,,0%,60,60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53568000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104204",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test new performance scenario runner,XP-1785,83201,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,eh941,eh941,13/Jun/19 09:22,06/Nov/20 12:28,22/Feb/21 13:26,27/Jun/19 09:32,,,Pre2020,,,,,,,,,,,"New scenario runner was written by XP-1675. It works but the results need to be verified.
 # Select scenario on which we want to test it - {color:#00875a}done{color} - it's SC15
 # Run the scenario with the old runner - {color:#00875a}done{color}
 # Generate report from the old runner
 # Run the same scenario with the new runner
 # Generate report from the new runner
 # Compare the results",,eh941,,,,,,,,,,,,180,180,,0%,180,180,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/19 12:26;ll664;newrun.zip;https://jira.deutsche-boerse.com/secure/attachment/70740/newrun.zip","21/Jun/19 12:26;ll664;oldrun.zip;https://jira.deutsche-boerse.com/secure/attachment/70739/oldrun.zip",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53568000,,,,,,,,,,,,,,,XP-4094,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08uj8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID CLONE: Prognosis sheet in SLA Boundary Reporting to be based on Linear growth calculation,XP-1780,83164,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,12/Jun/19 12:11,04/Aug/20 19:36,22/Feb/21 13:26,27/Jun/19 10:43,,,Pre2020,,,,,,,SLA,,,,"*{color:#00875a}Prognosis aligned with real growth{color}* 

1. as agreed on the NEMO OPSCOM 28/5, NEMOs/TSOs would like to ask DBAG to change calculation model in the “+Prognosis+” sheet delivered monthly as a part of the SLA Performance reporting in the “XBID Service Boundary Reporting <Month Year>.xlsx” {color:#ff8b00}from exponential{color} (present) to the {color:#ff8b00}linear{color} growth model.

There has been held experts call 12/6, there has been agreed:
 * to proceed with the change asap, if possible already for the next reporting season (June 2019).
 * NEMOs/TSOs also provided sample excel for the Prognosis sheet alternative calculation based on the linear growth.
 * The meeting minutes [^Joint_TWG-PTF_MM_Growth_calculation_experts_call_20190612.docx] contain the excel sheet embedded, as well as the record from the discussions. 

2. Growth estimation April from RCB: the monthly update for months February, March and April of 2019 of growth estimations:
 * growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):

 * Number of Block Orders (daily), as a subset of the orders = *29*%
 * Number of Explicit Requests (daily) = 0%
 * Number of Explicit Allocations (daily) = 0%
 * Number of Hubs = this is known to DBAG (2nd wave data set)
 * Number of Borders = this is known to DBAG (2nd wave data set)
 * Sustainable Load Items = *10*%

*AC*
 * updated SLA boundary template with sheet prognosis based on requirements (see attached meeting minutes and point 2. from above)
 * if possible use new template already for the next reporting period (June 2019).

 ",,de698,tz118,zi174,,,,,,,,,,57600,57600,,0%,57600,57600,,,,,,XBID-4566,,,,,,,,,,,,,,,,,,,"12/Jun/19 12:11;tz118;Joint_TWG-PTF_MM_Growth_calculation_experts_call_20190612.docx;https://jira.deutsche-boerse.com/secure/attachment/70344/Joint_TWG-PTF_MM_Growth_calculation_experts_call_20190612.docx","25/Jun/19 10:41;tz118;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70809/sla-report.xlsx","13/Jun/19 12:50;tz118;sla-report.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70442/sla-report.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52358400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08uj9:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Jun/19 12:51;tz118;new SLA report template uploaded, [~uv683] please review","25/Jun/19 16:10;tz118;topic explained and discsussed with [~zi174] and [~de698].

latest attached sla report template (from 25/6) currently in review

 ","27/Jun/19 10:13;zi174;From my point of view it's understandable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID statistics in grafana ,XP-1778,83161,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,zi174,zi174,12/Jun/19 11:38,13/Aug/20 19:51,22/Feb/21 13:26,18/Dec/19 13:21,,,Pre2020,,,,,,,TO-JOB,,,,"{color:#00875a}*Automated analytical business data overview for XBID product*{color}

*Introduction*
 We use Grafana as a monitoring software for information about trades, contracts etc. It offers good overview about our customers and XBID project. However, we currently do not have any automatic process which would transfer data to Grafana. We have to do this task manually. Thus. It may happen we will have some windows during which we will be without data. Thus, we would like to create a solution which will cover all necessary steps for Grafana usage without any manual action. It means that Grafana will have all data automatically and we will be able to provide XBID statistics every time once is necessary.

*Requirements*
 +To have Grafana with actual data (e. g. -1 day etc.)+
 * Prepare a job which will transfer data from prod-copy (Hotfix) to the Grafana (or propose a better solution)
 * Collaborate with TechOps where the job may be run - we need an environment for running that (?)
 * Test the data transferring script and data visibility in grafana
 * figure out all necessary things which I forget mention and they are necessary for the correct functionality :)

*Result*
 ""Live or whatever"" tracking of XBID trading and activity
 +Benefits+
 * XBID statistics whenever you need
 * First step ""know your product""
 * Lots of fancy graphs for potential presentation
 * and more",,de698,eg288,ei349,radeale,tz118,yo218,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/19 09:56;eg288;application-env.properties;https://jira.deutsche-boerse.com/secure/attachment/78511/application-env.properties","12/Dec/19 09:56;eg288;xbid-statistics-generator-0.9-SNAPSHOT.jar;https://jira.deutsche-boerse.com/secure/attachment/78512/xbid-statistics-generator-0.9-SNAPSHOT.jar",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,37324800,,,,,,,,,,,,,,,XP-1782,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09n2w:s4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmasprint,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jun/19 13:11;tz118;linking some jiras from thwe past with relation to Grafana statistics","19/Aug/19 09:54;ei349;discussed with [~ox626]. 

After the release of XBID 2.0 we will get read-only access on the 5th patroni cluster node  with historical data masking. Until then we should stick with manual data copying as we do it now. ","19/Aug/19 09:59;zi174;[~eg288] Please check the comment above","11/Dec/19 14:24;yo218;Planned approach: having a scheduled jenkins pipeline job which checks out the jar file and execute it locally on englobauto1. ","12/Dec/19 09:56;eg288;*HOWTO* start xbid-statistic-generator java app

1) download xbid-statistics-generator-0.9-SNAPSHOT.jar and application-env.properties into a target directory
2) update application-env.properties with connection details
3) to execute:
{code}
java -cp "".:xbid-statistics-generator-0.9-SNAPSHOT.jar"" -Dspring.profiles.active=env org.springframework.boot.loader.JarLauncher
{code}","16/Dec/19 14:15;yo218;A manual execution on host englobmon1 was succesful. Ansible playbook has been prepared and is ready to be triggered by jenkins","18/Dec/19 13:21;yo218;A jenkins job is triggered every Sunday at 04:00 AM:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/XBID%20Ansible%20Jobs/job/XBID-Statistics-Generator/]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable logging of internal messages between CMM and CMI,XP-1777,83157,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,12/Jun/19 10:32,06/Nov/20 11:34,22/Feb/21 13:26,13/Jun/19 14:49,,,Pre2020,,Capacity,,,,,,,,,"{color:#00875a}*More information in logs* {color}

For investigation purposes it would be great to log all AMQP messages sent and received between CMM and CMI. The feature is already in place only logback in CMM/CMI must be configured:
{code:xml}
    <logger name=""com.deutscheboerse.amqp.converter.MessageTraceLogger.incomingMessage"" level=""trace""/>
    <logger name=""com.deutscheboerse.amqp.converter.MessageTraceLogger.incomingInfo"" level=""trace""/>
    <logger name=""com.deutscheboerse.amqp.converter.MessageTraceLogger.outcomingMessage"" level=""trace""/>
    <logger name=""com.deutscheboerse.amqp.converter.MessageTraceLogger.outcomingInfo"" level=""trace""/>
{code}",,jy268,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53568000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08txr:a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 28,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,traversal-XP-2485,tomcat-rollback,XP-2942,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,trailing-slash-syt1,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Jun/19 14:23;jy268;pull request created: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/385",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check and improve HP Fortify results ,XP-1776,83156,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ei349,ei349,12/Jun/19 09:50,06/Nov/20 11:16,22/Feb/21 13:26,26/Jun/19 12:05,,,Pre2020,,,,,,,waiting-techops,,,,"{color:#00875a}*Increasing level of the application security rating*{color}

{color:#172b4d}XBID Develop HP Fortify URL: {color}

{color:#172b4d}https://hpfortify.dwain.infra/ssc/html/ssc/version/10475/fix/null/?issueFilters=FOLDER_FOLDER:5b50bb77-071d-08ed-fdba-1213fa90ac5a&filterSet=dbd63fcc-432f-4066-8388-1b008de27dc1{color}

{color:#172b4d}*AC:* {color}

{color:#172b4d}- all critical and high incidents are resolved or supressed{color}",,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52444800,,,,,,,,,,,,,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08uj9:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,tomcat-rollback,XP-2942,XP-3025-catalina-timezone,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-2484,XP-3110-deprecated-log,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-2501-to-xbid-dev-env,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,traversal-XP-2485,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,versions,XP-4505_reporting_tools_upgrade_hpfortify,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"24/Jun/19 16:00;ll664;Fortify found hardcoded Elastic user/pass committed in the source code - this was removed and configuration adjusted accordingly. Customer facing envs needs to be done by techops - TECHLOG-2526.

 

The remaining issues have been false positives and have been supressed.

 

 ","26/Jun/19 12:05;ll664;Fortify OK, pipeline works again, closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
User message for capacity_data_unavailable,XP-1770,83084,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,qo794,qo794,07/Jun/19 14:53,06/Nov/20 11:34,22/Feb/21 13:26,09/Aug/19 07:56,,,Pre2020,,Capacity,,,,,,,,,"h1. {color:#00875a}*Error message information clarity*{color}
h2. Current Situation

when there is problem with data exporting in CMM (or it takes longer than the timeout for requests from CMI to CMM) the following exception is thrown but not converted to a user message on UI but displayed in its ""raw"" format:
{code:java}
java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.deutscheboerse.energy.cmminteg.service.CapacityDataUnavailableException: capacity_data_unavailable{code}
h2. Proposed Solution

Replace the technical error message mentioned above with human readable format. 
h2. Acceptance Criteria

- technical exception message will be completely replaced by the human readable format. ",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,48643200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010423a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 31 [S],Home Office Team Sprint 32,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/19 07:56;qo794;It's impossible to test, fully covered by unit tests and manually by ""hacking"" cmi in the code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
alter energy-mkt-shared for CTPA to new versions,XP-1766,83035,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,06/Jun/19 15:09,06/Nov/20 11:34,22/Feb/21 13:26,07/Jun/19 12:14,,,Pre2020,,,,,,,,,,,"Dear Emergency, please prepare MR  for XBID 2.0.16, SPM 2.0.7, RE 5.0.45 to be deployed into CTPA on 12/6/2019, on the deployment date also release CT xx.52 add the MR into SERVICE-3308 thank you. I will rememer you with release of CT",,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,54086400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08w2g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Deliver May KPI,SLA reports",XP-1752,82847,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,uv683,03/Jun/19 11:56,06/Nov/20 10:25,22/Feb/21 13:26,03/Jun/19 14:03,,,Pre2020,,SLA Report Tool,,,,,,,,,,,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/19 14:03;uv683;XBID Performance and SM SLA Reporting May 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70007/XBID+Performance+and+SM+SLA+Reporting+May+2019.xlsx","03/Jun/19 14:03;uv683;XBID Service Boundary Reporting May 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70008/XBID+Service+Boundary+Reporting+May+2019.xlsx","03/Jun/19 14:03;uv683;XBID_Credit_points_report_May_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70006/XBID_Credit_points_report_May_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,54432000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08uja:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jun/19 14:03;uv683;Hi all ([~ei349],[~qm925],[~gd553])

KPi and SLA reports are generated, enclosed to this Jira and on sharepoint as usual. I have removed Market Halt tab.

Malina,Simona: please do some sanity check and distribute to customers.

Regards

Jakub",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deploy CTP Profile Server to SYT (1.5 PENTest related),XP-1745,82775,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,ek176,ek176,30/May/19 12:44,11/Aug/20 13:01,22/Feb/21 13:26,18/Jul/19 14:49,,,Pre2020,,,,,,,SECURITY,,,,"Deploy CTP Profile Server to SYT env.

Decide, if this needs to be done on single- or double-sided env.

 

The following XP tasks need to be tested against a Profile Server (CTP). 
 * XP-1322
 * XP-1315
 * XP-1316

Then, TechOps have relevant tasks already in Resolved mode.",,ek176,qo794,tm431,,,,,,,,,,,,,,,,,,XP-1315,XP-1322,XP-1316,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,50457600,,,,,,,,,,,,,,,XP-67,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420pc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],Home Office Team 28,Home Office Team Sprint 29 [S],,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,tomcat-rollback,XP-2942,XP-2506-xbid-dev-env,XP-69,trailing-slash-syt1,XP-3025-catalina-timezone,XP-2583,XP-2484,XP-3110-deprecated-log,XP-2554,XP-2501-to-xbid-dev-env,traversal-XP-2485,comtrader-2.5.x,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"31/May/19 08:52;qo794;TODO:
* prepare/find a server for deployment (/)
* create DB and users (/)
* add profile server deployment configuration to energy-mkt-shared (/)
* add apache server deployment configuration to energy-mkt-shared (/)
* firewall for profile server (/)
* configure Comtrader to use the profile server (/)
* release and deploy Comtrader for system test (/)","31/May/19 09:54;qo794;TECHLOG-2469 created, waiting.","11/Jul/19 10:16;tm431;Works ok of SYT2. CT starts properly","15/Jul/19 13:08;ek176;Needs to be accessible via SSL (in order to test XP-1322). Created TECHLOG-2575, reopened","18/Jul/19 14:45;qo794;HTTPS is already enabled: https://10.136.143.246:60806/profile-storage/services/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"new repository xbid-api, split from m7-api",XP-1742,82767,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eg288,eg288,30/May/19 10:02,06/Nov/20 11:34,22/Feb/21 13:26,03/Jul/19 14:25,,,Pre2020,,,,,,,,,,,"DISCUSS new repo name:
 * xbid-api
 * m7.xbid-api
 * any other

please take into a consideration groupId and packages renaming (discuss this first please). 

NOTES:
 # preserve only branches used by xbid
 # create jenkins release jobs
 # release new artifacts and change xbid pom file to reference the new xbid-api artifacts as dependency",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,54777600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08txr:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],Home Office Team 28,Home Office Team Sprint 29 [S],,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,XP-69,xbid-losses-poc,XP-2979-postgresql,XP-456,XP-3264,XP-2583,develop,XP-3230,XP-2694,XP-2232,XP-2554,master,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,comtrader-2.5.x,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fork reporting-engine and separate it from M7,XP-1741,82766,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,jy268,jy268,30/May/19 09:51,06/Nov/20 10:25,22/Feb/21 13:26,12/Jun/19 15:55,,,Pre2020,,Reporting Engine,,,,,,,,,"Currently we are sharing reporting-engine repository with M7. It has to be forked and reporting-engine-5.0.x should be a new develop.

please keep in mind the cleanup jobs when changing the groupId and packages. 

Acceptance criteria:
 * new repository is created
 * current 5.0.x branch should be a new develop
 * switch all jenkins jobs to new repository",,jy268,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53568000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08txo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1261-guava-28,selenide-poc,tomcat-rollback,XP-2942,XP-3025-catalina-timezone,xbid-losses-poc,XP-2484,XP-3110-deprecated-log,XP-3230,XP-3070,xbid-2.0.25.x,fixing-failover,plewmic-scripts,XP-2506-xbid-dev-env,XP-1504,trailing-slash-syt1,XP-456,XP-2979-postgresql,XP-3264,develop,XP-2694,XP-2232,master,XP-2501-to-xbid-dev-env,XP-4273-owasp-zap-enable,traversal-XP-2485,inline-tomcat-params,XP-4526-resource-managment-fix,XP-2488-xbid-dev-env,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Jun/19 14:31;qo794;Done:
* a new repository
* master, develop branch from reporting-engine-5.0.x
* groupId
* release
* dependency changed in xbid and xbid-test
* xbid-product
* release jenkins job","12/Jun/19 16:14;radeale;Test {color:#00875A}OK{color} on SYT2, Reporting Engine version 5.0.46.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
prognosis sheet update - CC,XP-1738,82747,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,29/May/19 14:27,12/Aug/20 13:56,22/Feb/21 13:26,12/Jun/19 12:55,,,Pre2020,,,,,,,,,,,"Dear DBAG (and TWG PTF members in copy),

We are coming back to the point announced on Joint meeting 20/5:

*20190516 TWG PTF:*
 * TWG FTF agreed Linear growth rate compared to July 2018 to be used for estimation of the growth
 * Prognosis sheet given in the XBID Service Boundary Reporting <Month Year>.xlsx:
 * Figures are provided by DBAG containing prognosis when the Boundary is going to be breached
 * Actual growth expectation is calculated and proposed to NEMO OPSCOM based on Linear growth rate
 * Prognosed values by DBAG are calculated with the assumption of the exponential growth - which obviously creates a difference in the growth estimations in between of DBAG/NEMO OPSCOM.
 * TWG PTF prepared an example comparison sheet Prognosis calculated with the linear growth vs the original one and will be a part of the message to be communicated to DBAG to illustrate the concern

 
 * *TWG PTF aims to approach NEMO OPSCOM with proposal of:*
 * NEMO OPSCOM to consider asking the DBAG for changing the Prognosis to be based on Linear growth calculation, too.
 * Likely it will be communicated on next RCB

 ** 
 * TWG PTF proposes as beneficial, as part of discussion with DBAG on calculation methods used for prognosis, to organize a CC:
 * Dedicated clarification meeting of TWG PTF experts with the DBAG technical experts for calculation to be agreed/organize

*20190520 TWG PTF/DBAG:*
 * There has been agreed:
 * First the request to be communicated on RCB level, then DBAG will provide the proposal of timeslots to the TWG PTF for the dedicated CC TWG PTF/DBAG expert discussion.

As agreed, the point has been confirmed on RCB level 28/5:

 ** 

*20190528 RCB:*
|17.|Linear growth rate| * TWG PTF agreed linear growth rate compared to July 2018 to be used for estimation of the growth
 * In the “+Prognosis+” sheet delivered as a part of the “XBID Service Boundary Reporting <Month Year>.xlsx” are calculated by DBAG estimates (prognosis) when the Boundary is likely going to be breached. However,
 * Actual growth expectation is calculated by TWG PTF and proposed to NEMO OPSCOM based on +linear growth rate+
 * Prognosed values by DBAG are calculated with the assumption of the +exponential growth+ - which obviously creates a difference in the growth estimations in between of DBAG/NEMO OPSCOM.

  * NEMOs are asking DBAG for changing the Prognosis to be based on Linear growth calculation, too.
 * If accepted the discussion can continue on expert level in Joint TWG PTF / DBAG meeting(s).|

 

Therefore*:*
 * *TWG PTF would like to ask DBAG for proposal of timeslots for the dedicated CC of TWG PTF/DBAG expert discussion.* 
 * *To illustrate the concern we are sharing the alternative Prognosis sheet showing the calculations based on the original and the proposed models.*

 ",,ei349,tz118,,,,,,,,,,,57600,57600,,0%,57600,57600,,,,,,,,,,,,,,XP-1780,,,,,,,,,,,"11/Jun/19 10:03;tz118;TWG-PTF_Growth_calculation_experts_call_20190612.docx;https://jira.deutsche-boerse.com/secure/attachment/70301/TWG-PTF_Growth_calculation_experts_call_20190612.docx","07/Jun/19 13:59;tz118;XBID Service Boundary Reporting March 2019 alt Prognosis.xlsx;https://jira.deutsche-boerse.com/secure/attachment/70264/XBID+Service+Boundary+Reporting+March+2019+alt+Prognosis.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53654400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420j",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/19 21:42;ei349;[~tz118] - can you propose the meeting on Wednesday please? Me and ACM are on the workshop with customers on Tuesday. Thank you. ","30/May/19 09:35;tz118;done","11/Jun/19 10:04;tz118;CC on 12/6 at 10am, agenda attached","12/Jun/19 12:55;tz118;CC - done, XP-1780 created as follow up

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
User overview file includes implicit allocation user XIMPLALO,XP-1731,82623,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,27/May/19 13:53,06/Nov/20 12:40,22/Feb/21 13:26,24/Jun/19 11:09,,,Pre2020,,Capacity,,,,,,,,,"{color:#00875a}*CMM Overview file aligned with the GUI*{color}

User overview file includes implicit allocation user XIMPLALO that are not visible on GUI.

Step to reproduce 
 1. Log in CMM Reference data management 
 2. Navigate to User management 
 3. Click on Download overview 
 4. Check the downloaded file - include XIMPLALO user

Expect behaviour:
 The overview file should exclude the XIMPLALO user and keep the overview to be 1:1 with GUI",,jy268,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/19 11:09;od044;Racf_SADMIN02_20180215180026.csv;https://jira.deutsche-boerse.com/secure/attachment/70770/Racf_SADMIN02_20180215180026.csv",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,52617600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,27/May/19 13:53,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 28,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jun/19 12:33;jy268;Review ok.","24/Jun/19 11:09;od044;Test pass on Docker with version R2.0.22-SNAPSHOT (Build 76a5cc183b18c08d03c5ed20464f0c63bb911de2)

- User overview file excludes the XIMPLALO user and contains user records 1:1 with GUI. 
 [^Racf_SADMIN02_20180215180026.csv] 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance perf tools to support ICEBERG product,XP-1725,82576,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,od044,od044,24/May/19 15:52,04/Aug/20 19:53,22/Feb/21 13:26,10/Jun/20 10:51,,,3.1.0,,Other,,,,,,,,,"{color:#00875a}*Enriching performance tools by supporting new products*{color}

Enhance perf tools to support ICEBERG product:

Detail of previous analysis (XP-1660):
{quote}Iceberg orders are supported by ScenarioRunner but unfortunately, there is no ScenarioGenerator with icebergs support.

Recently Rts3ScenarioGenerator has been used solely. To implement icebergs support there the following steps would be needed:

add ICEBERG product to enum com.deutscheboerse.thirdparty.testscenario.rts3.model.Product
 extend Rts3ScenarioGenerator.createNewOrderEntry() to support ICEBERG product
 to simplify it most iceberg features would be hardcoded, for example, number of slices, etc,
 another approach would be to define several ICEBERG products each with a specific iceberg property set similar to block products
{quote}",,ei349,od044,,,,,,,,,,,57600,57600,,0%,57600,57600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,54777600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000000000000000003000400006020hi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 9 (S),Alpha Sprint 10,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/May/19 15:27;ei349;to be done after dataset runner",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test Alarmtilt new version on non-prod env,XP-1718,82524,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,tz118,tz118,23/May/19 15:13,06/Nov/20 10:14,22/Feb/21 13:26,11/Jun/19 17:36,,,Pre2020,,,,,,,,,,,"on the shared AT platform ([https://v5.alarmtilt.net|https://v5.alarmtilt.net)/]) there was deployed new version => AT shared platform : v5.7.6

AC
 * check non prod env and procedures
 * review upgrade and features
 * investigate user manual updates (MFG500)",,od044,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53654400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08ut8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/19 17:36;od044;The actual version is v5.7.4

New version v5.7.6 contains the following new changes:
- https://support.alarmtilt.com/en/release-notes/version-5-7-5
- https://support.alarmtilt.com/en/release-notes/version-5-7-6

After review, improvements and new features do not have an impact on our actual procedure flows. Also, there no need an update of the user manual (MFG500), all feature remains only GUI has been changed a bit, mainly color design. 

- All procedures are working as usual. (tested on SYT3 against shared AT platform)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support switch of all remaining servers to Azul ,XP-1717,82521,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,ei349,ei349,23/May/19 15:04,14/Aug/20 14:38,22/Feb/21 13:26,14/Aug/20 14:37,,,Agile Pilot,,,,,,,ice,,,,"{color:#00875a}*[ JDK Consistency ]*{color}

Cooperate with techops on the migration of remaining servers to Azul. 

AC: 

- validate that every servers mentioned in connected TECHLOG Jira (https://jira.deutsche-boerse.com/browse/TECHLOG-2237) are succesfully migrated ",,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,42163200,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08t7c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/19 14:05;ek176;You can use a [xml_check_java_provider.sh|https://github.deutsche-boerse.de/ek176/shared/blob/master/utils/bash_check_java_provider/xml_check_java_provider.sh] BASH script to check the Java versions on certain hosts. Input: XML config file from energy-market-shared repository. 

Usage:

{code:bash}
# Only list hosts from the XML file
./xml_check_java_provider.sh --user ab123 --file xbid_env.xml  --list-only

# Check java processes on the hosts from the XML file. Omit red/green coloring of Azul/Oracle java.
./xml_check_java_provider.sh --user ab123 --file xbid_env.xml  --no-colors 

{code}
*Note:* You should use ssh-key based login.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extra Statistics for XBID Customer,XP-1711,82472,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,rg535,rg535,22/May/19 15:35,06/Nov/20 10:14,22/Feb/21 13:26,11/Jun/19 14:07,,,Pre2020,,,,,,,XBID,,,,"{color:#00875a}*[ Florence Conference materials input ]*{color}

*FYI Conference info*: https://ec.europa.eu/info/events/meeting-european-electricity-regulatory-forum-florence-2019-jun-17_en

Dear Team, the one year anniversary of XBID is approaching. In celebration of the good year, they want some extra statistics that they can use for marketing purposes. We will provide this data without additional charge (no 3rd party support, etc).

{color:#0747a6}Please can you kindly provide the following information to Suzanna on *11. June* *no later than 14:00*:{color}
 * total no. of trades since production start
 * total number of trades in June 2019 (from 1st June to 11th June),
 * total number of trades in May 2019
 * highest no. of trades on a single calendar day since production start
 * average SM file generation time",,ei349,rg535,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,54259200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104200i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,Home Office Team 27 [S],,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/May/19 15:40;ei349;[~zi174]: This is the task we already discussed. Can you please have a look when you find some time? Thank you in advance.  ","03/Jun/19 14:27;zi174;total no. of trades since production start until 10th June -------> 16,029 Mil 
total number of trades in June 2019 (from 1st June to 10th June), -------> 655.5 K
total number of trades in May 2019 -------> 1 948,5 k
highest no. of trades on a single calendar day since production start -------> 85,6 k - 07.06.2019
average SM file generation time -------> 6585 ms - from SLA report - MAY","05/Jun/19 09:13;ei349;idea for our Analytics in the future ... try to think/brainstorm about how to make this and other business related data visible on demand without further digging (dashboard, website, grafana,???) ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test Scenario Execution Improvements,XP-1675,82175,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,eh941,eh941,16/May/19 13:57,06/Nov/20 11:34,22/Feb/21 13:26,13/Jun/19 09:23,,,Pre2020,,,,,,,,,,,"Current solution suffer on multiple things:

# Improve code readability
# Improve performance - the throughput must be much higher than now - now it's around ~800 messages/second
# Keep the original XML format (you might introduce a new one but keep the old as well)
# Make a nice interface for execution",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,55987200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420ii",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],Alpha Team Sprint 27,Alpha Team Sprint 28 [S],,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clarify last Security Concept document comments with other teams and publish,XP-1672,82158,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,ei349,ei349,16/May/19 12:16,04/Aug/20 19:35,22/Feb/21 13:26,03/Jul/19 14:44,,,Pre2020,,,,,,,,,,,"Please check the latest consolidated document stored as the attachment of this Jira and update tasks to external teams with pending points (see ESO-123). After comments are clarified consolidate them in the final document, polish it and publish to the ESO and GIS for the review. 

AC: 
 * All missing points filled 
 * Document published to ESO and GIS for the review",,ei349,radeale,zi174,,,,,,,,,,,,,,,,,,,,,XP-1649,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,51753600,,,,,,,,,,,,,,,XP-1661,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:zxr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,Home Office Team 27 [S],Home Office Team 28,Home Office Team Sprint 29 [S],,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/May/19 14:45;zi174;From development point of view it seems we are done. Maybe some additional task will appear in future. We are currently waiting for the techops part. ","03/Jul/19 14:44;zi174;A clear version of security concept for an initial ESO review can be found here:
https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F02%20General%20topics%2FSecurity%2FSecurityConcept%2FXBID%2FClear%5Fversion&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7BB91642FD%2D7D32%2D4F21%2D8FBB%2DF503B3712788%7D

[~ei349] FYI",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create new performance scenarios to cover orderbook calculation,XP-1660,82038,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,od044,od044,14/May/19 10:22,06/Nov/20 12:29,22/Feb/21 13:26,24/May/19 15:48,,,Pre2020,,Trading,,,,,,,,,"Create new performance scenarios to cover orderbook calculation.
- do an analysis of its doable 
- create new excel scenario 
",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1725,,,,,,,XP-1579,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,55296000,,,,,,,,,,,,,,,XP-4094,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:zxi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/May/19 14:13;eg288;Iceberg orders are supported by ScenarioRunner but unfortunately there is no ScenarioGenerator with icebergs support. 

Recently Rts3ScenarioGenerator has been used solely. To implement icebergs support  there the following steps would be needed:
# add ICEBERG product to enum _com.deutscheboerse.thirdparty.testscenario.rts3.model.Product_
# extend _Rts3ScenarioGenerator.createNewOrderEntry()_ to support ICEBERG product
** to simplify it most iceberg features would be hardcoded, for example number of slices etc, 
** another approach would be to define several ICEBERG products each with a specific iceberg property set similar to block products
** yet another approach, the iceberg properties would be encoded in ICEBERG product name, example: ICEBERG_slice5_ppx10

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM - it is possible to login with one user in several 'windows' without note and 'force logout',XP-1659,81988,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,hj444,hj444,13/May/19 14:30,06/Nov/20 12:40,22/Feb/21 13:26,17/May/19 13:34,,,XBID 2.0,,,,,,,,,,,"env SYT2:

1. Firefox - login with Admin User SADMIN02

Navigate to  Capacity

2. Firefox private session : login with Admin User SADMIN02

Expected - note about already logged in with this user

Actual - successful login in both sessions is user active, no force logout.

3. Chrome : login with Admin User SADMIN02

Expected - note about already logged in with this user

Actual - successful login, in all 3 sessions is user active, no force logout.

 

It is also possible to do allocations in all open sessions with this one user.

 

I would expect - User can be active only in one session.

 ",,hj444,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/May/19 14:34;hj444;3window_oneUser.png;https://jira.deutsche-boerse.com/secure/attachment/68971/3window_oneUser.png","13/May/19 14:36;hj444;oneuser_2FFwindows.png;https://jira.deutsche-boerse.com/secure/attachment/68974/oneuser_2FFwindows.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,55900800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,13/May/19 14:30,,,,,,,,,,,,,,,,,,,,,,,"1|y08rfo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/May/19 13:27;qo794;h3. Analysis
The issue was ""introduced"" by migrating to Spring Boot 2.0, namely by replacing {{ConcurrentSessionControlStrategy}} (not present in 2.0 any longer) by {{ConcurrentSessionControlAuthenticationStrategy}}, the later does not register new sessions by itself but a different approach must by used.","17/May/19 13:34;od044;Test passed on docker 
- The session concurrencies work properly now. 
- user is informed about already logged user or invalidated session. 
- two sessions of the same user cannot be active at the same time anymore. 


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security Concept vol. 2,XP-1649,81926,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,zi174,zi174,10/May/19 09:23,06/Nov/20 12:47,22/Feb/21 13:26,17/May/19 09:18,,,Pre2020,,,,,,,waiting-po,,,,"We've received a feedback on provided Security Concept and based on techops review, they are considering some parts shall be filled by the development team.


",,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56505600,,,,,,,,,,,,,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08rac:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID SIMU - 22/5 new XBID 2.0 deployment to UAT  - release new ComTrader,XP-1646,81880,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,09/May/19 14:21,06/Nov/20 10:14,22/Feb/21 13:26,27/May/19 10:50,,,Pre2020,,,,,,,,,,,Plan delivery of new ComTrader version for 15/5,,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-3111,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56592000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08oif:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID LIP B - 22/5 new XBID 2.0 deployment to UAT - release new ComTrader,XP-1643,81876,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,09/May/19 14:15,06/Nov/20 10:14,22/Feb/21 13:26,22/May/19 15:15,,,Pre2020,,,,,,,,,,,Plan delivery of new ComTrader version for 15/5,,rehapav,,,,,,,,,,,,,,,,,,,,SERVICE-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56592000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08oif:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID LIP A - 22/5 new XBID 2.0 deployment to UAT - release new ComTrader,XP-1642,81874,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,09/May/19 14:10,06/Nov/20 10:14,22/Feb/21 13:26,22/May/19 15:14,,,Pre2020,,,,,,,,,,,Plan delivery of new ComTrader version for 15/5,,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-3107,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56592000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08oif:yi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID LIP A - 22/5 new XBID 2.0 deployment to UAT - release notes,XP-1641,81873,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,09/May/19 14:07,06/Nov/20 10:14,22/Feb/21 13:26,17/May/19 12:26,,,Pre2020,,,,,,,,,,,Prepare final release notes for the delivery and attach it to the linked XBID ticket XBID-4494,,rehapav,,,,,,,,,,,,,,,,,,,,SERVICE-3107,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56592000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08rfr:zi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify how bad is gluster.fs journal inconsitency with new Chronicle version,XP-1638,81845,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,eh941,eh941,09/May/19 11:15,06/Nov/20 11:07,22/Feb/21 13:26,24/May/19 10:31,,,Pre2020,,,,,,,,,,,"Before any test is done {color:#de350b}re-revert the changes made by XP-1250.{color}

Based on analysis in the comment of XP-1250 verify how bad is the inconsistency of the data in journal stored in gluster.fs if:
 # network from the writing node to the gluster goes down
 # the process which writes is killed hard
 # make up other scenarios.

I suggest to *create a synthetic test*. Create a simple app which will create pre-defined load of messages. Store these messages to the gluster.fs base journal files and right after that store the very same data to the local disk. Use disruptors for that to simulate the core setup. After the incident happens compare the data of these two journals.",,eh941,ek176,jy268,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1250,,,,,,,"23/May/19 09:39;jy268;run1.log;https://jira.deutsche-boerse.com/secure/attachment/69545/run1.log",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,55296000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08rfr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/May/19 17:56;jy268;Observation on local environment.

Scenario tested, run synthetic test and during runtime use *lsof* and *gdb* to close one of file descriptors. After around 10 minutes application crashes. Verifier is not able to read the journal due to:

{code}
Caused by: java.nio.BufferUnderflowException: null
	at net.openhft.chronicle.bytes.BytesInternal.parseUtf8_SB1(BytesInternal.java:378) ~[chronicle-bytes-2.17.13.jar:na]
	at net.openhft.chronicle.bytes.BytesInternal.parseUtf8(BytesInternal.java:135) ~[chronicle-bytes-2.17.13.jar:na]
	at net.openhft.chronicle.bytes.StreamingDataInput.readUtf8(StreamingDataInput.java:220) ~[chronicle-bytes-2.17.13.jar:na]
	at net.openhft.chronicle.bytes.BytesInternal.readUtf8(BytesInternal.java:1692) ~[chronicle-bytes-2.17.13.jar:na]
	at net.openhft.chronicle.bytes.StreamingDataInput.readUtf8(StreamingDataInput.java:188) ~[chronicle-bytes-2.17.13.jar:na]
	at com.detuscheboerse.energy.glusterfs.JournalReader.unmarshall(JournalReader.java:62) ~[classes/:na]
	at net.openhft.chronicle.wire.MarshallableIn.readBytes(MarshallableIn.java:67) ~[chronicle-wire-2.17.10.jar:na]
	at com.detuscheboerse.energy.glusterfs.JournalReader.read(JournalReader.java:50) ~[classes/:na]
	at com.detuscheboerse.energy.glusterfs.VerifierApplication.run(VerifierApplication.java:45) [classes/:na]
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:813) [spring-boot-2.1.5.RELEASE.jar:2.1.5.RELEASE]
	... 5 common frames omitted
Caused by: java.lang.IllegalStateException: utflen: 1024, readRemaining: 110
	at net.openhft.chronicle.bytes.BytesInternal.parseUtf8_SB1(BytesInternal.java:379) ~[chronicle-bytes-2.17.13.jar:na]
	... 14 common frames omitted
{code}

the important part is:

{code}
Caused by: java.lang.IllegalStateException: utflen: 1024, readRemaining: 110
	at net.openhft.chronicle.bytes.BytesInternal.parseUtf8_SB1(BytesInternal.java:379) ~[chronicle-bytes-2.17.13.jar:na]
	... 14 common frames omitted
{code}
which is a result of *readUtf8()* operation on BytesIn. In my opinion it means that journal is *corrupted* and it will be extremely hard to recover from this situation.","23/May/19 09:35;jy268;First test on *xbsyt1cor1* writing to glusterfs mounted drive.

After force unmount application was trying to write to unmounted drive in async mode. After the crash I compared journals written to local storage and to glusterfs.
In glusterfs, which was expected, some messages were missing, comparing timestamps from log it was around ~3s which were in local one but not in gluster. What is more I was able to read journal only from the beginning, operations like tail done this way resulted in no messages, which in my opinion means that journal was internally corrupted:

{code}
        ChronicleQueue queue = ChronicleQueue.single(path);
        ExcerptTailer tailer = queue.createTailer();
        final long endIndex = tailer.toEnd().index();
        final long startIndex = Math.max(0, endIndex - lastMessages);

        LOG.info(""Starting with index {}, journal max index was: {}"", startIndex, endIndex);
        tailer.moveToIndex(startIndex);

        while (tailer.readBytes(this::unmarshall));
{code}","23/May/19 15:22;jy268;Second test on *xbsyt1cor1* writing to glusterfs mounted drive.

In this test connection between *xbyst1cor1* and glusterfs drives was manually stopped using iptables. As a result messages on glusterfs journaler were lost (again around ~3s). The difference was that after a while async save to glusterfs stopped and was waiting for resource to be accessible again, it can be seen in logs here:

{code}
2019-05-23 11:44:06.362  INFO 14381 --- [           main] c.d.energy.glusterfs.TestPlan            : 181000 messages generated, 9819000 remaining.
2019-05-23 11:44:06.428  INFO 14381 --- [           main] c.d.energy.glusterfs.TestPlan            : 182000 messages generated, 9818000 remaining.
2019-05-23 11:45:19.375  INFO 14381 --- [           main] ConditionEvaluationReportLoggingListener : 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-05-23 11:45:19.380 ERROR 14381 --- [           main] o.s.boot.SpringApplication               : Application run failed

java.lang.InternalError: a fault occurred in a recent unsafe memory access operation in compiled Java code
        at net.openhft.chronicle.wire.AbstractWire.enterHeader(AbstractWire.java:314) ~[chronicle-wire-2.17.10.jar!/:na]
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreAppender.writeHeader(SingleChronicleQueueExcerpts.java:396) ~[chronicle-queue-5.17.4.jar!/:na]
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreAppender.openContext(SingleChronicleQueueExcerpts.java:401) ~[chronicle-queue-5.17.4.jar!/:na]
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreAppender.writingDocument(SingleChronicleQueueExcerpts.java:365) ~[chronicle-queue-5.17.4.jar!/:na]
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreAppender.writingDocument(SingleChronicleQueueExcerpts.java:345) ~[chronicle-queue-5.17.4.jar!/:na]
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueExcerpts$StoreAppender.writeBytes(SingleChronicleQueueExcerpts.java:144) ~[chronicle-queue-5.17.4.jar!/:na]
        at com.detuscheboerse.energy.glusterfs.persister.JournalMessagePersister.persist(JournalMessagePersister.java:26) ~[classes!/:1.0-SNAPSHOT]
        at com.detuscheboerse.energy.glusterfs.TestPlan.lambda$null$0(TestPlan.java:62) ~[classes!/:1.0-SNAPSHOT]
        at java.util.ArrayList.forEach(ArrayList.java:1257) ~[na:1.8.0_202]
        at com.detuscheboerse.energy.glusterfs.TestPlan.lambda$execute$1(TestPlan.java:61) ~[classes!/:1.0-SNAPSHOT]
        at java.util.ArrayList.forEach(ArrayList.java:1257) ~[na:1.8.0_202]
        at com.detuscheboerse.energy.glusterfs.TestPlan.execute(TestPlan.java:59) ~[classes!/:1.0-SNAPSHOT]
        at com.detuscheboerse.energy.glusterfs.LoadGeneratorApplication.run(LoadGeneratorApplication.java:51) [classes!/:1.0-SNAPSHOT]
        at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:813) [spring-boot-2.1.5.RELEASE.jar!/:2.1.5.RELEASE]
        at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:797) [spring-boot-2.1.5.RELEASE.jar!/:2.1.5.RELEASE]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:324) [spring-boot-2.1.5.RELEASE.jar!/:2.1.5.RELEASE]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1260) [spring-boot-2.1.5.RELEASE.jar!/:2.1.5.RELEASE]
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:1248) [spring-boot-2.1.5.RELEASE.jar!/:2.1.5.RELEASE]
        at com.detuscheboerse.energy.glusterfs.LoadGeneratorApplication.main(LoadGeneratorApplication.java:28) [classes!/:1.0-SNAPSHOT]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_202]
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_202]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_202]
        at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_202]
        at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [glusterfs-generator-1.0-SNAPSHOT.jar:1.0-SNAPSHOT]
        at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [glusterfs-generator-1.0-SNAPSHOT.jar:1.0-SNAPSHOT]
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
USM998 for release 2.0 (SIMU),XP-1617,81620,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,radeale,radeale,radeale,03/May/19 14:31,06/Nov/20 10:14,22/Feb/21 13:26,13/May/19 15:34,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,"Create USM998 for XBID 2.0. Should be based on the current SIMU configuration.

Don't expose the document to the customer yet.",,radeale,,,,,,,,,,";22/Jul/19 18:41;radeale;3600",,,0,3600,,,0,3600,,,,,,,,,,,,,,,,,,,,,,,,"13/May/19 15:34;radeale;USM998_System_Configuration_v46_v20_SIMU_internal.xlsx;https://jira.deutsche-boerse.com/secure/attachment/68986/USM998_System_Configuration_v46_v20_SIMU_internal.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56160000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08o4g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/May/19 15:34;radeale;A new version of document created based on v46 with the current SIMU parameters added based on the 24th of April findings.

Also in here:
https://projects.deutsche-boerse.de/sites/ps0080/_layouts/15/start.aspx#/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fps0080%2FShared%20Documents%2F04%20XBID%20Legal%20Framework%2F05%20Technical%20Documents%2FUSM998%20System%20Configuration%2FInternal&FolderCTID=0x0120001EB961193A6D2F4CA27436315BDB6B44&View=%7B6C81558C-B2AA-42D3-A854-B2860B7C1829%7D",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[AlarmTilt] PX roles are not visible during add new contact in AT administration,XP-1609,81577,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tz118,od044,od044,02/May/19 16:49,06/Nov/20 11:08,22/Feb/21 13:26,11/Jun/19 10:26,,,Pre2020,,,,,,,,,,,"PX roles are not visible during adding a new contact step in AT administration. 

Actually, it is possible to add PX role only after a user has been created with a general role e.g. administrator. After that assign the user into PX roles in the Access control menu and then unassign the administrator role that has been assigned during the user's creation.

Actual:
Add new contact flow:
 !2019-05-02_16-47-add-contact-roles.png! 

It is available only in Acces control menu:
 !2019-05-02_16-45-PX-roles.png! 

Expect:
It is possible to select PX roles during add new contract 
",,od044,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/May/19 16:49;od044;2019-05-02_16-45-PX-roles.png;https://jira.deutsche-boerse.com/secure/attachment/68628/2019-05-02_16-45-PX-roles.png","02/May/19 16:49;od044;2019-05-02_16-47-add-contact-roles.png;https://jira.deutsche-boerse.com/secure/attachment/68627/2019-05-02_16-47-add-contact-roles.png",,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,53740800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,02/May/19 16:49,,,,,,,,,,,,,,,,,,,,,,,"1|y08nvk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 27,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/19 10:59;tz118;AT support contacted regarding this issue

 ","11/Jun/19 10:25;tz118;AT support:
 # You said « PX roles are not visible during adding a new contact step in AT administration. This seems to be the same for all management units, eg. DGB IT »

 * I configured an user in « DGB IT » and I was able to select the PX roles immediately

 # You said « It is Simulation Mgmt user trying to create new one. »

 * I configure an user in « Mgmt Simulation » and, indeed, I was not able to select the PX roles. These roles are not created in this management unit

this suggests that roles shall be configured in the other mngmnt unit in order to work",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sonar Improvements - Increase to Level A ,XP-1608,81576,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,ei349,ei349,02/May/19 16:31,06/Nov/20 11:05,22/Feb/21 13:26,07/Aug/19 10:49,,,Pre2020,,,,,,,,,,,"[https://sonar.energy.dev.dbgcloud.io/dashboard?id=com.deutscheboerse.energy.xbid%3Axbid%3Axbid-2.0.x]

 

AC: 
 * All Sonar findings on the A level maximum. 
 * Agreed procedure how to keep the level",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,57110400,,,,,,,,,,,,,,,XP-3247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y094pr:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Java Cryptography Testing on Azul ,XP-1597,81518,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,ei349,ei349,02/May/19 10:31,11/Aug/20 13:01,22/Feb/21 13:26,09/May/19 17:03,,,Pre2020,,,,,,,,,,,"Can you please test sending of encrypted e-mails on any environment where there is Azul migration finished? 

 

AC: 

- Confirmation if this feature works or task in the back log if not with proper description. ",,ei349,od044,,,,,,,,,,,28800,28800,,0%,28800,28800,,,,,,,,,,,,,,,,,,,,,,,,,"09/May/19 16:54;od044;encrypted_ack.png;https://jira.deutsche-boerse.com/secure/attachment/68874/encrypted_ack.png","09/May/19 16:54;od044;encrypted_outbound.png;https://jira.deutsche-boerse.com/secure/attachment/68873/encrypted_outbound.png","09/May/19 17:03;od044;encrypted_reset_password.png;https://jira.deutsche-boerse.com/secure/attachment/68875/encrypted_reset_password.png",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56505600,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,02/May/19 10:31,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:zz7",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/May/19 16:55;od044;Test passed on XBID Version R2.0.14 after migration to Azul OpenJdK, version Zulu.
{code}
2019-05-09T13:52:18.670Z [executor-3][][] INFO  c.d.e.c.t.m.MailHandler - Creating encrypted e-mail for 10XDE-RWENET---W
2019-05-09T13:52:18.953Z [executor-3][][] INFO  c.d.e.c.t.m.MailHandler - Sending From: xbsyt2-cmi@xbid-test.deutsche-boerse.com, To: amp@xbid-test.deutsche-boerse.com, Subject: 20190510_RID_AMP-APG_001.xml, Attachment: 20190510_RID_AMP-APG_001.xml
2019-05-09T13:52:19.008Z [executor-2][][] INFO  c.d.e.f.e.GenericExporter - File saved successfully : File:20190509_RID_AMP-APG_001.xml in 0.488 seconds
2019-05-09T13:52:19.031Z [TaskScheduler-6][][] WARN  o.h.orm.deprecation - HHH90000022: Hibernate's legacy org.hibernate.Criteria API is deprecated; use the JPA javax.persistence.criteria.CriteriaQuery instead
2019-05-09T13:52:19.049Z [executor-1][][] INFO  c.d.e.c.t.m.MailHandler - Creating encrypted e-mail for 10XDE-RWENET---W
2019-05-09T13:52:19.103Z [executor-1][][] INFO  c.d.e.c.t.m.MailHandler - Sending From: xbsyt2-cmi@xbid-test.deutsche-boerse.com, To: amp@xbid-test.deutsche-boerse.com, Subject: 20190509_RID_AMP-APG_001.xml, Attachment: 20190509_RID_AMP-APG_001.xml
{code}
 !encrypted_outbound.png!  

{code}
2019-05-09T14:46:21.022Z [TaskScheduler-6][][] INFO  c.d.e.c.t.m.MailHandler - [imap://englobmail1:143/INBOX, imap://englobmail2:143/INBOX] : [1] messages. Fetching...
2019-05-09T14:46:21.022Z [TaskScheduler-6][][] INFO  c.d.e.c.t.m.MimeMessageTransformer - From : amp <amp@xbid-test.deutsche-boerse.com>, subject: ACK_20190509_RID_AMP-APG_002.xml
2019-05-09T14:46:21.026Z [TaskScheduler-6][][] WARN  o.h.orm.deprecation - HHH90000022: Hibernate's legacy org.hibernate.Criteria API is deprecated; use the JPA javax.persistence.criteria.CriteriaQuery instead
2019-05-09T14:46:21.031Z [TaskScheduler-6][][] INFO  c.d.e.c.t.m.MimeMessageTransformer - Email encryption is enabled for 10XDE-RWENET---W, email being processed is required to be encrypted and signed
2019-05-09T14:46:21.031Z [TaskScheduler-6][][] INFO  c.d.e.c.t.m.SMIMEConverter - Email message decrypting
2019-05-09T14:46:21.140Z [TaskScheduler-6][][] INFO  c.d.e.c.t.m.SMIMEConverter - Email message signature veryfing
{code}
!encrypted_ack.png! 

Reset password
 !encrypted_reset_password.png! ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix SLA reports for FEB and MAR,XP-1595,81513,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,02/May/19 10:19,13/May/19 10:26,22/Feb/21 13:26,13/May/19 10:26,XBID 1.5.9,,XBID 1.5.9,,SLA Report Tool,,,,,,,,,"Customer found issues with missing Explicit Allocation Request metrics in sustainable load minutes in February and March report.

It is very probably an issue on our side that was caused by manual report generation. Explicit Allocation Request metric from sustainable load minutes will have to be regenerated from log files that are on EBSM.",,ei349,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56851200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1tc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/May/19 12:44;ei349;info from JZavada: 
{quote}Dear DBAG,

TWG PTF 2/5 found out that the SLA performance reports received from DBAG for the last 2 months  (""XBID Performance and SM SLA Reporting February 2019.xlsx"" and ""XBID Performance and SM SLA Reporting March 2019.xlsx"") are missing sheets „*Market Halt*“.  The sheet should be present even if no market halt occurred during the month.

Please address this finding along with the original one in description of this ticket.

Best regards

Jiri
{quote}","06/May/19 13:23;uv683;We have found out that application logs obtained from EBSM are not complete for February. For example 1st of February core log is ending around 19:00. We need to restore logs in elastic",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare Report Tool deployment to production to make SLA report generation automatic,XP-1594,81512,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eh941,uv683,uv683,02/May/19 10:14,22/May/19 10:15,22/Feb/21 13:26,07/May/19 14:13,XBID 1.5.9,XBID 2.0,XBID 2.0,,SLA Report Tool,,,,,,,,,"*CURRENT STATUS*

At the moment Report Tool is broken on production. It is generating only some of the metrics that needs to be collected which is forcing us to create reports manually every month. Production version is 2.2.4 and the bug is that it always tries to download application logs from elastisearch for some specific January date and hour instead of iterating forward in time to present date time.

Application runs at two nodes in prod and simu in master-master status

*WHAT TO DO*

Along with [~eh941] we have come to the conclusion that 
 # current production version 2.2.4 bug will be fixed and new version 2.2.5 will be released and deployed to _*xbprodsla2*_
 # latest version from develop will be deployed to _*xbprodsla1*_

 * prepare these two artifacts
 * create deployment requests to simu first and then prod
 * be aware of DB changes, latest development version uses flyway but production version probably not - baseline will have to be done. Analyze and handle
 * be aware of application properties changes and change them appropriately in energy-mkt-shared
 * after deployment will be done on simu check that application is behaving as expected and populating computed_percentile and computed_total tables every day with valid values",,eh941,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56764800,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1t",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2942,tomcat-rollback,traversal-XP-2485,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,report-tool-2.2.x,master-report-tool-2.2.x,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/May/19 16:36;eh941;{quote}current production version 2.2.4 bug will be fixed and new version 2.2.5 will be released and deployed to xbprodsla2
{quote}
Fixed, release created
{quote}latest version from develop will be deployed to xbprodsla1
{quote}
MR created [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/302]
{quote}prepare these two artifacts
{quote}
They are prepared
{quote}create deployment requests to simu first and then prod
{quote}
MR to SIMU - [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/303]
It's settled that the deployment request will be created by [~rehapav]

{quote}be aware of DB changes, latest development version uses flyway but production version probably not - baseline will have to be done. Analyze and handle
{quote}
The upgrade from 2.2.4 to 2.14 is compatible
{quote}be aware of application properties changes and change them appropriately in energy-mkt-shared
{quote}
The versions have compatible property files.
{quote}after deployment will be done on simu check that application is behaving as expected and populating computed_percentile and computed_total tables every day with valid values
{quote}
Created XP-1633 for that","07/May/19 14:13;eh941;Created additional MR for all CuTes - https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/309",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SLA reports for April 2019,XP-1589,81493,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,ei349,ei349,30/Apr/19 20:04,12/Aug/20 13:56,22/Feb/21 13:26,10/May/19 08:53,XBID 1.5.9,,XBID 1.5.9,,SLA Report Tool,,,,,,,,,"Please generate the April SLA reports and provide them to the customers by 5th May. 

Note: It is not possible to generate report from Elasticsearch at the moment, there are no logs in elasticsearch for big part of April. See https://jira.deutsche-boerse.com/browse/TECHLOG-2264

During log generation please make sure that Explicit Capacity Allocation on Sustainable Load Minutes sheet is filled. It was problem in last two reports and there are zero values.",,ei349,gd553,uv683,,,,,,,,,,57600,57600,,0%,57600,57600,,,,,,,,,,,,,,,,,,M7ACM-562,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56505600,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1t9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/May/19 08:53;uv683;[~gd553] [~qm925]

please find reports for April on sharepoint, do some sanity check, remove Market Halt - if needed and distribute.

Thanks

Jakub","10/May/19 11:43;gd553;I have had a look and they seem fine to me.

[~qm925] - I have saved a new version of the Service Boundary report without the Market Halt. Please go ahead and distribute the reports.

Thanks both!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New orderbook implementation reports Mismatch,XP-1579,81396,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,od044,eg288,eg288,26/Apr/19 15:57,06/Nov/20 11:05,22/Feb/21 13:26,14/May/19 15:17,,,XBID 2.0,,Trading,,,,,,,,,"Several orderbook calculation experiment mismatches have been reported on LIP A env on May 17th . 

First sample for order-book-experiment:
{code}
Experiment: order-book-experiment; Control: time = 661 µs; Candidate: time = 10,741 µs; Mismatch: control size = 7, candidate size = 7; OrderbookInfoDelta{contractId=81998, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YCZ-CEPS-----N', memberId=Optional.empty}', modificationType='ACTIVE', revision=5, buyExposedOrderQties=[ExposedOrderQty{orderId=1224910, isBuy=true, price=1000, orderCreationTime=Wed Apr 17 11:57:10 CEST 2019, contractId=81998, lastUpdateTime=null, orderbookTsoEicCode='10YCZ-CEPS-----N', orderTsoEicCode='10YPL-AREA-----S', exposedQuantity=0, hiddenQuantity=50000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-TGE--------01', peakSizeQty=25000, sourceMemberId='TRM10'}, ExposedOrderQty{orderId=1224913, isBuy=true, price=1000, orderCreationTime=Wed Apr 17 11:57:10 CEST 2019, contractId=81998, lastUpdateTime=null, orderbookTsoEicCode='10YCZ-CEPS-----N', orderTsoEicCode='10YPL-AREA-----S', exposedQuantity=0, hiddenQuantity=85000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-TGE--------01', peakSizeQty=25000, sourceMemberId='TRM10'}], sellExposedOrderQties=[]} from control similar to OrderbookInfoDelta{contractId=81998, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YCZ-CEPS-----N', memberId=Optional.empty}', modificationType='ACTIVE', revision=5, buyExposedOrderQties=[ExposedOrderQty{orderId=1224910, isBuy=true, price=1000, orderCreationTime=Wed Apr 17 11:57:10 CEST 2019, contractId=81998, lastUpdateTime=null, orderbookTsoEicCode='10YCZ-CEPS-----N', orderTsoEicCode='10YPL-AREA-----S', exposedQuantity=0, hiddenQuantity=50000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-TGE--------01', peakSizeQty=25000, sourceMemberId='TRM10'}, ExposedOrderQty{orderId=1224913, isBuy=true, price=1000, orderCreationTime=Wed Apr 17 11:57:10 CEST 2019, contractId=81998, lastUpdateTime=null, orderbookTsoEicCode='10YCZ-CEPS-----N', orderTsoEicCode='10YPL-AREA-----S', exposedQuantity=0, hiddenQuantity=85000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-TGE--------01', peakSizeQty=25000, sourceMemberId='TRM10'}], sellExposedOrderQties=[]} from candidate
{code}

First sample for order-book-info-experiment:
{code}
Experiment: order-book-info-experiment; Control: time = 0 µs; Candidate: time = 0 µs; Mismatch: control size = 13079, candidate size = 13079; OrderbookInfo{contractId=81998, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YCZ-CEPS-----N', memberId=Optional.empty}', modificationType='ACTIVE', revision=5} from control similar to OrderbookInfo{contractId=81998, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YCZ-CEPS-----N', memberId=Optional.empty}', modificationType='ACTIVE', revision=5} from candidate
{code}

Kibana search:",,eg288,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56160000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,26/Apr/19 15:57,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:zz6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 24,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/19 16:35;eg288;Implemented improvements:
* CommonComparators.collectionUnorderedComparator() uses collectionA to build mapB (line 31),  it is bug, collectionB must be used
* ExposedOrderQty equals method used as comparator - no quantities etc are compared -> implement ExposedOrderQty comparator for scientits
* LatTradeInfo is not printed in mismatch report

Next steps:
* run a long-running test and monitor for mismatch occurrencies  
* try to reproduce by exploratory testing","03/May/19 13:52;eg288;Orderbook experiment mismatch reported in xbid SIMU env on April 30th, 14:00:00

* to replay -> db dump and journal files are located on EBSM server, directory /opt/data/transfer/dbdumps/xbid_simu and /opt/data/transfer/journals/xbid_simu

{code}
Experiment: order-book-experiment; Control: time = 962 µs; Candidate: time = 2,043 µs; Mismatch: control size = 6, candidate size = 6; OrderbookInfoDelta{contractId=65660, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YNL----------L', memberId=Optional.empty}', modificationType='ACTIVE', revision=29, buyExposedOrderQties=[], sellExposedOrderQties=[ExposedOrderQty{orderId=3318465, isBuy=false, price=500, orderCreationTime=Tue Apr 30 13:53:25 CEST 2019, contractId=65660, lastUpdateTime=null, orderbookTsoEicCode='10YNL----------L', orderTsoEicCode='10YES-REE------0', exposedQuantity=0, hiddenQuantity=90000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-OMIE-------02', peakSizeQty=10000, sourceMemberId='TRM01'}]} from control similar to OrderbookInfoDelta{contractId=65660, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10YNL----------L', memberId=Optional.empty}', modificationType='ACTIVE', revision=29, buyExposedOrderQties=[], sellExposedOrderQties=[ExposedOrderQty{orderId=3318465, isBuy=false, price=500, orderCreationTime=Tue Apr 30 13:53:25 CEST 2019, contractId=65660, lastUpdateTime=null, orderbookTsoEicCode='10YNL----------L', orderTsoEicCode='10YES-REE------0', exposedQuantity=0, hiddenQuantity=90000, orderRestriction=NONE, orderType=ICEBERG, orderModificationType=ACTIVE, balancingGroupId='BG-OMIE-------02', peakSizeQty=10000, sourceMemberId='TRM01'}]} from candidate
{code}","09/May/19 09:59;eg288;Bug in OLD orderbook calculation. The old implementation did not remove iceberg order with zero available quantity  from in memory orderbook table when the capacity was used up. The problem was not visible because the iceberg WAS removed from published local view orderbook. The remaining iceberg with zero exposed quantity in in-memory table led to unnecessary local view updates later when the order was inactivated. 

See the test IcebergIntegrationTest.icebergOnDifferentDeliveryAreaWithDifferentContractClosing which reproduces the scenario.","13/May/19 16:27;od044;Manual test passed on R2.0.13
StR:

1. Update delivery end of a particular contract that will be used for test to end 60m before delivery start time on ES delivery area in SOB
2. Update delivery end of a particular contract that will be used for test to end 5m before delivery start time on NL delivery area in SOB
3. Ensure that the tested contract on IC ES-FR has delivery end 60m before the delivery start time in CMM
4. Do a trade within ES delivery area
5. Do a trade within NL delivery area
6. Enter ICEBERG order on ES delivery area
7. Enter ICEBERG order on NL delivery area
8. Check a core log and looking up for string ""Mismatch""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Request limits are applied when disabled,XP-1574,81367,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,nn481,nn481,26/Apr/19 10:13,06/Nov/20 11:05,22/Feb/21 13:26,07/May/19 07:52,XBID 1.5.9,XBID 2.0,XBID 2.0,,Trading,,,,,,,,,"Env: ctpa
 user: SYT2EX01
 applicationId: m7-SYT2EX

xbid 1.5.9

We have disabled request limits for app id m7-SYT2EX, see screenshot attached.
 When sending a bunch of HubToHubReq we are receiving ErrResp about limit requests.

Example:
{code:java}
2019-04-25 15:04:01.083: REQUEST - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><HubToHubReq xmlns=""http://www.deutsche-boerse.com/m7/v1"" mktArea=""50Y-DUMMY-NO2--P"" dlvryDay=""2019-04-25T10:00:00.000Z""/>. MessageProperties
 [headers={timestamp_in_ms=1556204641075, server-timestamp=1556204641073}, timestamp=Thu Apr 25 15:04:01 UTC 2019, messageId=null, userId=null, receivedUserId=SYT2EX01, appId=m7-SYT2EX, clusterId=null, type=com.deutscheboerse.m7.trading.
api.v1.HubToHubReq, correlationId=[55, 56, 98, 53, 98, 54, 52, 50, 45, 99, 57, 52, 50, 45, 52, 100, 100, 49, 45, 56, 97, 54, 97, 45, 57, 52, 52, 100, 100, 54, 99, 101, 49, 55, 49, 99], correlationIdString=null, replyTo=amq.gen-y2fhdUd_v2
NoKd52MQUCPg, contentType=x-m7/request; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=NON_PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=comxerv.requestExchange.SY
T2EX01, receivedRoutingKey=cmm.request.inquiry, receivedDelay=null, deliveryTag=1485152, messageCount=0, consumerTag=amq.ctag-iQ6GTlmoJsqu_tsaJwuhGg, consumerQueue=xbid.monitoring.1]

2019-04-25 15:04:01.096: RESPONSE - Body: <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?><ErrResp xmlns=""http://www.deutsche-boerse.com/m7/v1""><StandardHeader marketId=""XSOB""/><Error err=""Limit is 500 per 3600000 ms.""/></ErrResp>. MessageProperties [headers={timestamp_in_ms=1556204641093}, timestamp=Thu Apr 25 15:04:01 UTC 2019, messageId=null, userId=null, receivedUserId=null, appId=null, clusterId=null, type=null, correlationId=[55, 56, 98, 53, 98, 54, 52, 50, 45, 99, 57, 52, 50, 45, 52, 100, 100, 49, 45, 56, 97, 54, 97, 45, 57, 52, 52, 100, 100, 54, 99, 101, 49, 55, 49, 99], correlationIdString=null, replyTo=null, contentType=x-m7/response; version=1, contentEncoding=gzip, contentLength=0, deliveryMode=null, receivedDeliveryMode=PERSISTENT, expiration=null, priority=0, redelivered=false, receivedExchange=, receivedRoutingKey=amq.gen-y2fhdUd_v2NoKd52MQUCPg, receivedDelay=null, deliveryTag=1485172, messageCount=0, consumerTag=amq.ctag-iQ6GTlmoJsqu_tsaJwuhGg, consumerQueue=xbid.monitoring.1]
{code}",,jy268,nn481,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/19 10:13;nn481;no_request_limit.png;https://jira.deutsche-boerse.com/secure/attachment/68444/no_request_limit.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56764800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,26/Apr/19 10:13,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujzs",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,CuTe A,,,CUTE A,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/May/19 11:22;jy268;Reviewed","07/May/19 07:10;qo794;Please review again as I had to merge changes made by the other team and amend the solution a bit, thanks.","07/May/19 07:53;jy268;Reviewed and merged",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Critical Business Processes - Func support for PMO,XP-1569,81267,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,radeale,radeale,radeale,25/Apr/19 10:12,06/Nov/20 10:14,22/Feb/21 13:26,10/May/19 12:10,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,"Give PMO support with the Enriched CBPs

Work directory:

S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\07 Operational Documents\Critical Business Processes for Production\CBP\2019\",,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,56505600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujzp",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 24,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,Production,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/19 16:04;radeale;Sent to Malina for review.","10/May/19 12:10;radeale;Done for the moment. Will probably return from the customers at some point.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TEST,XP-1551,81171,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jj069,jj069,jj069,23/Apr/19 14:19,06/Nov/20 10:14,22/Feb/21 13:26,23/Apr/19 14:23,,,Pre2020,,,,,,,,,,,,,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57974400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:25",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 24 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ana test,XP-1550,81165,Task,In Progress,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ub113,ub113,23/Apr/19 13:46,06/Nov/20 10:14,22/Feb/21 13:26,23/Apr/19 14:16,,,Pre2020,,,,,,,ice,,,,sdfwefeafgr,,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57974400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08lgo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TEST,XP-1549,81164,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jj069,jj069,jj069,23/Apr/19 13:43,06/Nov/20 10:14,22/Feb/21 13:26,24/Apr/19 09:06,,,Pre2020,,,,,,,,,,,,,jj069,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57974400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g2a:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 24,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMI Pull requests - Unit tests are failing,XP-1539,81079,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,jy268,qo794,qo794,18/Apr/19 09:36,06/Nov/20 10:59,22/Feb/21 13:26,29/Apr/19 14:15,,,Pre2020,,,,,,,,,,,"The following jenkins job is constantly failing
https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-pulls-unit-tests/

I a log level is increased from ERROR to INFO, it starts working properly. Investigation needed.

{code:java}
2019-04-18 08:14:43.721 [main] ERROR - o.h.e.j.s.SqlExceptionHelper:142 - Unique index or primary key violation: ""PRIMARY KEY ON PUBLIC.CMM_310_USER_ROLE(ID)""; SQL statement:
insert into PUBLIC.CMM_310_USER_ROLE (ROLE, RACF_ID, ID) values (?, ?, ?) [23505-187]
2019-04-18 08:14:44.558 [main] ERROR - o.s.t.c.TestContextManager:250 - Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@309d298] to prepare test instance [com.deutscheboerse.energy.cmminteg.AllocationEventIntegrationTest@5e5db72e]
java.lang.IllegalStateException: Failed to load ApplicationContext
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:125) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:108) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:118) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:83) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:246) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) [junit-4.12.jar:4.12]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363) [junit-4.12.jar:4.12]
	at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) [spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) [surefire-junit4-2.20.jar:2.20]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:272) [surefire-junit4-2.20.jar:2.20]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:236) [surefire-junit4-2.20.jar:2.20]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) [surefire-junit4-2.20.jar:2.20]
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:386) [surefire-booter-2.20.jar:2.20]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:323) [surefire-booter-2.20.jar:2.20]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:143) [surefire-booter-2.20.jar:2.20]
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'integrationTestDataInitializer': Invocation of init method failed; nested exception is javax.persistence.PersistenceException: org.hibernate.exception.ConstraintViolationException: could not execute statement
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:139) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:419) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1737) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:846) ~[spring-beans-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863) ~[spring-context-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) ~[spring-context-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:128) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.AbstractGenericContextLoader.loadContext(AbstractGenericContextLoader.java:60) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.delegateLoading(AbstractDelegatingSmartContextLoader.java:275) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.support.AbstractDelegatingSmartContextLoader.loadContext(AbstractDelegatingSmartContextLoader.java:243) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:117) ~[spring-test-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	... 26 common frames omitted
Caused by: javax.persistence.PersistenceException: org.hibernate.exception.ConstraintViolationException: could not execute statement
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:154) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:181) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:188) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1460) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1440) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.flushAndClear(GridCreatorServiceImpl.java:317) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.persist(GridCreatorServiceImpl.java:308) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.lambda$createTrader$1(GridCreatorServiceImpl.java:207) ~[cmm-grid-creator.jar:na]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_202]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[na:1.8.0_202]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_202]
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_202]
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_202]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.createTrader(GridCreatorServiceImpl.java:208) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$FastClassBySpringCGLIB$$da2d8640.invoke(<generated>) ~[cmm-grid-creator.jar:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$EnhancerBySpringCGLIB$$5dc0fdbe.createTrader(<generated>) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.createUsers(SimpleRunner.java:331) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.runAllGrid(SimpleRunner.java:221) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.runAllGrid(SimpleRunner.java:82) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner$$FastClassBySpringCGLIB$$23dd1e73.invoke(<generated>) ~[cmm-grid-creator.jar:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner$$EnhancerBySpringCGLIB$$f1cd42df.runAllGrid(<generated>) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmminteg.test.TestDataInitializer.doInitData(TestDataInitializer.java:21) ~[test-classes/:na]
	at com.deutscheboerse.energy.cmm.gridcreator.DataInitializer.initDataIfRequired(DataInitializer.java:15) ~[cmm-grid-creator.jar:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_202]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_202]
Caused by: org.hibernate.exception.ConstraintViolationException: could not execute statement
	at org.hibernate.exception.internal.SQLStateConversionDelegate.convert(SQLStateConversionDelegate.java:112) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:42) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:178) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3171) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3686) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:90) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:604) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1454) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1440) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.flushAndClear(GridCreatorServiceImpl.java:317) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.persist(GridCreatorServiceImpl.java:308) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.lambda$createTrader$1(GridCreatorServiceImpl.java:207) ~[cmm-grid-creator.jar:na]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_202]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[na:1.8.0_202]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_202]
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_202]
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_202]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.createTrader(GridCreatorServiceImpl.java:208) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$FastClassBySpringCGLIB$$da2d8640.invoke(<generated>) ~[cmm-grid-creator.jar:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$EnhancerBySpringCGLIB$$5dc0fdbe.createTrader(<generated>) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.createUsers(SimpleRunner.java:331) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.runAllGrid(SimpleRunner.java:221) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner.runAllGrid(SimpleRunner.java:82) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.SimpleRunner$$FastClassBySpringCGLIB$$23dd1e73.invoke(<generated>) ~[cmm-grid-creator.jar:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
Caused by: org.h2.jdbc.JdbcSQLException: Unique index or primary key violation: ""PRIMARY KEY ON PUBLIC.CMM_310_USER_ROLE(ID)""; SQL statement:
insert into PUBLIC.CMM_310_USER_ROLE (ROLE, RACF_ID, ID) values (?, ?, ?) [23505-187]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.message.DbException.get(DbException.java:179) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.message.DbException.get(DbException.java:155) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.mvstore.db.MVPrimaryIndex.add(MVPrimaryIndex.java:139) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.mvstore.db.MVTable.addRow(MVTable.java:638) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.command.dml.Insert.insertRows(Insert.java:156) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.command.dml.Insert.update(Insert.java:114) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.command.CommandContainer.update(CommandContainer.java:78) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.command.Command.executeUpdate(Command.java:254) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:157) ~[h2-1.4.187.jar:1.4.187]
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdate(JdbcPreparedStatement.java:143) ~[h2-1.4.187.jar:1.4.187]
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.executeUpdate(ResultSetReturnImpl.java:175) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3171) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3686) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:90) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:604) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1454) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1440) ~[hibernate-core-5.3.6.Final.jar:5.3.6.Final]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.flushAndClear(GridCreatorServiceImpl.java:317) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.persist(GridCreatorServiceImpl.java:308) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.lambda$createTrader$1(GridCreatorServiceImpl.java:207) ~[cmm-grid-creator.jar:na]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[na:1.8.0_202]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[na:1.8.0_202]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_202]
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[na:1.8.0_202]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_202]
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[na:1.8.0_202]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl.createTrader(GridCreatorServiceImpl.java:208) ~[cmm-grid-creator.jar:na]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$FastClassBySpringCGLIB$$da2d8640.invoke(<generated>) ~[cmm-grid-creator.jar:na]
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) ~[spring-tx-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) ~[spring-aop-5.1.2.RELEASE.jar:5.1.2.RELEASE]
	at com.deutscheboerse.energy.cmm.gridcreator.GridCreatorServiceImpl$$EnhancerBySpringCGLIB$$5dc0fdbe.createTrader(<generated>) ~[cmm-grid-creator.jar:na]
{code}",,jy268,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57888000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g28:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 24,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Apr/19 17:07;jy268;Info for git bisect: this hash works fine on Jenkins: 37376f68cf8c1d917f8cfcbdc1d0c6d274302283","19/Apr/19 17:44;jy268;Info for git bisect: this hash works fine on Jenkins as well: d36e438534a5a51e5085115c543691e1c6d53719","23/Apr/19 11:02;jy268;Info for git bisect: this has works fine on Jenkins as well:
723114bfb51aed111b5ca21a3a339569a5bc3a81","23/Apr/19 12:24;jy268;Info for git bisect: this hash failed on Jenkins:
fbbd0d48c3d6bea75cb952286f2c4ce8eae5ee62","24/Apr/19 11:27;jy268;Bisect results:
commit 3c980dff6079 was OK
commit aa2b15a3056 broke the build",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check Scientist in UATs,XP-1538,81067,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ei349,ei349,17/Apr/19 15:20,06/Nov/20 10:14,22/Feb/21 13:26,14/May/19 15:18,,,Pre2020,,,,,,,,,,,Check in Kibana and if there are no findings check directly on the environment. ,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1579,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58406400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g29:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 24,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze how to work with Kibana properly,XP-1533,81017,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eh941,eh941,16/Apr/19 16:09,06/Nov/20 10:14,22/Feb/21 13:26,29/Apr/19 14:47,,,Pre2020,,,,,,,,,,,"Kibana has been an industrial standard in log management. Yet we don't like it and can't use it.

Find out why is that and if it has set up the data fields correctly.

Propose the new configuration to techops guys on devops.

Optionally create a short session in which you show how the Kibana should be used for certain queries.",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57369600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:2s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 24 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/19 14:47;eh941;Created project https://github.deutsche-boerse.de/odehfra/kibana-data-loader

See the readme.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix rabbitmq failover tests,XP-1529,80996,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,16/Apr/19 10:30,06/Nov/20 11:34,22/Feb/21 13:26,18/Apr/19 09:49,,,Pre2020,,,,,,,,,,,,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58579200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08ipz:zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-2979-postgresql,XP-456,XP-3264,develop,XP-3230,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New orderbook calculator - implement cross-orderbook detection,XP-1520,80903,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,12/Apr/19 16:39,06/Nov/20 09:03,22/Feb/21 13:26,17/Apr/19 11:45,,,Pre2020,,,,,,,,,,,CrossedObkValidator is not invoked in the new orderbook implementation.,,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58838400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08jy0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
additional updates to Security Concept Document,XP-1513,80846,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,11/Apr/19 13:47,06/Nov/20 12:47,22/Feb/21 13:26,18/Apr/19 09:48,,,Pre2020,,,,,,,,,,,"*AC*

*review and udate following chapters*
 * A12.1.4: Development, Test and Production separated:

-TechOps + link (Attachment 5E - AIP110 - Technical Architecture Topology Diagram - Hosting v.4.0)
 * A14.1.3 Protecting application services transactions - check with PO and TechOps
 * A.14.2.1 Secure development policy – sdd Scrum guideline - [https://teams.deutsche-boerse.de/sites/sp0160/Shared%20Documents/Forms/AllItems.aspx?RootFolder=%2fsites%2fsp0160%2fShared%20Documents%2fSCRUM%20Guides&FolderCTID=0x012000BFAD097848060048BA05B122C15CD528] –
 * A.14.2.8 System security testing- add info about Sonar HP Fortify, check within Dev team

*coordinate with ESO, check updates with Pavel P*",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/19 09:41;tz118;Security Concept - Template 0.18-1_XBID_with_CMS_V09.docx;https://jira.deutsche-boerse.com/secure/attachment/68164/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V09.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58406400,,,,,,,,,,,,,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08ipw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/19 09:48;tz118;communicated to ESO and uploaded on the SP",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CR088 Comtrader Security - Switch download server to HTTPS,XP-1510,80834,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,tm431,ei349,11/Apr/19 12:40,13/Aug/20 19:51,22/Feb/21 13:26,22/May/19 12:47,,,Pre2020,,ComTrader,,,,,,,,,"*{color:#00875a}[ Security improvements of Comtrader across all internal and customer facing environments ]{color}*

See text of required change in PDF

*Prior 22nd May:*
 # prepare HTTPS version of latest Comtrader including CR088 for the further deployment to LipA, LipB, CuteC, Cute F-K (deployment itself will be done on 22nd May)
 # prepare switch of other comtraders on m7trading-test and m7trading-internaltests to https configuration 
 ## unpack 
 ## change config to https
 ## regenerate fingerprint and prepare the package for deployment on 22nd. 

*On 22nd May 2019 following is needed:* 
 # Support switch of download server m7trading-test to it's https version. Alignment and cooperation with [~fh971] and [~yo218] is needed as m7 switches the shared server together with XBID. This will be short window which needs to be agreed between all affected parties. After this is done: 
 ## Deploy new Comtrader to LipA, LipB, CuteC, Cute F-K (Cute L is under discussion and will be clarified soon)
 ## Upload https version of old comtraders to other 
 ## Verify that comtraders can be started from new https links (especially 1.5.9 envs!)

*AC:* 
 # m7trading-test and m7trading-internaltests on https 
 # LipA, LipB, CuteC, Cute F-K have new version of Comtraders including CR088 and can be started 
 # Other environments with old comtraders have their running https version. 

 ",,ei349,ll664,yo218,,,,,,,,,,,,,,,,,,,,,,,,XP-1314,,,,,,,,,SERVICE-5409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,55468800,,,,,,,,,,,,,,,XP-1661,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1td",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/19 14:42;ei349;chase techops","14/May/19 09:47;ll664;[~ei349], [~yo218], please note the rollout of the HTTPS in cute (and the others envs as well) needs to be executed at the same time with the deployment of the new Comtrader version. The reason is that once we switch to HTTPS, the old Comtrader webstarts will stop working as they contain links to old plain-http domain.","14/May/19 10:35;yo218;[~ll664] http requests will be redirected automatically to https
It has been implemented for m7trading-internaltest (fe https://m7trading-internaltest.deutsche-boerse.com/comtrader-6.7-epex-systemtest2/) yesterday, please verify. Can you please align with M7t team as it affects them, too?","14/May/19 11:17;yo218;The redirect is at least working for browser requests. But if CT behaves different then it might be required to change it. Waiting for further instructions from your side","14/May/19 13:32;ll664;[~yo218], Comtrader Webstart does not work, i.e. that's when you click on https://m7trading-internaltest.deutsche-boerse.com/comtrader-2.5.x/webstart/ComTrader-systemtest1-xsob-int.jnlp let's say.

My comment, still holds, https needs to be rolled out at the same time as the deployement of the new Comtrader.","14/May/19 13:41;yo218;fine, let's continue with testing the changes on  https://m7trading-internaltest.deutsche-boerse.com for one or two days and then we have to align on the tasks for  https://m7trading-test.deutsche-boerse.com","14/May/19 14:42;ll664;[~yo218], we,ve just realized that {{m7trading-test.deutsche-boerse.com}} is shared machine with M7. Swithching the whole server to HTTPS would break M7 envs, which is something we would like to avoid. 

The suggested workaround is to apply selective redirects from http to https only for following urls:
{code}
https://m7trading-test.deutsche-boerse.com/xbid-cute/
https://m7trading-test.deutsche-boerse.com/xbid-ctpa/
https://m7trading-test.deutsche-boerse.com/xbid-ctpb/
https://m7trading-test.deutsche-boerse.com/xbid-ctpc/
https://m7trading-test.deutsche-boerse.com/xbid-ctpd/
https://m7trading-test.deutsche-boerse.com/xbid-ctpe/
https://m7trading-test.deutsche-boerse.com/xbid-ctpf/
https://m7trading-test.deutsche-boerse.com/xbid-ctpg/
https://m7trading-test.deutsche-boerse.com/xbid-ctph/
https://m7trading-test.deutsche-boerse.com/xbid-ctpi/
https://m7trading-test.deutsche-boerse.com/xbid-ctpj/
https://m7trading-test.deutsche-boerse.com/xbid-ctpk/
https://m7trading-test.deutsche-boerse.com/xbid-ctpl/
https://m7trading-test.deutsche-boerse.com/xbid-ctso/
https://m7trading-test.deutsche-boerse.com/xbid-lipa/
https://m7trading-test.deutsche-boerse.com/xbid-lipb/
https://m7trading-test.deutsche-boerse.com/xbid-simu/
{code}

This way all M7 envs stay on HTTP and all XBID envs would be on HTTPS. 

[~fh971], [~ei349] FYI
","14/May/19 15:53;yo218;what about the already performed changes for https://m7trading-internaltest.deutsche-boerse.com, should we revert it or is it fine for M7?","22/May/19 12:37;ll664;Comtrader deployed to CUTEs today, all an HTTPs. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CR088 Comtrader Security - Generate release notes,XP-1509,80833,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tm431,ei349,11/Apr/19 12:40,06/Nov/20 10:14,22/Feb/21 13:26,02/May/19 13:54,,,Pre2020,,,,,,,,,,,See text of required change in PDF,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59011200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1v",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 24 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test groupping field in view SPM,XP-1503,80802,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,tm431,tm431,11/Apr/19 09:06,06/Nov/20 11:17,22/Feb/21 13:26,15/Apr/19 12:55,,,Pre2020,,,,,,,,,,,test XP-1443,,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/19 12:54;tm431;TSO files HNT grouping OK.png;https://jira.deutsche-boerse.com/secure/attachment/68069/TSO+files+HNT+grouping+OK.png","15/Apr/19 12:54;tm431;grouping CCP files OK.png;https://jira.deutsche-boerse.com/secure/attachment/68070/grouping+CCP+files+OK.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58665600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g22:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/19 12:54;tm431;Grouping in View of FTC is displayed correctly. See attached screenshots",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
delete IC after 7days - Test,XP-1502,80801,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,qo794,qo794,11/Apr/19 08:51,06/Nov/20 12:29,22/Feb/21 13:26,30/May/19 10:06,,,Pre2020,,,,,,,,,,,Test XP-1442,,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59011200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g24:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],Home Office team 24,Home Office Team 25 [S],Home Office Team 26,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Test switch to Azul 8,XP-1500,80770,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,uv683,ei349,ei349,10/Apr/19 13:39,04/Aug/20 19:36,22/Feb/21 13:26,12/Apr/19 16:11,,,Pre2020,,,,,,,,,,,,,ei349,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58838400,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Apr/19 16:11;uv683;no need for changes here, all our component's images which use customtomcat are build from xbid project and no other changes for java version are needed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify SIMU is configured according to USM998,XP-1499,80769,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,radeale,radeale,10/Apr/19 13:38,06/Nov/20 10:14,22/Feb/21 13:26,24/Apr/19 13:00,,,Pre2020,,Capacity,Shipping,Trading,,,UAT2.0,waiting-techops,,,Please verify that the SIMU env is configured the same way as PROD regarding the USM998 parameters (attached).,,ei349,od044,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1617,,,,,,,"10/Apr/19 13:38;radeale;USM998_System_Configuration_v46.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67906/USM998_System_Configuration_v46.xlsx","24/Apr/19 13:00;od044;USM998_System_Configuration_v46_internal.xlsx;https://jira.deutsche-boerse.com/secure/attachment/68302/USM998_System_Configuration_v46_internal.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57888000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g26:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],Home Office team 24,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Apr/19 14:27;ei349;please open external ticket for that ","24/Apr/19 13:00;od044;Done 
 [^USM998_System_Configuration_v46_internal.xlsx] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Docker switch to Azul 8,XP-1496,80764,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eh941,ei349,ei349,10/Apr/19 13:28,04/Aug/20 19:36,22/Feb/21 13:26,12/Apr/19 15:41,,,Pre2020,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59097600,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:19",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reporting Switch to Azul 8,XP-1495,80762,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ll664,ei349,ei349,10/Apr/19 13:27,04/Aug/20 19:35,22/Feb/21 13:26,24/Apr/19 10:22,,,Pre2020,,,,,,,,,,,"* Reporting Engine 
 * Report Tool ",,ei349,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57888000,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:24",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 24 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Apr/19 10:20;ll664;Done. Both RE and Report Tool works fine with Azul.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Comtrader switch to Azul 8,XP-1494,80757,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,ei349,ei349,10/Apr/19 12:34,04/Aug/20 19:36,22/Feb/21 13:26,16/Apr/19 09:44,,,Pre2020,,,,,,,,,,,,,ei349,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58838400,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08k06:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],,,,,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,comtrader-2.5.x,XP-69,XP-2583,XP-2554,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Apr/19 14:54;qo794;Tested with the following dependecies:
* ZuluFx
* IcedTea-Web

(/) local build
(/) local maven tests
(/) local run and login
(/) javaws.jar from IcedTea-Web added to the source code
(/) jenkins - created new jobs for xbid pull requests using zulu fx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID connected services switch to Azul 8,XP-1493,80756,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,,ei349,ei349,10/Apr/19 12:33,31/Aug/20 15:38,22/Feb/21 13:26,15/May/19 14:35,,,Pre2020,,,,,,,,,,,"This is the placeholder/todo list for findings from the JDK migration implementation tasks. 

Ideas: 

- Migration of servers",,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,nothing to be done,,,,,,,,,,,,,,55382400,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00ic",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2942,tomcat-rollback,traversal-XP-2485,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/May/19 12:48;ek176;Unmigrated dev hosts: 
{noformat}
xbdst1app1
xbidperfcor1
xbinterep1
xbinterep2
xbintessl1
xbintessl2
xbperfcmi1
xbperfcmm1
xbperfrep1
xbperfsla1
xbperfsmc1
xbperfsmi1
xbperfsob1{noformat}","23/May/19 12:48;ek176;Unmigrated hosts (non-prod). Simu is missing, as it is not reachable from RDEV nework.
{noformat}
xbctpaamq1
xbctpacor1
xbctpadow1
xbctpaenq1
xbctpbamq1
xbctpbcor1
xbctpbdow1
xbctpbenq1
xbctpcamq1
xbctpdamq1
xbctpdcor1
xbctpddow1
xbctpdenq1
xbctpeamq1
xbctpecor1
xbctpedow1
xbctpeenq1
xbctpfamq1
xbctpgamq1
xbctphamq1
xbctpiamq1
xbctpjamq1
xbctsoamq1
xbctsocor1
xbctsodow1
xbctsoenq1
xbcuteamq1
xbcutecor1
xbcutedow1
xbcuteenq1
xbcutsctp1
xbcutspmi1
xbcutsrep1
xbcutsrpt1
xbcutsssl1
xbcutsweb1{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jenkins Switch to Azul 8,XP-1492,80755,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ll664,ei349,ei349,10/Apr/19 12:31,04/Aug/20 19:36,22/Feb/21 13:26,16/Apr/19 10:25,,,Pre2020,,,,,,,,,,,,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59097600,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08ipz:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,versions,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Switch to Azul 8,XP-1491,80754,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ll664,ei349,ei349,10/Apr/19 12:30,04/Aug/20 19:36,22/Feb/21 13:26,12/Apr/19 16:09,,,Pre2020,,,,,,,,,,,"* CMM/CMI
 * Trading 
 * Core",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-2955,TECHLOG-2237,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59097600,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 23,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PMI Logger & PMI Archiver switch to Azul 8,XP-1490,80753,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,ei349,ei349,10/Apr/19 12:30,04/Aug/20 19:36,22/Feb/21 13:26,12/Apr/19 08:15,,,Pre2020,,,,,,,,,,,,,ei349,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58924800,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujx",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Apr/19 08:15;qo794;(/) local build
(/) local maven test
(/) local run",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shipping switch to Azul 8,XP-1489,80743,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,jy268,ei349,ei349,10/Apr/19 11:07,04/Aug/20 19:35,22/Feb/21 13:26,12/Apr/19 14:43,,,Pre2020,,,,,,,,,,,,,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58838400,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujwi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 23 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Apr/19 14:43;jy268;SMC / SMI work fine with Zulu 8. Tested locally both in intellij and on Tomcat 8.5.x",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Border configuration OCC files - test various approaches,XP-1479,80649,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,radeale,radeale,08/Apr/19 15:55,06/Nov/20 11:34,22/Feb/21 13:26,11/Apr/19 13:15,,,Pre2020,,,,,,,,,,,"20190405 MSD:
We still prefer/ask to include market area EIC codes when the file is configured at border level. As an alternative solution we would be able to accept inclusion of the data only for the leading IC.
As mentioned before the data should be included only once per direction.",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59011200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08h6c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 22,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Apr/19 09:16;qo794;I think it's doable, we can just include data for all interconnectors for the border and replace DAs by MAs. I've tested the scenario when allocating on a non-leading IC and then on a leading - ATC was changed correctly reflecting all allocations on both ICs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace RID mRID constant by border template,XP-1476,80639,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qo794,qo794,08/Apr/19 13:25,06/Nov/20 11:34,22/Feb/21 13:26,02/May/19 09:26,,,Pre2020,,Capacity,,,,,,,,,"Remove recently introduced {{com.deutscheboerse.energy.cmminteg.filetype.cim.RightsMarketDocumentXmlTimeSeriesFactory#MRID_CONSTANT}} and replace it with the {{BorderConfigKey.ECAN_CONTRACT_ID_TMPL}} template defined on a border level.

Only a change in the code, specification update is not needed as the behavior stays the same.",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57196800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1t",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/May/19 09:25;qo794;Will be treated within XP-766, closing this one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMC: Improve sending through SFTP,XP-1472,80620,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,jy268,jy268,08/Apr/19 08:54,11/Jun/19 16:10,22/Feb/21 13:26,11/Jun/19 16:10,,,XBID 2.0,,Shipping,,,,,,,,,"{color:#00875a}*[ Data restoration memory leak prevention ]*{color}
 Currently when huge bundle of files is sent through SFTP those files are sent one by one. It means that connections to SFTP is opened, file is transferred, connection is closed. We have discovered that it can be problematic when we are restarting SM with huge gap in synchronization points (SFTP queues are full). 
 The idea how to improve it is to use batching. Connection should be opened, batch of files should be sent and connection should be closed. We can achieve that with a new disruptor which will be handling SFTP sending, it supports batching and can be easily integrated with current application architecture.",,jy268,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59270400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08txr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare XBID presentation,XP-1463,80517,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zi174,radeale,radeale,04/Apr/19 17:28,06/Nov/20 11:19,22/Feb/21 13:26,11/Apr/19 11:40,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,Please prepare XBID presentation for the Frankfurt event and sent it to Alex W. for review.,,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59529600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08hoo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 22,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check if specifications updates based on the Technical Proposal (ASR003),XP-1462,80513,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,04/Apr/19 16:26,06/Nov/20 11:19,22/Feb/21 13:26,16/May/19 09:58,,,Pre2020,,,,,,,,,,,"With regards to ASR003 and Technical Proposal (official document can be found in the linked Jira) following documents may have been impacted:
 • DFS290 Cross Border Routing
 • HLS100 Functional Description Trading Module
 • DFS510 AMQP Public Message Interface – Trading - 
 • AIP110 Technical Architecture Topology Diagram 
 • AIP120 Failover Concept -",,ei349,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,55987200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08n33:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/19 15:09;ei349;Can you please put your estimates here [~tz118]? ","16/May/19 09:58;tz118;specifications contain description updated based on the ASR003",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH - Analyze and design PoC pipelines communicate,XP-1459,80473,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,04/Apr/19 10:00,04/Aug/20 19:36,22/Feb/21 13:26,19/Sep/19 10:48,,,Pre2020,,,,,,,,,,,"Our task is to be as close to streaming mode as possible. Find out and design a way to:
* If needed, refactor T task (Beam)
* Connect both E and T tasks (data passing)
* Trigger the E task (Flink) and subsequently the T task
 ",,,,,,,,,,,,,,,,,,,,,,XP-812,,,,,,,,XP-2125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59616000,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 34 [S],,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,poc_finalized_with_scratches,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID-Core slave takes too long to stop when DB is unavailable,XP-1448,80403,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,02/Apr/19 16:51,06/Nov/20 11:34,22/Feb/21 13:26,04/Apr/19 15:15,,,Pre2020,,,,,,,,,,,"XBID-Core slave does not react properly to SIGTERM and keeps retrying attempt to find a master DB node, which could take up to 5 minutes.

The node should give up retrying and exit gracefully.

Discovered within the failover tests.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59702400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 22 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
LIPA: SOB unreachable due to Unexpected error,XP-1442,80359,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Fixed,qo794,tm431,tm431,02/Apr/19 10:34,06/Nov/20 11:18,22/Feb/21 13:26,11/Apr/19 09:23,XBID 2.0,,Pre2020,,,,,,,Latent_Faults,UAT2.0,,,"Currently we are unable to access the SOB WebGui.

When the user tries to login the message ""An unexpected error occured, please retry"".",,ei349,qo794,tm431,ub113,,,,,,,,,,,,,,,,,XP-1502,,,XBID-4385,,,,,,,,,,,,XBID-4398,,,,,,,"02/Apr/19 11:14;qo794;core.log;https://jira.deutsche-boerse.com/secure/attachment/67530/core.log",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59011200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08idz:yc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 22,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Apr/19 11:13;qo794;h1. Investigation
h3. Logs
The following request caused core down:
{code:java}
2019-04-02T07:09:49.160Z [Unmarshaller][][474a6278] TRACE c.d.e.m.t.M.incomingMessage - [simple type, class com.deutscheboerse.energy.m7.cmm.api.refdata.RefDataUpdateRequest] - {""userId"":""JAO00002"",""req"":{""deleteIntrConnectorList"":{""deleteIntrConnector"":[{""dlvryAreaId1"":""10YDE-VE-------2"",""dlvryAreaId2"":""19YPL0000AAAA01H"",""revisionNo"":4}]}}}
{code}
The detailed log from core  [^core.log] 
h3. Database
cmm_230_inter_connector
{code}
69;4;;""10YDE-VE-------2"";""19YPL0000AAAA01H"";48;69
{code}

select * from cmm_235_interconnector_configuration where interconnector_id = 69 order by id;
{code}
127;""ACTIVE"";""2018-10-24 22:00:00"";""2018-11-17 23:00:00""
138;""ACTIVE"";""2018-11-17 23:00:00"";""2019-03-22 23:00:00""
166;""ACTIVE"";""2019-03-22 23:00:00"";""2019-03-25 23:00:00""
167;""SUSPENDED"";""2019-03-25 23:00:00"";""""
{code}
select * from cmm_130_contract where connector_id = 69;
{code}
863254;0;""2019-03-25 23:00:00"";;""INACTIVE"";""2019-03-25 23:00:00"";863253;""2019-03-25 22:00:00"";""ACTIVE"";175;69;""N""
{code}
h1. Root cause
An IC can be deleted after at least 7 days of being suspended, this way it's ensured that all related data has already been deleted from DB. Unfortunately a delivery interval deletion (together with other related entities) condition compares the delivery interval end, hence always the last delivery interval of D-7 stays in the DB, therefore the IC deletion fails.","03/Apr/19 15:12;qo794;merge request with the fix ready (not reviewed though): https://github.deutsche-boerse.de/dev/xbid/pull/340","03/Apr/19 15:14;qo794;The fix has not been required by the customer so far.","08/Apr/19 11:36;ub113;Hi, can we close this ticket, since the external one is in the status closed?","08/Apr/19 12:26;qo794;It's a bug causing core down and has not been fixed yet, the question is in what version we are going to deliver the fix.","08/Apr/19 12:27;tm431;Ana you are right, that external is closed. but this also ticket where we track the latent fault, and the fix is here ready to be merged into master branch... we are still awaiting customer to give us green light for this. I will link appropriate external ticket

we can put this into state waiting customer...","11/Apr/19 08:52;qo794;Will be tested within XP-1502, this is just an implementation task","11/Apr/19 09:23;qo794;Fix merged",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"XP-74 improvement, first generation time as parameter",XP-1435,80295,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,jy268,jy268,jy268,01/Apr/19 09:15,06/Nov/20 11:34,22/Feb/21 13:26,04/Apr/19 11:29,,,Pre2020,,Shipping,,,,,,,,,New requirement to XP-74. Currently when SPM is restarted after a longer time when it was offline it starts files generation from TODAY-1 at 00:00. This time should be provided as parameter as well.,,jy268,od044,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,change reverted. Please take a look at comments.,,,,,,,,,,,,,,59616000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08gco:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Apr/19 09:16;tm431;with default value set to 5min after startup","01/Apr/19 09:18;jy268;I suggest number of sync packages, means parameter set to 1 means 5 minutes (N*5min)","02/Apr/19 14:29;jy268;new parameter added
{code}spm.packages.old.skip.start{code}
number of missing sync packages which should be generated","04/Apr/19 10:31;od044;The feature works, but I am not sure whether this solution is proper. There will miss a lot of sync package that can have an impact on generated file content. 
Per discussion assign back for more analysis","04/Apr/19 11:09;jy268;Feature reverted, stays as it was previously.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare toggle for OBK implementations,XP-1428,80249,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,ei349,ei349,28/Mar/19 15:03,06/Nov/20 11:21,22/Feb/21 13:26,16/Apr/19 10:15,,,Pre2020,,,,,,,,,,,"*{color:#00875a}[ Safety go-back scenario, prevention of X days development ]{color}*

As there are two implementations of OBK calculations we would like to have some possibility to switch between those implementations. It can prevent long downtimes in the production after 2.0 go live. 

 

Part of this task is to verify the switch works also with already migrated downstream services. (more in: XP-1295).",,eg288,ei349,lt112,od044,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1520,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,58579200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:zw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 22,Home Office team 23 [S],,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Mar/19 10:25;lt112;Suggestions:
- use {{OrderBookStrategy}}
- create {{OrderbookInfoProvider}} and select implementation (old, new) based on configuration, use in services outside OBK calculation
- create a delegate service for OrderbookInfo services (old, new) and delegate updates to them based on configuration
- create a delegate service for routing services (old, new) and delegate updates to them based on configuration
- replace update calls with those delegates in services outside OBK calculation","08/Apr/19 10:19;tm431;test after implementation","08/Apr/19 19:35;eg288;* implemented OrderBookStrategy.OLD_ONLY
* OrderBookRoutingService.assertGridsAreEqualAfterChange() had been removed after discussion with [~lt112], it was not functional anymore
* CrossedObkValidator not implemented in the ne implementation","10/Apr/19 16:40;eg288;It has been implemented in xbid branch XP-1428-obk_calc_toggle_old-only, it has been already merged into develop branch. Please test.

To test set property orderbook.strategy=old-only","16/Apr/19 10:15;od044;Test passed on XBID_VERSION=2.0.3, SPM_VERSION=2.0.4
- XBID runs properly with all 3 strategies configurations old-only, new-only, comparison
- smoke test of order-book delta report passed
- both configurations old-only, new-only return the same calculation results  
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generate reports: 2019-03,XP-1426,80233,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ek176,ek176,28/Mar/19 14:18,06/Nov/20 10:25,22/Feb/21 13:26,04/Apr/19 09:44,,,Pre2020,,,,,,,,,,,,,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60134400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08g08:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,report-tool-2.2.x,master-report-tool-2.2.x,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Document identifier mRID for SXS for All Interconnectors is formed from a wrong string,XP-1410,80180,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,radeale,tr866,tr866,27/Mar/19 14:35,06/Nov/20 12:31,22/Feb/21 13:26,02/Apr/19 16:27,,,Pre2020,,Shipping,,,,,,,,,"h4. Description:
mRID for SXS files for all interconnectors is formed from a string containing {color:#DE350B}*ALL-DAs*{color} instead of {color:#00875A}*ALL-ICs*{color}

h4. Steps to reproduce:
# Log in as SA Admin
# Create a FTC for *File Type: SXS*, receiver: SA, *Grouping: All interconnectors*
# Log in as SA Operations and download the generated SXS file
# Check the Document Identifier ID stored in <mRID> element

h4. Expected behaviour:
As specified in DFS310 - Shipping Module File Management; 5.2.2 Document identifier:
{quote}SA/CCP files: indicator “ALL_DAs” substituting the border/IC/DA identifier if the file is for all DAs where a SA/CCP is assigned or indicator “ALL_ICs” substituting the IC identifier if the file is for all ICs where a SA is assigned{quote}
Where ALL-DAs and ALL-ICs with hyphen is currently used in Shipping Module for mRIDs for all files even for HNS and HNT files, not underscore. Btw HNS files are not mentioned in specs in the paragraph about extended configuration options at all, only HNT and CTS files are listed. Separate JIRA will be entered for specs clarification.
*mRID should be then MD5 formed from a string like*:
{noformat}SXS_ALL-ICs_[EIC of receiver]_[delivery date in YYYYMMDD]{noformat}
Examples with original string and corresponding MD5 hash:
||Document Identifier String||MD5 mRID||
|SXS_*{color:#00875A}ALL-ICs{color}*_18XOMIE-123456-T_20190326|1fddc45cc02e6b7058c336a34d252aa4|
|SXS_{color:#00875A}*ALL-ICs*{color}_11XEEX--MIA----J_20190326|5189ee537b035c1201c79b2bec89dc0c|
h4. Current behaviour:
*mRID for SXS files for all interconnectors is MD5 formed from a string like*:
{noformat}SXS_ALL-DAs_[EIC of receiver]_[delivery date in YYYYMMDD]{noformat}
Examples with original string and corresponding MD5 hash:
||Document Identifier String||MD5 mRID||
|SXS_*{color:#DE350B}ALL-DAs{color}*_18XOMIE-123456-T_20190326|005b6f9a6c8d5e510b1cc6b519e70c2b|
|SXS_{color:#DE350B}*ALL-DAs*{color}_11XEEX--MIA----J_20190326|613433e3b3ddb6bde9a7ef31373003c4|",,radeale,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/19 15:10;tr866;20190326_SXS_335001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_101_2.xml.gz;https://jira.deutsche-boerse.com/secure/attachment/67359/20190326_SXS_335001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_101_2.xml.gz","27/Mar/19 15:10;tr866;20190326_SXS_336001_11XID-CAPACITY-9_SAECC_ALL_ICs_101_2.xml.gz;https://jira.deutsche-boerse.com/secure/attachment/67360/20190326_SXS_336001_11XID-CAPACITY-9_SAECC_ALL_ICs_101_2.xml.gz","02/Apr/19 15:48;radeale;20190402_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml;https://jira.deutsche-boerse.com/secure/attachment/67551/20190402_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml","02/Apr/19 15:48;radeale;20190403_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml;https://jira.deutsche-boerse.com/secure/attachment/67552/20190403_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59702400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,27/Mar/19 14:35,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Apr/19 15:47;radeale;Tested together with Duc - test OK on SYST2, SM 2.0.1.

SAOMIE:
18XOMIE-123456-T

SXS

20190403_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml
<mRID>36a4d5cfbab2ce81b9cbf89abab6c15c</mRID>
Your Hash: 36a4d5cfbab2ce81b9cbf89abab6c15c
Your String: SXS_ALL-ICs_18XOMIE-123456-T_20190403

20190402_SXS_320001_11XID-CAPACITY-9_SAOMIE_ALL_ICs_100_2.xml
<mRID>759b62df9d06049d568b275762b370aa</mRID>
Your Hash: 759b62df9d06049d568b275762b370aa
Your String: SXS_ALL-ICs_18XOMIE-123456-T_20190402

SHC

20190403_SHC_323001_11XID-CAPACITY-9_CCPOMIE_ALL_DAs_103_2.xml
<mRID>89bb69e4c073ff1ba2c66b19a4573904</mRID>
Your Hash: 89bb69e4c073ff1ba2c66b19a4573904
Your String: SHC_ALL-DAs_18XOMIE-123456-T_20190403",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare release 2.0 dataset for the performance testing,XP-1409,80179,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ei349,ei349,27/Mar/19 14:19,06/Nov/20 12:38,22/Feb/21 13:26,07/May/19 15:10,XBID 2.0,,XBID 2.0,,,,,,,,,,,"* Transform the excel from XP-1351 into the dataset 
 * verify it on testing environment
 * track changes of the provided excel sheet and consider communication with customer

Testing: 
* Please test createContractNameFormat(entityHelper.getProduct(""Quarterly_Hour_Power""), entityHelper.buildContractNameFormat(""yyyyMMdd HH:mm"", ""-"", ""yyyyMMdd HH:mm""), entityHelper.buildQuarterlyContractShortNameFormat());
 ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1351,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60220800,,,,,,,,,,,,,,,XP-4094,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 22 [S],Alpha Team Sprint 23,Alpha Team Sprint 24 [S],Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate Wikidbs pages to confluence or git,XP-1408,80177,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,eg288,eg288,27/Mar/19 13:58,06/Nov/20 11:34,22/Feb/21 13:26,01/Apr/19 17:32,,,Pre2020,,,,,,,,,,,"Wikidbs will be closed soon. Please backup your data. Contact Marek Hudik for further details.

The pages in use must be migrated:
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/Xbid_new  (/)
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/CT_links (/)
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/Ubuntu_for_Energy_team (/)
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/New_PC_Installation_for_Energy_team (/)
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/Network_drives_on_Linux (/)

*Feel free to add more pages*",,eg288,hj444,od044,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59875200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Mar/19 13:31;od044;http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/New_PC_Installation_for_Energy_team -> https://confluence.energy.svc.dbgcloud.io/display/XBID/New+PC+Installation+for+Energy+team

http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/Network_drives_on_Linux -> https://confluence.energy.svc.dbgcloud.io/display/XBID/Network+drives+on+Linux","29/Mar/19 13:40;tr866;ComTrade links page in cofluence below
https://confluence.energy.svc.dbgcloud.io/display/XBID/ComTrader+Links

Ubuntu for including subpages can be found below
http://wikidbs.deutsche-boerse.de/dbsswiki/index.php/Ubuntu_for_Energy_team","01/Apr/19 10:27;hj444;Xbid_new wiki page transfered into Confluence 
https://confluence.energy.svc.dbgcloud.io/display/XBID/XBID",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA report update based on the new growth estimation - January 2019,XP-1406,80173,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,27/Mar/19 13:23,06/Nov/20 10:25,22/Feb/21 13:26,04/Apr/19 09:46,,,Pre2020,,,,,,,Reporting,,,,"Martin Vancura on 26.3.: 
let me provide you with the monthly update (January 2019) of growth estimations:
 
•	growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):
o	Number of Block Orders (daily), as a subset of the orders = 15%
o	Number of Explicit Requests (daily) = 0%
o	Number of Explicit Allocations (daily) = 0%
o	Number of Hubs = this is known to DBAG (2nd wave data set)
o	Number of Borders = this is known to DBAG (2nd wave data set)
o	Sustainable Load Items = 15%

AC
- analyze and update SLA boundary report based on the requerements",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Mar/19 16:21;tz118;Kopie von XBID Service Boundary Reporting February 2019=update1.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67455/Kopie+von+XBID+Service+Boundary+Reporting+February+2019%3Dupdate1.xlsx","29/Mar/19 16:25;tz118;sla-report_v2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67458/sla-report_v2.xlsx","01/Apr/19 14:14;tz118;sla-report_v3.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67494/sla-report_v3.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59875200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1b:g",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Mar/19 16:26;tz118;report template updated, ready for a review
","01/Apr/19 14:15;tz118;updated template with prognosis automation [^sla-report_v3.xlsx] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove @Ignore annotation for Trading Inquiry failover tests,XP-1403,80153,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,eh941,eh941,27/Mar/19 11:01,06/Nov/20 11:34,22/Feb/21 13:26,10/Apr/19 12:31,,,Pre2020,,Trading,,,,,,,,,"The Trading Inquiry failover tests are ignored because they fail. The resources like coreAmqp, pmiAmqp and so one are updated in wrong order. There is most likely a bug in resource management project.",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60307200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 22 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2694,XP-2232,master,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve failover test infrastructure configuration,XP-1402,80152,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eh941,eh941,27/Mar/19 10:56,06/Nov/20 11:34,22/Feb/21 13:26,11/Apr/19 10:27,,,Pre2020,,,,,,,,,,,"Current setup works with 2 database nodes and etcd.

What to do:
# Increase number of database nodes to 4
# Create consul cluster instead of etcd. Use at least 4 nodes
# Add more failover tests containing consul disconnections and disconnections between nodes (it's up to you)",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60307200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:1",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 22 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gartner - Energy Applications, Benchmark",XP-1394,80093,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,qz412,qz412,26/Mar/19 12:33,06/Nov/20 10:14,22/Feb/21 13:26,04/Apr/19 10:16,,,Pre2020,,,,,,,,,,,"XBID team is asked to fill in the excel sheet for the technologies we use, effort ratio on inidivdual dev activities, tools and their costs, internal/external resource ratio etc.

Please:
 * Read the documents
 * Decide *{color:#00875a}what dimensions of the excel sheet can be filled by the dev team{color}*, by when and fill them
 * Decide *{color:#de350b}what dimensions cannot be filled by the dev{color}* (e.g. costs, infrastructure, ...) team and indicate them to [~df894] who is coordinating this activity, he will align with the respective departments (e.g. procurement, TechOps, ...) for those areas
 * Attach the filled in excel sheet here and let AS know

Gartner (the requesting authority) is expecting the document to be filled in by end of March. But as they provided the document rather late without any buffer for considering the running project activities (R2.0 UAT preparation), Alex was informed XBID will not be able to respect this deadline and was supposed to relay this information to Gartner.",,qz412,radeale,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/19 12:34;qz412;DBAG_Kickoff_Benchmark.pdf;https://jira.deutsche-boerse.com/secure/attachment/67270/DBAG_Kickoff_Benchmark.pdf","26/Mar/19 12:34;qz412;Gartner BMS IT Overview Benchmark Application Development & Support Explain Text.docx;https://jira.deutsche-boerse.com/secure/attachment/67273/Gartner+BMS+IT+Overview+Benchmark+Application+Development+%26+Support+Explain+Text.docx","26/Mar/19 12:33;qz412;Templates_AppBM_Energy_Minimal_info.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67271/Templates_AppBM_Energy_Minimal_info.xlsx","01/Apr/19 12:11;zi174;Templates_AppBM_Energy_Minimal_info_filled.xlsx;https://jira.deutsche-boerse.com/secure/attachment/67487/Templates_AppBM_Energy_Minimal_info_filled.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59616000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Apr/19 10:17;zi174;Final version:
https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?RootFolder=%2fsites%2fsp0232%2fSP%20-%20Energy%2f02%20General%20topics%2fBenchmarking%2fAppBenchmark%2fApplication&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID - Dev team Contribution to the Security Concept document (under ESO coordination),XP-1391,80066,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,de698,qz412,qz412,25/Mar/19 17:07,06/Nov/20 12:47,22/Feb/21 13:26,04/Apr/19 09:02,,,Pre2020,,,,,,15/Apr/19 00:00,,,,,"Dear all,

XBID Product has been requested by ESO ([~ne232], [~rl336]) to provide information for the Security Concept Document.

Please:
 * See the *Turquoise* sections of the document and fill in the information needed. I have color-coded the document for your convenience
 * Feel free to read the complete document, not only the parts strictly belonging to you and make updates there as well
 * Provide the updated document in Track Changes mode to ESO

ESO is expecting the update to be provided to them by *15th April 2019*. Should you have any questions re the content, deadline or general purpose, please contact ESO directly.

Thank you very much, Ondra",,de698,gd553,jj069,qz412,tz118,,,,,,,,,,,,,,,,,,,SERVICE-2851,,,,,,,,,,,,ESO-123,XP-1513,,,,,,"25/Mar/19 17:08;qz412;Security Concept - Template 0.18-1_XBID_with_CMS_V04.docx;https://jira.deutsche-boerse.com/secure/attachment/67215/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V04.docx","02/Apr/19 16:21;tz118;Security Concept - Template 0.18-1_XBID_with_CMS_V04_sj.docx;https://jira.deutsche-boerse.com/secure/attachment/67558/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V04_sj.docx","02/Apr/19 16:35;de698;Security Concept - Template 0.18-1_XBID_with_CMS_V04_sj_ar.docx;https://jira.deutsche-boerse.com/secure/attachment/67560/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V04_sj_ar.docx","03/Apr/19 10:16;tz118;Security Concept - Template 0.18-1_XBID_with_CMS_V05.docx;https://jira.deutsche-boerse.com/secure/attachment/67574/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V05.docx","03/Apr/19 11:52;de698;Security Concept - Template 0.18-1_XBID_with_CMS_V06.docx;https://jira.deutsche-boerse.com/secure/attachment/67589/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V06.docx","10/Apr/19 09:28;gd553;Security Concept - Template 0.18-1_XBID_with_CMS_V07.docx;https://jira.deutsche-boerse.com/secure/attachment/67877/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V07.docx","10/Apr/19 11:57;gd553;Security Concept - Template 0.18-1_XBID_with_CMS_V08.docx;https://jira.deutsche-boerse.com/secure/attachment/67895/Security+Concept+-+Template+0.18-1_XBID_with_CMS_V08.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,Final doc is available inside (attached),,,,,,,,,,,,,,59097600,,,,,,,,,,,,,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1b:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Mar/19 15:02;jj069;I'll do part 
h3. A.14.2.2 System change control procedures

[reference/provide software development lifecycle procedure that is used]

  and send it for PO's review.","01/Apr/19 15:33;tz118;Dev team to prepare following parts:

A.12.3.1 Information backup
Backup interval: <specify how often backups are taken, e.g. daily backup>

A.9.4.5 Access control to program source code
DBG Github is used to control access to source code [provide screenshot] / <Describe how access to program source code is controlled> / <not applicable + describe reason, e.g. no own development and commercial-off-the-shelf solution used
","02/Apr/19 16:12;tz118;A.12.3.1 Information backup- updated  [^Security Concept - Template 0.18-1_XBID_with_CMS_V04_sj.docx] ","02/Apr/19 16:35;de698;A.9.4.5 Access control to program source code - updated [^Security Concept - Template 0.18-1_XBID_with_CMS_V04_sj_ar.docx]

Links to documents (within the text) - updated.","03/Apr/19 10:16;tz118;attached version with A.14.2.2 System change control procedures  [^Security Concept - Template 0.18-1_XBID_with_CMS_V05.docx] ","03/Apr/19 11:52;de698;A.14.2.2 updated [^Security Concept - Template 0.18-1_XBID_with_CMS_V06.docx]","10/Apr/19 09:20;gd553;Updated document with input from ACM - see version V07.","10/Apr/19 11:53;gd553;Updated document with updated input from ACM - see version V08.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IC deletion causing core down,XP-1390,80039,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Fixed,qo794,qo794,qo794,25/Mar/19 08:58,06/Nov/20 12:47,22/Feb/21 13:26,27/Mar/19 14:30,,,Pre2020,,Capacity,,,,,,,,,"The following scenario leads to core down:
# create an allocation on an IC
# wait one day until the allocation is deleted from the core memory (core holds allocations in its pool for one day only)
# delete the interconnector
# core goes down as a DB constrain is violated

Reason:
* core stores delivery intervals and all related data only for one day in its memory pool, after that period the data is deleted from its memory
* when deleting ICs a check whether an allocation is not present is applied, but only allocations in the core memory are taken into account
* delivery intervals and all related data are kept in DB for 7 days
* when deleting an IC that does not have an allocation made within last 24 hours, core allows that deletion, however there are still references in DB to that IC -> the deletion fails

The same result can be achieved by simply waiting more than one day (no allocation is needed) and then deleting an IC as old delivery intervals stay in DB for 7 days but only one day in the core memory.",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60220800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08exc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/19 14:07;radeale;Bug confirmed, please enforce this limitation from DFS700, chapter +9.2.3 Delete Existing Interconnector+:

{code}The interconnector can only be deleted if:
- It has been suspended for at least X days, where X is a parameter configurable by the system administrator. If this value is not configured, a default value of 7 days is used. This ensures the IC has no DI generated and no allocations.
...{code}

Edit: Please make exception for the newly created ICs whose configuration has not take effect (i.e. I create an IC with the ACTIVE status set in future, but I still can delete it today).","27/Mar/19 14:30;radeale;Test OK on SYST3, XBID Version R2.0.0

The implementation is now adherent to the specs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing housekeeping for m7_999_revision_index,XP-1389,80027,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,eg288,eg288,22/Mar/19 13:49,06/Nov/20 11:34,22/Feb/21 13:26,11/Apr/19 10:04,,,Pre2020,,Capacity,Trading,,,,,,,,"The table m7_999_revision_index  should be housekept along with the rest of history tables. Currently it contains 100_000_000 rows in production since 24.5.2018

Proposed solution is to hold only one entry in the table with the latest journal index. It is updated by persister instead of inserting new entry for each transaction.

Problem to solve: how to run it after database clean up. i.e. when application starts against empty database.",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-4643,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60652800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 22 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[FIX] Error generating Activity Report when the BM Code is deleted,XP-1387,80018,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Fixed,radeale,radeale,radeale,22/Mar/19 12:37,06/Nov/20 10:25,22/Feb/21 13:26,29/Mar/19 17:29,,,Pre2020,,Capacity,,,,,,,,,"+Problem+
 The problem arises when generating an Activity Log.

+Root cause+
 The root cause of the problems is that there are allocations made in December and January with Balancing Mechanism Entity code AMPRION1. The code was deleted at 2019-01-22 14:48:37. When trying to generate the requested report, the process fails because it tries to map the saved BM ID code to a no longer existing Balancing Mechanism code.

+Permanent fix+
 The information stored for report generation will include the BM Description as well as the BM ID code, thus reports can be generated even when a BM code used in an explicit allocation is already deleted.

Expected delivery is with XBID 2.0.",,eg288,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60048000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/19 10:44;eg288;Implemented in xbid-2.0.1 or git branch XP-1387-CMM_AllocationLog_added_balancing_mechanism_description","29/Mar/19 17:29;radeale;Tested {color:#00875A}OK{color} on Docker, XBID R1.6.0.37-SNAPSHOT.
- BM Description is stored in the cmm_950_atc_log table
- BM Description is shown in the Activity Log
- When BM code is set in the table to a non-existing, the report is still generated, the CMI remains available
- When the related info about BM allocation is removed from the table (_balancing mechanism description_), the allocation shows as regular explicit allocation
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate new graphx to be used everywhere in XBID,XP-1386,80012,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,lt112,lt112,22/Mar/19 10:18,06/Nov/20 11:34,22/Feb/21 13:26,25/Mar/19 09:13,,,Pre2020,,,,,,,,,,,"Currently XBID uses mostly graphx:
{code}
<artifactId>xbid-graphx</artifactId>
<groupId>com.deutscheboerse.math</groupId>
<name>xbid-graphx</name>
{code}
While orderbook uses graphx:
{code}
<artifactId>xbid-graphx</artifactId>
<groupId>com.deutscheboerse.energy</groupId>
<name>xbid-graphx</name>
{code}

Unify this and use only the {{energy}} one
",,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60739200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eie:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Merge change enabling XP-74 on all envs except SIMU and PROD, where it will be switched off",XP-1384,79995,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,jy268,jy268,21/Mar/19 14:17,06/Nov/20 11:34,22/Feb/21 13:26,04/Apr/19 15:12,,,Pre2020,,Shipping,,,,,configuration,,,,"*{color:#00875a}[ Disable loading of all sync packages in SMC to save time and resources (except PROD and SIMU) ]{color}*

 

Merge change enabling XP-74 on all envs except SIMU and PROD, where it will be switched off",,ei349,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,59616000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:zr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office team 22,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Mar/19 14:18;jy268;MR prepared: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/238","03/Apr/19 15:05;ei349;czech it Dejve","04/Apr/19 07:46;jy268;[~ei349] this one is already implemented here https://jira.deutsche-boerse.com/browse/XP-1435 and pull request is already merged. [~ei349] what do you mean here?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deliver Sprint Increment,XP-1373,79967,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,xu897,jj069,21/Mar/19 09:35,06/Nov/20 10:14,22/Feb/21 13:26,25/Mar/19 12:40,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,jj069,,,,,,,,,,,,,,,,,,,,,,,XP-1246,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60825600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08ei8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New SPM user has been created into LDAP with plain text password,XP-1369,79949,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,od044,od044,20/Mar/19 16:19,06/Nov/20 12:40,22/Feb/21 13:26,29/May/19 14:57,,,Pre2020,,Shipping,,,,,,,,,"New SPM user has been created into LDAP with plain text password.

expect:
The password should be hashed not plain text

StR.

1. Create a new user in SPM
2. Check a password value and properties of the user in LDAP 
3. Reset a password of user that doesn't exist in LDAP 
4. Check that the user has been created in LDAP and its password properties",,jy268,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,54777600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,20/Mar/19 16:19,,,,,,,,,,,,,,,,,,,,,,,"1|y08rfr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/May/19 11:58;jy268;waiting for techops: https://jira.deutsche-boerse.com/browse/TECHLOG-2409","29/May/19 14:57;jy268;Techops ticket done, I have verified that passwords are hashed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"R2.0 - exploratory ""confidence"" check, component 2",XP-1367,79938,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,20/Mar/19 14:47,06/Nov/20 10:14,22/Feb/21 13:26,28/Mar/19 09:48,,,Pre2020,,,,,,,,,,,"Design and execute {color:#de350b}basic{color} exploratory test giving confidence in the features for following areas:
 * ACER Reporting (without dummy EIC postprocessing) (XP-6)
 * SM Aggregate file types (XP-227)",,de698,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Mar/19 10:40;de698;ACER Reporting_v2.0_Commented_TWG FTF_20190325 DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/67131/ACER+Reporting_v2.0_Commented_TWG+FTF_20190325+DBAG.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60739200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1b:i9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 20 [S],,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Mar/19 10:40;de698;Latest specification attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"R2.0 - exploratory ""confidence"" check, component 1",XP-1366,79937,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,qz412,qz412,20/Mar/19 14:45,06/Nov/20 10:14,22/Feb/21 13:26,27/Mar/19 17:54,,,Pre2020,,,,,,,,,,,"Design and execute {color:#de350b}basic{color} exploratory test giving confidence in the features for following areas:
 * SM Enhanced SA Assignemnt Rule - Option 2 (XP-40)
 * Internal interconnectors halt (XP-528)",,od044,qz412,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60220800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eic:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/19 13:37;od044;- exploratory test (automation by Tosca and manually) of SM - passed 
","27/Mar/19 17:54;radeale;- exploratory testing of the iICs (and CMM/CMI) - passed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dispose syspdepl1 machine,XP-1361,79801,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ll664,ll664,19/Mar/19 13:50,06/Nov/20 11:34,22/Feb/21 13:26,25/Jun/19 08:46,,,Pre2020,,,,,,,,,,,"{color:#00875a}*Migration to new supported deployment machines*{color}
 For the deployments to internal envs, we still use old {{syspdepl1}} machine that is no longer supported by techops. [~qo288] has the knowledge about AWS workers that should replace it.

The job in question: [https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID-sysX-deploy-all/]",,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,52531200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s00010420q",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jun/19 08:46;qo794;{{syspdepl1}} has already been disposed, the job in question migrated to {{englobauto}} and working properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA report tool update ,XP-1356,79771,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,tz118,tz118,18/Mar/19 16:55,04/Aug/20 19:35,22/Feb/21 13:26,10/Jul/19 13:36,,,Pre2020,,,,,,,,,,,"h1. {color:#00875a}Consistency of SLA Report headlines{color}
h2. Current Situation 

SLA Credit Point report and KPI reports don't have matching sheet headlines aligned with the sheet name. 

See more in screenshot. 
h2. Proposed solution

Update SLA report generation to have correct sheet headlines based on the tab sheet name on all SLA reports. 
h2. Acceptance Criteria 
 - correct headline on sheet based on the tab sheet name aligned between all three SLA reports. 
 - new version of SLA report tool deployed",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1869,,,,,,,"18/Mar/19 16:57;tz118;credit pointt.PNG;https://jira.deutsche-boerse.com/secure/attachment/66952/credit+pointt.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60998400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08zvi:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 29,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dataset for R2.0 Performance tests,XP-1351,79727,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,tm431,tm431,18/Mar/19 10:08,31/Aug/20 15:38,22/Feb/21 13:26,07/May/19 15:59,,,Pre2020,,,,,,,support_request,,,,"Please process the attached performance scenario RTS3/B-2 (???) and prepare a deployable dataset.

How the scenario differs from the previous one:
* New Delivery Area
* Renamed Market Areas
* Added capacity limits for ICs
** We currently don't support this in our templete, we have to adjust it including the internal API => +3 MDs
* Added users

Proposed story points: 20

{color:#505F79}+_Original text:_+

TWG PTF provided reviewed Dataset for R2.0 Performance tests (the Dataset) to DBAG via Jira XBID-4289.

DBAG 8/3 provided feedback:""
 * please be aware, that if you wish to use a different (updated) dataset than the original one (RTS3/B), the performance results cannot be compared (there is an increased complexity of the grid etc.).

Also please create a separate support request ticket specifying along the new dataset the scenarios to be run with the new dataset.
 * Please be aware of the original timeline limitation laid out by DBAG (in this ticket description):

In case any changes to the proposed data set are requested by TWG or XTG (like adding new users to the dataset), please provide them at least a month before the actual R2.0 UAT performance run.”

Issue has been discussed in Joint TWG PTF/ DBAG 11/3, outcome of the discussion is:""
 * RTS3/B has been based on the topology of 2^nd^ wave + GME, which has not been altered in the provided dataset. TWG PTF is of opinion the originally provided Dataset (prior the corrections) was not possible to use for the R2.0 Performance tests.
 ** DBAG: examples of changes considered as significant (significant means impact of which would need to be further analysed by DBAG):
 *** Values of limits in the Interconnectors sheet
 ** Hint: if the new inputs in sheet Interconnectors, columns K..N are removed, the tests based on the Dataset would be better comparable with RTS3/B
 * Scenarios for Performance tests R2.0: TWG PTF will answer via the JIRA – Jiri to create the support request
 * Users: Users added in the Dataset can stay there
 * When R2.0 UAT performance to be run: to be still clarified (as UAT R2.0 test timeline is not communicated yet)

""

This support request is created to hold the finalization of the R2.0 performance tests Scenarios and finalisation of clarification regarding the Dataset. {color}",,gd553,tm431,,,,,,,,,";18/Mar/19 10:09;tm431;18000",";07/May/19 15:12;ek176;259200",,0,277200,,,0,277200,,,,,XBID-4341,,,,,,,,,,,,,,,,,,,"15/Apr/19 13:12;ek176;MBCopy_XBID dataset RTS3 B Wave 2 for DBAG_v1.0_20190308.xlsx;https://jira.deutsche-boerse.com/secure/attachment/68071/MBCopy_XBID+dataset+RTS3+B+Wave+2+for+DBAG_v1.0_20190308.xlsx","18/Mar/19 10:08;tm431;XBID dataset RTS3 B Wave 2 for DBAG_v1.0_20190308.xlsx;https://jira.deutsche-boerse.com/secure/attachment/66907/XBID+dataset+RTS3+B+Wave+2+for+DBAG_v1.0_20190308.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,See comments in IMplementation and Test subtasks,,,,,,,,,,,,,,60220800,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yek:2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1351-dataset-RTS3SB-for-PerfTestsR2-0,tomcat-rollback,XP-2942,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,XP-4276-split-io,XP-2484,develop,XP-3110-deprecated-log,master,XP-2501-to-xbid-dev-env,traversal-XP-2485,XP-4276-new-format,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Mar/19 09:38;tm431;Customer must decide what he wants.","25/Mar/19 10:56;gd553;Hi [~tm431],

In order to take this in the RCB tomorrow - I need to know what do they want to change in the dataset (in comparison to RTS3 B) and what effort it would mean for us to adjust the dataset?

I need the info until today eob.

Thanks.","25/Mar/19 11:32;radeale;Hi Malina,

there are several changes:
 * New Delivery Area
 * Renamed Market Areas
 * Added capacity limits for ICs
 ** We currently don't support this in our templete, we have to adjust it including the internal API => +3 MDs
 * Added users

However the point is, that even a small change results for us to need to check the validity of the provided dataset and generate a new dataset.

Also there is a need to check and change the performance tests to ensure they work with the changed dataset.

Internally the effort is rated at *8 MDs*, - if everything goes well and there are  no further changes, lengthy debates and the customer says ""Yes, this is the final dataset for this phase, we don't want to do any additional changes, please generate a new dataset and adjust the performance tests accordingly."" So far there is no such clear mandate resulting from the TWG calls or discussions in the relevant Jira tickets. Personally I'd add 2 more MDs considering the time already spent on this topic = *11 MDs*.

Kind regards,

Patrik, Duc, Alexandr","28/Mar/19 10:56;gd553;As discussed yesterday in the Core Meeting, please go ahead with the preparation. We will most probably not bill the customer for this, as it is also beneficial for DBAG. Thus do not mention anything to customers. I will address this point during the RCB.","28/Mar/19 11:51;radeale;Dear Malina,
thank you. I'm unsure about the process, but I prepared this task for the product backlog and moved it up.
/A/
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Respond to NEMOs / TSOs comments on ASR010c,XP-1329,79594,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,rg535,rg535,rg535,14/Mar/19 11:07,06/Nov/20 11:25,22/Feb/21 13:26,01/Apr/19 08:18,,,Pre2020,,,,,,,,,,,,,de698,rg535,tz118,,,,,,,,,,,,,,,,,,,,,XP-1328,,,,,,,,,,,,M7ACM-363,,,,,,,"14/Mar/19 11:07;rg535;ASR010c - Analysis for Losses Part III_V1.4.docx;https://jira.deutsche-boerse.com/secure/attachment/66824/ASR010c+-+Analysis+for+Losses+Part+III_V1.4.docx","20/Mar/19 09:56;tz118;ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032019_sj.docx;https://jira.deutsche-boerse.com/secure/attachment/67020/ASR010c+-+Analysis+for+Losses+Part+III_V1.4_DBAG+18032019_sj.docx","22/Mar/19 09:57;tz118;ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032022_sj.docx;https://jira.deutsche-boerse.com/secure/attachment/67129/ASR010c+-+Analysis+for+Losses+Part+III_V1.4_DBAG+18032022_sj.docx","25/Mar/19 15:57;de698;ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032025_ar.docx;https://jira.deutsche-boerse.com/secure/attachment/67205/ASR010c+-+Analysis+for+Losses+Part+III_V1.4_DBAG+18032025_ar.docx","27/Mar/19 10:01;tz118;ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032026.docx;https://jira.deutsche-boerse.com/secure/attachment/67337/ASR010c+-+Analysis+for+Losses+Part+III_V1.4_DBAG+18032026.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,comments sent to NEMOs and TSOs on 1. April.,,,,,,,,,,,,,,60307200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 19,Alpha Team Sprint 20 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Mar/19 09:56;tz118;[~de698] few additional comments after our alignment from yesterday, marked purple. also sent via email. ","25/Mar/19 15:58;de698;Please find attached the updated comments after our call on Friday. [^ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032025_ar.docx]

[~tz118] please also have a look :)","27/Mar/19 10:02;tz118;a version with few updates attached  [^ASR010c - Analysis for Losses Part III_V1.4_DBAG 18032026.docx] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing VDA in trading errors in logs,XP-1327,79592,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eg288,qo794,qo794,14/Mar/19 10:59,06/Nov/20 12:38,22/Feb/21 13:26,25/Mar/19 09:57,,,Pre2020,,,,,,,,,,,"A lot of errors are present in core log files:
{code:java}
2019-03-14 10:37:50.133 ERROR 17969 --- [rderbookHandler] c.d.e.m.t.validation.XbidSoftAsserts: CMM delivery area 11VID-CAPACITY-0 is missing in Trading.
{code}

Virtual delivery areas are not known to trading, it's not a bug.",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61430400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00yi00i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5 PEN Test - PT-4 CSV Injection,XP-1324,79553,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,ek176,ek176,13/Mar/19 12:44,04/Aug/20 19:19,22/Feb/21 13:26,26/Mar/19 13:59,,,Pre2020,,Capacity,,,,,,,,,"XP-1030 was analyzed, but not fixed",,ek176,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1368,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"CSV Injection vulnerability in multiple places. An XP-1368 has been created to: 1) unify the CSV approach, and 2) Fix remaining issues (too complex to fix within this XP)
",,,,,,,,,,,,,,60825600,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c14:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],Alpha Team Sprint 19,Alpha Team Sprint 20 [S],,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Mar/19 13:34;radeale;If you have time please also validate, that the imported data undergo the same validations as specified in DFS700, chapter 7.1.1	Create New Balancing Group:

Balancing Group EIC code
- 16 characters
- Alphanumeric

Balancing Group GLN Code
- 13 characters
- Alphanumeric

Name field
- 64 characters
- Alphanumeric (Refer section 1.3.1 for allowed characters details) (see also XP-1030)","20/Mar/19 17:15;ek176;In addition to string quoting, the security fix is prepending the string with a single quote (') if the string starts with one of the '@=-+'.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Run performance test on fixed new orderbook,XP-1323,79552,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,od044,lt112,lt112,13/Mar/19 12:41,06/Nov/20 12:43,22/Feb/21 13:26,27/Mar/19 11:08,,,Pre2020,,Trading,,,,,,,,,"h2. Wait for merge issues to be solved

Re-run performance test (due to possibly performance-related changes) for internal use only (verification):
 - branch: {{develop}}
 - dataset: {{rts3-sliceb-data-fake}}
 - scenario: {{xbid-rts3b-2019-sc14-v09}}
- additional parameters: {{-Dorderbook.strategy=new-only}}
",,lt112,od044,,,,,,,,,,,7200,7200,,0%,7200,7200,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/19 11:06;od044;HandlersReport-newODK-1-6-0-36-only-new-26032019.xls;https://jira.deutsche-boerse.com/secure/attachment/67341/HandlersReport-newODK-1-6-0-36-only-new-26032019.xls","27/Mar/19 11:06;od044;sc14v09-perf-newOBK-1-6-0-6-only-new-26032019.xls;https://jira.deutsche-boerse.com/secure/attachment/67342/sc14v09-perf-newOBK-1-6-0-6-only-new-26032019.xls",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60307200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08bd2:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/19 09:55;od044;Test passed on 
XBID_VERSION=1.6.0.34
SPM_VERSION=1.5.0.21

both old and new calculation return the same result - there were no mismatches
test via perf scenarios SC14v09","21/Mar/19 08:57;lt112;[~od044] Examine the performance results, please. Also add log files.","21/Mar/19 10:58;lt112;also, with the {{new-with-new-graphx}} argument, there are no mismatch checks, as there is no comparison happening.","27/Mar/19 11:07;od044;Test passed on a new release of OBK 
XBID_VERSION=1.6.0.36
SPM_VERSION=1.5.0.23

executed two runs:
 - with comparison:
{code}-Dorderbook.new.strategy=new-with-new-graphx{code}
 -> no mismatch - OK

- with new OBK calculation:
{code} -Dorderbook.strategy=new-only{code} 
-> reports:
 [^HandlersReport-newODK-1-6-0-36-only-new-26032019.xls]  [^sc14v09-perf-newOBK-1-6-0-6-only-new-26032019.xls] 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5 PEN Test - PT-9 Secure SSL/TLS Configuration,XP-1322,79551,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ek176,ek176,13/Mar/19 12:36,31/Aug/20 15:38,22/Feb/21 13:26,29/Oct/19 15:00,XBID 1.5.9,XBID 2.0,XBID 2.0,,,,,,,Waiting-Internal,,,,"The SSL config has to be deployed: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/429]

 

Next steps: 

1) Internal test envs.

  - deploy change to SYT2

  - deploy change to other SYTs

2) merge into energy-mkt-shared/master

  - update relevant envs

 

The services can be tested via 'testssl' command (Ubuntu), or: https://testssl.sh/

AC: 
 * Verify that the services are not vulnerable by:
 ** LOGJAM (CVE-2015-4000)
 ** LUCKY13 (CVE-2013-0169)
 * Verify our envs are not vulnerable

Use testssl script",,ei349,ek176,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2503,XP-2184,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Merged into prod. Remaining changes in XP-2184,,,,,,,,,,,,,,17366400,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ivz:x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],Alpha Team Sprint 19,Alpha Team Sprint 30 [S],Alpha Team Sprint 31,Alpha Team Sprint 32 [S],Alpha Team Sprint 33,Alpha Team Sprint 34 [S],Alpha Team Sprint 35,Alpha Team Sprint 36 [S],Alpha Team Sprint 37,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2942,tomcat-rollback,traversal-XP-2485,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,trailing-slash-syt1,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/May/19 08:14;ei349;it looks that TO Jira has been resolved - removing the waiting techops label ","02/Sep/19 17:10;ll664;Niklas fixed the SSL Ciphers for customer facing env - https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/452
PR has been added to SERVICE-2664 as suggested by Pavel Rehak, so it's no forgotten.

I'll also fix ciphers for our internal envs.","04/Sep/19 17:41;ll664;Waiting for deployment to CUTE.","11/Sep/19 15:13;ek176;CTP server ciphers: Prepared the following MRs:

SIMU: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/491] (SERVICE-4479) [Merged]
 CUTE: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/492] (seems not to be used) [Merged]
 PROD: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/493] (merged via SERVICE-3669) [Merged]","29/Oct/19 14:59;ek176;Note, there are still Apache configs that were not updated. See XP-2184.","04/Aug/20 19:18;ei349;[~ek176] can you please check whether this item is still valid? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5 PEN Test - PT-11: Disable HTTP TRACE method,XP-1316,79532,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,13/Mar/19 10:36,27/Oct/20 18:01,22/Feb/21 13:26,08/Oct/19 14:50,XBID 1.5.9,,Pre2020,XBID 2.0,,,,,,Waiting-Internal,,,,"PR to be deployed: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/428 

See XP-1040 for details. It is not fixed yet, only analysis has been done.

AC: 
 * Verify the TRACE method is disabled, see TECHLOG-2094 for commands.
 * Verify the TRACE method on our env's CTP Profile servers",,ei349,ek176,yo218,,,,,,,,,,30,30,,0%,30,30,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TraceEnable Off in apache config,,,,,,,,,,,,,,43372800,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09ivz:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],Alpha Team Sprint 19,Alpha Team Sprint 30 [S],Alpha Team Sprint 31,Alpha Team Sprint 32 [S],Alpha Team Sprint 33,Alpha Team Sprint 34 [S],Alpha Team Sprint 35,Alpha Team Sprint 36 [S],,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,XP-2942,tomcat-rollback,traversal-XP-2485,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"25/Mar/19 10:58;ek176;TODO: Deploy ComTrader Profile Server to SYT(2).","16/Jul/19 13:08;ek176;Works for `xbid-dev-env` branch. 

 
{noformat}
$ https_proxy='' curl -i -X TRACE --insecure --basic --user SADMIN01  https://xbinteweb1:60806/profile-storage/services

Enter host password for user 'SADMIN01':

HTTP/1.1 405 Method Not Allowed

$ https_proxy='' curl -i --insecure --basic --user SADMIN01 -X TRACE https://xbinteweb1:60806/profile-storage/services -H ""Cookie: name=Deloitte""

Enter host password for user 'SADMIN01':

HTTP/1.1 405 Method Not Allowed



{noformat}
 

TBD: 

1) Update CTP server ('master' branch):

 

AC: The HTTP Trace method is 405 Forbidden

Current state: 
{code:java}
$ curl -X TRACE -i https://simu1.profiles.xbid.deutsche-boerse.com:60104/ -H ""Cookie: name=Deloitte""                                              
HTTP/1.1 200 Connection established


HTTP/1.1 200 OK
...
TRACE / HTTP/1.1
Host: simu1.profiles.xbid.deutsche-boerse.com:60104
Accept: */*
Cookie: name=Deloitte

{code}
Expected (target) state:
{noformat}
$ curl -X TRACE -i https://simu1.profiles.xbid.deutsche-boerse.com:60104/ -H ""Cookie: name=Deloitte""
...
HTTP/1.1 405 Method Not Allowed
...
...{noformat}
 

 ","08/Aug/19 13:38;ei349;waiting for deployment","05/Sep/19 09:08;ek176;Related PR: [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/428/files]

Added to https://jira.deutsche-boerse.com/browse/SERVICE-2664 as suggested by [~rehapav] so it's not forgotten","08/Oct/19 14:49;ek176;Deployed in SERVICE-4479
Works as expected:

$ curl -X TRACE -i https://simu1.profiles.xbid.deutsche-boerse.com:60104/ -H ""Cookie: name=Deloitte""   
HTTP/1.1 200 Connection established

HTTP/1.1 405 Method Not Allowed
","08/Oct/19 14:50;ek176;Works, deployed on SIMU",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5. PEN Test - PT-10 Disable directory listing on the servers,XP-1315,79530,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,13/Mar/19 10:24,11/Aug/20 16:36,22/Feb/21 13:26,01/Aug/19 13:30,XBID 1.5.9,XBID 2.0,Pre2020,XBID 2.0,,,,,,,,,,"XP-1039: Disable directory listing is not implemented

 

AC:
 * Verify the links in TECHLOG-2093 do not display the directory structure
 * Verify the CTP profile servers on our envs are not vulnerable",,ek176,,,,,,,,,,";16/Dec/19 14:32;ek176;57600",,,0,57600,,,0,57600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Checked on SIMU and SYT2. Fixed.,,,,,,,,,,,,,,50716800,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08eso:2u9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],Alpha Team Sprint 19,Alpha Team Sprint 30 [S],Alpha Team Sprint 31,,,,,,,,,,,,,,,,,,See comments,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,XP-2501-to-xbid-dev-env,XP-2942,traversal-XP-2485,tomcat-rollback,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,profile-storage-1.8.x,XP-1315-PEN.10-disable-dir-listing,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"25/Mar/19 10:58;ek176;TODO: Deploy ComTrader Profile Server to SYT(2). XP-1745","16/Jul/19 12:46;ek176;Ok for SYT2 CTP server:
{noformat}
$ https_proxy='' curl -i --insecure --basic --user SADMIN01 -X GET https://xbinteweb1:60806/ -H ""Cookie: name=Deloitte""                 
Enter host password for user 'SADMIN01':

HTTP/1.1 302 Found
Location: https://xbinteweb1:60806/profile-storage/

{noformat}
 

Ok for simu:
{noformat}
$ curl -X GET -i https://simu1.profiles.xbid.deutsche-boerse.com:60104                         
HTTP/1.1 200 Connection established



HTTP/1.1 403 Forbidden


{noformat}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5 PEN Test - PT-3 Enable SSL,XP-1314,79518,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ek176,ek176,ek176,13/Mar/19 10:10,04/Aug/20 19:19,22/Feb/21 13:26,30/May/19 11:49,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[more secure connection to... ]*{color}

XP-1029 

Additionally, we should provide some mechanism to verify the files: SHA256/SHA512SUM, or el. signature (to be able to verify that the tool has not been tampered). IMHO the simple is to provide two .SHA files (it is much more difficult to find a collision in both functions):

i.e. the following should be added to the pipeline, uploading the new JNLP and ZIP files:

'sha256sum *.jnlp *.zip > checksums.sha256'

'sha512sum *.jnlp *.zip > checksums.sha512'

 

Note: Do not use SHA-1, nor MD5: [https://en.wikipedia.org/wiki/Hash_function_security_summary]

 

AC: 
 * Verify the links in TECHLOG-2092 are served via HTTPS
 * Either update the Jenkins Release job to provide SHA sums, or create another XP task",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1480,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Switched to SSL
Not very relevant, see XP-1480 and related (CR088)",,,,,,,,,,,,,,61516800,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:01",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],Alpha Team Sprint 19,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make new OBK solution primary for the services connected to the old OBK,XP-1295,79387,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,ei349,ei349,08/Mar/19 16:22,06/Nov/20 11:34,22/Feb/21 13:26,25/Mar/19 09:12,,,Pre2020,,,,,,,,,,,"There is a finding that even that we have new OBK calculation in place there are still side services using the old OBK solution. Target of this task is to identify and update these services to use new OBK solution so we can use the old solution only as a referential for the comparsion purposes using the Scientists approach. 

*Acceptance Criteria:*

- Old OBK calculation will be used just for the Scientist purposes. All other services will use new OBK. ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61862400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08d3w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Investigate if the final solution of DB setup is aligned with the technical proposal  (ASR003),XP-1274,79153,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ei349,ei349,01/Mar/19 14:56,06/Nov/20 11:26,22/Feb/21 13:26,19/Jul/19 15:17,,,Pre2020,,,,,,,,,,,"It looks that final solution of the DB setup after TechOps impementation is still aligned with the technical proposal ASR003. Can you please check, communicate and align? 

*AC:* 
 * Confirm the alignment or provide proposal for the documentation update in e.g. AIP100. 
 * Discuss the topic with Release Manager about further steps (communication and coordination) with customers

 ",,ei349,jy268,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50198400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08jzc:u",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 30,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jul/19 16:38;jy268;Documentation in ASR003 does not reflect current setup which is described here: https://confluence.energy.svc.dbgcloud.io/display/ET/Patroni","19/Jul/19 15:14;jy268;Not all PROD tasks are finished which means that PROD environment is not ready yet: https://jira.deutsche-boerse.com/browse/TECHLOG-2083","19/Jul/19 15:15;jy268;[~rehapav] please be aware that PROD env is not ready.
[~ei349] please note that documentation has to be altered to reflect current configuration. Does it mean that new jira ticket has to be created? I am leaving it up to you.","19/Jul/19 15:20;rehapav;I linked dependency to XBID 2.0 PROD deployment https://jira.deutsche-boerse.com/browse/SERVICE-3669","22/Jul/19 09:39;ei349;[~jy268] - I've created task for the future documentation update (https://jira.deutsche-boerse.com/browse/XP-1905). Thank you for the investigation. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Logs are flooded with meaningless warning,XP-1262,79110,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Fixed,qo794,qo794,qo794,01/Mar/19 08:54,06/Nov/20 11:34,22/Feb/21 13:26,04/Mar/19 07:47,,,Pre2020,,,,,,,,,,,"As of XP-244 core log files have become very large, they are flooded with the following message which btw does not bring anything important at all and is always the same, moreover this behavior was requested by the customer:
{code:java}
2019-02-28T14:12:20.664Z [rderbookHandler][XBDBX001][42ea947a] WARN  c.d.e.m.o.s.H2HService - Populating H2H Matrix ATC with values limited to the value of 1073741822
{code}

*Remove this message or introduce something less aggressive (lowering to DEBUG does not make much sense to me)*
",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62294400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y089i0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 17 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Mar/19 07:47;qo794;Fixed within XP-1149",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce OWASP security check for xbid dependencies,XP-1261,79106,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,eg288,eg288,28/Feb/19 17:06,03/Feb/21 16:07,22/Feb/21 13:26,10/Mar/20 10:51,,,3.1.0,,,,,,,SECURITY,,,,"h1. {color:#00875a}Improving dependency security{color}

It is a maven plugin dependency-check-maven ([info|https://jeremylong.github.io/DependencyCheck/dependency-check-maven/], [github|https://github.com/jeremylong/DependencyCheck]). See how it is implemented in M7 project. Addresses OWASP Top Ten: _A9 - Using Components with Known Vulnerabilities_ (also reported in PenTest findings XBID 2.0).

There are multiple {color:#de350b}*CRITICAL*{color} vulnerabilities in the dependencies of our projects (see attached HTML reports):

*{{xbid 2.0.x/3.0.x:}}*
 \{{ pkg:maven/ch.qos.logback/logback-core@1.1.3 CRITICAL}}
 \{{ pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.9.5 CRITICAL}}
 \{{ pkg:maven/org.springframework.ws/spring-ws-core@2.3.0.RELEASE CRITICAL}}
 \{{ pkg:maven/com.unboundid/unboundid-ldapsdk@4.0.1 CRITICAL}}
 \{{ pkg:maven/commons-fileupload/commons-fileupload@1.3.1 CRITICAL}}
 \{{ pkg:maven/commons-collections/commons-collections@3.2.1 CRITICAL}}
 \{{ pkg:maven/org.springframework.integration/spring-integration-core@5.0.8.RELEASE CRITICAL}}
 \{{ pkg:maven/org.quartz-scheduler/quartz@2.2.1 CRITICAL}}
 \{{ pkg:maven/org.springframework.ws/spring-ws-core@2.2.4.RELEASE CRITICAL}}
 \{{ pkg:maven/commons-collections/commons-collections@3.2 CRITICAL}}
 \{{ pkg:maven/org.kohsuke.jetbrains/annotations@9.0 CRITICAL}}

*{{report-tool:}}*
 \{{ pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.9.0 CRITICAL}}
 \{{ pkg:maven/org.springframework.boot/spring-boot-starter-batch@2.1.10.RELEASE CRITICAL}}
 \{{ pkg:maven/org.springframework.shell/spring-shell-core@2.0.0.RELEASE CRITICAL}}

*{{shipping-module:}}*
 \{{ pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.9.7 CRITICAL}}
 \{{ pkg:maven/commons-collections/commons-collections@3.2.1 CRITICAL}}
 \{{ pkg:maven/org.springframework.ws/spring-ws-core@3.0.4.RELEASE CRITICAL}}

*{{testclient(develop):}}*
 \{{ pkg:maven/org.springframework.boot/spring-boot@1.4.0.RELEASE CRITICAL}}
 \{{ pkg:maven/org.springframework/spring-core@4.3.2.RELEASE CRITICAL}}
 \{{ pkg:maven/org.springframework/spring-jdbc@4.3.1.RELEASE CRITICAL}}
 \{{ pkg:maven/ch.qos.logback/logback-core@1.1.7 CRITICAL}}
 \{{ pkg:maven/commons-collections/commons-collections@3.2.1 CRITICAL}}
 \{{ pkg:maven/org.springframework.batch/spring-batch-core@3.0.7.RELEASE CRITICAL}}
 \{{ pkg:maven/org.springframework/spring-core@4.0.5.RELEASE CRITICAL}}
 \{{ pkg:maven/com.mchange/c3p0@0.9.5.2 CRITICAL}}
 \{{ pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.9.8 CRITICAL}}

Plugin configuration in M7:
{code:java}
...
                <plugin>
                    <groupId>org.owasp</groupId>
                    <artifactId>dependency-check-maven</artifactId>
                    <version>3.3.2</version>
                    <configuration>
                        <suppressionFiles>src/main/resources/security-check-suppressions.xml</suppressionFiles>
                        <cveValidForHours>20</cveValidForHours>
                    </configuration>
                </plugin>
...
{code}
Estimated total effort: 3WD (xbid: 2WD, spm: 1WD, CT: ?, ProfileServer:?, PMI:?, ...)

Configuration params: [https://jeremylong.github.io/DependencyCheck/dependency-check-maven/configuration.html]

_Note_: For Jenkins, the plugin has no access to the [NVD database|[https://nvd.nist.gov/]]. Consider skipping: {{mvn clean verify -DskipTests -Ddependency-check.skip}}

_Note_: Consider creating a 'final' task for Jenkins tasks, failing builds for CVSS score > X? (M7 uses the level of 4).

_Note_: Consider creating similar task for the DB included projects, i.e.:
 * m7.energy-comxerv-commons
 * m7.energy-commons-files-core
 * m7 API
 * graphix, routing...
 * ...

 _Note_: For the remaining vulnerabilities (i.e. [CVE-2019-3773|https://nvd.nist.gov/vuln/detail/CVE-2019-3773]) we need to coordinate/decide (can use suppresion files/URL [ref|https://jeremylong.github.io/DependencyCheck/dependency-check-maven/])
  
 *TODO:* 
 *   Decide the way of using maven-dependency plugin in the pipeline (i.e.: profile that can be disabled/enabled). IMHO: First have it to generate reports, in second phase fail on CVSS score > CVSS_LEVEL (see below)
 * Set the CVSS_LEVEL that fails the build. M7 uses the value of *4*.
 * Create tasks for relevant applications/libraries/dependencies to be fixed (IE: Comtrader, Xbid, SPM, RT, ...). First, start with smaller projects.
 * Fix the most obvious/simplest cases. Use the knowledge to estimate the future tasks.

 

*AC*: 
 * Jenkins pipeline integration of the maven-dependency-plugin for the selected projects. Allows to simply switch to fail the builds on CVSS_LEVEL
 * XP tasks for the selected projects, estimated.",,eg288,ei349,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2855,XP-2746,,,,,,"20/Nov/19 15:43;ek176;20191120_owasp_reports_xbid_SM_RT_TC.tar.bz2;https://jira.deutsche-boerse.com/secure/attachment/77475/20191120_owasp_reports_xbid_SM_RT_TC.tar.bz2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,32832000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,28/Feb/19 17:06,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:40000000ez",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 0,Alpha Sprint 1 (S),Alpha Sprint 2,Alpha Sprint 3 (S),Alpha Sprint 4,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4527,XP-2478-tobago-upgrade-clean02,master-3.0.x,XP-2478-tobago-upgrade-clean01,XP-2903,XP-2583,XP-2694-xbid-3.0.x-latest-tag-fix,xbid-api-3.0.x,XP-3594-cpm-ramping,master-xbid-2.0.36.x,XP-TEST,XP-3094-sonar-gate,master-comtrader-2.5.x,XP-4277-develop-sonar-test,XP-1261-owasp-sec-deps-update,XP-3001-xbid-2.0.36.x,XP-3048-merge-to-xbid-2.0.36.x,XP-4152-acceptance,XP-3909,cpm,XP-1211-confidential-label,XP-2942-losses-perf,XP-4354,XP-2521-labeling-cmi-leftovers,develop,XP-4234,master-acceptance,XP-TEST2,XP-4250-metrics-integration-test,XP-2843-BR01,XP-1261-owasp-fix,acceptance,XP-3233-prod-jgitflow,XP-3161-pom-cleanup-develop,fixing-dataset,XP-222-acceptance,XP-4211-perf-analysis-develop-jh,XP-2843-BR07,XP-3394_flyway_standard_implementation,XP-4211-perf-analysis-jh,XP-69,xbid-losses-poc,XP-PULL-TEST,XP-4250-develop,XP-4100,XP-3055,xbid-dataset-2.0.x,XP-2400,XP-3161-develop,XP-2478-tobago-upgrade,XP-4211-perf-analysis-develop,master-cpm,XP-761-spooooky-migration-from-grunt-to-webpack,XP-4250-develop-jh,master-xbid-losses-poc,XP-3233-acceptance-jgitflow,XP-2635-redo-fix-3.0,hotfix,minor-fixups,prod,master-prod,XP-4530,XP-4122-perf-analysis,XP-3594-allocation-plans,XP-2554,master,XP-4250-metrics-integration-test-2,XP-2476,comtrader-2.5.x,XP-4250,XP-3394_remove_schema_version,XP-4174,CPM-release-settings,XP-4526-resource-managment-fix,xbid-2.0.36.x,XP-4349_set_default_page,using-no-package-lock-during-npm-install,XP-139-xbid-3,,,,,,,,,true,"20/Nov/19 15:44;ek176;To generate the reports, I've used the following config:
{code:java}
           <plugin><!-- Can be skipped (Jenkins): `mvn clean verify -DskipTests -Ddependency-check.skip` -->
                <groupId>org.owasp</groupId>
                <artifactId>dependency-check-maven</artifactId>
                <version>${owasp.maven.plugin.version}</version>
                   <configuration><!-- https://jeremylong.github.io/DependencyCheck/dependency-check-maven/configuration.html -->
                    <cveValidForHours>20</cveValidForHours> <!-- copied from M7 team -->
<!--                    <failBuildOnCVSS>4</failBuildOnCVSS>--><!-- fails when the CVSS score is > 4 ; beware of false positives (can be excluded) --> 
                  <suppressionFiles><!-- can be HTTP resource -->      
                  <suppressionFile>./owasp-suppressions.xml</suppressionFile> 
                   </suppressionFiles>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>aggregate</goal> <!-- mvn verify -->
                        </goals>
                    </execution>
                </executions>
            </plugin>
{code}
 ","26/Nov/19 16:27;ei349;[~ek176] can you please estimate (if it's less than 5 SPs)","27/Nov/19 12:22;ek176;It's either 3 or 5, depending on how deep we want to go (how many projects, fix/update obvious problems). I've put 5 (so that some impl. can be performed within the task). ","06/Jan/20 17:34;ek176;There are a few PR (XBID dependencies, unmerged) that can be used as a starting point (Note: the plugin is not as a maven-profile(!): TBD). Not merged yet (failing XBID-integration tests, maybe unrelated; expecting updates/finetuning):

[https://github.deutsche-boerse.de/dev/m7.energy-commons-process/pull/2]

[https://github.deutsche-boerse.de/dev/m7.energy-commons-jsf/pull/2]

[https://github.deutsche-boerse.de/dev/m7.energy-comxerv-commons/pull/5]

[https://github.deutsche-boerse.de/dev/m7.energy-commons-transport/pull/45]

[https://github.deutsche-boerse.de/dev/m7.energy-commons-passwd/pull/34]

 

Note: [CVE-2018-1258|https://pivotal.io/security/cve-2018-1258] is being suppressed as false-positive, as it relates only to 5.0.5.RELEASE version (see [suppresion example PR|https://github.deutsche-boerse.de/dev/m7.energy-commons-jsf/pull/2/files])

 ","05/Feb/20 15:58;ek176;In XBID, the following sub-projects were upgraded (and relevant Jenkins jobs created/updated/resurrected):

 

*{color:#4c9aff}Added maven plugins (and released){color}*:

com.deutscheboerse:remote-commons:jar:2.0.3

com.deutscheboerse.energy:energy-commons-date-time:jar:1.16

com.deutscheboerse.energy:energy-commons-test:jar:2.3

com.deutscheboerse.energy.xbid:xbid-cim-api:jar:3.0.3 
 com.deutscheboerse.energy.xbid:xbid-cmm-api-xml-all:jar:3.0.3 
 com.deutscheboerse.energy.xbid:xbid-trading-api-xml:jar:3.0.3

com.deutscheboerse.energy:energy-commons-amqp:jar:0.19 
 com.deutscheboerse.energy:energy-commons-core:jar:1.6 
 com.deutscheboerse.energy:energy-commons-failover:jar:3.0.2 
 com.deutscheboerse.energy:energy-commons-files-core:jar:1.22 
 com.deutscheboerse.energy:energy-commons-files-entso:jar:1.23 
 com.deutscheboerse.energy:energy-commons-jsf:jar:1.10 
 com.deutscheboerse.energy:energy-commons-passwd-jar:jar:1.0.62 
 com.deutscheboerse.energy:energy-commons-passwd-war:war:1.0.62 
 com.deutscheboerse.energy:energy-commons-process:jar:1.0.1 
 com.deutscheboerse.energy:energy-commons-transport:jar:2.0.12

energy-commons-hibernate: 1.15

com.deutscheboerse.energy.m7:m7-internal-api-sbe:jar:0.0.32 
 com.deutscheboerse.energy.m7:m7-internal-api-services:jar:0.0.32

com.deutscheboerse.energy:routing:jar:0.4.15 
 com.deutscheboerse.energy:xbid-graphx:jar:1.0.4 
 com.deutscheboerse.energy.xbid:reporting-api:jar:5.0.49

com.deutscheboerse.energy.m7:m7-alarmtilt-adapter:jar:3.0.7

com.deutscheboerse.cmm:cmm-refdata-api:jar:1.1.4

com.deutscheboerse.comxerv:comxerv-commons:jar:2.0.29 
 com.deutscheboerse.energy:resourcemanagement:jar:2.0.2

*{color:#4c9aff}Added maven plugin (no release) and upgraded:{color}*

com.deutscheboerse.comxerv:energy-project-logging:jar:1.9

energy-buildtools:1.1

m7-api: 2.1.2

*{color:#4c9aff}Unable to find/unresolved (messy):{color}*

com.deutscheboerse.comxerv:time-patcher:jar:1.1

com.deutscheboerse.comxerv:tobago-theme-comxerv:jar:2.1.5

 ","06/Feb/20 10:17;ek176;Created info about Jenkins jobs: [https://confluence.energy.svc.dbgcloud.io/display/XBID/How+to+create+or+configure+Jenkins+release+job]

 

 

(to work with OWASP dependency plugin)","07/Feb/20 13:57;ek176;Performed release of xbid-3.0.17 (updated in m7.dataset)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid-1.5 - broken jenkins pipelines,XP-1251,79079,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eg288,eg288,28/Feb/19 11:20,06/Nov/20 11:26,22/Feb/21 13:26,19/Jun/19 16:16,,,Pre2020,,,,,,,,,,,"The xbid -1.5 continuous an nightly piplines are broken. It seems the root cause is the same. It is missing artifacts in the artifactory.

{code}
[ERROR] Failed to execute goal on project m7-h2h: Could not resolve dependencies for project com.deutscheboerse.energy.xbid:m7-h2h:jar:1.5.10-SNAPSHOT: Could not find artifact com.deutscheboerse.energy.m7:m7-cmm-api-xml-all:jar:1.0.40 in central (http://cmqaart.deutsche-boerse.de/artifactory/eex-dev) -> [Help 1]
{code}

Estimated effort: 4h",,eg288,,,,,,,,,,,,14400,14400,,0%,14400,14400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62640000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,28/Feb/19 11:20,,,,,,,,,,,,,,,,,,,,,,,"1|y089b4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gluster.fs - journal improvement failover test,XP-1250,79074,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,qz412,qz412,28/Feb/19 10:30,31/Aug/20 15:38,22/Feb/21 13:26,04/Mar/19 15:06,,,Pre2020,,,,,,,,,,,A failover test should be executed to confirm the gluster.fs journaller improvements (XP-759) did not compromise the functioning of the failover. [~tm431] - please add the expected filover internal test timeline (I believe it is planned for ,,eh941,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62208000,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088u7:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Mar/19 14:47;eh941;h2. TL;DR; the performance upgrades are based on non-supported setup which may and most likely will lead to data inconsistency - some message might get lost or the message order might not match

The whole *improvement* is based on ChronicleQueue *upgrade to version 5*. There is +*no batching*+ involved at all.

The *old* Chronicle Queue version supported *flag for synchronous writes*. Although we actually could *never be sure if it worked as expected* (meaning once the write method was called the data was persisted on network drive), we were convinced it works that way and we also made couple of failover tests which proved it really does work.

The new version is very fast. But it has no synchronous switch. After a bit of digging in documentation I found a following statement:
{quote}
h3. Important note

Chronicle Queue does *not* support operating off any network file system, be it NFS, AFS, SAN-based storage or anything else. The reason for this is those file systems do not provide all the required primitives for memory-mapped files Chronicle Queue uses.
{quote}
I also found a [question on stackoverflow|https://stackoverflow.com/questions/49126670/san-based-storage-with-chronicle-queue] with an answer directly from the author of the library:
{quote}If you only ever access a SAN or NFS drive from one machine, this should work. However, if the you access it from two machines, you are likely to see an inconsistent state as the order in which pages are flushed to the underlying storage is not reliable.

For fail over and distribution of queues, we recommend using Chronicle Queue Enterprise.
{quote}
From *my understanding* how the new Chronicle Queue works the network storage isn't suitable because the java process tells operating system to write the data. It relies on the file system's cache and therefore it's very fast. It guaranties the same operating system reads the data in consistent state and in the latest version because the cache is maintained by the OS. If I understand it correctly the data is always ""persisted"" if the java process fails/crashes/is killed as long as the operating system is kept running. The data can be lost in case of OS failure or machine plug off. Here's why I think that:
{quote}... If your application dies, the operating system keeps running for seconds longer, so no data is lost; even without replication.
{quote}
{quote}... while Chronicle Queue directly uses the operating system’s file system and cache.
{quote}

h2. What can we do?
h3. Downgrade
We might *go back to the old solution*. In this case we would most likely breach the SLAs because journal times were the bottleneck factor for overall performance.

h3. Take a risk
We might take the risk the inconsistency isn't _big_ issue. That should be tested though. If the database is synchronous the only thing that might happen is that in case of the network drive unavailability we send acknowledgement but we don't process the message. Now it depends on how long it takes for the core module to detect the network is gone. If it's up to let's say 2 seconds I would say it's fine. If it's 30 seconds I would say it's really bad.

Another thing connected to this issue is actually XP-1241. If the *database replication* is done *asynchronously* then the persistence might no longer be considered as synchronous. In this case if the *whole datacenter failover takes place some data might get lost*.

h3. Get rid of the network drive
This is rather *long-term solution*. If we get rid of the network drive we must choose other technology. There are several options. We already spoke about *Kafka* but there is also an option of using Chronicle Queue Replication as an Enterprise version of the queue we're already using. It's a paid feature though and I didn't find out how much it costs.","04/Mar/19 13:24;qz412;Dear [~eh941], [~ll664],

thank you for the investigation.

For the time being I suggest:
 * Given the difficulties we are facing with the obk inconsistencies (https://jira.deutsche-boerse.com/browse/XP-1188) and db cluster (https://jira.deutsche-boerse.com/browse/XP-1241) I suggest we now stick with the as-is state and keep the task in the backlog for future sprints. With high likelihood this means that the solution design, implementation & internal testing will run in parallel to the UATs and may mean DBAG creates a finding on itself later on in UATs. But as those things above do not even allow start of the UATs, the prio is clear.
 * The SLAs may be breached in synthetic very high-load scenarios => May become apparent in the perf tests that will be executed in SIMU at the end (Sept, Oct?) of UATs. That gives the investigation / solution timeline by which the decision or implementation should be made.

Best regards, Ondra","04/Mar/19 15:07;eh941;Changes made by XP-759 reverted. Once we want to investigate this issue further we might re-revert these changes again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deliver Sprint Increment,XP-1246,79062,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,xu897,jj069,28/Feb/19 09:51,06/Nov/20 11:27,22/Feb/21 13:26,14/Mar/19 10:31,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,jj069,,,,,,,,,,,,,,,,,,,,,,,XP-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62640000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088u7:qi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 17 [S],Alpha Team Sprint 18 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH - Implement incremental E job with Beam,XP-1245,79060,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,ll664,ll664,28/Feb/19 09:45,04/Aug/20 19:35,22/Feb/21 13:26,30/May/19 10:44,,,Pre2020,,,,,,,,,,,"Replace Sqoop by Beam (batch) job that:
* Runs daily/weekly
*  Incrementally extracts given table into the Parquet data format
* Stores it in correct place (See https://confluence.energy.svc.dbgcloud.io/display/EDW/Directory+design)
* Keep last-saved-id in HDFS  (file)",,ek176,ll664,qo794,,,,,,,,,,,,,,,,,,XP-812,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,54777600,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08esv:zx",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,poc_finalized_with_scratches,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"30/May/19 07:41;qo794;Beam job implemented, only order_history table export is present at the moment, see https://github.deutsche-boerse.de/dev/xbid-etl/tree/develop/xbid-beam-jobs, TODOs written into the README.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix Boundary report for January 2019,XP-1235,79002,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,27/Feb/19 11:03,06/Nov/20 10:25,22/Feb/21 13:26,05/Mar/19 09:09,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ Document fix ]*{color}

Jiri Zavada (20190227):
 During review of the performance report files on January 2019 TWG PTF found there is missing all data of Daily maximum % of order transactions in peak (sheet Orders) in Service Boundary Reporting file (XBID Service Boundary Reporting January 2019.xlsx).

Could DBAG deliver the fixed report asap, please ?

AC
 - Boundaries Report is enhanced with maximum % of orders transactions in peak
 - Investigate root cause",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Mar/19 15:26;tz118;XBID Service Boundary Reporting January 2019_v2.0.xlsx;https://jira.deutsche-boerse.com/secure/attachment/66435/XBID+Service+Boundary+Reporting+January+2019_v2.0.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62208000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088u7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 17,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Mar/19 15:27;tz118; [^XBID Service Boundary Reporting January 2019_v2.0.xlsx] report updated and reviewed.  Asked PM support to communicate to the customers. 

AC
    Boundaries Report is enhanced with maximum % of orders transactions in peak *DONE*
    Investigate root cause *DONE* - issue with report generator, shall be fixed in the latest version of report tool, suggestion to test February reports more in detail as reporting tool code changes changes are major. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SLA reports for Feb 2019,XP-1234,79001,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,qz412,27/Feb/19 10:41,30/Apr/19 20:07,22/Feb/21 13:26,12/Mar/19 11:08,XBID 1.5.9,,XBID 1.5.9,,SLA Report Tool,,,,,,,,,"*{color:#00875a}[ Standard service ]{color}*

Please generate the Jan SLA reports and provide them to the customers by Mar 5th",,qz412,uv683,,,,,,,,,,,,,,,,,,,,,,XP-1072,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61603200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088u7:qy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 18 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/19 11:08;uv683;[~gd553] [~qm925] please find reports on sharepoint",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check why OBK improvements improved order execution time and API response time so significantly,XP-1232,78986,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,ei349,ei349,26/Feb/19 15:11,06/Nov/20 11:34,22/Feb/21 13:26,24/May/19 08:48,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ Performance improvement understanding ]*{color}

Latest order book improvements showed significant  improvements in the order execution and API response times which were not expected at the first time. Can we investigate what was the root cause of this improvement? 

 

for details about response times please see attached file and column C and E

additionally there are reports saved here:

S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\RTS3\slice B\execution\newDBConfiguration_04122018

 

confluence page with internal OBK improvements descriptions:

https://confluence.energy.svc.dbgcloud.io/display/XBID/Order+book+perfomance+improvements",,eg288,ei349,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/May/19 11:13;tz118;Perf_DB_OBK_results_analysis_v8.xlsx;https://jira.deutsche-boerse.com/secure/attachment/69554/Perf_DB_OBK_results_analysis_v8.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,55296000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08rfr:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 26,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/May/19 16:50;eg288;What we are comparing when looking into 95 percentile are the worst cases out of 150_000 events. Here the differences are clearly visible. But when we look at a lower percentiles there is no difference between vanilla and improved implementations in the API Response Time and Order Execution Time. On the other hand the difference for Orderbook Computation Time (Proportional) is clearly visible for all percentiles including the low ones. 

||API Response Times [ms] ||

||Percentile||Vanilla||Improved||
||25%|0|0|
||50%|0|0|
||75%|0|0|

||Order Execution Times [ms]||

||Percentile||Vanilla||Improved||
||25%|0|0|
||50%|3|3|
||75%|15|15|

||Orderbook Calculation Times (Proportional) [ms]||

||Percentile||Vanilla||Improved||
||25%|388|5|
||50%|521|75|
||75%|801|364|

What we see here is that the improvements for API Response Time and Order Execution Times are not visible for an average order. There is only significantly less outliers. In other words the overall difference is rather small for the two metrics in questions.

The less outliers can be explained by the significantly improved resource utilization (memory, cpu) when the new optimized orderbook calculation is used. The better resource utilization means that the application is less overloaded in peaks, there is less lagging  and thus there is not so many outliers produced.","24/May/19 08:48;tz118;review done, thanks , Jirka, for the explanation of differences",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jenkins - use new AWS workers ,XP-1230,78982,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,ll664,ll664,26/Feb/19 13:39,06/Nov/20 11:34,22/Feb/21 13:26,01/Oct/19 12:49,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[make future firewall requests easier for TO]*{color}
From #energy-devops:
{quote}Piotr Wasilewski [3:12 PM]
 Hi @m7-dev, @xbid-dev, as a part of the plan to move Jenkins docker workers from AWS Dev to AWS Service Zone I have installed 4 new instances, called *englobwkr-fulltime[0-3].svc.dbgcloud.io*. They have identical setup and _should_ have the same network accesses. There are new labels *englobwkr* and *englobwkr-nightly* Could you please move the builds to the new labels and ping me if there is anything not working? We would like to gradually increase the amount of workers in SVC and phase out the workers in DEV which should make future firewall requests easier for us.
{quote}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62726400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y8s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Response to RTS3SB questions ,XP-1226,78969,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,26/Feb/19 09:07,04/Aug/20 19:15,22/Feb/21 13:26,18/Mar/19 09:28,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ CUSTOMER ENGAGEMENT ]*{color}

During the TWG PTG DBAG jointly discussed some of the provided answers. Official feedback shall come this week however some par of work can start now.

AC
 - describe to a practical / acceptable extent what is batching and how does it work in terms of performance, which operations include batching (e.g. OBK calculation)
 - Hand over for internal review PO",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1623,,,,,,,"28/Feb/19 15:51;tz118;Analysis_of_the_RTS3_Slice_B_results_20190225_TWG FTF.docx;https://jira.deutsche-boerse.com/secure/attachment/66362/Analysis_of_the_RTS3_Slice_B_results_20190225_TWG+FTF.docx","18/Mar/19 09:27;tz118;Analysis_of_the_RTS3_Slice_B_results_20190315_TWG_PTF_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/66905/Analysis_of_the_RTS3_Slice_B_results_20190315_TWG_PTF_DBAG.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61084800,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1a:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 19,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Mar/19 09:27;tz118;communicated externally' via linked Jira on Friday 15/3",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OBK - order book depth (100) - add to cucumber end-to-end tests ,XP-1214,78848,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,21/Feb/19 14:07,04/Aug/20 19:35,22/Feb/21 13:26,02/Sep/19 09:11,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ Extended test coverage ]*{color}

OBK depth tested manually :
 https://jira.deutsche-boerse.com/browse/XP-357

Define TCs (from XP-357) for automation and add them for OBK depth validation into cucumber end-to-end tests.

Task is also part of Epic *'Performance tuning and prognosis'*",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2048,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46569600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099lr:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,selenide-poc,XP-1504,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"08/Jul/19 12:37;hj444;# Create new feature file for end-to-end-test/core/ : _orderbookDepth.feature_
# Add all new TCs defined for OBK depth into orderbookDepth.feature file.","02/Sep/19 09:10;hj444;orderBookDepth.fetaure
all TCs done and will be rewritten after XP-2048 is done.","02/Sep/19 09:11;hj444;https://github.deutsche-boerse.de/dev/xbid-test/pull/187 merged into develop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[HO] Cucumber knowledge handover,XP-1206,78832,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,radeale,radeale,21/Feb/19 10:53,31/Aug/20 15:39,22/Feb/21 13:26,21/Mar/19 11:17,,,Pre2020,,,,,,,,,,,Split the Cucumber handover over the team so everyone with sufficient software configuration can it.,,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60825600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y087vk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/19 11:31;tm431;Add also support for reporting tool, so you can generate ACER reports localy","21/Mar/19 11:17;radeale;Got some basic intro from Janette :)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reset password fails when user is missing in LDAP,XP-1205,78828,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,od044,eg288,eg288,21/Feb/19 10:39,06/Nov/20 10:59,22/Feb/21 13:26,20/Mar/19 16:13,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,"{color:#00875a}*[ deployment process improvement ]*{color}

*Problem:*

The password reset can fail when LDAP is not in sync with XBID databases.  It happens  when database import from a different environment is made. Typically PROD/SIMU database is imported into a CUTE environment.

After a database import there is a flood of requests to create users in individual CUTE LDAP trees as they are missing there and password reset operation does not work. This consumes significant time of operation and development teams dealing with the requests.

*Solution:*

The reset password operation will create user in LDAP if it is not present. The xbid databases are source of true, if the user exists in xbid database then it is valid. Thus it does not impose any additional risk. Furthermore the xbid can already add users into LDAP when a new user is created.

*Notes:*

Needs to be implemented in all modules with reference data:**
 * trading
 * cmm
 * shipping

 Effort estimate: *3PD*

 ",,eg288,od044,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60825600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,21/Feb/19 10:39,,,,,,,,,,,,,,,,,,,,,,,"1|y08bd3:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Mar/19 14:13;eg288;please test, implemented in XBID 1.6.0.35, SM 1.5.0.22","20/Mar/19 16:13;od044;Test passed on
XBID_VERSION=1.6.0.35
SPM_VERSION=1.5.0.22

- User entity is created in LDAP in case that existing user in app requires a reset password. Email with a new password is sent accordingly. 

StR:
1. Remove existed user in app from LDAP 
2. Require a reset password for the user
3. Check that the user entity has been created in LDAP 
4. Check that email with new password arrives into user's email inbox 
5. Check that the user can login with new password 
6. Repeat step 1-5 for users in SOB, CMM and SPM
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deliver Sprint Increment,XP-1193,78809,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,jj069,21/Feb/19 09:15,06/Nov/20 10:14,22/Feb/21 13:26,28/Feb/19 09:38,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,jj069,,,,,,,,,,,,,,,,,,,,,,,XP-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63244800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088cs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shipping  - replace docker-maven-plugin,XP-1192,78799,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,ll664,ll664,20/Feb/19 16:01,06/Nov/20 11:34,22/Feb/21 13:26,25/Feb/19 10:18,,,Pre2020,,Shipping,,,,,,,,,"It just sucks. Every other SM release job fails because it cannot parse response from registry - https://englobjci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/XBID%20Shipping%20-%20Release/20/console

{code:java}
[ERROR] Failed to execute goal io.fabric8:docker-maven-plugin:0.27.2:build (build-docker-image) on project shipping-core: Execution build-docker-image of goal io.fabric8:docker-maven-plugin:0.27.2:build failed: com.google.gson.stream.MalformedJsonException: Expected ':' at line 1 column 48 path $.xbid-docker-dev-local.artifactory.dbgcloud.io -> [Help 1] {code}

Replace it with something sane - plain {{docker build}}/bash,  [spotify/docker-maven-plugin|https://github.com/spotify/docker-maven-plugin] etc.",,ll664,qo794,,,,,,,,,,,,,,,,,,,XP-1181,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63244800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y087rb:p",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Run perf scenarios against optimized OBK with Scientist, understand & fix the inconsistencies in OBK calcualtion",XP-1188,78757,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,od044,ll664,ll664,20/Feb/19 10:08,04/Aug/20 19:15,22/Feb/21 13:26,19/Mar/19 09:54,,,Pre2020,,Trading,,,,,,,,,"{color:#00875a}*[ Investigation - potential bugfix ]*{color}

In order to gain additional confidence in new OBK implementation, we need to run couple of performance scenarios with Scientist turned on:
  
 # Pick couple (2-3) scenarios (RTS 3?) that has different characteristics, i.e. order distributions in the DAs, Capacity settings etc.
 # Deploy the XBID into perf with Scientist turned on in order to verify old and new implementation produces same results.  Comparison is enabled by following conf property:

{code:java}
 orderbook.new.strategy=comparison-with-new-graphx{code}
 #  Mismatches are logged into application logs, evaluate them after the test run.

*Additional test tasks to consider:*
 - auctions testing - compare how system behaves during the auction
 - exploratory testing - eg comtrader, update capacity, shortest path, halting interconnectors (island creation), eventually matching (RTM-03-05-10_Matcher_and_Order_Maintenance_0.3)
 - deep dive in routing testing (RTM-04_Capacity - CrossBorder Trading_v1.3 test models can be used)
 - included during UAT phase a test when both XBID versions(with and w/o OBK improvements) are running and results are compared (Scientist can be used)

h2. Findings
 * the crossed order book validation is not called in the new implementation
 * the perf test revealed inconsistent results when comparing the old and new calculations - {color:#ff0000}*further analysis needed*{color}

h2. Next steps
 * Execute the perf test using the version without recent changes, meaning using the ""clean"" new orderbook calculation, and verify mismatches appear as well
 * Understand & fix the inconsistencies in OBK calcualtion",,ei349,jy268,ll664,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1149,,,,,,,"25/Feb/19 13:38;od044;select_from_cx_100_order_where_order_id_97783_201902251330.csv;https://jira.deutsche-boerse.com/secure/attachment/66209/select_from_cx_100_order_where_order_id_97783_201902251330.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60998400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y088u7:i3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 16,Home Office Team 17 [S],Home Office Team 18,Home Office Team 19 [S],,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Feb/19 13:27;qo794;Test failed, different order book results were generated by the old and the new order book calculations:
{code:java}
2019-02-25T11:58:34.163Z [rderbookHandler][XBDBX001][7db4f7d] INFO  c.d.e.m.s.Experiment -
 Experiment: order-book-experiment; 
 Control: time = 743,302 µs; 
 Candidate: time = 736,507 µs; 
 Mismatch: control size = 952, candidate size = 952; 
 
 OrderbookInfoDelta{
    contractId=848,
    orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A73I', memberId=Optional.empty}', 
    modificationType='ACTIVE', 
    revision=2, 
    buyExposedOrderQties=[
        ExposedOrderQty{
            orderId=97783,
            isBuy=true, 
            price=5000, 
            orderCreationTime=Mon Feb 25 12:57:23 CET 2019, 
            contractId=848, 
            lastUpdateTime=null, 
            orderbookTsoEicCode='10Y1001A1001A73I', 
            orderTsoEicCod e='10YAT-APG------L', 
            exposedQuantity=0, 
            hiddenQuantity=0, 
            orderRestriction=ALL_OR_NOTHING, 
            orderType=BLOCK, 
            orderModificationType=ACTIVE, 
            balancingGroupId='BG-BGPX-------01', 
            peakSizeQty=0, 
            sourceMemberId='DBM01'
        },
        ExposedOrderQty{
            orderId=105150, 
            isBuy=true, 
            price=5100, 
            orderCreationTime=Mon Feb 25 12:58:31 CET 2019, 
            contractId=848, 
            lastUpdateTime=null, 
            orderbookTsoEicCode='10Y1001A1001A73I', 
            orderTsoEicCode='10YDE-EON------1', 
            exposedQuantity=45000, 
            hiddenQuantity=0, 
            orderRestriction=ALL_OR_NOTHING, 
            orderType=BLOCK, 
            orderModificationType=ACTIVE, 
            balancingGroupId='BG-BGPX-------01', 
            peakSizeQty=0, 
            sourceMemberId='DBM01'
        }
    ],
    sellExposedOrderQties=[]} from control
 
    similar to
 
 OrderbookInfoDelta{
    contractId=848, 
    orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A73I', memberId=Optional.empty}',
    modificationType='ACTIVE', 
    revision=2, 
    buyExposedOrderQties=[
        ExposedOrderQty{
            orderId=105150, 
            isBuy=true, 
            price=5100, 
            orderCreationTime=Mon Feb 25 12:58:31 CET 2019, 
            contractId=848, 
            lastUpdateTime=null, 
            orderbookTsoEicCode='10Y1001A1001A73I', 
            orderTsoEicCode='10YDE-EON------1', 
            exposedQuantity=45000, 
            hiddenQuantity=0, 
            orderRestriction=ALL_OR_NOTHING, 
            orderType=BLOCK, 
            orderModificationType=ACTIVE, 
            balancingGroupId='BG-BGPX-------01', 
            peakSizeQty=0, 
            sourceMemberId='DBM01'
        }, 
        ExposedOrderQty{
            orderId=105151, 
            isBuy=true, 
            price=5100, 
            orderCreationTime=Mon Feb 25 12:58:31 CET 2019, 
            contractId=848, 
            lastUpdateTime=null, 
            orderbookTsoEicCode='10Y1001A1001A73I', 
            orderTsoEicCode='10YNL----------L', 
            exposedQuantity=45000, hiddenQuantity=0, 
            orderRestriction=ALL_OR_NOTHING, 
            orderType=BLOCK, 
            orderModificationType=ACTIVE, 
            balancingGroupId='BG-BGPX-------01', 
            peakSizeQty=0, sourceMemberId='DBM01'
        },
        ExposedOrderQty{
            orderId=105149, 
            isBuy=true, 
            price=5000, 
            orderCreationTime=Mon Feb 25 12:58:31 CET 2019, 
            contractId=848, 
            lastUpdateTime=null, 
            orderbookTsoEicCode='10Y1001A1001A73I', 
            orderTsoEicCode='10YAT-APG------L', 
            exposedQuantity=35000, 
            hiddenQuantity=0, 
            orderRestriction=ALL_OR_NOTHING, 
            orderType=BLOCK, 
            orderModificationType=ACTIVE, 
            balancingGroupId='BG-BGPX-------01', 
            peakSizeQty=0, 
            sourceMemberId='DBM01'
        }
    ],
    sellExposedOrderQties=[]} from candidate
{code}","25/Feb/19 13:39;od044;Order 97783 details:
DB:
 [^select_from_cx_100_order_where_order_id_97783_201902251330.csv] 

perf tools request:
{code:java}
<OrderEntryActions delay=""329999"">
     <OrdrEntryAction contract=""16-T22"" state=""ACTI"" type=""BLO"" side=""BUY"" dlvryArea=""10YAT-APG------L"" timestamp=""0"" executionRes=""AON"" quantity=""35000"" price=""5000"" validityRes=""GFS"" clOrdrId=""rtsp4|rts3-|H01A0HrlB30Bas|1027"" text=""Hub S|ADD|B30Bas""/>
</OrderEntryActions>
{code}","25/Feb/19 14:54;od044;Next run failed either

{code:java}
{""root"":2019-02-25T13:48:08.583Z [rderbookHandler][XBDBX001][5501ab71] INFO  c.d.e.m.s.Experiment - Experiment: 
order-book-experiment; 
Control: time = 383,521 µs; 
Candidate: time = 281,160 µs; 
Mismatch: control size = 159, 
candidate size = 159; 
	OrderbookInfoDelta{
		contractId=847, 
		orderBookInfoColumnKey='OrderBookInfoColumnKey{
			deliveryAreaEic='10Y1001A1001A73I', 
			memberId=Optional.empty}', 
		modificationType='ACTIVE', 
		revision=5, 
		buyExposedOrderQties=[
			ExposedOrderQty{
				orderId=51808, 
				isBuy=true, price=5000, 
				orderCreationTime=Mon Feb 25 14:44:43 CET 2019, 
				contractId=847, 
				lastUpdateTime=null, 
				orderbookTsoEicCode='10Y1001A1001A73I', 
				orderTsoEicCode='10YDE-EON------1', 
				exposedQuantity=0, 
				hiddenQuantity=0, 
				orderRestriction=ALL_OR_NOTHING, 
				orderType=BLOCK, 
				orderModificationType=ACTIVE, 
				balancingGroupId='BG-BGPX-------01', 
				peakSizeQty=0, 
				sourceMemberId='DBM01'}, 
			ExposedOrderQty{orderId=56782, 
			isBuy=true, 
			price=5200, 
			orderCreationTime=Mon Feb 25 14:48:07 CET 2019, 
			contractId=847, 
			lastUpdateTime=null, 
			orderbookTsoEicCode='10Y1001A1001A73I', 
			orderTsoEicCode='10Y1001A1001A46L', 
			exposedQuantity=45000, 
			hiddenQuantity=0, 
			orderRestriction=ALL_OR_NOTHING, 
			orderType=BLOCK, 
			orderModificationType=ACTIVE, 
			balancingGroupId='BG-BGPX-------01', 
			peakSizeQty=0, 
			sourceMemberId='DBM01'}], 
		sellExposedOrderQties=[]} 
	from control 
similar to 
	OrderbookInfoDelta{
		contractId=847, 
		orderBookInfoColumnKey='OrderBookInfoColumnKey{
			deliveryAreaEic='10Y1001A1001A73I', 
			memberId=Optional.empty}', 
		modificationType='ACTIVE', 
		revision=5, 
		buyExposedOrderQties=[
			ExposedOrderQty{orderId=56782, 
			isBuy=true, 
			price=5200, 
			orderCreationTime=Mon Feb 25 14:48:07 CET 2019, 
			contractId=847, 
			lastUpdateTime=null, 
			orderbookTsoEicCode='10Y1001A1001A73I', 
			orderTsoEicCode='10Y1001A1001A46L', 
			exposedQuantity=45000, 
			hiddenQuantity=0, 
			orderRestriction=ALL_OR_NOTHING, 
			orderType=BLOCK, 
			orderModificationType=ACTIVE, 
			balancingGroupId='BG-BGPX-------01', 
			peakSizeQty=0, 
			sourceMemberId='DBM01'}], 
		sellExposedOrderQties=[]} 
	from candidate
}
{code}","26/Feb/19 15:44;od044;Run failed on XBID_VERSION=1.6.0.30-SNAPSHOT
{code:java}
2019-02-26T14:40:52.789Z [CoreService][XBDBX001][750400e4] INFO  c.d.e.m.t.o.m.i.OrderInactivationService - Inactivating 1 orders.
2019-02-26T14:40:52.816Z [Persister][XBDBX001][3fe27fc3] INFO  c.d.e.m.c.o.Persister - Batch persisted: 66 sts, speed: 709 /s
2019-02-26T14:40:52.827Z [Persister][XBDBX001][1b58abd8] INFO  c.d.e.m.c.o.Persister - Batch persisted: 1 sts, speed: 90 /s
2019-02-26T14:40:52.833Z [rderbookHandler][XBDBX001][6c733045] INFO  c.d.e.m.s.Experiment - Experiment: order-book-experiment; Control: time = 5,017,251 µs; Candidate: time = 2,283,075 µs; Mismatch: control size = 1571, candidate size = 1571; OrderbookInfoDelta{contractId=844, orde
rBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A73I', memberId=Optional.empty}', modificationType='ACTIVE', revision=5, buyExposedOrderQties=[ExposedOrderQty{orderId=51339, isBuy=true, price=5000, orderCreationTime=Tue Feb 26 15:37:12 CET 2019, contractId=8
44, lastUpdateTime=null, orderbookTsoEicCode='10Y1001A1001A73I', orderTsoEicCode='10YDE-EON------1', exposedQuantity=0, hiddenQuantity=0, orderRestriction=ALL_OR_NOTHING, orderType=BLOCK, orderModificationType=ACTIVE, balancingGroupId='BG-BGPX-------01', peakSizeQty=0, sourceMember
Id='DBM01'}, ExposedOrderQty{orderId=56275, isBuy=true, price=5200, orderCreationTime=Tue Feb 26 15:40:36 CET 2019, contractId=844, lastUpdateTime=null, orderbookTsoEicCode='10Y1001A1001A73I', orderTsoEicCode='10Y1001A1001A46L', exposedQuantity=45000, hiddenQuantity=0, orderRestric
tion=ALL_OR_NOTHING, orderType=BLOCK, orderModificationType=ACTIVE, balancingGroupId='BG-BGPX-------01', peakSizeQty=0, sourceMemberId='DBM01'}], sellExposedOrderQties=[]} from control similar to OrderbookInfoDelta{contractId=844, orderBookInfoColumnKey='OrderBookInfoColumnKey{deli
veryAreaEic='10Y1001A1001A73I', memberId=Optional.empty}', modificationType='ACTIVE', revision=5, buyExposedOrderQties=[ExposedOrderQty{orderId=56275, isBuy=true, price=5200, orderCreationTime=Tue Feb 26 15:40:36 CET 2019, contractId=844, lastUpdateTime=null, orderbookTsoEicCode='1
0Y1001A1001A73I', orderTsoEicCode='10Y1001A1001A46L', exposedQuantity=45000, hiddenQuantity=0, orderRestriction=ALL_OR_NOTHING, orderType=BLOCK, orderModificationType=ACTIVE, balancingGroupId='BG-BGPX-------01', peakSizeQty=0, sourceMemberId='DBM01'}], sellExposedOrderQties=[]} fro
m candidate
{code}","27/Feb/19 11:02;od044;Run failed 

{code:java}
2019-02-27T09:57:19.898Z [rderbookHandler][XBDBX001][2e31fbd2] INFO  c.d.e.m.s.Experiment - Experiment: order-book-info-experiment; Control: time = 6 µs; Candidate: time = 11 µs; Mismatch: control size = 9668, candidate size = 9668; OrderbookInfo{contractId=844, orderBookInfoColumn
Key='OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A44P', memberId=Optional.empty}', modificationType='ACTIVE', revision=5} from control similar to OrderbookInfo{contractId=844, orderBookInfoColumnKey='OrderBookInfoColumnKey{deliveryAreaEic='10Y1001A1001A44P', memberId=Option
al.empty}', modificationType='ACTIVE', revision=5} from candidate
{code}","14/Mar/19 12:35;ei349;remaining tasks: 
 # team review
 # [~lt112] will write the tests. ","15/Mar/19 16:20;jy268;[~od044] change merged, you can proceed with testing.","18/Mar/19 14:49;od044;Test passed on 
XBID_VERSION=1.6.0.34
SPM_VERSION=1.5.0.21
- both old and new calculation return the same result - there were no mismatches 
- test via perf scenarios SC14v09

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool logs false exception on manual generation,XP-1186,78671,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,19/Feb/19 15:02,06/Nov/20 10:25,22/Feb/21 13:26,21/Feb/19 09:11,,,Pre2020,,SLA Report Tool,,,,,,,,,"When manual report generation is done (from the CLI), Report Tool tries to mark given month as generated, however it fails on DB constraint:
{code:java}
2019-02-19T13:45:03.050Z [h-jobs-thread-1][][] ERROR o.s.b.c.s.AbstractStep - Encountered an error executing step mark-bid-ask-spread-report-month-as-generated in job bid-ask-spread-report
org.springframework.dao.DuplicateKeyException: PreparedStatementCallback; SQL [insert into ACER_GENERATED_REPORT (report, month) VALUES (?, ?)]; ERROR: duplicate key value violates unique constraint ""acer_generated_report_report_month_key""
  Detail: Key (report, month)=(BID_ASK_SPREAD, 2019-02-01 00:00:00) already exists.; nested exception is org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""acer_generated_report_report_month_key""
  Detail: Key (report, month)=(BID_ASK_SPREAD, 2019-02-01 00:00:00) already exists.
        at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.doTranslate(SQLErrorCodeSQLExceptionTranslator.java:242)
        at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
        at org.springframework.jdbc.core.JdbcTemplate.translateException(JdbcTemplate.java:1444)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:632)
        at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:862)
        at org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:917)
        at com.deutscheboerse.energy.xbid.reporttool.acer.report.ReportStateService.markMonthAsGenerated(ReportStateService.kt:19)
        at com.deutscheboerse.energy.xbid.reporttool.acer.report.MarkMonthAsGeneratedTasklet.execute(MarkMonthAsGeneratedTasklet.kt:17)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:407)
        at org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:331)
        at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)
        at org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:273)
        at org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:82)
        at org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:375)
        at org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215)
        at org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:145)
        at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:258)
        at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:203)
        at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)
        at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:68)
        at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:169)
        at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)
        at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:136)
        at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:313)
        at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:144)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""acer_generated_report_report_month_key""
  Detail: Key (report, month)=(BID_ASK_SPREAD, 2019-02-01 00:00:00) already exists.
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2458)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2158)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:291)
        at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:432)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:358)
        at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:171)
        at org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:138)
        at org.springframework.jdbc.core.JdbcTemplate.lambda$update$0(JdbcTemplate.java:867)
        at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:617)
        ... 25 common frames omitted  {code}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1180,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63331200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,19/Feb/19 15:02,,,,,,,,,,,,,,,,,,,,,,,"1|y0867j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SPM: External dataset does not work,XP-1181,78618,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,qo794,qo794,19/Feb/19 09:03,06/Nov/20 10:59,22/Feb/21 13:26,27/Feb/19 16:10,,,Pre2020,,Shipping,,,,,,,,,"After introducing XP-762 the dataset is bundled in the application and is not possible to use any other version even though another version of dataset is deployed on the server, the one in the war file is always used. *It affects system tests and also customers facing evns!*",,qo794,,,,,,,,,,,,,,,,,,,,XP-1139,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63417600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y087rb:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMC failover doesn't work when network glitches - issue analysis,XP-1174,78592,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,ll664,ll664,18/Feb/19 10:31,06/Nov/20 10:59,22/Feb/21 13:26,26/Feb/19 09:19,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ Analysis for decision making ]*{color}

During recent problems in XBID PROD with network timeouts, SMC should have been failing over as well, but it haven't.

There are couple of suspicious things:

1. SMC db connection has no timeouts whatsoever. This means the defaults are used - for socket timeouts it's *infinite*/ OS level timeouts may apply - see {{org.postgresql.PGProperty}}
 2. Due to long/infinite timeout, master node didn't fail when updating the table lock. However the update took too long (longer than 15s failover timeout) and slave attempted to take over. The slave failed with weird exception:
{code:java}
Unexpected error occurred in scheduled task.
javax.persistence.OptimisticLockException: Batch update returned unexpected row count from update [0]; actual row count: 0; expected: 1
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.wrapStaleStateException(AbstractEntityManagerImpl.java:1800)
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.convert(AbstractEntityManagerImpl.java:1705)
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.convert(AbstractEntityManagerImpl.java:1677)
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.convert(AbstractEntityManagerImpl.java:1683)
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.flush(AbstractEntityManagerImpl.java:1338)
	at com.deutscheboerse.energy.failover.dao.impl.TableLockDaoJpaImpl.getLock(TableLockDaoJpaImpl.java:61)
	at com.deutscheboerse.energy.failover.dao.impl.TableLockDaoJpaImpl.updateLock(TableLockDaoJpaImpl.java:91)
	at com.deutscheboerse.energy.failover.service.impl.TableLockServiceImpl.updateLock(TableLockServiceImpl.java:90)
	at sun.reflect.GeneratedMethodAccessor146.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:281)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208)
	at com.sun.proxy.$Proxy235.updateLock(Unknown Source)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.hibernate.StaleStateException: Batch update returned unexpected row count from update [0]; actual row count: 0; expected: 1
	at org.hibernate.jdbc.Expectations$BasicExpectation.checkBatched(Expectations.java:81)
	at org.hibernate.jdbc.Expectations$BasicExpectation.verifyOutcome(Expectations.java:73)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.checkRowCounts(BatchingBatch.java:155)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:132)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:114)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:163)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.executeBatch(JdbcCoordinatorImpl.java:226)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:484)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:351)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:350)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:56)
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1258)
	at org.hibernate.jpa.spi.AbstractEntityManagerImpl.flush(AbstractEntityManagerImpl.java:1335)
	... 23 common frames omitted
{code}
For more details see Kibana:
{code:java}
https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:'2019-02-15T04:09:20.230Z',mode:absolute,to:'2019-02-15T04:24:56.541Z'))&_a=(columns:!(logline,beat.hostname,log_level),index:xbid_prod-tomcat,interval:auto,query:(language:lucene,query:'beat.hostname:xbprodsmc*'),sort:!('@timestamp',desc))
{code}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63158400,,,,,,,,,,,,,,,XP-3109,,,Impediment,,,,,,,,,,,18/Feb/19 10:31,,,,,,,,,,,,,,,,,,,,,,,"1|y087ra:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Feb/19 11:42;ll664;The issue analysis showed that this is not an incorrect behavior at all. The exception is rather a false alarm and implementation deficiency of the failover lib. The {{updateLock()}} method doesn't handle {{OptimisticLockException}}, but those happens when two nodes compete on lock row.

Here's how the issue occurs:

1. The Postgres  is lagging due to faulty SAN infrastructure.
2. SMC1 attempts to update the table lock - the request is stuck on the DB level. Note that SMC currently does not have read timeouts set, therefore there's no exception and SMC happily waits a long time till the update is completed. 
3. As the update takes longer than 15s, the SMC2 attempts to take over and reloads the {{TableLock}} entity with certain revision, i.e. 10.
4. SMC2 mutates the entity and attempts DB update.
5. SMC1 finishes the DB updated from step 2. The {{TableLock}} revision is now 11.
6. SMC2 updates the entity with old revision - 10 - and fails on {{OptimisticLockException}}.

As this is just a false alarm, the fix would go to SM 1.5 branch that will be part of XBID 2.0 delivery. No point in hotfixing this in PROD branch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Crossed orderbooks in PROD,XP-1173,78588,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Not a Bug,ll664,ll664,ll664,18/Feb/19 10:13,06/Nov/20 09:04,22/Feb/21 13:26,18/Feb/19 12:37,,,Pre2020,,,,,,,,,,,"Lot's of them :(

{code}
https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:now-7d,mode:quick,to:now))&_a=(columns:!(logline),index:xbid_prod-tomcat,interval:auto,query:(language:lucene,query:'beat.hostname:xbidprodcor*%20AND%20log_level:ERROR%20AND%20name:c.d.e.m.t.v.XbidSoftAsserts'),sort:!(_score,desc))
{code}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63504000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,18/Feb/19 10:13,,,,,,,,,,,,,,,,,,,,,,,"1|000ycl:9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/19 12:36;ll664;False alarm, fixed in develop by XP-452.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 Prepare feedback regarding RTS3SB results and TWG questions - round 4 [deadline monday,XP-1167,78559,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,15/Feb/19 16:24,04/Aug/20 19:15,22/Feb/21 13:26,25/Feb/19 09:08,,,Pre2020,,,,,,,,,,,"*[CUSTOMER ENGAGEMENT]*

TWG PTF 14/2 added during the meeting clarification questions related to the proper understanding of the explanation provided by DBAG 31/1 (highlighted in the file in yellow). Please check the attached file Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190214.docx. We have not processed the file you provided in previous post 14/2 17:13

Will you kindly check the questions in the attached file (including the explanatory ones) and provide the feedback to the complete set of questions?

AC
 analyse questions/requests
 plan and estimate delivery of DBAG Feedback
 communicate date of delivery
 prepare and Review DBAG answers
 coordinate external communication",,tz118,,,,,,,,,,,,,,,,,,,,,,,XP-1071,,,,,,,,,,,,,,,,,,,"15/Feb/19 16:34;tz118;Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190214_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/65804/Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190214_DBAG.docx","21/Feb/19 15:58;tz118;Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190221_DBAG_v1.docx;https://jira.deutsche-boerse.com/secure/attachment/66130/Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190221_DBAG_v1.docx","25/Feb/19 09:07;tz118;Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190225_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/66178/Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190225_DBAG.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62899200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y087rb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/19 15:59;tz118;draft proposal sent for team review and analysis [^Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190221_DBAG_v1.docx] ","25/Feb/19 09:08;tz118;reviewed by PO and after alignment communicated externally ( [^Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190225_DBAG.docx] )",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use xbid-graphx library,XP-1164,78512,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,14/Feb/19 15:20,06/Nov/20 11:34,22/Feb/21 13:26,18/Feb/19 13:09,,,Pre2020,,,,,,,,,,,"We forked [https://github.deutsche-boerse.de/dev/m7.graphx/] into [https://github.deutsche-boerse.de/dev/xbid.graphx] some time ago.

However fixes for XP-244 were committed into {{m7.graphx}} project.

Cherry pick the changes into {{xbid.graphx}} and replace {{com.deutscheboerse.math:graphx}} artifact with {{com.deutscheboerse.math:xbid-graphx}}",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63763200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0867g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH: Ask (ping) Niklas on Tue/Wed about access to ENTESTDWH,XP-1163,78507,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,14/Feb/19 14:12,31/Aug/20 15:39,22/Feb/21 13:26,20/Feb/19 11:21,,,Pre2020,,,,,,,,,,,,,ek176,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63331200,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0867c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Feb/19 11:21;ll664;SSH works, closing.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 15] Deliver Sprint Increment,XP-1151,78482,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,xu897,jj069,14/Feb/19 08:53,06/Nov/20 10:14,22/Feb/21 13:26,21/Feb/19 13:19,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,jj069,qo794,,,,,,,,,,,,,,,,,,,,,,XP-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63244800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y087r4:j",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 15 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/19 09:47;qo794;SPM release is constantly failing due to XP-1192, so only XBID and report-tool released. Tosca tests not executed.","21/Feb/19 11:02;qo794;Release notes: https://github.deutsche-boerse.de/dev/xbid-product/blob/develop/CHANGELOG.md",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Merge obk improvements to 2.0, evaluate current test coverage ",XP-1149,78449,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,qz412,qz412,13/Feb/19 11:03,04/Aug/20 19:15,22/Feb/21 13:26,21/Feb/19 09:06,,,Pre2020,,,,,,,,,,,"AC:
 * The orderbook improvements are merged into 2.0 and prepared for UAT
 * The Scientist run in the past is understood and evaluated (are the findings sufficient, do we need more?) 
 * Current test coverage is considered and if lacking completely or in certain areas:
 ** The effort needed is evaluated
 ** The required test task(s) are created and discussed with PO for prioritization",,ll664,qz412,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1191,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63331200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ycg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master-math,master,develop-math,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"18/Feb/19 09:55;tz118;following described changes are linked or shall be analyzed (and eventually considered) in reference to the OBK improvements:

*HLS100*
Change Request(s):
XBID-2933 CR083 Recall and Cancel
XBID-3770 ASR014 Analysis on Removal of OBK Limitations
Batch 4 container(s):
XBID-3604 HLS100 - “Asynchronous public order books delta reports” functionality not specified

*DFS510*
Change Request(s):
CR083 XBID-2933 Recall and Cancel
ASR014 XBID-3770 Analysis on Removal of OBK Limitations
CR ID 45 Closure of internal Interconnectors (XBID-3536)
Batch 4 container(s):
 XBID-1919 DFS510 - Incorrect attribute value in SystemInfoResp message
XBID-3135 DFS510, DFS700 - State and tradingPhase attributes
XBID-3136 DFS510 - SMOD action code
XBID-3152 DFS510 - Login/Logout Request
XBID-3187 DFS510 - UADD is always propagated when order enters order book successfully
XBID-3195 DFS510 - RevisionNo initial value
XBID-3304 DFS510 - Rejection of OrdrModify in case it contains multiple modifications for the same order
XBID-3534 DFS510 - TradeCaptureReport contractPhase CLSD
XBID-3547 DFS510 - Trade retrieval period
XBID-3550 DFS510 - chapters 2-4 review
XBID-3575 DFS510 - SOB PMI  schema version in DFS510 & XSD files
XBID-3578 DFS510 - section 5.5.7 TradeCaptureReq - “recallGrantedTime”
XBID-3583 DFS510 - exGTD OrderEntry attribute clarification
XBID-3617 DFS510 - Table 1 Standard header – update
","20/Feb/19 10:11;ll664;For the scientist:

An additional set of tests needs to be run in order to verify implementation correctnes - XP-1188 created for that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide clean version of ASR003 - Technical proposal,XP-1140,78414,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,zi174,tz118,tz118,12/Feb/19 13:31,04/Aug/20 19:16,22/Feb/21 13:26,25/Feb/19 11:06,,,Pre2020,,,,,,,,,,,"For ASR003 – Technical Proposal, DBAG will provide clean document once the clarification with XTG is finalized

AC
 - XTG clarification is final (outcome of the clarification to be put somewhere else than ASR003 TC)
 - document updated if needed
 - send for review and acceptance internally
 - coordinate external communication",,qm925,radeale,tz118,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/19 15:38;radeale;ASR003 - Technical Proposal_v1.0_CLEAN.docx;https://jira.deutsche-boerse.com/secure/attachment/65801/ASR003+-+Technical+Proposal_v1.0_CLEAN.docx","14/Feb/19 15:18;qm925;ASR003 - Technical Proposal_v1.0_commented_TWG_PTF_20190131.docx;https://jira.deutsche-boerse.com/secure/attachment/65745/ASR003+-+Technical+Proposal_v1.0_commented_TWG_PTF_20190131.docx","15/Feb/19 15:30;zi174;ASR003 - Technical Proposal_v1.0_commented_TWG_PTF_20190131_CLEAN.docx;https://jira.deutsche-boerse.com/secure/attachment/65800/ASR003+-+Technical+Proposal_v1.0_commented_TWG_PTF_20190131_CLEAN.docx","19/Feb/19 16:44;qm925;ASR003 - Technical Proposal_v2.0_CLEAN_SH.docx;https://jira.deutsche-boerse.com/secure/attachment/65935/ASR003+-+Technical+Proposal_v2.0_CLEAN_SH.docx","22/Feb/19 12:27;qm925;ASR003 - Technical Proposal_v2.0_final.docx;https://jira.deutsche-boerse.com/secure/attachment/66153/ASR003+-+Technical+Proposal_v2.0_final.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62899200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0863b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 15 [S],Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Feb/19 11:32;radeale;Stefan asked to provide the document...","14/Feb/19 14:03;radeale;...and he doesn't know. So I asked Simona, so let's wait!","14/Feb/19 14:40;tz118;I know that I do not have the latest Version of this document. :)TWG PMO seems to forgot to send it.","14/Feb/19 14:59;qm925;Dear all,

I have attached the latest version of ASR003 - Technical proposal, which is also available in XBID-1705. 

Please see a comment from J. Zavada (31.01.2019): _We have also proceed with the review of ASR003, there is one comment still being clarified by XTG, but to speed up please see the input on behalf of TWG FTF_

Let me know in case you need some more information.

Best regards,
Simona","14/Feb/19 15:14;tz118;Hi Simona, 

actually during the TWG call on 4.2. Jiri updated online this document and updated comments. I think he forgot to send it to us. 
[~radeale]We can ask per email or directly during the call on Monday.
Thank you.
Best,
Stefan","14/Feb/19 15:22;qm925;Hi Stefan,

They have uploaded the document on 04.02. - just the naming convention is still 31.01.
I have re-uploaded the document again just now, for just in case. 
Since then, no other exchanges have been made. Please check with Patrik if they have discussed something additionally on XTG level

Best regards,
Simona
","14/Feb/19 15:31;tz118;
Ah ok, thank you, Simona for clarification. Confusing versioning  :)","15/Feb/19 15:39;radeale;I made a few formatting changes atop of the Jakub's clean version, no content changes:

 [^ASR003 - Technical Proposal_v1.0_CLEAN.docx] 

[~qm925], please check whether the versioning etc. is correct and doesn't need changes :)","15/Feb/19 15:48;zi174;As we discussed on the Friday's TWG alignment. The customer shall be informed that XTG feedback will not be part of this document and if necessary, the feedback will be tracked in a different ticket (opt. in a different document).","19/Feb/19 17:15;qm925;Dear all,

I made some minor admin changes and increased the version number, please see attached. 

I also inserted one comment on p. 3 where it says ""This is a change request to the following..."". This is not a change request as stipulated in the contracts.

[~rg535], could you please check as well?

Best regards,
Simona","20/Feb/19 16:13;zi174;Waiting for Suzanna's feedback.","22/Feb/19 12:29;qm925;Dear all,

I attached final version  [^ASR003 - Technical Proposal_v2.0_final.docx]. The first page has been removed as this not a CR or ASR and it was not necessary. 

Best regards,
Simona","25/Feb/19 11:03;qm925;The clean version has been provided in XBID-1705",,,,,,,,,,,,,,,,,,,,,,,,,
Dataset Generator - Additional fields,XP-1139,78412,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,radeale,radeale,12/Feb/19 12:53,06/Nov/20 11:34,22/Feb/21 13:26,26/Feb/19 14:13,,,Pre2020,,Capacity,,,,,,,,,"* Add support for the EIC Endpoint field for TSOs (CMM RefData). Currently it is supported only for DIs.
* Add support for the Opens At field for Interconnectors (CMM RefData). Currently the default value is 11:00 and this cannot be override in the dataset.

_Acceptance criteria:_
Test: Input various sensible values into the dataset excel and check whether they are correctly reflected in the deployed configuration.

Original ticket: XP-1101",,qo794,qz412,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/19 08:51;tm431;RefData changes for  2.0.docx;https://jira.deutsche-boerse.com/secure/attachment/65763/RefData+changes+for++2.0.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62726400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0863b:x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 15 [S],Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1351-dataset-RTS3SB-for-PerfTestsR2-0,XP-4276-split-io,XP-4276-new-format,develop,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Feb/19 10:13;radeale;Suggested SP: 3","15/Feb/19 08:50;tm431;Add support also for new fields which will be in rel. 2.0

1) Ccp type

2) FTC grouping per All DAs or per ALL ICs, is in 2.0 possible also for following file types
 for SHC, SHS - 'All Delivery Areas' or 'Per delivery area'
 for SXS - 'All Interconnectors' or 'Per interconnector'

 

see attached word document where the changes are higligted.

 

increasing story points to 4

 ","15/Feb/19 14:04;radeale;Regarding point 2) - Please introduce a new column into the dataset generator named ""Grouping"", possible values: DA, IC.

This adheres to how it is done in the SM.

Any other data than DA and IS are ignored without hindering the dataset generation.","18/Feb/19 10:00;qo794;Customers provided the new dataset in a completely different excel format ([~tm431] please attach it here). Needed to discuss with PO how to proceed:
# rewrite the dataset generator
# return to the customers to provide the dataset in our format
# manually convert the new excel to the old format","18/Feb/19 10:35;radeale;As I see it, the second solution is preferred one.","18/Feb/19 11:16;qo794;[~qz412]/[~ei349] please have a look at my comment above, thx.","18/Feb/19 11:21;qz412;Hi, please return it back to them, we definitely are not doing any changes / postprocessing on our side. Feel free to explain that we have the dataset load automated and therefore we need to keep the structure as previously provided, will sound fancy and nice. Thx :).","19/Feb/19 12:46;tm431;Add Also support for SOB, MEMBER Trade Recall & Cancel SUPPORTED x UNSUPPORTED","21/Feb/19 09:38;qo794;Implementation done, only testing is missing, it's blocked by XP-1181","26/Feb/19 14:13;qo794;The grouping feature works, no new column has been introduced so far (can be improved in the future though) - when both DA and IC columns are left empty, the grouping is applied.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deployment failing on Syt3 due to journaler,XP-1127,78388,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,tr866,tr866,11/Feb/19 16:49,06/Nov/20 10:59,22/Feb/21 13:26,12/Feb/19 13:11,,,Pre2020,,Trading,,,,,,,,,"Deployment of XBID 1.6.0.28 failing on Systemtest 3 with the following exception in core logfile:
{noformat}
2019-02-11T15:21:32.214Z [overScheduler-1][SCHEDULER][244e03e0] WARN  o.h.orm.deprecation - HHH90000022: Hibernate's legacy org.hibernate.Criteria API is deprecated; use the JPA javax.persistence.criteria.CriteriaQuery instead
2019-02-11T15:21:32.216Z [overScheduler-1][SCHEDULER][244e03e0] INFO  c.d.e.m.M7LifecycleManagerImpl - redoing messages after 0...
2019-02-11T15:21:32.219Z [nio-8080-exec-2][][] INFO  o.s.w.s.DispatcherServlet - Completed initialization in 17 ms
2019-02-11T15:21:32.242Z [Journaller][SYSTEM_TASK][65c49d57] WARN  n.o.c.q.i.s.SingleChronicleQueueBuilder - Failback to readonly tablestore
net.openhft.chronicle.core.io.IORuntimeException: file=/xbid/journal/metadata.cq4t
        at net.openhft.chronicle.queue.impl.table.SingleTableBuilder.build(SingleTableBuilder.java:138)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueBuilder.initializeMetadata(SingleChronicleQueueBuilder.java:425)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueBuilder.preBuild(SingleChronicleQueueBuilder.java:907)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueBuilder.build(SingleChronicleQueueBuilder.java:322)
        at net.openhft.chronicle.queue.ChronicleQueue.single(ChronicleQueue.java:72)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.lambda$createQueueFactory$0(Journaler.java:109)
        at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQueueJournaler.start(ChronicleQueueJournaler.java:32)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.doOnEvent(Journaler.java:55)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.doOnEvent(Journaler.java:24)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:63)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:29)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Permission denied
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.createNewFile(File.java:1012)
        at net.openhft.chronicle.queue.impl.table.SingleTableBuilder.build(SingleTableBuilder.java:103)
        ... 14 common frames omitted
2019-02-11T15:21:32.266Z [Journaller][][] ERROR c.d.e.m.c.e.XbidExceptionHandler - Handling error on event 'com.deutscheboerse.energy.m7.core.in.RequestEvent@2cef06a8[error=<null>,input=Input:com.deutscheboerse.energy.m7.failover.StartupTask@33bc1060,request=<null>]'
java.lang.UnsupportedOperationException: Read only
        at net.openhft.chronicle.queue.impl.table.ReadonlyTableStore.doWithExclusiveLock(ReadonlyTableStore.java:53)
        at net.openhft.chronicle.queue.impl.single.TableDirectoryListing.init(TableDirectoryListing.java:41)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueue.<init>(SingleChronicleQueue.java:163)
        at net.openhft.chronicle.queue.impl.single.SingleChronicleQueueBuilder.build(SingleChronicleQueueBuilder.java:327)
        at net.openhft.chronicle.queue.ChronicleQueue.single(ChronicleQueue.java:72)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.lambda$createQueueFactory$0(Journaler.java:109)
        at com.deutscheboerse.energy.m7.core.in.journal.ChronicleQueueJournaler.start(ChronicleQueueJournaler.java:32)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.doOnEvent(Journaler.java:55)
        at com.deutscheboerse.energy.m7.core.in.journal.Journaler.doOnEvent(Journaler.java:24)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:63)
        at com.deutscheboerse.energy.m7.core.AbstractEventHandler.onEvent(AbstractEventHandler.java:29)
        at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
2019-02-11T15:21:32.267Z [Journaller][][] WARN  c.d.e.m.s.ApplicationShutdown - shutdown was triggered
2019-02-11T15:21:32.284Z [Thread-9][][] INFO  o.s.a.r.l.SimpleMessageListenerContainer - Waiting for workers to finish.
2019-02-11T15:21:32.326Z [nio-8080-exec-1][][] ERROR o.s.b.w.s.s.ErrorPageFilter - Forwarding to error page from request [/jolokia/read] due to exception [null]
java.lang.NullPointerException: null
        at org.springframework.boot.web.servlet.support.ErrorPageFilter.handleErrorStatus(ErrorPageFilter.java:164)
        at org.springframework.boot.web.servlet.support.ErrorPageFilter.doFilter(ErrorPageFilter.java:132)
        at org.springframework.boot.web.servlet.support.ErrorPageFilter.access$000(ErrorPageFilter.java:66)
        at org.springframework.boot.web.servlet.support.ErrorPageFilter$1.doFilterInternal(ErrorPageFilter.java:105)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.springframework.boot.web.servlet.support.ErrorPageFilter.doFilter(ErrorPageFilter.java:123)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
        at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:154)
        at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:122)
        at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:107)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
        at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
       at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:493)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
        at org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:650)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
        at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:800)
        at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
        at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:806)
        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1498)
        at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:745)
2019-02-11T15:21:32.366Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Attempting to connect to: [10.139.41.71:51900, 10.139.41.211:51900]
2019-02-11T15:21:32.378Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Created new connection: ackConnFactory#633e5b16:0/SimpleConnection@53e263a0 [delegate=amqp://comxerv@10.139.41.71:51900/ext, localPort= 38008]
2019-02-11T15:21:32.390Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Attempting to connect to: [10.139.41.71:51900, 10.139.41.211:51900]
2019-02-11T15:21:32.410Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Created new connection: respConnFactory#1a5dbc0b:0/SimpleConnection@40575701 [delegate=amqp://comxerv@10.139.41.71:51900/ext, localPort= 38010]
2019-02-11T15:21:32.417Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Attempting to connect to: [10.139.41.71:51901, 10.139.41.211:51901]
2019-02-11T15:21:32.425Z [nio-8080-exec-2][][] INFO  o.s.a.r.c.CachingConnectionFactory - Created new connection: integOutConnFactory#7bfdbb47:0/SimpleConnection@7a8f7313 [delegate=amqp://comxerv@10.139.41.71:51901/int, localPort= 54552]
2019-02-11T15:21:32.433Z [overScheduler-1][SCHEDULER][244e03e0] INFO  c.d.e.m.M7LifecycleManagerImpl - 0 inputs published to redo

{noformat}",,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-1971,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64022400,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y085hs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/19 17:16;tr866;It looks related to the linked ticket TECHLOG-1971
we noticed that the owner of the /.../journal/ folder on Syt3 is root
{noformat}drwxr-xr-x 4 root   root        4096 20. dub  2018 journal{noformat}
where as for example on DST or PERF environment, where there are no problems with deployment the folder is owned by tomcat user
{noformat}drwxrwxr-x 3 tomcat tomcat  4096 11. úno 01.00 journal{noformat}","12/Feb/19 13:11;tr866;Issue solved in linked TECHLOG-1971",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM TSO Admin GUI Test - extended cucumber smoke test - part1,XP-1126,78385,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,od044,od044,11/Feb/19 15:16,04/Aug/20 19:35,22/Feb/21 13:26,20/Feb/19 14:58,,,Pre2020,,Capacity,,,,,,,,,"Extended - TSO admin smoke test - Part1:

Login like TSO Admin
 _GUI validations_
TSO admin page is active :
 # Menu Bar:
 ** Main
 ** Preferences
 ** Interconnectors
 ** Reports
 ** Help
 ** Reload with img.
 # Verify Submenu list > navigate trough
 # Capacity Overview panel is present
 ** Capacity Overview: overview_today tab is active
 ** Capacity Overview: overview_tommorrow tab is present not active
 ** Buttons are not present - Import, Export,
 ** Buttons present - Update, Reset, Submit
 ** All Contracts are visible - active, inactive...
 # Administration panel is present
Navigate through all tabs, they are in proper order and verify content
 ** Message
 ** Contract Modification,
 ** Contract Halt
 ** Direction Halt
 ** Service halt
 ** Upload
 ** Download",,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63849600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0854s:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 14,Home Office Team Sprint 15 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Feb/19 18:16;od044;Done,

PR: https://github.deutsche-boerse.de/dev/xbid-test/pull/145",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DST SCC testing in March 2019,XP-1120,78363,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,de698,tz118,tz118,11/Feb/19 09:51,31/Aug/20 15:38,22/Feb/21 13:26,25/Mar/19 10:15,XBID 1.5.9,,XBID 1.5.9,,,,,,,support_request,,,,"Dear DBAG,

 

As part of the regular processes for DST testing, OPSCOM would like to request related DBAG support for DST SCC testing in March 2019.

 

Find below the agreed high-level execution timeline of related testing activities:
 * 2019/02/25-2019/03/01: 1st DST test run
 * 2019/03/04-2019/03/15: DBAG bug fix period (if needed)
 * 2019/03/18-2019/03/22: 2nd DST test run

 

In order to proceed with it, find below relevant information OPSCOM has gathered for this request:

 
 * *Environment: CuTe PX* (as it was indicated to be the only CuTe environment prepared for DST testing)
 * *Release versions:* *XBID 1.5.9 and SM 1.0.39* (versions that will most likely be in PROD during DST day)
 * *Exact time travel details:*
 * For the first run, DBAG to time travel on *Monday 25/02/2019 09:00* (real time) to *27/03/2019 21:00* (system time)
 * For the second run, DBAG to time travel on *Monday 18/03/2019 09:00* (real time) to *27/03/2019 21:00* (system time)

 * *NTP Server:* as primary ""NTP"" server for ""XBID CUTE"" environment will be used host:""xbcutsntp1.deutsche-boerse.de"" - IP address within the MPLS range is 10.103.128.11, port 123 (UDP) {color:#00875a}- confirm with TechOps, is it the right server to connect and change time?{color}

 

We have tried to complete the template that has been circulated, although we understand it still under discussion:

 

*Version {color:#00875a}- confirm with Pavel Rehak{color}*
 * XBID_VERSION=1.5.9
 * SPM_VERSION=1.0.39
 * REP_VERSION=Same that in PROD
 * PMI_VERSION=Same that in PROD
 * PMI_ARCHIVER_VERSION=Same that in PROD
 * DATA_SET_COR=Same that in PROD
 * DATA_SET_VERSION=Same that in PROD
 * ComTrader=Same that in PROD

 ** 

*Environment*

CuTe PX

 

*DB clean up {color:#00875a}- response should be DB clean up NO{color}*

Yes, with the following time travel:
 * For the first run, DBAG to time travel on Monday 25/02/2019 09:00 (real time) to 27/03/2019 21:00 (system time)
 * For the second run, DBAG to time travel on Monday 18/03/2019 09:00 (real time) to 27/03/2019 21:00 (system time)

 

*Date*

25/02/2019 at 09:00 (first time)

18/03/2019 at 09:00 (second time)

 

*Set the password expiration date for all users to x+90 days and reset passwords to default value*

Yes

 

*Restore DB snapshot*

It is understood that this is not needed, as we want to keep current setup

 

*Restore LDIF*

It is understood that this is not needed, as we want to keep current setup",,de698,radeale,tm431,tz118,,,,,,,";18/Mar/19 10:15;tm431;50400",,,0,50400,,,0,50400,,,,,XBID-4287,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60393600,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08c1b:l",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 15 [S],Alpha Team Sprint 16 [S],Home Office Team 17 [S],Alpha Team Sprint 18 [S],Home Office Team 19 [S],Alpha Team Sprint 20 [S],,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/19 15:57;de698;asked for confirmation in external jira: DB clean up should be NO","13/Feb/19 12:58;de698;service Jira set up: https://jira.deutsche-boerse.com/browse/SERVICE-2639","25/Feb/19 08:09;de698;Note: this Jira contains also request for second test run
 * For the second run, DBAG to time travel on Monday 18/03/2019 09:00 (real time) to 27/03/2019 21:00 (system time)","25/Feb/19 10:49;de698;Time travel in CuTePX for the *first run* is finished, customer informed.

There were couple of issues with the service ticket - first do the timetravel step, then Run SMC cleanup script, and check the script for correct syntax when copying it. Please be aware of it next time. ","26/Feb/19 11:06;de698;service Jira for 2nd run set up https://jira.deutsche-boerse.com/browse/SERVICE-2706","19/Mar/19 09:50;tm431;All time travel request were done properly. Awaiting customer reaction","22/Mar/19 10:26;de698;From XBID-4287: ""On Monday 25/3 Morning we will stop everything, do the time change to actual time, restore DB snapshot from 22/02, start everything and let you know""

Service ticket for this change is approved: https://jira.deutsche-boerse.com/browse/SERVICE-2838","25/Mar/19 10:13;de698;Time travel to real time completed.

Service ticket closed.

Customer informed. External Jira Resolved.","25/Mar/19 10:15;de698;2 test runs with time travel and restoring of real time completed.","25/Mar/19 15:47;tm431;External ticket closed. thanx everybody for great cooperation :)",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Revive Dataset Generator,XP-1101,78273,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tm431,tm431,tm431,07/Feb/19 10:49,06/Nov/20 11:34,22/Feb/21 13:26,25/Feb/19 14:45,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ RETAINED DATASET DEPLOYMENT ]*{color}

We will get new excel dataset file from customers, so Dataset Generator should be prepared and in good condition

AC:
 * Revive datastet generator, test that the excel is in line with the import
 * Check that the .ldfis generated are correct",,od044,qo794,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-1986,XP-1139,,,,,,"11/Feb/19 09:49;tm431;Dataset-Template-1.3-v10.3_inclDBAG users.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65577/Dataset-Template-1.3-v10.3_inclDBAG+users.xlsx","11/Feb/19 15:56;radeale;Dataset-Template-1.3-v10.5_inclDBAG users.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65616/Dataset-Template-1.3-v10.5_inclDBAG+users.xlsx","12/Feb/19 12:48;radeale;Dataset-Template-1.3-v10.7_inclDBAG users.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65635/Dataset-Template-1.3-v10.7_inclDBAG+users.xlsx","18/Feb/19 15:30;radeale;Dataset-Template-1.3-v10.9_DBAG.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65855/Dataset-Template-1.3-v10.9_DBAG.xlsx","11/Feb/19 15:57;qo794;file.shipping.ldif;https://jira.deutsche-boerse.com/secure/attachment/65617/file.shipping.ldif","11/Feb/19 15:57;qo794;file.trading.ldif;https://jira.deutsche-boerse.com/secure/attachment/65618/file.trading.ldif",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63331200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 14,Home Office Team Sprint 15 [S],Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Feb/19 09:33;qo794;[~tm431] please provide an excel file with a dataset to test, thanks.","11/Feb/19 09:51;tm431;[~qo794] exampl of excel file attached, included are DBAG users for rel2.0 UAT testing (in green background colour) let's see what happens :)","11/Feb/19 10:30;qo794;LDIF files generated: [^file.shipping.ldif]  [^file.trading.ldif] ","11/Feb/19 12:06;radeale;Please find attached a new version of the dataset.

Changes:
CMM BG +QA-BAL-ALL-----M+ to be used instead of +01-SADMIN-ALL--C+ (this one doesn't exist in this dataset, but QA-BAL-ALL-----M can serve the purpose).
+SADMIN01+ admin added (atop to SADMIN02, 03, 03)

 [^Dataset-Template-1.3-v10.4_inclDBAG users.xlsx] ","11/Feb/19 12:10;tm431;As of the LDIF password, I think we should introduce *xbidTest01!* as default one for every user. This is the default pwd client is used for in all LIPAs, CUTEes For both SOB/CMM and SPM modules","11/Feb/19 13:27;od044;Error due new deployment 

{code}
Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-02-11T12:19:04.547Z [ost-startStop-1][][] ERROR o.s.b.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'simpleRunner' defined in class path resource [spring-application.xml]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: cannot create implicit interconne
ctor for a virtual area
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1745)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)
        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:846)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546)
        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)
        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:157)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:137)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:91)
        at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:171)
        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)
        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
        at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)
        at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)
        at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)
        at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:985)
        at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1857)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: cannot create implicit interconnector for a virtual area
{code}","11/Feb/19 14:56;od044;Additional error

{code}
Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-02-11T13:52:16.749Z [ost-startStop-1][][] ERROR o.s.b.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'simpleRunner' defined in class path resource [spring-application.xml]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Switch area1/area2 parameters. Only area1 can be virtual during creating VDA-DA interconnector. Current virtual DA in area2: 'TSVDA1---------R'.
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1745)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)
        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:846)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546)
        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)
        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:157)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:137)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:91)
        at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:171)
        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)
        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
        at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)
        at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)
        at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)
        at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:985)
        at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1857)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Switch area1/area2 parameters. Only area1 can be virtual during creating VDA-DA interconnector. Current virtual DA in area2: 'TSVDA1---------R'.

{code}","11/Feb/19 15:39;tm431;additional error

 
{code:java}
Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-02-11T14:32:18.196Z [ost-startStop-1][][] ERROR o.s.b.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'simpleRunner' defined in class path resource [spring-application.xml]: Invocation of init method failed; nested exception is javax.persistence.EntityExistsException: A different object with the same identifier value was already associated with the session : [com.deutscheboerse.energy.m7.cmm.model.party.User#SADMIN01]
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1745)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)
        at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:846)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546)
        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
        at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:775)
        at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
        at org.springframework.boot.SpringApplication.run(SpringApplication.java:316)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.run(SpringBootServletInitializer.java:157)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.createRootApplicationContext(SpringBootServletInitializer.java:137)
        at org.springframework.boot.web.servlet.support.SpringBootServletInitializer.onStartup(SpringBootServletInitializer.java:91)
        at org.springframework.web.SpringServletContainerInitializer.onStartup(SpringServletContainerInitializer.java:171)
        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5245)
        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)
        at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)
        at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)
        at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)
        at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:985)
        at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1857)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: javax.persistence.EntityExistsException: A different object with the same identifier value was already associated with the session : [com.deutscheboerse.energy.m7.cmm.model.party.User#SADMIN01]
        at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:123)
        at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:181)
        at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:188)
        at org.hibernate.internal.SessionImpl.firePersist(SessionImpl.java:807)
        at org.hibernate.internal.SessionImpl.persist(SessionImpl.java:785)
        at com.deutscheboerse.energy.m7.test.GridCreatorService.persist(GridCreatorService.java:746)
:

 {code}","11/Feb/19 15:56;radeale;Fixed version, SADMIN01 excluded, as it is present by default.

 [^Dataset-Template-1.3-v10.5_inclDBAG users.xlsx] ","12/Feb/19 08:24;tm431;Deployemnt to Perf successful. Techlog Jira for LDIF file upload created.","12/Feb/19 09:10;tm431;questions.

1) We create users with *fake*-email@xx.xx*.example.com* adresses. Is this correct? I think fake is enough we do not need .example.com at the end of eamil adress

2) SADMIN has email [user@xbid.deutsche-boerse.com|mailto:user@xbid.deutsche-boerse.com]

3) how about sft configuration? CMI: tbxi035_config SPM: ftp_config are they rewritten after dataset is deployed? I thin we should keep them before the deployment and restore them after.

4) what about ECP configuration? is it rewritten?

5) we need to try whether [tso01@xbid.deutsche-boerse.com  |mailto:tso01@xbid.deutsche-boerse.com%C2%A0]works","12/Feb/19 10:08;radeale;Observations from testing the CMM part:
SADMIN01 - password is *xbidtest01*
SADMIN02, 03 - neither *xbidtest01* nor *xbidTest01!* works :(

ad 1) - I think it is better to leave it as it is, i.e. to add the _example.com_ part.
Maybe we could use the procedure techops use, i.e. to add ""fake-"" in front of the email address domain.
https://confluence.energy.svc.dbgcloud.io/display/ET/Copy+data+from+one+DB+to+another

ad 2) I propose to use _elia@xbid-test.deutsche-boerse.com_ as the test email, it is working.

ad 3) SFTP config should be according to the environment, i.e.:
{code}#please replace lipa with actual used environment
update tbxi035_config set config_value = replace(config_value, '_lipa', '_syt2');
...
\q
 
psql -p 20750 -dxbsyt2spm
...
update ftp_config set ftp_user = replace(ftp_user, '_lipa', '_syt2'); {code}

ad 4) I believe nothing has to be done with this, it is up to the cusomers to supply working EIC codes in case they want to actually test the feature.

ad 5) It doesn't, see point 2 :)","12/Feb/19 12:00;qo794;Dataset generator works perfectly, can be used for a further customer's defined dataset provided via an excel file. The only thing that needs to be modified manually is VDA-PDA IC definition - it's done via a template in the project.","12/Feb/19 12:06;qo794;One thing I've noticed that is not (and has never been) supported by the dataset generator is the *Opens At* field in interconnectors. I think the generated dataset should be checked against the excel file whether there are more unsupported fields like that.","12/Feb/19 12:38;radeale;Version 7 of the dataset:
- elia@xbid-test.deutsche-boerse.com added as the CMM SADMIN02 email address

 [^Dataset-Template-1.3-v10.7_inclDBAG users.xlsx] ","12/Feb/19 13:02;tm431;reseting of pwd to [elia@xbid-test.deutsche-boerse.com|mailto:elia@xbid-test.deutsche-boerse.com] works OK. tested on SADMI02 user","18/Feb/19 15:30;radeale;A new version with explanation notes added to the default values.

[^Dataset-Template-1.3-v10.9_DBAG.xlsx] ","20/Feb/19 13:13;radeale;The current template updated, column Grouping.

S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Tools\Dataset Generator\Dataset-Template-1.3-v9_DBAG.xlsx",,,,,,,,,,,,,,,,,,,,
Refactor SLA report,XP-1099,78262,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,uv683,uv683,07/Feb/19 09:43,04/Aug/20 19:35,22/Feb/21 13:26,21/Feb/19 08:33,,,Pre2020,,,,,,,,,,,"Investigate how refactoring was done in creditpoint report and perform major refactoring of SLA XP-921 in the similar manner. This has to be done after tests 

Prefferable language is Kotlin.",,eh941,qz412,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63849600,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08544:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/Feb/19 10:39;qz412;[~eh941] - please add an estimate here","14/Feb/19 11:14;eh941;Changed to 3 story points
Already spent 3 MD on it",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 14] Deliver Sprint Increment,XP-1094,78257,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,xu897,xu897,07/Feb/19 09:25,06/Nov/20 10:14,22/Feb/21 13:26,15/Feb/19 14:30,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,xu897,,,,,,,,,,,,,,,,,,,,,,,XP-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yct:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve Tosca data set IC capacity fix,XP-1092,78244,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,tr866,radeale,radeale,06/Feb/19 17:22,06/Nov/20 11:34,22/Feb/21 13:26,08/Feb/19 17:49,,,Pre2020,,Capacity,,,,,,,,,"1. Please fix _Tosca_ data set:
CMM IC configuration (table _cmm_235_interconnector_configuration_), where max/min capacity and max quantity is 1073741823 it needs to be 1073741822 due to validation introduced with XP-244.
2. Check whether this also affects other used data sets.

For each such data set fixed:
1. Deploy Tosca data set to DST env and run the Tosca quick show test
2. If also other data sets were fixed,  deploy each to a test env => deploy is successful, verified with login ans quick check of each module

Reasoning: 
Otherwise deployment with DB cleanup fails (XBID 1.6.0.27) with the following error in the log:
{code}Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2019-02-06T16:09:37.367Z [ost-startStop-1][][] ERROR o.s.b.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'simpleRunner' defined in class path resource [spring-application.xml]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: maxQuantity has to less or equal than 1073741822
       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1745)
       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576)
       at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498){code}",,radeale,tr866,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64281600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zk",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"06/Feb/19 17:22;radeale;Suggested story points 2.","08/Feb/19 09:23;ek176;No code change was needed. Released dataset (1.3.47). Released xbid-core (1.6.0.27).

Deployment to DST was performed.","08/Feb/19 17:46;tr866;Successfully tested with version XB 1.6.0.28, DATA_SET_VERSION=1.3.47
Deployment finished with success with 2 different datasets xbid-data-customer-env and tosca-fake. The exception didn't occur anymore in the core logfile and core was successfully started during the deployment. Login to webguis of all modules was working fine too and Tosca Quick Show tested was ran.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AlarmTilt - update user configuration,XP-1091,78233,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,06/Feb/19 14:59,06/Nov/20 12:48,22/Feb/21 13:26,18/Feb/19 17:02,,,Pre2020,,,,,,,AlarmTILT,waiting-3rdparty,,,"AC
 - users in Simu and Prod have same setup as before AT url migration - focus on custom roles
 - at least 4 eyes principle applied
 - OPSCOM (M. Vancura) is consulted on when the setup should be aligned",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/19 17:13;tr866;AlarmTilt XP-1091.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65806/AlarmTilt+XP-1091.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63417600,,,,,,,,,,,,,,,XP-4089,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zp",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Feb/19 16:02;tz118;users in Simu and Prod have same setup as before AT url migration - focus on custom roles --> *DONE*
at least 4 eyes principle applied ---> *new url login does not work, waiting for AT*
OPSCOM (M. Vancura) is consulted on when the setup should be aligned ---> *DONE, communicated that setup will be done during this week*","14/Feb/19 14:37;tz118;[~tr866], please review","18/Feb/19 15:34;tz118;Thanks, [~tr866], very good. I will have a look and communicate externally.","18/Feb/19 17:02;tz118;users in Simu and Prod have same setup as before AT url migration - focus on custom roles --> DONE
at least 4 eyes principle applied ---> DONE
OPSCOM (M. Vancura) is consulted on when the setup should be aligned ---> DONE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SLA reports for January,XP-1072,78076,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,qz412,01/Feb/19 09:55,30/Apr/19 20:08,22/Feb/21 13:26,07/Feb/19 09:05,XBID 1.5.9,,XBID 1.5.9,,SLA Report Tool,,,,,,,,,Please generate the Jan SLA reports and provide them to the customers by Feb 5th,,qz412,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/19 09:01;uv683;XBID Performance and SM SLA Reporting January 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65461/XBID+Performance+and+SM+SLA+Reporting+January+2019.xlsx","07/Feb/19 09:01;uv683;XBID Service Boundary Reporting January 2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65462/XBID+Service+Boundary+Reporting+January+2019.xlsx","07/Feb/19 09:01;uv683;XBID_Credit_points_report_January_2019.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65460/XBID_Credit_points_report_January_2019.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zzi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/19 09:02;uv683;[~gd553] [~qm925] reports for January are attached. Please find them on sharepoint as well",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare feedback regarding RTS3SB results and TWG questions - round 3,XP-1071,78063,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,31/Jan/19 17:09,04/Aug/20 19:16,22/Feb/21 13:26,14/Feb/19 17:20,,,Pre2020,,,,,,,,,,,"*[CUSTOMER ENGAGEMENT]*

Jirka Zavada uploaded PTF Response 01/31
 Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190131.docx

AC
 analyse questions/requests
 plan and estimate delivery of DBAG Feedback
 communicate date of delivery
 prepare and Review DBAG answers
 coordinate external communication",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/19 11:25;tz118;65755_Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190214.docx;https://jira.deutsche-boerse.com/secure/attachment/65784/65755_Analysis_of_the_RTS3_Slice_B_results_commented_by_TWG_PTF_20190214.docx","05/Feb/19 13:35;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190131.docx;https://jira.deutsche-boerse.com/secure/attachment/65400/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190131.docx","08/Feb/19 09:47;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190208.docx;https://jira.deutsche-boerse.com/secure/attachment/65522/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190208.docx","11/Feb/19 16:35;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190211.docx;https://jira.deutsche-boerse.com/secure/attachment/65621/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190211.docx","12/Feb/19 17:43;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190212.docx;https://jira.deutsche-boerse.com/secure/attachment/65688/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190212.docx","14/Feb/19 17:20;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190214.docx;https://jira.deutsche-boerse.com/secure/attachment/65751/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190214.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63763200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zq",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/19 17:38;tz118;proposed answers sent for internal review","14/Feb/19 14:25;tz118;new version udapted based on PO feedback atttached   [^Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_20190214.docx] ","14/Feb/19 17:20;tz118;
communicated to the customers",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"AlarmTilt - investigate with M-PLify what went wrong in the migration, align the PROD + SIMU setup in the xbid.alarmtilt.net instance with the specs",XP-1068,78028,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,qz412,qz412,31/Jan/19 09:38,06/Nov/20 12:49,22/Feb/21 13:26,06/Feb/19 15:01,,,Pre2020,,,,,,,AlarmTILT,,,,"There are custom roles (PX Directory etc.) missing in the PROD + SIMU setup in the xbid.alarmtilt.net instance with the specs

*DoD:*
 * M-PLify consulted on what went wrong
 * A solution is understood and described here
 * OPSCOM (M. Vancura) is consulted on when the setup should be aligned
 * A task for config fix is created for next sprint",,qz412,radeale,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1091,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-4089,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Feb/19 10:35;tz118;S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\04 User Manuals\MFG500 - Events and Notifications","01/Feb/19 15:25;tz118;Alarmtilt (M-Plify) representative contacted via email, situation described and explained (missing custom roles in SIMU and PROD)","06/Feb/19 15:01;tz118;*DoD:*
 * M-PLify consulted on what went wrong DONE - issue with migration (new AT url) of custom roles 
 * A solution is understood and described here DONE, Solution - custom roles are present in the AT now, modify user setup to follow
 * OPSCOM (M. Vancura) is consulted on when the setup should be aligned - part of the new task
 * A task for config fix is created for next sprint DONE--> XP-1091",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 13] Deliver Sprint Increment,XP-1062,78022,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,xu897,31/Jan/19 09:18,06/Nov/20 10:14,22/Feb/21 13:26,07/Feb/19 09:35,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,cf948,xu897,,,,,,,,,,,,,,,,,,,,,,XP-936,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y083c8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 13 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/19 09:19;cf948;DataSet is incompatible with release of XBID 1.6.0.27, created https://jira.deutsche-boerse.com/browse/XP-1092.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix ports of Reporting engine in Ansible according Techops convention,XP-1059,78019,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,nn481,nn481,nn481,31/Jan/19 09:03,06/Nov/20 09:08,22/Feb/21 13:26,20/Feb/19 08:12,,,Pre2020,,Reporting Engine,,,,,,,,,Port convention document attached.,,nn481,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/19 09:02;nn481;Copy of M7_Environments_2019-01-30.xlsx;https://jira.deutsche-boerse.com/secure/attachment/65275/Copy+of+M7_Environments_2019-01-30.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63331200,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd5:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Feb/19 08:12;qo794;Techops reviewed and merged the changes, the xbid reporting-engine is ready for ansible deployment. Not tested on any env but AWS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Read only role to SOB(core and sob) to enable automatic deployment verification,XP-1047,77988,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,gd553,nn481,nn481,30/Jan/19 10:55,06/Nov/20 11:34,22/Feb/21 13:26,08/Mar/19 10:19,,,Pre2020,,,,,,,,,,,"In order to {color:#00875a}*verify deployment*{color} we need to add read only role (read only user) to core and SOB.

We must do:
 # Analyze the change (size)
 # Estimate workload
 # Alignment with [~qz412], [~rg535]
 # Proposal to customer

----

*+Solution:+*

+Aim of the change:+
 The aim of the change is to introduce read-only _Admin_ _user role_ to the SOB to:
- Use such user in the Deployement verifier
- Monitor the PROD by DBAG
- Use by the NEMOs and TSOs where they see fit

+Current state:+
Currently the CMM and the SM modules offer read-only admin roles for monitoring of the configuration and reference data. The SOB lacks this feature.

+Proposed solution:+
 A new _User Role_ _*Read-only Admin*_ is introduced:
 - The role is available only for the _ADMIN_ Member (the same is for the current _Admin_ User Role)
 - The role has the following Additional Rights:
-- _*Public API*_ - User can access the Public Message Interface (read-only)
 -- _*Reference Data GUI*_ - _User can view the Reference Data_
-- _*Superadmin*_ - _User can view other Admin Users_
 --- It is the same as for the current Admin, but only the view functionality is available. Without this additional user right the user cannot view admin users.
 - Such user has only view functionality available, all active Market and Reference Data operations are disabled for the user
- The user can be used with the automatic deployement verifier

+Affected documents:+
 - DFS700, chapters:
 -- 3.1.1 Create New User
 - DFS700a, sheets:
 -- PX Roles vs Rights - Admin
 -- Public Message Interface
- USM998 in case a new DBAG prod user is created

+Effort Estimate:+
 ANL: 3
 DEV: 7
 TEST: 4
 (Includes regression testing of the current SOB roles)
 Total: 14 MDs",,nn481,qz412,radeale,rg535,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62294400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y8w:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 16,Home Office Team 17 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jan/19 13:49;radeale;What would I like to see:
4. Communicate the proposal to other analysts and interested parties
:)","22/Feb/19 10:29;radeale;+Aim of the change:+
 The aim of the change is to introduce read-only _Admin_ _user role_ to the SOB to:
- Use such user in the Deployement verifier
- Monitor the PROD by DBAG
- Use by the NEMOs and TSOs where they see fit

+Current state:+

Currently the CMM and the SM modules offer read-only admin roles for monitoring of the configuration and reference data. The SOB lacks this feature.

+Proposed solution:+
 A new _User Role_ _*Read-only Admin*_ is introduced:
 - The role is available only for the _ADMIN_ Member (the same is for the current _Admin_ User Role)
 - The role has the following Additional Rights:
-- _*Public API*_ - User can access the Public Message Interface (read-only)
 -- _*Reference Data GUI*_ - _User can view the Reference Data_
-- _*Superadmin*_ - _User can view other Admin Users_
 --- It is the same as for the current Admin, but only the view functionality is available. Without this additional user right the user cannot view admin users.
 - Such user has only view functionality available, all active Market and Reference Data operations are disabled for the user
- The user can be used with the automatic deployement verifier

+Affected documents:+
 - DFS700, chapters:
 -- 3.1.1 Create New User
 - DFS700a, sheets:
 -- PX Roles vs Rights - Admin
 -- Public Message Interface
- USM998 in case a new DBAG prod user is created

+Effort Estimate:+
 ANL: 3
 DEV: 7
 TEST: 4
 (Includes regression testing of the current SOB roles)
 Total: 14 MDs","27/Feb/19 17:14;qz412;Dear Alex, thank you, please make sure you also take the goal of this task (marked in green above) into consideration :).

It is nice and I fully support this enhancement but it may be an overkill.

Thx, Ondra.","04/Mar/19 10:45;radeale;Dear [~rg535] and [~qz412],

the proposal outlined in this comment:
https://jira.deutsche-boerse.com/browse/XP-1047?focusedCommentId=209612&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-209612
has been consulted with the dev as well as with Pavel Řehák and is prepared for your review.

Kind regards,
Alexandr","04/Mar/19 10:52;rg535;[~radeale], is the idea to sell this to the customer? I think, although a good idea, it will be difficult to sell it. Let me know the business idea behind this proposal. Thanks.","04/Mar/19 11:22;radeale;Hi Suzanna,

the implementation would be useful for the customer and for the DBAG:
- DBAG could have a read-only admin user for the production to speed up support in case the need arises (we have the same for the CMM a the SM)
- The user would be extremely useful to use by the DBAG in the deployment verification process
To sum it up, the purpose if this task is to have this option prepared to be offered to the customer if a suitable situation arises, it is currently of no high priority.

Feel free to give me a call,

Best regards,
Alexandr","04/Mar/19 11:32;rg535;[~gd553], please can you coordinate this with Alexandr. I do not see a way to get the effort reimbursed via a CR. I do see that it would be useful and if we want a read only user we will need to request permission from the PXs. Can you check the history. I cannot remember if they declined this when we discussed it as part of R1.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5 PEN Test Findings,XP-1031,77931,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,qz412,qz412,29/Jan/19 10:08,04/Aug/20 19:19,22/Feb/21 13:26,06/Feb/19 16:54,,,Pre2020,,,,,,,,,,,"Deloitte security findings are attached in the .pdf below.

Please analyze the individual issues and suggest whether we shoud:
 * Fix in 2.0 (valid and severe finding)
 * Fix later (valid but minor finding or a finding with high impact)
 * Not fix (irrelevant, incorrect or prohibitively difficult to fix)

PLease see individual sub tasks below.",,qz412,radeale,rl336,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ESO-106,,,,,,,"29/Jan/19 16:09;qz412;20181210_Deloitte_DBG_XBID_REPORT.pdf;https://jira.deutsche-boerse.com/secure/attachment/65202/20181210_Deloitte_DBG_XBID_REPORT.pdf",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61603200,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y083cf:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 13 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Mar/19 14:01;rl336;https://vmt.deutsche-boerse.de/browse/PT-1064
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New root certificate authority for Test Client and ComTrader,XP-1026,77909,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ei349,dw255,dw255,28/Jan/19 17:08,06/Nov/20 12:49,22/Feb/21 13:26,30/Jan/19 17:13,,,Pre2020,,ComTrader,Other,,,,,,,,"SSL certificates in SYT1, SYT2 and SYT3 have been updated and have new root CA. This root CA must be added to truststore of Test Client and ComTrader.

Details and root CA .cer file can be found in TECHLOG-1912.",,dw255,ei349,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Feb/19 13:51;dw255;cacerts.jks;https://jira.deutsche-boerse.com/secure/attachment/65350/cacerts.jks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64713600,,,,,,,,,,,,,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ymj:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,comtrader-2.5.x,XP-69,XP-2583,XP-2554,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"01/Feb/19 13:51;dw255;New .jks file is necessary for catrina - explicit participant test client. The file is attached here [^cacerts.jks]","01/Feb/19 15:47;radeale;It works! You are my heroes! :)","04/Feb/19 09:15;ei349;(y)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Update tests Recall feature in Cucumber -  Block Orders recall, Repeated recall",XP-1023,77861,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,28/Jan/19 09:48,04/Aug/20 19:40,22/Feb/21 13:26,19/Feb/19 15:02,,,Pre2020,,,,,,,,,,,"TCs could be found:
002 Test\002 XBid Release\Test Models\22_Updated_Regression
excel file : RTM-27 Regression recall and cancel model 1.0.xlsx

Update Recall feature and add TC for Block orders recall and repeated recall.
",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63417600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y085yf:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"19/Feb/19 08:28;hj444;# test added :
--19 Block orders trade, local trade on one exchange, recall & auto grant, and repeated recall on RGRA trade.
--20 Block orders trade,cross border trade on one exchange, recall & auto reject, repeated recall on RREJ and auto-grant .
--21 Recall a user defined block orders trade cross border trade,RGRA,two exchanges and trader1 sends repeated request recall for RGRA
-- 22 Recall a user defined block orders trade cross border trade,two exchanges and trader1 sends repeated request recall for RREJ
-- 23 Recall already Canceled CNCL cross-border trade for block contracts
-- 24 reject cross-border for block contracts - One member has not trade cancel right
-- 25 Trader repeats recall request for block trade in status RRQE
-- 26  Recall request for block trade in Auction should not be possible
-- 27 Admin sends reject cross-border block trade, Error response is received because of not requesting the recall by trader
-- 28 Admin sends reject local block trade, Error response is received because of not requesting the recall by trader
-- 29 Admin accept cross-border block trade recall request but is rejected NO_CAP 
#  Pull request done
-- https://github.deutsche-boerse.de/dev/xbid-test/pull/146
-- automatic tests passed
# _Code review in progress._","19/Feb/19 09:05;hj444;Code review done.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH: Coordinate and evalute new technologies,XP-992,77760,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ek176,ek176,24/Jan/19 12:54,04/Aug/20 19:41,22/Feb/21 13:26,07/Feb/19 09:11,,,Pre2020,,,,,,,,,,,"After some consultations, the new technologies are recommended, namely:
 * Argo
 * Drill
 * Presto

Coordination is needed to make the first MVP running. 

Drive knowledge transfer to other teams.

 ",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-267,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluated Argo, Presto, Drill",,,,,,,,,,,,,,65232000,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 12,Alpha Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/19 15:13;ek176;Presentation available at: [https://github.deutsche-boerse.de/dev/xbid-etl/blob/master/doc/DWH_Team_Intro.md]

 

Argo and Drill+Presto info added to Confluence:  [https://confluence.energy.svc.dbgcloud.io/display/EDW/Tech+stack]​_

 

Drill container is also available.

 

Presto: Not really needed (drill alternative, requires Parquet JSON che3ma), too much effort to install (out-of-memory, hive/hcatalog/thrift/zookeper dependencies, poor documentation). ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor database access framework usage,XP-991,77759,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,24/Jan/19 12:50,04/Aug/20 19:40,22/Feb/21 13:26,19/Feb/19 15:20,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ SIMPLIFICATION ]*{color}

There are three ways how to connect to database. Namely DBI, Spring jdbcTemplate and  plain JDBC. Refactor to use only one way, jdbcTemplate is favourable.

Optionaly change simple data source to connection pool (Hikari?)",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65664000,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zqr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate to new artifactory,XP-990,77740,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,qz412,qz412,24/Jan/19 10:54,06/Nov/20 10:49,22/Feb/21 13:26,13/Feb/19 16:59,,,Pre2020,,,,,,,,,,,"{color:#00875a}*[ MANDATORY BUILD-RELATED TASK ]*{color}

Already kicked off by M7, details in the linked JIRA.",,ll664,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63849600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zo",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Feb/19 10:23;ll664;All good except the perl deployment machine - {{syspdepl1}} - cannot access the new artifactory, hence deployments to sytX does not work at the moment.

Techops are aware and requested firewall to be open - Kaan pushing it - should be ready soon - TECHLOG-1949","13/Feb/19 16:59;ll664;Firewall was open, deploy works. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 12] Deliver Sprint Increment,XP-985,77713,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,cf948,cf948,24/Jan/19 09:26,06/Nov/20 11:30,22/Feb/21 13:26,30/Jan/19 17:13,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,cf948,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65664000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000yzi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
UDB orders not matched investigate why auction is created but orders deleted,XP-979,77693,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,tm431,tm431,23/Jan/19 15:14,06/Nov/20 12:51,22/Feb/21 13:26,04/Feb/19 11:41,,,Pre2020,,,,,,,,,,,"investigate why following testcase triggers an auction and then deletes the orders.  It is fishy....

why are UDB blcok orders deleted (20 T03) and not matched?

is the capacity published also for next day contracts?

I would say that they should stay in the orderbook if cmm contracts on next day are withou capacity, or they should be rejected if the contracts on next day are not yet active

 

 

 

 
{code:java}
Scenario: Return correct totalQty in pblcOrdrbooksResp for (UDB) user defined block trade totalQty = qty after second trade
  Given CMM admin publishes capacity and activates interconnector from APG to RWENET
  And trader1 logs in
  When trader1 sends orders for products and delivery areas
    | contractId | px | side | qty | prod           | da     | type | dlvryStart           | dlvryEnd             | clOrdrId    | restriction |
    | NONE       | 1  | SELL | 100 | INTRADAY_POWER | RWENET | B    | 2018-02-15T20:00:00Z | 2018-02-16T03:00:00Z | scenario4b1 | AON         |
  Then Expect following order broadcasts
    | user    | messageType | action | side | px | qty | dlvryAreaId | state | clOrdrId    |
    | trader1 | OrdrExeRprt | UADD   | SELL | 1  | 100 | RWENET      | ACTI  | scenario4b1 |
  And trader2 logs in
  When trader2 sends orders for products and delivery areas
    | contractId | px | side | qty | prod           | da     | type | dlvryStart           | dlvryEnd             | clOrdrId    | restriction |
    | NONE       | 1  | BUY  | 100 | INTRADAY_POWER | APG    | B    | 2018-02-15T20:00:00Z | 2018-02-16T03:00:00Z | scenario4b2 | AON         |
  Then trader2 expects a trade
  And Expect following order broadcasts
    | user    | messageType | action | side | px | qty | dlvryAreaId | state | clOrdrId     |
    | trader2 | OrdrExeRprt | UADD   | BUY  | 1  | 100 | APG         | ACTI  | scenario4b2  |
  And Expect following order broadcasts
    | user    | messageType      | state |
    | trader2 | TradeCaptureRprt | ACTI  |
  When trader1 sends orders for products and delivery areas
    | contractId | px | side | qty | prod           | da     | type | dlvryStart           | dlvryEnd             | clOrdrId     | restriction |
    | NONE       | 1  | BUY  | 200 | INTRADAY_POWER | RWENET | B    | 2018-02-15T20:00:00Z | 2018-02-16T03:00:00Z | scenario4b1a | AON         |
  Then Expect following order broadcasts
    | user    | messageType | action | side | px | qty | dlvryAreaId | state | clOrdrId     |
    | trader1 | OrdrExeRprt | UADD   | BUY  | 1  | 200 | RWENET      | ACTI  | scenario4b1a |
  And trader2 logs in
  When trader2 sends orders for products and delivery areas
    | contractId | px | side | qty | prod           | da     | type | dlvryStart           | dlvryEnd             | clOrdrId     | restriction |
    | NONE       | 1  | SELL | 200 | INTRADAY_POWER | APG    | B    | 2018-02-15T20:00:00Z | 2018-02-16T03:00:00Z | scenario4b2a | AON         |
  Then trader2 expects a trade
  And Expect following order broadcasts
    | user    | messageType | action | side | px | qty | dlvryAreaId | state | clOrdrId     |
    | trader2 | OrdrExeRprt | UADD   | SELL | 1  | 200 | APG         | ACTI  | scenario4b2a |
  And Expect following order broadcasts
    | user    | messageType      | state |
    | trader2 | TradeCaptureRprt | ACTI  |
  When trader1 sends PblcOrdrBooksReq for product INTRADAY_POWER
  Then trader1 expects following orderbook
    | dlvryAreaId | dlvryStart          | dlvryEnd            | prod           | totalQty |
    | RWENET      | 2018-02-15T20:00:00 | 2018-02-16T03:00:00 | INTRADAY_POWER | 300      |
 {code}",,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64713600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 11,Home Office Team Sprint 12 [S],Home Office Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Feb/19 11:35;tm431;False alarm, after manual retest in SYT1 everything works OK. R1.6.0.25

 

there must be an error in cucumber test

 
{code:java}
<?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrEntry xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr acctId=""BG-EPEX-------01"" prod=""IdBLOCKTest2"" side=""BUY"" px=""1000"" qty=""10000"" ordrExeRestriction=""AON"" dlvryAreaId=""10Y1001A1001A46L"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" type=""B"" dlvryStart=""2019-02-04T15:00:00.000Z"" dlvryEnd=""2019-02-05T18:00:00.000Z"" validityRes=""GFS"" state=""ACTI""/>
    </OrdrList>
</OrdrEntry><?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrExeRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr ordrId=""99"" initialOrdrId=""99"" acctId=""BG-EPEX-------01"" contractId=""4908"" side=""BUY"" px=""1000"" qty=""10000"" initialQty=""10000"" ordrExeRestriction=""AON"" txt="""" dlvryAreaId=""10Y1001A1001A46L"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" preArranged=""false"" type=""B"" state=""ACTI"" usrCode=""TRD001"" revisionNo=""1"" timestmp=""2019-02-04T10:32:21.202Z"" validityDate=""2019-02-04T14:00:00.000Z"" validityRes=""GFS"" action=""UADD"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001""/>
    </OrdrList>
</OrdrExeRprt><?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrEntry xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr acctId=""BG-EPEX-------01"" prod=""IdBLOCKTest2"" side=""SELL"" px=""1000"" qty=""10000"" ordrExeRestriction=""AON"" dlvryAreaId=""10YBE----------2"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" type=""B"" dlvryStart=""2019-02-04T15:00:00.000Z"" dlvryEnd=""2019-02-05T18:00:00.000Z"" validityRes=""GFS"" state=""ACTI""/>
    </OrdrList>
</OrdrEntry><?xml version=""1.0"" encoding=""UTF-8""?>
<OrdrExeRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <OrdrList>
        <Ordr ordrId=""100"" initialOrdrId=""100"" acctId=""BG-EPEX-------01"" contractId=""4908"" side=""SELL"" px=""1000"" qty=""10000"" initialQty=""10000"" ordrExeRestriction=""AON"" txt="""" dlvryAreaId=""10YBE----------2"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" preArranged=""false"" type=""B"" state=""ACTI"" usrCode=""TRD001"" revisionNo=""1"" timestmp=""2019-02-04T10:32:37.611Z"" validityDate=""2019-02-04T14:00:00.000Z"" validityRes=""GFS"" action=""UADD"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001""/>
        <Ordr ordrId=""99"" initialOrdrId=""99"" acctId=""BG-EPEX-------01"" contractId=""4908"" side=""BUY"" px=""1000"" qty=""0"" initialQty=""10000"" ordrExeRestriction=""AON"" txt="""" dlvryAreaId=""10Y1001A1001A46L"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" preArranged=""false"" type=""B"" state=""IACT"" usrCode=""TRD001"" revisionNo=""2"" timestmp=""2019-02-04T10:32:21.202Z"" validityDate=""2019-02-04T14:00:00.000Z"" validityRes=""GFS"" action=""FEXE"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001""/>
        <Ordr ordrId=""100"" initialOrdrId=""100"" acctId=""BG-EPEX-------01"" contractId=""4908"" side=""SELL"" px=""1000"" qty=""0"" initialQty=""10000"" ordrExeRestriction=""AON"" txt="""" dlvryAreaId=""10YBE----------2"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" preArranged=""false"" type=""B"" state=""IACT"" usrCode=""TRD001"" revisionNo=""2"" timestmp=""2019-02-04T10:32:37.611Z"" validityDate=""2019-02-04T14:00:00.000Z"" validityRes=""GFS"" action=""FEXE"" lastUpdateUsrInfo=""BG-EPEX-------01TRD001""/>
    </OrdrList>
</OrdrExeRprt>
<?xml version=""1.0"" encoding=""UTF-8""?>
<TradeCaptureRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <TradeList>
        <Trade tradeId=""50"" state=""ACTI"" contractId=""4908"" qty=""10000"" px=""1000"" execTime=""2019-02-04T10:32:37.611Z"" revisionNo=""1"" preArranged=""false"" contractPhase=""CONT"">
            <Buy dlvryAreaId=""10Y1001A1001A46L"" acctId=""BG-EPEX-------01"" ordrId=""99"" txt="""" usrCode=""TRD001"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" mbrId=""TRM03""/>
            <Sell mbrId=""TRM03""/>
        </Trade>
    </TradeList>
</TradeCaptureRprt>
<?xml version=""1.0"" encoding=""UTF-8""?>
<TradeCaptureRprt xmlns=""http://www.deutsche-boerse.com/m7/v1"">
    <StandardHeader marketId=""XSOB""/>
    <TradeList>
        <Trade tradeId=""50"" state=""ACTI"" contractId=""4908"" qty=""10000"" px=""1000"" execTime=""2019-02-04T10:32:37.611Z"" revisionNo=""1"" preArranged=""false"" contractPhase=""CONT"">
            <Buy mbrId=""TRM03""/>
            <Sell dlvryAreaId=""10YBE----------2"" acctId=""BG-EPEX-------01"" ordrId=""100"" txt="""" usrCode=""TRD001"" clOrdrId=""085d15b3-2d1c-47ad-a613-a77781973027"" mbrId=""TRM03""/>
        </Trade>
    </TradeList>
</TradeCaptureRprt>
 {code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make sure jobs cannot run concurrently,XP-977,77682,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,23/Jan/19 13:08,31/Aug/20 15:38,22/Feb/21 13:26,24/Jan/19 16:23,,,Pre2020,,,,,,,,,,,"CRON executed jobs currently share single threaded executor, but when a job is launched with the CLI it can run concurrently.

Make sure jobs use same executor to avoid race conditions.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65750400,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000k9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze/Define: Update tests Cancel in Cucumber vs regression Recall/Cancel model  RTM-27,XP-975,77641,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,hj444,hj444,23/Jan/19 08:22,04/Aug/20 19:41,22/Feb/21 13:26,29/Jan/19 16:23,,,Pre2020,,,,,,,,,,,"002 Test\002 XBid Release\Test Models\22_Updated_Regression
 excel file : RTM-27 Regression recall and cancel model 1.0.xlsx

1. Analyze and Define test cases for adding to cucumber tests *Cancel feature*
 actual state _xbid-test/end-to-end-tests/src/test/resources/com/deutscheboerse/energy/m7/endtoendtests/trading/core/tradeCancel.feature *vs* RTM-27 Regression recall and cancel model 1.0.xlsx_
 2. Create new task for automation part",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65750400,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy7:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/19 12:55;hj444;1. results from Analyze & Define : comparing xbid-test/end-to-end-tests/src/test/resources/com/deutscheboerse/energy/m7/endtoendtests/trading/core/tradeCancel.feature vs RTM-27 Regression recall and cancel model 1.0.xlsx

TC for adding to Automation tradeCancel.feature :
1. Verify Cancel performed by PX user (016_FN_Cancel_NotAdmin)
2. Verify Cancel performed by central admin without rights(017_FN_Cancel_NoRights)
3. Verify Cancel for order in status RGRA(021_FN_Cancel_RGRA)

Block Orders Cancel
1. Request a Cancel on Trade (043_FP_Block_Order_Cancel)
2. Request a Cancel on Trade No Cap (044_FN_Block_Order_Cancel)
3. Request a Cancel on Trade - Inter PX trade (047_FP_Block_Order_Cancel_PX)
4. Request a Cancel on Trade - Inter PX trade No Cap(048_FN_Block_Order_Cancel_PX)

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze/Define: Update tests Recall in Cucumber vs regression Recall model  RTM-27,XP-974,77640,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,23/Jan/19 08:19,04/Aug/20 19:41,22/Feb/21 13:26,30/Jan/19 13:29,,,Pre2020,,,,,,,,,,,"002 Test\002 XBid Release\Test Models\22_Updated_Regression
 excel file : RTM-27 Regression recall and cancel model 1.0.xlsx

1. Analyze and Define test cases for adding to cucumber tests *Recall feature*
 actual state _xbid-test/end-to-end-tests/src/test/resources/com/deutscheboerse/energy/m7/endtoendtests/trading/core/tradeRecall.feature *vs* RTM-27 Regression recall and cancel model 1.0.xlsx_
 2. Create new task for automation part",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1023,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65318400,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"23/Jan/19 12:40;hj444;1. results from Analyze & Define :   comparing _xbid-test/end-to-end-tests/src/test/resources/com/deutscheboerse/energy/m7/endtoendtests/trading/core/tradeRecall.feature *vs* RTM-27 Regression recall and cancel model 1.0.xlsx_

TC for adding to Automation tradeRecall.feature :

1.  RepeatedRecallRequest - Verify Recall requested for order in status RREQ (010_FN_Recall_ReapetedRecallRequest)
2.  RepeatedRecallRequest - Verify Recall requested for order in status RREJ (011_FN_Recall_ReapetedRecallRequest)
3.  RepeatedRecallRequest - Verify Recall requested for order in status RGRA (012_FN_Recall_RGRA)
4. Verify Recall unsuccessfully accepted by admin without rights (013_FN_Recall_Acceptance_AdminWithoutRights)
5. Verify Recall request sent by third party PX (019_FN_Recall_ReqByThirdPartyPX)
6.  RepeatedRecallRequest - (Xborder)Verify Recall requested for order in status RREQ by second part of trade (020_FN_Recall_ReapetedRecallRequest)
7. Verify recall request for order in status CNCL (022_FN_Recall_CNCL)

Block Orders Recall
1. Request a Recall - RREJ (041_FN_Block_Order_Recall)
2. Request a Recall - RGRA(042_FP_Block_Order_Recall)
3. Request a Recall - RREJ - Inter PX trade( 045_FN_Block_Order_Recall_PX)
4. Request a Recall - RGRA - Inter PX trade(046_FP_Block_Order_Recall_PX)

 ","28/Jan/19 09:43;hj444;Added :
# new - admin rejects cross-border Recall request 
# new -  trader send recall request on Auction trade 
# auto-grant cross-border - RepeatedRecallRequest - Verify Recall requested for order in status RGRA
# admin accept cross-border - RepeatedRecallRequest - Verify Recall requested for order in status RGRA (012_FN_Recall_RGRA)
# Xborder trade 2 different exchanges - Trader1 sends Recall Request and trader2 sends repeated Recall Request -RREQ (010_FN_Recall_ReapetedRecallRequest,020_FN_Recall_ReapetedRecallRequest)
 # recall already Canceled CNCL cross-border trade(022_FN_Recall_CNCL)
 # auto-reject cross-border NO_CAP - RepeatedRecallRequest - Verify Recall requested for order in status RREJ, verify RGRA
 # repeat Recall request for RREJ - after Admin Rejects admin rejects cross-border Recall request 
# started - user defined block orders trade - auto grant & repeated recall

Note : Document HLS100-Functional Description SOB v18.00.docx ,  7.2 Trade recall :
A Recall ca be requested for trades with Status ""ACTI"", ""RREJ"" , but not for trades in status ""RGRA' or 'RREQ""


# TODO :
## Block Orders - more variations


","28/Jan/19 09:57;hj444;Jira was split to 2 tasks.
# Orders - most combinations covered. (XP-974)
# Block orders - user defined block orders area is not covered yet in Recall. (one TC added basic, all other combinations has to be added) (XP-1023)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Implicit allocations only via the leading IC - FTF Discussion, Container to be approved",XP-947,77449,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,radeale,radeale,radeale,17/Jan/19 15:35,06/Nov/20 11:30,22/Feb/21 13:26,08/Mar/19 14:04,,,Pre2020,,Capacity,,,,,waiting-customer,,,,"DBAG uncovered a situation, where implicit allocations are routed via Common ATC border in a specific corner situation when the internal IC between DAs connected to the Common ATC IC is closed and there is no other way around.

The situation is result of specification in HLS100A, chapter _2.6.1 Leading Interconnector_:
{code:java}
When looking at borders with multiple interconnectors, which have been marked with common ATC flag, it is necessary to introduce leading interconnectors. All implicit allocations on this border are booked to this interconnector.{code}
DBAG considers the situation described below very unlikely to happen, but would like to consult it with the TWG and ITTF members, whether they foresee any market situation this could happen (it have not happened so far).

Explicit allocations are not affected by this, only implicit.

+Description of the situation in an example+

All ICs are open, trade is possible from DA1 to DA4.

!Figure1s.png!

Internal IC DA2-DA3 closed and because implicit allocations are always booked on the leading IC, trade from DA1 to DA4 is not possible. All other connected ICs are closed (so no route possible in another way around).

!Figure2s.png!",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XBID-4299,,,,,,,"17/Jan/19 15:47;radeale;Figure1.png;https://jira.deutsche-boerse.com/secure/attachment/64467/Figure1.png","17/Jan/19 15:48;radeale;Figure1s.png;https://jira.deutsche-boerse.com/secure/attachment/64470/Figure1s.png","17/Jan/19 15:47;radeale;Figure2.png;https://jira.deutsche-boerse.com/secure/attachment/64468/Figure2.png","17/Jan/19 15:48;radeale;Figure2s.png;https://jira.deutsche-boerse.com/secure/attachment/64471/Figure2s.png","28/Jan/19 12:36;radeale;Figure3s.png;https://jira.deutsche-boerse.com/secure/attachment/65111/Figure3s.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,61862400,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y8z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 11 [S],Ampere Sprint 13 [S],Home Office Team Sprint 15 [S],Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/19 10:29;radeale;Depends on the outcome of XBID-4248.","28/Jan/19 12:30;radeale;Comment added to the external ticket:

Dear ITTF members,

DBAG would like to add that the same situation can happen in one additional case:

1. Halt the leading IC.
2. Manually unhalt the non-leading IC.

This results in situation, when implicit allocations are not routed through the border because of the feature described above. This is a corner case situation.

Regards
Alexandr

 !Figure3s.png! ","06/Feb/19 11:46;radeale;Reply from the MSD:

_Dear Alexandr,_

_Can you please provide more details on the exact behaviour of XBID when the non-leading interconnector is unhalted? Most important is to get some clarity whether implicit trading between the two areas connected by the non-leading interconnector could lead to a routing across the Common ATC border or not (of course limited by the Common ATC on that border). If implicit trading can be routed across the Common ATC border by unhalting the non-leading interconnector, what will happen in the capacity allocation?_

_Kind regards_

_David_","06/Feb/19 11:59;radeale;Dear David,

I suppose you inquire about the situation when both Common ATC border ICs were put to halt (by setting the leading IC to halt) and the non-leading IC has been manually unhalted afterwards.

When the leading IC is {color:#DE350B}halted{color}, the non-leading is {color:#00875A}active{color}:
- Implicit allocations - IAs are not routed through the Common ATC border, as only the leading IC is used for implicit allocation.
- Explicit allocations - EAs are possible on the non-leading IC, as these are requested directly on the IC.

Kind regards
Alexandr","08/Mar/19 14:03;radeale;Wording approved in XBID-4299.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XTG support answer comments in robustness of process,XP-942,77442,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs131,tm431,tm431,17/Jan/19 15:03,06/Nov/20 10:14,22/Feb/21 13:26,06/Feb/19 16:14,,,Pre2020,,,,,,,,,,,comments in robustness of process were not anwered in last month. please answer and provide the new version to XTG,,cs131,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 11,Home Office Team Sprint 12 [S],Home Office Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/19 08:56;cs131;comments have been addressed and sent to customers, waiting to XTG responses, will confirm on XTG call and close after next XTG call.","06/Feb/19 16:14;cs131;per last meeting with XTG on site, this can be closed for now and if any further comments will arise then reopen or create a new ticket in order to address them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse and prepare feedback regarding TWG questions - Non-High Prio Items [ASR003] (HOT component),XP-938,77436,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,nn481,tz118,qz412,17/Jan/19 14:07,11/Aug/20 16:36,22/Feb/21 13:26,24/Jan/19 09:03,,,Pre2020,,,,,,,,,,,"Analyse and prepare feedback regarding TWG questions - *other* than {color:#de350b}*red* {color}text (see attached file)

DoD
 * analyse questions/comments
 * investigate where applicable (have a proof at hand if available)
 * prepare answers
 * review answers

Answers shall be sent to ACM/PO for business review before communicating externally",,qz412,,,,,,,,,,,,,,,,,,,,,,,XP-620,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66182400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000z3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 11] Deliver Sprint Increment,XP-936,77430,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,xu897,17/Jan/19 12:34,06/Nov/20 10:14,22/Feb/21 13:26,24/Jan/19 09:32,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,xu897,,,,,,,,,,,,,,,,,,,,,,,XP-870,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66268800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07yhw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 11 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Version is skipped in ContractInfoRprt,XP-935,77426,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,uv683,uv683,17/Jan/19 11:08,06/Nov/20 12:40,22/Feb/21 13:26,30/Jan/19 12:01,,,Pre2020,,Trading,,,,,,,,,"* When a contract name is updated (daily at midnight) a contract version is updated twice, for instance from 2 to 4, one version is always skipped.

There were also some other issues with contract history table found:
 * last_update_time and last_update_user are not updated when a contract is marked for deletion
 * last_update_time and last_update_user are not updated when a contract is deleted
 marked_for_deletion is not present in history table",,eg288,radeale,tr866,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jan/19 11:55;tr866;Syt1-marked for deletion - screenshot_30.01.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/65253/Syt1-marked+for+deletion+-+screenshot_30.01.2019-001.png","30/Jan/19 11:45;tr866;lastupdate time after fix-screenshot_30.01.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/65251/lastupdate+time+after+fix-screenshot_30.01.2019-001.png","30/Jan/19 11:45;tr866;lastupdate time before fix-screenshot_30.01.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/65252/lastupdate+time+before+fix-screenshot_30.01.2019-001.png","30/Jan/19 11:35;tr866;version-db-cleanup-screenshot_30.01.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/65245/version-db-cleanup-screenshot_30.01.2019-001.png","30/Jan/19 11:35;tr866;version-screenshot_30.01.2019-001.png;https://jira.deutsche-boerse.com/secure/attachment/65246/version-screenshot_30.01.2019-001.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65145600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,17/Jan/19 11:08,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/19 15:51;eg288;1) FixContractNamesTask increases contract version by 1 (was by 2)
2) last_update_time and last_update_user are now updated when a contract is marked for deletion
3) contract column marked_for_deletion is audited now (the column was added into history table)
NOTE: 
* The last_update_time and last_update_user are still NOT updated when a contract is deleted. This a general problem for each entity. To implement it every trigger must be modified to updated the columns when an entity is deleted. Thus not implemented for contracts to keep the trigger implementations consistent.
* New column marked_for_deletion in contract history table is NULL for existing entries ","30/Jan/19 12:00;tr866;Successfully tested on environment Syt1,Syt3 with version XB R1.6.0.24-1ee2add271f0dab3e9bb3bd6e838477b78a24435 and Syt2 with version XB R1.6.0.23-7244cee1eefe04d4056eeca9a02081fced1b9499
# As seen on the screenshot at midnight when contracts get renamed the version number is now increased correctly by 1
in Syt1 where the deploy was without DB cleanup it's visible that before the version used to be increased by 2 and after the deployment of the fix, version was increased already only by 1
!version-screenshot_30.01.2019-001.png|width=75%,height=75%!
in Syt3 where the DB cleanup was done it's visible, that version wasn't increased by 2 for all time
!version-db-cleanup-screenshot_30.01.2019-001.png|width=75%,height=75%!
#  last_update_time and last_update_user are now updated when a contract is marked for deletion
as seen on Syt2 before fix, when contract was marked for deletion(marked_for_deletion column missing, but revtype is changing from 1 to 2 at that point) last_update_user and last_update time was remaining the same
!lastupdate time before fix-screenshot_30.01.2019-001.png|width=75%,height=75%!
where as on Syt1 with the fix the last_update_user and last_update_time gest updated when contract gets marked for deletion
!lastupdate time after fix-screenshot_30.01.2019-001.png|width=75%,height=75%!
last 2 last_update_time and last_update_user stay the same when contract gets deleted as explained above
# marked_for_deletion column was added in contract history table and as it was seen on previous screenshot before the fix column was missing
when deployment is done, existing contracts were filled in by null in marked_for_deletion column and new ones are having already Y/N state. When second deployment was done after that the existing values were preserved, i.e. where it was null it stayed null and same for Y/N states.
!Syt1-marked for deletion - screenshot_30.01.2019-001.png|width=75%,height=75%!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make Repoting engine Ansible installation idempotent,XP-931,77415,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,nn481,nn481,nn481,17/Jan/19 09:15,06/Nov/20 09:08,22/Feb/21 13:26,31/Jan/19 08:58,,,Pre2020,,,,,,,,,,,"TODOS:
* update https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/reporting-engine/roles/postgresql/README.md according changes done in role
* Test properly all tags
* Test on SYT env",,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66268800,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000z6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 11,Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce docker images for external services,XP-929,77400,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,qo794,qo794,16/Jan/19 16:56,04/Aug/20 19:40,22/Feb/21 13:26,14/Feb/19 09:19,,,Pre2020,,,,,,,,,,,"* -SFTP- done
* -SCP- sftp server can be used
* -MailServer- - done, imap not supported though
* -Elasticsearch- - done
* -SLA (report tool) database- done",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-744,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63936000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07czz:zzm",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Feb/19 11:23;qo794;https://github.deutsche-boerse.de/dev/xbid-test/blob/develop/end-to-end-tests/src/test/resources/com/deutscheboerse/energy/m7/endtoendtests/GherkinTests.MD",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automated change detection for all XBID components to speed up increment creation,XP-928,77396,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,16/Jan/19 16:28,06/Nov/20 11:34,22/Feb/21 13:26,18/Jan/19 16:27,,,Pre2020,,,,,,,,,,,"Let's have a jenkins job that would check git repositories for new commits so we see immediately what needs to be released and included in the increment.

This is done manually at the moment.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66268800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j4",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,TOFIX-migration-to-declarative-not-working,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-1069,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,versions,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Credit Point Report end to end test using testcontainers,XP-927,77379,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,uv683,uv683,16/Jan/19 14:37,04/Aug/20 19:41,22/Feb/21 13:26,07/Feb/19 09:06,,,Pre2020,,,,,,,,,,,,,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66268800,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zzr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make all jobs running via Spring Batch,XP-924,77371,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eh941,eh941,16/Jan/19 12:29,31/Aug/20 15:37,22/Feb/21 13:26,07/Feb/19 09:45,,,Pre2020,,,,,,,,,,,"Jobs for SLA, KPI and CreditPoints should run over Spring Batch",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66355200,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yej:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor KPI report,XP-923,77370,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,uv683,uv683,16/Jan/19 12:28,04/Aug/20 19:40,22/Feb/21 13:26,10/Jun/19 10:31,,,Pre2020,,,,,,,,,,,"Investigate how refactoring was done in creditpoint report and perform major refactoring of KPI in the similar manner. This has to be done after tests XP-920. 

Prefferable language is Kotlin.

 ",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66355200,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08oif:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],Alpha Team Sprint 27,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sla Boundry report end to end using testcontainers,XP-921,77368,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,uv683,uv683,16/Jan/19 12:17,04/Aug/20 19:40,22/Feb/21 13:26,08/Feb/19 14:21,,,Pre2020,,,,,,,,,,,,,uv683,,,,,,,,,,,,,,,,,,,,XP-1099,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66355200,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j7zqw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 14 [S],,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kpi Performance report end to end using testcontainers,XP-920,77367,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,uv683,uv683,16/Jan/19 12:17,04/Aug/20 19:40,22/Feb/21 13:26,28/Feb/19 09:49,,,Pre2020,,,,,,,,,,,,,uv683,,,,,,,,,,,,,,,,,,,,XP-923,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66355200,,,,,,,,,,,,,,,XP-919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0867i:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 15,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use master node for jenkins executor if possible,XP-913,77322,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,eh941,eh941,15/Jan/19 14:12,06/Nov/20 11:34,22/Feb/21 13:26,01/Apr/19 18:30,,,Pre2020,,,,,,,waiting-techops,,,,"For some jobs it isn't necessary to use englobcon machines - for orchestration or simple job launching. Because englobcon are restricted for only one job per VM. On the other hand there is _master_ node which should have this restriction very relaxed. It's meant to be used for such tasks when there is no difficult computation needed.

Analyze the pull request jobs and change the behavior when possible.

To tell the job should run on the master node it should be enough to remove the restriction on which machines the job runs (please verify this, it might be wrong).

Potentially discuss witm M7 + [~qo288]",,eh941,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,no action needed anymore. Not implemented. ,,,,,,,,,,,,,,62640000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd6:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/19 12:57;ei349;Not needed anymore. See comment in TECHLOG-1956",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use timeout in XBID pipelines,XP-912,77318,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,eh941,eh941,15/Jan/19 13:50,06/Nov/20 11:34,22/Feb/21 13:26,06/Feb/19 09:38,,,Pre2020,,,,,,,,,,,"On DevOps community we were asked to use timeouts for our pipelines. It happens time from time that some of the pipeline jobs get stuck forever and it's blocking the node.

There should be command for that - https://stackoverflow.com/questions/38096004/how-to-add-a-timeout-step-to-jenkins-pipeline",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66355200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy7:qi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 13,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,XP-2942-losses-perf,TOFIX-migration-to-declarative-not-working,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-1069,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,versions,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.5.9 evaluate database conversion run for cute/simu/prod,XP-911,77309,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,15/Jan/19 11:16,06/Nov/20 11:34,22/Feb/21 13:26,13/Feb/19 09:06,,,Pre2020,,,,,,,,,,,"This topic to be discuissed on Architecture communicty on 21.1:

Techops highlighted potential impact of any new release deployment in case there is database change (alter table) or databases conversion (historical tables being change) - which is the case for 1.5.9 release
 (For example with 1.5 database conversion for some cutes took up to 40 minutes and in production 3 hours)

*Task*: product team to provide measurements of execution time (performance) of these database conversion scripts for
 * CuTE PX (Result: *less than 1s*)
 * SIMULATION
 * PRODUCTION

With further releases (R2.0 => on) this evaluation to become a step in the deployment preparation ([~rehapav] to inlcude in the checklist).

{color:#de350b}Techops to measure CuTe PX on Mon 21/1 {color}",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-2362,XP-775,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66441600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000z602",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
R1.5.9. - CuTe PX robust working state check,XP-906,77270,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,dw255,qz412,qz412,14/Jan/19 12:38,06/Nov/20 10:58,22/Feb/21 13:26,22/Jan/19 10:34,,,Pre2020,,,,,,,,,,,After the R1.5.9 is deployed to CUTE on 21st Jan a thorough working state check needs to be performed to ensure problems similar to R1.5 are not present.,,dw255,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-775,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65836800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/19 10:36;dw255;Cute PX environment is up and running. SOB, CMM, CMI and SPM components have been checked by login to GUI and logfile analysis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SLA Reporting - check and provide corrected report for December,XP-904,77265,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,de698,de698,14/Jan/19 10:17,31/Aug/20 15:39,22/Feb/21 13:26,15/Jan/19 09:22,XBID 1.5.9,,Pre2020,,SLA Report Tool,,,,,,,,,"Request comes from the TWG PTF call.

First three days have duplicated data (hourly and daily) related to SM files generation.

 

 ",,de698,gd553,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/19 09:21;uv683;XBID Performance and SM SLA Reporting December 2018.xlsx;https://jira.deutsche-boerse.com/secure/attachment/64263/XBID+Performance+and+SM+SLA+Reporting+December+2018.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66441600,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07z14:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 10 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/19 09:22;uv683;[~de698][~gd553][~qm925] Please find corrected report attached and uploaded to sharepoint.","15/Jan/19 09:42;gd553;[~uv683] thanks for the corrected report. Can you shortly tell us what caused the error and how did you solve it?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix failing TestClient dependency: m7-public-api:6.5.3 not in Artifactory anymore,XP-895,77213,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ek176,ek176,11/Jan/19 10:40,31/Aug/20 15:39,22/Feb/21 13:26,02/Jan/20 12:35,,,3.1.0,,Other,,,,,Artifactory,ComTrader,ice,TestClient,"[ IMHO This can be closed: Should be resolved with new artifactory/releases ]

 

Test client contains dependency on m7-trading-api v. 6.5.3. However, it is not in artifactory anymore (a _smart script_ has cleaned it from artifactory). The build is about 5 months old... 

 

*Problem*: Current artifactory: [https://cmqaart.deutsche-boerse.de/artifactory/eex-dev/com/deutscheboerse/energy/m7/m7-trading-api/] contains versions 6.5.6 and 6.5.[9–14]. These are NOT compatible with TestClient (API change). Simple change to 6.5.6 does not work (API change). Compilation fails (module: {{backend-gateway-comxerv-v42).}}

 

*Error*:
 \{{ERROR: Failed to execute goal on project backend-gateway-comxerv-v42: }}
 \{{ Could not resolve dependencies for project }}
 \{{ com.deutscheboerse.energy.m7.testclient:backend-gateway-comxerv-v42:jar:6.0.25-SNAPSHOT: }}
 \{{ Failure to find com.deutscheboerse.energy.m7:m7-trading-api:jar:6.5.3 in }}
 {{ [http://cmqaart.deutsche-boerse.de/artifactory/eex-dev]}}
  

*MVN info*:
 * ./{{pom.xml}} excerpt: {color:#0747a6}{{<m7-public-api.version>6.5.3</m7-public-api.version>}}{color}
 * ./{{backend-gateway/backend-gateway-comxerv-v42.pom.xml}} excerpt: {{
 {color:#0747a6}<groupId>com.deutscheboerse.energy.m7</groupId>{color}
 {color:#0747a6} <artifactId>m7-trading-api</artifactId>{color}
 }}

*Reproduce*:
 # Clean the Maven cache (remove com.deutscheboerse.energy.m7)
 # cd m7.test-client
 # mvn clean install

*Proposed solution* (maybe consult on CoP first):
 * Fix and periodically re-schedule this task so we keep up-to-date
 * Add explicit note about building the API project
 * Systematical: change the _smart script_ (artifactory cleaning) so it checks dependencies currently in use (in active branches, _development_ at least).

 

*Note*: Manual hack: Build locally. Or, ask someone to give you his cached version from .m2 directory...",,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,outdated,,,,,,,,,,,,,,65923200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0000f5",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/19 13:35;ek176;The same applies for comtrader (branch 2.5.x):

 

Failed to execute goal on project comtrader-m7-v1: Could not resolve dependencies for project com.deutscheboerse.comxerv:comtrader-m7-v1:jar:2.5.1.44-SNAPSHOT: Failure t
o find com.deutscheboerse.energy.m7:m7-trading-api-xml:jar:1.0.35 in http://cmqaart.deutsche-boerse.de/artifactory/eex-dev was cached in the local repository, resolution will no
t be reattempted until the update interval of central has elapsed or updates are forced","21/Jan/19 12:19;ek176;We've discussed it in the issue on Jan, 17: [https://confluence.energy.svc.dbgcloud.io/display/AGILE/Energy+Dev+and+Arch+CoP]

We can tag the builds needed so that these are not cleaned-up. The same approach is used by M7.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Check and fix SOB Tosca tests, link to Feature Matrix",XP-874,77170,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,radeale,radeale,10/Jan/19 14:20,06/Nov/20 11:34,22/Feb/21 13:26,23/Jan/19 14:46,,,Pre2020,,Trading,,,,,,,,,"Make 95% of SOB Tosca Quick Show tests green. Reason for non-pass needs to be known and understood on all non-green items.
Quick Show can be then used as a part of sprint increment regression tests.

Acceptance criteria

* Make Quick Show test green
* Mark Features that are covered in Tosca - see https://confluence.energy.svc.dbgcloud.io/display/XBID/SOB+Feature+Matrix
* Fill Tosca column there",,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-303,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66787200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07yhs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 10,Ampere Sprint 11 [S],,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 10] Deliver Sprint Increment,XP-870,77147,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,dw255,xu897,xu897,10/Jan/19 09:43,06/Nov/20 10:49,22/Feb/21 13:26,17/Jan/19 09:30,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,dw255,xu897,,,,,,,,,,,,,,,,,,,,,,XP-823,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66268800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 10 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jan/19 09:33;dw255;Sprint increment is created: XBID 1.6.0.22, SPM 1.5.0.14.

Deployment in DST environment was successful.

Tosca quick test suite is running in DST environment. Results will be analyzed on Thursday 17. January.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update Trading Inquiry 1.6.x deployment configurations for SIMU,XP-864,77053,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,eh941,eh941,eh941,08/Jan/19 17:13,06/Nov/20 11:34,22/Feb/21 13:26,14/Jan/19 12:11,,,Pre2020,,,,,,,configuration,,,,"There are couple of Jira that affects the new version of Trading Inquiry 1.6.x. There are multiple changes in deployment. It's
 * XDEV-4769
 * XP-108

When 1.6.x is being deployed to any of CuTes, Lips, Simu and Prod it must adopt all changes in energy-mkt-shrd to master branch.",,eh941,,,,,,,,,,,,,,,,,,,,XP-775,,,,,,,,,,,,,,,SERVICE-2377,SERVICE-2466,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66528000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000o",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 10 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/19 12:11;eh941;MR prepared - https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/146",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix end-to-end pipeline issues on new Jenkins,XP-860,77019,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ei349,ei349,ei349,08/Jan/19 10:28,06/Nov/20 11:34,22/Feb/21 13:26,15/Jan/19 10:01,,,Pre2020,,,,,,,,,,,"* It looks that new jenkins is running more than what's specified in the testing scope. (i.e. [https://englobjci1.deutsche-boerse.de/job/Energy/job/xbid-end-to-end-pipeline/22/).] 
 ** Done
 * New jenkins does not log categories properly
 ** Waiting on techops - [~qo288]
 * Ensure that pipeline steps are executed in parallel.
 ** Done by [~eh941]",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67046400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,TOFIX-migration-to-declarative-not-working,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-1069,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,versions,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ensure that all xbid jobs delete workspace after run,XP-858,77017,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,nn481,nn481,08/Jan/19 09:57,06/Nov/20 11:34,22/Feb/21 13:26,10/Jan/19 15:01,,,Pre2020,,,,,,,,,,,,,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67046400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07xvc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Re-queuing message in Trading Inquiry when an error occurs,XP-848,76953,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eh941,eh941,eh941,04/Jan/19 16:13,06/Nov/20 12:40,22/Feb/21 13:26,07/Jan/19 10:20,,,Pre2020,,Trading,,,,,,,,,"When an error occurs while processing a message in trading inquiry the message is automatically re-queued and it's endless. It leads to infinite logging the message like: 

{noformat}
No user found in database with login CXDBSU01
No user found in database with login CXDBSU01
No user found in database with login CXDBSU01
No user found in database with login CXDBSU01
No user found in database with login CXDBSU01
No user found in database with login CXDBSU01
...
{noformat}",,eh941,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67305600,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,04/Jan/19 16:13,,,,,,,,,,,,,,,,,,,,,,,"1|y07xi0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change default Tosca test data set,XP-847,76943,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,radeale,radeale,04/Jan/19 14:34,06/Nov/20 10:48,22/Feb/21 13:26,16/Jan/19 16:44,,,Pre2020,,Capacity,,,,,,,,,"Please change the default Tosca test data set (or other relevant test data sets).

Module: CMI
Table: tbxi035_config

The actual config_value for the user has to changed from *_test to *_inte.

Example:
UPDATE tbxi035_config SET config_value = 'xbid_ren_inte' WHERE config_value = 'xbid_ren_test';

This is needed for the System Test to SFTP connection to be successfully working.",,radeale,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66873600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000xi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"09/Jan/19 18:49;radeale;Please also test the change including the sFTP connection as described in the Confluence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 9] Deliver Sprint Increment,XP-823,76849,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,xu897,02/Jan/19 12:18,06/Nov/20 10:14,22/Feb/21 13:26,10/Jan/19 09:43,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,xu897,,,,,,,,,,,,,,,,,,,,,,,XP-787,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67564800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:1",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MVP - Refactor to work with provided Hadoop cluster,XP-817,76753,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,de698,de698,21/Dec/18 14:01,04/Aug/20 19:41,22/Feb/21 13:26,04/Apr/19 10:28,,,Pre2020,,,,,,,,,,,"*{color:#00875a}[ FEATURE, EASE OF OPERATION AND LOWERING MAINTENANCE ]{color}*

Coordinate with Techops, see TECHLOG-1614

The work will resume from mid-January.

*What needs to be done:*

Once the cluster infrastructure is ready, the prepared, currently dockerised solution (with Flink, sqoop, HDFS, Beam, ev. Spark) needs to be refactored so that it runs on the dedicated infrastructure.
 * Design directory structure (namespace) for future: Logs, Exports, Reports
 * Set guidelines for namespace extension",,de698,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-267,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Continues in:
XP-810
XP-1245
XP-1459
Final coordination(delivery) task:
XP-812

Related (Zeppelin, Benchmark):
XP-816, XP-677
XP-683",,,,,,,,,,,,,,68515200,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ymj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 12,Alpha Team Sprint 13,Alpha Team Sprint 14 [S],Alpha Team Sprint 15,Alpha Team Sprint 16 [S],,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MVP - Apache Beam working with Flink,XP-813,76735,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,de698,de698,20/Dec/18 15:56,04/Aug/20 19:40,22/Feb/21 13:26,07/Feb/19 09:18,,,Pre2020,,,,,,,,,,,"*Task:* create a Beam pipeline including Flink (i.e. make Flink and Beam work together)

Within this pipeline:
 * the Sqoop EL job is started from Flink
 * synchronised job is started which aggregates (completed) data from HDFS storage
 * final report is created

[https://beam.apache.org/get-started/beam-overview/]

 

We expect that most of the DWH logic will be implemented in Beam. Therefore it is  needed to get familiar with the technology.

 

Evaluate Stream/Batch processing. Emulate stream i.e. by reading increments from ProdCopy.

 

Evaluate Py, Scala, Kotlin.",,de698,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-267,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64454400,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:0ujr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 12,Ampere Sprint 13 [S],,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,poc_finalized_with_scratches,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"07/Feb/19 09:42;eg288;Created simple beam pipeIine and two runners in xbid-etl/beam-job project. See XbidOrderCountPerDeliveryAreaPipelineFactory for details.

Runners:
* direct runner XbidOrderCountPerDeliveryAreaDirectRunner - enables pipeline execution on local machine, local parquet file is used as input, it is suitable for pipeline development and debugging
* flink runner XbidOrderCountPerDeliveryAreaFlinkRunner - enables pipeline execution via flink in hadoop
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH - Finalization: Deliver PoC: KPI report in DWH implemented/running,XP-812,76734,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,de698,de698,20/Dec/18 15:09,04/Aug/20 19:41,22/Feb/21 13:26,17/Oct/19 12:31,,,Pre2020,,,,,,,,,,,"To be estimated/realized after: XP-810 XP-1245 XP-1459

The integration part of DWH PoC:
DoD: 
* E and T jobs are running (no manual intervention, manually deployed)
* Each (month/week) a new KPI report is saved to HDFS
* E job is maintaining it's status (last ID) in a HDFS file
* KPI report is correct
* Description in Confluence
* Presentation to the Energy (not only XBID)
* Describe monitoring and troubleshooting",,de698,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2247,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Remaining work splitted to XP-2247,,,,,,,,,,,,,,68601600,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5k:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 36 [S],,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,master,poc_finalized_with_scratches,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DWH - Flink runs in the ENTEST environment,XP-810,76731,Story,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,de698,de698,20/Dec/18 15:00,04/Aug/20 19:41,22/Feb/21 13:26,05/Sep/19 09:41,,,Pre2020,,,,,,,,,,,"After the expert consultation, it was recommended to start working with Flink - open source platform for distributed stream and batch data processing.

Ansible repo: [https://github.deutsche-boerse.de/dev/energy.datalake]

*Task* is to make the Flink framework working in the {{entestdwh}} environment. 

*Outcome:*
 * **Flink runs in the entestdwh environment
 * Flink Web GUI is accessbile [Done, tunneling via SSH:22 port – the only visible port from Citrix env]
 * We are able to start a job (JAR) via:
 ** Cmdline ({{flink run}}): [Done] 
 ** Cmdline ({{flink run -m yarn cluster}}): [Done] 
 ** REST API: [Done]
 ** GUI [WordCount: Flink OK]
 ** from Java [DONE – use REST API, as in Ansible]
 * We are able to start job in
 ** batch mode [DONE]
 ** session mode [Won't be used: uses random port]
 * Document findings/problems in Confluence page [Done]

Note: beam-runner-flink-1.9 should be released with Beam 2.16.0: [https://issues.apache.org/jira/browse/BEAM-7730]",,de698,ek176,,,,,,,,,,,,,,,,,,,XP-812,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"https://confluence.energy.svc.dbgcloud.io/display/EDW/Flink
https://github.deutsche-boerse.de/dev/energy.datalake/pull/2
",,,,,,,,,,,,,,46310400,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y099lr:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team 26 [S],Alpha Team Sprint 27,Alpha Team Sprint 28 [S],Alpha Team Sprint 33,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,develop,poc_finalized_with_scratches,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"27/Jun/19 13:57;ek176;Try to make the beam WordCount example work: [https://beam.apache.org/get-started/quickstart-java/]

According to [~fp407] we should have root access. Works for my (ab123) account.

According to older discussions, we should not open ports of the machines, but use tunneling.","05/Sep/19 09:39;ek176;Updated [https://confluence.energy.svc.dbgcloud.io/display/EDW/Flink]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix and test Comtrader Release/Deploy,XP-808,76698,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,ei349,ei349,19/Dec/18 10:48,06/Nov/20 12:51,22/Feb/21 13:26,16/May/19 11:41,,,Pre2020,,,,,,,,,,,Blocked by  TECHLOG-1892 ,,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66960000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yek:c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jan/19 10:57;ei349;Problem with security-settings.xml file on the techops side. ","09/Jan/19 11:54;ei349;security-settings.xml issue fixed. 

Remaining: 

waiting for the exception on proxy to the internal testing machines. Same case as m7 has. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Growth estimation update,XP-798,76570,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tz118,tz118,14/Dec/18 15:37,06/Nov/20 10:48,22/Feb/21 13:26,23/May/19 11:01,,,Pre2020,,,,,,,,,,," 
----
[~tz118], [~uv683]: Please either specify in a bit more detail what needs to be done or add as a subtask to Dec/Jan/Feb etc. reports. Thx.
[~qz412] more detailed explanation added, sub-tasks can be created based on the solution (two options proposed)
----
 
*future SLA boundaries reports (prognosis tab), e.g. Jan 2019 shall be updated based on the following requirements:*

email M Vancura on 14.12.:
 Dear DBAG, 
 let me provide you with the monthly update (November 2018) of growth estimations:

growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):
 Number of Block Orders (daily), as a subset of the orders = 35%
 Number of Explicit Requests (daily) = 0%
 Number of Explicit Allocations (daily) = 0%
 Number of Hubs = this is known to DBAG (2nd wave data set)
 Number of Borders = this is known to DBAG (2nd wave data set)
 Sustainable Load Items = 35%

DoD
 consider growth estimation for the future SLA reports (this can be automated and reporting tool release would be needed or it can be manually modified after report generation)
validate (test) a new report

",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1072,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69120000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yf4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update SB proposal ,XP-794,76528,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,13/Dec/18 15:48,06/Nov/20 12:50,22/Feb/21 13:26,14/Dec/18 13:26,,,Pre2020,,,,,,,,,,,"Update boundaries Excel based on the latest update(request from Malina RS):

As agreed in yesterday’s RCB, DBAG investigated possibilities to modify the Service Boundaries uplift proposal (Exhibit 20) to a level requested by NEMOs and I would like to provide the following update to the proposal:
1,5 million (1 500 000) maximum daily number of Order Transactions with daily maximum of 15.00% of Order Transactions in peak

1,5 - 2 million (2 000 000) maximum daily number of Order Transactions with daily maximum of 11.25% of Order Transactions in peak
 

",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/18 13:20;tz118;ASR003_RTS3 Slice B_List of Service Level Boundaries  KPIs_v5.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63595/ASR003_RTS3+Slice+B_List+of+Service+Level+Boundaries++KPIs_v5.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69206400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07v1c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Christmas Sprint 8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Dec/18 13:21;tz118;updated excel communicated to PM [^ASR003_RTS3 Slice B_List of Service Level Boundaries  KPIs_v5.xlsx] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add dataset to SPM docker,XP-762,76354,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,qo794,qo794,10/Dec/18 10:49,04/Aug/20 19:41,22/Feb/21 13:26,15/Jan/19 16:11,,,Pre2020,,Shipping,,,,,,,,,"Shipping module docker image does not contain an external data-set jar at all therefore it's not possible to select an external one, only built-in datasets are available.
- external dataset needs to be copied to the docker image
- it must be added to {{context.xml}} (see xbid as an example)",,od044,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69552000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07vfw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Dec/18 10:54;od044;Note: This issue blocks possibility to use SM TOSCA test suites against docker.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM: replace grunt with webpack,XP-761,76337,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ll664,ll664,07/Dec/18 16:05,08/Jan/21 11:58,22/Feb/21 13:26,06/Jan/21 08:58,,,3.2.x,,Shipping,,,,,,,,,"{color:#00875a}*[ Cleaner and easier future development on SPM ]*{color}

Current frontend development experience is not very pleasant. It requires running jetty, grunt, disabling CORS, grunt watch is very slow, etc.

Replace the JS build with webpack and introduce webpack-dev-server for local development.

 

Use webpack with as much same code we have right now as possible ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4305,,,,,,,XP-2756,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69724800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0c927:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,HOT Christmas Sprint,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,fixing-dataset,develop,XP-761-spooooky-migration-from-grunt-to-webpack,using-no-package-lock-during-npm-install,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generate handler reports for SC14 runs with new DB,XP-760,76330,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,nn481,nn481,07/Dec/18 15:04,06/Nov/20 11:34,22/Feb/21 13:26,12/Dec/18 16:00,,,Pre2020,,Other,,,,,,,,,It would be interesting to see avg handler times for new DB PoC. It means to generate reports for SC 14 scenario for 5 runs. [~od044] has logs and runs times.,,nn481,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69724800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07txc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/18 15:11;tz118;It would be good to have also respective percentiles at least 93% and 96,5%
[~nn481]I changed to SC14 as for SC15 we have runs onlz for SC14 from this week",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix journaller batching and do perf tests on gluster.fs,XP-759,76329,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,,nn481,nn481,07/Dec/18 14:57,04/Aug/20 19:41,22/Feb/21 13:26,26/Feb/19 15:24,,,Pre2020,,Trading,,,,,,,,,"{color:#00875a}*[ INVESTIGATION - Potential for further perf imrpovement ]*{color}

After discussion with Techops, we need to decide whether use synchronous (expensive) or asynchronous (cheaper) replication on Database.

We agreed that when gluster.fs is used for journal then asynchronous replication can be used. 
 When we fallback to NFS then synchronous replication must be used.

So we need ASAP decide, to make the decision we need to measure XBID vanilla vs XBID fixed journaller batching.

*Current state:*
 Performance measurements for SYT+gluster.fs with vanilla vs fixed journaller showed that performance gain is not sufficient. Avg. journal write time is same for both cases, peaks during higher load are smoothed with fixed journaller.

*Steps to do:*
 We should find a way how to speedup gluster.fs.
 As far as we know from Techops, there is ongoing cooperation with RadHat to solve the issue with gluster.fs, Redhat needs debug logs to analyze the issue. We can run the tests on SIM env but the SIMU is used by customer.

An alternative way is to run the pref tests on SYT, IMHO at first we should check if HW beneath gluster.fs is similar to SIMU (See TECHLOG-1806) and decide if it makes sense to run the perf tests on SYT.

if it is not possible to speedup the gluster.fs then our fallback plan is to use NFS and DB with synchronous replication

Optional to do:
 Proposal from [~eh941] is to develop small application to measure performance on gluster.fs with given parameters.",,lt112,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/19 10:18;nn481;new_journaller_handlers_report.xls;https://jira.deutsche-boerse.com/secure/attachment/65819/new_journaller_handlers_report.xls","18/Feb/19 10:18;nn481;new_journaller_report_perf.xls;https://jira.deutsche-boerse.com/secure/attachment/65818/new_journaller_report_perf.xls","18/Feb/19 10:17;nn481;vanilla_handlers_report.xls;https://jira.deutsche-boerse.com/secure/attachment/65817/vanilla_handlers_report.xls","18/Feb/19 10:17;nn481;vanilla_perf_report.xls;https://jira.deutsche-boerse.com/secure/attachment/65816/vanilla_perf_report.xls",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63849600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0863b:u",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 12 [S],Home Office Team Sprint 13,Home Office Team Sprint 14,Home Office Team Sprint 15 [S],Home Office Team Sprint 16,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Feb/19 11:23;lt112;h3. Code changes
- external library for journal I/O has been upgraded from version 3.x to version  5.x
- library API has been changed, thus the journaler has been partially reimplemented

h3. Results
TODO [~od044]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Run Docker - Script improvemet,XP-745,76264,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,hj444,hj444,06/Dec/18 10:01,06/Nov/20 11:34,22/Feb/21 13:26,07/Dec/18 10:31,,,Pre2020,,,,,,,,,,,"Improve the script for running docker .

- Actual : not possible to run docker via this script.

- Expected: We can run docker via this script.",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69897600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yq3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Docker - Error while sending data to elastic database, 'CertificateNotYetValidException'",XP-744,76263,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,hj444,hj444,06/Dec/18 09:58,04/Aug/20 19:40,22/Feb/21 13:26,13/Feb/19 16:59,,,Pre2020,,,,,,,,,,,"In docker logs Error : *Error while sending data to elastic database* 

{code}2018-02-15T10:33:05.037Z [/O dispatcher 6][][] ERROR c.d.e.m.e.ElasticHandler - Error while sending data to elastic database, {}
javax.net.ssl.SSLHandshakeException: General SSLEngine problem
	at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1478)
	at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:535)
	at sun.security.ssl.SSLEngineImpl.writeAppRecord(SSLEngineImpl.java:1214)
	at sun.security.ssl.SSLEngineImpl.wrap(SSLEngineImpl.java:1186)
	at javax.net.ssl.SSLEngine.wrap(SSLEngine.java:469)
	at org.apache.http.nio.reactor.ssl.SSLIOSession.doWrap(SSLIOSession.java:265)
	at org.apache.http.nio.reactor.ssl.SSLIOSession.doHandshake(SSLIOSession.java:305)
	at org.apache.http.nio.reactor.ssl.SSLIOSession.isAppInputReady(SSLIOSession.java:509)
	at org.apache.http.impl.nio.reactor.AbstractIODispatch.inputReady(AbstractIODispatch.java:120)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.readable(BaseIOReactor.java:162)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvent(AbstractIOReactor.java:337)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.processEvents(AbstractIOReactor.java:315)
	at org.apache.http.impl.nio.reactor.AbstractIOReactor.execute(AbstractIOReactor.java:276)
	at org.apache.http.impl.nio.reactor.BaseIOReactor.execute(BaseIOReactor.java:104)
	at org.apache.http.impl.nio.reactor.AbstractMultiworkerIOReactor$Worker.run(AbstractMultiworkerIOReactor.java:588)
	at java.lang.Thread.run(Thread.java:748)
Caused by: javax.net.ssl.SSLHandshakeException: General SSLEngine problem
{code}
...
{code}Caused by: java.security.cert.CertPathValidatorException: validity check failed
	at sun.security.provider.certpath.PKIXMasterCertPathValidator.validate(PKIXMasterCertPathValidator.java:135)
	at sun.security.provider.certpath.PKIXCertPathValidator.validate(PKIXCertPathValidator.java:223)
	at sun.security.provider.certpath.PKIXCertPathValidator.validate(PKIXCertPathValidator.java:140)
	at sun.security.provider.certpath.PKIXCertPathValidator.engineValidate(PKIXCertPathValidator.java:79)
	at java.security.cert.CertPathValidator.validate(CertPathValidator.java:292)
	at sun.security.validator.PKIXValidator.doValidate(PKIXValidator.java:357)
	... 23 common frames omitted
Caused by: java.security.cert.CertificateNotYetValidException: NotBefore: Thu Nov 22 01:00:00 CET 2018
	at sun.security.x509.CertificateValidity.valid(CertificateValidity.java:270)
	at sun.security.x509.X509CertImpl.checkValidity(X509CertImpl.java:629)
	at sun.security.provider.certpath.BasicChecker.verifyValidity(BasicChecker.java:190)
	at sun.security.provider.certpath.BasicChecker.check(BasicChecker.java:144)
	at sun.security.provider.certpath.PKIXMasterCertPathValidator.validate(PKIXMasterCertPathValidator.java:125)
{code}",,hj444,od044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,63849600,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,06/Dec/18 09:58,,,,,,,,,,,,,,,,,,,,,,,"1|000yrx:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Feb/19 16:58;od044;Test passed 
 * An error does not occur anymore. 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 7] Deliver Sprint Increment,XP-743,76262,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,qz412,06/Dec/18 08:11,06/Nov/20 10:14,22/Feb/21 13:26,13/Dec/18 09:29,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,qz412,,,,,,,,,,,,,,,,,,,,,,,XP-686,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69897600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yq5:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hibernate 5 might generate negative IDs,XP-739,76203,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,ll664,ll664,05/Dec/18 11:08,06/Nov/20 11:34,22/Feb/21 13:26,07/Dec/18 14:26,,,Pre2020,,Capacity,Trading,,,,,,,,"In Hibernate 5, the default strategy for dealing with auto-generated values has changed (from {{HiLo}} to {{Pooled}} optimizer). However, this requires that DB sequences are adjusted, otherwise invalid IDs are generated.

This was discovered (and fixed) in Shipping, however affects any module that uses Hibernate's auto-generated IDs, i.e:
 * CMI
 * CMM
 * Trading-inquiry - not sure here

The fix is super simple, set {{hibernate.id.new_generator_mapping}}  property to {{false}}.
 

For more details see: [https://stackoverflow.com/questions/9861416/hibernate-generates-negative-id-values-when-using-a-sequence]

 ",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69984000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07sc7:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Modularize XBID Pipelines,XP-738,76202,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,ei349,ei349,05/Dec/18 10:33,04/Aug/20 19:41,22/Feb/21 13:26,13/Feb/19 11:54,,,Pre2020,,,,,,,,,,,"{color:#57d9a3}*[BUILD SIMPLIFICATION]*{color}

There are lots of duplicates in pipeline step definitions. It would be nice to have steps more reusable. ",,ei349,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69984000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 13,Home Office Team Sprint 14,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analysis of boundaries uplift modification request from JSC,XP-737,76196,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tz118,tz118,tz118,05/Dec/18 10:16,06/Nov/20 11:31,22/Feb/21 13:26,07/Dec/18 16:32,,,Pre2020,,,,,,,,,,,"DBAG’s boundary uplift proposal has been taken positively and the topic has proven a “substance” deal maker in the whole discussion. 
The only discussion point was the OT system boundary. The customers wish to go higher than the suggested 1.5 mil order transactions/d and require/expect the system to be able to handle 2 mil. 

Action item: 
Until Friday we need to consider following – Is DBAG willing to accept 2 mil OTs a day whilst reducing the relative proportion of Order Transactions in peak to 11.25% (from originally suggested 15%) with the percentiles (93, 96.5) in place for the SLAs? All other system boundaries stay as proposed by DBAG. (formula: 15% out of 1.5 mil = 225k, 225k = 11.25 out of 2 mil)

DoD
- form a task force which is able to provide this answers
1. are there are further requirements which shall be raised by DBAG?
2. do we need to meet somewhere in the middle, OK, we just need to be able to explain the “comfort level” boundary.
-3 run test/s to confirm hypothesis if needed-

our internal position shall be aligned *by 6/12 at 14:00*",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69984000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yr9:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report Tool small issues fixes,XP-725,76168,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,uv683,uv683,04/Dec/18 14:16,06/Nov/20 10:25,22/Feb/21 13:26,10/Dec/18 16:53,,,Pre2020,,,,,,,,,,,"When KPI,SLA and CreditPoints report are being delivered at the beginning of each month there are still some minor issues which are forcing us to spend some time and do some manual steps in order to get these report into desired state.

Purpose of this Jira will be to list all these issues in one place and start resolving them one by one so that Report Tool will run on its own next month.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69465600,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Dec/18 13:30;uv683;please review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare feedback regarding RTS3SB results and TWG questions - round 2,XP-720,76101,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,03/Dec/18 14:48,06/Nov/20 10:14,22/Feb/21 13:26,13/Dec/18 09:26,,,Pre2020,,,,,,,,,,,"TWG PTF 3/12
DBAG will align internally on clarification of question in the file  [^Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF.docx] with answers related to results of RTS Slice B

DoD
- analyse questions/requests
- plan and estimate delivery of DBAG Feedback
- communicate date of delivery 
- prepare and Review DBAG answers
- ask Project Management (Simona) for support with regards to external communication",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/18 13:10;tz118;63164_Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/63485/63164_Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx","03/Dec/18 14:49;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF.docx;https://jira.deutsche-boerse.com/secure/attachment/63164/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF.docx","13/Dec/18 09:36;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/63540/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69292800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yq4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/18 13:11;tz118;[~eh941] / [~uv683] please Review proposed answer  [^63164_Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx] ","13/Dec/18 09:36;tz118;attached is reviewed version ready for communication [^Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF_DBAG.docx] 
TODO: align with PO/ACM about external communication together with Technical proposal document next year as indicated during TWG call on Monday",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migration of Jenkins jobs from enterprise to Energy,XP-718,76092,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,dm700,dm700,03/Dec/18 14:02,06/Nov/20 11:34,22/Feb/21 13:26,10/Jan/19 09:41,,,Pre2020,,,,,,,,,,,"On the end of the year the central DBAG/DBSS Jenkins will be turned off at the end of the year.
All XBID jobs should be checked if ok after migration.",,dm700,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70070400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:1w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 7,Christmas Sprint 8,Home Office Team Sprint 9,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-4505_pipeline_option_timestamps,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,XP-4505_pmi_tools_upgrade_hpfortify,XP-4505_xbid_hpfortify_upgrade,automatic-tests,TOFIX-migration-to-declarative-not-working,XP-2942-losses-perf,XP-2979-postgresql,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-1069,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,XP-4250,versions,XP-4505_reporting_tools_upgrade_hpfortify,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"03/Dec/18 14:03;dm700;contract for dev pre agreed [~ei349]. On Techops side [~qo288]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare answers to TWG questions regarding DBAG Technical proposal ,XP-703,76025,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qz412,tz118,tz118,30/Nov/18 10:02,04/Aug/20 19:16,22/Feb/21 13:26,23/Jan/19 13:57,,,Pre2020,,,,,,,,,,,"Email form Jiri Zavada on 29.11.:
TWG FTF reviewed the ASR003 - Technical Proposal_v1.0.docx provided by DBAG 19/11, please find attached the resulting document ASR003 - Technical Proposal_v1.0_commented_TWG_PTF.docx 

Will you kindly indicate by when will DBAG provide the document with answers to the TWG PTF comments ?
---------

 DoD
- estimate delivery, coordinate internally with regards to communication strategy - {color:#4C9AFF}estimate shall be delivered to Jiri until 5/12 eob{color}
- analyse questions and requests and coordinate with respective parties (eg. TechOps for Infrastructure, etc.)
- prepare answers and review internally, (ACM for business review, Jens R for technical review if needed)
- communicate to PM for external communication",,dm700,qz412,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Nov/18 10:03;tz118;ASR003 - Technical Proposal_v1.0_commented_TWG_PTF.docx;https://jira.deutsche-boerse.com/secure/attachment/63095/ASR003+-+Technical+Proposal_v1.0_commented_TWG_PTF.docx","10/Dec/18 10:29;lt112;ASR003 - Technical Proposal_v1.0_commented_TWG_PTF_v2.docx;https://jira.deutsche-boerse.com/secure/attachment/63404/ASR003+-+Technical+Proposal_v1.0_commented_TWG_PTF_v2.docx","10/Dec/18 14:03;lt112;ASR003 - Technical Proposal_v1.0_commented_TWG_PTF_v3.docx;https://jira.deutsche-boerse.com/secure/attachment/63443/ASR003+-+Technical+Proposal_v1.0_commented_TWG_PTF_v3.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65664000,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000z60r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/18 13:43;dm700;PM should coordinate outputs from dev and techops ","23/Jan/19 13:57;qz412;Answers sent to the customers, new task will be created for next iteration (if there is any).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SLA reports for November,XP-695,75994,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,uv683,29/Nov/18 13:48,04/Aug/20 19:40,22/Feb/21 13:26,05/Dec/18 09:11,,,Pre2020,,SLA Report Tool,,,,,,,,,"*Background*

XBID Report Tool is generating three reports for customers containing various performance metric, statistics and credit points. Names of these reports are (for November)
 * XBID Service Boundary Reporting November 2018.xlsx
 * XBID Performance and SM SLA Reporting November 2018.xlsx
 * XBID_Credit_points_report_November_2018.xlsx

At the moment the process of getting and providing these reports is not fully automated. They are being generated xbprodsla1 and that's it for automatition. Moreover there has been issues in generating them in past months so if this happens again (shouldn't be a problem) it needs to be done from localhost.

*What needs to be done*
 # On 3nd of December download all three reports from xbprodsla1. There is a job for this here [https://scmci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Download-SLA_Reports/].
 # Smoke check data in reports. Does it cover all the hourly and daily intervals? Maybe last hour and last day will be missing, if so connect to xbprodsla1 database and add it manually. Isn't there zeros in fields?
 # Upload files to [https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/03%20XBID%20SLA%20Reporting] in particular directories and let [~gd553] and [~qm925]know.

 ",,gd553,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-741,,,,,,,"04/Dec/18 16:18;tz118;Kopie von XBID Service Boundary Reporting November 2018v2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63230/Kopie+von+XBID+Service+Boundary+Reporting+November+2018v2.xlsx","04/Dec/18 15:43;uv683;XBID Performance and SM SLA Reporting November 2018.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63227/XBID+Performance+and+SM+SLA+Reporting+November+2018.xlsx","04/Dec/18 15:43;uv683;XBID Service Boundary Reporting November 2018.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63228/XBID+Service+Boundary+Reporting+November+2018.xlsx","04/Dec/18 16:19;tz118;XBID Service Boundary Reporting November 2018v2.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63231/XBID+Service+Boundary+Reporting+November+2018v2.xlsx","05/Dec/18 09:08;uv683;XBID_Credit_points_report_November_2018.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63238/XBID_Credit_points_report_November_2018.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69984000,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00vr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/18 15:45;uv683;[~tz118] please review","04/Dec/18 16:20;tz118;[~uv683] Reports look good, one correction needed
- Global Performance in the Credit Points Report shall be capped to 5 per DBAG 

do we know the root couse of Long RabbitMQ times?
2018-11-15 04:00:002018-11-15 05:00:00 759
 2018-11-15 05:00:002018-11-15 06:00:00 766
 2018-11-15 06:00:002018-11-15 07:00:00  645

*Boundaries Report with prognosis update was uploaded  [^XBID Service Boundary Reporting November 2018v2.xlsx] ","04/Dec/18 16:21;tz118;[~dw255] please feel free to double check reports","05/Dec/18 09:00;uv683;[~tz118] fixed and uploaded

no idea reagarding rabbitMQ times but I believe that it will come back and we will investigate further","05/Dec/18 09:10;uv683;[~gd553] [~qm925] you can find final reports on sharepoint",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse remaining docker problems and ensure docker works on all testers' machines,XP-692,75982,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,nn481,qz412,qz412,29/Nov/18 12:09,06/Nov/20 10:58,22/Feb/21 13:26,05/Dec/18 10:09,,,Pre2020,,,,,,,,,,,"DoD:
 * The problems are understood and fixed
 * All testers are able to run XBID in docker on their computers",,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70502400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07rjz:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 6] Deliver Sprint Increment,XP-686,75967,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,xu897,xu897,29/Nov/18 09:41,06/Nov/20 10:14,22/Feb/21 13:26,05/Dec/18 16:54,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,jy268,xu897,,,,,,,,,,,,,,,,,,,,,,XP-646,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69897600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07rss:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/18 16:54;jy268;SM 1.5.0.9 and XBID 1.6.0.10 released",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Benchmark data format [Mostly done; Needs update]",XP-683,75960,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qo794,qo794,29/Nov/18 08:59,31/Aug/20 15:38,22/Feb/21 13:26,04/Apr/19 10:36,,,Pre2020,,,,,,,,,,,"based on XP-636 create benchmarks with real data using the solution implemented in XP-654

The quesiton is whether to use parquet for structured data. Or use any other way to query it (Drill?)

[~ll664], [~qo794]: please provide more details, eventually close. ",,ek176,qo794,wm282,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Clarified the use of Parquet
Benchmark is postponed until the proj. is running",,,,,,,,,,,,,,59616000,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ymi:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Apr/19 09:07;ek176;Please consider also comments from [~wm282] (Feb 18, 2019):

---
 
Thank you for the links.
I see that (according to Jira, at least) there was no benchmarking completed with actual data so where do we stand on that today?
 
Also, from the XP-636 Jira it follows that the only consideration for choosing the data format was read/write performance.
 
What about considerations regarding schema versioning and backwards compatibility in case of schema changes?
It is very important factor that should never be discounted when laying a foundation for something that is will serve as a universal platform for many different things.
 
At least I would expect a statement on that (i.e., acknowledging and accepting Parquets limitations in the “schema evolution” area) before the format selection is finalized.
 
Kind regards,
Andrei Nazarenko","04/Apr/19 10:34;ek176;Parquet was selected as it is column oriented.
We are aware about 'schema evolution', in Parquet, the schema is part of the file (stored in the footer).

Performance benchmark is not an issue now, it's a PoC. Will be performed eventually when we have more data and fixed project structure.","04/Apr/19 12:13;wm282;[~ek176]

My concern was not about whether the developers are aware about the location of the schema with Parquet (where it is stored and how).

Parquet does not offer same flexibility like Avro with regards to schema evolution.

The only real ""evolution"" that Parquet allows are the append operations like addition of columns to schema (and even not without performance impact when doing schema merging).

But Avro is suitable for both appending, deleting and modification operations that (depending on application requirements) may be critical requirements.

Once again, I am asking to recognize these limitations so that they are taken into account when new software is architected OR reconsider the data format, ""before it is too late"".

 

 

 

.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
XBID Number of Trades since Business Go-live ,XP-681,75951,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qm925,qm925,qm925,28/Nov/18 15:31,06/Nov/20 12:18,22/Feb/21 13:26,03/Dec/18 15:40,,,Pre2020,,,,,,,,,,,"Dear all,

We need to provide the number of Trades to the PXs:
 * total since Business Go-live until 2nd Dec EOD
 * total for 1st + 2nd Dec

Expected delivery date is *Monday, 03.12*",,eg288,qm925,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70070400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07rsv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/18 15:40;eg288;Trade counts:

12.06. - 02.12:  6318558

01.12. - 02.12:  97576",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse and compare test results from XP-664,XP-676,75933,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qz412,tz118,tz118,28/Nov/18 11:04,04/Aug/20 19:15,22/Feb/21 13:26,15/Jan/19 11:44,,,Pre2020,,,,,,,,,,,"Analyse and compare test results from XP-664

DoD
 * analyse additional DB setup results for SC14 and SC15 (if results are as defined scenario in terms of parameters, eg. load)
 * compare between executions and define impact in response times
 * prepare quick management summary description

results link:
 S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\RTS3\slice B\execution\obk-db-imrovements",,dw255,tz118,,,,,,,,,,,,,,,,,,,,,,XP-637,,,,,,,,,,,,,,,,,,,"30/Nov/18 16:42;tz118;Perf_DB_OBK_results_analysis_v3.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63123/Perf_DB_OBK_results_analysis_v3.xlsx","12/Dec/18 11:36;tz118;Perf_DB_OBK_results_analysis_v6.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63517/Perf_DB_OBK_results_analysis_v6.xlsx","30/Nov/18 16:35;dw255;XP-648.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63120/XP-648.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69379200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrw:or",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Nov/18 16:35;dw255;93 and 96,5 percentiles are added to excel files in S: drive and files are saved with _enhanced suffix. New runs are added to previous ones in attached excel. [^XP-648.xlsx]","30/Nov/18 16:42;tz118;results comparison attached  [^Perf_DB_OBK_results_analysis_v3.xlsx] ","12/Dec/18 11:37;tz118;comparison with 3 new runs with diff DB configuration from last week attached  [^Perf_DB_OBK_results_analysis_v6.xlsx] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JSC presentation support,XP-674,75929,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,tz118,tz118,28/Nov/18 10:33,06/Nov/20 10:14,22/Feb/21 13:26,05/Dec/18 16:34,,,Pre2020,,,,,,,,,,,be available and present/support boundaries uplift proposal during JSC on 4.12.,,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70588800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00vy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup dockerized Hadoop cluster (Postgres => Sqoop => Hadoop cluster),XP-654,75701,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ek176,ll664,ll664,22/Nov/18 15:22,04/Aug/20 19:40,22/Feb/21 13:26,13/Dec/18 09:26,,,Pre2020,,,,,,,,,,,"*Outcome:*
 * Consider Hadoop version to be used with Sqoop
 * make it work and showcase to the teams (CoP)
 * findings are added to confluence space",,ek176,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69292800,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,Alpha Team Sprint 6,Alpha Team Sprint 7,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Dec/18 09:26;ek176;The code is available in the following repo (we have decided not to merge it into XBID repo):

[https://github.deutsche-boerse.de/dev/xbid-etl/tree/XP-654-dockerizing-hadoop]

 Howto start servers: 

cd hadoop_sqoop_etl/docker ; make build && docker-compose up

Finished:
 * dockers: (Hadoop+Yarn+Sqoop+Spark) servers and small PostgreSQL; start with docker-compose
 * test: HadoopUtilsTest.java: Verifies access and basic ops over HDFS
 * test: SqoopUtilsTest.java: Verifies running Sqoop server
 * test: ProdCopyRunningPostgreSqlTest.java: Verifies running ProdCopy postgres
 * test: EDH_ETL_SqoopJobTest.java: Starts the Sqoop job and verifies that it has been executed (a new file in HDFS was created)
 * scala scripts that can be submittted via spark-submit.sh (client mode) without compilation to (fat) JAR. Good for local development. For cluster mode, it has to be compiled into (fat) JAR.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 5] Deliver Sprint Increment,XP-646,75689,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,xu897,qz412,22/Nov/18 14:49,06/Nov/20 10:14,22/Feb/21 13:26,29/Nov/18 09:33,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]



 

 ",,qz412,,,,,,,,,,,,,,,,,,,,,,,XP-484,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71020800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00yi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PMI Review/Compare/Create new OrdrMngt tests in Cucumber vs RTM_03-05-10,XP-643,75658,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tm431,tm431,22/Nov/18 09:28,09/Feb/21 13:20,22/Feb/21 13:26,09/Feb/21 13:20,,,Pre2020,,,,,,,ice,,,,"Matcher and Order Maintenance Regression test model RTM-03-05-10 will be compared with existing cucumber test in code.

Following non existing cucumber test will be added:
 * Auction
 * Block orders

S:\Energie\Prod_DEVELOP\002 Test\002 XBid Release\Test Models\22_Updated_Regression",,hj444,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00yi6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Feb/21 13:20;hj444;Block orders : https://jira.deutsche-boerse.com/browse/XP-2057
Auction order matching: https://jira.deutsche-boerse.com/browse/XP-1855
Iceberg Auction scenarios : https://jira.deutsche-boerse.com/browse/XP-1858

This Jira will be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Internal Test Strategy - Ampere's contribution ,XP-642,75656,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cf948,qz412,qz412,22/Nov/18 09:24,06/Nov/20 10:14,22/Feb/21 13:26,29/Nov/18 09:31,,,Pre2020,,,,,,,,,,,"Review Alpha's + HOT's Internal test strategy suggestions, add your ideas, finalize the document.

Link:
http://172.19.250.235:8090/confluence/display/XBID/Test+Strategy+Draft",,qz412,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70761600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b00g",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/18 10:34;radeale;My few bits...

http://172.19.250.235:8090/confluence/display/XBID/Ampere+Test+Strategy+Review",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MVP - Implement the first part - data transfer to HDFS,XP-639,75648,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,de698,de698,21/Nov/18 16:38,04/Aug/20 19:41,22/Feb/21 13:26,13/Dec/18 14:53,,,Pre2020,,,,,,,,,,,"The first step to build the MVP is to create a simple report. Full end-to-end process is not achievable in one sprint and it has to be delivered in several increments, this task being the first.

*Background:* refer to [http://172.19.250.235:8090/confluence/pages/viewpage.action?title=Data+Lake+Product+Vision&spaceKey=EDW] and _Data Lake MVP Draft.pptx_.

*What needs to be done:*
 * implement the ETL job to transport the first set of data from prod DB to HDFS infrastructure
 * chosen report is to be SLA report - Order count

*Pre-condition:* HDFS infrastructure is in place (monitor the progress of TechOps Jiras TECHLOG-1548, TECHLOG-1547)

*Outcome:*
 * 1-2-1 copy of selected prod data is present in Hadoop
 * Gathered knowledge described in dedicated confluence space (link above)",,de698,ek176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-214,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71107200,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00yi06r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse and compare test results from XP-467 (PERF db SSD array installed),XP-637,75645,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tz118,tz118,21/Nov/18 16:26,04/Aug/20 19:16,22/Feb/21 13:26,28/Nov/18 11:08,,,Pre2020,,,,,,,,,,,"Analyse and compare test results from XP-467

DoD
* analyse results (if results are as defined scenario in terms of parameters, eg. load)
* compare between executions and define impact in response times

results link:
S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\RTS3\slice B\execution\obk-db-imrovements",,dw255,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/18 15:57;dw255;XP-648.xlsx;https://jira.deutsche-boerse.com/secure/attachment/62690/XP-648.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70934400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:001",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/18 15:58;dw255;XP-648 Analyze results - confirm correctness:

Scenario 14 was executed correctly with all configurations. Results are comparable.

Scenario 15 was executed the same way for current system, DB upgrade and Orderbook upgrade. These results are comparable. The test on system with both DB and Orderbook upgrade has different numbers of executed orders and trades.

Overview is in attached file XP-648.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MVP - Discussion about data format store in hadoop,XP-636,75641,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qo794,de698,de698,21/Nov/18 16:19,04/Aug/20 19:41,22/Feb/21 13:26,29/Nov/18 08:56,,,Pre2020,,,,,,,,,,,"Analytical task.

*Background:* technology pool for the Data Lake MVP is set. However, a discussion arose around the decision for Parquet, Avro, or other alternative technologies for the data store in Hadoop. Developers will have the best insight into the topic and can contribute with further investigation to support the final decision on data store technology.

*Outcome:* dedicated confluence space is updated with relevant information http://172.19.250.235:8090/confluence/display/EDW/XBID+reports+requirements

 ",,de698,ek176,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/18 15:00;qo794;An-Introduction-to-Big-Data-Formats-Nexla.pdf;https://jira.deutsche-boerse.com/secure/attachment/63039/An-Introduction-to-Big-Data-Formats-Nexla.pdf","28/Nov/18 14:44;qo794;File format benchmark_ Avro, JSON, ORC, and Parquet Presentation.pptx;https://jira.deutsche-boerse.com/secure/attachment/63036/File+format+benchmark_+Avro%2C+JSON%2C+ORC%2C+and+Parquet+Presentation.pptx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70588800,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xhhw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 5 (PS),,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/18 11:59;qo794;h4. Comparison
||Format||Columnar/Row||Heavy Read/Write||Compression||Splitability||Schema evolution support||Support||Notes||
|Apache Avro|Row|Write|Good|Great|Full|Kafka,Druid,Hive||
|Apache Parquet|Columnar|Read|Great|Great|Adding only|Impala,Spark,Drill,Arrow,Hive|Indexes,Summary/Statistics|
|Apache ORC|Columnar|Read|Excellent|Excellent| |Hive,MapReduce,Spark|Indexes,Summary/Statistics|

h4. Conclusion
Overall these format can drastically optimize workloads, especially for Hive and Spark which tend to just read segments of records rather than the whole thing (which is more common in MapReduce). Since these formats have so much in common when choosing a file format to use with HDFS, we need to consider read performance and write performance. Because the nature of HDFS is to store data that is write once, read multiple times, we want to emphasize on the read performance. The fundamental difference in terms of how to use either format is this: Avro is a Row based format. If you want to retrieve the data as a whole, you can use Avro. Parquet and ORC are Column based formats. If your data consists of lot of columns but you are interested in a subset of columns, you can use Parquet or ORC.

There are not many (almost none) benchmarks available comparing Parquet and ORC formats,  [^File format benchmark_ Avro, JSON, ORC, and Parquet Presentation.pptx] presentation depicts slightly better values for ORC in comparison to Parquet.

h4. ToDo
Benchmark on our real data using MVP from XP-639",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix logging,XP-629,75630,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,lt112,lt112,lt112,21/Nov/18 14:39,06/Nov/20 11:34,22/Feb/21 13:26,26/Nov/18 12:53,,,Pre2020,,,,,,,CONFIGURATION,,,,after https://jira.deutsche-boerse.com/browse/XDEV-5546 logging does not work,,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71107200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/82,,,,,,,,,,,,,,,,,,,,"1|000yu5:xhhr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 5 (PS),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JSC - prepare a slide set with system boundaries proposal,XP-624,75593,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,qz412,qz412,21/Nov/18 09:08,04/Aug/20 19:16,22/Feb/21 13:26,28/Nov/18 10:39,,,Pre2020,,,,,,,,,,,"The table needs to be put into a few commented slides for the business JSC audience.

[~rg535] - please help us with detailed description of what is expected. Thx!

[~qz412], Suzanna Vogeler provides the following input: ASR003 defines the following:
 * *Analysis of Service Boundaries by DBAG*

 # Analyse the possibilities for (further) uplifting the Service Boundaries of the XBID Solution stipulated in *Exhibit 20* (_Boundaries of Service_) ({color:#ff0000}SV states that this is the excel sheet which you have been working on{color})
 # Evaluate the results taking into consideration the enduring XBID Solution stability ({color:#ff0000}SV states that this is the task that you are currently working on, I think{color})
 # Present and discuss the results including presentation of the way forward to the JSC ({color:#ff0000}the results of 1 and 2 need to be put in management format on a JSC slide{color}).

Based on the three points above we need to:
 # put the proposal for the Service Boundary Uplifts need to put on a slide for the JSC.
 # provide some bullet points in management format with the concept of the uplift, reasoning and explanations behind the uplift proposal. This can include arguments from the Technical Proposal. The slide should also include an explanation of the infrastructure uplift.
 # add the commercials associated with the uplift (*SV will do this*). 
 # present the slides in the JSC at the beginning of December.

Please use the attached template.

The slide set for the JSC can also be found under XBID on SharePoint under meetings/external meetings/2018/JSC

Internal deadline for the slides: {color:#de350b}*28/11/2018 12:00*{color}",,qz412,rg535,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Nov/18 11:26;qz412;201812XX_PPI140G_Executive_Status_Report.pptx;https://jira.deutsche-boerse.com/secure/attachment/62569/201812XX_PPI140G_Executive_Status_Report.pptx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70502400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:009",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/18 16:19;tz118;slide set with system boundaries proposal was included on the SharePoint (meetings/external meetings/2018/JSC) as per agreement with [~rg535]","28/Nov/18 10:39;tz118;Slides available on the SharePoint, closing, new task created regarding JSC call","29/Nov/18 10:06;rg535;Thank you, [~tz118]. Please edit the slides based on my comments on each slide. Please do before 13:00 today, if at all possible.","29/Nov/18 12:22;tz118;
Dear [~rg535], slides are edited and updated based on the comments and as discussed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse and prepare feedback regarding TWG questions - Non-High Prio Items [ASR003] (Alpha component),XP-620,75573,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,tz118,tz118,20/Nov/18 14:39,11/Aug/20 16:35,22/Feb/21 13:26,23/Jan/19 11:04,,,Pre2020,,,,,,,,,,,"Analyse and prepare feedback regarding TWG questions - *other* than {color:#de350b}*red* {color}text (see attached file)

DoD
 * analyse questions/comments
 * investigate where applicable (have a proof at hand if available)
 * prepare answers
 * review answers

Answers shall be sent to ACM/PO for business review before communicating externally",,lt112,nn481,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Dec/18 13:54;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF.docx;https://jira.deutsche-boerse.com/secure/attachment/63280/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0_commented_TWG_PTF.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65750400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000j",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/19 10:45;uv683;Answer to 10,2,11 page 2:
{code}
After some additional analysis of these three scenarios it has been discovered, that scenarios 10 and 11 were wrongly configured in the first place. They had 5500 and 8500 less events respectively. These missing event were order deletions. Scenario is designed in a way that orders from prefill are deleted. However in this case prefill was smaller that required number of deletions and thus some deletions were not send. Deletions were a big part of Peak2 which means that Peak2 were also significantly lower than they should be. Peak2 in scenarios 10 and 11 should last 2 seconds and should have 1300 events in total. In reality these peaks had only 816 events. Peak2 in scenarios 2 had correctly 1306 events. Peak2 in SC10 and SC11 are only 62 % of peak2 in SC02. This is why SC02 has by far the worst performance. Regarding performance between SC10 and SC11, answer has already been provided.
{code}","21/Jan/19 10:55;uv683;Answer to 1,2,3,4 page 1 by [~eh941]
{code:java}
For scenarios 1,2,3,4 there are the same amount of the orders sent during the peaks but within different time frame. The system has limited throughput and when it's exceeded the messages are getting queued. If there are short peaks with very high load the system queues them and the high percentiles have high times because the messages wait in the queue. When the load is distributed to longer time the queuing isn't used that much and the message doesn't wait that long to be processed. {code}","21/Jan/19 13:51;nn481;Answer to 1,2,3,4 page 2:
{code}
Bottleneck causing the high percentiles is journalling, journaller in SC01 was overloaded in 6 of 15 peaks (peak2),  journaller in SC02  was overloaded in 10 of  15 peaks (peak2). 
Because SC01 had higher peaks, it caused higher reponse times in that 6 peaks (97-100 percentile is worse than SC02). 
SC02 had lower peaks but journaller was overloaded more often, this caused higher response times during 87-97 percentiles.
{code}","21/Jan/19 14:58;lt112;Answer to 6,2,7 page 2:
{noformat}
Number of responses is irrelevant, as it is somewhat randomized. Increase in Order execution time is present as expected.
{noformat}","22/Jan/19 10:32;lt112;Answer to 5,14 and 2,15, page 2:
{code}
Relaxing order-book depth causes more difficult computation, thus decreasing performance. It is then correct, that scenario 15 is slower than scenario 2. Also, it's the orders that are not traded that make the calculation more difficult (as the fully traded orders are not taken into account), therefore more trades for the same amount of orders is actually better for the order-book calculation.

As for the 5 vs 14, system overload was observed for scenario Scenario 5 (SC05) as there was higher load than expected within 3 last peeks (somewhat compromising the result), thus the scenario 14 appears to be better.
{code}","22/Jan/19 10:38;lt112;Answer to 12,2,13, page 2:
{code}
Scenario 2 (SC2) is performing slightly slower than scenario 12 (SC12). Aprox. 18 % on 99.50 OrdrExe time. This could be caused by increased number of orders in 15minute and/or eventually by statistical discrepancy.
After closer investigation of scenario 13 (SC13) it was discovered that there was lower count of orders sent to XBID. SC12 has 172k count of responses  (mostly orders) whereas SC13 has 164k. Specifically, approximately 8k less order deletions were generated for SC13. This caused the overall order difference between scenarios and within peaks which resulted in observed performance improvement of SC13.

It is unrelated to Explicit capacity allocations, nor the number of trades.
{code}","22/Jan/19 10:41;lt112;Answer to 5,15, page:
{code}
System was overloaded with external requests during performance testing of Scenario 05. System overload means heavier load on the system than it can handle at a time.
{code}","22/Jan/19 10:48;lt112;Answer to Parameters vs. Counts, page2:
{code}
Achieving the exact numbers as parametrized is a fairly difficult task, thus large variance can occur in some cases.
{code}
{code}
?
{code}
{code}
Explicit allocation have minor impact on KPIs
{code}","22/Jan/19 13:41;uv683;Answer to 6,2,7 page 1

{code}

Performances decrease with the increase of order transactions in peak.
DBAG: This is expected behaviour. Height of the peak is the major indicator of performance load. The higher the peak the slower the system.

{code}","23/Jan/19 09:14;nn481;Answer to 8,4,9, page 2:
{noformat}
Actually higher peaks mean worse percentiles. So the question is why is SC08 slower than SC04 when SC08 has lower peaks.
We have found that SC08 has 37% of order deletes in peak2, SC04 has 0% of order deletes in peak2, so scenarios are not same.
Detail analysis showed that high percentiles of SC08 are caused by order deletes of peak2 on persister, 3 of 18 peaks is affected.
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyse and prepare feedback regarding TWG questions - High Priority Items (red text) [ASR003],XP-619,75572,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tz118,tz118,tz118,20/Nov/18 14:27,11/Aug/20 16:36,22/Feb/21 13:26,30/Nov/18 10:49,,,Pre2020,,,,,,,,,,,"Analyse and prepare feedback regarding TWG questions - {color:#de350b}*red* {color}text (see attached file)

DoD
 - analyse questions
 - investigate where applicable (have a proof at hand if available)
 - prepare answers
 - review answers

Answers to be provided externally on *29.11.*, ideally sent prepared answers to ACM for review on 28th eob.",,eg288,eh941,nn481,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-720,,,,,,,"20/Nov/18 13:56;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAG.docx;https://jira.deutsche-boerse.com/secure/attachment/62536/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAG.docx","28/Nov/18 17:26;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv1.0.docx;https://jira.deutsche-boerse.com/secure/attachment/63042/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv1.0.docx","29/Nov/18 16:20;tz118;Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0.docx;https://jira.deutsche-boerse.com/secure/attachment/63082/Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0.docx","28/Nov/18 10:25;tz118;Check-validation-failed.xlsx;https://jira.deutsche-boerse.com/secure/attachment/63003/Check-validation-failed.xlsx","27/Nov/18 13:43;eh941;SC02 Journal time-1543322586325.json;https://jira.deutsche-boerse.com/secure/attachment/62956/SC02+Journal+time-1543322586325.json","27/Nov/18 13:43;eh941;SC12 Journal time-1543322584081.json;https://jira.deutsche-boerse.com/secure/attachment/62957/SC12+Journal+time-1543322584081.json","21/Jan/19 15:40;uv683;SC_06.dmp;https://jira.deutsche-boerse.com/secure/attachment/64669/SC_06.dmp","21/Jan/19 15:09;uv683;SC_07.dmp;https://jira.deutsche-boerse.com/secure/attachment/64667/SC_07.dmp","29/Nov/18 08:48;uv683;SC_11.dmp;https://jira.deutsche-boerse.com/secure/attachment/63052/SC_11.dmp","28/Nov/18 08:40;uv683;SC_13.dmp;https://jira.deutsche-boerse.com/secure/attachment/62987/SC_13.dmp","21/Jan/19 09:38;nn481;report_tool_sc01.dmp;https://jira.deutsche-boerse.com/secure/attachment/64630/report_tool_sc01.dmp","27/Nov/18 13:50;eh941;report_tool_sc02.dmp;https://jira.deutsche-boerse.com/secure/attachment/62961/report_tool_sc02.dmp","18/Jan/19 11:46;eh941;report_tool_sc03.dmp;https://jira.deutsche-boerse.com/secure/attachment/64539/report_tool_sc03.dmp","22/Jan/19 15:21;nn481;report_tool_sc04.dmp;https://jira.deutsche-boerse.com/secure/attachment/64719/report_tool_sc04.dmp","21/Jan/19 15:51;nn481;report_tool_sc08.dmp;https://jira.deutsche-boerse.com/secure/attachment/64671/report_tool_sc08.dmp","22/Jan/19 14:38;nn481;report_tool_sc09.dmp;https://jira.deutsche-boerse.com/secure/attachment/64710/report_tool_sc09.dmp","29/Nov/18 08:50;eh941;report_tool_sc10.dmp;https://jira.deutsche-boerse.com/secure/attachment/63053/report_tool_sc10.dmp","27/Nov/18 13:46;eh941;report_tool_sc12.dmp;https://jira.deutsche-boerse.com/secure/attachment/62958/report_tool_sc12.dmp","29/Nov/18 09:06;nn481;sc04_sc08_sc09.dump.gz;https://jira.deutsche-boerse.com/secure/attachment/63054/sc04_sc08_sc09.dump.gz","28/Nov/18 11:53;eh941;sc13_to_check.xml;https://jira.deutsche-boerse.com/secure/attachment/63024/sc13_to_check.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,70416000,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,Alpha Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,Simulation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/18 13:46;eh941;Added dumps and grafana exported dashboards for sc02 and sc12","28/Nov/18 10:27;tz118;added overview of ""validation failed"" requests","28/Nov/18 13:22;uv683;*Resolution 12,2,13*
Scenario 2 (SC2) is slightly worse than scenario 12 (SC12). Aprox. 18 % on 99.50 OrdrExe. This could be caused by increased number of orders in 15minute or it is just a statistical discrepancy.
However we have investigated scenario 13 (SC13) a little bit deeper and unfortunately found out that less orders with lower peaks has been sent into XBID during its execution. SC12 has 172k events (mostly orders) whereas SC13 has 164k. Moreover SC12 has multiple high peaks where number of orders reaches 700 per second. In SC13 these peaks have only 470 orders. 

DBAG is using internal tool that is generating and sending a load to XBID. Due to the wrong configuration in SC13, this tool generated aprox 8k less order deletes. This caused the overall order difference between scenarios and lower peaks which resulted in big performance improvement of SC13.","28/Nov/18 13:57;eh941;*Resolution 5,15*
We found out that in Scenario 5 (SC5) there are doubled last 3 peeks which caused very high API Response Time in higher percentages. These times influence the most of the other times including Orderbook Computation Propo. There are measured about 1300 order events per second during these 3 peaks instead of expected 700.","28/Nov/18 14:01;uv683;*Resolution 5,2*

Same issue with SC5 as in *Resolution 5,15*","28/Nov/18 14:27;eg288;*Resolution 10,11*
 * both has the same order volumes in peak 1 and peak 2
 * sc10 has sligthly higher base load
 * sc11 has more frequent peaks 2 to ensure there is more orders in peaks then in sc 10
 * in total sc11 has less order transactions (the difference is 4000)
 * 95% percentile the times are very similar
 ** only small percent of order transactions is being processed significantly longer in sc10 (all outliners occurred during peak 2)
 * pk2 + base load results into slightly higher peaks in sc10, in other words we have less peaks in sc10 but more intense
 ** the difference is really small (order transaction volumes in *sc10*: 3998, *sc11*: 3817 [per minute with peak2])
 ** looks like we have found breaking point where the system is getting overloaded and overall performance is degrading","28/Nov/18 14:28;nn481;*Resolution 4,8,9*
Summary of the scenarios:
* sc04 - 95%:104ms, customer assignment in peak: 1300, reality: 10x175 messages in peak in total, peak window (200ms)
* sc08 - 95%:195ms,customer assignment in peak: 1100, reality: 11x160 messages in peak in total,  peak window (100ms)
* sc09 - 95%:243ms,customer assignment in peak: 1750, reality: 11x220 messages in peak in total,  peak window (10ms)

The worst OrderExe times came from peaks. Scenario sc09 has highest message count sent during shortest peak window it implies highest percentile. Scenario sc08 has lower message count sent during one peak then sc04, but sc08 has higher percentile. There is difference in time window for each peak: sc04 has 200ms, sc08 has 100ms which is reason for higher percentile for SC08.
*Bottleneck at this cases is persister.*

Discrepancies between customer assignment and our scenario definition excel:

||scenario||customer assignement||scenario excel||95%||total sent in peak||peak window||
|sc04|1300|1310|104|175|200|
|sc08|1100|1100|195|160|100|
|sc09|1750|1760|243|220|10|
","28/Nov/18 17:28;tz118;Answers consolidated and updated based on the Alignment Meeting today.   [^Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv1.0.docx] 
Please Review and propose answer for SC 10 & 11","29/Nov/18 09:33;uv683;Stefan, please consolidate answers","29/Nov/18 10:41;eh941;For sc10 vs sc11 compare:

The problem: *sc10* should perform a bit better because it has *only 15 %* of the orders in peak and *sc11 has 20 %*.
 Reality: *sc11 perform a +way+ better*.

From the first look the times are determined by API response times:
||Scenario||Count of responses||Percentile 99.95%||Percentile 99.50%||Percentile 95.00%||
|sc10|165830|5481.00|4145.00|99.00|
|sc11|161575|195.00|154.00|88.00|

From grafana I can see that the overall runs are pretty much the same. But looking deeply into journal times I found out that during sc10 run the journal sometimes performed very poorly during the peeks. On the other hand sc11 always performed perfectly during the peaks (PK2)

{code:sql|title=SC10|borderColor=red}
select avg(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%'
2.2218137254901961

select sum(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%'
21756

select count(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%';
9792
{code}

{code:sql|title=SC11|borderColor=green}
select avg(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%'
0.41591775599128540305

select sum(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%'
6109

select count(journaller_time) from sender_real_times_all_restricted where name ILIKE '%Pk2%';
14688
{code}

From the numbers above notice that sc11 has 1.5 times more added orders during the peaks yet it has more than 3.5 times lower total time spent in journal. This is super weird.

 ","29/Nov/18 15:32;eh941;*10,11*
I agreed with Jirka that there is no point in further investigation.

As answer to the customers I suggest:
The differences between sc10 and sc11 start to be significant at very high percentages. It's caused by two factors. The first factor is number of sent orders during the peaks. Scenario sc10 has less peaks but the same overall amount of the sent order events. These order events are present in the base load which cause higher number of order events during the peaks (base load is sent constantly, including peaks). The second factor is non-deterministic batching that may lead to different measurements in the high percentages.

Please [~eg288] to review my answer","29/Nov/18 15:57;tz118;Answers consolidated and updated.  [^Analysis_of_the_RTS3_Slice_B_results_supplied_by_DBAGv2.0.docx] 
Please raise a hand in case of update needed until today eob. Thanks, Stefan","30/Nov/18 10:49;tz118;answers communicated externally",,,,,,,,,,,,,,,,,,,,,,,,,
"Improve local deployment - replace jetty plugin (it does not work), align that everybody use Tomcat",XP-615,75541,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,eg288,eg288,19/Nov/18 16:36,06/Nov/20 10:59,22/Feb/21 13:26,05/Dec/18 13:13,,,Pre2020,,Capacity,Trading,,,,,,,,"* no jetty support - remove it
* improve standalone tomcat deloyment
** ideally utilize idea run configuration, deploying into vanilla tomcat, all configuration files required for local deployment are in repository
* update README files
* implement at least for cmi, cmm, trading-inquiry (core can be started with spring-boot)",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71280000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,19/Nov/18 16:36,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b00hi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 5,Ampere Sprint 6,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Finalize and test deployment verifier [+ how do we make sure it is a standard part of every deployment?],XP-603,75495,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,nn481,nn481,19/Nov/18 10:12,04/Aug/20 19:40,22/Feb/21 13:26,27/Jun/19 14:16,,,Pre2020,,,,,,,waiting-techops,,,,,,ei349,nn481,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,52358400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:zuc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/19 12:52;rehapav;Until relevant techlog tickets are delivered, please provide manual instructions for TechOps how to run the test per environments.
something like:
 - connect to host1
 - switch environment CuTe A
 - get test from github
 - run test on CuTe A
 - validate results","01/Mar/19 09:08;nn481;Manual instructions within script: https://github.deutsche-boerse.de/dev/xbid-deploy-verifier/blob/develop/pipeline/deployer-veryfier-pipeline","27/Jun/19 14:16;ei349;Verification and follow up actions in XP-1687",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use Ansible for deployment of XBID components - REPORTING ENGINE,XP-600,75454,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,nn481,cv179,cv179,16/Nov/18 16:15,06/Nov/20 09:08,22/Feb/21 13:26,17/Jan/19 09:22,,,Pre2020,,Reporting Engine,,,,,,,,,"{color:#de350b}--- consult in slack channel #energy-deployment ---{color}

Create idempotent ansible role to deploy *reporting engine* component.

Execution of the role like this:
{code:java}
ansible-playbook playbooks/deploy_xbid_rep.yml --limit 'xb-xbid-syt3*'
{code}
Should lead to the component being deployed on a host that already has prepared users and filesystems as well as already java version available.

Tags available for deployment should be:
 * clean (stops and removes)
 * stop (just stop)
 * start (starts instance)
 * deploy (redeploy instance)

Repository to contain the role and playbook is this one:

[https://github.deutsche-boerse.de/dev/energy.automation.deployments]

Parameters should go to inventory repository.

Guidelines can be found here: 

[http://172.19.250.235:8090/confluence/display/ET/Ansible+guidelines+for+Energy]

eg. Connecting user can be personal user. The role should itself change to technical account...

 

 

 ",,cv179,qo794,,,,,,,,,,,,,,,,,,,,,,,,,INIT-203,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69292800,,,,,,,,,,,,,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 6,Home Office Team Sprint 7,Christmas Sprint 8,Home Office Team Sprint 9,Home Office Team Sprint 10,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-600-qo794,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"13/Dec/18 09:20;qo794;Everything is in *XP-600-qo794* branches in *energy.automation.deployments* and *energy.automation.inventory* projects. The current status:
(/) the already configured AWS servers deployment - rabbitmq, ha proxies, ldap, mail server, core, core database
(/) reporting engine database
(/) initial configuration RE tomcat (copied from sob - unfortunately it's the current way how to implement it)
(/) tomcat deployment added to the terraform playbook

(x) ssl configuration of ha proxies - missing keystore in the vault
(x) reporting engine flyway
(x) reporting engine parameters in application properties
(x) review by techops",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing indexes in some tables in XBID PROD,XP-598,75433,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Not a Bug,radeale,iO924,iO924,16/Nov/18 12:49,06/Nov/20 11:34,22/Feb/21 13:26,30/Nov/18 10:25,,,Pre2020,,,,,,,,,,,"With CyberTec we found some time in the past that tables:

 

cmm_150_message,

cmm_100_allocation,

cmm_120_capacity are missing indexes.

 

Can you please check if this is still the case",,iO924,radeale,,,,,,,,,,,,,,,,,,,,,,TECHLOG-803,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70416000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07rsv:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Nov/18 15:08;radeale;Currently nothing is needed from the XBID DEV team. Steffen will probably let us know once this changes... And I'll reopen this ticket.

+His comments from the slack communication:+

_Its about missing indexes and i have a similar ticket for xbid production database.. https://jira.deutsche-boerse.com/browse/TECHLOG-821 about slow queries.._
 _to analyze these tickets we need to enable the modul pg_stat_statements to get proper statistics informations._
 _i already created today a SERVICE-Task to enable this modul in the next/2 weeks, than i will have a look with cybertec together on the database._

_right now we dont need support from the dev guys.. we want to enable modul on xbid prodcution database like we did it last week for simulation database.._
 _than we have more informations to analyze slow queries and missing indexes and to find the reason for this._
 _than we can communicate to the dev´s when we find the reason for the issue_",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix CMM reports download in 1.6.x branch,XP-588,75368,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,jy268,jy268,15/Nov/18 08:19,06/Nov/20 12:40,22/Feb/21 13:26,21/Nov/18 16:02,,,Pre2020,,Capacity,,,,,,,,,"Due to migration to Hibernate 5 we are not able to download reports anymore. Exception occurs:

{code}
javax.persistence.TransactionRequiredException: no transaction is in progress
{code}",,jy268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Interceptor was added to RequestHandler class,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,15/Nov/18 08:19,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b00i",9223372036854775807,,,,,,,,,,,Missing transaction interceptor on RequestHandler class,,,,,,,,,,,,Ampere Sprint 4,,,,,,,,,,,,,,,,,,,,,"Try to download any report, it should be successful",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Technical Proposal for Improvements (ASR003),XP-584,75336,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,tz118,rg535,rg535,14/Nov/18 15:32,06/Nov/20 12:50,22/Feb/21 13:26,20/Nov/18 10:09,,,Pre2020,,,,,,,,,,,"Dear all,

 As you know, you agreed to provide the Technical Proposal for the Improvements (ASR003) on 16.11.2018. I have attached a draft document which you need to complete by tomorrow. The document needs to be ready for internal review by Thursday, 15:00.

 Please distribute to the necessary team members.

 Kind regards,

 

Suzanna",,gd553,qm925,qz412,rg535,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/18 15:30;rg535;ASR003 - Technical Proposal_v01.docx;https://jira.deutsche-boerse.com/secure/attachment/62183/ASR003+-+Technical+Proposal_v01.docx","16/Nov/18 11:45;tz118;ASR003 - Technical Proposal_v02.docx;https://jira.deutsche-boerse.com/secure/attachment/62387/ASR003+-+Technical+Proposal_v02.docx","16/Nov/18 10:08;uv683;ASR003 - Technical Proposal_v03.docx;https://jira.deutsche-boerse.com/secure/attachment/62350/ASR003+-+Technical+Proposal_v03.docx","16/Nov/18 11:45;tz118;ASR003 - Technical Proposal_v04.docx;https://jira.deutsche-boerse.com/secure/attachment/62386/ASR003+-+Technical+Proposal_v04.docx","16/Nov/18 12:50;qz412;ASR003 - Technical Proposal_v05_OS.docx;https://jira.deutsche-boerse.com/secure/attachment/62396/ASR003+-+Technical+Proposal_v05_OS.docx","16/Nov/18 13:42;tz118;ASR003 - Technical Proposal_v06.docx;https://jira.deutsche-boerse.com/secure/attachment/62398/ASR003+-+Technical+Proposal_v06.docx","19/Nov/18 14:43;rg535;ASR003 - Technical Proposal_v07.docx;https://jira.deutsche-boerse.com/secure/attachment/62493/ASR003+-+Technical+Proposal_v07.docx","19/Nov/18 15:58;tz118;ASR003 - Technical Proposal_v09.docx;https://jira.deutsche-boerse.com/secure/attachment/62505/ASR003+-+Technical+Proposal_v09.docx","19/Nov/18 16:00;tz118;ASR003 - Technical Proposal_v1.0.docx;https://jira.deutsche-boerse.com/secure/attachment/62507/ASR003+-+Technical+Proposal_v1.0.docx","14/Nov/18 15:31;rg535;RTS3 Slice B_timeline_v3.0.pptx;https://jira.deutsche-boerse.com/secure/attachment/62182/RTS3+Slice+B_timeline_v3.0.pptx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71280000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:wg",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/18 10:10;uv683;[^ASR003 - Technical Proposal_v03.docx] added. 
 * Journal time and database optimization added
 * data structures rewritten
 * caching rewritten","16/Nov/18 11:46;tz118; attached consolidated and updated document ready for team review  [^ASR003 - Technical Proposal_v04.docx] ","16/Nov/18 12:52;qz412;I have attached the ""Strategic outlook part"" in [^ASR003 - Technical Proposal_v05_OS.docx] . All, please have a look, I tried my best to describe async persister and binary API changes.

[~rg535] - I need calrification for the chapter 7.2 Market-Based Service Model, I am at loss what exactly we wish to communicate there.","16/Nov/18 13:43;tz118;Dear [~rg535],

please find attached updated Technical Proposal for the Improvements (ASR003) ready for the Review [^ASR003 - Technical Proposal_v06.docx]

As mentioned yesterday, Alpha Team ([~eh941] [~uv683]) took this task yesterday during the planning and this Output was achieved together with previous preparation and dedicated Developers from other teams and PO. Special thank you    [~nn481] [~eg288] [~lt112] and [~qz412] for the prompt Support. 

Best,
Stefan


","16/Nov/18 13:57;gd553;Hi [~tz118],

Thank you for your efforts. Please provide the document to Jens R. for review.

Regards

Malina","16/Nov/18 14:54;tz118;document sent to Jens R. for technical review","19/Nov/18 11:28;rg535;please do not edit the document. I have checked it out to do revisions. I will upload it later today. Thanks.","19/Nov/18 14:31;rg535;I have uploaded version 07 with the language improvements. Please finalise the document and ask Simona to send out to the final version.","19/Nov/18 15:57;tz118;attached two updated Versions (0.9 in track changes mode and final clean Version 1.0). [~rg535], please double check changes disucssed earlier. Thank you.","19/Nov/18 18:22;qm925;Version 1.0 has been provided to the PXs for a review (19/11).",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test of new transfer of performance logs,XP-583,75335,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,dw255,dw255,14/Nov/18 15:28,06/Nov/20 11:34,22/Feb/21 13:26,15/Nov/18 14:29,,,Pre2020,,,,,,,,,,,"Transfer of performance logs into Elasticsearch was changed in XP-457 and it was not tested yet. So far the transfer was done by Filebeat agent and that was configured by TECHOPS. This is the first time the performance logs are sent directly to Elasticsearch by XBID core.

What should be tested:
- Are the performance logs correctly transferred to Elasticsearch?
- Is there any impact on SLA reporting tool? Such as XP-552

 

 ",,dw255,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Product cannot be created in SOB,XP-582,75326,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,zi174,dw255,dw255,14/Nov/18 15:08,06/Nov/20 12:40,22/Feb/21 13:26,27/Nov/18 12:10,,,Pre2020,,Trading,,,,,,,,,"Description:
============
It is not possible to create new Product in SOB. There is no ""Create"" button at the last screen (Assign Market Segment) of new Product details. ""Next"" button is present but it doesn't do anything.

Steps to reproduce:
===================
1. Login to SOB as reference data admin (e.g. XBOMIEA1)
2. Navigate to Reference Data Management - Product Setup - Product Management
3. Create new product
4. Fill in all fields in all tabs: Details, Attributes, Contract Names, Contract Generation, Assign Market Segment
5. Create the Product by ""Create"" button

Expected behaviour:
===================
New Product is created. Described in DFS700 - chapter 4.1.1 and 4.1.7

Current behaviour:
==================
""Create"" button is missing. Product cannot be created.

Configuration:
==============
SYT2 with XBID 1.6.0.2
Tested in the one and only supported browser - Internet Explorer.",,dw255,eg288,radeale,zi174,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/18 15:05;dw255;Screenshot from 2018-11-14 14-17-06.png;https://jira.deutsche-boerse.com/secure/attachment/62181/Screenshot+from+2018-11-14+14-17-06.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70675200,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,14/Nov/18 15:08,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b00h",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,Systemtest,,,Systemtest,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Nov/18 17:59;radeale;Confirmed for XBID R1.6.0.6, instead of the _Create_ button there is a _Next_ button which does nothing all.","26/Nov/18 10:44;eg288;*Root-cause:*
- tab COMBINATION was removed from create/modify product form as part of XDEV-5213 remove spread contracts. The COMBINATION tab removal broke the create/previous/next buttons logic.

*Test:*
- create/modify product
- different ways of navigation between tabs in product form","27/Nov/18 12:09;zi174;Tested on Systemtest II env, version R1.6.0.7-59a5ba9f2d091e3463cb1f86bf4a9a45c548931e ---> result  (/)

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
core - enforced user disconnect generates AMQP errors,XP-574,75307,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,eg288,eg288,14/Nov/18 12:12,06/Nov/20 12:40,22/Feb/21 13:26,27/Nov/18 11:55,,,Pre2020,,Trading,,,,,,,,,"When user disconnect is triggered due to reference data changes the operation succeeds but there are several 404 Not Found errors in the core log.

This is caused by an attempt to delete a broadcast queue of the given user twice. It is done concurrently utilizing async tasks. Only first attempt is successful. Also AMQP connections removal fails as the first attempt to delete the queue also removes all related connections.

The problematic code is in TraderLogoutHelper.addBroadcasts(). 

The questions is why disconnect is conditional while the broadcast queue removal is always executed effectively causing the user disconnect anyway.

Discovered when fixing XP-463

Exception:
{code}
2018-02-15T11:24:24.885Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] INFO  c.d.w.c.JsonTemplate - '172.16.238.1:55826%20-%3E%20172.16.238.10:5672' deleted from '/api/connections/' with reason 'Trader session has been terminated by Core'.
2018-02-15T11:24:24.890Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 172.16.238.1:55856 -> 172.16.238.10:5672
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:525)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:521)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:689)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:521)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:102)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:85)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:97)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:79)
        at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:777)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:735)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:709)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:597)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-02-15T11:24:24.903Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete queue comxerv.broadcastQueue.SADMIN02
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:169)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:401)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:397)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:689)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteQueue(RabbitmqApiClientImpl.java:397)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:114)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:85)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:97)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:79)
        at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:777)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:735)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:709)
        at org.springframework.web.client.RestTemplate.delete(RestTemplate.java:541)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:166)
        ... 12 common frames omitted
2018-02-15T11:24:24.904Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] INFO  c.d.e.m.a.AsyncJobExecutorImpl - Finished execution of async task 'TmRabbitmqAsyncAdminImpl::disconnect(SADMIN02, Trader session has been terminated by Core)'. Time spent: 130ms
{code}",,eg288,eh941,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-463,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70675200,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,14/Nov/18 12:12,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:00y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Nov/18 15:55;eh941;How to test:
Scenario 1
* Login with a trader with Application ID ""X"" (DB-TestClient e.g.) with test client
* Login as admin to trading inquiry
* Suspend the application ID
* In the core module logs there should be no exception nor error (see the description)

Scenario 2
* Login with admin via test client or ComTrader
* Login with the same admin to trading inquiry - kick the previous user
* See the core module logs - there should be no error
* Repeat the same procedure but with login to WEB gui first and via AMQP later
","26/Nov/18 08:18;hj444;Test started
Env:  Docker.
Scenario 1

    Login with a trader with Application ID ""X"" (DB-TestClient e.g.) with test client
    Login as admin to trading inquiry
    Suspend the application ID -> ApplicationID overview tab.
    In the core module logs there should be no exception nor error (see the description)

Scenario 2

    Login with admin via ComTrader
    Login with the same admin to trading inquiry - kick the previous user
    See the core module logs - there should be no error
    
Scenario 3
     (Repeat the same procedure(Scenario 2 ) but with login to WEB gui first and via AMQP later)
    
    Login with the same admin to trading inquiry - kick the previous user
    Login with admin via  ComTrader - kick the previous user
    See the core module logs - there should be no error
","27/Nov/18 11:54;hj444;Scenario 4

Login with the ref data admin to trading inquiry 
Login with admin via ComTrader 
Suspend Admin logged into Comtrader.
See the core module logs - there should be no error
Activate - Admin


Scenario 5

Login with the ref data admin to trading inquiry 
Login with Exchange User via test client
Suspend Exchange User logged into  test client.
See the core module logs - there should be no error
Activate -  Exchange User


core logs verified
grep 'TmRabbitmqAdminImpl' m7-app-xbidCore1.log
grep '404 Not Found' m7-app-xbidCore1.log
grep 'ERROR' m7-app-xbidCore1.log

No errors mentioned in Descrition.
Jira will be closed.





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TECHLOG - 1087, SIMU failover",XP-557,75239,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,qz412,qz412,13/Nov/18 10:14,06/Nov/20 12:37,22/Feb/21 13:26,30/Jan/19 10:04,,,Pre2020,,Capacity,Trading,,,,waiting-po,,,,"We need to:
 * deploy 1.6.x to SYT1
 * shoot down DC (coordinate with techops)
 * test that the application does not experience minute long freezes",,qz412,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67305600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy6:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 4,Home Office Team Sprint 5 (PS),Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/18 12:45;tm431;After discussion with Niklas outcome is that this can be tested only in SIMU and cannot be tested on any SYT env.

 

 

Patrik Cupak [10:36]
 Hi Niklas, we need to test [http://172.19.250.235:8090/confluence/display/ET/PM2018%3A+Lessons+learned] in SYT1, what shoudl we create for this. Task? or Service ticket. in nutshall you can do it anytime on syt1, we do not test there
 We (DEVs) have no idea what ESX cluster is.
 ```It was planned to stop all Energy applications in HAU between 10:00 and 14:00.
 At 11:00 ESX CloudAdmins started to initiate the shutdown of the ESX Cluster
 (Hypervisor) with shutdowns for each still running VMs. This was according to plan - we simply misinterpreted it.```
 (edited)

Niklas Albers [10:37]
 this can't be done

Patrik Cupak [10:38]
 aha... and just disconnect (unplug the cable) of one DC wouldn't help?

Niklas Albers [10:38]
 also not possible
 the VM's are running on shared infrastructure
 on systemtest
 it means there are several other (not energy) VMs running on the ESX Host

Patrik Cupak [10:39]
 aha, so this would kill all sys envs... I see

Niklas Albers [10:39]
 we can't mess around with those hosts
 it can just be done on Simu (or Prod) as we have dedicated hosts only in those two environments (edited)

Patrik Cupak [10:41]
 ok, thankx... maybe we will find some time in SIMU for this, as there are currently penetration test, but there is not 1.6.3version. anyway thankx for clarificatoin

Niklas Albers [10:42]
 sure","19/Nov/18 15:10;tm431;Unfortunatelly this is not configured in SIMU yet, see TECHLOG-1087","21/Nov/18 08:47;tm431;Waiting on techops .Ok, thanx for info. It would be great if we can test this on SIMU. So if you have some spare time get in touch with [~hu772] as she makes all the communication about SIMU env. with customers, if we can have this env. for introducing the change and actual test (kill ESX servers) (I believe that there are penetration tests ongoing there so we can grab couple of hours of this env.)","04/Jan/19 13:56;qz412;Deployment of R1.6 for testing of this ticket is planned in the SIMU availability window for R1.5.9 deploy on *28th Jan 2019*.

[~yo218] + [~tm431]: please track + cooredinate accordingly, thx. I will be posting updatets in this ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix Report Tool after log line has been changed,XP-552,75222,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,qo794,uv683,uv683,12/Nov/18 16:36,06/Nov/20 10:25,22/Feb/21 13:26,14/Nov/18 14:05,,,Pre2020,,SLA Report Tool,,,,,,,,,"Logging of Front disruptor's Scheduler handler's start and end times has been added into perf-raw-orderbook and perf-raw-sender loggers. See commit [https://github.deutsche-boerse.de/dev/xbid/commit/72340b23ba31576623208344cd757624f500e0d1] if interested.

This caused Report Tools log line parsing to be broken. In perf-raw-* loglines there two more milis values that designates start and end time of scheduler handler.

This is how the beggining of perf-raw-* logline looks like at the moment. In bold are two new added values which need to be accounted for in Report Tool:

receiveJournallerTime,username,eventName,totalMilis,receiveTime,rabbitReceiveTime,*scheduler_start,scheduler_end*,journaller_start,journaller_end.... 

 ",,nn481,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71798400,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,12/Nov/18 16:36,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:9008",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 3 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,parser-hack,xbid-2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"14/Nov/18 13:03;nn481;Review pls. https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/125",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
End to End test - TradeCaptureReq.feature failing in night pipeline  ,XP-547,75194,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,hj444,hj444,12/Nov/18 12:19,06/Nov/20 10:59,22/Feb/21 13:26,20/Nov/18 13:13,,,Pre2020,,,,,,,,,,,"end-to-end test: tradeCaptureReq.feature is failing in night pipeline.

1. Find the rout cause.
2. Improve test.
3. Test is successfully running - in all workflows - daily jobs, night pipeline.



",,eg288,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71280000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b01i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-1241-new-failover-docker,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Nov/18 13:13;eg288;Problematic cucumber tests were unignored. All builds including nightly ones are passing -> closing the issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze CMM AMQP tests - can we use current ones or do we need to introduce different tests?,XP-526,75118,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ll664,ll664,09/Nov/18 13:26,06/Nov/20 12:52,22/Feb/21 13:26,29/Nov/18 08:59,,,Pre2020,,Capacity,,,,,,,,,"We ignored couple of tests in CMM when the builds were moved to new AWS infra, since there's no RabbitMQ broker which is required for those tests.

Think about how to make them work without the broker:

{code}
AmqpCmiInTest
AmqpCmiOutTest
M7CoreConnectorAmqpTest
PublishServiceImplCtxTest
{code}",,jy268,ll664,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-682,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70502400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b007",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 4,Ampere Sprint 5,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/18 15:35;jy268;*TESTS WHICH WILL BE DELETED*

AmqpCmiInTest could be deleted because test's functionality is duplicated in explicitAllocation.feature in e2e tests.
M7CoreConnectorAmqpTest could be deleted because test's functionality is duplicated in internalCmmRequest.feature
","28/Nov/18 16:26;jy268;*TESTS WHICH COULD BE MOVED TO SELENIUM*

AmqpCmiOutTest verifies if files download / upload is successful. In my opinion this can be moved to Selenium tests.

PublishServiceImplCtxTest verifies if files to publish list is not empty and contains expected files, it could be done via UI Selenium tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create diff between 1.5.8 (Production) and 25.10.2018 (Start of the first sprint),XP-525,75114,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,xu897,xu897,09/Nov/18 12:35,06/Nov/20 12:35,22/Feb/21 13:26,21/Nov/18 16:28,,,Pre2020,,,,,,,,,,,"To be clear what is in the XBID 2.0 we need to know what was delivered before the first sprint (Issues in XDEV projects).

Outcome
- List of XDEV Jira issues which were finalized before the first sprint are not in production and will be released in XBID 2.0.
- Include also tickets from https://jira.deutsche-boerse.com/browse/XP-474  https://jira.deutsche-boerse.com/browse/XP-475 https://jira.deutsche-boerse.com/browse/XP-476",,ll664,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-392,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71107200,,,,,,,,,,,,,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:wh",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Nov/18 16:16;ll664;The list of jiras fixed since the beginning of SCRUM, that are not part of XBID 1.5.8 and SM 1.0.38:

XBID:

XP-131
XP-290
XDEV-3249
XDEV-3991
XDEV-4058
XDEV-4170
XDEV-4200
XDEV-4759
XDEV-4769
XDEV-4952
XDEV-4984
XDEV-5087
XDEV-5186
XDEV-5207
XDEV-5213
XDEV-5215
XDEV-5217
XDEV-5264
XDEV-5316
XDEV-5321
XDEV-5345
XDEV-5346
XDEV-5470
XDEV-5483
XDEV-5484
XDEV-5491
XDEV-5546
XDEV-644
XDEV-5336
XDEV-5145
XDEV-4451
XDEV-5320
XDEV-4697
XDEV-4558
XDEV-4761
XDEV-5342
XDEV-5312

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test legacy item XDEV-5316,XP-505,75053,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,tm431,tm431,08/Nov/18 14:17,06/Nov/20 12:35,22/Feb/21 13:26,04/Dec/18 11:47,,,Pre2020,,,,,,,waiting-techops,,,,https://jira.deutsche-boerse.com/browse/XDEV-5316,,od044,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70070400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07rjw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 5 (PS),Home Office Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/18 11:16;od044;Test passed .1.6.0.9

Starting time is still more than 10s after deployment. But starting time during restart is less the 10s 

Tested on SYT2 with prod dump DB with 1 507 198 orders, 159 294 trades.

1.5.8 after deployment
{code}
variables=XBID_VERSION=1.5.8,SPM_VERSION=1.0.36,REP_VERSION=5.0.41,PMI_VERSION=1.0.28,PMI_ARCHIVER_VERSION=1.0.18,DATA_SET_COR=tosca-fake,DATA_SET_SPM=tosca-fake,DATA_SET_CMI=tosca-fake,DATA_SET_VERSION=1.3.38

2018-12-03T13:32:45.238Z [CoreService][SYSTEM_TASK][1b1aeec9] INFO  c.d.e.m.f.StartupTask - Started in 22900ms
{code}

1.6.0.9 after deployment
{code}
XBID_VERSION=1.6.0.9,SPM_VERSION=1.5.0.4,REP_VERSION=5.0.41,PMI_VERSION=1.0.28,PMI_ARCHIVER_VERSION=1.0.18,DATA_SET_COR=tosca-fake,DATA_SET_SPM=tosca-fake,DATA_SET_CMI=tosca-fake,DATA_SET_VERSION=1.3.43

2018-12-03T14:10:33.882Z [CoreService][SYSTEM_TASK][1c03b7ba] INFO  c.d.e.m.f.StartupTask - Started in 16870ms
{code}

After restart 
{code}
2018-12-03T14:30:00.948Z [CoreService][SYSTEM_TASK][6af414e5] INFO  c.d.e.m.f.StartupTask - Started in 8116ms
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM Report doesn't finish - Solution analysis,XP-487,74965,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,cf948,cf948,08/Nov/18 09:20,06/Nov/20 12:40,22/Feb/21 13:26,14/Nov/18 15:23,,,Pre2020,,Capacity,,,,,,,,,Analyze two bugs in sub-tasks and propose solution / fix.,,cf948,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SMXBID-995,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72316800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,08/Nov/18 09:20,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:900i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 3] Deliver Sprint Increment,XP-484,74962,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,xu897,xu897,08/Nov/18 09:07,06/Nov/20 10:14,22/Feb/21 13:26,14/Nov/18 16:37,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]

Coordinate with XP-431 and XP-432 (linked below)

 

 ",,xu897,,,,,,,,,,,,,,,,,,,,,,,XP-434,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72316800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:9004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 3 (PS),,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze initial ideas for the MVP and consider feasibility,XP-482,74955,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,de698,qz412,qz412,07/Nov/18 17:39,04/Aug/20 19:40,22/Feb/21 13:26,22/Nov/18 11:03,,,Pre2020,,,,,,,,,,,"XBID has been chosen as the fitting candidate to spearhead the common cross product DWH.
 * A MVP will be outlined, specified, built and tested based on XBID's needs.
 * DWH will gather raw Prod data which will be available for querying and subsequent use in reports, monitoring, ...

The idea is to start small (from basic requirements) and gradually add functionality - suggested, not binding:
 # Reporting Engine
 # SLA/KPI reports
 # EBSM

PMI logger and individual application reports (although a major pain point) not to be considered for MVP.

Please study attached initial ideas + tech stack by TechOps + [~df894]

DoD:
 * Idea + tech stack are commented, if we prefer any other solution / tech, we capture and communicate this fact
 * Next steps are clearly formulated + tasks are agreed with PO, added to backlog
 * Confluence space is reserved (existing / new) and any findings are captured so handover to other teams is smooth",,de698,df894,ek176,qo794,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-188,,,,,,,"07/Nov/18 17:45;qz412;Data Lake MVP Draft.pptx;https://jira.deutsche-boerse.com/secure/attachment/61694/Data+Lake+MVP+Draft.pptx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71107200,,,,,,,,,,,,,,,XP-481,,,,,,,,,,,,,,07/Nov/18 17:39,,,,,,,,,,,,,,,,,,,,,,,"1|000yt1:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Nov/18 15:58;df894;Entity Model Review conducted by Aleksander Buczek can be found here: [http://172.19.250.235:8090/confluence/display/EDW/Entity+Model+Review]","21/Nov/18 17:28;de698;DoD:
 * Idea + tech stack are commented, if we prefer any other solution / tech, we capture and communicate this fact {color:#00875a}- see XP-636, question raised per email{color}
 * Next steps are clearly formulated + tasks are agreed with PO, added to backlog {color:#00875a}- XP-636, XP-639, more to come{color}
 * Confluence space is reserved (existing / new) and any findings are captured so handover to other teams is smooth{color:#00875a} - studied the information available on confluence, currently no new content added{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Formulate a position on whether / how to uplift system boundaries,XP-477,74902,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,07/Nov/18 11:14,04/Aug/20 19:15,22/Feb/21 13:26,22/Nov/18 09:35,,,Pre2020,,Trading,,,,,,,,,"Based on the performance test results and production data consider whether / how the system boundaries can be uplifted. 

To be communicated to the customers by Nov 16th.

Discuss with [~rg535].",,qz412,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-423,,,,,,,"12/Nov/18 11:33;tz118;ASR003_RTS3 Slice B_List of Service Level Boundaries  KPIs_DRAFT_v1.4.xlsx;https://jira.deutsche-boerse.com/secure/attachment/61937/ASR003_RTS3+Slice+B_List+of+Service+Level+Boundaries++KPIs_DRAFT_v1.4.xlsx","09/Nov/18 14:38;tz118;XBID Service Boundary Reporting October 2018_uplift.xlsx;https://jira.deutsche-boerse.com/secure/attachment/61872/XBID+Service+Boundary+Reporting+October+2018_uplift.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 3,Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Nov/18 14:41;tz118;attaching Production boundary report (October 2018) together with 12 months load prognosis (July, August, September, October)  as a baseline for expected boundary uplifts","12/Nov/18 11:34;tz118; proposal to uplift boundaries attached (v1.4), to be discussed during intranl Alignement meeting","15/Nov/18 12:27;tz118;Dear [~rg535], 

the latest proposed Boundaries uplift has been communicated via email. Confirmation tests are ongoing, however no Major changes are expected. Information to be updated as soon as we have results.

Thanks and regards,
Stefan
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test legacy tickets from XDEV project - Alpha ,XP-476,74893,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,cs131,cs131,07/Nov/18 09:51,06/Nov/20 10:14,22/Feb/21 13:26,14/Nov/18 15:19,,,Pre2020,,,,,,,,,,,"we need to finalize the following tickets as there leftover from XDEV project
 - XDEV-4761
 - XDEV-5345
 - XDEV-4769
 - XDEV-4906
 - XDEV-5346
 - XDEV-5342
 - XDEV-3991",,cs131,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XDEV jiras tested.,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test legacy tickets from XDEV project - Ampere,XP-475,74891,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,cs131,cs131,07/Nov/18 09:48,06/Nov/20 10:14,22/Feb/21 13:26,14/Nov/18 15:23,,,Pre2020,,,,,,,,,,,"we need to finalize the following tickets as there leftover from XDEV project
 - XDEV-5312
 - XDEV-4697
 - XDEV-4558
 - XDEV-4058
– XDEV-3190 is closed, please confirm if testing is needed.",,cs131,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-474,XP-476,XP-326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:96",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test legacy tickets from XDEV project - HOT,XP-474,74890,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,cs131,cs131,07/Nov/18 09:44,06/Nov/20 10:14,22/Feb/21 13:26,28/Nov/18 10:13,,,Pre2020,,,,,,,,,,,"we need to finalize the following tickets as there leftover from XDEV project
 - XDEV-5316
 - XDEV-5546
 - XDEV-5336
 - XDEV-5145
 - XDEV-4451
 - XDEV-5320
",,cs131,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-476,XP-326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xf",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 3 (PS),Home Office Team Sprint 4,Home Office Team Sprint 5 (PS),,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
It should be possible to turn off Elastic metrics handler,XP-471,74858,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ll664,ll664,06/Nov/18 15:48,31/Aug/20 15:38,22/Feb/21 13:26,20/Jan/20 16:28,,,3.1.0,,Other,,,,,ice,,,,"In cases when Elastic cluster is not available, {{xbid-core}} should not attempt to send data there.

Introduce configuration property that turns on/off Elastic metrics. For local dev/docker profiles, it should be disabled.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,34387200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07czx:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/20 16:28;ll664;Already implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Docker vs Data Set - change default dataset, make the selection of dataset configurable",XP-470,74846,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,qz412,hj444,hj444,06/Nov/18 14:50,06/Nov/20 11:34,22/Feb/21 13:26,21/Nov/18 14:47,,,Pre2020,,,,,,,,,,,"1. Change default dataset to Tosca-fake.
           (Actually - Shipping module missing structures - SA, CCP, Files, ..... - testing this areas needs setting over all Shipping)
2. Make selection of dataset configurable- it will be possible to load different datasets.",,cs131,hj444,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xhi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 3 (PS),Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Nov/18 14:55;tm431;also add possibility to choose *version* of dataset","14/Nov/18 14:53;cs131;documentation https://github.deutsche-boerse.de/dev/xbid.utils-py",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Execute tests on perf with OBK improvements/DB change,XP-467,74835,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,tz118,tz118,06/Nov/18 13:08,04/Aug/20 19:15,22/Feb/21 13:26,21/Nov/18 10:09,,,Pre2020,,,,,,,,,,,"Execute tests on perf with OBK improvements on perf

DoD
 - execute latest Versions of RTS3SB SC14 and SC15 on perf, have reports available
 - execute same verisons of scenarios on perf with implemented improvements (see link bleow), have reports available
 [http://172.19.250.235:8090/confluence/display/TD/Order+book+perfomance+improvements]
 - execute same Scenarios on perf with new DB (TechOps dependency, contact Person Niklas A.) - this can be done on perf without SW improvements and then with SW and DB changes to isolate Impacts
http://172.19.250.235:8090/confluence/display/ET/PoC+-+Hardware+configuration+and+ordering

----
{color:#de350b}Obk changes need to be merged first{color}",,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72489600,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 3 (PS),Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Testing with Docker -  preparation ,XP-466,74823,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,hj444,hj444,hj444,06/Nov/18 11:12,06/Nov/20 11:34,22/Feb/21 13:26,07/Nov/18 09:19,,,Pre2020,,,,,,,,,,,"Create page with general information about  : Test with Docker

1. Prepare Docker, Python, ...
2. Install DB tool to local (pgAdmin)
3. Set up Db connections
4. Set up  Test client connections
5. Set up Comtrader Login
6. Logs
7. Links to envs

 ",,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07l6g:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 09:18;hj444;Page is created.   
http://172.19.250.235:8090/confluence/display/XBID/Testing+with+Docker",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RabbitMQ 3.7.7 - AMQP disconnect not working from application - FIX,XP-463,74815,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eg288,radeale,radeale,06/Nov/18 10:29,06/Nov/20 10:46,22/Feb/21 13:26,14/Nov/18 14:59,,,Pre2020,,Trading,,,,,,,,,"
XBID application enforces user disconnection in case of events like user suspensions, password change, balancing group modification, product modification, etc. According to M7P-2960 it is not working with new production rabbitmq 3.7.7. Please verify and fix.

For more details see XP-374.

*Proposed solution:*
Use library for URI path encoding (RFC 3986) like spring org.springframework.web.util.UriUtils.encode(connectionName, Charsets.UTF_8.name()) instead of java.net.URLEncoder which is intended for form data encoding (application/x-www-form-urlencoded).

UriUtils replaces space in URI by %20.

Discussion with detailed explanation on [stackoverflow|https://stackoverflow.com/questions/4737841/urlencoder-not-able-to-translate-space-character]
",,eg288,radeale,,,,,,,,,,,,,,,,,,,,,,XP-374,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71798400,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,26/Oct/18 11:17,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:94",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Nov/18 15:29;eg288;implemented with commit bc33ace in xbid repo -> please test [~radeale]","13/Nov/18 17:26;radeale;Test results - LOCAL, XBID R1.6.0.3-SNAPSHOT-bc33ace71d8742aa9276ba5faf8560dc03cf4127

An Admin user connected to ComTrader, suspended. An error is thrown in the log, but the user is disconnected shortly after - {color:#00875A}OK{color}.

{code}2018-02-15T11:24:24.885Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] INFO  c.d.w.c.JsonTemplate - '172.16.238.1:55826%20-%3E%20172.16.238.10:5672' deleted from '/api/connections/' with reason 'Trader session has been terminated by Core'.
2018-02-15T11:24:24.890Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 172.16.238.1:55856 -> 172.16.238.10:5672
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:525)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:521)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:689)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:521)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:102)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:85)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:97)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:79)
        at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:777)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:735)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:709)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:597)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-02-15T11:24:24.903Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete queue comxerv.broadcastQueue.SADMIN02
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:169)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:401)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:397)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:689)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteQueue(RabbitmqApiClientImpl.java:397)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:114)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.springframework.web.client.HttpClientErrorException$NotFound: 404 Not Found
        at org.springframework.web.client.HttpClientErrorException.create(HttpClientErrorException.java:85)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:97)
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:79)
        at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:777)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:735)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:709)
        at org.springframework.web.client.RestTemplate.delete(RestTemplate.java:541)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:166)
        ... 12 common frames omitted
2018-02-15T11:24:24.904Z [cTaskExecutor-1][ASYNC_JOB][6c236f75] INFO  c.d.e.m.a.AsyncJobExecutorImpl - Finished execution of async task 'TmRabbitmqAsyncAdminImpl::disconnect(SADMIN02, Trader session has been terminated by Core)'. Time spent: 130ms{code}","14/Nov/18 12:17;eg288;The error above is no longer caused by invalid usage of rabbitmq 3.7 rest API. It is caused by XP-574.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pentest support - coordinate user creation in SIMU with ESO,XP-458,74792,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,radeale,qz412,qz412,05/Nov/18 15:45,06/Nov/20 10:14,22/Feb/21 13:26,28/Nov/18 11:53,,,Pre2020,,,,,,,,,,,"Please support ESO (Regina Gerson) and BizOps ([~hu772]) with user creation for the PenTest (ESO-19) that takes place in SIMU from *12th - 26th Nov*.

By *Nov 9th* we have to create for the penetration test on SIMU *2 users* (name, password, certificate) for each user role for following areas:
 * CMM / CMI
 * SM
 * SOB (MPLS, will be tested by Deloitte guys on-site)
 * Comtrader (only admin user)
 * Webserver (*Niklas*)
 * SFTP Server (*Niklas*)

 ",,qz412,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70588800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 2,Ampere Sprint 5,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Nov/18 13:21;radeale;*SIMU1 users for the Penetration Tests (**12th - 26th Nov**)*

Edited 7.11. after the DB restore.

*+SOB+*
(These users are registered using the Alexandr Radecky's mail.)

The user-name: *XBPENT01*
The password: *KO4k&dpN2db1*
User Role: *Admin*
Additional Rights:
_Public API - User can access the Public Message Interface_
_Capacity Info - User can view available capacity information_
_Reference Data GUI - User can access the Reference Data GUI_
_Superadmin - User can view/create/modify other Admin Users_
_Trade Recall & Trade Cancellation_
(Can connect to the ComTrader as well as to the WebGUI.)

The user-name: *XBPENT02*
The password: *.w03KtnRlN,G*
User Role: *Exchange User*
Additional Rights:
_Public API - User can access the Public Message Interface_
_Capacity Info - User can view available capacity information_

*+CMM+*
(These users are registered using the Alexandr Radecky's mail.)
{color:#505F79}Admin user used: XBCMMAD1{color}

The user-name: *XBPENT03*
The password: *:ksCdqsci0XZ*
User Roles:
_TSO Admin_
_File Management Admin_
_Super Admin_
_Reference Data Admin_

The user-name: *XBPENT04*
The password: *uvz,TC:0Z,=S*
User Roles:
_Explicit Participant_
_Explicit Participant PMI User_
_Allocation Reporting PMI User_

*+Shipping Module+*
(These users are registered using the Jakub Musil's mail.)

The user-name: *XBPENT05*
The password: *xbidTest01!*
Roles:
_SA_OPERATIONS_ 
_CCP_OPERATIONS_ 
_SA_ADMIN_ 
_CCP_ADMIN_ 
_TSO_OPERATIONS_ 
_TSO_ADMIN_ 

The user-name: *XBPENT06*
The password: *xbidTest01!*
Roles:
_SUPER_ADMIN_","07/Nov/18 16:23;radeale;The users are re-created after the DB restore - SERVICE-2021.","26/Nov/18 16:58;radeale;...and now deactivate them.","28/Nov/18 11:52;radeale;Simona asked the customer which dataset should be deployed when we revert the environment to the state before. The deactivation of the client certificates need to be added to the deployment request then.

I'll monitor the task in the background...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Send performance logs directly into Elasticsearch,XP-457,74791,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,ll664,uv683,uv683,05/Nov/18 15:19,06/Nov/20 11:34,22/Feb/21 13:26,07/Nov/18 10:47,,,Pre2020,,,,,,,,,,,"*Background*

For every event in XBID, start and end timestamps of their processing per handler are printed into core log file. These events are logged by *perf-raw-orderbook* and *perf-raw-sender* loggers. Our logs are monitored by agent called *Filebeat* which is sending them into *Elasticsearch* database. This has several drawbacks
 # log files are much bigger then they could be because with every event there is one or two extra lines of logging
 # Filebeat is parsing log lines and sending JSON into Elasticsearch. It stores data as Elasticsearch document. When  Report Tool - which is used for creating SLA and KPI reports, downloads data from Elasticsearch it again construct the logline. Too many transformations.
 # Filebeat has some buffer and when the core logile is growing rapidly is can overflow and cause some lines being thrown away.

*What needs to be done*

We want to stop logging perf lines by perf-raw-sender and perf-raw-orderbook loggers. Data contained in these loglines can be converted into JSON and pushed asynchronously into Elasticsearch by core itself. This would overcome all the above mentioned issued. 

Moreover we would like to add start and end processing time of front disruptor and flags of batch end for all handlers.

 ",,ll664,qz412,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-583,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:y",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/18 15:28;uv683;reviewed and ready to be merged  [https://github.deutsche-boerse.de/dev/xbid/pull/214]

 ","06/Nov/18 10:06;qz412;Added to Alpha Sprint 2 - as per request of [~uv683]. Large portion of those 5 SPs has been spent before the Sprint, pending agreement with [~xu897] whether to include total or respective part in this Sprint. Will be adjusted accordingly.

Update - changed to 1 SP as only the merge is missing.","07/Nov/18 11:05;ll664;Change reviewed and merged into {{develop}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
xbid-test POM cleanup,XP-456,74789,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,05/Nov/18 15:10,31/Aug/20 15:38,22/Feb/21 13:26,19/Mar/20 10:22,,,3.1.0,,Other,,,,,ice,,,,"In the {{xbid-test}} POMs, there are multiple dependencies/properties that are not used.

Those are mostly leftovers from the time the project was part of {{xbid}} repository.

Review and cleanup.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72489600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07czz:zc",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-2979-postgresql,XP-456,XP-3264,XP-4526-resource-managment-fix,develop,XP-3230,XP-2232,fixing-failover,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze the RTS3 SB run results - dev support 2,XP-437,74492,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,qz412,qz412,01/Nov/18 16:00,04/Aug/20 19:15,22/Feb/21 13:26,07/Nov/18 14:55,,,Pre2020,,Trading,,,,,,,,,"{color:#de350b}-----{color}

{color:#de350b}Provide dev support to the primary solving team XP-423{color}

{color:#de350b}-----{color}

RTS3 Slice B runs will be concluded with the end of 1st Sprint.

Next steps (= DoD of this tasks):
 * Analyze the RTS3 SB run results
 * Prepare communication to customers, align with ACM. The commented results need to be handed over to the customers by 6th Nov

[~rg535], please cooperate with the team who is working on this item.

[~tz118], please consider taking this task up with Alpha - you have strong skills in this are + historic context of the task.",,eg288,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72316800,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu1:x",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 14:54;eg288;Done.

Analyses outcome has been delivered/discussed on several meetings with [~tz118] and ACM.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix all failing Jenkins jobs,XP-436,74478,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,qz412,qz412,01/Nov/18 14:14,06/Nov/20 10:59,22/Feb/21 13:26,08/Nov/18 09:23,,,Pre2020,,,,,,,,,,,"* Fix all failing Jenkins jobs
 * consider dedicated Slack alert",,ei349,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72748800,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yuo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1261-guava-28,selenide-poc,XP-3777,XP-1833,XP-3988-all_pipelines_should_use_new_eex_artifactory,xbid-losses-poc,XP-3230,XP-4505_new_m7_pipeline_lib_paralle_build_disabled_by_default,XP-3094-sonar-gate,XP-4505_xbid_hpfortify_enabled_parralel_build,XP-4505_spm_hpfortify_upgrade,XP-3070,XP-4505_pipeline_option_timestamps,xbid-2.0.25.x,XP-4505_xbid_hpfortify_dev_translate_speedup_in_pipeline_lib,XP-4505_pmi-archiving_upgrade_hpfortify,XP-4505_ct_sloth_hpfortify_upgrade,fixing-failover,XP-4505_pmi_tools_upgrade_hpfortify,plewmic-scripts,XP-4505_xbid_hpfortify_upgrade,automatic-tests,XP-1504,TOFIX-migration-to-declarative-not-working,XP-2942-losses-perf,XP-2979-postgresql,XP-456,XP-3264,XP-3361,develop,XP-4505_xbid_develop_hpfortify_upgrade,XP-2232,XP-1241-new-failover-docker,XP-2694,XP-1069,XP-4273-owasp-zap-enable,XP-3243-report-tool-hp-fortify,cpm-compatibility-pack,XP-4250,XP-4505_pmi_tools_fixed_SCA_MAVEN_PLUGIN_VERSION_definition,inline-tomcat-params,versions,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,XP-4505_reporting_tools_upgrade_hpfortify,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"02/Nov/18 15:24;ei349;Failing important tests: 
 * https://scmci1.deutsche-boerse.de/job/Energy/view/Pipelines/job/xbid-develop-nightly-pipeline/
 * [https://scmci1.deutsche-boerse.de/job/Energy/view/Pipelines/job/xbid-end-to-end-pipeline/]
 * [https://scmci1.deutsche-boerse.de/job/Energy/view/Pipelines/job/xbid-1-5-nightly-pipeline]
 ** Won't fix in this sprint",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 2] Deliver Sprint Increment,XP-434,74468,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Incomplete,ei349,xu897,qz412,01/Nov/18 12:35,06/Nov/20 10:14,22/Feb/21 13:26,08/Nov/18 09:25,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]

Coordinate with XP-431 and XP-432 (linked below)

 

 ",,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Done for XBID. ,,,,,,,,,,,,,,72921600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yuk:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Finalize deployment verifier - summarize the problems + prepare TechLog tickets,XP-433,74467,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,nn481,qz412,qz412,01/Nov/18 11:45,06/Nov/20 11:34,22/Feb/21 13:26,22/Nov/18 09:09,,,Pre2020,,,,,,,,,,,"Deploy verifier repository: https://github.deutsche-boerse.de/dev/xbid-deploy-verifier

Current status (16/Nov/2018): Application developed tested on local dev machines, not tested on dev jenkins due to blocker [TECHLOG-1313].

Pipelines:
Local pipeline: https://scmci1.deutsche-boerse.de/job/Energy/view/Xbid Sections/job/xbid-deploy-verifier-pipeline
* does not use Vault
* fails due to [TECHLOG-1313]
Techops production pipeline using Vault: https://scmci1.deutsche-boerse.de/job/Energy-Operations/job/xbid-deploy-verifier-pipeline/
* not tested, can be run only by Techops [TECHLOG-1611]
* Vault is missing passwords: [TECHLOG-1339]

Applications in place:
# Comtrader tester - connects to XBID core, performs Login - Logout.
# Web tester - connects to configured web environment (SOB, CMM, CMI, SPM, REP) and performs Login.
# Version tester - connects to configured health (SOB, CMM, CMI, SPM, REP; skipped CORE and SMC, endpoint is not accessible via network) endpoint reads and checks endpoint.

Note:
Applications above uses energy-mk-shared(EMS) project as source of hostnames, ports,... So when there is any change in the EMS deploy-verifier might not work.

 ",,ei349,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-603,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71625600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xg",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/18 10:18;ei349;summarize the current status and further requirements ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Shipping release job is failing,XP-432,74465,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,ll664,qo794,qo794,01/Nov/18 10:56,06/Nov/20 10:59,22/Feb/21 13:26,05/Nov/18 10:27,,,Pre2020,,,,,,,,,,,https://scmci1.deutsche-boerse.de/job/Energy/view/M7%20Shipping/job/M7%20Shipping%20-%20Release/,,ll664,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-434,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72576000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:k",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,develop,XP-3230,XP-2232,XP-2694,XP-1241-new-failover-docker,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Nov/18 10:26;ll664;It seems like a temporary problem with the Docker registry {{xbid-docker-dev-local.artifactory.dbgcloud.io}}. During release, {{docker-maven-plugin}} builds images and contacts the registry which returned invalid JSON and caused the build failure. 

I run the job again and it's working now. The version 1.5.0.1 has been released.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reach SonarQube + HP Fortify acceptance level for general code,XP-431,74460,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,qz412,qz412,01/Nov/18 10:33,06/Nov/20 10:14,22/Feb/21 13:26,22/Nov/18 08:36,,,Pre2020,,,,,,,,,,,"* Get to acceptance level with general code so following stagegates are passable at the end of Sprint 2:
 ** -SonarQube-
 ** HP Fortify - reach *level 2* (so software can be deployed to Prod)
 * Potentially reoformulate DoD where applicable

----
GIS Guidelines on HP Fortify findings:

!GIS_HPF.png!

 ",,qz412,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-434,,,,,,,"01/Nov/18 13:00;qz412;GIS_HPF.png;https://jira.deutsche-boerse.com/secure/attachment/61312/GIS_HPF.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71798400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:x9",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 3,Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/18 10:12;uv683;Many of the current Critical and High issues in HP Fortify has been already analyzed and suppressed (if not relevant) by [~lt112] at the end on July. However this work has been lost for some reason while we have switched from previous Jenkins job, that has been running HP Fortify analysis and sending results to the server, to the new job, utilizing pipeline. This happened on 3rd of September.

Current issues will have to be reevaluated and processed again I am afraid.

At the momented I am *BLOCKED* because I am waiting for rights to write into HP Fortify project.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze the RTS3 SB run results - dev support 1,XP-428,74447,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,qz412,qz412,01/Nov/18 08:12,04/Aug/20 19:15,22/Feb/21 13:26,08/Nov/18 09:26,,,Pre2020,,Trading,,,,,,,,,"{color:#de350b}-----{color}

{color:#de350b}Provide dev support to the primary solving team XP-423{color}

{color:#de350b}-----{color}

RTS3 Slice B runs will be concluded with the end of 1st Sprint.

Next steps (= DoD of this tasks):
 * Analyze the RTS3 SB run results
 * Prepare communication to customers, align with ACM. The commented results need to be handed over to the customers by 6th Nov

[~rg535], please cooperate with the team who is working on this item.

[~tz118], please consider taking this task up with Alpha - you have strong skills in this are + historic context of the task.",,qz412,,,,,,,,,,,,,,,,,,,,,,,XP-423,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72921600,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu6:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Analyze the RTS3 SB run results, prepare communication to customers, align with ACM",XP-423,74406,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tz118,qz412,qz412,31/Oct/18 08:54,04/Aug/20 19:15,22/Feb/21 13:26,07/Nov/18 17:43,,,Pre2020,,Trading,,,,,,,,,"RTS3 Slice B runs will be concluded with the end of 1st Sprint.

Next steps (= DoD of this tasks):
 * Analyze the RTS3 SB run results DONE
 * Prepare communication to customers, align with ACM. Meeting with ACM and Jens Rick planned for *Monday 5th 15:00 - 16:00* DONE
 * The commented results need to be handed over to the customers by *6th Nov* DONE
 * See comment below DONE

[~rg535], please cooperate with the team who is working on this item.

[~tz118], please consider taking this task up with Alpha - you have strong skills in this are + historic context of the task.",,qz412,rg535,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72489600,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/18 10:02;rg535;[~tz118], [~tr866], [~od044] Please provide the draft recommendations for the uplifts to the Service Boundaries by 5. November 2018 and distribute this information to [~qm925], [~gd553], [~qz412], [~fx762], [~rg535] and any other relevant team members before the Monday 15:00 meeting. An invitation will follow for the Monday meeting. Please also distribute the results and the recommendations for the improvements along with the recommendations for the uplifts.","02/Nov/18 10:19;tz118;communication and latest info (links, folders, etc) in slack channel  #rts_slice_b
results analysis from SIMU shall focus on:
1. SC02 vs SC11 (order execution time and OBK computation time)
2. SC06 vs SC07 results and drivers (only due to higher peak load?)
3. overall slow API response time (e.g. due to GlusterFS, other drivers?)
4. RabbitMQ time slow on SC05","05/Nov/18 13:22;rg535;[~tz118], slack is not usable as most of it is just sound-bites and some in Czech. Not useful. For this afternoon, I expect a first, internal draft of the proposal for the boundary uplifts (c.f. Exhibit 20), as well as a summary of the test results and a draft of the technical proposals (c.f. ASR003).","05/Nov/18 14:35;tz118;Dear [~rg535],  consolidated as well as detailed test results, recommendations for the improvemwents and initial draft recommendations for the uplifts to the Service Boundaries were communicated via email. 
Slack was used to streamline investigations/information exchange within the team and to support this challenging task.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 2] XBID Support,XP-418,74388,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,cf948,cf948,30/Oct/18 15:13,06/Nov/20 10:14,22/Feb/21 13:26,08/Nov/18 09:22,,,Pre2020,,,,,,,,,,,"XBID responsible team : Ampere

See sub-tasks for individual items.

How XBID support works: http://172.19.250.235:8090/confluence/display/AGILE/XBID+Support+Team",,cf948,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73008000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu0:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Scp exceptions are consumed,XP-415,74379,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,qo794,qo794,30/Oct/18 14:10,04/Aug/20 19:40,22/Feb/21 13:26,12/Jun/19 13:00,,,Pre2020,,,,,,,,,,,"If an SCP command fails, the exception is consumed and not logged at all after M7P-578 was introduced! It's not possible to investigate such an issue:
{noformat:title=log}
Unable to delete remote file via SSH (dbs_xbid@10.146.5.5:22)
{noformat}
Extend the log by an exception in {{energy-commons-transport}}.",,qo794,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,53654400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y89:00i1s000104201",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 27 [S],,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"12/Jun/19 13:00;radeale;Internal tech improvement.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test Client doesn't work against docker,XP-410,74362,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,eh941,eh941,30/Oct/18 13:17,17/Feb/21 09:18,22/Feb/21 13:26,17/Feb/21 09:18,,,Pre2020,,,,,,,ice,,,,"When loading order book the following exception is risen:

{noformat}
13:15:29.750 ERROR c.d.c.t.a.ComXervClient - Uncaught exception in thread AWT-EventQueue-0
java.lang.NullPointerException: null
	at com.deutscheboerse.commons.gateway.datamodel.OrderbookDataModel.lambda$findByDeliveryAreaAndProduct$1(OrderbookDataModel.java:59)
	at java.util.function.Predicate.lambda$and$0(Predicate.java:69)
	at java.util.function.Predicate.lambda$and$0(Predicate.java:69)
	at java.util.function.Predicate.lambda$and$0(Predicate.java:69)
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174)
	at java.util.concurrent.ConcurrentHashMap$ValueSpliterator.forEachRemaining(ConcurrentHashMap.java:3566)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499)
	at com.deutscheboerse.commons.gateway.datamodel.OrderbookDataModel.findByDeliveryAreaAndProduct(OrderbookDataModel.java:64)
	at com.deutscheboerse.comxerv.testclient.components.OrderbookPanel.addOrderbooks(OrderbookPanel.java:370)
	at com.deutscheboerse.comxerv.testclient.components.OrderbookPanel.handleEntitySelected(OrderbookPanel.java:363)
	at com.deutscheboerse.comxerv.testclient.components.OrderbookPanel.handleEntitySelected(OrderbookPanel.java:52)
	at com.deutscheboerse.comxerv.testclient.components.ProductSelectionComponent.lambda$new$0(ProductSelectionComponent.java:77)
	at javax.swing.JList.fireSelectionValueChanged(JList.java:1796)
	at javax.swing.JList$ListSelectionHandler.valueChanged(JList.java:1810)
	at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:184)
	at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:164)
	at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:211)
	at javax.swing.DefaultListSelectionModel.changeSelection(DefaultListSelectionModel.java:405)
	at javax.swing.DefaultListSelectionModel.changeSelection(DefaultListSelectionModel.java:415)
	at javax.swing.DefaultListSelectionModel.addSelectionInterval(DefaultListSelectionModel.java:518)
	at javax.swing.JList.addSelectionInterval(JList.java:2088)
	at com.deutscheboerse.comxerv.testclient.components.ProductSelectionComponent$ProductListModel$1.done(ProductSelectionComponent.java:221)
	at javax.swing.SwingWorker$5.run(SwingWorker.java:737)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.run(SwingWorker.java:832)
	at sun.swing.AccumulativeRunnable.run(AccumulativeRunnable.java:112)
	at javax.swing.SwingWorker$DoSubmitAccumulativeRunnable.actionPerformed(SwingWorker.java:842)
	at javax.swing.Timer.fireActionPerformed(Timer.java:313)
	at javax.swing.Timer$DoPostEvent.run(Timer.java:245)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:756)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:80)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:726)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:201)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:109)
	at java.awt.WaitDispatchSupport$2.run(WaitDispatchSupport.java:184)
	at java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:311)
	at java.awt.EventQueue.dispatchEventImpl(EventQueue.java:756)
	at java.awt.EventQueue.access$500(EventQueue.java:97)
	at java.awt.EventQueue$3.run(EventQueue.java:709)
	at java.awt.EventQueue$3.run(EventQueue.java:703)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:80)
	at java.awt.EventQueue.dispatchEvent(EventQueue.java:726)
	at java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:201)
	at java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:116)
	at java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:105)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101)
	at java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:93)
	at java.awt.EventDispatchThread.run(EventDispatchThread.java:82)

{noformat}",,eh941,hj444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,432000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r00008u6",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Feb/21 09:18;hj444;Actually Test Client is working against Docker. 
Jira will be closed.
If any issue a new task will be created.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove obsolete cmminteg.events.out queue,XP-404,74314,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eh941,qo794,qo794,29/Oct/18 19:54,09/May/19 10:14,22/Feb/21 13:26,09/May/19 10:14,XBID 1.5.9,XBID 2.0,XBID 2.0,,Capacity,,,,,,,,,"{{cmminteg.events.out}} queue in INT vhost is obsolete (used by CMM back in the time, but not any longer). It must be removed as messages in it dead-letter all the time and might produce false alarms.",,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73094400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,29/Oct/18 19:54,,,,,,,,,,,,,,,,,,,,,,,"1|y08oic:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KPIs for section reporting (XBID SW quality),XP-394,74261,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,dm700,dm700,29/Oct/18 12:18,06/Nov/20 10:14,22/Feb/21 13:26,02/Jan/19 16:31,,,Pre2020,,,,,,,,,,,"From 2019 we could refactor and rethink our current KPI over XBID product. IN section KPIs for the product are reported in 2018 two metrics - test coverage and number of bugs in CUTe. 

We should replace them with something more acceptable and reasonable. And something team really understands and stands behind.

If XBID will agree on metrics which is applicable only on XBID than ok. Perfect metric would be one which is reasonable across all products.
 ",,dm700,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67478400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r01s",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Dec/18 08:58;dm700;-	Technický dluh: Target je, aby nerostl v čase
-	Code coverage: Target je, aby neklesala v čase
-	Number of bugs on new features – metrika je 0 bugů z UAT testů na nových features

- kognitivní komplexita - jen monitorovat","02/Jan/19 16:31;xu897;KPI's are prepared and to be presented by [~dm700] on the next XBID Product Review.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Set up release notes process,XP-392,74249,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,qz412,qz412,29/Oct/18 10:50,06/Nov/20 10:11,22/Feb/21 13:26,14/Nov/18 17:53,,,Pre2020,,,,,,,,,,,"We need to set up a process on tracking:
 * what has been included in a Sprint increment
 * what is included in a test / prod release

=> streamlined Release Notes approach that will make our lives easier and reduce error rate + risk of reverts

Acceptance criteria
 * The resulting process is agreed with Release Manager [~th407]",,ll664,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-3229,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/18 17:53;ll664;The job to generate the release notes for the whole XBID product set up here:

https://scmci1.deutsche-boerse.de/job/Energy/view/Xbid%20Sections/job/xbid-release-notes/

The release notes are committed incrementally in {{CHANGELOG.md}}, currenlty the job needs to be run manually after the spring increment is created.

Changelog can be found here: https://github.deutsche-boerse.de/dev/xbid-product/blob/develop/CHANGELOG.md


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Internal Test Strategy v1.0 [Alpha DONE, Ampere, HOT]",XP-377,74175,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs131,cs131,cs131,26/Oct/18 13:55,04/Aug/20 19:41,22/Feb/21 13:26,22/Nov/18 09:06,,,Pre2020,,,,,,,,,,,"Blueprint strategy to define testing process within agile team:=
 * Testing techniques (don't forget topic of feature branching - discussed on retro)
 ** Cucumber is preferred DBG tool
 ** See draft of Feature Matrix - http://172.19.250.235:8090/confluence/display/XT/feature+list+for+Xbid+regression+tests
 * Test environment
 * When to test
 * Test approach
 * Tools and framework
 * Regression tests

Anyone reading this ticket feel free to add your comments/inputs/ideas for the benefit of all

For inspiration: http://172.19.250.235:8090/confluence/display/AGILE/Agile+Test+Strategy+2.0

-Maybe relevant: [http://172.19.250.235:8090/confluence/display/TOS/High+Level+Test+Strategy]- Obsolete

Acceptance criteria:
 * v1.0 covering the areas indicated above is written and reviewed within the responsible team",,cs131,de698,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71712000,,,,,,,,,,,,,,,XP-401,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:wr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 3,Home Office Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/18 11:37;xu897;My thinking about structure of tests strategy - http://172.19.250.235:8090/confluence/pages/viewpage.action?title=Test+Strategy+Draft&spaceKey=XBID","14/Nov/18 13:53;de698;Please see couple of changes in the confluence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RAbbitMQ 3.7.7 - AMQP disconnect not working from application - ANALYSIS,XP-374,74165,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Critical,Done,eg288,eg288,eg288,26/Oct/18 11:17,06/Nov/20 10:59,22/Feb/21 13:26,06/Nov/18 15:54,,,Pre2020,,Trading,,,,,,,,,"*Analyse:*

XBID application enforces user disconnection in case of events like user suspensions, password change, balancing group modification, product modification, etc. According to M7P-2960 it is not working with new production rabbitmq 3.7.7. Please verify and suggest a fix.",,eg288,jy268,qz412,radeale,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,26/Oct/18 11:17,,,,,,,,,,,,,,,,,,,,,,,"1|000yu1:r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Oct/18 17:20;jy268;I can confirm that this issue was happening on SIMU as well. For example on 16.10.2018","02/Nov/18 10:44;radeale;SYS3 test related error in case a user is SUSPENDED. In this case the user is also disconnected = {color:#00875A}*OK*{color}.

{code}2018-11-02T09:43:19.844Z [cTaskExecutor-2][ASYNC_JOB][1e68094] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:33318 -> 10.139.41.211:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T09:43:19.847Z [cTaskExecutor-2][ASYNC_JOB][1e68094] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:33532 -> 10.139.41.211:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T09:43:19.858Z [cTaskExecutor-2][ASYNC_JOB][1e68094] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:41982 -> 10.139.41.71:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T09:43:19.860Z [cTaskExecutor-2][ASYNC_JOB][1e68094] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete queue comxerv.broadcastQueue.SADMIN02
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:169)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:403)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:399)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteQueue(RabbitmqApiClientImpl.java:399)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:149)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.delete(RestTemplate.java:462)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:166)
        ... 12 common frames omitted
2018-11-02T09:43:19.861Z [cTaskExecutor-2][ASYNC_JOB][1e68094] INFO  c.d.e.m.a.AsyncJobExecutorImpl - Finished execution of async task 'TmRabbitmqAsyncAdminImpl::disconnect(SADMIN02, Trader session has been terminated by Core)'. Time spent: 60ms{code}","02/Nov/18 10:48;radeale;Resetting an ADMIN user password results in heartbeat loss for the user and subsequent disconnection = *{color:#00875A}OK{color}*.","02/Nov/18 11:14;radeale;{color:#0747A6}PX User{color}
User Suspension - results in the error below in the log, the user seems to stay connected, but cannot perform any operations (only a blank Ack is returned). The test client says: {color:#DE350B}An error occurred in the broadcast connection, attempting to reinitialize...{color}

{code}2018-11-02T10:11:20.417Z [cTaskExecutor-1][ASYNC_JOB][6807861d] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:37586 -> 10.139.41.71:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:11:20.420Z [cTaskExecutor-1][ASYNC_JOB][6807861d] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:57156 -> 10.139.41.211:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:11:20.422Z [cTaskExecutor-1][ASYNC_JOB][6807861d] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:57300 -> 10.139.41.211:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:11:20.423Z [cTaskExecutor-1][ASYNC_JOB][6807861d] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete queue comxerv.broadcastQueue.XBEPEXX1
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:169)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:403)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$9.execute(RabbitmqApiClientImpl.java:399)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteQueue(RabbitmqApiClientImpl.java:399)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:149)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.delete(RestTemplate.java:462)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:166)
        ... 12 common frames omitted
2018-11-02T10:11:20.423Z [cTaskExecutor-1][ASYNC_JOB][6807861d] INFO  c.d.e.m.a.AsyncJobExecutorImpl - Finished execution of async task 'TmRabbitmqAsyncAdminImpl::disconnect(XBEPEXX1, Trader session has been terminated by Core)'. Time spent: 51ms
{code}","02/Nov/18 11:23;radeale;{color:#0747A6}PX User{color}
BG Suspension - results in the error below in the log, the user seems to stay connected, but cannot perform any operations (only a blank Ack is returned). The test client says: {color:#DE350B}An error occurred in the broadcast connection, attempting to reinitialize...{color}

{code}2018-11-02T10:22:32.877Z [cTaskExecutor-2][ASYNC_JOB][6a12eeb5] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:36732 -> 10.139.41.211:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:22:32.880Z [cTaskExecutor-2][ASYNC_JOB][6a12eeb5] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:45390 -> 10.139.41.71:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:22:32.883Z [cTaskExecutor-2][ASYNC_JOB][6a12eeb5] ERROR c.d.e.m.a.TmRabbitmqAdminImpl - Can not delete connection 10.136.143.245:45516 -> 10.139.41.71:51900
org.springframework.web.client.HttpClientErrorException: 404 Not Found: Not Found; nested exception is org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at com.deutscheboerse.web.client.JsonTemplate.handleRestError(JsonTemplate.java:147)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:192)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:532)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl$14.execute(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.handleConnectException(RabbitmqApiClientImpl.java:699)
        at com.deutscheboerse.amqp.rabbitmq.api.RabbitmqApiClientImpl.deleteConnection(RabbitmqApiClientImpl.java:527)
        at com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminImpl.disconnect(TmRabbitmqAdminImpl.java:137)
        at com.deutscheboerse.energy.m7.async.TmRabbitmqAsyncAdminImpl.lambda$disconnect$2(TmRabbitmqAsyncAdminImpl.java:30)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$null$2(AsyncJobExecutorImpl.java:59)
        at com.deutscheboerse.energy.m7.log.ContextLogging.doWithinContext(ContextLogging.java:42)
        at com.deutscheboerse.energy.m7.async.AsyncJobExecutorImpl.lambda$executeInternal$3(AsyncJobExecutorImpl.java:56)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.springframework.web.client.HttpClientErrorException: 404 Not Found
        at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)
        at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:667)
        at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:620)
        at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:595)
        at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:516)
        at com.deutscheboerse.web.client.JsonTemplate.deleteObject(JsonTemplate.java:187)
        ... 12 common frames omitted
2018-11-02T10:22:32.903Z [cTaskExecutor-2][ASYNC_JOB][6a12eeb5] INFO  c.d.w.c.JsonTemplate - 'comxerv.broadcastQueue.XBEPEXX1' deleted from '/api/queues/ext/'.
2018-11-02T10:22:32.903Z [cTaskExecutor-2][ASYNC_JOB][6a12eeb5] INFO  c.d.e.m.a.AsyncJobExecutorImpl - Finished execution of async task 'TmRabbitmqAsyncAdminImpl::disconnect(XBEPEXX1, Trader session has been terminated by Core)'. Time spent: 85ms
{code}","06/Nov/18 11:17;qz412;Please add a suggestion how to fix. Then we can move to implementation. Thx, Ondra.","06/Nov/18 15:49;eg288;Solution proposal attached to XP-463, see the description part.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace certificates for all non-prod environments for ComTrader and RabbitMQ,XP-372,74158,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cf948,cf948,cf948,26/Oct/18 10:00,06/Nov/20 10:45,22/Feb/21 13:26,23/Nov/18 08:25,,,Pre2020,,Capacity,ComTrader,RabbitMQ,Trading,,,,,,"Current certificates will expire 23rd November.
 Public keys are attached.

Passwords:
 TEST policy 1055
 COMTRADER,CMM J382pB7cgM8kd3DT
 PMITEST,CMM W4Ds93zb775jNhAX
 COMTRADER,SOB w486isZS8YZ8u8aS
 PMITEST,SOB FC8Mp93xp2BcmG39
----
This is the dev part of the task - updating of the keystore.

*Refinement:*
 * What needs to be done by dev team (CT only?) 
 * What needs to be done by TechOps?

The external comunication to be coordinated with [~tj898].",,cf948,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-2129,,,,,,,"26/Oct/18 10:00;cf948;COMTRADER_1055_CMM.p12;https://jira.deutsche-boerse.com/secure/attachment/60918/COMTRADER_1055_CMM.p12","26/Oct/18 10:00;cf948;COMTRADER_1055_SOB.p12;https://jira.deutsche-boerse.com/secure/attachment/60917/COMTRADER_1055_SOB.p12","26/Oct/18 10:00;cf948;PMITEST_1055_CMM.p12;https://jira.deutsche-boerse.com/secure/attachment/60916/PMITEST_1055_CMM.p12","26/Oct/18 10:00;cf948;PMITEST_1055_SOB.p12;https://jira.deutsche-boerse.com/secure/attachment/60915/PMITEST_1055_SOB.p12",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70675200,,,,,,,,,,,,,,,XP-3201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b004",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 4,Ampere Sprint 5,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,comtrader-2.5.x,XP-69,XP-2583,XP-2554,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"26/Nov/18 15:07;jenkins;SUCCESS: Integrated in Jenkins build Energy/TestClient - Release #47 (See [https://scmci1.deutsche-boerse.de/job/Energy/job/TestClient%20-%20Release/47/])
XP-372: replace all non-prod certs (pavel.ceska: rev ec3fedb903b61986abd4182565149b16acb3845d)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"RTS3 Slice B - Execution shadowing, calibration + PERF/DST/etc. runs",XP-352,74114,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tr866,qz412,qz412,25/Oct/18 12:57,04/Aug/20 19:16,22/Feb/21 13:26,01/Nov/18 09:21,,,Pre2020,,Trading,,,,,,,,,"[http://172.19.250.235:8090/confluence/display/TD/UAT+II+-+test+plan] --> test plan
 [http://172.19.250.235:8090/confluence/display/TD/RTS+3] --> RTS3

*Goal*:
 * Cooperate with the assignee of XBID-305
 * Execute tests in PERF / DST / Other envs, tweak, calibrate as needed

[~od044], [~tr866], please review confluence links and attached word document which was used during UAT II

Execution will happen from 25 - 31th (working days exclusively) Oct be supported by a call from 13:00 - 16:00 (organized by TWG). 

 ",,od044,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73526400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yts:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
External JIRA management sprint 1,XP-350,74112,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,tm431,cs131,cs131,25/Oct/18 12:15,06/Nov/20 10:14,22/Feb/21 13:26,31/Oct/18 14:19,,,Pre2020,,,,,,,,,,,"daily review and follow up on external Jira tickets and creating/moving tickets to internal  DEV team or Techlog team

 

*Jira Filter*

project = ""XBID Project""",,cs131,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72921600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r0000002",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/18 14:19;tm431;All external JIRAs were cloned&moved to XP projects as subtask.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AlarmTilt - test of corporate contract version,XP-345,74103,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,de698,qz412,qz412,25/Oct/18 10:51,27/Aug/20 13:41,22/Feb/21 13:26,31/Oct/18 09:56,,,Pre2020,,AlarmTilt,,,,,,,,,"New Alarmtilt URL will be deployed to PROD on 30. October. The URL is [https://xbid.alarmtilt.net|https://xbid.alarmtilt.net/] and can be also used in SYT1.

It can be tested by adding own email into Alarmtilt recipients in URL above and triggering Alarmtilt event in SYT1 according [http://172.19.250.235:8090/confluence/pages/viewpage.action?title=AlarmTilt+events+and+messages&spaceKey=TD]

Easy events to test are LTS lost connection or Shipping Module no longer available. Alarmtilt will send email and the event can be found in Alarmtilt history.

Alarmtilt documents can be found in S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\04 User Manuals\MFG500 - Events and Notifications 
Valid credentials are in Support documents subfolder and document VisualMapAT-v12.docx.",,de698,dw255,eh941,qz412,rehapav,,,,,,,,,,,,,,,,TECHLOG-1359,,,,,,,,,,,,,,,SERVICE-1958,,,,,,,"29/Oct/18 17:04;de698;AlarmTilt _notification emails.txt;https://jira.deutsche-boerse.com/secure/attachment/61071/AlarmTilt+_notification+emails.txt","29/Oct/18 17:04;de698;History Alarmtilt.PNG;https://jira.deutsche-boerse.com/secure/attachment/61070/History+Alarmtilt.PNG",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73094400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07heg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/18 13:28;eh941;Waiting for TECHLOG-1359","25/Oct/18 15:19;dw255;Deployed into SYT1 on 25. October. Tested by killing connected Test Client and shutting down both SPM nodes. No email was received and the events are not even in Alarmtilt history. TECHLOG-1359 was created.","26/Oct/18 15:22;rehapav;Critical for go live on 30/10 at 8:00
Sucesful tests required to be finished Monday 29/10 EOB","26/Oct/18 15:43;dw255;Directory and Procedures in PROD environment were compared in new xbid.alarmtilt.net and old v5.alarmtilt.net. The new alarmtilt contains everything what is in the old one.","29/Oct/18 13:27;rehapav;Piotr Wasilewski confirmed that since 12:48 on Slack
https://jira.deutsche-boerse.com/browse/TECHLOG-1359
is resolved","30/Oct/18 08:48;rehapav;Any update regarding SMS delivery?","30/Oct/18 09:36;de698;SMS delivery was not in scope for this test. Discussed with the test team: sms delivery was not tested as it was not enabled.

Emails received from AlarmTilt are attached as well as the screenshot from History with corresponding events.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Evaluate  Support request since JULY,XP-343,74094,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cs131,tm431,tm431,25/Oct/18 09:59,06/Nov/20 12:34,22/Feb/21 13:26,31/Oct/18 09:58,,,Pre2020,,,,,,,,,,,"Evaluate 3rd Party Support request and Support reuquest since JULY, for Suzanna and Malina. Outcome will be an excel file or confluence page",,cs131,tm431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/18 14:55;cs131;support request evaluation.csv;https://jira.deutsche-boerse.com/secure/attachment/61279/support+request+evaluation.csv",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73008000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:2h",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/18 14:58;tm431;use following FILTER

project = ""XBID Project"" and (type = ""Support Request"" or type = ""3rd Party Support"") and created > ""2018/06/01""","30/Oct/18 14:44;cs131;support request evaluation sheet  [^support request evaluation.csv] ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make running XBID in Docker easier (basic PoC),XP-340,74076,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,ll664,ll664,25/Oct/18 08:40,06/Nov/20 11:34,22/Feb/21 13:26,01/Nov/18 09:25,,,Pre2020,,Other,,,,,,,,,"Running XBID Docker images within xbid-test project requires couple of manual steps and is not particularly straightforward.

To enable easy manual testing of intermediate builds during the sprint, it should be possible to run the whole thing with a single script, optionally specifying an image version.

+ investigate the status of similar activities in M7T

PoC for a minimal version - fixed set or modules + versions, dataset selectable.",,ei349,ll664,lt112,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73008000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:0i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/18 10:18;lt112;https://github.deutsche-boerse.de/dev/xbid.utils-py","31/Oct/18 10:08;ei349;can you please prepare some basic documentation on confluence? ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BAIT - Security Analysis,XP-336,74043,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,24/Oct/18 14:02,06/Nov/20 12:34,22/Feb/21 13:26,03/Jan/19 13:06,,,Pre2020,,,,,,,,,,,"----
{color:#de350b}*To be split and estimated*{color}
----
Request from Security Officers,

In order to reach BaFin compliance we need to
 * understand the BAIT requirements (which comprises the BaFin requirements)
 * identify which of these are/aren't covered by our M7 products (or not relevant) and
 * estimate the implementation effort/timeline on our side.

It is also important to understand the impact in the future (e.g. concerning infrastructure, tools, cloud usage, security awareness in all units).

 

All units and POs have to analyse and understand the BAIT requirements and identify which requirement are already fulfilled and which need to be added/adapted to be BaFin-compliant for this.

 

Based on this analysis we will create and agree a roadmap 2019 ""BaFin-compliance of the M7 products"" .

 

The next steps are:
 # The teams and Product Owner will go through the BAIT requirements within 2 weeks in order to get an understanding about the scope.
 # Starting in 2 weeks, we will schedule weekly info sessions to clarify questions.
 # We will focus in each session on ca. 2 topics. We will inform you before the meetings which topics will be discussed in the meeting – your presence is not needed if you are not affected by these topics or if you don’t have questions.
 # Units and PO will fill out the BAIT document.

Don’t hesitate to contact us also via our slack channel energy_security.

 

Timeline for filling out the all sheets (01_IT Strategy,….09_Kritical Infrastructure); i.e. Identifying the missing BAIT processes in Energy and aligning them with DBAG GIS expectations, is end of this year. It is not expected that you create any process description etc. until then.

 

You can find
 * The presentation of the meeting on sharepoint: [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/BAIT%20Requirement/BAIT_Energy.pptx?web=1]
 * The BAIT sheet, you have to fill out (only the 2 columns related to your team/application) on sharepoint: [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/BAIT%20Requirement/BAIT%20Requirements%20V5.xlsx?web=1]
 * The description how it should be filled out on confluence: [http://172.19.250.235:8090/confluence/display/ESO/Preparation+of+BAIT+Requirements+in+Energy+Section]

*Excel sheet can be found here - {color:#de350b}accessible only via Citrix{color}:*

https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F02%20General%20topics%2FSecurity%2FBAIT%20Requirement&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D​

 

Please contact me if you don’t have access to the documents on sharepoint.",,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/19 13:06;qz412;BAIT Requirements V6_6_XBID done.xlsx;https://jira.deutsche-boerse.com/secure/attachment/64008/BAIT+Requirements+V6_6_XBID+done.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67478400,,,,,,,,,,,,,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r00008u0a",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/19 13:06;qz412;Provided to ESO by PO on 13th Dec, Excel attached - [^BAIT Requirements V6_6_XBID done.xlsx], ticket status set to Done.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove unused Order database columns,XP-330,68113,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,eg288,eg288,09/May/18 17:28,06/Nov/20 11:34,22/Feb/21 13:26,21/Nov/18 10:11,,,Pre2020,,Trading,,,,,,,,,"remove unused Order database columns even before removing the related features itself
 * needs discussion
 * could have have decent perf impact if order and order_history tables are lean and mean

The list bellow includes only db structures which are not used by CODE at all, i.e. xbid code was already altered not to rely on it.

*Unused DB structures* (the usage was removed from code under JIRA issue in brackets):

*Columns:*
 Order.brokerUserId (---XDEV-4678---)
 Order.openCloseInd (-XDEV-5214-)
 Trade.buyBrokerUserId (---XDEV-4678---)
 Trade.sellBrokerUserId (---XDEV-4678---)
 Trade.buyOrderOpenCloseInd (-XDEV-5214-)
 Trade.sellOrderOpenCloseInd (-XDEV-5214-)
 Member.memberTyoe(---XDEV-5079---)

Order(XDEV-5187)
 * {color:#333333}clientAcctId{color}
 * {color:#333333}clientMbrId{color}
 * {color:#333333}clientTraderId{color}

{color:#333333}Trade(XDEV-5187){color}
 * {color:#333333}buyOrderClientAcctId{color}
 * {color:#333333}buyOrderClientMbrId{color}
 * {color:#333333}buyOrderClientTraderId{color}
 * {color:#333333}sellOrderClientAcctId{color}
 * {color:#333333}sellOrderClientMbrId{color}
 * {color:#333333}sellOrderClientTraderId{color}

Remove externalRevision column from tables (XDEV-5189 - merged into Develop only)
* Order
* Trade
* TmMarketArea
* TmDeliveryArea

*Tables:*
 CX_350_BALANCING_GROUP_X_BALANCING_GROUP (---XDEV-4678---)
 CX_351_BALANCING_GROUP_X_BALANCING_GROUP_HISTORY (---XDEV-4678---)",,eg288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XDEV-5189,XDEV-5079,XDEV-5187,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88041600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:whi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SLA reports for October,XP-328,74020,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,dw255,uv683,uv683,24/Oct/18 12:34,04/Aug/20 19:41,22/Feb/21 13:26,06/Nov/18 10:35,,,Pre2020,,SLA Report Tool,,,,,,,,,"*Background*

XBID Report Tool is generating three reports for customers containing various performance metric, statistics and credit points. Names of these reports are (for October)
 * XBID Service Boundary Reporting October 2018.xlsx
 * XBID Performance and SM SLA Reporting October 2018.xlsx
 * XBID_Credit_points_report_October_2018.xlsx

At the moment the process of getting and providing these reports is not fully automated. They are being generated xbprodsla1 and that's it for automatition. Moreover there has been issues in generating them in past months so if this happens again (shouldn't be a problem) it needs to be done from localhost.

*What needs to be done*
 # On 2nd of November download all three reports from xbprodsla1. There is a job for this here [https://scmci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Download-SLA_Reports/] .However it doesn't support Credit Scheme Report at the moment. I have created a Jira to add it at the beginning of October https://jira.deutsche-boerse.com/browse/TECHLOG-1225.  If you will not get Credit Scheme Report, contant Techops.
 # Smoke check data in reports. Does it cover all the hourly and daily intervals? Isn't there zeros in fields?
 # Upload files to [https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/03%20XBID%20SLA%20Reporting] in particular directories and let [~gd553] and [~qm925] know.

 

 ",,dw255,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,APM-219,,,,,,,"05/Nov/18 09:41;tz118;XBID Service Boundary Reporting October 2018 (004).xlsx;https://jira.deutsche-boerse.com/secure/attachment/61511/XBID+Service+Boundary+Reporting+October+2018+%28004%29.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72489600,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Nov/18 16:42;uv683;report generated and sent to [~tz118] and [~dw255] for quick verifaction. In case that I will not be here on Monday, please add the mto sharepoint

https://projects.deutsche-boerse.de/sites/ps0080/Shared%20Documents/03%20XBID%20SLA%20Reporting","02/Nov/18 16:56;tz118;[~uv683]updated boundary report with modified ""prognosis"" attached
Credit points - max for DBAG is 5 (in report is 24)","06/Nov/18 10:34;dw255;[~gd553], [~qm925]:

SLA Reports for October are reviewed and uploaded to SharePoint.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explain why Heartbeat has been lost in ComTrader,XP-327,73499,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,cf948,tm431,tm431,11/Oct/18 08:18,06/Nov/20 10:40,22/Feb/21 13:26,27/Nov/18 15:05,,,Pre2020,,ComTrader,PMI Tools,,,,,,,,"*Environment:* SIMU
*Scenario: *Fail-over re-execution - Scenario 1.3
*Date/Time:* 2018/10/09 - 13:45 - 1500 CEST

*Steps to reproduce:*
Step 7; DBAG will kill the active node (i.e. the primary)
Step 9; DBAG drop one of the nodes in the mirrored state (only one node is available now): DBAG will kill the node which is the one where PXs are currently connected to

*Expected result:*
Step 7; Hot stand node by change to mirrored. 2 Node mirror state,  1 Node off
RabbitMQunaivalable on primary node= FR_AE_016 alarm expected.
LTSs are not forced to relogin.
Step9; 1 Node runnig, 2 nodes off. FR_AE_017 RabbitMQ unavailable on secondary node alarm expected

*Actual result:*
step 7;  Hot stand node by change to mirrored. 2 Node mirror state,  1 Node off
RabbitMQunaivalable on primary node= FR_AE_016 alarm received
LTSs are not forced to relogin, but message 'Heartbeat of exchange has been lost' received
step 9; 1 Node runnig, 2 nodes off. FR_AE_017 RabbitMQ unavailable on secondary node alarm received, but No message 'Heartbeat of exchange has been lost' received.",,cf948,qz412,tm431,,,,,,,,,,,,,,,,,,,,,XBID-3999,,,,,,,,,,,,XP-383,,,,,,,"11/Oct/18 08:19;tm431;XTG with DBAG MM 20181009 - R1.5 failover tests - Re-execution Scenario 1.3.docx;https://jira.deutsche-boerse.com/secure/attachment/60323/XTG+with+DBAG+MM+20181009+-+R1.5+failover+tests+-+Re-execution+Scenario+1.3.docx","12/Oct/18 11:12;tm431;hearbeat lost.png;https://jira.deutsche-boerse.com/secure/attachment/60382/hearbeat+lost.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70588800,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,10/Oct/18 16:49,,,,,,,,,,,,,,,,,,,,,,,"1|y07rhg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Oct/18 08:18;tm431;Note from Niklas:

{color:#000000} {color}

{color:#000000}EPEX: LTS to Datacenter 2 and ComTrader to Datacenter 1{color}

 

{color:#000000}OMIE: LTS to Datacenter 1 and ComTrader to Datacenter 2{color}

 

{color:#000000}NP: LTS to Datacenter 1 and ComTrader to Datacenter 1{color}

{color:#000000}NPADM002 disregarded for that execution]{color}

 

everyone was connect to node2, then everyone was connected to node4 then everyone was connected to node6
 I always stopped the active one","11/Oct/18 12:33;tm431;To simplify what needs to be analysed:

Only relevant for Commtrader.

step 7

RabbitMQ Node2 was active node4 and node6 passive, everybody was connected to Node2 which was killed.

'Heartbeat of exchange has been lost' *received*

step 9

RabbitMQ Node2 was killed, Node4 was killed where everybody was connected, only active node6 was up

'Heartbeat of exchange has been lost' *was not received.* 

 

To be answered why it was received for step 7 and not received in step 9. They are just questioning the inconsistency...

*All PX's should have receive it.* ","12/Oct/18 12:34;cf948;Message displayed in ComTrader doesn't originate from XBID Core.
We display this message when we don't receive appplication HeartBeat for 2 heart beat intervals (cca 11 seconds).

This message is displayed only when first of 3 RabbitMQs is put down, probably because synchronization of 2 remaining node takes some time.
When second RabbitMQ is put down only 1 RabbitMQ is remaining in cluster and continuation is faster.

Run of scenario is also dependent on exact times when RabbitMQs are put down, because application heart beat is sent in 5 seconds intervals.","15/Oct/18 12:45;tm431;Dear DBAG,

Hearbeat lost message is indeed not expected as part of the result in R1.5 scenario 1.3 step 9 due to the <SeqNum rk=""1.comxerv.heartbeat"" seq=""1491""/> message at 12:26:40 UTC, 12:26:47 UTC etc, which means that only 1 heartbeat message was missed at 12:26:45. However according to the DFS510 and MFG500 the comxerv.heartbeatExchange (used for broadcasting heartbeat messages) is missing from the PMI files.

 

No need to hurry with answer.  As external Jira was relabeled to Minor, and we can have 8minors to pass UAT phase

 

 ","18/Oct/18 13:26;tm431;what needs to be answered:

is ti OK that core Heartbeat message is not in PMI logs? form specification point of view
is it vaild to validate hearbeat timestamps from SeqNum message?","27/Nov/18 09:55;tm431;New Question from customers:

Dear Pavel,

TWG FTF would like to clarify if time to synchronization when the first of the first of 3 RabbitMQ is put down require more tan 10 seconds, and if during this time gap the clientes cannot process the messages from the broadcast queue.

Could you confirm if this is the reason why the comtrader raise the message?

Best regards","27/Nov/18 09:57;tm431;two options:

1) political answer, and we will do nothing, but during next failover this can be tricky, becaouse 10s of not sending broadcast can be considered as major, and I think that there is no way how to easily fix it

2) add more logging into core and rabbitmq and investigate what is really happening. Will take some time.","27/Nov/18 15:05;qz412;Further discussed in XP-669",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test resolved issues for SLA Report Tool from XDEV project,XP-325,74011,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,cf948,cf948,24/Oct/18 11:58,04/Aug/20 19:40,22/Feb/21 13:26,29/Jan/19 11:11,,,Pre2020,,SLA Report Tool,,,,,,,,,"Test 11 issues with label testSLA from XDEV project.

Search query: project = ""XBID Development"" and labels = testSLA",,cf948,ll664,od044,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-326,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65232000,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07zy7:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 10,Alpha Team Sprint 11,Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Nov/18 09:30;xu897;Estimated by [~uv683]","15/Jan/19 13:38;od044;XDEV-5343 - passed
XDEV-4954 - passed","16/Jan/19 16:09;od044;[~uv683] Can you have quick a look whether related tickets are still valid regarding new SLA report tools?","21/Jan/19 13:44;ll664;Went through through the issue, most of the are either technical/very old to be worth testing.

The only one to test IMHO is XDEV-3685.","29/Jan/19 11:11;ll664;Discussed with [~od044], the Report Tool is undergoing heavy rewrite at the moment, hence it's not worthy to test the issue on old 1.x version. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Limit max number of open channels on RabbitMQ,XP-323,71273,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,eg288,nn481,nn481,20/Aug/18 11:06,31/Aug/20 15:38,22/Feb/21 13:26,28/Mar/19 14:05,,,Pre2020,,RabbitMQ,,,,,configuration,,,,"Several times we have faced wrong behaving AMQP clients, whose were opening thousands of channels on connection to RabbitMQ.

RabbitMq can restrict max number of channels per connection:
channel_max- Maximum permissible number of channels to negotiate with clients, not including a special channel number 0 used in the protocol. Setting to 0 means ""unlimited"", a dangerous value since applications sometimes have channel leaks. Using more channels increases memory footprint of the broker.

Default: channel_max = 2047

We should check if set and adjust to reasonable value.",,cf948,eg288,ei349,nn481,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60134400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/22,,,,,,,,,,,,,,,,,,,,"1|y071js:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,qo288-patch-2,tomcat-rollback,traversal-XP-2485,XP-2942,XP-2506-xbid-dev-env,XP-3025-catalina-timezone,trailing-slash-syt1,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"20/Aug/18 13:28;nn481;We have found that channel_max is not set in energy-mkt-shared. On perf rabbitmq runtime there is channel_max set to 0, which means unlimited (It seems that default  2047 is not applied):

{code}
[rabbitmq@xbperfamq1 sbin]$ ./rabbitmqctl -n xbid-perf-int-amq1@xbperfamq1 environment | grep channel
WARNING: Removing trailing slash from RABBITMQ_LOG_BASE
      {channel_max,0},
      {channel_operation_timeout,15000},
          [rabbit_reader,rabbit_channel,gen_server2,rabbit_exchange,
{code}","11/Sep/18 15:42;cf948;channel_max is now set to 512","12/Sep/18 15:17;cf948;This needs to be merged with release of XB-1.5.4.
https://gitlab.deutsche-boerse.de/energy-mkt-prodsupp/energy-mkt-shared/merge_requests/945/diffs","20/Sep/18 12:57;ei349;MR for Energy Mkt Shared: 

[https://gitlab.deutsche-boerse.de/energy-mkt-prodsupp/energy-mkt-shared/merge_requests/963/diffs]

MR for Ansible: 

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/163","20/Sep/18 12:58;ei349;Can you please review? ","27/Sep/18 10:01;eg288;I closed invalid MR (it was modifying M7 configs): https://gitlab.deutsche-boerse.de/energy-mkt-prodsupp/energy-mkt-shared/merge_requests/945/diffs
I merged MR https://gitlab.deutsche-boerse.de/energy-mkt-prodsupp/energy-mkt-shared/merge_requests/963/diffs into xbid-dev-env

MR for master is *missing*","15/Oct/18 16:49;ei349;MR to the master branch is ready and can be found below: 

https://gitlab.deutsche-boerse.de/energy-mkt-prodsupp/energy-mkt-shared/merge_requests/989","24/Oct/18 17:21;eg288;GitHub MR: https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/22","28/Mar/19 14:04;eg288;GitHub MR https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/22 has been merged -> closing the issue",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade XBID-Core to Spring Boot 2,XP-311,73987,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,24/Oct/18 09:37,06/Nov/20 11:34,22/Feb/21 13:26,28/Nov/18 15:33,,,Pre2020,,,,,,,configuration,,,,"{color:#ff0000}*On rollout of XBID 2.0*{color}

Do not forget to push for Grafana update - TECHLOG-1789 - health endpoints API has changed.

 

-*Blocked*-

In order to upgrade to latest Spring Boot (2.0.6.RELEASE at the time of writing) we need upgrade out target Tomcats to 8.5.34 (that's what Spring Boot uses). Otherwise the WAR is not deployable, because of incompatibility of 8.0.x and 8.5.x Tomcat versions.

{color:#de350b}The tomcat upgrade is to be performed by techops.{color}

The code upgrade is in progress and tracked here: [https://github.deutsche-boerse.de/dev/xbid/commits/XP-311]

Update docker",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4146,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,70416000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/98,,,,,,,,,,,,,,,,,,,,"1|000yus:00w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1261-guava-28,selenide-poc,XP-2942,tomcat-rollback,XP-3025-catalina-timezone,xbid-losses-poc,XP-2484,XP-3230,XP-3110-deprecated-log,XP-3070,xbid-2.0.25.x,fixing-failover,plewmic-scripts,XP-1504,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-456,XP-2979-postgresql,XP-3264,develop,XP-2694,XP-1241-new-failover-docker,XP-2232,XP-2501-to-xbid-dev-env,XP-4273-owasp-zap-enable,traversal-XP-2485,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,XP-2488-xbid-dev-env,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"29/Nov/18 16:01;ll664;Spring Boot has been upgraded across XBID, the new versions starting from 1.6.0.9 require Tomcat 8.5.35.

Merge request for Tomcat upgrade in the customer-facing envs attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Sprint 1] Deliver Sprint Increment,XP-308,73981,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,xu897,xu897,24/Oct/18 08:21,06/Nov/20 10:14,22/Feb/21 13:26,07/Nov/18 16:23,,,Pre2020,,,,,,,,,,,"Deliver Sprint Increment based od DoD quality criteria - [http://172.19.250.235:8090/confluence/display/AGILE/XBID+-+Definition+of+Done+and+Potentially+Shippable]

 

 ",,ei349,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72921600,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:0c",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/18 14:32;ei349;XBID
 * XBID Hp Fortify: [https://scmci1.deutsche-boerse.de/job/Energy/view/Xbid/job/xbid-hpfortify-nigtly-pipeline/]
 * XBID E2E Pipeline: [https://scmci1.deutsche-boerse.de/job/Energy/view/Xbid/job/xbid-end-to-end-pipeline/]
 * XBID Sonar: [https://scmci1.deutsche-boerse.de/job/Energy/view/Xbid/job/xbid-pulls-sonar/]

Shipping:
 * Shipping Continuous Pipeline: [https://scmci1.deutsche-boerse.de/job/Energy/view/M7%20Shipping/job/m7-shipping-1-5-continuous/]
 ** covers unit testing, ui tests, e2e tests and sonar analysis
 * Shipping Niightly Build: [https://scmci1.deutsche-boerse.de/job/Energy/view/M7%20Shipping/job/m7-shipping-1-5-nightly/]
 ** covers ui-tests and sonar analysis

Place for Improvement:

Shipping pipelines do almost the same (checkout, build, ui test) with only small differences - create new one containing everything from the nightly and continous build would be nice. 

It would be nice to have XBID Sonar Job accepting SHA1 as a parameter instead of MR reference. ","31/Oct/18 15:54;ei349;For the future:
 * Every JIRA task should be properly labeled with the sprint fix version to help establish release notes. 
 * Every JIRA task should have properly filled affected components to help determine which modules should be released. ","01/Nov/18 09:28;ei349;XBID 1.6.0.1 Released and deployed on syt1. 

Shipping manually deployed on syt1 but release is failing. There is a need to investigate in the next sprint. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Perf Improvements - Customer call 07/11/2018 (14:00 - 15:00),XP-306,73977,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,lt112,qz412,qz412,23/Oct/18 17:37,04/Aug/20 19:15,22/Feb/21 13:26,08/Nov/18 07:30,,,Pre2020,,Trading,,,,,,,,,"*DBAG communication on perf improvements from 5/10:*
 # ** _What parts of the system will be affected by what improvements?_
 ** _To achieve the desired performance improvements extensive re-implementation of order book calculation has been introduced_
 ** _Improvements to the OBK calculation algorithms_
 *** _Optimized utilization of the routing calls_
 *** _Memory management adjusted_
 *** _Optimized calculation steps for higher performance_
 ** _General Core improvements_
 *** _Parallelization_
 *** _Caching_
 *** _Data structures modified_

 # _What needs to be retested?_
 ** _DBAG suggests thorough regression of OBK LV calculation_
 ** _There has been no impact on matching and this area therefore is not necessarily recommended to be included in thorough testing_

*Feedback from customers:* 

An ad-hoc call will be held to clarify (*07/11/2018 14:00 - 15:00*):
 * Which technical and functional changes are being proposed by DBAG, with full understanding of consequences on PXs side
 * What are impacts of these changes to existing functionality and technical solutions
 * What would technical and functional changes mean for testing – what types of testing and how complex the (UAT) testing should be

{color:#00875a}*Guidelines:*{color}
 * Questions will provided on 29th Oct EOB (see table below), please prepare to answer them before the call. Align with [~rg535], [~tz118] + [~qz412],
 * Only discuss high-level of detail - whether those changes (marked blue in the list above) have been on application / db / configuration level and do not expose details of individual changes
 * Study following material which has internal info in it (in case you have not been directly involved): [http://172.19.250.235:8090/confluence/display/TD/Order+book+perfomance+improvements]

----
Questions:
|*_A. What parts of the system will be affected by what improvements?_*|
|*#*|*Author*|*Question*:|
|*A1.*|OMIE (Carlos)|Could DBAG explain a bit the optimization of routing calls?|
|*A2.*|OMIE (Carlos)|Are other elements apart from local order view calculations impacted or benefit with the change, eg. routing flow, routing plans, etc.?|
|*A3.*|OMIE (Carlos)|Can DBAG confirm that event-driven architecture is respected as it is?  Which elements are impacted with the change eg. “Business (Logic) Processor”, “orderbook handler”?|
|*A4.*|OMIE (Carlos)|We are assuming that those changes do not impact on equal treatment, could DBAG confirm that this improvements guarantee that the distribution of OB is not deterministic and respect the current agreements about availability of OB between parties?|
|*A5.*|OMIE (Carlos)|Does those changes require a documentation update?|
|*A6.*|OTE (Vladimír)|Is the purpose of these performance improvements to enable (sufficient) relaxing of the relevant SLA boundaries (#OrdTrans, in peak%, baseload, peak-load, topology, etc.)?|
|*A7.*|OTE (Vladimír)|_Question to ”Improvements to the OBK calculation algorithms / Optimized utilization of the routing calls”:_
 We support OMIEs questions – more details are needed. Does this mean only  internal implementation changes, or routing keys are going to change or messages are to be grouped etc.? Please describe type and principles of the application logic changes.|
|*A8.*|OTE (Vladimír)|_Question to ”General Core improvements / Parallelization”:_
 Could DBAG explain a bit the principle of change – if new parallelization (of what?) is introduced or only different strategy for parallelization of core operations is to be used, in what part of functional scope of the component, what processes are to be affected?|
|*A9.*|OTE (Vladimír)|_Question to ”General Core improvements / Caching”:_
 Similar as for parallelization: Could DBAG explain a bit the principle of change – if new caching (of what?) is introduced or only different strategy for caching of core operations is to be used, in what part of functional scope of the component, what processes are to be affected?|
|*A10.*|OTE (Vladimír)|_Question to ”General Core improvements / Data structures modified”:_
 Does this affects only some internal data structures used during processing or business data database storage (XBID Core DB) is modified (in this case which business data entities)?|
|*A11.*|OTE (Vladimír)|Could DBAG  highlight scope of the impacts through an indicative list of sections expected to change in documentation? For example what chapters of AIP100 Software Architecture are expected to be modified, which functional specification documents are affected?|
|*A12.*|Nord Pool (Timo)|_To achieve the desired performance improvements extensive re-implementation of order book calculation has been introduced_
 Can DBAG explain with architectural examples the planned changes
  |
|*A13.*|Nord Pool (Timo)|Can DBAG provide a view per improvement items about how much each of the items will individually improve the performance?|
|*A14.*|Nord Pool (Timo)|Can DBAG provide the risk level of the each proposed change?|
|*_B. What needs to be retested?_*|
|*#*|*Author*|*Question*:|
|*B1.*|OMIE (Carlos)|Order book calculation is a bit generic, could we assume that the following functionalities should be tested:
 ·          Normal updates of OB eg: manage orders/trades/cancel trades.
 ·          Normal updates of ATC, including auctions.
 ·          Dispute functionality ?|
|*B2.*|OMIE (Carlos)|We assume that the system will we tested in same scenarios with and without the improvements, how will be measured the improvement in each element, eg. performance test scenarios, consume of memory and CPU, etc.?|
|*B3.*|OMIE (Carlos)|Would be tests' results (see B2.) shared with TWG-PTF?|
|*B4.*|OTE (Vladimír)|What typical scenarios/situations will perform better or worse after proposed optimization – what impacts on service boundaries, KPIs and other measures are expected, what is the best proposed approach to measure end evaluate the impacts of improvements?|
|*B5.*|Nord Pool (Timo)|If order book calculation needs to be re-implemented, Memory management adjusted and data structures modified, why DBAG do not see need for re-testing of matching process?|

 ",,lt112,qm925,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/18 17:38;qm925;Joint Call is scheduled on 07/11/2018 14:00 - 15:00

Updated Agenda with questions will be send out to DBAG by 05/11/2018","06/Nov/18 13:51;lt112;Questions with prepared answers: http://172.19.250.235:8090/confluence/pages/viewpage.action?pageId=10468559",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RTS3 Slice B - SIMU Run support,XP-305,73976,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,23/Oct/18 17:11,04/Aug/20 19:16,22/Feb/21 13:26,01/Nov/18 09:27,,,Pre2020,,Trading,,,,,,,,,"[http://172.19.250.235:8090/confluence/display/TD/UAT+II+-+test+plan] --> test plan
 [http://172.19.250.235:8090/confluence/display/TD/RTS+3] --> RTS3

*Goal*:
 * Run RTS3 Slice B tests in SIMU with the customers:
 ** Support smooth execution
 ** Coordinate with TechOps / other units
 ** Review Meeting Minutes if needed
 * Cooperate with the assignee of XP-352--

[~od044], [~tr866], please review confluence links and attached word document which was used during UAT II

Execution will happen from 25 - 31th (working days exclusively) Oct be supported by a call from 13:00 - 16:00 (organized by TWG). ",,qz412,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-352,,,,,,,"24/Oct/18 10:36;tz118;XTG with DBAG MM 20171019 - Morning - R1 3 UAT II - Run 1 - Modified TC2-17 T1 LP1.docx;https://jira.deutsche-boerse.com/secure/attachment/60796/XTG+with+DBAG+MM+20171019+-+Morning+-+R1+3+UAT+II+-+Run+1+-+Modified+TC2-17+T1+LP1.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73612800,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:2",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deliver XBID 1.5 src to Escrow ,XP-304,73954,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,rehapav,rehapav,23/Oct/18 14:17,06/Nov/20 10:14,22/Feb/21 13:26,31/Oct/18 09:57,,,Pre2020,,,,,,,,,,,"maximum in 5 working days after XBID 1.5 is deployed into the PROD on *30th Oct 2018*,
 DBAG is obliged to deliver complete XBID source to Escrow.

Please execute based on deployed version (1.5.x).

SMEs: [~eh941], [~jy268]

The process takes about 4-8 hours depending on source code changes (mainly 3rd party dependencies).

Article how to do that - [http://172.19.250.235:8090/confluence/display/TD/DEPOSIX+-+source+export]

[~eh941]:
 * please describe the process in few short words directly here so we have guidelines for the future.
 * Please consider to what extent XP-201 can be done together with this one + the effort needed. Thx!",,eh941,jy268,qz412,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-201,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72403200,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:3",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/18 09:41;eh941;XP-201 - I already tried to make the source code exporter tool reliable enough to automate the whole process. I improved it a lot but I'm starting to think it isn't possible to do it fully automated at all. What we could do is to automate the delivery itself (we have a folder with the source code which needs to be packed, encrypted and sent to deposix). We might discuss this topic.","30/Oct/18 15:52;jy268;Source code was successfully uploaded to deposix escrow.","06/Nov/18 14:40;jy268;Versions:
comtrader 2.5.1.31
pmiarchiving 1.0.18
reporting engine 5.0.41
shipping 1.0.38
pmilogger 1.0.28
xbid 1.5.8
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make 95% of Tosca Quick SM Show tests green and map them to feature matrix,XP-303,73949,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,qz412,cs131,cs131,23/Oct/18 13:48,04/Aug/20 19:40,22/Feb/21 13:26,31/Jan/19 09:36,,,Pre2020,,,,,,,,,,,"Make 95% of SM Tosca Quick Show tests green (Quick Show - 3hours shorter version). Reason for non-pass needs to be known and understood on all non-green items.
 Quick Show can be then used as a part of sprint increment regression tests.

Acceptance criteria
 * Make Quick Show test green
 * Mark Features that are covered in Tosca - see [http://172.19.250.235:8090/confluence/display/XBID/Feature+Matrix]
 ** Fill *Tosca* column there",,cs131,xu897,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,65059200,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrt:000000z",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 2,Ampere Sprint 6,Ampere Sprint 7,Home Office Team Sprint 10,Home Office Team Sprint 11,Home Office Team Sprint 12 [S],,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/19 09:36;xu897;All subtasks are done, assuming that task is done. Ok [~od044]  ?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Analyze switch from JDK ?n? to Azul,XP-301,73944,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,23/Oct/18 13:07,04/Aug/20 19:41,22/Feb/21 13:26,17/Apr/19 13:31,,,Pre2020,,,,,,,,,,,,,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73699200,,,,,,,,,,,,,,,XP-1715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yrw:ozr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ASR014 - Implement OBK limit relaxation,XP-284,73799,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,de698,de698,18/Oct/18 13:47,04/Aug/20 19:16,22/Feb/21 13:26,31/Oct/18 10:46,,,Pre2020,XB-1.6.0.1,Trading,,,,,,,,,"*Background:* the orderbook limitations are +agreed+ to change as follows:
 * minVolume limit to be removed completely
 * one unified limit to be applied (instead of orderbook.depth.max=31 and effectiveMaxOrderbookDepth=50)

*What needs to be done:*
 * {color:#00875a}review the proposed documentation, confirm it is in a final form and no further +formal+ changes are needed -> proposal is attached{color}
 * {color:#00875a}implement the change to the OBK depth algorithm; below is an extract from the current implementation{color}
{code:java}
private boolean isAllowedDepthReached(int currentOrderBookDepth, int currentTotalExposedQty) \{
        if (currentOrderBookDepth >= effectiveMaxOrderbookDepth) {
            return true;        
}
        if (currentOrderBookDepth < maxOrderBookDepth) \{
            return false;        
}
        if (currentTotalExposedQty < minTotalExposedQty) \{
            return false;        
}
        return true;    
}{code}

*Output* of this task is:
 * affected documents HLS100, DFS510, USM998 are updated and provided for a review to the customers
 * development work on the OBK depth algorithm is done",,de698,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-1214,,,,,,,"18/Oct/18 13:41;de698;USM998_System_Configuration_v44_with OBK relaxation proposal.xlsx;https://jira.deutsche-boerse.com/secure/attachment/60603/USM998_System_Configuration_v44_with+OBK+relaxation+proposal.xlsx","18/Oct/18 13:34;de698;XP-42 ASR014_DFS510 Change of OBK limitation.docx;https://jira.deutsche-boerse.com/secure/attachment/60604/XP-42+ASR014_DFS510+Change+of+OBK+limitation.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74131200,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SM - remove dependency to XBID-Core flyway scripts,XP-231,73483,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,10/Oct/18 15:08,04/Aug/20 19:41,22/Feb/21 13:26,24/Oct/19 12:27,,,Pre2020,,Shipping,,,,,ice,,,,"In order to run refdata synchronization tests SM uses DDLs from XBID-Core to create the underlying DB schema.

With migration to Hibernate 5, those SQLs are no longer produced.

 

Remove the dependency:
{code:java}
<groupId>com.deutscheboerse.energy.xbid</groupId>
<artifactId>xbid-core</artifactId>
<version>${xbid.core.version}</version>
<classifier>flyway-no-triggers</classifier>{code}

and replace it with hand-exported DDLs. Those would need to be updated manually every time the XBID DB schema changes, but it's small price to pay compare to rewriting XBID-Core DatabaseGenerator to Hibernate 5.",,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74736000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07czw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 37,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2418-provide-SM-reports-PSE,XP-1211-confidential-label,acceptance,XP-3161-pom-cleanup-develop,XP-PULL-TEST,develop,XP-3161-develop,XP-TEST,XP-3094-sonar-gate,master-acceptance,master,XP-TEST2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Report generating returns Internal server error in case generating time exceed 1 min.,XP-220,73438,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Trivial,Done,,radeale,radeale,10/Oct/18 10:27,06/Nov/20 12:40,22/Feb/21 13:26,03/Jan/19 15:06,,,Pre2020,,Shipping,,,,,,,,,"Report generating returns Internal server error in a case generating time exceed 1 min.
It happened mainly during generating a report per DA or without a filter on env under load. 
 [^Interna_server_error_report_DA.png] 

{code}
2018-01-29T14:26:41.909Z [nio-8014-exec-3][][] ERROR o.s.b.c.w.ErrorPageFilter - Cannot forward to error page for request [/api/reports/all] as the response has already been committed. As a result, the response may have the wrong status code. If your application is running on WebSphere Application Server you may be able to resolve this problem by setting com.ibm.ws.webcontainer.invokeFlushAfterService to false
org.apache.catalina.connector.ClientAbortException: java.io.IOException: Broken pipe
        at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:393)
        at org.apache.tomcat.util.buf.ByteChunk.append(ByteChunk.java:344)
        at org.apache.catalina.connector.OutputBuffer.writeBytes(OutputBuffer.java:418)
        at org.apache.catalina.connector.OutputBuffer.write(OutputBuffer.java:406)
        at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:97)
        at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:90)
        at org.springframework.util.StreamUtils.copy(StreamUtils.java:92)
        at org.springframework.http.converter.ByteArrayHttpMessageConverter.writeInternal(ByteArrayHttpMessageConverter.java:65)
        at org.springframework.http.converter.ByteArrayHttpMessageConverter.writeInternal(ByteArrayHttpMessageConverter.java:37)
        at org.springframework.http.converter.AbstractHttpMessageConverter.write(AbstractHttpMessageConverter.java:195)
        at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:238)
        at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:183)
        at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:80)
        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:126)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:817)
        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:731)
        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:968)
        at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:859)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)
        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:844)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:237)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at com.deutscheboerse.m7.shipping.web.X509CustomFilter.doFilter(X509CustomFilter.java:44)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
Caused by: java.io.IOException: Broken pipe
        at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
        at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:124)
        at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101)
        at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:172)
        at org.apache.coyote.ajp.AjpNioProcessor.output(AjpNioProcessor.java:140)
{code}

Reproduction 
1. Login SPM as Central Admin user on env under load
2. Try to download report without any filter or filter per DA with maximum time range
",,radeale,,,,,,,,,,,,,,,,,,,,,,,XDEV-4387,,,,,,,,,,,,,,,,,,,"10/Oct/18 10:27;radeale;Interna_server_error_report_DA.png;https://jira.deutsche-boerse.com/secure/attachment/60289/Interna_server_error_report_DA.png","10/Oct/18 10:27;radeale;Screenshot from 2018-04-24 15-03-52.png;https://jira.deutsche-boerse.com/secure/attachment/60290/Screenshot+from+2018-04-24+15-03-52.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67392000,,,,,,,,,,,,,,,XP-3109,,Limited number of trades in the report to 50 (configurable).,,,,,,,,,,,,29/Jan/18 16:32,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:rzx",9223372036854775807,,,,,,,,,,,Number of trades in the report set caused that generation took significant time and the Apache timed out before it was finished.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,ReportIntegrationTest,Try to generate report with more than 50 trades and see that error is shown.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/19 15:06;radeale;Fixed in TECHLOG-368.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Configuration changes on running system,XP-209,68959,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,wg141,wg141,04/Jun/18 15:04,06/Nov/20 11:34,22/Feb/21 13:26,03/Jan/19 14:00,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,"(for details see the linked ticket)

Currently it is not possible to change configuration on a running system. There are some configuraiton items which might help solve issues for one specific customer, but now require a downtime for the whole system, e.g. changing of a primary mailserver. 

Maybe it would be possible to have some configuration in a file/database and reload it with a running system?",,wg141,xu897,,,,,,,,,,,,,,,,,,,,,,SERVICE-1271,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.1263731258E10,,Report a Critical Incident,,,,,,67392000,,,,,,,,,,,,,,,XP-844,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y06oe8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jan/19 14:00;xu897;Obsolete, solved in related service ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Info endpoint for SPM,XP-205,69051,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,zh552,zh552,06/Jun/18 12:58,04/Aug/20 19:41,22/Feb/21 13:26,03/May/19 15:59,,,Pre2020,,Shipping,,,,,,,,,"It should contain information about app version, preferably in the same format as xbid(plain json:\{""build"":\{""version"":""1.4.15-SNAPSHOT""}})",,jy268,qo794,zh552,,,,,,,,";18/Jun/18 08:52;qo794;7200",,,0,7200,,,0,7200,,XDEV-5075,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,57283200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yd4:zz8",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 25 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"15/Jun/18 16:52;qo794;SM uses spring boot version 1.3.3.RELEASE that does not contain info endpoint feature, it's available since version 1.4.","18/Jun/18 08:52;qo794;Upgrading to version 1.4 is not straightforward, we'll not implement any other solution. Waiting for the upgrade - XDEV-4608","30/Apr/19 15:41;jy268;Currently SPM uses spring boot 2.1.1, we can work on this ticket now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
change templates for SLA reports to XLSX,XP-169,73254,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,uv683,05/Oct/18 13:21,31/Aug/20 15:39,22/Feb/21 13:26,04/Jan/19 07:58,,,Pre2020,,SLA Report Tool,,,,,,,,,"At the moment sustainable load sheet in SLA report contains almost hundred thousands lines of data. Report Tool will fail with exception when generating the sheet either because of heap space or because of the fact that there can be only 65k rows in one sheet in XLS format.

Change the template to XLSX which do not have any such limitation and increase the heap space for application.",,ca143,iO924,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74390400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07czs:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Oct/18 17:03;iO924;Please create a Techlog and assign it to Steffen Englert. 

 

Best Regards

Michael","15/Oct/18 12:54;ca143;Merged:
https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/122

*Fix version:  1.31*",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gherkin test for ""Message of user is not authenticated without previus logout""",XP-149,70606,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,cf948,qo794,qo794,30/Jul/18 08:46,06/Nov/20 11:34,22/Feb/21 13:26,31/Oct/18 09:31,,,Pre2020,,Capacity,Trading,,,,,,,,Implement end-to-end test for https://jira.deutsche-boerse.com/browse/XDEV-4984,,qo794,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74822400,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y06xyg:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-456,XP-2979-postgresql,XP-3264,XP-3230,develop,XP-2232,XP-2694,XP-1241-new-failover-docker,XP-4273-owasp-zap-enable,XP-3070,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"10/Oct/18 12:11;qo794;Implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Performance improvements - High level description of Post 2.0 big changes (Async Persister, Binary API)",XP-144,73206,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,nn481,cf948,cf948,04/Oct/18 15:12,04/Aug/20 19:15,22/Feb/21 13:26,31/Oct/18 09:58,,,Pre2020,,Trading,,,,,,,,,"The topic needs to be prepared in a high level concept state for the communication of improvements once RTS3 SB + ASR014 at the end of Oct 2018.
 * What is the substance of the change
 * What are the benefits
 * What are the affected areas (including changes needed on the side of the customers)",,cf948,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73353600,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000ytp:29",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Oct/18 15:05;qz412;I have moved https://jira.deutsche-boerse.com/browse/XP-146 out as it is a solution implementation question irrelevant for the high level description

[~nn481] - please check, thx.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove dependency on real RabbitMQ server in integration tests,XP-139,71792,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,mp667,mp667,31/Aug/18 17:34,04/Aug/20 19:53,22/Feb/21 13:26,01/Apr/20 10:56,,,3.1.0,,RabbitMQ,,,,,ice,,,,"List of dependent tests:
 * com.deutscheboerse.energy.m7.amqp.TmRabbitmqAdminCtxTest
 * com.deutscheboerse.energy.m7.amqp.CmmRabbitmqAdminIntegrationTest
 * com.deutscheboerse.energy.cmm.amqp.AmqpCmiInTest
 * com.deutscheboerse.energy.cmm.amqp.AmqpCmiOutTest
 * com.deutscheboerse.energy.cmm.service.impl.PublishServiceImplCtxTest
 * com.deutscheboerse.energy.cmm.service.M7CoreConnectorAmqpTest
 * com.deutscheboerse.energy.cmminteg.failover.CmiLifecycleFailoverHandlerIntegTest",,mp667,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77760000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0ai2w:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 5 (S),,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2942-losses-perf,xbid-losses-poc,develop,master-xbid-losses-poc,XP-139-xbid-3,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"05/Sep/18 15:23;uv683;Changes done in this Jira caused that xbid core failed to load. Test were Ignored at the moment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate SM to Spring Boot 2 (prerequisite for SM changes),XP-137,73185,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,jy268,jy268,jy268,04/Oct/18 10:56,27/Aug/20 13:41,22/Feb/21 13:26,05/Nov/18 16:44,,,Pre2020,,Shipping,,,,,,,,,"* Migrate SM to Spring Boot 2
 * *Suggestion:* Regression test to be covered by SM feature changes for R2.0",,jy268,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-205,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"migration to spring-boot 2.0 done, all tests are green.",,,,,,,,,,,,,,73440000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu1:i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 1,Ampere Sprint 2,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"25/Oct/18 16:01;ll664;Unfortunately,  looked like review only task, but couple of tests are still failing randomly on jenkins.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate XBID to Hibernate 5,XP-131,72981,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,27/Sep/18 15:47,06/Nov/20 11:34,22/Feb/21 13:26,08/Oct/18 13:27,,,Pre2020,,,,,,,,,,,,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75859200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07bc0:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate XBID to Spring 5,XP-130,73102,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ll664,ll664,ll664,02/Oct/18 17:29,06/Nov/20 11:34,22/Feb/21 13:26,24/Oct/18 14:18,,,Pre2020,,Capacity,Shipping,Trading,,,,,,,,,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75427200,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07c2o:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KPI report - delete id_batch from SQL queries,XP-118,69683,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,uv683,uv683,uv683,26/Jun/18 10:54,04/Aug/20 19:40,22/Feb/21 13:26,21/May/19 10:45,,,Pre2020,,SLA Report Tool,,,,,,,,,"When KPI report is generated id_batch is used to filter SQL queries. It is historical feature which was never used. When KPI collect job is started and pulls logs from elastic, these logs obtain id_batch in raw tables. id_batch should group all the logs that were obtained in one DB transaction. This id_batch is further used to generate percentiles from raw tables. However it is not working for daily percentiles. Daily percentile is calculated at 1:05 AM. Batch of logs that is downloaded at that time contains logs from 00:00 to 01:00 and thus no logs for previous day are found. Daily pecentiles containes only zeros.

Please, delete id_batch from all relevant places.

Current workaround will involve chaning the kpi collect job's cron on xbprodsla2. Job will be started in cron mode at 0:35 (in order not to overload DB, because jobs on xbprodsla1 runs at 0:05) only once a day. It will download all the data for the previous day in one batch, generate 24 hourly percentiles and one daily percentile.",,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XDEV-5117,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,83980800,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,26/Jun/18 10:29,,,,,,,,,,,,,,,,,,,,,,,"1|y08oie:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Team Sprint 25,Alpha Team 26 [S],,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-118-removed-connection-details,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Trade Information,XP-105,72864,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,rg535,rg535,rg535,25/Sep/18 14:48,06/Nov/20 12:33,22/Feb/21 13:26,25/Sep/18 17:34,,,Pre2020,,,,,,,,,,,"Hi Frantisek,
For the EU XBID Event the PXs need the following data. Can you give it to me today or tomorrow morning? I cannot figure out how to get it out of Grafana.

Avg trades in Sept, total no. of trades from go-live and highest no. of trades in a single day. Thanks, Suzanna",,ca143,rg535,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76032000,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y07amw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/18 15:08;ca143;Avg count of trades per day in September (till ""2018-09-25 00:00:00.0"" UTC): 34400
Total number of trades (till ""2018-09-25 00:00:00.0"" UTC): 3268411
Highest number of trades: ""2018-09-21"": 49551","25/Sep/18 17:34;rg535;Perfect. Thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Volume Data,XP-101,72726,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ca143,rg535,rg535,21/Sep/18 08:34,06/Nov/20 12:33,22/Feb/21 13:26,25/Sep/18 09:56,,,Pre2020,,,,,,,,,,,"{color:#000000}Dear all,{color}

{color:#000000} {color}

{color:#000000}As stated in the RCB this week, the NEMOs are in need of the traded volumes for each month since BGL including September (to date). Please could you provide a rough estimate of the effort required to do a one-time extract.  The data is needed for the Commission. I need the information this morning.{color}

{color:#000000} {color}

{color:#000000}Side note: I am aware that we do not have this in our normal tool set. At this point in time they do not want us to include it in the standard reporting but just want a one-time extract. We will take up talks about including it in the normal reporting.{color}

{color:#000000} {color}

{color:#000000}Thanks,{color}

{color:#000000} {color}

{color:#000000}Suzanna{color}",,ca143,lt112,rg535,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Sep/18 15:20;ca143;XP-101_EXTERNAL_XBID-trade-quantities.xlsx;https://jira.deutsche-boerse.com/secure/attachment/59690/XP-101_EXTERNAL_XBID-trade-quantities.xlsx","24/Sep/18 15:20;ca143;XP-101_INTERNAL_XBID-trade-quantities.xlsx;https://jira.deutsche-boerse.com/secure/attachment/59691/XP-101_INTERNAL_XBID-trade-quantities.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76118400,,,,,,,,,,,,,,,XP-2648,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y079t4:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Sep/18 11:07;ca143;Hi [~rg535],
there is estimation below. Testing is not included.

*Expected output*
{noformat}
Month | Total traded quantity [MW]
-----------------------------------------------------------
June | x MW
July | x MW
August | x MW
September | xMW
{noformat}

*Estimate:*
* Total 3 days
** 1 day: query preparation
** 1 day: restoring data and query execution
** 1 day: Reserve

*Internal info for DEV:*
* For Hourly contracts (including block), we can use query
{noformat}
select sum(delivery_quantity) from cx_111_trade_history t where t.revtype = 0 and delivery_quantity > 0 and t.last_update_time >= '2018-08-01 00:00:00.000' and t.last_update_time < '2018-08-31 00:00:00.000';
{noformat}
* For 15m/30m we have to count delivery quantity manually (extra sql) due to bug - XP-78.
","21/Sep/18 11:41;rg535;Thank you for the quick response. I have communicated the effort to the PXs. We will wait for their response.","21/Sep/18 12:18;rg535;[~ca143] tThe NEMOs agree with the proposal as long as the figures are provided not later than by 25/09 EoD. Please confirm if this is possible, if so please procced with generating the data.

Please note that they would like to provide *MWh*.","21/Sep/18 14:59;ca143;I will check with others on Monday. I think there is a risk that we will spent some time with the tasks and won't be able to deliver solution on time.","21/Sep/18 15:10;rg535;thank you, [~ca143]. I have informed the customers. Let me know Monday, regarding if you can be finished by 25.09..","21/Sep/18 15:23;ca143;Hi [~lt112],
I think the queries below should be valid. Please, could you check them?

{code}
--All hourly contracts, blocks included (using delivery_quantity)
SELECT sum(delivery_quantity)
FROM cx_111_trade_history t
JOIN cx_211_contract_history c ON t.contract_id = c.contract_id
WHERE 
 t.revtype = 0 
 AND c.revtype = 0
 AND t.action = 'UADD'
 AND c.product_long_name = 'XBID_Hour_Power'
 AND t.last_update_time >= '2018-08-01 00:00:00.000' 
 AND t.last_update_time < '2018-08-31 00:00:00.000';

--All 15m product (using match_quantity)
SELECT sum(t.match_quantity * 0.25)
FROM cx_111_trade_history t
JOIN cx_211_contract_history c ON t.contract_id = c.contract_id
WHERE 
 t.revtype = 0 
 AND c.revtype = 0
 AND t.action = 'UADD'
 AND c.product_long_name = 'XBID_Quarter_Hour_Power'
 AND t.last_update_time >= '2018-08-01 00:00:00.000' 
 AND t.last_update_time < '2018-08-31 00:00:00.000';

--All 30m product (using match_quantity)
SELECT sum(t.match_quantity * 0.5)
FROM cx_111_trade_history t
JOIN cx_211_contract_history c ON t.contract_id = c.contract_id
WHERE 
 t.revtype = 0 
 AND c.revtype = 0
 AND t.action = 'UADD'
 AND c.product_long_name = 'XBID_Half_Hour_Power'
 AND t.last_update_time >= '2018-08-01 00:00:00.000' 
 AND t.last_update_time < '2018-08-31 00:00:00.000'; 
{code}","24/Sep/18 10:00;lt112;[~ca143] Checked and tested, the queries seem to be correct.","24/Sep/18 10:02;rg535;Hi,
 do you think you can be finished by EOD tomorrow? (Tuesday)?","24/Sep/18 15:24;ca143;Hi [~rg535],
the reports are done (see attachment). There are 2 versions - ""external"" and ""internal"". The internal one contains quantities per product & and database queries.

I don't know what should be the next step - distribute to customer or ask someone for testing (which means to do the same work as I did: download DB dumps, load them, run queries and compare results).","24/Sep/18 15:43;rg535;I do not think we need to test it. You had 4 eyes on it, if I understand correctly. Thanks a lot.","24/Sep/18 16:30;rg535;I have sent the external view to the customers. Thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,
CMM TSO Admin GUI Test convert existing test to cucumber test ,XP-88,72562,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ei349,hj444,hj444,18/Sep/18 13:44,04/Aug/20 19:40,22/Feb/21 13:26,05/Dec/18 15:57,,,Pre2020,,Capacity,,,,,,,,,"we need to take below test and convert it to a cucumber test where it will utilize UI.
{code:java}
 @Test
    public void checkTsoAdminPage() {
        runAs(UserLogin.CMM_TSO_ADMIN,
                app -> administrationTabs(app).selectFirst(),
                app -> administrationTabs(app).selectContractModification(),
                app -> administrationTabs(app).selectContractHalt(),
                app -> administrationTabs(app).selectDirectionHalt(),
                app -> administrationTabs(app).selectServiceHalt(),
                app -> administrationTabs(app).selectUpload(),
                app -> administrationTabs(app).selectDownload(),

                app -> menu(app)
                        .preferences()
                        .allocationOnBehalf()
                        .verifyContentAvailability(),

                app -> menu(app)
                        .interconnector()
                        .beDe()
                        .verifyContentAvailability(),

                app -> menu(app)
                        .interconnector()
                        .beFr()
                        .verifyContentAvailability(),

                app -> menu(app)
                        .reports()
                        .download()
                        .cancel(),

                app -> menu(app)
                        .help()
                        .about()
                        .close(),

                app -> logout(app)
        );
    }
{code}
 

 *AC:*
 above scenario in cucumber scenario 
 e.g
 *given* user login to CMM
 *when* user click on administration tab
 *then* administration tab page is displayed

and *test passed locally and on jenkins*.


 

 ",,hj444,,,,,,,,,,,,,,,,,,,,XP-641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,71107200,,,,,,,,,,,,,,,XP-60,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yu5:xhhy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 5 (PS),Home Office Team Sprint 6,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,plewmic-scripts,XP-1261-guava-28,selenide-poc,XP-1504,xbid-losses-poc,XP-2979-postgresql,XP-456,XP-3264,XP-3230,develop,XP-2694,XP-2232,XP-1241-new-failover-docker,XP-3070,XP-4273-owasp-zap-enable,inline-tomcat-params,XP-528-feature-file-testcases,XP-4526-resource-managment-fix,xbid-2.0.25.x,fixing-failover,XP-2080-finishing-price-rounding-integration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Nov/18 09:27;hj444;code is taken from 
xbid-test/selenium tests /integration tests
CmmSmokeTest.java - TSO Admin, Explicit Participant, Ref data Admin, Super Admin gui checks and basic workarounds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix problems during applying LDIF files for PERF testing,XP-85,72474,Bug,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,ca143,ca143,17/Sep/18 10:23,06/Nov/20 12:40,22/Feb/21 13:26,26/Nov/18 10:42,,,Pre2020,,,,,,,,,,,"There were some issues with importing LDIF files (attached in SERVICE-1707) for XBID Performance testing:

Info for DEV team from TECHOPS is that the LDIFs are not valid and some manual steps are required.

{code}
alexander [09:48]
with provided ldif files it's not possible to do a successfully import.


frantisek.hradil [09:48]
we provided same files as for last 3 performance testing
so, are you able to create some users manually?
if so, we will provide a list

alexander [09:50]
the errors are: #!ERROR [LDAP: error code 19 - password in history]
i'm not sure if there is possibility to clear the password history within the script (ldif file) (edited)

manh.duc [09:51]
ok, then could please maually  create these users in LDAP
```CMM: XBAPI099

SOB: XBDBX001```
the same password as SADMIN01 from the confluence

alexander [09:54]
both users are there. i have to delete the password history and set the password. give me 1min
@manh.duc done for both users

manh.duc [09:59]
it doesn't work
I got
```ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN.```
with a password xbidTest01!

alexander [10:01]
yes
users are not locked and the password is correct.

manh.duc [10:02]
and the password is using which hash method ?
because sometime it default set plain text instead of SHA and it doesn't work then

alexander [10:04]
SSHA-256 hashed password

niklas.albers [10:07]
@alexander delete the old tree
then it is possible to import the files I attached to the ticket

alexander [10:08]
in the tree we have more users as in the file.

niklas.albers [10:09]
@frantisek.hradil your files never work instantly. I have to perform several manual steps before they can be imported

alexander [10:09]
if i should delete complete tree, pls put this into the ticket.

frantisek.hradil [10:17]
@niklas.albers ok, so let's discuss it after this test. I will create a ticket for you and will ask you for a valid example.
I'm aware only a manual step related with adding a policy for admin users

alexander [10:18]
deleted old trees and imported the ldifs from ticket without any errors
{code}
 ",,ca143,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/18 07:53;yo218;perf.v1.3.16.shipping.ldif;https://jira.deutsche-boerse.com/secure/attachment/59413/perf.v1.3.16.shipping.ldif","18/Sep/18 07:53;yo218;perf.v1.3.16.trading.ldif;https://jira.deutsche-boerse.com/secure/attachment/59414/perf.v1.3.16.trading.ldif",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76464000,,,,,,,,,,,,,,,XP-3109,,,,,,,,,,,,,,17/Sep/18 10:23,,,,,,,,,,,,,,,,,,,,,,,"1|y078ag:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"17/Sep/18 10:24;ca143;Hi [~yo218],
please, could you provide some details what is wrong in the LDIF files? Could you provide a valid example which is expected? Thank you.","18/Sep/18 07:59;yo218;Examples are attached. Following parts are missing and need to be altered manually:
 * PasswordPolicy for exchange users is missing
 * default passwords should respect the password policy (xbidTest01!)
 * HEALTH_CHECKER user is required for AlarmTilt (in both trees)","20/Sep/18 10:52;ca143;Ready for review/merge:
https://github.deutsche-boerse.de/dev/m7.m7-dataset/pull/91","20/Sep/18 13:59;ca143;Hi [~yo218],
there are updated LDIFs. If you want, you can take a looks and provide feedback:
* https://github.deutsche-boerse.de/dev/m7.m7-dataset/blob/develop/src/main/ldifs/perf.v1.3.16.shipping.ldif
* https://github.deutsche-boerse.de/dev/m7.m7-dataset/blob/develop/src/main/ldifs/perf.v1.3.16.trading.ldif

Hi [~od044],
there are updated LDIFs which should be used during RTS3 Slice B:
* https://github.deutsche-boerse.de/dev/m7.m7-dataset/blob/develop/src/main/ldifs/rts3b.shipping.ldiff
* https://github.deutsche-boerse.de/dev/m7.m7-dataset/blob/develop/src/main/ldifs/rts3b.trading.ldiff
Be aware, that passwords were change to ""xbidTest01!"".
Please, ask TechOps for uploading the files to PERF LDAP. Before execution on SIMU, the files have to be upload also to SIMU LDAP.","21/Sep/18 09:14;yo218;I can confirm that it looks good now",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SMC should not load all Sync Packages from DB on startup,XP-74,71905,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,jy268,ll664,ll664,04/Sep/18 15:46,06/Nov/20 11:34,22/Feb/21 13:26,25/Mar/19 15:09,,,Pre2020,,Shipping,,,,,,,,,"In case the SM is stopped for couple of days (i.e. the weekend-long LIPA/CUTE maintenance), subsequent startup triggers file generation from the last known SPs. This is very time and resource consuming.

 

In order to fix it/make it faster, we need to:
 * stop loading all Sync Packages from DB into memory, but rather limit them to yesterday's midnight
 * stop replaying old events that trigger file generation (older than yesterday's midnight)

 

This behavior needs to be configurable and *disabled* in PROD/SIMU.

 ",,jy268,ll664,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,60825600,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y08bd3:w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team 19 [S],Home Office Team 20,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-2501-to-xbid-dev-env,tomcat-rollback,traversal-XP-2485,XP-2942,XP-2506-xbid-dev-env,trailing-slash-syt1,XP-3025-catalina-timezone,XP-2484,XP-3110-deprecated-log,XP-2488-xbid-dev-env,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"21/Mar/19 12:18;jy268;new parameter
{code}
spm.packages.old.skip=true
{code}
to skip old sync packages generation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Store ordrers & trades statistics into InfluxDB and show them in Grafana,XP-73,70967,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,ca143,ca143,ca143,10/Aug/18 13:14,06/Nov/20 11:34,22/Feb/21 13:26,31/Oct/18 09:39,,,Pre2020,,Other,,,,,,,,,"Target:
Show orders & trades statistics and keep history:
* #orders per PX
* #orders per DA
* etc.

Idea:
* load grouped data from XBID CORE PROD COPY DB and store them into Influx
* create grafana dashboard and visualize the data
* (checked with techops and it is fine - we can use influxdb)",,ca143,qo794,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-1025,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73008000,,,,,,,,,,,,,,,XP-844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y06zpc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/18 10:14;ca143;Initial commit ready for review. Once it is done I will continue with adding some other metrics (average quantities & prices).
https://github.deutsche-boerse.de/dev/xbid-statistics/pull/1","03/Oct/18 15:37;ca143;Implemented measurement for trade quantity:
https://github.deutsche-boerse.de/dev/xbid-statistics/pull/2","31/Oct/18 09:39;ca143;Initial version is ready. Right now we are waiting for new VM.
Once we have it, we need to
* add release plugin
* prepare jenkins job for release
* prepare jenkins job for deployment

FYI: [~qz412]","31/Oct/18 09:55;qz412;Added to Ampere Sprint 1 for transparency reasons. Thx.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Insecure SFTP file upload,XP-71,59064,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,yo218,rehapav,rehapav,25/Jul/17 15:07,04/Aug/20 19:19,22/Feb/21 13:26,21/Nov/19 16:21,,,Pre2020,,Capacity,Shipping,,,,waiting-techops,,,,"The SFTP server of the XBID application allows users to upload documents into the application. We noticed that the upload function does not check the extension and content of the files, allowing users to upload unwanted and potentially insecure files such as scripts or executables. Furthermore, we noticed that it is possible to upload malware. This indicates the lack of anti-virus software on the underlying system of the SFTP server.

The following screenshots show the upload and download of various and potentially dangerous files to and from the SFTP server:




An attacker can upload malicious files such as malware, which could get further spread within the SFTP server’s supporting infrastructure or infect DBG hosts when opened by other users. This could eventually lead to the compromise of systems resulting in confidentiality, integrity and availability issues.


Priority LOW, not for XBID 1.2",,ei349,qz412,radeale,rehapav,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39571200,,,,,,,,,,,,,,,XP-67,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y09vng:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Home Office Team Sprint 39 [S],,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Apr/18 09:15;yo218;[~radeale], please check whether it would be possible to validate documents for extension and content for sFTP as communication channel for CMM and SM. Are the expected files always in the same format? Do they have always the same (or a set of) extension(s)?","12/Apr/18 10:59;radeale;Dear Niklas,

in DFS800 it is stated:

{code}The name of the uploaded file is assigned by the TSO or DI and not validated by CMM.{code}

I've checked and the implementation adheres to the specification.

So I guess an antivirus checking would be useful, but I guess that would require additional testing for possible false positives?

Regards Alexandr","15/Nov/18 15:53;radeale;We should discuss with [~qz412] whether to introduce XML inbound file validation (extension, extension adheres to the file type).","15/Nov/18 16:17;qz412;Dear all,

this should be fully covered by the anti-virus being installed first to CUTEs and then to SIMU & PROD. Please stay tuned on TECHLOG-574.","15/Nov/18 18:07;radeale;Well, I checked the CMI inbound files in the PROD anyway, just to have an overview and all files in the stored period are *.xml with one exception of one being *.XML. So just in case such validation can be also introduced.

SQL queries used (if needed again):

{code}select * from tbxi700_file_header where file_name not like '%xml';

select * from tbxi700_file_header_history where file_name not like '%xml';{code}","15/Nov/18 18:08;radeale;Waiting for the outcome of TECHLOG-574.","02/Jan/19 14:09;rehapav;According to TECHLOG-574 the fix was deployed everywhere (CuTes/SIMU) but not yet on PROD.
[~qz412] I suggest to deploy the fix for PROD together with 1.5.9 

[~radeale] does info above unblock you with next steps with this ticket?","02/Jan/19 16:57;radeale;Deployment of an antivirus protection solves this security issue.","15/Jan/19 11:52;qz412;Will be deployed to PROD with R1.5.9, see SERVICE-2362 + TECHLOG-574","13/Feb/19 13:09;qz412;Was not deployed with R1.5.9 due to issues experienced after the implementation of clamav in CuTe environments. Will be deployed with R2.0.","21/Nov/19 15:03;ei349;[~yo218] can you please have a look on that and confirm the fix? ","21/Nov/19 16:21;yo218;confirmed:
{noformat}
[root@xbprodcom1 ~]# systemctl status clamd@scan.service
? clamd@scan.service - Generic clamav scanner daemon
   Loaded: loaded (/usr/lib/systemd/system/clamd@scan.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2019-10-30 08:57:49 CET; 3 weeks 1 days ago
  Process: 1054 ExecStart=/usr/sbin/clamd -c /etc/clamd.d/%i.conf (code=exited, status=0/SUCCESS)
 Main PID: 12030 (clamd)
   CGroup: /system.slice/system-clamd.slice/clamd@scan.service
           +-12030 /usr/sbin/clamd -c /etc/clamd.d/scan.confNov 21 14:00:41 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 14:15:41 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 14:26:47 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 14:37:36 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 14:49:11 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 15:00:13 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 15:15:11 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 15:32:50 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 15:45:17 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
Nov 21 16:00:15 xbprodcom1 clamd[12030]: SelfCheck: Database status OK.
{noformat}
We can't exclude any file extensions as the customer didn't define which files they are uploading and nothing is specified in the contracts. Antivirus has been implemented, therefor we consider this risk as mitigated ",,,,,,,,,,,,,,,,,,,,,,,,,,
Should CMM ReferenceDataAdmin be allowed to create SuperAdmin?,XP-70,57961,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Fixed,radeale,yo218,yo218,22/Jun/17 16:45,04/Aug/20 19:19,22/Feb/21 13:26,26/Nov/19 12:27,,,Pre2020,,Capacity,,,,,,,,,In -CMM- *SOB* a user with the role ReferenceDataAdmin is able to create a new user with the role SuperAdmin and could therefore potentially grant himself more permissions then he should have. Please check whether this is fine or whether this has to be prevented,,ei349,ne232,qz412,radeale,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,27043200,,,,,,,,,,,,,,,XP-67,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000y5p:4000002",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/17 11:03;qz412;Dear Niklas,

The user with Reference Data Right is already an extremely protected user whose every action must be cross-aligned among all TSOs and PXs (as it leads to changes in the grid).

Current behaviour is not in contradiction to the specification and therefore cannot be changed. I suggest we keep this item as nice to have for future release.

Cheers,

Ondra","07/Jul/17 15:23;yo218;Dear Ondra,

your point is understood but as Deloitte were quite pushing this topic to evaluate the risk, I checked the MFG130 and found the following

 
|Admin|A Central Admin has access to administration features, to create and modify users and to process ""Trade Recalls"" and ""Trade Cancellations"".|*Reference Data* |*User can access the Reference Data GUI.*|
|*Superadmin*|*User can view/create/modify other Admin Users in the Reference Data.*|
|Capacity Info |User can view available capacity information.|
|Public API|User can access the XBID Public Message Interface|
|Trade Recall and Trade Cancellation|User can process Trade Recall requests and perform Trade Cancellations|

I know that MFG are not the specifications, but still I want to double check with you whether this would be a reason to increase the priority of this feature. What do you think?

Regards,

Niklas","10/Jul/17 11:27;radeale;Proposed solution:
- Reference Data Admin cannot assign or de-assign himself/herself Super Admin user role
- Only user with both Reference Data Admin and Super Admin user role can create a Super Admin user role
- When a user with Reference Data Admin user role and *without* Super Admin user role is unable to assign the Super Admin user role to a user","09/Mar/18 09:54;yo218;[~qz412], is this going to be implemented? It is still on the GIS requirements list","12/Mar/18 18:23;qz412;Hi Niklas, depending on what consequence keeping it on that list has. I do not feel comfortable by touching the application at this stage at all for such a thing.","13/Mar/18 08:07;yo218;Hi [~qz412], there is no need to have it ready until BGL. Due date set by GIS is 01/Oct/2018. So please consider this to be included in a future release.","16/Nov/18 14:02;radeale;Situation confirmed, a user with RefDataAdmin role can even directly add the Super Admin role to himself/herself.

Functional solution is possible:
- add validation that only a user with the Super Admin role can create an Admin with a Super Admin role
- at least one Super Admin user has to exist in the system, i.e. the last one cannot be deleted
- a user cannot de-assign/assign the Super Admin role from/to himself/herself

However JAO has operational procedures in place to contain such misuse of the system.

Let's wait for the results of the ongoing PenTests and than tackle the issue.","23/Nov/18 10:41;qz412;I have flipped the status to Refined (as the ticket sits in backlog and findings will come only 10 days after the PEN tests are concluded)","21/Nov/19 15:07;ei349;[~radeale] can you please have a look into specs and check if this can fixed in the development without involvement of customers? If customers are needed can you please open the external ticket and ask them ? ","26/Nov/19 12:26;radeale;The situation is no longer present in XBID R3.0.11.
- An admin user cannot edit its own roles
- A RefDataAdmin without the SuperAdmin right cannot create other admin users
(I'm not sure which ticket corrected it)

The ticket can be closed.","14/Apr/20 16:35;ne232;[~radeale], [~ei349]: Do I understand it correct? Currently it is still in possible in production, but the behaviour will change with rel 3.0 also in production.

Thanks Jutta",,,,,,,,,,,,,,,,,,,,,,,,,,,
Sensitive user data in memory of ComTrader,XP-69,59052,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,rehapav,rehapav,25/Jul/17 13:04,04/Aug/20 19:19,22/Feb/21 13:26,16/Apr/20 08:04,,,Pre2020,,ComTrader,,,,,,,,,"We noticed that the rich client stores sensitive user data in clear text in the memory. The following data was identified in the memory after the user has already logged out (the application was still running):

- Username;
- User password.




An attacker could abuse this issue to obtain sensitive user information, which could be used to compromise an account and perform actions on other user’s behalf, e.g. trading activities or execution of administrative tasks. Depending on the used module/application, the username and the password might be the only authentication factor for accessing arbitrary accounts; at the time of testing, this applies for the CMM and CMI module (see finding XBID-PT-5: No two-factor authentication for Internet-facing web application modules) as well as for the rich client (see finding XBID-PT-1: Hard-coded certificates and passwords).",,eg288,ek176,hj444,radeale,rehapav,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/20 12:15;hj444;2020-04-17_10-55-00-410_comtrader_logfile.0.log;https://jira.deutsche-boerse.com/secure/attachment/82749/2020-04-17_10-55-00-410_comtrader_logfile.0.log","17/Apr/20 12:15;hj444;2020-04-17_11-48-30-916_comtrader_logfile.0.log;https://jira.deutsche-boerse.com/secure/attachment/82750/2020-04-17_11-48-30-916_comtrader_logfile.0.log","17/Apr/20 12:13;hj444;CTRemoteProfileError.png;https://jira.deutsche-boerse.com/secure/attachment/82747/CTRemoteProfileError.png","17/Apr/20 12:13;hj444;CTRemoteProfileError_details.png;https://jira.deutsche-boerse.com/secure/attachment/82748/CTRemoteProfileError_details.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,26870400,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y0amac:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Alpha Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,comtrader-2.5.x,XP-69,master-comtrader-2.5.x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"11/Apr/18 16:23;rehapav;Hi Niklas,

 I didn’t plan for https://jira.deutsche-boerse.com/browse/FXTC-5204

to be fixed prior to BGL.

 

My assumption was that with certificate support enabled original

[https://vmt.deutsche-boerse.de/browse/PT-797]

medium priority is obsolete and we lower it to low – after BGL.

 

I honestly would prefer to do it later and not touch code now.","20/Nov/18 14:59;eg288;My feeling is that password in memory cannot be fully solved. The only advice is to run on trustworthy computer. Once a computer is compromised there are many ways how to steal credentials including memory dumps. Due to nature of java memory model it is never fully under control where this string is copied and at some point it needs to be plain text to use. I suggest to close it as too much effort with low benefit.

Interesting reading here:
https://security.stackexchange.com/questions/29019/are-passwords-stored-in-memory-safe?rq=1","20/Nov/18 15:40;radeale;Trustworthy computer:
- Physically secure (no public machine)
- Software security
- Network security
...","22/Nov/19 13:22;ek176;1) The password should be stored in char[], not String. As we are able to modify the content of char[].

2a) If the password is not further needed, it should be cleared from the memory.

2b) If the password is reused (i.e.: reconnect/reauth), it should be encrypted in memory by a random key. Yes, it is still in memory, but not clearly readable.

 

The same aplies to the username. However, as the username is displayed in the window's title, this is not relevant.","15/Apr/20 15:29;uv683;I have replaced all our uses of password with safe representation where password is saved XORed with random padding value in char[] array. It is easy to replace char[] with e.g. zeros and its ""object"" will not remain in memory. When user logs out all these safe password representations are cleared.

There are some places where password remains in String form however:
 * {{com.rabbitmq.client.ConnectionFactory}} for rabbitMQ connection to the broker
 * {{org.apache.cxf.configuration.security.AuthorizationPolicy}} for connection to the Profile Server'
 * if password will be set as {{connectionParameters0.rabbitPassword}} in property file than it will be also converted to String object

For username it is the same story. However I have not implemented saving the username in char[] because it is pointless from my point of view.  Username is also saved in home directory in .java/.userPrefs. It is loaded from this location when CT starts and it is autofilled into username field. If we want to mask all the username usage in our code we would also need to delete this feature.","17/Apr/20 12:49;hj444;CT version for test : 2.5.1.61",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Detailed SFTP error messages disclosed,XP-68,59067,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,rehapav,rehapav,25/Jul/17 15:15,04/Aug/20 19:19,22/Feb/21 13:26,04/Jan/19 15:17,,,Pre2020,,Other,,,,,,,,,"The SFTP server of the XBID application responds with detailed error messages containing technical information after sending an adapted XML file.

In order to trigger an error message, we uploaded the following adapted XML file including a XML doctype injection (excerpt):

<?xml version=""1.0"" encoding=""UTF-8""?><!DOCTYPE foo [<!ELEMENT foo ANY><!ENTITY xxe SYSTEM ""file:///etc/passwd"">]><foo>&xee;</foo>

<ns5:Capacity_MarketDocument xmlns:ns6=""urn:iec62325.351:tc57wg16:451-3:rightsdocument:7:0"" xmlns:ns5=""urn:iec62325.351:tc57wg16:451-3:capacitydocument:7:1"" xmlns:ns4=""urn:iec62325.351:tc57wg16:451-3:totalallocationresultdocument:7:0"" xmlns:ns3=""urn:iec62325.351:tc57wg16:451-2:scheduledocument:5:0"" xmlns:ns2=""urn:iec62325.351:tc57wg16:451-3:implicitauctiondocument:7:0"" xmlns=""urn:iec62325.351:tc57wg16:451-1:acknowledgementdocument:7:0"">
<ns5:mRID>2488d6fa0da74d668de7e47aacf65b34</ns5:mRID>
<ns5:revisionNumber>1</ns5:revisionNumber>
<ns5:type>A31</ns5:type>
<ns5:process.processType>A15</ns5:process.processType>
(...)

As a result, we received the following error message from the SFTP server:

<text>File was not recognized: JAXB unmarshalling exception; nested exception is javax.xml.bind.UnmarshalException - with linked exception: [org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 48; DOCTYPE is disallowed when the feature ""http://apache.org/xml/features/disallow-doctype-decl"" set to true.]</text>

*VMT link:* https://vmt.deutsche-boerse.de/browse/PT-792",,iv732,jy268,radeale,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-71,,,,,,,"04/Jan/19 15:15;radeale;ACK_ES-PT_CBS_20190104_invalid_1_20190104150752.xml;https://jira.deutsche-boerse.com/secure/attachment/64053/ACK_ES-PT_CBS_20190104_invalid_1_20190104150752.xml","04/Jan/19 15:15;radeale;ES-PT_CBS_20190104_invalid.xml;https://jira.deutsche-boerse.com/secure/attachment/64052/ES-PT_CBS_20190104_invalid.xml",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67305600,,,,,,,,,,,,,,,XP-67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yus:b00f",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,Ampere Sprint 4,Ampere Sprint 5,Ampere Sprint 6,Ampere Sprint 7,Ampere Sprint 9,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jul/17 15:16;rehapav;


This information disclosure allows an attacker to obtain technical information, which could be used to identify further attack vectors. However, during our tests we were not able to derive any specific attacks from the obtained information.","25/Jul/17 15:16;rehapav;Check SFTP server config, what can be done","03/Aug/18 16:11;iv732;Testing to change server directives.

 

[~rehapav] can you please give me the hostname of the SFTP server that was confirmed to be vulnerable?","21/Nov/18 12:10;radeale;The issue is still valid. The solution is to send a generic message about the file being invalid instead of detailed message from the XML validator.

Contact Kamil Nezval, if you need some consulting.","26/Nov/18 16:03;jy268;Change implemented:

Exception which occurred - label present in response file

UnsupportedFileException - Unsupported file
UnexpectedFileException - Unexpected file
FileImportException - File import exception
FileTypeNotRecognizedException - File type not recognized
FileProcessingException - Exception during file processing

[~radeale] please test","27/Nov/18 12:52;radeale;Blocked by TECHLOG-1665 (SYST1 cannot connect to the SFTP).","07/Dec/18 11:56;radeale;CMI DB, table tbxi035_config, *_test users need to be replaced with *_inte users.","11/Dec/18 10:07;radeale;SYST1 still cannot connect to the SFTP server even after changing the test user to _xbid_ree_inte_.
Checking with the TechOps.","03/Jan/19 16:48;radeale;{code}2019-01-03T15:45:21.870Z [TaskScheduler-6][][] ERROR c.d.e.c.t.s.MultiNodeSftpTemplate - Action failed on current secondary SFTP node.
org.springframework.messaging.MessagingException: Failed to execute on session; nested exception is java.lang.IllegalStateException: failed to create SFTP Session
        at org.springframework.integration.file.remote.RemoteFileTemplate.execute(RemoteFileTemplate.java:445)
        at com.deutscheboerse.energy.commons.transport.sftp.MultiNodeSftpTemplate.lambda$execute$10(MultiNodeSftpTemplate.java:123)
        at com.deutscheboerse.energy.commons.transport.sftp.MultiNodeSftpTemplate.doWithFallback(MultiNodeSftpTemplate.java:149)
        at com.deutscheboerse.energy.commons.transport.sftp.MultiNodeSftpTemplate.execute(MultiNodeSftpTemplate.java:123)
        at com.deutscheboerse.energy.cmminteg.transport.sftp.SftpHandler.receive(SftpHandler.java:80)
        at sun.reflect.GeneratedMethodAccessor151.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
        at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88)
        at com.deutscheboerse.energy.failover.aop.SkipExecutionIfNotMasterAspect.aroundHandler(SkipExecutionIfNotMasterAspect.java:41)
        at sun.reflect.GeneratedMethodAccessor149.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644)
        at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633)
        at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175)
        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212){code}","04/Jan/19 15:16;radeale;Cannot reproduce the issue.

File uploaded:
 [^ES-PT_CBS_20190104_invalid.xml] 
File received:
 [^ACK_ES-PT_CBS_20190104_invalid_1_20190104150752.xml] 

Additionally antivirus is to be deployed to protect the SFTP channel (TECHLOG-574), therefore this situation is no longer considered a risk. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automate credit points calculation form monthly reporting ,XP-56,69907,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,tz118,tz118,03/Jul/18 16:15,31/Aug/20 15:39,22/Feb/21 13:26,07/Jun/19 14:33,,,Pre2020,,SLA Report Tool,,,,,,,,,For the purpose of credit points calculation based on the monthly reporting attached document describes requirements and details about applicable contacted measures.,,ca143,dw255,tz118,uv683,ym281,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/18 16:16;tz118;Kopie von XBID Performance and SM SLA Reporting June 2018_cp.xls;https://jira.deutsche-boerse.com/secure/attachment/57150/Kopie+von+XBID+Performance+and+SM+SLA+Reporting+June+2018_cp.xls","29/Aug/18 08:46;uv683;XBID Performance and SM SLA Reporting July 2018.xls;https://jira.deutsche-boerse.com/secure/attachment/58508/XBID+Performance+and+SM+SLA+Reporting+July+2018.xls","28/Aug/18 15:16;ym281;XBID_Credit_points_report_July_2018.xls;https://jira.deutsche-boerse.com/secure/attachment/58505/XBID_Credit_points_report_July_2018.xls","23/Aug/18 10:27;tz118;XBID_Credit_points_report_June_2018 (002).xls;https://jira.deutsche-boerse.com/secure/attachment/58384/XBID_Credit_points_report_June_2018+%28002%29.xls","03/Jul/18 16:16;tz118;performance_credit_points.docx;https://jira.deutsche-boerse.com/secure/attachment/57149/performance_credit_points.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78451200,,,,,,,,,,,,,,,XP-1590,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|y06u28:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"27/Jul/18 13:45;uv683;current branched merged into develop in 

[https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/110]

[~ym281] what are missing steps to finish this?","30/Jul/18 08:30;ca143;Hi [~dw255],
[~tz118] asked me for moving this task to test. The work will be finished once [~ym281] is back from vacation (end of August). Anyway, we released v1.23 and you can do some preparation for testing.

Is it necessary to collect SLA/KPI data from an environment and then run the application with parameters like:
{noformat}
-Dspring.profiles.active=credits-generate
--from=2018-07-01T00:00:00.000 --to=2018-07-31T00:00:00 --input=credit-points-report.xls
{noformat}

For the case above, you should find result file: XBID_Credit_points_report_July_2018.xls
","23/Aug/18 13:44;tz118;[~ym281], please prepare report for July as requested by AM. Thanks","28/Aug/18 16:51;dw255;I checked attached report for July. There are several issues that should be fixed:

1) All sheets except Info and Global performance:
 cell A1 (and B1 in Public Order...) is grey. Why?

2) Order Execution Time:
 missing last line: 2018-07-31 23:00:00 2018-08-01 00:00:00

3) API Response Time:
 missing last line: 2018-07-31 23:00:00 2018-08-01 00:00:00

4) Public Order Books Reports Resp:
 missing last line: 2018-07-31 23:00:00 2018-08-01 00:00:00

5) RabbitMQ queuing Time:
 missing last line: 2018-07-31 23:00:00 2018-08-01 00:00:00

6) Global Performance:
 Correct text for cell D2: Shortfall in any of four metrics
Missing line with Total sum of DBAG/PX points","29/Aug/18 07:33;ca143;I have noticed that there is no credit point for DBAG, I can't understand why:
* API Response time
** row 638
** from: 2018-07-27 07:00:00 to: 2018-07-27 08:00:00","29/Aug/18 08:46;uv683;[~dw255]  regarding points 2-5: there is a bug in report tool which is not printing the last interval.

[~ym281]  you can copy the last lines into Credit Point report from  [^XBID Performance and SM SLA Reporting July 2018.xls]","29/Aug/18 09:45;ym281;[~ca143] because 95% percentile is 77 and Upper Service Credit threshold is 75",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RTS3 Slice B,XP-55,70983,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,10/Aug/18 16:25,31/Aug/20 15:37,22/Feb/21 13:26,03/Jan/19 13:27,,,Pre2020,,Capacity,Trading,,,,,,,,,,qz412,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Aug/18 13:31;tz118;RTS3B - Scenario parameters v1_for DBAG.xlsx;https://jira.deutsche-boerse.com/secure/attachment/58190/RTS3B+-+Scenario+parameters+v1_for+DBAG.xlsx","13/Aug/18 15:10;tz118;XBID dataset RTS3 B Wave 2 for DBAG – kopie.xlsx;https://jira.deutsche-boerse.com/secure/attachment/58171/XBID+dataset+RTS3+B+Wave+2+for+DBAG+%E2%80%93+kopie.xlsx","13/Aug/18 15:09;tz118;topology_RTS3 Slice B.PDF;https://jira.deutsche-boerse.com/secure/attachment/58170/topology_RTS3+Slice+B.PDF",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67392000,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r01r",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/18 15:12;tz118;Attached PXs input regarding Topology (topology_RTS3 Slice B.PDF & XBID dataset RTS3 B Wave 2 for DBAG – kopie.xlsx) and scenarios inputs (RTS3B - Scenario parameters v1_for DBAG.xlsx)","03/Jan/19 13:27;qz412;Task is done. All scenarios executed, improvements implemented, system boundaries uplift proposal communicated & accepted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Load prognosis for the next 12 months,XP-44,70603,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,uv683,tz118,tz118,27/Jul/18 16:26,04/Aug/20 19:15,22/Feb/21 13:26,15/Oct/18 15:48,,,Pre2020,,SLA Report Tool,,,,,,,,,"(b)  DBAG shall provide, in the course of the regular monthly reporting according to Section 9.4.2 of the XBID-MSA and based on the actual use figures and estimated growth figures received from the PXs, a prognosis for the next twelve (12) months, regarding the point of time at which Service Boundaries will be exceeded. 

Email from Martin vancura 25.7.
Growth estimation
We are following the obligation to provide you with estimation of growth figures on a monthly basis. For July 2018 our estimation follows:
The expected growth for next 12 months is estimated at 5%.",,ca143,gd553,lZ644,rg535,tz118,uv683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/18 10:04;tz118;XBID Service Boundary Reporting September 2018_with Prognosis.xlsx;https://jira.deutsche-boerse.com/secure/attachment/60574/XBID+Service+Boundary+Reporting+September+2018_with+Prognosis.xlsx","21/Sep/18 07:19;ca143;kpi-report.xls;https://jira.deutsche-boerse.com/secure/attachment/59601/kpi-report.xls","21/Sep/18 07:19;ca143;sla-report.xls;https://jira.deutsche-boerse.com/secure/attachment/59602/sla-report.xls","09/Oct/18 15:05;tz118;sla-report_v2.xls;https://jira.deutsche-boerse.com/secure/attachment/60264/sla-report_v2.xls","09/Oct/18 15:55;tz118;sla-report_v3.xls;https://jira.deutsche-boerse.com/secure/attachment/60267/sla-report_v3.xls","23/Oct/18 17:48;tz118;sla-report_v4.xls;https://jira.deutsche-boerse.com/secure/attachment/60781/sla-report_v4.xls",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73526400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r01w",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,master,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"27/Jul/18 17:32;lZ644;[~tz118], I replied to the NEMOs that we do not see a broad growth estimate of 5% as sufficient and asked them to align their prognosis with the items which form part of the Service Boundaries. ","24/Aug/18 13:35;tz118;
The PXs clarified in various RCBs that the: 
* Growth estimation for August 2018: The expected growth for next 12 months is estimated as 5% based on the volume of July
* the increase of 5% per month is applicable for the number of the orders and transactions
* as for the impact on the other parameters established in the Service Boundaries is concerned, they are subject of the analysis which can start as soon as the trend data are available, which might be roughly in 1 year.","20/Sep/18 16:01;tz118;
The PXs have provided us with growth estimates based on their contractual obligation.  
PXs shall provide to DBAG on a monthly basis the estimated growth figures (such figures being provided on a best effort basis) for the usage of the XBID Solution for the next twelve (12) months, using the items, which form part of the Service Boundaries.
Growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):

Number of Block Orders (daily), as a subset of the orders = 5%
Number of Explicit Requests (daily) = 0%
Number of Explicit Allocations (daily) = 0%
Number of Hubs = this is known to DBAG (2nd wave data set)
Number of Borders = this is known to DBAG (2nd wave data set)
Sustainable Load Items = 5%","20/Sep/18 16:31;tz118;[~ca143], thanks for the alignment. Please provide Boundaries report template where I will update proposed design and info based on the requirements. 
[~eg288], we propose to update reporting in order to include one additional sheet with load prognosis","20/Sep/18 16:36;rg535;Dear [~tz118]

we will need to provide some information / status update to the customers on this topic in the first half of October. It does not mean we need to be finished; it just means we will need some update from you on the topic that I can put into the October slides. We will need the information either
 * *no later than 27. September for slides dated 2. October or* 

 * *by 4 October for the slides dated 9. October or* 

 * *by 11 October for the slides dated 16. October.* 

I have tried to give you enough time to provide feedback.

 

DSA-Hosting  §9.3 The Parties agree that Service Boundaries and utilization ratios shall be monitored and actively managed continuously taking into account the following:
 # PXs shall provide to DBAG on a monthly basis the estimated growth figures (such figures being provided on a best effort basis) for the usage of the XBID Solution for the next twelve (12) months, using the items, which form part of the Service Boundaries.
 # DBAG shall provide, in the course of the regular monthly reporting according to +Section 9.4.2+ of the XBID-MSA and based on the actual use figures and estimated growth figures received from the PXs, a prognosis for the next twelve (12) months, regarding the point of time at which Service Boundaries will be exceeded. 20.09.2018: PXs provided DBAG with their growth estimates for their growth estimation for next 12 months as percentages based on volumes from July 2018 (with exception of hubs and borders):

 * Number of Block Orders (daily), as a subset of the orders = 5%
 * Number of Explicit Requests (daily) = 0%
 * Number of Explicit Allocations (daily) = 0%
 * Number of Hubs = this is known to DBAG (2^nd^ wave data set)
 * Number of Borders = this is known to DBAG (2^nd^ wave data set)
 * Sustainable Load Items = 5% 

*+DBAG is currently evaluating how to integrate item b from §.9.3 into the regular monthly reporting. DBAG will revert to the Parties in the first half of October (at the latest by 16.10) with further information.+* 

Regards,

Suzanna","21/Sep/18 07:19;ca143;Hi [~tz118],
the latest templates are in GitHub:
https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/tree/develop/src/templates

It looks that you don't have GitHub account, right? Could you ask for the account?
In the meantime, I have attached the templates.
","24/Sep/18 14:42;tz118;Dear [~rg535], udate regarding this Topic shall be available by 4 October for the slides dated 9.","09/Oct/18 15:04;tz118;Hi [~ca143], please find attached updated template with proposal with description and design  how to prepare and report  a prognosis for the next twelve (12) months. Please review and provide effort estimates. Feel free to approach me with questions. 

Dear [~rg535], update for the customers: DBAG analysed possibilities how to integrate item b from §.9.3 into the regular monthly reporting and identified that the best approach would be to update a monthly SLA boundary report with a new sheet including this information. DBAG prepared an updated design proposal and now is internally reviewing feasibility to implement a prognosis based on the provided growth figures to a regular monthly reporting. 
","09/Oct/18 15:55;tz118;[~ca143], please find attached updated template based on our discussion (v3)","09/Oct/18 16:17;tz118;Martin Vancura email on 8/10
let me provide you with the monthly update (September 2018) of growth estimations:
growth estimation for next 12 months is provided as percentages based on volumes from July 2018 (with exception of hubs and borders):

Number of Block Orders (daily), as a subset of the orders = 5%
Number of Explicit Requests (daily) = 0%
Number of Explicit Allocations (daily) = 0%
Number of Hubs = this is known to DBAG (2nd wave data set)
Number of Borders = this is known to DBAG (2nd wave data set)
Sustainable Load Items = 5%","15/Oct/18 13:27;ca143;Ready for review:
https://github.deutsche-boerse.de/dev/m7.xbid-report-tool/pull/123","18/Oct/18 10:04;tz118;Dear [~rg535], please find attached updated boundary report from September with Load prognosis (""Prognosis"" sheet) for the next 12 months ready for your review. Please let me know in case of changes are needed.  Thank you. ","23/Oct/18 17:49;tz118; [^sla-report_v4.xls] [~uv683], please double check and implement this Version to monthly reporting,","24/Oct/18 09:25;rg535;{color:#FF8B00}For transparency this is an extract of the communication which went out to the customer over the past weeks.{color}

DSA-Hosting  §9.3 The Parties agree that Service Boundaries and utilization ratios shall be monitored and actively managed continuously taking into account the following:

a)PXs shall provide to DBAG on a monthly basis the estimated growth figures (such figures being provided on a best effort basis) for the usage of the XBID Solution for the next twelve (12) months, using the items, which form part of the Service Boundaries.
b)DBAG shall provide, in the course of the regular monthly reporting according to Section 9.4.2 of the XBID-MSA and based on the actual use figures and estimated growth figures received from the PXs, a prognosis for the next twelve (12) months, regarding the point of time at which Service Boundaries will be exceeded. 

{color:#FF8B00}Item b from §.9.3 will be integrated  into the regular monthly reporting starting with reports delivered in November. {color}","25/Oct/18 09:00;uv683;MErged in ca74b3632ed0689c5dbc0b4e011922c1ce1d8f8c

Fix version *1.31*",,,,,,,,,,,,,,,,,,,,,,,
ASR014 - Analysis  Relaxation Orderbook Local View Limits,XP-42,70591,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Minor,Done,,qz412,qz412,27/Jul/18 09:34,04/Aug/20 19:15,22/Feb/21 13:26,23/Nov/18 10:43,,,Pre2020,,Trading,,,,,,,,,"Analysis Service Request - aimed at relaxing the OBK LV limitations.

This is the external part of the Performance Tuning topic related directly to the ASR itself.

_{color:#505f79}AR Note: The folder with the related documents: S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\PER120 Change Management\Change Requests\ASR014 - Analysis Removal of the OBK limitations{color}_",,ca143,cf948,eg288,gd553,lt112,lZ644,qz412,radeale,rg535,tz118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/18 15:42;rg535;59026_Additional+Service+Request+–+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v02.docx;https://jira.deutsche-boerse.com/secure/attachment/59032/59026_Additional%2BService%2BRequest%2B%E2%80%93%2BResults%2Bof%2BASR014%2BAnalysis%2Bon%2Bthe%2BRemoval%2Bof%2BOrderbook%2BLimitation_v02.docx","10/Sep/18 17:02;tz118;59032_59026_Additional+Service+Request+–+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v03.docx;https://jira.deutsche-boerse.com/secure/attachment/59038/59032_59026_Additional%2BService%2BRequest%2B%E2%80%93%2BResults%2Bof%2BASR014%2BAnalysis%2Bon%2Bthe%2BRemoval%2Bof%2BOrderbook%2BLimitation_v03.docx","10/Sep/18 17:01;tz118;59032_59026_Additional+Service+Request+–+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v03.docx;https://jira.deutsche-boerse.com/secure/attachment/59037/59032_59026_Additional%2BService%2BRequest%2B%E2%80%93%2BResults%2Bof%2BASR014%2BAnalysis%2Bon%2Bthe%2BRemoval%2Bof%2BOrderbook%2BLimitation_v03.docx","30/Jul/18 17:20;tz118;ASR014 Analysis Relaxation Orderbook Limitations_v.2.0_30072018.docx;https://jira.deutsche-boerse.com/secure/attachment/57808/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.0_30072018.docx","27/Jul/18 09:51;qz412;ASR014 Analysis Relaxation Orderbook Limitations_v.2.0_OS.docx;https://jira.deutsche-boerse.com/secure/attachment/57732/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.0_OS.docx","27/Jul/18 11:24;tz118;ASR014 Analysis Relaxation Orderbook Limitations_v.2.0_OS_SJ.docx;https://jira.deutsche-boerse.com/secure/attachment/57735/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.0_OS_SJ.docx","30/Jul/18 17:11;tz118;ASR014 Analysis Relaxation Orderbook Limitations_v.2.1_OS_SJ.docx;https://jira.deutsche-boerse.com/secure/attachment/57807/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.1_OS_SJ.docx","30/Jul/18 18:12;radeale;ASR014 Analysis Relaxation Orderbook Limitations_v.2.1_OS_SJ_AR.docx;https://jira.deutsche-boerse.com/secure/attachment/57809/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.1_OS_SJ_AR.docx","07/Aug/18 10:59;qz412;ASR014 Analysis Relaxation Orderbook Limitations_v.2.5_OS.docx;https://jira.deutsche-boerse.com/secure/attachment/58046/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.5_OS.docx","07/Aug/18 17:14;lZ644;ASR014 Analysis Relaxation Orderbook Limitations_v.2.6.docx;https://jira.deutsche-boerse.com/secure/attachment/58095/ASR014+Analysis+Relaxation+Orderbook+Limitations_v.2.6.docx","29/Aug/18 15:58;rg535;ASR014 Analysis on the Removal of Orderbook Limitations_v3.0.docx;https://jira.deutsche-boerse.com/secure/attachment/58543/ASR014+Analysis+on+the+Removal+of+Orderbook+Limitations_v3.0.docx","31/Aug/18 14:49;rg535;ASR014 Analysis on the Removal of Orderbook Limitations_v3.2.docx;https://jira.deutsche-boerse.com/secure/attachment/58611/ASR014+Analysis+on+the+Removal+of+Orderbook+Limitations_v3.2.docx","05/Sep/18 16:51;rg535;ASR014 Analysis on the Removal of Orderbook Limitations_v4.0.docx;https://jira.deutsche-boerse.com/secure/attachment/58822/ASR014+Analysis+on+the+Removal+of+Orderbook+Limitations_v4.0.docx","07/Sep/18 12:59;qz412;Additional Service Request – Results of ASR014 Analysis on the Removal of Orderbook Limitation.docx;https://jira.deutsche-boerse.com/secure/attachment/58950/Additional+Service+Request+%E2%80%93+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation.docx","10/Sep/18 14:47;ca143;Additional Service Request – Results of ASR014 Analysis on the Removal of Orderbook Limitation_v02_DEV.docx;https://jira.deutsche-boerse.com/secure/attachment/59026/Additional+Service+Request+%E2%80%93+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v02_DEV.docx","10/Sep/18 14:47;ca143;Count_of_active_orders_prod.xlsx;https://jira.deutsche-boerse.com/secure/attachment/59027/Count_of_active_orders_prod.xlsx","14/Sep/18 15:23;qz412;Results of ASR014 Analysis on the Removal of Orderbook Limitation_v3.0.docx;https://jira.deutsche-boerse.com/secure/attachment/59331/Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v3.0.docx","11/Sep/18 16:59;qz412;Results of ASR014 Analysis on the Removal of Orderbook Limitation_v4_OS.docx;https://jira.deutsche-boerse.com/secure/attachment/59096/Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v4_OS.docx","13/Sep/18 12:21;qz412;Results of ASR014 Analysis on the Removal of Orderbook Limitation_v5_OS.docx;https://jira.deutsche-boerse.com/secure/attachment/59237/Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v5_OS.docx","13/Sep/18 13:22;rg535;Results of ASR014 Analysis on the Removal of Orderbook Limitation_v6.docx;https://jira.deutsche-boerse.com/secure/attachment/59251/Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v6.docx","14/Sep/18 14:18;gd553;Results of ASR014 Analysis on the Removal of Orderbook Limitation_v6_MRS.docx;https://jira.deutsche-boerse.com/secure/attachment/59325/Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v6_MRS.docx",,,,,,,,,,,,,,,,,,,,,,,,,,,74822400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r0000i",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/18 09:37;qz412;Dear [~lZ644], [~ca143], [~tz118], [~radeale],

I thought a bit more about the questions to ASR014 the customers raised and added one reaction in the rather extensive comment section of the document attached (my reactions are all in blue).

Summary:
 * With regards to the indicators they wish to implement, I think we should not be too soft - as I argue in the doc. They seem to request something bit different than what was the substance of the ASR.
 * Nevertheless we should explore whether some of the indicators are easy to provide, interesting or acceptable at a cost. Please decide by when we can give them the answer (marked red in the text) and when you wish to discuss on call.

Please have a look (all of you have interest in this topic) and feel free to call / write until 12:00 today.

{color:#0747a6}Also - as it has proven already invaluable in terms of transparency I am using the new work process method on CRs/ASRs (and soon pretty much any task). This ticket is assigned to Stefan (who is therefore expected to push if needed), all mentioned people should get notifications, everything is attached to the ticket => do not expect any further e-mail on this matter :). Also, please capture everything directly here - either in form of comments or attached docs.{color}","27/Jul/18 11:29;tz118;Dear all, 
updated version with some additional comments attached. With Alex and Frantisek we initiated discussion about this topic. 
Requested measurements indeed were not considered for this ASR, hence represent additional requirements. After initial analysis we can state that some measurements are possible some will be not or at least will mean performance impact which would go against purpose of this ASR. A date indicating when we can communicate analysis (which measurements are possible and what is not and what are related efforts) was added in the commented version. ","30/Jul/18 17:16;tz118;Please find updated version (2.1)attached.
[~lZ644], I added DBAG proposed answer about new measurements as discussed today.
[~radeale] you can use this version to merge updates from today.

thank you.","30/Jul/18 18:15;radeale;Please find the updated version attached:

[^ASR014 Analysis Relaxation Orderbook Limitations_v.2.1_OS_SJ_AR.docx]

Also:

S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\PER120 Change Management\Change Requests\ASR014 - Analysis Removal of the OBK limitations\ASR014 Analysis Relaxation Orderbook Limitations_v.2.1_OS_SJ_AR.docx

As agreed on the 20180730 TWG FTF/DBAG call, the contract terminology was changed in the text to be in line with HLS100 and Exhibit 01 (_predefined contracts_ and _user-defined contracts_). 

I propose to wait for Ondrej to check the document, especially what to do with all the internal comments in the document.","07/Aug/18 11:02;qz412;Dear [~rg535], [~lZ644], [~ca143],  

I have drafted DBAG answers for all the ASR014 comments. Please see v2.5 attached. Important parts are marked red, please enhance / review / comment by 16:00 so we can finalize and send out.

[~ca143]: [~tz118] indicated that by 10.8. we will be able to comment on feasibility / effort / willingness to implement individual measurements. Hope this still holds.

[~gd553]: There may be 1 item for the RCB today – definition of the partner body for ASR014 discussion on the NEMO side. I could not find that AI on the slides. Cheers, Ondra","07/Aug/18 17:16;lZ644;Dear [~qz412]
All comments accepted and sent out to the NEMOs - I do not see blocking points for a final agreement. 
A Performance Release 1.X may be in discussion after presenting the results of ASR014 mid-September. ","17/Aug/18 16:25;tz118;Dear, [~qz412],  new Task was opend regarding feasibility individual measurements XP-47","29/Aug/18 15:42;rg535;Version 3.0 distributed to customer via Jira waiting for final confirmation.","31/Aug/18 14:50;rg535;[~qz412] check version 3.2 and revert to Suzanna. Comment any items in the document to which you are opposed.","31/Aug/18 15:04;qz412;No additional comments.","05/Sep/18 14:52;ca143;Please, find DEV analysis below. We are ready to discuss the results with functional team.

1) It is not possible to remove the two-tier limits described in ASR014, chapter 3.2.

2) Based on our measurements, we can relax value “maxOrderbookDepth” from “31” to “103”.
 * The value 103 can be used on current grid and boundaries and we can offer to clients “extra performance release 1.6” which will contain OrderBook performance improvements and the parameter relaxation.
 * The value 103 can also be used as an input for RTS3 Slice B.
 ** Anyway, based on the current knowledge of scenario parameters , there is a risk that XBID won’t meet performance criteria because it is expected that there will be huge load of 150K+ events per hour.
 * (as a consequence of the change, value ""effectiveMaxOrderbookDepth"" will be setup also to ""103"" and the minimum volume functionality won't be used)

3) We cannot provide any recommendation for combination of parameters ""maxOrderbookDepth"", “minimumVolume” and “effectiveMaxOrderbookDepth”. We haven’t received any answers for our questions below:
{code:java}
Which are the biggest problems with current orderbook (local view) depth configuration?
Is there a problem with too low visible total quantity in local view? Which minimum quantity would you like to see in local view?
Is there a problem with too low count of orders in local view regardless of total quantity? How many orders would you like to see in local view?
Would you prefer to setup fixed OBK depth (e.g. 6 orders regardless of contract length) for block orders or to have today’s approach: “BLOCK_OBK_DEPTH = OBK_DEPTH / BLOCK_LENGTH”?
{code}
We don’t know what is better for customers, e.g.:
 * To see 70 orders with a defined minimum quantity and have better performance OR to see 103 orders regardless on quantity and have a worse performance

4) We cannot provide any recommendation for splitting parameter “maxOrderbookDepth” for two “maxOrderbookDepthCanonical” & “maxOrderbookDepthBlock”. The reason is the same as in the previous point.

5) We recommend to add new restrictions for qrid & product setup:
 * Define maximum number of interconnectors with 15m and 30m resolution period
 * Define maximum number of DAs which have assigned HALF_HOURLY and QUATERLY products.

6) We didn’t test XBID on the “new database solution”.

7) Our findings are based on:
 * known information about the 2019-grid
 * scenarios based on PROD data (it is possible to create a much worse scenario (blocks, trade path, order distribution, etc.))
 * expectation that TECHLOG-811 (Slow Journaler) shall be fixed (there is still ""the old"" Journaler solutionon PERF)","05/Sep/18 15:28;ca143;Hi [~qz412],
there are some additional info which were requested:

ICs with resolution 15m/30m:
{noformat}
contract_resolution	area_1_eic	area_2_eic
HALF_HOURLY	10YDE-ENBW-----N	10YFR-RTE------C
HALF_HOURLY	10YDE-RWENET---I	10YFR-RTE------C
QUARTERLY	10YDE-VE-------2	10YDE-EON------1
QUARTERLY	10YDE-RWENET---I	10YAT-APG------L
QUARTERLY	10YDE-RWENET---I	10YDE-ENBW-----N
QUARTERLY	10YDE-RWENET---I	10YDE-EON------1
QUARTERLY	10YDE-VE-------2	10YDE-RWENET---I
QUARTERLY	10YDE-ENBW-----N	10YDE-EON------1
QUARTERLY	10YDE-VE-------2	10YDE-ENBW-----N
{noformat}

DAs assigned to 15m/30m products:
{noformat}
product_long_name	tso_area_eic
XBID_Half_Hour_Power	10YDE-VE-------2
XBID_Half_Hour_Power	10YDE-RWENET---I
XBID_Half_Hour_Power	10YFR-RTE------C
XBID_Half_Hour_Power	10YDE-ENBW-----N
XBID_Half_Hour_Power	10YDE-EON------1
XBID_Quarter_Hour_Power	10YDE-ENBW-----N
XBID_Quarter_Hour_Power	10YDE-VE-------2
XBID_Quarter_Hour_Power	10YDE-EON------1
XBID_Quarter_Hour_Power	10YDE-RWENET---I
XBID_Quarter_Hour_Power	10YAT-APG------L
{noformat}

Total number of DAs: 49 (including 3 virtual DA)
Total number of ICs: 75
Total number of LTSs: 6","05/Sep/18 16:51;rg535;Version 4 of ASR sent to PXs on 5.9. Waiting for final approval from NPS.","07/Sep/18 12:52;rg535;Results to be prepared and proposal sent to PXs.","07/Sep/18 13:00;qz412;{color:#de350b}*Draft* {color}of result communication prepared:

[^Additional Service Request – Results of ASR014 Analysis on the Removal of Orderbook Limitation.docx]

Please:

React to comments with @dev in the document: [~ca143], [~eg288]: 

Review, decide how to enhance the format and polish formulations: [~rg535], [~gd553], [~tz118]

Thx, Ondra","10/Sep/18 14:51;ca143;Hi [~qz412],
please, find comments from DEV team here:
* [^Additional Service Request – Results of ASR014 Analysis on the Removal of Orderbook Limitation_v02_DEV.docx] 
Also, please find count of active orders per contract & side (top 100 items sorted by count of active orders). The data are based on 2 midnights snapshots:
*  [^Count_of_active_orders_prod.xlsx] 

*Based on discussion in DEV team, we would like to ask you for decreasing the recommended OBK depth value from ""103"" to ""100"".*","10/Sep/18 15:43;rg535;[^59026_Additional+Service+Request+–+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v02.docx]

uploaded by SV with review comments.","10/Sep/18 17:02;tz118;few changes and one additionel JS comment, version uploaded by SV was used
[^59032_59026_Additional+Service+Request+–+Results+of+ASR014+Analysis+on+the+Removal+of+Orderbook+Limitation_v03.docx]","11/Sep/18 16:58;qz412;Dear all, I have merged all comments and modified the document a bit. I think we are well on track for the communication on *15th September*, thx.

Here: [^Results of ASR014 Analysis on the Removal of Orderbook Limitation_v4_OS.docx]

[~ca143], [~cf948], [~eg288] - please review, comment, modify and then assign to [~rg535] for next review round.

Thank you, Ondra","13/Sep/18 11:35;gd553;[~ca143], [~cf948], [~eg288] - what is the status? When can [~rg535] and myself review? Please note that Suzanna can review this document only today.","13/Sep/18 11:57;eg288;I have no additional comments","13/Sep/18 12:21;qz412;Dear [~gd553], [~rg535], I have made two minor corrections, version [^Results of ASR014 Analysis on the Removal of Orderbook Limitation_v5_OS.docx] is ready for your review. ","13/Sep/18 13:23;rg535;[~qz412] [~gd553], version V6 attached. I find the analysis a bit thin. I would have expected more scientific-like explanations of what we observed in specific scenarios. I edited the document in track changes.","13/Sep/18 13:36;qz412;Dear [~rg535],

then please define to exactly what areas you would like to apply the scientific approach and (preferably sooner - we need to distribute tomorrow) discuss such strategy with dev + [~tz118]. The document as it is written now purposefully avoids the details because DBAG only was asked to indicate how far it is willing to relax the OLV - it has never been defined based on what DBAG makes this decision. For the full depth of details and discussion on how close or far to the reality we are there is the RTS3 scenarios. For the binding result there is the results interpretation after the RTS3 SB runs.

I just probably do not understand the aim, that's all.

+ Please for process improvement - why do we have this comment now after you did full review round 2 days ago on fairly the same document (at least depth-wise)?

Thx, Ondra","13/Sep/18 14:22;rg535;oh just leave it then, if you are fine with it. The ASR does not state we have to provide the exact results but I think I am anticipating the discussion.","14/Sep/18 14:22;gd553;V06_MRS attached to the ticket. [~qz412] just small changes made, Simona also sent you the email. When you finish this, please send it to [~qm925]so she can send it out. Thanks! 

 ","14/Sep/18 14:35;qz412;Clean version attached with minor improvements. [~qm925], please distribute. Thank you all!

[^Results of ASR014 Analysis on the Removal of Orderbook Limitation_v3.0.docx]","09/Oct/18 18:17;qz412;Customers received the document. Waiting til their reaction is received.",,,,,,,,,,
XBID 2nd wave - performance measurement & tuning,XP-15,69485,Task,Done,XP,XBID Agile Development,software,dm700,Agile XBID delivery ,,Major,Done,,ca143,ca143,20/Jun/18 08:15,31/Aug/20 15:38,22/Feb/21 13:26,03/Jan/19 13:24,,,Pre2020,,Trading,,,,,,,,,"*XBID after 2nd wave:*
* will meet criteria (response times) defined in Exhibit 20
** Order execution and trade capture response (3-4a/4b*) – Indicator 1a and 1b 
** Response time of the API
** Public Order Books Reports response (3-6*)
** Rabbit MQ queuing time
* observation period for the percetile measurements will be one day (same as today)
* try to increase orderbook depth (as big as possible)
* allow to have in system:
** grid
*** 50 delivery areas (now 30 in Exhibit 20)
*** 81 interconnectors (now 50 in Exhibit 20)
** LTS
*** 6 (now 3)

*Input parameters:*
* At the moment, there are no other requirements for increasing load (count of orders, trades, explicit allocations, peaks, etc.). *But it is expected, that there will be such the requirements. See comment from Henning (22 Jun 2018)*
** S:\Energie\Prod_DEVELOP\001 XBID\002 System Documentation\Planned\SLA reports\ASR003_RTS3 Slice A_List of Service Level Boundaries  KPIs_v.1.6.xlsx (also attached)
* product configuration (especially min quantity on product) will stay same as today in production
* 15m/30m contracts will be assigned only on the same delivery areas as today in production",,ca143,lZ644,qo794,qz412,,,,,,,";20/Jun/18 09:07;ca143;3600",";20/Jun/18 14:27;ca143;3600",,0,7200,,,0,256500,,,,,,,,,,,,,,,,,XDEV-4144,,,,,,,"20/Jun/18 08:27;ca143;180131 XBID presentation go-live launch event.pdf;https://jira.deutsche-boerse.com/secure/attachment/56818/180131+XBID+presentation+go-live+launch+event.pdf","22/Jun/18 12:43;ca143;ASR003_RTS3 Slice A_List of Service Level Boundaries  KPIs_v.1.6.xlsx;https://jira.deutsche-boerse.com/secure/attachment/56929/ASR003_RTS3+Slice+A_List+of+Service+Level+Boundaries++KPIs_v.1.6.xlsx",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,67478400,,,,,,,,,,,,,,,XP-41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1|000yvu:r01",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,graphx-2.2.x-perf-api,master-graphx-2.1.x,master-math,graphx-2.2.x,graphx-2.1.x,graphx-2.1.x-perf-api,XP-244-h2h-values-integer-to-long,master-graphx-2.2.x,master,develop-math,XDEV-5170-grid-copy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,"22/Jun/18 10:08;ca143;Hi [~gd553],
please, could you validate the requirements in description and once it is done, assign the ticket back to me? We would like to use this ticket for sharing all related informations/requirements about performance testing/improvements etc. for XBID 2.0.","22/Jun/18 11:51;lZ644;Hi Frantisek, 

_there are no other requirements for increasing load (count of orders, trades, explicit allocations, peaks, etc.) _

Please take into account that we must start to make 12month load projections as soon as we receive monthly expected growth rates by the PXs. => (Internal) requirements for increasing load are to be derived from this prognosis. 

_(a)    DBAG shall provide, in the course of the regular monthly reporting according to Section 9.4.2 of the XBID-MSA and based on the actual use figures and estimated growth figures received from the PXs, a prognosis for the next twelve (12) months, regarding the point of time at which Service Boundaries will be exceeded. _

THX, 
Henning","22/Jun/18 12:41;ca143;Hi [~lZ644],
thanks for the info. So, to me, it sounds that there will be requirements for more order transactions. I will upgrade the description. Please, let us know once we will have the estimations. It is important to know the expected load. 
Higher load = higher probability of negative impact in other components (SOB Intraday module, ComTrader, CMI, SPM, ReportingEngine, SLA reporting,...).

I will assign the ticket back to development.","03/Jan/19 13:24;qz412;Task is done. All scenarios executed, improvements implemented, system boundaries uplift proposal communicated & accepted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Creation of new VMs for XBID syt3 rabbitmq,SYSENGEXT-120,98566,Task,Done,SYSENGEXT,Energy Systems Engineering EXTERNAL,service_desk,ox626,,,Minor,Done,yo218,yo218,yo218,31/Jul/20 11:04,12/Nov/20 14:09,22/Feb/21 13:26,31/Jul/20 15:46,,,13082020_rel1,,,,,,07/Aug/20 00:00,,,,,"Please create 6 new VMs for the rabbitmq 3-node cluster in XBID Syt3:
||Host group||Hostname||VLAN||vCPU   ||RAM      ||DISK        ||ESX                                 ||OS                ||Description||Environment Contact||
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3xmq1|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3xmq2|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3xmq3|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3imq1|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3imq2|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|
|Energy/XBID/Internal Test/Systemtest III/AMQ|xbsyt3imq3|476 (10.139.40.0/23)|2|4|40| CLUST-EGY-NON-PROD | RHEL7          | New host for RabbitMQ 3-node cluster| Niklas Albers|

 ",,cv524,yo218,,,,,,,,,,,,,,,,,,,,,,XP-3351,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,17712000,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2644,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0bb9c:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/20 14:17;cv524;Created ISR request to assign desired IP addresses and write DNS records for new created VM hosts
ISR tickets: 91016158-63

10.139.41.254   xbsyt3xmq1 xbsyt3xmq1.deutsche-boerse.de
10.139.41.253   xbsyt3xmq2 xbsyt3xmq2.deutsche-boerse.de
10.139.41.239   xbsyt3xmq3 xbsyt3xmq3.deutsche-boerse.de
10.139.41.232   xbsyt3imq1 xbsyt3imq1.deutsche-boerse.de
10.139.41.210   xbsyt3imq2 xbsyt3imq2.deutsche-boerse.de
10.139.41.207   xbsyt3imq3 xbsyt3imq3.deutsche-boerse.de","31/Jul/20 14:49;cv524;ISR tickets successfully processed

{noformat}
###########################################################################
[ enprodauto1 ~]$ for j in x i; do for i in 1 2 3; do nslookup xbsyt3""$j""mq""$i""; done; done
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3xmq1.deutsche-boerse.de
Address: 10.139.41.254

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3xmq2.deutsche-boerse.de
Address: 10.139.41.253

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3xmq3.deutsche-boerse.de
Address: 10.139.41.239

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3imq1.deutsche-boerse.de
Address: 10.139.41.232

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3imq2.deutsche-boerse.de
Address: 10.139.41.210

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   xbsyt3imq3.deutsche-boerse.de
Address: 10.139.41.207

[enprodauto1 ~]$
###########################################################################
{noformat}
{noformat}
###########################################################################
[ enprodauto1 ~]$ for i in 254 253 239 232 210 207; do nslookup 10.139.41.""$i""; done
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
254.41.139.10.in-addr.arpa      name = xbsyt3xmq1.deutsche-boerse.de.

Authoritative answers can be found from:

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
253.41.139.10.in-addr.arpa      name = xbsyt3xmq2.deutsche-boerse.de.

Authoritative answers can be found from:

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
239.41.139.10.in-addr.arpa      name = xbsyt3xmq3.deutsche-boerse.de.

Authoritative answers can be found from:

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
232.41.139.10.in-addr.arpa      name = xbsyt3imq1.deutsche-boerse.de.

Authoritative answers can be found from:

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
210.41.139.10.in-addr.arpa      name = xbsyt3imq2.deutsche-boerse.de.

Authoritative answers can be found from:

Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
207.41.139.10.in-addr.arpa      name = xbsyt3imq3.deutsche-boerse.de.

Authoritative answers can be found from:

[ enprodauto1 ~]$
###########################################################################
{noformat}","31/Jul/20 15:45;cv524;Required hosts were created and installed with RHEL7.6 OS version
VM hosts are started and running

{noformat}
#######################################################################
xbsyt3imq1 | SUCCESS | rc=0 >>
xbsyt3imq1.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:ac:a9 brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.232/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  301M  34% /boot
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
xbsyt3imq2 | SUCCESS | rc=0 >>
xbsyt3imq2.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:0f:31 brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.210/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  301M  34% /boot
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
xbsyt3imq3 | SUCCESS | rc=0 >>
xbsyt3imq3.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:06:50 brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.207/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  301M  34% /boot
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
{noformat}


{noformat}
#######################################################################
xbsyt3xmq1 | SUCCESS | rc=0 >>
xbsyt3xmq1.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:63:3c brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.254/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  301M  34% /boot
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
xbsyt3xmq2 | SUCCESS | rc=0 >>
xbsyt3xmq2.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:40:b4 brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.253/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  302M  34% /boot
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
xbsyt3xmq3 | SUCCESS | rc=0 >>
xbsyt3xmq3.deutsche-boerse.de
Red Hat Enterprise Linux Server release 7.6 (Maipo)
3.10.0-957.27.2.el7.x86_64
processor       : 0
processor       : 1
MemTotal:        3861492 kB
Disk /dev/sda: 48.3 GB, 48318382080 bytes, 94371840 sectors
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    94371839    46672896   8e  Linux LVM
2: ens192: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:be:9d:29 brd ff:ff:ff:ff:ff:ff
    inet 10.139.41.239/23 brd 10.139.41.255 scope global ens192
       valid_lft forever preferred_lft forever
Filesystem                           Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root           7.6G  1.2G  6.1G  17% /
devtmpfs                             1.9G     0  1.9G   0% /dev
tmpfs                                1.9G     0  1.9G   0% /dev/shm
tmpfs                                1.9G   12M  1.9G   1% /run
tmpfs                                1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                            477M  151M  302M  34% /boot
/dev/mapper/rootvg-lv_home           969M  2.7M  900M   1% /home
/dev/mapper/rootvg-lv_tmp            1.9G   15M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_var            1.9G  1.1G  789M  57% /var
/dev/mapper/rootvg-lv_var_log        1.9G   11M  1.8G   1% /var/log
/dev/mapper/rootvg-lv_var_log_audit   93M  2.4M   84M   3% /var/log/audit
tmpfs                                378M     0  378M   0% /run/user/518104
/dev/mapper/rootvg-lv_xbid           976M  2.6M  907M   1% /xbid
/dev/mapper/rootvg-lv_xbid_logs      976M  2.6M  907M   1% /xbid/logs
tmpfs                                378M     0  378M   0% /run/user/1985
Loaded plugins: enabled_repos_upload, package_upload, product-id, search-
              : disabled-repos, subscription-manager
repo id                                        repo name                  status
!DBG_Energy_Global_DBAG-7-x86_64_UCMDB_UD      UCMDB_UD                        0
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64 EPEL-7-x86_64              13,229
!DBG_Energy_Global_XBID-7_XBID-7               XBID-7                         46
!rhel-7-server-extras-rpms/x86_64              Red Hat Enterprise Linux 7  1,275
!rhel-7-server-optional-rpms/x86_64            Red Hat Enterprise Linux 7 17,914
!rhel-7-server-rpms/x86_64                     Red Hat Enterprise Linux 7 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64 Red Hat Satellite Tools 6.     65
!rhel-server-rhscl-7-rpms/x86_64               Red Hat Software Collectio 11,287
repolist: 68,355
Uploading Enabled Repositories Report
Loaded plugins: product-id, subscription-manager

#######################################################################
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
M7 - Running out of swap on database hosts,M7P-6948,100676,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,26/Sep/20 10:57,10/Feb/21 11:29,22/Feb/21 13:26,09/Feb/21 10:06,,,7tops_sprint110,,Database,,,,,M7PRODOPS,OS,TechOps,,"[~hw120] recommend us to do this changes for our M7 Database setup as well. 

##########################################################################

xbprodpdb1 is reporting high swap usage.

Consulted with Cybertec and got a recommendation on how to set kernel parameters correctly for swappiness in /etc/sysctl.conf:
{code:java}
vm.overcommit_memory = 2
vm.overcommit_ratio = 93
vm.swappiness = 1
{code}
based on this calculation they provided

memory_limit = swap + overcommit_ratio/100 * RAM
 # only commit as much memory as we have RAM
 # overcommit_ratio = ( (RAM - swap) / RAM ) * 100

[https://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit]

According to the documentation from redhat, I calculated value to be...

[https://access.redhat.com/solutions/68612]

RHEL6, 7:
 allocatable memory=(swap size + ((RAM size - huge tlb size) * overcommit ratio / 100))

where ""allocatable memory"" should be less or equal than 100

 

Discussing with Cybertec proper values, ask how it could be influenced by configured hugepages.

 
 - Implement on Test db hosts, it was already configured on pdb hosts

 * 
 ** xbtestpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 ** xbtestdbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbinteedb1: 4.8GB RAM, 4GB SWAP,  overcommit_ratio = 16

 - Implement on Simu and perf db hosts, wait for a week
 ** xbsimupdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbsimudbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbsimuedb1: 8GB RAM, 2GB SWAP,  overcommit_ratio = 75
 ** xbperfpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 - Implement on Prod and perf db hosts, wait for week
 ** xbprodpdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbproddbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbprodedb1: 4.8GB RAM, 2GB SWAP,  overcommit_ratio = 58

 

 
{code:java}
cat << EOF > /etc/sysctl.d/98-db.conf
## Cybertec recommendations

# don't overcommit memory
vm.overcommit_memory = 2

# only commit as much memory as we have RAM
# overcommit_ratio = ( (RAM - swap) / RAM ) * 100
vm.overcommit_ratio = 95

# Minimize swapping
vm.swappiness = 1
EOF

# to apply the settings run
sysctl -p/etc/sysctl.d/98-db.conf
# OR
sysctl --system
{code}
 

 ",,cs687,,,,,,,,,,,,,,,,,,,,,,,XP-3575,,,,,,,,,,,,M7P-7728,M7P-7727,M7P-7726,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,"all the configuration changes are done, more info´s are in the following tickets:
* M7P-7726 (TEST)
* M7P-7727 (SIMU)
* M7P-7728 (PROD)",,,,,,,,,,,,,,1123200,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-2234,,,Impediment,,,,,,,,,,,,,,,,,,,,,,,,None,,,M7C,M7T,,,,,,"1|y0cb7z:zr",9223372036854775807,,No,,,,,,,,,,,,,,,,,,,,,7tops Sprint 110,7tops Sprint 111,,,,,,,,,,,,,,,,,,,,"see Change description
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 08:28;cs687;ticket will be solved in the 3 separated tickets 
* M7P-7726
* M7P-7727
* M7P-7728","09/Feb/21 10:06;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
AquaSec integration in CI/CD Jenkins Pipeline,A2AP-212,101647,Task,Done,A2AP,Audit 2 Action Internal,software,df894,[INTERNAL] A2A project for DBAG internals,,Major,Done,cb162,cb162,cb162,15/Oct/20 14:03,26/Jan/21 17:49,22/Feb/21 13:26,26/Jan/21 17:49,,,,,,,,,,A2A,EEXJF,highprio,Security,"In order to ensure scanning of container images before they are made available for deployment, integration into the deployment is required : Upfront scan of each container image before they are made available for deployment.

AquaSec scanning can be integrated in the CI/CD Jenkins pipeline;

In the pipeline process, after an image is built, before pushing it to Artifactory, it can be processed by the AquaSec Security Scanner engine in Jenkins which will look for malware & vulnerabilities in the image.

Based on the granularity control we want to configure inside Aquasec (based on policies), we have the control to decide if an image receives the green light to proceed further in the pipeline (being pushed to Artifactory and used later fo actual deployment on OpenShift).

 

*Challenge:* AquaSec Security Scanner plugin in Jenkins is docker based and we do not use docker in our approach. I had a talk with Pavel Jakimov already and I think workaround are existing, we just need to identify the best one.",,cb162,df894,HV988,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,A2AP-301,,,,,,,"26/Oct/20 18:14;cb162;Podman-Aqua-scanner-cli-scan-image.txt;https://jira.deutsche-boerse.com/secure/attachment/89056/Podman-Aqua-scanner-cli-scan-image.txt","26/Oct/20 18:28;cb162;Re AquaSec CICD Pipeline integration.msg;https://jira.deutsche-boerse.com/secure/attachment/89058/Re+AquaSec+CICD+Pipeline+integration.msg","26/Oct/20 18:14;cb162;podman-scan-image.txt;https://jira.deutsche-boerse.com/secure/attachment/89057/podman-scan-image.txt",,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,2246400,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ae42:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/20 10:18;cb162;update

After detailed discussion with [~HV988], I understood this is nothing we can do because we use buildah-podman stack and AquaSec uses docker daemon -> we cannot integrate this in the existing approach.

I asked already Aqua Engineering team if there is a way we can make this integration happen.

*Question*: we mentioned that in the SDD already, do you think we should remove it for the moment ?","26/Oct/20 18:29;cb162;update from Aqua IT team with the podman alternative

(attached)[^Re AquaSec CICD Pipeline integration.msg]

*Next: discuss with Pavel & Aqua team how can we make this work for us*","19/Nov/20 16:16;cb162;update

Next Wednesday 25.11 we will test an approach established with Jenkins to scan the image as per the building pipeline. (with Pavel Jakimov)

 

 ","25/Nov/20 18:22;cb162;update

session had with [~HV988], we tested a possible integration and the result was positive...need to test it proper on the SZ Cluster because this cluster will be used for image build

SZ Cluster doesn t have in this moment access to AquaSec WEB + Scanner-> FW Request raised","10/Dec/20 17:37;cb162;no update so far, still waiting for the FW to be implemented so that we can test the integration","05/Jan/21 20:00;cb162;AS IS: wait for the FW Rules to be implemented for testing

         clarify internally with Aqua team if it makes sense or is redundant ([~cb162])

 ","11/Jan/21 13:34;cb162;update 11.01

before any deployment in Production, a deployment in test will be done so that AquaSec can scan and see vulnerabilities.

Based on results, EEX will take immediate actions (if necessary) before doing deployment in PROD or if not possible accept and acknowledge the RISK and do the deployment anyway.

A CI/CD Pipeline integration can be tested and implemented but for this to be effective a block step in the pipeline must be made (and revise the build) so that not everything will be pushed to Artifactory.

Integration with CI/CD Pipeline can be tested, althought it requires more complexity and extra work on EEX side as they need to make adjustments so that pipeline goes further or not.

 

 ","26/Jan/21 17:49;cb162;CI/CD Pipeline integration is not being considered as it doesn t provide enough value for the extra complexity created",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CyberArk onboarding for A2A,A2AP-159,97771,Task,Done,A2AP,Audit 2 Action Internal,software,df894,[INTERNAL] A2A project for DBAG internals,,Minor,Done,cb162,iO924,iO924,06/Jul/20 17:52,05/Jan/21 20:10,22/Feb/21 13:26,05/Jan/21 20:10,,,,,,,,,15/Oct/20 00:00,A2A,lowprio,Security,,"Dear [~cb162],

 

Please check with Kanan and Daniel how we onboarded the ocp platform to CyberArk for the test environment and if not done, please plan how we are going to onboard Cyberark.

 

BR

Michael ",,cb162,df894,iO924,yw674,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/20 11:15;yw674;cyberark-ssh-key.png;https://jira.deutsche-boerse.com/secure/attachment/85653/cyberark-ssh-key.png",,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0ae44:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/20 15:58;cb162;New Hosts related to A2A projects (deployed in OpenShift) would need to be discovered in CyberArk in order to permit access

Is this automatically done and how ?

[https://www.openshift.com/blog/managing-secrets-in-openshift-containers-with-cyberark-conjur-and-the-cyberark-vault]

INI PAM and PAM Teams

 [Sebastien.Pascutto@clearstream.com,|mailto:Sebastien.Pascutto@clearstream.com] [toufik.hadjadj@clearstream.com|mailto:toufik.hadjadj@clearstream.com] 

Next meeting: Tuesday 14th of July","14/Jul/20 11:16;yw674;The docs say: ""The Privileged Access Security solution provides an out-of-the-box target platform to manage SSH keys, called *Unix Via SSH Keys*."" [https://docs.cyberark.com/Product-Doc/OnlineHelp/PAS/Latest/en/Content/SSHKM/Using%20SSH%20Keys.htm]

But we don't have this option, see here:

!cyberark-ssh-key.png!

We should ask CyberArk admins if it is possible to add this option.","14/Jul/20 16:53;cb162;Ok, for the moment I am not able to see anything in CyberArk and it seems for the moment, there is not a clear way how to achieve this, but I will figure out somehow.

Next step: I will ask the guys above if they can provide something on this.

 

Thanks.

Cristian","14/Jul/20 17:56;cb162;Update from  [Sebastien.Pascutto@clearstream.com|mailto:Sebastien.Pascutto@clearstream.com]

CyberArk could generate and import SSH keys via *Unix Via SSH Keys* but for the moment is not implemented and they can not provide now.

CybearArk can also do SSH Key rotation (as it happens now for password rotation) but specific configuration needs to be done.

*Next:* I already asked Florian L. if this is planned to be implemented in the future and if not, if there is a workaround to accomplish this.

 

 ","20/Jul/20 14:12;cb162;Update

Onboarding discussion with Florina Laudensack and Daniel, tomorrow Tuesday 21.07, 13:30 - 14:00 PM.

 ","23/Jul/20 17:15;cb162;Update

*Summary from the call with IS Engineering regarding CyberArk onboarding:*
 * password integration can still be used for platform admin/container admin (_abc123_) in OpenShift. Session recording will still be possible.
 * Timeline: *Web front-end: August 2020*
 * CLI: *to be defined because of linux (OCP) – windows (CyberArk) integrati*on

 * CoreOS root user only works with SSH Key and integration need to be tested if this is achievable through CyberArk. 
 * *update:* in parallel CBL colleagues opened a support case with RedHat to get an statement from the vendor on this. Updates will be provided.
 * Conjour is a solution provided by CyberArk for secrets inside containers (ex: service accounts or appl accounts) but How-to and implementation scenarios still need to be provided/tested by IS Eng
 * Timeline: *end of October 2020*
 *  [https://www.conjur.org/]            

               
 * SSH Key generation and management features are available but its deployment for DBAG environment is still under development

                        Timeline: *End of 2020/Beginning of 2021 ???*

*update:* feature is theoretical available, but SSH key management is currently not used at all. For plain key storage Cyberark platform need to be activated in FRA Vault. Further discussion internally in IS Eng Ops will be held.

On request it is possible to activate this feature but there is no warranty for support or integration for the moment (lack of personal & holiday season). 

  *Open question:*

How will the hosts & containers in OCP be discovered in Cyberark ? Will the manual import still be used or is there a way to automatize the process (ex: agent deployment in a Node/Cluster level for scaning/discovering functs) ?

*update:* At this point there is no blueprint or documentation that makes us confident regarding the onboarding process for OCP/K8s in CyberArk. A “classical” priv. account onboarding to CyberArk Vault is not applicable for containers. If there is the need to store something like access keys of ephemeral container instances, than the upcoming Conjur Vault would be the correct place to store it but further testing and development is needed.

 ","24/Jul/20 13:36;cb162;Update

Cristian: Is there well know path to consider for onboarding OCP/K8s in Cyberark ?

Florian L: OCP/ K8S is a gap we (IAM/IS ENG) need to close asap.","05/Aug/20 17:48;cb162;Update

due to people being in holidays, I was not able to receive any update regarding this topic","12/Aug/20 11:22;cb162;update

meeting established for tomorrow 13.08 to get the latest status from Florian Laudensack

 ","11/Sep/20 18:34;cb162;update

alignment meeting with Florian Laudensack on 15.09","24/Sep/20 18:18;cb162;update

 - non-ocp EEX machines are now reachable through CyberArk (CPM or PS 35 Citrix)

 - CoreOS nodes could not be reached through Cyberark

 - CyberArk Conjur onboarding for credential provisioning for Container (still in progress, end of November 2020 ?)

 - Web/CLI access for OCP 99 % implemented, only not officialy announced","15/Oct/20 17:52;cb162;update

last status from Florian L:

Web-Connector is finished. What we need from you are the OCP URLs, that we can customize it to your needs and then push it to prod.

The CLI is currently still in development - most probably December / beginning of next year 

 ","19/Oct/20 15:57;cb162;update

Openshift web URLs sent to PAM team for integration in CyberArk Vault","21/Oct/20 11:18;cb162;update

OpenShift Web URLs integrated with CyberArk [https://cyberarkbat-fra/PasswordVault/] 

CLI: in development (December 2020/January 2021) ?

non-OCP: already implemented

Next: ?

 ","29/Oct/20 10:24;cb162;update 

Jenkins + Vault integration to CyberArk

 ","03/Nov/20 18:44;cb162;update

FW Request TASKS #506049 | EGY Energy_EEX_SZ (OCP, Jenkins, Vault) access via CyberArk -> need to be approved by destination -> I contacted already Florian Laudensack","17/Nov/20 11:59;cb162;update

FW implemented - OK

Jenkins/Vault integration with CyberArk Test - in progress

I ve made a request to obtain an ab123admin account so that we can then test the integration in CyberArk PROD

 ","19/Nov/20 17:39;cb162;update

Jenkins/Vault HTTPS also works directly via CyberArk TEST

Next: wait to get my ab123admin account to test it for CyberArk PROD (ITSR made, WIP)","24/Nov/20 13:57;cb162;update

NEXT: discuss with the team the usage of the ab13admin account","30/Nov/20 17:31;cb162;next: onboard all EIT ab123admin users to connect directly via admin safe in CyberArk ?

 ","10/Dec/20 18:15;cb162;update

OCP, Vault and Jenkins GUI (https) integration with CyberArk done via ab123admin account

 

*NEXT:*
 # map all EIT ab123admin users to AD Groups for OCP, OS, Vault, Jenkins access via CyberArk without removing ab123 access (for the time being until we confirm functionality - with [~wm282]
 # map all ECC ab123admin users to AD Groups for OCP, OS, Vault, Jenkins access via CyberArk (we could follow the same yml pull request process to push users to the groups) without removing ab123 access (ffor the time being until we confirm functionality) - pull request by EEX / ldap map with automation scripts by EIT","05/Jan/21 20:10;cb162;this ticket can be closed, 2 separate tickets will be created :
 # push ab123admin accounts to the correct group so that login works on the systems
 # decommission jump.test.eex.energy",,,,,,,,,,,,,,,,
Tools necessary for Service Provisioning - Location and Data Exposion,A2A-603,97602,Task,Done,A2A,Audit 2 Action Energy Shared,software,df894,[EXTERNAL] Jira Project for DBAG & EEX collaboration on A2A. Project contains members of external EEX customer group.,,Major,Done,cb162,iO924,iO924,01/Jul/20 10:59,05/Jan/21 19:46,22/Feb/21 13:26,05/Jan/21 19:45,,,,,,,,,07/Jul/20 00:00,A2A,lowprio,SECURITY,,"Dear [~ox626] 

Please provide us a list of Tools in our toolchain necessary for us to provide the service (i.e. Aquasec, Git). Please also add the information where the tools are currently located (i.e. on premise, cloud) and provide if necessary what kind of data would be exposed to the cloud. 

 

Best Regards

Michael ",,cb162,iO924,ox626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,4060800,,,,,,,,dm700,lw641,ox626,rehapav,sw455,,,XP-4095,,,,,,,,,,,,,,,,,,,,,,,,,,,None,,,,,,,,,,"1|y0b5mo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Dec/20 09:12;ox626;[~cb162] could you please tell if this ticket is still valid?","05/Jan/21 19:44;cb162;Toolchain: Jenkins, Vault - on premise

Other Security Tools: AquaSec, Sec Tools

No PROD like data is shared outside DBG,

Ticket can be closed.

 ","05/Jan/21 19:45;cb162;DONE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
