Summary,Issue key,Issue id,Parent id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Due Date,Labels,Labels,Labels,Labels,Labels,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocks),Outward issue link (Blocks),Outward issue link (Cloners),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Issue split),Outward issue link (Issue split),Outward issue link (Issue split),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Problem/Incident),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Affected Areas),Custom field (Begin Date),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (BizOps Approvers),Custom field (Business Justification),Custom field (Change Type),Custom field (Change completion date),Custom field (Change description),Custom field (Change reason),Custom field (Change risk),Custom field (Change start date),Custom field (Conditions),Custom field (Contact Number),Custom field (Cucumber Scenario),Custom field (Cucumber Test Type),Custom field (Customer),Custom field (Customer),Custom field (Customer),Custom field (Customer),Custom field (Customer),Custom field (Customer),Customer Request Type,Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (DEV Approvers),Custom field (Database & Journal cleanup),Custom field (Days Since Last Comment),Custom field (Delivery Due Date),Custom field (Deployment Environments),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (Duty Manager Approvers),Custom field (End Date),Custom field (End Time),Custom field (Epic Color),Custom field (Epic Link),Custom field (Epic Name),Custom field (Epic Status),Custom field (Estimate),Custom field (Fix Description),Custom field (Flagged),Custom field (Generic Test Definition),Custom field (Hosting Services Coordinator),Custom field (Impact),Custom field (Impact),Custom field (Introduction Factor),Custom field (Investigation reason),Custom field (Issue Detection Factor),Custom field (Issue Time),Custom field (M7 User),Custom field (Manual Test Steps),Custom field (Merge Request Config),Custom field (Merge Request SQL),Custom field (Operational categorization),Custom field (PIR (Post Implementation Review)),Custom field (PO / ACM Approvers),Custom field (Pending reason),Custom field (Period),Custom field (Phase),Custom field (Pre-Condition Type),Custom field (Price (excl. VAT)),Custom field (Product),Custom field (Product),Custom field (Product Categorization),Custom field (Purchasing Type),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Release Notes),Custom field (Release Notes),Custom field (Release Notes),Custom field (Release Notes),Custom field (Reproducible),Custom field (Request participants),Custom field (Requirement ID),Custom field (Requirement Status),Custom field (Revision),Custom field (Rollback Plan),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root Cause Detail),Custom field (Root cause),Custom field (SAP Change),Custom field (SAP Record),Satisfaction score (out of 5),Custom field (Shift Start Date),Custom field (Shift Type),Custom field (Source),Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Custom field (Start Time),Custom field (Steps Count),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Steps to reproduce),Custom field (Story Points),Custom field (Story Points),Custom field (Story Points),Custom field (Story Points),Custom field (TechOps Approvers),Custom field (TechOps Approvers),Custom field (TechOps Customer),Custom field (Test Count),Custom field (Test Coverage),Custom field (Test Execution Status),Custom field (Test Instructions),Custom field (Test Plan Status),Custom field (Test Repository Path),Custom field (Test Result),Custom field (Test Set Status),Custom field (Test Type),Custom field (TestRunStatus),Time Spent in Progress,Time Spent in Progress simplified,Time to approve normal change,Time to approve normal change simplified,Time to close after resolution,Time to close after resolution simplified,Time to first response,Time to first response simplified,Time to resolution,Time to resolution simplified,Custom field (Urgency),Custom field (Urgency),Custom field (Waiting on),Custom field (Workaround),Custom field ([Environment]),Custom field (gitBranch),Custom field (gitBranch),Custom field (gitCommitsReferenced),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
EPEX PORTAL: SSL certificate expiry ,M7P-8973,115143,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,cv179,tj898,tj898,16/Sep/21 11:49,16/Sep/21 12:03,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"Documentation:

[https://confluence.energy.svc.dbgcloud.io/display/M7T/Customer+Portal#CustomerPortal-Certificatehandling]

 ",,cv179,tj898,,,,,,,,,,,,,,,,,,SERVICE-11113,,,,,,,,,,,,,,,,,,,,"16/Sep/21 11:49;tj898;portal-inttest.m7.epexspot.com.pem.txt;https://jira.deutsche-boerse.com/secure/attachment/99305/portal-inttest.m7.epexspot.com.pem.txt","16/Sep/21 11:49;tj898;portal-simulation.m7.epexspot.com.pem.txt;https://jira.deutsche-boerse.com/secure/attachment/99306/portal-simulation.m7.epexspot.com.pem.txt","16/Sep/21 11:49;tj898;portal.m7.epexspot.com.pem.txt;https://jira.deutsche-boerse.com/secure/attachment/99307/portal.m7.epexspot.com.pem.txt",,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,Other Service Request,,,,,,,,,,7663,,,dm700,ox626,rehapav,sw455,,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00p9b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":115143,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Sep/21 11:49;t.juhasz@epexspot.com;

[^portal-inttest.m7.epexspot.com.pem.txt] _(2 kB)_

[^portal-simulation.m7.epexspot.com.pem.txt] _(2 kB)_

[^portal.m7.epexspot.com.pem.txt] _(2 kB)_","16/Sep/21 12:03;cv179;All certificates replaced in vault: [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/shrd/portal/cert/]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,
Fix product deployment - Purging kafka topics,M7P-8971,115138,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,ax460,ax460,16/Sep/21 11:03,16/Sep/21 11:17,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"Since we have opportunity to deploy with clean DB, some data may have be gone from DB but stay in kafka topics. Eg new member is created. But events for this member might be in kafka topics. eg. Throttler reads it since ReplayFromBeginningStrategy. This may lead to inconsistencies.

Lets update deployment job and when *cleandb* tag is used also purge kafka topic, so we have consistent environment.",,ax460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11274,,,dm700,ox626,rehapav,sw455,,,,,M7P-7518,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:jls",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":115138,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gradually enable new log archiving mechanism on all environments,M7P-8955,114733,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,HO764,HO764,09/Sep/21 12:29,14/Sep/21 14:39,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"During M7P-6238, new logarch ansible role was implemented, and enabled on shrd environments via {code}move_and_compress_logs: false{code}. Let's gradually enable this setting on customer facing environments, and then change the default to false and remove it from the inventory completely.
The purpose of this change is to fix missing parts of logs in kibana caused by old log rotation.",,HO764,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,604800,,,dm700,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:jlo",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114733,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix M7P deployment job for new modules,M7P-8954,114711,,Bug,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,op211,PB446,PB446,09/Sep/21 09:50,16/Sep/21 09:50,16/Sep/21 14:11,,,,,,,,,,,7tops,ansible,deployment,jenkins,M,,,"[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/1221/console|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/1221/consoleFull] - full deployment of older version of the product failed  as particular module's (throttler) deployment was unable to download (yet undefined) version of the artifact (since deployed product had not contained it (just yet) - [https://artifactory.dbgcloud.io:443/artifactory/eex-dev-local/com/deutscheboerse/energy/m7/m7-product/m7p-reports/6.11.265/m7p-reports-6.11.265-components.yml|https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/m7/m7-product/m7p-reports/6.11.265/m7p-reports-6.11.265-components.yml] .

To fix, module/artifact version has to be defined (and checked for) in addition to module's existence in the inventory in order to execute that particular module's deployment.  This shall result in skipping the deployment of modules that are not included in the product version being deployed (regardless of their inventory status).

 AC:
 - fix is applied
 - fix is tested

Note: there are likely to be exceptions to this -e.g. amq, hap, web, ...",,PB446,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,604800,,,dm700,ox626,rehapav,sw455,,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00mnz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114711,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Reports for August 2021,M7P-8926,114473,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,03/Sep/21 11:58,14/Sep/21 23:21,16/Sep/21 14:11,10/Sep/21 11:19,,6.12.143,,,,EBSM,,,,7tops,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD| 03/09/2021|    10/09/2021  |
| M7 EPEX ASIM| 02/09/2021|    10/09/2021  |
| M7 HUPX| 02/09/2021|    10/09/2021  |
| M7 XSOP| 02/09/2021|    10/09/2021  |
| M7 TGE| 02/09/2021|    10/09/2021  |
| M7 OPCOM| 02/09/2021|    10/09/2021  |
| M7 SHRD SYT1| 02/09/2021| |
| M7 AUCTION| 02/09/2021|    09/09/2021|
| ICS / Swissgrid| 02/09/2021|    10/09/2021  |
| ICS / CH-AT| 02/09/2021 |    10/09/2021  |

[https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/10%20KPI%20%26%20SLA%20Reporting/02)%20Service%20Level%20Reporting/2021/2021-08?csf=1&e=VT7hgN]

Greenlight requesting email was sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Martin Komberec <martin.komberec@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>;{code}",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,reports sent by Volkan,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,dm700,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00lbj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114473,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
varios PROD M7 VMs with outdated OS - to be upgraded,M7P-8922,114428,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,rehapav,rehapav,02/Sep/21 10:25,16/Sep/21 08:12,16/Sep/21 14:11,,,,,,,,,,,7tops,M,,,,,,"*Description:* 

Following VMs have been identified still with RH older then RH 7.9

Please perform one by one OS upgrade and reboot to RH 7.9
|m7prodtap1|(/)|

 
|m7prodmail1|
|m7prodmail2|

 
* Discuss it with XBIT*
*Expected outcome:*

RH 7.9 is installed on all above listed VMs.

*Desired date:* anytime

ToDO:
 - check if we can upgrade test servers to RH 7.9 > talk with XBID
       -  if yes, update test servers from RH 7.8 to 7.9
       - if not, we would neet to exlclude postfix
 - wait a bit and evaluate if test deployment is OK (put ticket in waiting)
 - update abovementioned prod VMs  to RH 7.9
 - documentation: if needed, document how to exclude postfix
 - test: check the installed version 

",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8894,SERVICE-10329,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,dm700,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:jlq",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114428,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/21 07:24;cs687;*m7prodtap1*

Confirmed by Andrei that the host was used for tapping (not anymore) but should not be decomissioned, they have some plans with it in a sense support some alternative solutions for tapping - OS upgrade would be nice, anytime",,,,,,,,,,,,,,,,,,,,,,,,,,,
Downgrade kafka-cluster to version 5.4,M7P-8913,114352,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,cs687,cs687,01/Sep/21 09:08,16/Sep/21 08:14,16/Sep/21 14:11,16/Sep/21 08:14,,,,,,,,,,7tops,,,,,,,"As kafka flush-time was somehow solved with kafka cluster downgrade from version *6.1.1* to *5.5.1* and finally *5.4.2*

https://jira.deutsche-boerse.com/browse/M7P-8802

we are gonna prepare a downgrade-plan for all the untouched kafka-cluster, starting by *m7t-shrd-inte* cluster

Latest described upgrade-steps: 
https://jira.deutsche-boerse.com/browse/SERVICE-10710",,cs687,cv179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8848,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,seamless downgrade completed,,,,,,,,,,,,,,,,,,,,,,,,21512,,,dm700,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00kjb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114352,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Sep/21 11:12;cs687;h1. Zookeeper Downgrade (node by node) 
{code:java}
Current situation on SHRD INTE:
version on 6.1.1-1
kzk3: leader
zookeeper version 3.5.9
{code}

{code:java}
# stopping zookeeper instances and remove installed packages
systemctl stop confluent-zookeeper.service
yum remove confluent*

# install required confluent-packages
yum install confluent-platform-2.11-5.4.2-1 confluent-common-5.4.2-1 confluent-control-center-5.4.2-1 confluent-control-center-fe-5.4.2-1 confluent-hub-client-5.4.2-1 confluent-kafka-2.11-5.4.2-1 confluent-kafka-connect-elasticsearch-5.4.2-1 confluent-kafka-connect-jdbc-5.4.2-1 confluent-kafka-connect-jms-4.4.2 confluent-kafka-connect-replicator-5.4.2-1 confluent-kafka-connect-s3-5.4.2-1 confluent-kafka-connect-storage-common-5.4.2-1 confluent-kafka-mqtt-5.4.2-1 confluent-kafka-rest-5.4.2-1 confluent-ksql-4.4.2 confluent-rebalancer-5.4.2-1 confluent-rest-utils-5.4.2-1 confluent-schema-registry-5.4.2-1

# re-deploying zookeeper for proper path settings:
ansible-playbook playbooks/kafka/deploy_cluster.yml -l m7t-shrd-inte-kafka-zookeeper-3 -t confirm_operation -e av_product=m7t -e av_customer=shrd -e av_env=inte

systemctl status confluent-zookeeper.service

# check log-files
less /shrd/logs/zookeeper/zookeeper.log

# check if leader selection is working 
ansible ""m7t-shrd-inte-kafka-zookeeper-*"" -m shell -a ""/usr/bin/kafka-run-class org.apache.zookeeper.client.FourLetterWordMain localhost 2181 srvr""
{code}","01/Sep/21 11:12;cs687;h1. Broker Downgrade (node by node)

changing the versions and restarting each broker
{code:java}
inter.broker.protocol.version=2.4
log.message.format.version=2.4
{code}
","01/Sep/21 13:04;cv179;* broker nodes restarted one by one
 * 

{code:java}
rpm -qa | grep conflu > ~/kafka-6.1.1-packets

kafka-topics --version

systemctl stop confluent-kafka

yum remove confluent*

yum install confluent-platform-2.11-5.4.2-1 confluent-common-5.4.2-1 confluent-control-center-5.4.2-1 confluent-control-center-fe-5.4.2-1 confluent-hub-client-5.4.2-1 confluent-kafka-2.11-5.4.2-1 confluent-kafka-connect-elasticsearch-5.4.2-1 confluent-kafka-connect-jdbc-5.4.2-1 confluent-kafka-connect-jms-4.4.2 confluent-kafka-connect-replicator-5.4.2-1 confluent-kafka-connect-s3-5.4.2-1 confluent-kafka-connect-storage-common-5.4.2-1 confluent-kafka-mqtt-5.4.2-1 confluent-kafka-rest-5.4.2-1 confluent-ksql-4.4.2 confluent-rebalancer-5.4.2-1 confluent-rest-utils-5.4.2-1 confluent-schema-registry-5.4.2-1

# patch jolokia file in the role...

# on deployment host:
ansible-playbook playbooks/kafka/deploy_cluster.yml -l m7t-shrd-inte-kafka-broker-1 -t confirm_operation -e av_product=m7t -e av_customer=shrd -e av_env=inte -e update_operation=false





{code}","02/Sep/21 13:51;cv179;running on shrd-exte

using playbook/role changes from this branch/PR: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1768/files]

In advance, on all brokers changed the lines with the compatibility from 2.7 to 2.4 in file /shrd/kafka/config/server.properties 
{code:java}
inter.broker.protocol.version=2.4
log.message.format.version=2.4 {code}
and restarted brokers one by one with a delay of 2 minutes

 
{code:java}
node=1


# iterated for node=1,2,3:
# zookeepers
ansible m7tshrdextekzk${node} -m shell -b -a ""kafka-topics --version""
ansible m7tshrdextekzk${node} -m shell -b -a ""systemctl stop confluent-zookeeper""
ansible m7tshrdextekzk${node} -m shell -b -a ""yum remove -y confluent*""
ansible m7tshrdextekzk${node} -m shell -b -a ""yum install -y confluent-platform-2.11-5.4.2-1 confluent-common-5.4.2-1 confluent-control-center-5.4.2-1 confluent-control-center-fe-5.4.2-1 confluent-hub-client-5.4.2-1 confluent-kafka-2.11-5.4.2-1 confluent-kafka-connect-elasticsearch-5.4.2-1 confluent-kafka-connect-jdbc-5.4.2-1 confluent-kafka-connect-jms-4.4.2 confluent-kafka-connect-replicator-5.4.2-1 confluent-kafka-connect-s3-5.4.2-1 confluent-kafka-connect-storage-common-5.4.2-1 confluent-kafka-mqtt-5.4.2-1 confluent-kafka-rest-5.4.2-1 confluent-ksql-4.4.2 confluent-rebalancer-5.4.2-1 confluent-rest-utils-5.4.2-1 confluent-schema-registry-5.4.2-1""
ansible-playbook playbooks/kafka/deploy_cluster.yml -l m7t-shrd-exte-kafka-zookeeper-${node} -t confirm_operation -e av_product=m7t -e av_customer=shrd -e av_env=exte -e update_operation=false

# broker
ansible m7tshrdextekbr${node} -m shell -b -a ""kafka-topics --version""
ansible m7tshrdextekbr${node} -m shell -b -a ""systemctl stop confluent-kafka""
ansible m7tshrdextekbr${node} -m shell -b -a ""yum remove -y confluent*""
ansible m7tshrdextekbr${node} -m shell -b -a ""yum install -y confluent-platform-2.11-5.4.2-1 confluent-common-5.4.2-1 confluent-control-center-5.4.2-1 confluent-control-center-fe-5.4.2-1 confluent-hub-client-5.4.2-1 confluent-kafka-2.11-5.4.2-1 confluent-kafka-connect-elasticsearch-5.4.2-1 confluent-kafka-connect-jdbc-5.4.2-1 confluent-kafka-connect-jms-4.4.2 confluent-kafka-connect-replicator-5.4.2-1 confluent-kafka-connect-s3-5.4.2-1 confluent-kafka-connect-storage-common-5.4.2-1 confluent-kafka-mqtt-5.4.2-1 confluent-kafka-rest-5.4.2-1 confluent-ksql-4.4.2 confluent-rebalancer-5.4.2-1 confluent-rest-utils-5.4.2-1 confluent-schema-registry-5.4.2-1""
ansible-playbook playbooks/kafka/deploy_cluster.yml -l m7t-shrd-exte-kafka-broker-${node} -t confirm_operation -e av_product=m7t -e av_customer=shrd -e av_env=exte -e update_operation=false


 {code}
validated kafka and hupx-simu status:

[https://grafana.energy.svc.dbgcloud.io/d/GF7EmQBGz/kafka-clusters?orgId=2&from=1630579602433&to=1630583202433&var-client=shrd&var-client_env=exte&var-sampling_rate=30s&refresh=30s]

[https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&fullscreen&panelId=41&from=1630572427400&to=1630583227400&refresh=30s&var-host=All&var-client=hupx&var-client_env=simu&var-interval=30s&var-exchangeId=EPEX]

 ","02/Sep/21 14:40;cv179;updates on shrd-exte done! Connection of HUPX-SIMU kept running. The preformance / kafka-flush-times went into a much better state!

 ","06/Sep/21 16:00;cv179;updates on shrd-prod done. roman-patch-4 branch with the overall script:
{code:java}
 product=m7 cust=shrd inv_cust=shrd env=prod node=1 type=zookeeper type_hs=kzk service=zookeeper ./reinstall_broker
 product=m7 cust=shrd inv_cust=shrd env=prod node=2 type=zookeeper type_hs=kzk service=zookeeper ./reinstall_broker
 product=m7 cust=shrd inv_cust=shrd env=prod node=3 type=zookeeper type_hs=kzk service=zookeeper ./reinstall_broker
 product=m7 cust=shrd inv_cust=shrd env=prod node=1 type=broker type_hs=kbr service=kafka ./reinstall_broker
 product=m7 cust=shrd inv_cust=shrd env=prod node=2 type=broker type_hs=kbr service=kafka ./reinstall_broker
 product=m7 cust=shrd inv_cust=shrd env=prod node=3 type=broker type_hs=kbr service=kafka ./reinstall_broker {code}","13/Sep/21 09:34;cv179;keeping this ticket open until elts-prod and elts-asim is downgraded","16/Sep/21 08:13;cv179;elts-asim and elts-prod downgrade was done.

For elts-asim the java packages needed to be replaced. A replacement was done using following commands:
{code:java}
yum remove java-latest-openjdk-headless -y; yum install XBID-zulu-8 -y; systemctl restart confluent-kafka
 {code}",,,,,,,,,,,,,,,,,,,,
Technical change + EPEX PROD Deployment on version 6.11.279,M7P-8894,114217,,Deployment,Closed,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,yq577,yq577,yq577,30/Aug/21 08:44,14/Sep/21 23:15,16/Sep/21 14:11,14/Sep/21 23:15,,,,,,,,,,7tops,,,,,,,"*Deploy M7 into respective environments according to the following timeline:* 

|*Customer*|*Environment*|*Date & Time*|*Comment*|
| EPEX |PROD  |14/09/2021 21:00 to 23:00  |Envt will be down  |

*Software versions* 
M7 6.11.279

*Components Version are listed in*
https://github.deutsche-boerse.de/dev/m7.m7-product/blob/acceptance/CHANGELOG.md


+*Execution team*+
*DEV support* :[~nn481]
*BIZOPs coordinator*:[~yq577],[~dp007] ,[~oh856](Only for M7C-XBID)
*TechOps execution* :[~cs687], [~cv179] 
*SysEng* : [~kw089], [~up809], [~xx256]
*CCI team*:-Michael Mehlhorn , romain.hilbert@clearstream.com

+*Technical scope*+

*1)* Infrastructure change - M7 firewall cluster upgradation,the firewall switch to be planned only during the maintenance window  as it have impact on PROD envt as experinced in previous change
* 44030128/ SERVICE-11084  - Update Checkpoint firewall C3FFF0M0 -M7 - Production 
* 44030130 / SERVICE-11085 - Update Checkpoint firewall C3FFH1M2-M7 - Production 
change Implementer ""*romain.hilbert@clearstream.com*"" 

*2)* OS Upgrade on shared machines. Refer ticket SERVICE-10882 (Only Reboot will be taken place during maintenance window)

*3)* Load Balancer Migration-SERVICE-5915 / SYSENGINT-853 (Resource from CCI team *Michael Mehlhorn* and from SysEng [~xx256]

*4)* HP critical dbpatching - PROD - Refer ticket https://jira.deutsche-boerse.com/browse/M7P-8273 /SYSENGINT-985- SyeEng team-[~up809]

*5)* enable hot plug feature for VMs - PROD - SYSENGINT-980 /  M7P-8269 SysEng team [~kw089]
5b.Once point 3 finish then  start Apachy Haproxy



+*Application Scope*+
*Product version - M7 6.11.279*

Core Version - M7T v6.11.199
Comtrader - 6.11.124
Reporting engine- 6.5.29.17
Reporter  - 1.0.237.9

*Previous Version details*
|Prod|Cust|Env|Core|Enq|RE|Reporter|H2H|MTT|Stalker|Harvester|Info Updated|
|m7t|elts|prod|6.11.194|6.11.194|6.4.78|1.0.237.6|2.1.5|1.2.10.3|1.0.84|1.0.98|30.8.2021, 04:11:39|

Note : 


    ",,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,yq577,,,,,,,,,,,,,,,,EPEX,,,,,,,nn481,,,,,,,,No,86400,,PROD,dm700,lw641,ox626,rehapav,sw455,,14/Sep/21 23:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00jpr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14/Sep/21 21:00,,,,,,,,,,cs687,yq577,,,,"{""issueId"":114217,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/21 23:15;yq577;Change is completed and also the completed EPEX PROD deployment",,,,,,,,,,,,,,,,,,,,,,,,,,,
netbackup migration in M7 SIMU,M7P-8887,114112,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,cs687,cs687,cs687,25/Aug/21 14:16,09/Sep/21 17:06,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"The new netbackup component should be deployed on all the SIMU database hosts, ones we have the final green light after testing it for M7 SYSTEMTEST3, which was enabled today:

The following steps needs to be done: 
* before we are starting we should check the current +utilization of the backup-FS+
* deactivating the old configured backup 
* Installing the new NBU agent described in https://jira.deutsche-boerse.com/browse/M7P-8193 + Certs etc. 
* enable new backup for all the proper env´s like it was done for SYT3, later on we can just put it to m7t/postgres.yml and disable it for few test-env´s were we don´t need it 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/e3a079d3e2bd9900aae975cec85dadd5766f1e0b/inventory/m7t/shrd/syt3/postgres/vars.yml#L4
* deploy new netbackup role for all the necessary instances
{code:java}
ansible-playbook playbooks/deploy_netbackup.yml  --limit ""m7t-shrd-syt3-pdb-async*"" --tags deploy --diff
{code}

Current Plan for SIMULATION would be 2th of September, we will clarify it with Michael Lievens from nbu-side. 
Production can be handled few days later, maybe during maintenance day 14th of September.
 ",,cs687,zl246,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,518400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|i00j2f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114112,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Aug/21 11:47;zl246;Tokens for getting the NetBackup client certificates can be found here: [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/infrastructure/netbackup/client_cert_tokens]","09/Sep/21 17:06;zl246;FYI: Action delayed because of bug in backup client. No timeline for fix.
{noformat}
RE: nbpgsql nonlvm backup failing with error No such file or directory - non archive [Incident: 210830-000886]

Ok, no problem Manuel. It was just to mention the possibility but I understand.
This issue has been raised internally by Jean Jacques to prioritize it and make sure the Product Managers understand the criticality of the situation.

There is no timeline for resolution at this time but I will send updates as soon as they become available.
Please, let me know if you have any questions.

Thanks.
Regards,

Dante

Dante Caregnato
Remote Product Specialist, NetBackup
Business Critical Services
Veritas Technologies LLC

Office: +44(0) 118 943 7370  
Mobile: +44(0) 788 079 6579
dante.caregnato@veritas.com
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,
[Jira] Add 'Confidential' label to outgoing Jira mails ,M7P-8883,114104,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,tj898,sw455,sw455,25/Aug/21 10:22,15/Sep/21 09:58,16/Sep/21 14:11,,,,,,,,,,01/Nov/21 00:00,7tops,BizOps,,,,,,"*Why:* this is a risk found during the risk assessment of our Jira services. Per group security guidelines, items like our outgoing mails from Jira should be have a confidentiality label. Ours do not.

vmt risk ticket: [https://vmt.deutsche-boerse.de/browse/ISRM-59485]
 ??Description from the above ticket:??
{quote}Outgoing mails are not labelled. This can lead to unwanted modification and deletion of information, and data leakage.
 This risk does not pose any risk to the business. We have email as back-up solution, no financial impact according to the cotract, and Jira is not a regulated application.
{quote}
 

 

 

*Task:* add a label to the outgoing Jira mail. Classify them all as confidential (highest common denominator of these kind of mails.) +A footer disclaimer message would suffice.+

 Once completed, check it's in the mails, and report back to [~sw455]  or anyone from ESO to get the [VMT Ticket|https://confluence.atlassian.com/adminjiraserver/customizing-email-content-in-jira-server-1027142312.html] closed

*Proposed footer text:*

_The content of this email is confidential and intended for the recipient specified in the message only. If you have received this message by mistake, please reply to this mail to report the issue, and follow with its deletion._

 

A quick search shows that this is probably done via Apache velocity email templates on the Jira server: [https://confluence.atlassian.com/adminjiraserver/customizing-email-content-in-jira-server-1027142312.html]

Note: this _MIGHT_ be different after upgrading to Jira Datacenter versions (but I doubt it)",,pd122,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Sep/21 14:35;pd122;email_templates.tar.gz;https://jira.deutsche-boerse.com/secure/attachment/99216/email_templates.tar.gz","15/Sep/21 09:54;pd122;email_templates2.tar.gz;https://jira.deutsche-boerse.com/secure/attachment/99251/email_templates2.tar.gz",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00lbq:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":114104,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"25/Aug/21 10:24;sw455;Due date per RAP process is 31/12/2021. I set a due date of 1/11/2021 , to make sure we can validate it and close it in time.","14/Sep/21 12:49;tj898;* Go to _<jira-installation-directory>/atlassian-jira/WEB-INF/atlassian-bundled-plugins/_.

 * Find the _batchers-1.3.10.jar_ file.

 * Copy the file to a separate directory.

 * {{Execute     jar xf batchers-1.3.10.jar templates/email}}

 * {{Export the file to this ticket}}","14/Sep/21 14:36;pd122; 
{code:java}
[pd122adm@jirpada1 tmp]$ jar xvf /opt/jira/app/atlassian-jira-software-8.5.11-standalone/atlassian-jira/WEB-INF/atlassian-bundled-plugins/batchers-1.3.10.jar templates/email 
 created: templates/email/
 created: templates/email/batch/
 created: templates/email/batch/html/
 created: templates/email/batch/text/
 inflated: templates/email/batch/html/IssueUpdateBatcher-daily-subject.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-daily.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-history.vm
 inflated: templates/email/batch/text/IssueUpdateBatcher-subject.vm
 inflated: templates/email/batch/text/IssueUpdateBatcher.vm
 inflated: templates/email/batch/html/hr-bottom.vm
 inflated: templates/email/batch/html/spacer.vm
 inflated: templates/email/batch/html/MentionIssueUpdateBatcher.vm
 inflated: templates/email/batch/text/MentionIssueUpdateBatcher-subject.vm
 inflated: templates/email/batch/html/template.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-content.vm
 inflated: templates/email/batch/html/MentionIssueUpdateBatcher-subject.vm
 inflated: templates/email/batch/text/IssueUpdateBatcher-daily.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-header.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-daily-min.css
 inflated: templates/email/batch/html/IssueUpdateBatcher-daily.css
 inflated: templates/email/batch/html/MentionIssueUpdateBatcher-min.css
 inflated: templates/email/batch/html/MentionIssueUpdateBatcher.css
 inflated: templates/email/batch/html/footer.vm
 inflated: templates/email/batch/html/IssueUpdateBatcher-min.css
 inflated: templates/email/batch/html/IssueUpdateBatcher.css
 inflated: templates/email/batch/html/IssueUpdateBatcher-subject.vm
 inflated: templates/email/batch/text/IssueUpdateBatcher-daily-subject.vm
 inflated: templates/email/batch/text/MentionIssueUpdateBatcher.vm
[pd122adm@jirpada1 tmp]$ tar czf email_templates.tar.gz templates/
{code}
File attached.","15/Sep/21 09:33;tj898;Also, [~pd122], I'd need this:

==========================
h3. Step 1: Retrieve the Velocity templates
 # Go to the following location in your Jira installation directory: 
 /atlassian-jira/WEB-INF/classes/templates/email/{{}}If you're using Jira sources files, go to {{jira/src/etc/java/templates/email/}} instead.
 # Under this directory, there are three subdirectories:


 ** {{html}} - contains the templates used to create emails in html
 ** {{text}} - contains the templates used to create plain text mail outs
 ** {{subject}} - contains the templates used to generate the subject of the emails","15/Sep/21 09:56;pd122; 
{code:java}
[pd122adm@jirpada1 ~]$ cd /opt/jira/app/atlassian-jira-software-8.5.11-standalone/atlassian-jira/WEB-INF/classes/templates/email

[pd122adm@jirpada1 email]$ tar czvf /tmp/email_templates2.tar.gz html text subject
html/
html/issueworklogdeleted.vm
html/issueworklogged.vm
html/issueupdated.vm
html/issuedeleted.vm
html/issueresolved.vm
html/issuecommented.vm
html/forgotusernames.vm
html/issuecreated.vm
html/issueassigned.vm
html/filtersubscription.vm
html/issueworkstarted.vm
html/issuegenericevent.vm
html/usercreated-nopassword.vm
html/issuereopened.vm
html/emailfromadmin.vm
html/includes/
html/includes/mention-actions.vm
html/includes/summary-topleft.vm
html/includes/set-issue-details-context.vm
html/includes/userdetails.vm
html/includes/summary-bottom.vm
html/includes/changelog-issue-description.vm
html/includes/patterns/
html/includes/patterns/text-top.vm
html/includes/patterns/comment-top.vm
html/includes/patterns/button-action.vm
html/includes/patterns/extra-footer-content.vm
html/includes/patterns/page-title.vm
html/includes/patterns/issue-title.vm
html/includes/patterns/text-paragraph.vm
html/includes/patterns/worklog-top.vm
html/includes/patterns/comment-title.vm
html/includes/patterns/comment-action.vm
html/includes/patterns/worklog-row.vm
html/includes/patterns/involvedUsers.vm
html/includes/fields/
html/includes/fields/worklogchanges.vm
html/includes/fields/issuekeysummary.vm
html/includes/fields/changelog.vm
html/includes/fields/issuekey.vm
html/includes/fields/duedate.vm
html/includes/fields/issuetype.vm
html/includes/fields/securitylevel.vm
html/includes/fields/createddate.vm
html/includes/fields/labels.vm
html/includes/fields/assignee.vm
html/includes/fields/worklog.vm
html/includes/fields/reporter.vm
html/includes/fields/resolveddate.vm
html/includes/fields/priority.vm
html/includes/fields/attachments.vm
html/includes/fields/comment.vm
html/includes/fields/components.vm
html/includes/fields/affectsversions.vm
html/includes/fields/timetracking.vm
html/includes/fields/fixversions.vm
html/includes/fields/environment.vm
html/includes/fields/status.vm
html/includes/fields/project.vm
html/includes/fields/description.vm
html/includes/header.vm
html/includes/footer.vm
html/includes/emailconstants.vm
html/issueworkstopped.vm
html/usersignup.vm
html/issuearchived.vm
html/issueclosed.vm
html/issuerestored.vm
html/issuementioned.vm
html/issuenotify.vm
html/usercreated.vm
html/issuecommentedited.vm
html/contactadministrator.vm
html/emailfromadmintext.vm
html/issueworklogupdated.vm
html/issuemoved.vm
html/forgotpassword.vm
text/
text/issueworklogdeleted.vm
text/issueworklogged.vm
text/issueupdated.vm
text/issuedeleted.vm
text/lossysubscriptionconversion.vm
text/issueresolved.vm
text/issuecommented.vm
text/forgotusernames.vm
text/cannotchangepassword.vm
text/issuecreated.vm
text/issueassigned.vm
text/filtersubscription.vm
text/errorinhandler.vm
text/issueworkstarted.vm
text/issuegenericevent.vm
text/jirasupportrequest.vm
text/usercreated-nopassword.vm
text/issuereopened.vm
text/includes/
text/includes/userdetails.vm
text/includes/patterns/
text/includes/patterns/involvedUsers.vm
text/includes/userdetails_secure.vm
text/includes/issuesummary.vm
text/includes/footer.vm
text/issueworkstopped.vm
text/usersignup.vm
text/issueclosed.vm
text/partialsavedfilterconversion.vm
text/issuementioned.vm
text/issuenotify.vm
text/usercreated.vm
text/issuecommentedited.vm
text/errorsubscriptionconversion.vm
text/contactadministrator.vm
text/issueworklogupdated.vm
text/issuemoved.vm
text/forgotpassword.vm
subject/
subject/issueworklogdeleted.vm
subject/issueworklogged.vm
subject/issueupdated.vm
subject/issuedeleted.vm
subject/issueresolved.vm
subject/issuecommented.vm
subject/issuecreated.vm
subject/issueassigned.vm
subject/filtersubscription.vm
subject/issueworkstarted.vm
subject/issuegenericevent.vm
subject/issuereopened.vm
subject/issueworkstopped.vm
subject/issuearchived.vm
subject/issueclosed.vm
subject/issuerestored.vm
subject/issuementioned.vm
subject/issuenotify.vm

subject/issuecommentedited.vm
subject/issueworklogupdated.vm
subject/issuemoved.vm
{code}
file attached

 ",,,,,,,,,,,,,,,,,,,,,,,
enhance environment overview to include newly introduced 6.12 components,M7P-8866,113947,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,iu252,rehapav,rehapav,20/Aug/21 09:06,16/Sep/21 12:17,16/Sep/21 14:11,,,,,,,,,,,7tops,S,,,,,,"Please enhance the Energy environment overview page

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#filter=product%20%3D%20m7t]

for the components newly introduced with release 6.12

such as:
 * Throttler
 * PMI Gateway
 * Harvester

Use:
https://github.deutsche-boerse.de/dev/energy.deployment.versions/pull/6/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/946/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/956/files",,dm700,iu252,nn236,PB446,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7065,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00lbq:i",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113947,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"06/Sep/21 15:31;PB446;[~cv179] to provide pull request containing [version page |https://github.deutsche-boerse.de/dev/energy.deployment.versions/pull/6/files] and for inventory report changes","16/Sep/21 12:11;iu252;Harvester part is already implemented. Nothing to do here.","16/Sep/21 12:13;iu252;Throttler:

https://github.deutsche-boerse.de/dev/energy.deployment.versions/pull/12
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1820
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1818

Merged after review.

Deployed inventory-report on ATE4:
https://englobjci1.deutsche-boerse.de/job/Operations/job/01-Common/job/inventory_version_report/770/console

Throttler version is now available in environment overview:
https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/",,,,,,,,,,,,,,,,,,,,,,,,,
Verify how the ungraceful failover was triggered,M7P-8846,113890,113816,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,nn236,nn236,nn236,18/Aug/21 16:45,25/Aug/21 10:05,16/Sep/21 14:11,20/Aug/21 10:30,,7tops_sprint124,,,,,,,,M7PRODOPS,,,,,,,"During integration test DBAG-EPEX we were asked to perform two ungraceful failovers.

Client claims and from the logs it seems that he is right, that both failovers were graceful.

Could you please verify what steps were taken to kill the cores?

From https://jira.deutsche-boerse.com/browse/M7P-8683 it is unfortunately not apparent. The date of the test: 27th July from 13:00 to 13:30.

If not possible, could you please check the correctness of the procedure for killing the cores ungracefully?

Thanks!",,nn236,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00hpb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 124 (PS),Magnificent 7 Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113890,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Aug/21 10:30;nn236;[~cs687] tried to check the commands executed with SIEM department, but unfortunately, the substituting person wasn't aware of such details.

Therefore, we ran a test yesterday (19.08.2021) on SYT3 where we executed two commands and observed system behaviour afterwards:

+1st test run+
 command used: kill [M7 core process]

Result: M7 core took time to be killed, so it managed to send out the {color:#1d1c1d}DeactOrdersForExchange{color} to XBID.

+2nd test run+

command used: kill -9 [M7 core process]

Result: M7 core was killed instantly, so no {color:#1d1c1d}DeactOrdersForExchange{color} was sent to XBID.

 

*Conclusion:*

To simulate *an ungraceful failover*, the command *kill -9* *[M7 core process]* must be used.

The command *kill [M7 core process]* triggers *a graceful failover*.

 

[~cs687] could you please spread amongst the 7tops team the steps how to ensure the correct simulation of an ungraceful failover? Thank you.

The findings were shared with the customer in the external ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE:  Frequent Disconnections post M7 6.11 Version Release,M7P-8845,113889,,Bug,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,op211,wn626,wn626,18/Aug/21 15:26,13/Sep/21 09:11,16/Sep/21 14:11,,,,,,,cor,,,,7tops,,,,,,,"Dear DBAG colleagues,

Member ESUEX has been suffering disconnections every 5-10 minutes since yesterday's 6.11 deployment with their two API users SXCJVP13 and SXCJVP17.

We tried suspending and reactivating them, but apparently that has not solved the issue.

I've attached the API logs they provided.

Could you please investigate?

 

Logs: [https://kibana.energy.svc.dbgcloud.io/goto/19e2695139bb0c2730678f8dd62acfcb]

 

Best regards,

Jaime",,nn236,op211,wn626,,,,,,,,,,,,,,,,,SERVICE-10981,,,,,,,,,,,,,,,,,,,,"18/Aug/21 15:26;wn626;NotificationReport_2021-08-18-12-59-42-1.csv;https://jira.deutsche-boerse.com/secure/attachment/98451/NotificationReport_2021-08-18-12-59-42-1.csv",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,Report a Non-Critical Incident,,,,,,,,,,777600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,Communication -> Customer,18/Aug/21 14:17,,[],,,,,,,,None,,,M7T,,,,"2|i00hp3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 124 (PS),7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113889,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"20/Aug/21 11:10;nn236;Hi [~wn626]

Could you please ask the users impacted by the disconnections to try connecting using ComTrader and come back to us if they also experience the same symptoms?

According to our logs it seems that it is the user who is closing the connection:

SXCJVP13:
{code:java}
August 18th 2021, 13:07:53.057
<0.9168.24> connection <0.9168.24> (10.136.151.250:52348 -> 10.139.53.170:50060): user 'SXCJVP13' authenticated and granted access to vhost 'app'

August 18th 2021, 13:11:49.444
<0.9168.24> closing AMQP connection <0.9168.24> (10.136.151.250:52348 -> 10.139.53.170:50060, vhost: 'app', user: 'SXCJVP13'){code}
SXCJVP17:
{code:java}
August 18th 2021, 13:22:10.316
  <0.19082.24> connection <0.19082.24> (10.136.151.250:59476 -> 10.139.53.170:50060): user 'SXCJVP17' authenticated and granted access to vhost 'app'

August 18th 2021, 13:26:33.687
  <0.19082.24> closing AMQP connection <0.19082.24> (10.136.151.250:59476 -> 10.139.53.170:50060, vhost: 'app', user: 'SXCJVP17'):
client unexpectedly closed TCP connectio{code}
 

Thanks,
 J.","20/Aug/21 11:23;wn626;Thanks for the information. As you may see in the comments to corresponding ticket, they already confirmed that there is no issue with ComTrader","20/Aug/21 11:34;nn236;It's not in the description of this ticket or its comments, so I missed that information, sorry.

Then it is as you wrote to EPEX, it's very probable that the issue is in the implementation of the client and it should be investigated as a 3rd party support.

Please reopen the ticket if they come back asking for the 3rd party support or prioritise the ticket as Minor Prod ticket.

Thanks!

J.","01/Sep/21 11:29;wn626;hi [~nn236], 

 

they asked for third party support and basically it's already happening, so, please re-open the ticket","06/Sep/21 15:13;op211;Ticket re-opened to use it in Kanban board.",,,,,,,,,,,,,,,,,,,,,,,
Kafka: decrease number of partitions for m7-throttler-statuses (by manual delete),M7P-8836,113805,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fp407,fp407,17/Aug/21 11:10,14/Sep/21 23:21,16/Sep/21 14:11,13/Sep/21 10:32,,6.12.143,,,,,,,,7tops,M,OPS,,,,,"Due to functional constraints we need to decrease the number of partitions for m7-throttler-statuses from 3 to 1.

This cannot be done by reconfiguring the partitions (self service script), because it can cause data loss and kafka is not allowed to perform such action.

This has to be done manually by deleting the topic.

Unfortunately this topic has probably been created in following clusters for certain environments, because we use one role for all deployments, which now includes these new topics:

shrd-exte (shared simu envs) (/)
shrd-prod (shared prod envs) (/)
elts-asim (dedicated simu) (/)
elts-prod (dedicated prod) (/)

Please delete the topic if it exists, it will be recreated with 6.12 deployment anyway - with the updated configuration.

Following command can be used: 
{code:java}
kafka-topics --delete --zookeeper m7tshrdintekzk1:2181 --topic "".*throttler-statuses.*""
{code}

ToDO:
 - run above provided command
 - documentation: update technology stack [Confluence page|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Maintenance+and+Troubleshooting]
 -  Test: run command to show the current replication status and what the output should look like",,cs687,fp407,PB446,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"removed manually all the topics with the naming-pattern ""throttler-statuses"" 
on all the mentioned kafka-clusters in the description:

https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Maintenance+and+Troubleshooting#MaintenanceandTroubleshooting-Howtoremovetopicsonserver

",,,,,,,,,,,,,,,,,,,,,,,,259200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7518,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00lbp:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113805,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/21 15:08;PB446;[~fp407] could you please add:
 - info regarding expected impact (if the expected inpact is high, we would neet to secure customer support).
 - command to show the current replication status and what the output should look like
 ","06/Sep/21 15:14;fp407;1. customer impact in zero, these topics will be used in 6.12
2. --describe instead of delete in the above command","10/Sep/21 09:49;cs687;to describe the topics, how it looks like a the moment: 
{code:java}
[root@m7tshrdintekbr1 ~]# kafka-topics --describe --zookeeper m7tshrdintekzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7tshrdate2_m7-throttler-statuses  PartitionCount: 1       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tshrdate2_m7-throttler-statuses  Partition: 0    Leader: 2       Replicas: 2,3,1 Isr: 2,1,3
Topic: topic_m7tshrdate3_m7-throttler-statuses  PartitionCount: 1       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tshrdate3_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
Topic: topic_m7tshrdate4_m7-throttler-statuses  PartitionCount: 1       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tshrdate4_m7-throttler-statuses  Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
Topic: topic_m7tshrdsyt1_m7-throttler-statuses  PartitionCount: 1       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tshrdsyt1_m7-throttler-statuses  Partition: 0    Leader: 2       Replicas: 2,3,1 Isr: 2,1,3
{code}

to see the differences between the m7t-shrd-exte Kafka-Cluster 
*_PartitionCount: 3 vs PartitionCount: 1_*
{code:java}
[root@m7tshrdextekbr1 ~]# kafka-topics --describe --zookeeper m7tshrdextekzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7teltslipa_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
{code}

","13/Sep/21 09:50;cs687;*+removed ""Throttler"" Topics from kafka-cluster m7t-shrd-exte:+*

BEFORE: 
{code:java}
[root@m7tshrdextekbr1 ~]# kafka-topics --describe --zookeeper m7tshrdextekzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7teltslipa_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
        Topic: topic_m7teltslipa_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
Topic: topic_m7teltsxsim_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7teltsxsim_m7-throttler-statuses  Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
        Topic: topic_m7teltsxsim_m7-throttler-statuses  Partition: 1    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
        Topic: topic_m7teltsxsim_m7-throttler-statuses  Partition: 2    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
Topic: topic_m7tplpxcute_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tplpxcute_m7-throttler-statuses  Partition: 0    Leader: 2       Replicas: 2,1,3 Isr: 2,3,1
        Topic: topic_m7tplpxcute_m7-throttler-statuses  Partition: 1    Leader: 3       Replicas: 3,2,1 Isr: 2,3,1
        Topic: topic_m7tplpxcute_m7-throttler-statuses  Partition: 2    Leader: 1       Replicas: 1,3,2 Isr: 2,3,1
Topic: topic_m7tplpxlipa_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=compact,min.insync.replicas=2
        Topic: topic_m7tplpxlipa_m7-throttler-statuses  Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
        Topic: topic_m7tplpxlipa_m7-throttler-statuses  Partition: 1    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
        Topic: topic_m7tplpxlipa_m7-throttler-statuses  Partition: 2    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
Topic: topic_m7tplpxsimu_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=compact,min.insync.replicas=2
        Topic: topic_m7tplpxsimu_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,2,1 Isr: 2,3,1
        Topic: topic_m7tplpxsimu_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,3,2 Isr: 2,3,1
        Topic: topic_m7tplpxsimu_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 2,3,1
Topic: topic_m7tshrddst1_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tshrddst1_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 2,3,1
        Topic: topic_m7tshrddst1_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 2,3,1
        Topic: topic_m7tshrddst1_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
Topic: topic_m7txsopasim_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=compact,min.insync.replicas=2
        Topic: topic_m7txsopasim_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,2,1 Isr: 2,3,1
        Topic: topic_m7txsopasim_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,3,2 Isr: 2,3,1
        Topic: topic_m7txsopasim_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 2,3,1
Topic: topic_m7txsopsimu_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=compact,min.insync.replicas=2
        Topic: topic_m7txsopsimu_m7-throttler-statuses  Partition: 0    Leader: 2       Replicas: 2,1,3 Isr: 2,3,1
        Topic: topic_m7txsopsimu_m7-throttler-statuses  Partition: 1    Leader: 3       Replicas: 3,2,1 Isr: 2,3,1
        Topic: topic_m7txsopsimu_m7-throttler-statuses  Partition: 2    Leader: 1       Replicas: 1,3,2 Isr: 2,3,1
{code}

{code:java}
[root@m7tshrdextekbr1 ~]# kafka-topics --delete --zookeeper m7tshrdextekzk1:2181 --topic "".*throttler-statuses.*""
Topic topic_m7teltslipa_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7teltsxsim_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7tplpxcute_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7tplpxlipa_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7tplpxsimu_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7tshrddst1_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7txsopasim_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7txsopsimu_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
[root@m7tshrdextekbr1 ~]#
[root@m7tshrdextekbr1 ~]# kafka-topics --describe --zookeeper m7tshrdextekzk1:2181 --topic "".*throttler-statuses.*""
Error while executing topic command : Topic '.*throttler-statuses.*' does not exist as expected
[2021-09-13 09:49:09,765] ERROR java.lang.IllegalArgumentException: Topic '.*throttler-statuses.*' does not exist as expected
        at kafka.admin.TopicCommand$.kafka$admin$TopicCommand$$ensureTopicExists(TopicCommand.scala:484)
        at kafka.admin.TopicCommand$ZookeeperTopicService.describeTopic(TopicCommand.scala:390)
        at kafka.admin.TopicCommand$.main(TopicCommand.scala:67)
        at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
{code}
","13/Sep/21 09:52;cs687;*+removed ""Throttler"" Topics from kafka-cluster m7t-elts-asim:+*

BEFORE: 
{code:java}
[root@m7eltsasimkbr1 ~]# kafka-topics --describe --zookeeper m7eltsasimkzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7teltsasim_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7teltsasim_m7-throttler-statuses  Partition: 0    Leader: 1       Replicas: 1,3,2 Isr: 2,1,3
        Topic: topic_m7teltsasim_m7-throttler-statuses  Partition: 1    Leader: 2       Replicas: 2,1,3 Isr: 2,1,3
        Topic: topic_m7teltsasim_m7-throttler-statuses  Partition: 2    Leader: 3       Replicas: 3,2,1 Isr: 2,1,3
{code}

{code:java}
[root@m7eltsasimkbr1 ~]# kafka-topics --delete --zookeeper m7eltsasimkzk1:2181 --topic "".*throttler-statuses.*""
Topic topic_m7teltsasim_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.


[root@m7eltsasimkbr1 ~]# kafka-topics --describe --zookeeper m7eltsasimkzk1:2181 --topic "".*throttler-statuses.*""
Error while executing topic command : Topic '.*throttler-statuses.*' does not exist as expected
[2021-09-13 09:53:57,417] ERROR java.lang.IllegalArgumentException: Topic '.*throttler-statuses.*' does not exist as expected
        at kafka.admin.TopicCommand$.kafka$admin$TopicCommand$$ensureTopicExists(TopicCommand.scala:539)
        at kafka.admin.TopicCommand$ZookeeperTopicService.describeTopic(TopicCommand.scala:445)
        at kafka.admin.TopicCommand$.main(TopicCommand.scala:70)
        at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)

{code}
","13/Sep/21 09:55;cs687;*+removed ""Throttler"" Topics from kafka-cluster m7t-shrd-prod:+*

BEFORE:
{code:java}
[root@m7shrdprodkbr1 ~]# kafka-topics --describe --zookeeper m7shrdprodkzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7thupxprod_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7thupxprod_m7-throttler-statuses  Partition: 0    Leader: 2       Replicas: 2,3,1 Isr: 1,2,3
        Topic: topic_m7thupxprod_m7-throttler-statuses  Partition: 1    Leader: 3       Replicas: 3,1,2 Isr: 1,2,3
        Topic: topic_m7thupxprod_m7-throttler-statuses  Partition: 2    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3
Topic: topic_m7tplpxprod_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7tplpxprod_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,2,1 Isr: 1,2,3
        Topic: topic_m7tplpxprod_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,3,2 Isr: 1,2,3
        Topic: topic_m7tplpxprod_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 1,2,3
Topic: topic_m7txrpmprod_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7txrpmprod_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 1,2,3
        Topic: topic_m7txrpmprod_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3
        Topic: topic_m7txrpmprod_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 1,2,3
Topic: topic_m7txsopprod_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7txsopprod_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,2,1 Isr: 1,2,3
        Topic: topic_m7txsopprod_m7-throttler-statuses  Partition: 1    Leader: 1       Replicas: 1,3,2 Isr: 1,2,3
        Topic: topic_m7txsopprod_m7-throttler-statuses  Partition: 2    Leader: 2       Replicas: 2,1,3 Isr: 1,2,3
{code}

{code:java}
[root@m7shrdprodkbr1 ~]# kafka-topics --delete --zookeeper m7shrdprodkzk1:2181 --topic "".*throttler-statuses.*""
Topic topic_m7thupxprod_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7tplpxprod_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7txrpmprod_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
Topic topic_m7txsopprod_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.


[root@m7shrdprodkbr1 ~]# kafka-topics --describe --zookeeper m7shrdprodkzk1:2181 --topic "".*throttler-statuses.*""
Error while executing topic command : Topic '.*throttler-statuses.*' does not exist as expected
[2021-09-13 10:00:11,327] ERROR java.lang.IllegalArgumentException: Topic '.*throttler-statuses.*' does not exist as expected
        at kafka.admin.TopicCommand$.kafka$admin$TopicCommand$$ensureTopicExists(TopicCommand.scala:484)
        at kafka.admin.TopicCommand$ZookeeperTopicService.describeTopic(TopicCommand.scala:390)
        at kafka.admin.TopicCommand$.main(TopicCommand.scala:67)
        at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
{code}

","13/Sep/21 10:01;cs687;_*+removed ""Throttler"" Topics from kafka-cluster m7t-elts-prod:+*_

BEFORE:
{code:java}
[root@m7eltsprodkbr1 ~]# kafka-topics --describe --zookeeper m7eltsprodkzk1:2181 --topic "".*throttler-statuses.*""
Topic: topic_m7teltsprod_m7-throttler-statuses  PartitionCount: 3       ReplicationFactor: 3    Configs: cleanup.policy=delete,min.insync.replicas=2,retention.ms=604800000,segment.ms=604800000
        Topic: topic_m7teltsprod_m7-throttler-statuses  Partition: 0    Leader: 3       Replicas: 3,2,4 Isr: 2,3,4
        Topic: topic_m7teltsprod_m7-throttler-statuses  Partition: 1    Leader: 4       Replicas: 4,3,1 Isr: 1,3,4
        Topic: topic_m7teltsprod_m7-throttler-statuses  Partition: 2    Leader: 1       Replicas: 1,4,2 Isr: 1,2,4
{code}

{code:java}
[root@m7eltsprodkbr1 ~]# kafka-topics --delete --zookeeper m7eltsprodkzk1:2181 --topic "".*throttler-statuses.*""
Topic topic_m7teltsprod_m7-throttler-statuses is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
[root@m7eltsprodkbr1 ~]# kafka-topics --describe --zookeeper m7eltsprodkzk1:2181 --topic "".*throttler-statuses.*""
Error while executing topic command : Topic '.*throttler-statuses.*' does not exist as expected
[2021-09-13 10:02:37,101] ERROR java.lang.IllegalArgumentException: Topic '.*throttler-statuses.*' does not exist as expected
        at kafka.admin.TopicCommand$.kafka$admin$TopicCommand$$ensureTopicExists(TopicCommand.scala:539)
        at kafka.admin.TopicCommand$ZookeeperTopicService.describeTopic(TopicCommand.scala:445)
        at kafka.admin.TopicCommand$.main(TopicCommand.scala:70)
        at kafka.admin.TopicCommand.main(TopicCommand.scala)
 (kafka.admin.TopicCommand$)
{code}
","13/Sep/21 10:32;cs687;done",,,,,,,,,,,,,,,,,,,,
Connecting M7 PLPX-SIMU to XBID CUTE via MPLS,M7P-8835,113803,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,cs687,cs687,17/Aug/21 10:58,01/Sep/21 11:20,16/Sep/21 14:11,17/Aug/21 13:33,,6.12.120,7tops_sprint124,,,,,,17/Aug/21 00:00,M7PRODOPS,,,,,,,"M7 TGE SIMU connect to XBID CUTE

cleandb and clean journal *are necessary for this step *

Account to be used for connection:
Login: XBTGEX01
Password: 
if necessary, check XBID LDAP if the password is matching with the mentioned one above

Updating vault -> https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/plpx/simu/m7core/sob_user (/) 

Steps:
Before the deployment will happen we have to define the new connection endpoints, either via pull-request for our inventory or directly on the hosts 
* m7plpxsimumpls1
* m7plpxsimumpls2
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/724e8551c25924a262ad4494500617a24fc1cf4b/inventory/m7t/plpx/simu/xinetd/main.yml#L4
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/724e8551c25924a262ad4494500617a24fc1cf4b/inventory/m7t/plpx/simu/xinetd/main.yml#L5

*dest_xb_addr*: 10.103.128.11
*dest_xb_port*: 50310

1.) stopping the instances (cor, enq, amq, h2h4u, rep)
2.) Truncated the m7_999_revision_index + Deleting journal files
3.) Run the deployment
4.) Create user XBTGEX01 in WebGUI, User should be with Admin Rights and with ""Reference Data GUI"" additional rights (to be done by BizOps)",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"we connected plpx-simu to XBID CUTE via INTERNET connection (over proxy hosts m7shrdexteprx1/2) *Root Cause - missing firewall-request to reach xbid-cute with mpls hosts*

For this we just did one temporarily preparation in the inventory:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2971/files

This needs to be rolledback ones we are connecting back to xbid-simu over mpls

All the made changes above with MPLS host were rolled back and reloaded!

Which steps were done:
1.) checked plpx hosts, if config is pointing to xbid-cute  was already done
2.) stopped core, enq, h2h4u, rep, amq, stalker
3.) redeployed core (with clean-db), enq, h2h4u, rep and restarted amqp, stalker",,,,,,,,TGE,,,,,,,,,,,,,,,,2592000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00h6f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,see last comment ,,,,,,,,,,"{""issueId"":113803,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"17/Aug/21 11:10;cs687;Prepared the config-changes on the hosts
* m7plpxsimumpls1
* m7plpxsimumpls2

{code:java}
service plpx-simu-mpls-ixe1
{
        disable = no
        type = UNLISTED
        socket_type = stream
        protocol = tcp
        wait = no
        #redirect = 10.103.128.23 50100
        redirect = 10.103.128.11 50310
        bind = 0.0.0.0
        port = 55120
        user = nobody
}
{code}

afterwards restart of xinetd was necessary
","17/Aug/21 11:19;cs687;1.) stopping applications 
* core
* enq
* amq
* h2h4u
* rep

and reloading the xinetd changes 
{code:java}
systemctl reload xinetd.service
{code}

{code:java}
[root@m7plpxsimumpls1 xinetd.d]# systemctl status xinetd.service
● xinetd.service - Xinetd A Powerful Replacement For Inetd
   Loaded: loaded (/usr/lib/systemd/system/xinetd.service; enabled; vendor preset: enabled)
   Active: active (running) since Mon 2020-11-02 11:30:02 CET; 9 months 14 days ago
  Process: 2309 ExecReload=/usr/bin/kill -HUP $MAINPID (code=exited, status=0/SUCCESS)
 Main PID: 9640 (xinetd)
   CGroup: /system.slice/xinetd.service
           └─9640 /usr/sbin/xinetd -stayalive -pidfile /var/run/xinetd.pid

Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: removing tcpmux
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: removing time
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: removing time
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: Swapping defaults
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: readjusting service check_mk
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: IPv6 socket creation failed for service check_mk, trying IPv4
Aug 17 11:21:37 m7plpxsimumpls1 systemd[1]: Reloaded Xinetd A Powerful Replacement For Inetd.
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: readjusting service plpx-simu-mpls-ixe1
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: readjusting service plpx-simu-mpls-ixe2
Aug 17 11:21:37 m7plpxsimumpls1 xinetd[9640]: Reconfigured: new=0 old=3 dropped=0 (services)
{code}
","17/Aug/21 11:28;cs687;2.) Truncated the m7_999_revision_index + Deleting journal files
{code:java}
You are now connected to database ""m7tplpxsimum7b"" as user ""postgres"".
m7tplpxsimum7b=# truncate m7_999_revision_index;
TRUNCATE TABLE
{code}

{code:java}
drwxr-x--- 2 tomcat tomcat 42 Aug 17 06:00 20210815
drwxr-x--- 2 tomcat tomcat 63 Aug 16 03:03 20210816
drwxr-x--- 2 tomcat tomcat 63 Aug 17 03:03 20210817
[root@m7plpxsimum7b1 m7-msgs]# rm -rf *
{code}


In the meanwhile I already started up the AMQP Cluster and double checked RABBITMQ Management GUI ","17/Aug/21 11:30;cs687;3.) Running core deployment + *CLEAN DB*

After redeployment of core we faced out this error 
{code:java}
2021-08-17T09:33:39.089Z [SobSender] ERROR c.d.e.m.c.o.SobSender - Unable to connect to SOB
com.deutscheboerse.energy.m7.sobgateway.SobConnectorException: Can not connect to response queue; responseQueueStatus: DISCONNECTED, broadcastQueueStatus: DISCONNECTED
{code}

We needed to update the password on XBID LDAP part!

started the instances: 
* enq
* rep
* h2h4u 
* and stalker

PLPX-CUTE is already using XBID-CUTE over Internet with the user: 
sob.amqp.username=XBTGEX01 and the proper password, what is not matching with the password what TGE provided us. 

Gonna try to use *sob.amqp.username=XBTGEX02* for this purpose.
On XBID LDAP we reset the password for user *XBTGEX02*
","17/Aug/21 12:58;cs687;We also figured out that the connection from MPLS host 
m7plpxsimumpls1/2 is reaching the XBID CUTE env

{code:java}
[root@m7plpxsimumpls1 ~]# telnet 10.103.128.11 50310
Trying 10.103.128.11...
{code}

so seems like just XBID SIMU can be reached via mpls hosts, and all other xbid-env´s needs to be connected via Internet prx hosts.
[~yq577] and [~dp007] are checking it with customer. 
","17/Aug/21 13:32;cs687;h1. {color:#00875A}*FINAL Decision:*{color}

*we connected plpx-simu to XBID CUTE via INTERNET connection (over proxy hosts m7shrdexteprx1/2)*

For this we just did one temporarily preparation in the inventory: 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2971/files

{color:#DE350B}*This needs to be rolledback ones we are connecting back to xbid-simu over mpls*{color}
 
All the made changes above with MPLS host were rolled back and reloaded! 

Which steps were done: 
1.) checked plpx hosts, if config is pointing to xbid-cute (/) was already done
2.) stopped core, enq, h2h4u, rep, amq, stalker
3.) redeployed core (with clean-db), enq, h2h4u, rep and restarted amqp, stalker
 ","17/Aug/21 13:33;cs687;done",,,,,,,,,,,,,,,,,,,,,
adjust SLA reports for HUPX,M7P-8834,113801,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,hz922,hz922,17/Aug/21 10:24,01/Sep/21 11:20,16/Sep/21 14:11,17/Aug/21 16:52,,6.12.120,7tops_sprint124,,,EBSM,,,10/Sep/21 00:00,7tops,SLA,,,,,,"as per agreement with customer, daily OMTs has been raised to 30k

confirmation can be found here:
https://jira.deutsche-boerse.com/browse/SERVICE-10849

 ",,dp007,hz922,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,PBIX template + EBSM database adjusted,,,,,,,,HUPX,,,,,,,,,,,,,,,,2505600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00h5z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113801,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/21 16:51;dp007;{code:sql}
update cxhu_kpi_slas set kpi_sla_value = 30000 where kpi_sla_name = 'ORDERSPERDAY_MAX';{code}
 m7t_hupx_prod.pbix template adjusted and saved in [SharePoint|https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?id=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2Fgenerate]:
 * OMTs per month - it will show 30k from August
 * OMTs per day - it will show 10k till 17/08 and 30k from 18/08 on

Tested with temp data set:
{code:sql}
update cxhu_kpi_valuesday   set kpi_value = 30000 where kpi_date = '2021-07-31' and kpi_id = 10760;
update cxhu_kpi_valuesmonth set kpi_value = 30000 where kpi_date = '2021-07-01' and kpi_id = 21060;
--revert
update cxhu_kpi_valuesday   set kpi_value = 10000 where kpi_date = '2021-07-31' and kpi_id = 10760;
update cxhu_kpi_valuesmonth set kpi_value = 10000 where kpi_date = '2021-07-01' and kpi_id = 21060;{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,
Ops part: Make sure 6.12 envs have proper configuration,M7P-8823,113755,113348,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fp407,fp407,16/Aug/21 09:13,08/Sep/21 13:47,16/Sep/21 14:11,26/Aug/21 11:04,,7tops_sprint125,,,,,,,,M7PRODOPS,,,,,,,"Required roles must exist in DB, we need some sort of solution ... manual or automatic:

{code:java}
CREATE ROLE debezium REPLICATION LOGIN;
ALTER ROLE debezium WITH PASSWORD '{{ lookup(""hashi_vault"", ""secret=secret/{{ product }}/{{ customer }}/{{ env }}/db/debezium:password token={{ hashi_vault_token }} url={{ hashi_vault_addr }}"") }}';

CREATE ROLE {{ main_db_name }}_table_owner ;
GRANT {{ main_db_name }}_table_owner to {{main_db_name}};
GRANT {{ main_db_name }}_table_owner to debezium;

GRANT USAGE ON SCHEMA {{ main_db_name }} TO debezium;
GRANT CREATE ON DATABASE {{ main_db_name }} TO debezium;
{code}

The individual table ownership will be handled by dev in m7.m7 project as part of flyway.

This should be probably as simple as updating the file https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/patroni/templates/alter_role_for_debezium.sql.j2 and making sure patroni/postgresql is reconfigured prior to core installation.",,cs687,fp407,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1814400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00gvr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113755,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/21 14:10;fp407;Hopefully should not be more than updating this: https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/patroni/templates/alter_role_for_debezium.sql.j2 + making sure that we reconfigure patroni before 6.12 deployment on that env","19/Aug/21 14:45;fp407;PR: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1752","20/Aug/21 13:02;fp407;1. merge PRs
2. change patroni role, so that we can run the db setup scripts ""separately"" (= without deleteing DB contents, basically we need a way to reconfigure DB roles/users, etc.) (add new tag, e.g. ""db_roles_credentials_refresh"")
3. (TEST ENV ONLY!!!) write to dev channel, that they should redeploy patroni (delete database) when installing 6.12 (once on each environment is enough, not all the time)
4. (CUSTOMER ENVS) make bizops aware that for every 6.12 env, they need to run patroni deployment with tag ""db_roles_credentials_refresh""","24/Aug/21 08:23;cs687;prepared proper pull-request, all the things was tested on SYT2 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1758/files

added a new tag ""*reinit*"" which is basically just executing the db-init scripts. 
Also changed the format of the scripts, that they will not fail with ansible, in case there is already a ROLE or something else existing.
Unfortunately we are using a to old ansible version to use postgresql ansible module, in that case I would be maybe easier to implement this checks.   

At least our job could fail with kind of this messages: 
{code:java}
psql:/var/lib/pgsql_m7tshrdsyt2async/ADMIN/INSTALL/031_ALTER_ROLE_FOR_DEBEZIUM.sql:22: NOTICE:  role ""m7tshrdsyt2m7b"" is already a member of role ""m7tshrdsyt2m7b_table_owner""
psql:/var/lib/pgsql_m7tshrdsyt2async/ADMIN/INSTALL/031_ALTER_ROLE_FOR_DEBEZIUM.sql:23: NOTICE:  role ""debezium"" is already a member of role ""m7tshrdsyt2m7b_table_owner""
{code}

h1. DROP DATABASE for DEV on TEST-ENV´s 
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t-shrd-syt2-pdb-async*"" --tags dropdb --diff
{code}

{code:java}
postgres=# \l
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2m7b                   +
                |                |          |             |             | m7tshrdsyt2m7b=CTc/m7tshrdsyt2m7b    +
                |                |          |             |             | uapp01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b+
                |                |          |             |             | uapp01m7tshrdsyt2rep=c/m7tshrdsyt2m7b+
                |                |          |             |             | udev01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b+
                |                |          |             |             | debezium=C/m7tshrdsyt2m7b
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2mtt                   +
                |                |          |             |             | m7tshrdsyt2mtt=CTc/m7tshrdsyt2mtt    +
                |                |          |             |             | uapp01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt+
                |                |          |             |             | udev01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2rep                   +
                |                |          |             |             | m7tshrdsyt2rep=CTc/m7tshrdsyt2rep    +
                |                |          |             |             | uapp01m7tshrdsyt2rep=c/m7tshrdsyt2rep+
                |                |          |             |             | udev01m7tshrdsyt2rep=c/m7tshrdsyt2rep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)


postgres=# \du
                                                     List of roles
         Role name          |                         Attributes                         |          Member of
----------------------------+------------------------------------------------------------+------------------------------
 debezium                   | Replication                                                | {m7tshrdsyt2m7b_table_owner}
 m7tshrdsyt2m7b             |                                                            | {m7tshrdsyt2m7b_table_owner}
 m7tshrdsyt2m7b_table_owner | Cannot login                                               | {}
 m7tshrdsyt2mtt             |                                                            | {}
 m7tshrdsyt2rep             |                                                            | {}
 postgres                   | Superuser, Create role, Create DB, Replication, Bypass RLS | {}
 replicated                 | Cannot login                                               | {}
 replicator                 | Replication                                                | {}
 uapp01m7tshrdsyt2m7b       |                                                            | {}
 uapp01m7tshrdsyt2mtt       |                                                            | {}
 uapp01m7tshrdsyt2rep       |                                                            | {}
 udev01m7tshrdsyt2m7b       |                                                            | {}
 udev01m7tshrdsyt2mtt       |                                                            | {}
 udev01m7tshrdsyt2rep       |                                                            | {}
 usernetbackup              | Superuser                                                  | {}
{code}

*After dropping we see this view:*
{code:java}
postgres=# \du
                                     List of roles
   Role name   |                         Attributes                         | Member of
---------------+------------------------------------------------------------+-----------
 postgres      | Superuser, Create role, Create DB, Replication, Bypass RLS | {}
 replicated    | Cannot login                                               | {}
 replicator    | Replication                                                | {}
 usernetbackup | Superuser                                                  | {}

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(3 rows)
{code}

h1. REINIT Database setup ones again
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t-shrd-syt2-pdb-async*"" --tags reinit --diff
{code}
","26/Aug/21 11:04;cs687;[~fp407] prepared Jenkins Job for dev´s -> https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Kafka/job/(wip)%20deploy-patroni/
for re-initializing the database setup https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Kafka/job/(wip)%20deploy-patroni/89/console

we made a dry-run for SYSTEMTEST3 all went fine. 
Ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,
[VMT]Apache HTTP Server: Multiple Vulnerabilities - M7 PROD STAGING,M7P-8809,113608,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,cs687,cs687,10/Aug/21 10:32,13/Aug/21 11:25,16/Sep/21 14:11,12/Aug/21 14:50,,7tops_sprint123,,,,,,,,M7PRODOPS,Web,,,,,,"Like described in ticket M7P-8477 we need to upgrade our older apache version from 2.4.6 to 2.4.48 to get rid of several vulnerabilities. Vulnerable Hosts would be

m7shrdprodweb1
m7tshrdprodweb2

During the TEST/SIMU Staging we clarified the necessary steps, these things needs to be repeated for the hosts above.

https://jira.deutsche-boerse.com/browse/M7P-8807
https://jira.deutsche-boerse.com/browse/M7P-8808
",,cs687,,,,,,,,,,,,,,,,,M7P-8477,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"with OS Upgrade we installed the latest apache version 2.4.6 with the last security patch, provided by RH

{code:java}
Installed Packages                                                    
Name        : httpd                                                   
Arch        : x86_64                                                  
Version     : 2.4.6                                                   
Release     : 97.el7_9                                                
Size        : 3.7 M                                                   
Repo        : installed                                               
From repo   : rhel-7-server-rpms                                      
Summary     : Apache HTTP Server                                      
URL         : http://httpd.apache.org/                                
License     : ASL 2.0                                                 
Description : The Apache HTTP Server is a powerful, efficient, and    
            : extensible web server.                                  
{code}

instances were restarted",,,,,,,,,,,,,,,,,,,,,,,,2937600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|i00f70:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113608,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"12/Aug/21 14:50;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,
[VMT]Apache HTTP Server: Multiple Vulnerabilities - M7 TEST STAGING,M7P-8807,113606,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,10/Aug/21 10:28,01/Sep/21 11:20,16/Sep/21 14:11,12/Aug/21 10:57,,6.12.120,7tops_sprint123,,,,,,,M7PRODOPS,Web,,,,,,"Like described in ticket M7P-8477 we need to upgrade our older apache version from 2.4.6 to 2.4.48 to get rid of several vulnerabilities. Vulnerable Hosts would be 
* m7tshrdinteweb1
* m7tshrdinteweb2

During the TEST/SIMU/PROD Staging we need to clarify the steps what needs to be done to upgrade the apache version.
Would it be enough to stop the apache instances and run a yum update/install command by deploying it via ansible apache-server role 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/apache_server/tasks/main.yml ?

The same things has to be done for SIMU AND PROD 
 ",,cs687,,,,,,,,,,,,,,,,,M7P-8477,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"with OS Upgrade we installed the latest apache version 2.4.6 with the last security patch, provided by RH

{code:java}
Installed Packages                                                    
Name        : httpd                                                   
Arch        : x86_64                                                  
Version     : 2.4.6                                                   
Release     : 97.el7_9                                                
Size        : 3.7 M                                                   
Repo        : installed                                               
From repo   : rhel-7-server-rpms                                      
Summary     : Apache HTTP Server                                      
URL         : http://httpd.apache.org/                                
License     : ASL 2.0                                                 
Description : The Apache HTTP Server is a powerful, efficient, and    
            : extensible web server.                                  
{code}

instances were restarted",,,,,,,,,,,,,,,,,,,,,,,,3024000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:jq",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":113606,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/21 10:54;cs687;During OS UPGRADE to 7.9 the new security patch was installed on the following hosts: 
* m7shrdinteweb1
* m7shrdintweb2
* m7shrdtestldp1
* m7shrdtestldp2

{code:java}
Installed Packages                                                  
Name        : httpd                                                 
Arch        : x86_64                                                
Version     : 2.4.6                                                 
Release     : 97.el7_9                                              
Size        : 3.7 M                                                 
Repo        : installed                                             
From repo   : rhel-7-server-rpms                                    
Summary     : Apache HTTP Server                                    
URL         : http://httpd.apache.org/                              
License     : ASL 2.0                                               
Description : The Apache HTTP Server is a powerful, efficient, and  
            : extensible web server.                                                                                    
{code}


","12/Aug/21 10:57;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Install Consul agents on m7b3/b4 hosts,M7P-8803,113585,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,jv861,jv861,09/Aug/21 11:19,14/Sep/21 23:21,16/Sep/21 14:11,10/Sep/21 07:57,,6.12.143,,,,,,,,7tops,M,M7PRODOPS,,,,,"For PMI Gateway to be able to run in MASTER/SLAVE mode, we need a Consul available for the app to connect to. Since PMI Gateway will run on m7b3/b4 hosts, the Consul agent should be runnig there. Se please deploy it to all {{*m7b3}} /{{*m7b4}} hosts, including:

* internal test envs
* external test envs
* prod envs

This is a prerequisite for 6.12

Feel free to split this ticket to multiple ones, if needed",,cs687,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed the new network-segments and consul client/server for pmi-instance ate3. 
This setup should be taken as a PoC, ones everything is proofed we will create the consul agents for all the other env´s as well. 

next step should be discussed with DEV to decide on a proper path in consul k/v, that it will not interfere with Other´s 

Hand it over to DEV, closing this ticket, for further consul implementation will create a dedicated ticket. ",,,,,,,,,,,,,,,,,,,,,,,,518400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7518,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:jo",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":113585,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Aug/21 10:19;cs687;need to talk about this topic with Peter P. and Kamil, there was a discussion happening already few days before. 
It´s still unclear which consul hosts we are using for it, separate one or the already existing one which are used by patroni instances.

First dry-run we can try to do it with *ate3* env: 
as far I can see *throttler* and pmi-gateway is deployed on host *m7tenrgate3m7b3* 

Host m7tenrgate3m7b4 is reachable but nothing is deployed so far. 
","10/Aug/21 11:54;cs687;Changed the T-Shirt size from S to M. 
There are couple more things to do, like 
* changing some part on consul server 
* creating FW requests for the proper hosts 
* installing consul agent on the m7b machines 

this ticket can be taken as an example:
https://jira.deutsche-boerse.com/browse/M7A-1066

Having a meeting with Peter this Thursday about it 8/12/2021","12/Aug/21 10:48;cs687;so there are few things to do: 
 1.) defining proper ports which are used in ports.yml
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/ports.yml]
 2.) defining instance like auction was doing it for rabbitmq-consul connection 
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/tree/master/inventory/m7a/shrd/syt1/consul]
 3.) defining the new consul network segment
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/energy/shrd/test/consul/vars.yml]
 4.) requesting the firewall-request
 Example can be found here:
{code:java}
complete firewall request can be seen in:
TuFiN: 508662 | EGY M7A Setup Test Consul
m7aenrgsyt1amq1+2 -> Consul Server TCP 31001, UDP 31001,
m7aenrgsyt2amq1+2 -> Consul Server TCP 31002, UDP 31002
{code}
5.) to avoid some issues on other consul instances, we should put all patroni instances to maintenance mode
 6.) deploying consul_network_segements
{code:java}
ansible-playbook playbooks/configure_consul_network_segments.yml -e consul_group_name=consul_energy_shrd_test -e ansible_python_interpreter=/usr/bin/python --limit 'energy-shrd-test-cons*' --diff
{code}
7.) deploying consul server
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K --limit 'energy-shrd-test-cons*' --diff
{code}
8.) deploying server and clients
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python -K --limit 'energy-shrd-test-cons*:m7a*-syt1*amq*' --diff
{code}
9.) check consul members if the new instances are in-place, in case yes resume patroni maintenance mode
 10.) IMPORTANT application should be using a dedicated namespace for consul keystore, here an example of patorni
{code:java}
service/patroni/m7/m7t/ate1/

# maybe for throttler it could be 
service/throttler/m7/m7t/ate3/
{code}
Currently all our instances which are communicating with consul-test/simu/prod are using one dedicated bootstrap token, should think about to create for each instance an separate one.

In ports.yml file we could have a concept for TRADING like this:
{code:java}
32001
(32) -> trading
32(0) -> consul test, (1) -> consul simu, (2) -> consul prod 
320(01) -> first instance either throttler or MTT 
{code}
*{color:#de350b}From beginning{color}*{color:#172b4d} we are planning to start with *MTT* and *pmi-gateway* to use consul, but it can also happen that other instances like throttler, reporter and also h2h4u will also use it in the future. {color}

 

Pull-request for PoC *ate3 pmi-gateway*

Should be reviewed from TO´s of 7tops and [~hw120] 

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2958/files","17/Aug/21 08:12;cs687;The Following Firewall-Request is necessary: 
Example of hosts *m7tenrgate3m7b3* and *m7tenrgate3m7b4* which could be candidates for PoC before we are opening few port-ranges for this purpose

||Source||Destination||Port||
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8300|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8501|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8301|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|UDP 8301|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 32001|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|UDP 32001|

|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|TCP 8301|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|UDP 8301|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|TCP 8302|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|UDP 8302|










","25/Aug/21 08:35;cs687;Created FW-Request described above with the *ID: 510387*
""EGY M7T Setup Test Consul PMI GATEWAY PoC""

UPDATE: Rule implementation 9/3/2021
UPDATE: Rules implemented 9/9/2021

*Validating the implementation:*

||Source||Destination||Port||Checks||
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8300|(/)| 
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8501|(/)|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 8301|(/)|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|UDP 8301|(/)|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|TCP 32001|(/)|
|m7tenrgate3m7b3/4|testcons1/2/3/4/5.srv.energy|UDP 32001|(/)|

|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|TCP 8301|(/)|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|UDP 8301|(/)|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|TCP 8302|(/)|
|testcons1/2/3/4/5.srv.energy|m7tenrgate3m7b3/4|UDP 8302|(/)|

*+for opening the port on m7tenrgate3m7b3/4 installed ncat to open the port manually:+*
{code:java}
# tomcat host
[root@m7tenrgate3m7b3 ~]# ncat -l -4 8301
▒▒▒▒▒▒

# cons host 
[root@testcons1.srv.energy ~]# telnet m7tenrgate3m7b3 8301
Trying 10.139.117.188...
Connected to m7tenrgate3m7b3.
Escape character is '^]'.
{code}
","09/Sep/21 13:14;cs687;Deployed consul config for new pmi-gateway network segments and also clients on pmi-gateway-servers.
To be on the safe side, *we first paused all m7 test patroni clusters*
{code:java}
[root@m7testpdb1 ~]# sudo su -
Last login: Thu Sep  9 13:14:13 CEST 2021 on pts/0
[root@m7testpdb1 ~]# for config in /etc/patroni_m7*/config.yml; do patronictl -c $config pause; done
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
[root@m7testpdb1 ~]#
{code}

{code:java}
# deploy new network-segment
ansible-playbook playbooks/configure_consul_network_segments.yml -e consul_group_name=consul_energy_shrd_test -e ansible_python_interpreter=/usr/bin/python --limit 'energy-shrd-test-cons*' --diff

# checking if the network segment changed
[root@testcons1.srv.energy /etc/consul/consul.d]# cat network_segments.json 
{
  ""segments"": [
    {
      ""name"": ""m7-test-patroni-cluster"",
      ""bind"": ""{{GetPrivateIP}}"",
      ""port"": 8313
    },
    {
      ""name"": ""xbid-test-patroni-cluster"",
      ""bind"": ""{{GetPrivateIP}}"",
      ""port"": 8314
    },
    {
      ""name"": ""m7a-syt1-rabbitmq-cluster"",
      ""bind"": ""{{GetPrivateIP}}"",
      ""port"": 31001
    },
    {
      ""name"": ""m7a-syt2-rabbitmq-cluster"",
      ""bind"": ""{{GetPrivateIP}}"",
      ""port"": 31002
    },
    {
      ""name"": ""m7t-shrd-ate3-pmi-cluster"",
      ""bind"": ""{{GetPrivateIP}}"",
      ""port"": 32001
    }
  ]
}
{code}

*Deploy on Servers*
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --limit 'energy-shrd-test-cons*' --diff
{code}

*Deploy on all servers and clients*
first listing the hosts which will be touched, afterwards running the deployment:
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --limit 'energy-shrd-test-cons*:m7t*-ate3*pmi*' --diff --list-hosts

  play #1 (consul_energy_shrd_test): Assemble Consul cluster    TAGS: []
    pattern: ['consul_energy_shrd_test']
    hosts (7):
      m7t-shrd-ate3-consul-pmi1
      energy-shrd-test-cons4
      energy-shrd-test-cons5
      energy-shrd-test-cons2
      m7t-shrd-ate3-consul-pmi2
      energy-shrd-test-cons3
      energy-shrd-test-cons1
{code}

*Check the status on consul cluster node*
{code:java}
[root@testcons1.srv.energy consul]# export CONSUL_HTTP_TOKEN=XXXXX

[root@testcons1.srv.energy ~]# consul members
Node                           Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-test-cons1         10.139.130.241:8301  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons2         10.139.130.242:8301  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons3         10.139.130.243:8301  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons4         10.139.130.244:8301  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons5         10.139.130.245:8301  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
m7t-shrd-test-consul-dbr1      10.139.133.221:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-dbr2      10.139.133.222:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-pdb1      10.139.117.253:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-pdb2      10.139.117.254:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7a-shrd-syt1-consul-amq1      10.139.117.227:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7a-syt1-rabbitmq-cluster
m7a-shrd-syt1-consul-amq2      10.139.117.226:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7a-syt1-rabbitmq-cluster
m7a-shrd-syt2-consul-amq1      10.139.117.249:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7a-syt2-rabbitmq-cluster
m7a-shrd-syt2-consul-amq2      10.139.117.245:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7a-syt2-rabbitmq-cluster
m7t-shrd-ate3-consul-pmi1      10.139.117.188:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7t-shrd-ate3-pmi-cluster
m7t-shrd-ate3-consul-pmi2      10.139.117.187:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7t-shrd-ate3-pmi-cluster
xb-xbid-inte-consul-datalake1  10.139.133.253:8301  alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-inte-consul-datalake2  10.139.133.251:8301  alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-inte-consul-dbr1       10.139.133.223:8301  alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-inte-consul-dbr2       10.139.133.224:8301  alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-inte-consul-pdb1       10.139.20.254:8301   alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-inte-consul-pdb2       10.139.20.253:8301   alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-perf-consul-pdb1       10.139.20.248:8301   alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
xb-xbid-perf-consul-pdb2       10.139.20.247:8301   alive   client  1.8.6+ent  2         energy-shrd-test  xbid-test-patroni-cluster
{code}

and we can see the new members are im-place 
{code:java}
m7t-shrd-ate3-consul-pmi1      10.139.117.188:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7t-shrd-ate3-pmi-cluster
m7t-shrd-ate3-consul-pmi2      10.139.117.187:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7t-shrd-ate3-pmi-cluster
{code}

*Finally resuming the maintenance mode for patroni and checking the clusters*
{code:java}
[root@m7testpdb1 ~]# for config in /etc/patroni_m7*/config.yml; do patronictl -c $config resume; done
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
{code}

","09/Sep/21 13:57;cs687;Consul agent installed on m7tenrgate3m7b3/4 
Next step would be to hand it over to DEV and talk about how the path in consul k/v should be specified, that it will not interfere with other´s 
*properly something like this should be working out: /service/pmi/m7/m7t/ate3*

Will inform DEV about the status in the m7_dev channel and close this ticket.","10/Sep/21 07:57;cs687;done",,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: PROD - TC540 - EPEX - Order has timestamp revisions not monotonically increasing,M7P-8799,113577,,Bug,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,dp007,ub113,ub113,09/Aug/21 05:59,16/Sep/21 12:39,16/Sep/21 14:11,16/Sep/21 12:39,,,,,,M7T BE,RE,,,7tops,,,,,,,"Dear DBAG colleagues,

This morning one of our internal checks on the TC540 failed. It seems that order 11699729409 has order revision with timestamps not monotonically increasing.

Here more details:

Initial Order ID: 11699729409
Order ID: 11699737122
Revision PKEY: 2586798569
Revision Nr: 2	
Action Code: D	
Timestamp: 2021-08-07 22:00:07

Best regards,

Jaime
					
",,ub113,vp223,,,,,,,,,,,,,,,,,,SERVICE-10916,,,,,,,,,,,,,,,,,,,,"09/Aug/21 06:31;ub113;epex_TC540_20210808_ADMIN_CXEEXP00.xml.zip;https://jira.deutsche-boerse.com/secure/attachment/98267/epex_TC540_20210808_ADMIN_CXEEXP00.xml.zip",,,,,,,,,,,,,,,sw455,,,,,,,,n/a,,,,,,,,EPEX,,,,,,Report a Non-Critical Incident,,,,,,,,,,3283200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,Communication -> Customer,09/Aug/21 05:46,,[],,,,,,,,None,,,M7T,,,,"2|hzn3ot:r",9223372036854775807,,,,No,,,,,,,,,,issue within the linked tickets and already delivered to prod.,,,,,,,,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113577,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"09/Aug/21 06:30;ub113;[^epex_TC540_20210808_ADMIN_CXEEXP00.xml.zip]","09/Aug/21 09:39;vp223;The fix according to slack conversation should be in * 6.5.29.11*","09/Aug/21 11:15;vp223;This is a known issue, the one described in SERVICE-10546.

The fix is still pending.
---------------------
That known issue Ana Kovacevic (dbg ops) was referring to is already fixed, we even deployed the fix version (RE 6.5.29.14) to your ASIM two weeks ago. The fix version is ready for the Prod tier environment.

I can offer you that we will deploy this version to your Production and we regenerate the TC540 report again. If there will be a problem, we can revert back to the current version RE 6.4.78 at any point of time.

There's no downtime needed for the Reporting Engine deployments.",,,,,,,,,,,,,,,,,,,,,,,,,
Reporting Engine totally oversized regarding Xmx ,M7P-8793,113555,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,cs687,cs687,06/Aug/21 14:25,08/Sep/21 15:16,16/Sep/21 14:11,,,,,,,,,,,7tops,dev,M7PRODOPS,Reporting_Engine,,,,"We noticed not the first time that reporting_engine is crashing with the time or not reachable anymore (*for example for elts-asim today 8/6/2021*)

the following error we saw for rep1:
{code:java}
NON_CLUSTERED_MisfireHandler] ERROR o.s.s.q.LocalDataSourceJobStore - MisfireHandler: Error handling misfires: Failed to obtain DB connection from data source 'springNonTxDataSource.schedulerFactory': java.lang.OutOfMemoryError: Java heap space
{code}
some other I/O Error came up for the second instance:

 
{code:java}
org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:282)
Caused by: org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend.{code}
 

Never the less by analyzing the root cause for rep1 we saw that we have a totally oversized Xmx setting for the host m7shrdexterep1/2 



We should either +increase RAM+ for this machines, better to +reconfigure some Xms/Xmx+ values to proper ones or +outsource+ some instances on the hosts like reporter instances? 

Here the overview about the current setting: 
||Env (both Hosts)||Xms||Xmx||
|plpx-simu-rep1|256m|2700m|
|elts-asim-rep1|256m|2700m|
|xrpm-simu-rep1|256m|2700m|
|hupx-cute-rep1|256m|2700m|
|hupx-asim-rep1|256m|2700m|
|hupx-simu-rep1|256m|2700m|
|xsop-cute-rep1|256m|2700m|
|elts-xsim-rep1|256m|2700m|
|xsop-asim-rep1|256m|2700m|
|xsop-simu-rep1|256m|2700m|
|plpx-cute-rep1|256m|2700m|
|elts-ctpb-rep1|256m|2700m|
|elts-simu-rep1|256m|2700m|
|elts-cute-rep1|256m|2700m|
|xrpm-lipa-rep1|256m|2700m|
|shrd-show-rep1|256m|2700m|
|plpx-lipa-rep1|256m|2700m|
|elts-lipa-rep1|256m|2700m|
|elts-acut-rep1|256m|2700m|
|*total*|*{color:#de350b}4,75g{color}*|*{color:#de350b}50g{color}*|
||Env (both hosts)||Xms||Xmx||
|elts-ctpb-rpr1|128m|1g|
|elts-simu-rep1|128m|1g|
|*total* |{color:#de350b}*256m*{color}|{color:#de350b}*2g*{color}|

The machines have just 24G RAM assigned, seems like they are not heavy under load 

Just 1,92G are in use atm similar to m7shrdexterep2, anyways its idle for the most of the time, when reports will be generated its a different situation and we can run with few instances into heap-space issues. ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3283200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00fov:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113555,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Aug/21 13:14;cs687;needs to be discussed in next m7 dev refinement meeting as soon there is free capacity available. 
first discussion started here: 
[https://dbg-devops.slack.com/archives/G451D1RQB/p1628496718028800]
FYI: [~pn508] [~sJ194]",,,,,,,,,,,,,,,,,,,,,,,,,,,
ansible deployment for CTP WEB (prod),M7P-8769,113477,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,pd122,pd122,04/Aug/21 10:37,10/Aug/21 08:27,16/Sep/21 14:11,,,,,,,ansible,apache,,,7tops,,,,,,,"create production inventory and make sure ansible deployment works properly, fix deployment where needed",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3715200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00f6v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113477,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Customer Portal - Change log not updated with the latest increment,M7P-8729,113307,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,nn236,nn236,29/Jul/21 18:24,13/Aug/21 11:25,16/Sep/21 14:11,30/Jul/21 14:53,,6.12.114,7tops_sprint123,,,Customer Portal,,,,7tops,,,,,,,"It seems that the Change log is not automatically updated with the release of a new increment, which would be the desired behaviour:
 * The latest version in CP is 6.11.263 vs.  the last increment in internal Change log is 6.11.267
 * The latest version in CP is 6.12.99 vs.  the last increment in internal Change log is 6.12.107

This behaviour was observed on the EPEX internal test bucket, may be present on other buckets too.

After a non-expert look into [https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy%2Fm7-product-publish-docs-to-portal/detail/m7-product-publish-docs-to-portal/104/pipeline] it looks like to me that maybe there could be some issue with credentials? Or perhaps it's just a config to turn the automated updates on?",,dp007,nn236,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5187,M7P-7316,M7P-7789,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,deploy-trigger pipeline adjusted,,,,,,,,,,,,,,,,,,,,,,,,4060800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5772,,,,,,,,,,,,,29/Jul/21 18:24,,[],,,,,,,,None,,,M7T,,,,"2|hzn3os:fw",9223372036854775807,,,,No,,,,,,,,,,synchronization issue of the CP deploy-trigger job,,,,,,,,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113307,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,develop,master,true,"30/Jul/21 09:46;dp007;It's s customer portal issue, product pipeline works fine because the increments are presents int the customer portal repository:
[https://github.deutsche-boerse.de/dev/m7.customer.portal/tree/master/change-log/6.11/6.11.267]
[https://github.deutsche-boerse.de/dev/m7.customer.portal/tree/master/change-log/6.12/6.12.107]","30/Jul/21 10:00;dp007;6.11.267
 * 27.07.2021 22:10 - created in CP repository
 * 27.07.2021 22:11 - deploy-trigger pipeline triggered but failed

{code:java}
[Checks API] No suitable checks publisher found.
java.lang.ClassCastException: hudson.model.StringParameterValue.value expects class java.lang.String but received class java.util.ArrayList
	at org.jenkinsci.plugins.structs.describable.DescribableModel.coerce(DescribableModel.java:492)
	at org.jenkinsci.plugins.structs.describable.DescribableModel.buildArguments(DescribableModel.java:409)
	at org.jenkinsci.plugins.structs.describable.DescribableModel.instantiate(DescribableModel.java:329)
Caused: java.lang.IllegalArgumentException: Could not instantiate {name=chl_deploy_bucket, value=[shrd, simu, epextest]} for hudson.model.StringParameterValue{code}
caused by a syntax error in the pipeline definition:

{code:java}
 script { def build_result = build('job': 'Energy-Operations/Customer-Portal/deploy-change-log', parameters: [string(name: 'chl_deploy_bucket', value: ['shrd','simu','epextest'])]) }{code}

6.12.107
 * 13.07.2021 23:25 - created in CP repository
 * the pipeline job history is not available for such an old job execution but I expect the same root cause","30/Jul/21 14:52;dp007;the pipeline synchronization issue was fixed:
 * the trigger job calls deploy-change-log job with a string parameter and with value ALL
 * epex-prod and epex-simu then ignore the job execution as the change-log feature is turned off in their config
 * additional stages introduced in order to synchronize the html content with the updated files (depending on the trigger)


afterwards the job calls _deploy-portal_ job for buckets: _shrd, epex-inttest, simu, prod_ in order to propagate the changes to all affected html sites.

Besides that I activated the change log for prod bucket - the only buckets without the change log are epex-prod and epex-simulation.

Plus, not relevant to the issue itself, but found useful, I enabled 6.12 docu on _epex-inttest_ bucket.",,,,,,,,,,,,,,,,,,,,,,,,,
Capacitor messages for XSOP PROD RE every morning,M7P-8706,113225,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,dp007,dp007,28/Jul/21 11:02,13/Aug/21 11:25,16/Sep/21 14:11,06/Aug/21 09:48,,6.12.118,7tops_sprint123,,,Monitoring,RE,,,7tops,,,,,,,"There are 4 messages in m7_prod_alerts channel every day:
 [!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-large%2F26a0-fe0f.png!|https://app.slack.com/services/B4328NFB5] [kapacitor|https://app.slack.com/services/B4328NFB5]APP  [05:00|https://dbg-devops.slack.com/archives/C941CV942/p1627441200164500]

 WARNING on m7t - southpool - prod | M7 ADMIN TC540 report generation
  
 [!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-large%2F26a0-fe0f.png!|https://app.slack.com/services/B4328NFB5] [kapacitor|https://app.slack.com/services/B4328NFB5]APP  [05:30|https://dbg-devops.slack.com/archives/C941CV942/p1627443000164600]
 OK on m7t - southpool - prod | M7 ADMIN TC540 report generation

[!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-large%2F26a0-fe0f.png!|https://app.slack.com/services/B4328NFB5][kapacitor|https://app.slack.com/services/B4328NFB5]APP  [06:00|https://dbg-devops.slack.com/archives/C941CV942/p1627444800164700]
 WARNING on m7t - southpool - prod | M7 ADMIN TC540 report generation

[!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F13.0%2Fgoogle-large%2F26a0-fe0f.png!|https://app.slack.com/services/B4328NFB5][kapacitor|https://app.slack.com/services/B4328NFB5]APP  [07:30|https://dbg-devops.slack.com/archives/C941CV942/p1627450200164800]
 OK on m7t - southpool - prod | M7 ADMIN TC540 report generation
  
 But the report was generated as expected at 03:41:09 (CEST)
{code:java}
2021-07-28 01:41:09.884 [schedulerFactory_Worker-1] INFO  c.d.e.u.MonitorService - statsD count sent: generation_time; tags=client:xsop,client_environment:prod,platform:southpool,report:TC540,subscriber:ADMIN{code}
{code:java}
2021-07-28 01:41:10.066 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.ReportServiceImpl - Done processing reports for subscriber Subscriber[lastUpdateUser=9999999999999999TRD017,lastUpdateTime=2020-09-25 15:06:52.891,modificationType=SYSTEM_ADD,id=34,charId=MVMTR,type=MEMBER,reports={}]
2021-07-28 01:41:10.066 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.ReportServiceImpl - Finished generating reports for subscribers for platform southpool
2021-07-28 01:41:10.074 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.s.SubscriptionReportGenerationJob - Finished. Total: 6 reports generated.{code}",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,statsD daemon restarted,,,,,,,,Southpool,,,,,,,,,,,,,,,,3542400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,28/Jul/21 11:02,,[],,,,,,,,None,,,M7T,,,,"2|i00dnr:",9223372036854775807,,,,No,,,,,,,,,,statsD daemon restarted,,,,,,,,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113225,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"28/Jul/21 11:14;dp007;the statsd section of the RE config is correct, also compared with HUPX prod
{code:java}
statsd.enabled=True
statsd.host=localhost
statsd.port=8125
statsd.client=xsop
statsd.client_environment = prod
statsd.prefix=m7_rep
statsd.suffix=
statsd.module=
statsd.reportdate=False
statsd.members=ADMIN
statsd.reports=TC540,TC810,TC820,TC840 {code}","03/Aug/21 14:46;dp007;statsd daemon restarted","06/Aug/21 09:46;dp007;There are no new messages in m7_prod_alerts channel pointing to the southpool prod reporting engine, closing the ticket.",,,,,,,,,,,,,,,,,,,,,,,,,
Fix M7P deployment job to be able handle downgrades,M7P-8700,113187,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,,op211,ax460,ax460,27/Jul/21 15:37,16/Sep/21 11:47,16/Sep/21 14:11,,,,,,,,,,,7tops,deployment,,,,,,"Note [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/1221/consoleFull] deployment failed to stop Throtttler component within deployment of 6.11.265

But Throttler is not part of M7Product in version 6.11.265 as you can see in 
 [https://artifactory.dbgcloud.io:443/artifactory/eex-dev-local/com/deutscheboerse/energy/m7/m7-product/m7p-reports/6.11.265/m7p-reports-6.11.265-components.yml|https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/m7/m7-product/m7p-reports/6.11.265/m7p-reports-6.11.265-components.yml]
 But since Throttler is already defined in [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/shrd/ate3/throttler/main.yml] (since we have been deploying 6.12 to ATE3 already) deployment job fails.

 Same applies for PMI and all other components defined in 6.12

Deployment job should be able to handle this downgrade situation
 * new component is defined in inventory
 * 6.12 is deployed
 * 6.11 is deployed without any failures

The question is what should we do with the running component during 6.11 deployment. Imho stop it *if its running*. ",,ax460,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8954,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,691200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmqev:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113187,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"27/Jul/21 15:39;ax460;Note that this request would help us to not forget to merge any PR in inventory. Now we have some PR pending eg. [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2785] because we assumed that it might break deployment of 6.11 to customer environemtns.","02/Sep/21 15:11;pd122;Looking at the attached output it looks to me that throttler deployment failed not because it failed to stop the instance but because it failed to fetch the artifact (version not defined):
{code:java}
Fetching artifact info failed: Fetching url https://artifactory.dbgcloud.io/artifactory/api/storage/eex-dev-local/com/deutscheboerse/energy/m7/throttler/null/throttler-null.zip failed. {code}","02/Sep/21 15:19;pd122;Proper solution I think would be not to run module's deployment if the version is not defined.  My suggestion would be to update jenkins pipeline(s) to only run particular module deployment if its version is defined.  Currently, the only condition is instance's presence in the inventory.","02/Sep/21 15:34;ax460;[~pd122] right it was not stop but deplyo. Correct we should not run unknown component deployment during deployment of product. Feel free to update deployment job. But note the situation in description - in case of downgrade we might want to stop component if it was running. To ensure whole environment is consistent.","02/Sep/21 16:14;pd122;How about just stopping the component separately before downgrading (this functionality is already there/accessible I believe).  Additionally, would there be any adverse effects if the component kept running?  If yes, what could they be?  How often would that be used ?  Just trying to understand how important/needed is the functionality requested as I suspect it may not be trivial to implement. ","02/Sep/21 16:39;ax460;Yes running additional stop job before downgrading is possible but not really convenient especially for testers. Ideally you should not care what version was deployed before you run deployment job. And downgrades are very often when testing in final stage of delivery eg. 6.11 and already started development of 6.12.

The effect of keeping component running is not really predictable and that why its unwanted. But I can give you a blocker example. Core used to have exclusive consumer in 6.11, in 6.12 its was moved to PMI GW. You cant run two component with exclusive AMQP consumer at the same time. That means you can have running PMI GW (from 6.12) while deploying older core 6.11","08/Sep/21 11:56;ax460;Agreed on planing to fix deployment bug originally described. A not improve deployment (stopping components). We will stop component manually in case of downgrade. And create new ticket in case it show up that this approach is inconvenient.",,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: M7 - ASIM - Product deletion (Hibernated After Market products),M7P-8698,113177,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,27/Jul/21 13:13,13/Aug/21 11:25,16/Sep/21 14:11,02/Aug/21 09:10,,6.12.114,7tops_sprint123,,,Database,M7T BE,,,7tops,,,,,,,"Hello all,

Could you please delete the following products in ASIM environment:

-After_Market_Hour_Power
-After_Market_Quarter_Hour_Power

which are now hibernated?

The reason for this request is that we don't want M7 to generate contracts for these Hibernated contracts. We want ASIM and PROD setup to be identical. Currently we receive errors in DTT ASIM because we don't expect those contracts to be generated.

Deleting these 2 products is the best solution for use. However if you have an alternative solution please let us know.

Ideally we like the modification to be made within the next 2 weeks.

Can you do that without cleaning the database? 

Thank you,
Kind regards,
Theo",,dp007,fp407,pn508,,,,,,,,,,,,,,,,,SERVICE-10851,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,both products set to ADEL,,,,,,,,EPEX,,,,,,Report a problem or bug,,,,,,,,,,3888000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00ddz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113177,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"27/Jul/21 13:13;dp007;TODO: Please check if setting the products to ADEL will resolve the issue.","27/Jul/21 15:58;fp407;It seems that contracts are being generated for ADEL products in ELTS/PROD and there's no complains regarding DTT prod: https://jira.deutsche-boerse.com/browse/M7P-7505

Cleaning the database would of course be the best solution, but there are concerns about consistency as there's no standard procedure to delete product master data.","28/Jul/21 13:25;pn508;No additional effort will be announced due to M7P-7505

Hi XXX,

The respective ticket is waiting for further prioritization, in case if you would like to speed up the implementation process, kindly prioritize the ticket among other minor tickets as per EPEXMT-2634 or request extended additional support in line with the contract.

Thanks and Regards,
 XXX","28/Jul/21 13:30;dp007;Please, before taking any action, follow the external SERVICE jira, EPEX needs to discuss internally the proposed solution I gave them in SERVICE-10851:

_Yes, I understand, when you clarify this topic internal, we'll execute the following:_
 # _stop the environment,_
 # _set those two products into ADEL and_
 # _start the environment back._

_~15 minutes downtime._","02/Aug/21 08:56;dp007;Deployment ongoing, executing the following update:
{code:java}
update cx_200_product set mod_type_code='ADEL' where product_long_name in ('After_Market_Hour_Power','After_Market_Quarter_Hour_Power'); {code}","02/Aug/21 09:09;dp007;Both products as requested in SERVICE-9547, closing the ticket.",,,,,,,,,,,,,,,,,,,,,,
update patroni config SIMU-STAGING,M7P-8690,113153,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,27/Jul/21 08:02,08/Sep/21 09:06,16/Sep/21 14:11,10/Aug/21 08:28,,7tops_sprint123,,,,,,,,Database,M7PRODOPS,,,,,,"*needs to be started, after we are done with M7P-8689*

XBOPS made some few changes for the patroni role and also polished the inventory db-settings. 

we improved our patroni playbook with 2 new tags: 
 * configure (which will update new changes in the patroni config without touching it manually on one of the cluster-nodes, proper inventory changes needs to be prepared for that)

{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t-shrd-syt3-pdb-async*"" -k -K --tags configure --diff  {code}
afterwards when we see some changes which require a restart of the patroni nodes, we need to use an additional tag to complete it.
{code:java}
TASK [patroni : Output pending restart] **********************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-syt3-pdb-async1] => {}MSG:Restart pending: 'True'ok: [m7t-shrd-syt3-pdb-async2] => {}MSG:Restart pending: 'True'* {code}
 * use pending_restart to restart patroni nodes to refresh the updated config (if necessary!)
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t-shrd-syt3-pdb-async*"" -k -K --tags restart_pending --diff{code}

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1674/files]
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2876/files]

We need to run this +configure tag+ for all the test db-instances and have to precisely check the output, so better to run it with diff and check mode first. 

Ones this is done we have to complete it for SIMU and PROD instances as well!

 ",,cs687,,,,,,,,,,,,,,,,,M7P-8691,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"all patroni-cluster were updated with the default patroni configuration. 

required restart was proceed ",,,,,,,,,,,,,,,,,,,,,,,,3196800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|i00d8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,see previous tickets and comments ,,,,,,,,,,"{""issueId"":113153,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Aug/21 07:08;cs687;*The Following Cluster needs to be updated:*

patroni_m7axeercutesync/ (/) 8/6/2021
 patroni_m7aamprcutesync/ (/) 8/6/2021
 patroni_m7axeersimusync/ (/) 8/10/2021
 patroni_m7aamprsimusync/ (/) 8/10/2021
 patroni_m7axeerasimsync/  (/) 8/10/2021

patroni_m7teltsacutasync/ (/) 8/6/2021
 patroni_m7teltslipaasync/ (/) 8/6/2021
 patroni_m7teltsasimasync/ (/) 8/10/2021
 patroni_m7teltssimuasync/ (/) 8/10/2021
 patroni_m7teltsctpbasync/ (/) 8/6/2021
 patroni_m7teltsxsimasync/ (/) 8/6/2021
 patroni_m7teltscuteasync/ (/) 8/6/2021

patroni_m7thupxcuteasync/ (/) 8/6/2021
 patroni_m7thupxsimuasync/ (/) 8/10/2021
 patroni_m7thupxasimasync/ (/) 8/10/2021

patroni_m7tplpxsimuasync/ (/) 8/10/2021
 patroni_m7tplpxcuteasync/ (/) 8/6/2021
 patroni_m7tplpxlipaasync/ (/) 8/6/2021

patroni_m7txrpmlipaasync/ (/) 8/6/2021
 patroni_m7txrpmsimuasync/ (/) 8/10/2021

patroni_m7txsopsimuasync/ (/) 8/10/2021
 patroni_m7txsopasimasync/ (/) 8/10/2021
 patroni_m7txsopcuteasync/ (/) 8/6/2021

patroni_m7tshrddst1async/ (/) 8/5/2021 (deactivated archiving) 

patroni_m7cicsccuteasync/ (/) 8/10/2021
 patroni_m7cshrddst1async/ (/) 8/5/2021 (deactivated archiving) 

patroni_m7tshrdexteasync/ (/) 8/5/2021

patroni_m7tshrdshowasync/ (/) 8/5/2021","10/Aug/21 08:28;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate PowerBI SLA reports to SharePoint,M7P-8680,113096,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,23/Jul/21 13:43,26/Aug/21 09:29,16/Sep/21 14:11,16/Aug/21 15:10,,7tops_sprint124,,,,EBSM,,,,7tops,M,,,,,,As the S drive is going to be decommissioned by the mid of August we need to migrate the SLA reports to Share Point.,,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,reports migrated to SP,,,,,,,,,,,,,,,,,,,,,,,,2592000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00dga:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":113096,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/21 15:10;dp007;reports migrated from S drive to SP: 
{code:java}
https://bluebook.deutsche-boerse.de/sites/sp0232/SP - Energy/10 KPI & SLA Reporting/02) Service Level Reporting/generate/
{code}
Report file names unified in the following way: _product_customer_environment.pbix_
 for example: m7t_xrpm_prod.pbix

main CSV folder
{code:java}
https://bluebook.deutsche-boerse.de/sites/sp0232/SP - Energy/10 KPI & SLA Reporting/02) Service Level Reporting/generate/CSV/
{code}
[https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?id=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2Fgenerate]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
OPS: out of memory in db,M7P-8670,113068,112877,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,pw231,pw231,22/Jul/21 15:52,28/Jul/21 10:34,16/Sep/21 14:11,22/Jul/21 16:45,,7tops_sprint122,,,,,,,,7tops,OPS,,,,,,"h4. Problem - elts CTPB, 19.7.

Since 10:20:14.837 :
{code}
 - org.postgresql.util.PSQLException: ERROR: out of memory
  Detail: Failed on request of size 40 in memory context ""MessageContext""
{code}
Database replied that to both cores several times. 

Since 10:27:22.568 both Persister's (cor1 and cor2) frozen.

Only at 
{code}
 10:52:17.344	FATAL: terminating connection due to administrator command
{code}

See https://kibana.energy.svc.dbgcloud.io/goto/857cf5a4e64c6a9302cfca39c223aa9d

Both cores were frozen for several minutes since the Persister was blocked.

h4. Task
What happened with the db?
Make sure it does not happen in production.",,op211,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4752000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00cqf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 122 (PS),Schmetterling Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113068,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/21 16:42;op211;Yes, it's known issue and already fixed. We reduced shared buffers for all DBs except ELTS ASIM to 2GB. The two new environments PLPX CUTE and ELTS XSIM were to much for the 128g memory.","22/Jul/21 16:45;op211;Production is safe, because we don't have so many instances running there.",,,,,,,,,,,,,,,,,,,,,,,,,,
ansible deployment for CTP WEB (exte),M7P-8668,113061,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pd122,pd122,22/Jul/21 14:07,13/Aug/21 11:25,16/Sep/21 14:11,04/Aug/21 10:34,,6.12.114,7tops_sprint123,,,ansible,,,,7tops,S,,,,,,complete inventory and make sure ansible deployment works properly for external test environments,,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8769,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,both CTP ansible template and as well as inventory were updated and external test profiles successfully deployed,,,,,,,,,,,,,,,,,,,,,,,,3715200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00dgc:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":113061,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"22/Jul/21 14:08;pd122;extending on the work done for internal tests in [M7P-6604]","02/Aug/21 10:07;pd122;PRs:
 * https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1701
 * [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2929]","03/Aug/21 15:41;pd122;both PRs merged, internal profile web servers re-deployed in https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/11897/console","03/Aug/21 16:23;pd122;external environments deployed:

- https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/11902/console

- https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/11904/console",,,,,,,,,,,,,,,,,,,,,,,,
repointing log4j.properties to proper directory (KAFKA-CLUSTER) ,M7P-8667,113060,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,22/Jul/21 13:50,05/Aug/21 13:24,16/Sep/21 14:11,26/Jul/21 08:49,,6.12.114,7tops_sprint122,,,,,,28/Jul/21 00:00,Kafka,M7PRODOPS,,,,,,"We need to run kafka ansible deployment for broker instances in 
* m7t-shrd-inte (/) fixed -> 7/22/2021
* m7t-shrd-exte (/) fixed -> 7/23/2021 + Version upgrade 
* m7t-elts-asim (/) fixed -> 7/23/2021 
* m7t-shrd-prod double check with BO, planned for Monday) (/)

{code:java}
[cs687@m7shrdprodkbr1 ~]$ ps -ef | grep kafka
cp-kafka  53157      1  1 Jul20 ?        00:33:53 java -Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/shrd/logs/kafka/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/shrd/logs/kafka -Dlog4j.configuration=file:/etc/kafka/log4j.properties -cp /usr/bin/../share/java/kafka/*:/usr/bin/../share/java/confluent-telemetry/* -Djava.security.auth.login.config=/shrd/kafka/config/kafka_server_jaas.conf kafka.Kafka /shrd/kafka/config/server.properties
{code}

for *-Dlog4j.configuration=file:/etc/kafka/log4j.properties* we need to link/point it to /shrd/kafka/config | /elts/kafka/config 

It was proofed that the ansible playbook is fixing all this things, we need to deploy broker node by node seamlessly. 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"redeployed broker and part of zookeeper for m7t-shrd-inte, m7t-shrd-exte, m7t-shrd-prod and also m7t-elts-asim kafka cluster 

double checked the started processes with Dlog4j.configuration path 
{code:java}
Dlog4j.configuration=file:/shrd/kafka/config/log4j.properties
{code}

everything is pointing to the proper path´s.
double checked Kafka status page in grafana and double checked the application health-check afterwards. ",,,,,,,,,,,,,,,,,,,,,,,,4492800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00con:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":113060,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/21 11:15;cs687;h2. +*m7t-shrd-exte Kafka Cluster*+
*deployed zookeeper*: m7tshrdextekzk1/2/3 (/)
with parameter ""* -e update_operation=true*"" to skip the yum commands for package installation
{code:java}
ansible-playbook playbooks/kafka/deploy_cluster.yml -l m7t-shrd-exte-kafka-zookeeper-1 -t confirm_operation -e av_product=m7t -e av_customer=shrd -e av_env=exte -e update_operation=true -b -K -k --diff
{code}

{code:java}
[root@m7tshrdextekzk1 ~]# /usr/bin/kafka-run-class org.apache.zookeeper.client.FourLetterWordMain localhost 2181 mntr
zk_version      3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT
zk_avg_latency  2
zk_max_latency  5
zk_min_latency  0
zk_packets_received     28
zk_packets_sent 27
zk_num_alive_connections        1
zk_outstanding_requests 0
zk_server_state follower
zk_znode_count  860
zk_watch_count  0
zk_ephemerals_count     4
zk_approximate_data_size        145089
zk_open_file_descriptor_count   134
zk_max_file_descriptor_count    500000
{code}

afterwards checked that zookeeper is running +as follower+

and checking the process for this 
{code:java}
 -Dlog4j.configuration=file:/shrd/zookeeper/config/log4j.properties
{code}

*deployed broker:* m7tshrdextekbr1/2/3 (/)
{code:java}

Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: [2021-07-23 11:43:13,039] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes...0, maxBytes=10485
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: java.io.IOException: Connection to 3 was disconnected before the response was read
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:110)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:211)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:301)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:136)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:135)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:118)
Jul 23 11:43:13 m7tshrdextekbr1 kafka-server-start[40784]: at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)

# after getting this exceptions we added the two lines


# added this lines in server.properties file and restarted broker
inter.broker.protocol.version=2.5
log.message.format.version=2.5
{code}


need to do an additional step by removing all old confluent packages and re-running the playbook with yum installation.  ","23/Jul/21 13:25;cs687;h2. +*m7t-elts-asim Kafka Cluster*+

deployed node by node *broker and zookeeper*

zookeeper are pointing to the proper path
{code:java}
cp-kafka  78268      1  1 13:29 ?        00:00:02 java -Xmx8g -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/elts/logs/zookeeper/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/elts/logs/zookeeper -Dlog4j.configuration=file:/elts/zookeeper/config/log4j.properties -cp /usr/bin/../share/java/kafka/*:/usr/bin/../share/java/confluent-telemetry/* -Djava.security.auth.login.config=/elts/zookeeper/config/zookeeper_server_jaas.conf org.apache.zookeeper.server.quorum.QuorumPeerMain /elts/zookeeper/config/zookeeper.properties
{code}

","26/Jul/21 08:44;cs687;h2. +*m7t-shrd-prod Kafka Cluster*+

deployed node by node *broker*
","26/Jul/21 08:49;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Kafka-Cluster deployment ELTS-PROD (ansible) ,M7P-8666,113059,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,22/Jul/21 13:44,13/Aug/21 11:25,16/Sep/21 14:11,30/Jul/21 10:20,,6.12.114,7tops_sprint123,,,,,,28/Jul/21 00:00,Kafka,M7PRODOPS,,,,,,"we need for the planned deployment on 17th of August Kafka Cluster in ELTS-PROD 

We have to check:
* prepared filesystems
* log4j.properties pointing to the proper directory 
* log4j.properties check MaxFileSize & Rotation 

https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/playbooks/kafka/docs/KAFKA_OVERVIEW_AND_INSTALLATION.md

Deployment via Ansible:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Kafka/job/deploy-cluster/",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed kafka cluster for elts-prod with ansible playbook on following hosts:  
* m7eltsprodkzk1
* m7eltsprodkzk2
* m7eltsprodkzk3
* m7eltsprodkzk4
* m7eltsprodkzk5
* m7eltsprodkzk6

* m7eltsprodkbr1
* m7eltsprodkbr2
* m7eltsprodkbr3
* m7eltsprodkbr4

also deployed monitoring clients and proper elts-prod topics and users.
everything was double checked by Miroslav and AlexO. ",,,,,,,,ELTS,,,,,,,,,,,,,,,,4147200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00cof:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":113059,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"26/Jul/21 10:37;cs687;h1. +*cleaned up old installation:*+

*1.)* stopped confluent-kafka.service & confluent-zookeeper.service

*2.)* removed old package installation on zookeeper and broker hosts
{code:java}
[root@m7eltsprodkbr1 kafka]# yum list installed | grep confluent*
confluent-kafka-2.11.noarch 5.4.2-1 @DBG_Energy_Global_CONFLUENT_Confluent-5_4
{code}
{code:java}
==============================================================================================================================================================================================
 Package Arch Version Repository Size
==============================================================================================================================================================================================
Removing:
 confluent-kafka-2.11 noarch 5.4.2-1 @DBG_Energy_Global_CONFLUENT_Confluent-5_4 71 M
Transaction Summary
==============================================================================================================================================================================================
Remove 1 Package
Installed size: 71 M
Is this ok [y/N]: y
{code}
*3.)* removed old deployed config files
{code:java}
[root@m7eltsprodkbr1 kafka]# rm -rf /etc/kafka/ {code}
*4.)* cleaning up old logfiles in /var/log/kafka

*5.)* during installation we found out that we have docker running for m7eltsprodkzk6
{code:java}
[root@m7eltsprodkzk6 ~]# du -sh /var/lib/docker*
8.0G    /var/lib/docker
4.0K    /var/lib/docker-engine{code}
removed docker package and also /var/lib/docker ","26/Jul/21 10:52;cs687;Deployed the cluster like it is described here: 

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/playbooks/kafka/docs/KAFKA_OVERVIEW_AND_INSTALLATION.md]

*deployed newer kafka version 6.1.1-1 on zookeeper and broker hosts* (/)
{code:java}
[root@m7eltsprodkzk1 kafka]# yum list installed | grep confluent*
confluent-cli.x86_64               6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-common.noarch            6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-control-center.noarch    6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-control-center-fe.noarch 6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-hub-client.noarch        6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-kafka.noarch             6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-kafka-connect-replicator.noarch
confluent-kafka-mqtt.noarch        6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-kafka-rest.noarch        6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-ksqldb.noarch            6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-platform.noarch          6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-rebalancer.noarch        6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-rest-utils.noarch        6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-schema-registry.noarch   6.1.1-1                   @DBG_Energy_Global_CONFLUENT_Confluent-6_1
confluent-telemetry.noarch         1:6.1.1-1                 @DBG_Energy_Global_CONFLUENT_Confluent-6_1
{code}

pull-request is still necessary for broker and zookeeper deployment 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1692/files#diff-e66ce9e66061c5897db0cc05b01c42461fe81121237a948a98d2f9ebed4c749cR42
these changes were done manually before. 
","27/Jul/21 09:11;cs687;h1. Cluster Validation: 
All 4 Brokers are visible for zookeeper
{code:java}
[root@m7eltsprodkzk1 ~]# zookeeper-shell localhost:2181 ls /brokers/ids
Connecting to localhost:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[1, 2, 3, 4]
{code}
1 Master Zookeeper and 4 Follower are detected: 
{code:java}
m7t-elts-prod-kafka-zookeeper-1 | SUCCESS | rc=0 >>
Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
Latency min/avg/max: 0/1/8
Received: 196
Sent: 195
Connections: 2
Outstanding: 0
Zxid: 0x20000010e
Mode: follower
Node count: 57

m7t-elts-prod-kafka-zookeeper-4 | SUCCESS | rc=0 >>
Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
Latency min/avg/max: 0/0/7
Received: 222
Sent: 227
Connections: 1
Outstanding: 0
Zxid: 0x20000010e
Mode: follower
Node count: 57

m7t-elts-prod-kafka-zookeeper-2 | SUCCESS | rc=0 >>
Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
Latency min/avg/max: 0/0/6
Received: 90
Sent: 89
Connections: 2
Outstanding: 0
Zxid: 0x20000010e
Mode: follower
Node count: 57

m7t-elts-prod-kafka-zookeeper-5 | SUCCESS | rc=0 >>
Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
Latency min/avg/max: 0/0/2
Received: 331
Sent: 330
Connections: 4
Outstanding: 0
Zxid: 0x20000010e
Mode: leader
Node count: 57
Proposal sizes last/min/max: 32/32/327

m7t-elts-prod-kafka-zookeeper-3 | SUCCESS | rc=0 >>
Zookeeper version: 3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
Latency min/avg/max: 0/0/6
Received: 361
Sent: 362
Connections: 4
Outstanding: 0
Zxid: 0x20000010e
Mode: follower
Node count: 57
{code}

*elts-FS* is in use for config and log´s 
{code:java}
[root@m7eltsprodkbr1 kafka]# ps -ef | grep kafka
cp-kafka 22056     1  3 09:03 ?        00:00:12 java -Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/elts/logs/kafka/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/elts/logs/kafka -Dlog4j.configuration=file:/elts/kafka/config/log4j.properties -cp /usr/bin/../share/java/kafka/*:/usr/bin/../share/java/confluent-telemetry/* -Djava.security.auth.login.config=/elts/kafka/config/kafka_server_jaas.conf kafka.Kafka /elts/kafka/config/server.properties

[root@m7eltsprodkbr1 kafka]# ls -all /elts/logs/kafka/
total 108
drwxr-xr-x 3 cp-kafka confluent  4096 Jul 27 09:03 .
drwxr-xr-x 4 cp-kafka confluent  4096 Jul 22 12:23 ..
-rw-r--r-- 1 cp-kafka confluent  5890 Jul 27 09:08 controller.log
-rw-r--r-- 1 cp-kafka confluent   270 Jul 27 09:03 jolokia.out
-rw-r--r-- 1 cp-kafka confluent     0 Jul 27 09:03 kafka-authorizer.log
-rw-r--r-- 1 cp-kafka confluent     0 Jul 27 09:03 kafka-request.log
-rw-r--r-- 1 cp-kafka confluent  1920 Jul 27 09:03 kafkaServer-gc.log
-rw-r--r-- 1 cp-kafka confluent  1125 Jul 27 09:03 kafkaServer-gc.log.0
-rw-r--r-- 1 cp-kafka confluent   172 Jul 27 09:03 log-cleaner.log
drwx------ 2 root     root      16384 Jul 22 12:23 lost+found
-rw-r--r-- 1 cp-kafka confluent 53948 Jul 27 09:03 server.log
-rw-r--r-- 1 cp-kafka confluent   459 Jul 27 09:03 state-change.log



cp-kafka  7461     1  0 Jul26 ?        00:01:54 java -Xmx8g -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xloggc:/elts/logs/zookeeper/zookeeper-gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/elts/logs/zookeeper -Dlog4j.configuration=file:/elts/zookeeper/config/log4j.properties -cp /usr/bin/../share/java/kafka/*:/usr/bin/../share/java/confluent-telemetry/* -Djava.security.auth.login.config=/elts/zookeeper/config/zookeeper_server_jaas.conf org.apache.zookeeper.server.quorum.QuorumPeerMain /elts/zookeeper/config/zookeeper.properties

[root@m7eltsprodkzk1 ~]# ls -all /elts/logs/zookeeper/
total 88
drwxr-xr-x 2 cp-kafka confluent  4096 Jul 26 11:04 .
drwxr-xr-x 4 cp-kafka confluent  4096 Jul 26 11:04 ..
-rw-r--r-- 1 cp-kafka confluent  9811 Jul 27 07:13 zookeeper-gc.log.0.current
-rw-r--r-- 1 cp-kafka confluent 67937 Jul 27 09:09 zookeeper.log
{code}","27/Jul/21 09:14;cs687;h1. Deployed monitoring clients for zookeeper/broker hosts 
needs to be double checked by [~iu252]","27/Jul/21 09:17;cs687;h1. prepared credentials for elts-prod deployment 

triggered: setup-application-entities
needs to be double checked by [~nz893]","28/Jul/21 08:25;cs687;h1. Zookeeper stability test with zookeeper-6

stopped 3 Kafka nodes in DC1 
* m7eltsprodkzk1
* m7eltsprodkzk3
* m7eltsprodkzk5

Afterwards the cluster crashed with *two running nodes*.
After *starting m7eltsprodkzk6* it was complaining about 
{code:java}
Jul 30 09:13:26 m7eltsprodkzk6 zookeeper-server-start[15947]: 2021-07-30 09:13:26,484 [myid:6] - INFO  [main:Login@302] - QuorumLearner successfully logged in.
Jul 30 09:13:26 m7eltsprodkzk6 zookeeper-server-start[15947]: 2021-07-30 09:13:26,485 [myid:6] - ERROR [main:QuorumPeerMain@101] - Unexpected exception, exiting abnormally
Jul 30 09:13:26 m7eltsprodkzk6 zookeeper-server-start[15947]: java.lang.RuntimeException: My id 6 not in the peer list
{code}

also changing the Myid file in data-FS and restarting service for following zookeepers
* m7eltsprodkzk2 -> myid1 
* m7eltsprodkzk4 -> myid3
* m7eltsprodkzk6 -> myid5 

.... was not making the trick. 
{code:java}
Jul 30 09:53:16 m7eltsprodkzk6 zookeeper-server-start[24314]: at java.net.PlainSocketImpl.socketBind(Native Method)
Jul 30 09:53:16 m7eltsprodkzk6 zookeeper-server-start[24314]: at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:387)
Jul 30 09:53:16 m7eltsprodkzk6 zookeeper-server-start[24314]: at java.net.ServerSocket.bind(ServerSocket.java:375)
Jul 30 09:53:16 m7eltsprodkzk6 zookeeper-server-start[24314]: at java.net.ServerSocket.bind(ServerSocket.java:329)
Jul 30 09:53:16 m7eltsprodkzk6 zookeeper-server-start[24314]: at org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener.run(QuorumCnxManager.java:931)
Jul 30 09:53:17 m7eltsprodkzk6 zookeeper-server-start[24314]: 2021-07-30 09:53:17,458 [myid:5] - INFO  [m7eltsprodkzk5/10.139.53.145:3888:QuorumCnxManager$Listener@973] - Leaving listener
Jul 30 09:53:17 m7eltsprodkzk6 zookeeper-server-start[24314]: 2021-07-30 09:53:17,458 [myid:5] - ERROR [m7eltsprodkzk5/10.139.53.145:3888:QuorumCnxManager$Listener@975] - As I'm leaving the listener thread after 3 errors. I won't be able to participate in leader election any longer: 10.139.53.145:3888. Use zookee...
Jul 30 09:53:17 m7eltsprodkzk6 systemd[1]: confluent-zookeeper.service: main process exited, code=exited, status=14/n/a
Jul 30 09:53:17 m7eltsprodkzk6 systemd[1]: Unit confluent-zookeeper.service entered failed state.
Jul 30 09:53:17 m7eltsprodkzk6 systemd[1]: confluent-zookeeper.service failed.
Hint: Some lines were ellipsized, use -l to show in full.
{code}

We have to investigate in a dedicated ticket a proper workaround, what needs to be done ones DC1 will fully crash. 
","30/Jul/21 10:20;cs687;done
Open Point with zookeeper-6 tests will be handled in ticket 
https://jira.deutsche-boerse.com/browse/M7P-8730",,,,,,,,,,,,,,,,,,,,,
migrate englobauto1 & enprodauto1 to new servers,M7P-8652,112948,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,rehapav,rehapav,20/Jul/21 11:07,03/Aug/21 08:26,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"*Description:* 

As a consequence of discussion within SYSENGINT-641 where we are resolving 

VMT Finding: AA13 Ensure SSH MaxAuthTries is set to 4 or less

It was agreed that we need to migrate from old and start using new servers for jenkins:

*Old servers in use*
 * englobauto1:10.139.54.246
 * enprodauto1:10.139.54.214

*New servers*

Infrastructure-wise (from SysEng side) the networking and VMs are long time ready for migrating the current Energy Jenkins setup from ""englobjci1/englobauto1"" to a distributed agent model with 4 hosts in the new network zones:
 * jenkins.srv.energy    (new Jenkins master in the Energy ""secure"" Service Zone)
 * prodjag1.srv.energy (production Jenkins Agent)
 * simujag1.srv.energy (simulation Jenkins Agent)
 * testjag1.srv.energy (test Jenkins Agent)

*Acceptance criteria*
 * All the necessary services (Jenkins?) are migrated from old to new hosts
 * old hosts are decomissioned

FYI: [~cv179] ",,cv179,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3801600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:q",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112948,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Aug/21 08:26;cv179;Migration to new servers will not solve the maxAuthRetries ""issue"". Any other reason to migrate? If not, we can call it off I think.

I just challenged the security requirement on this setting. But besides that, we can find a ssh config setting for jenkins so we CAN reduce the setting using the existing servers.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Activity report emails over 15MB do not arrive to EPEX,M7P-8649,112893,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,dp007,dp007,19/Jul/21 13:44,13/Aug/21 11:25,16/Sep/21 14:11,29/Jul/21 11:01,,6.12.114,7tops_sprint123,,,EBSM,,,,EBSM,M7PRODOPS,,,,,,"As reported many times in SERVICE-10166 the activity report emails over 15MB do not arrive to EPEX due to DBG company wide policies on the outgoing mail server.

Therefore we need to split the attached zip file and send multiple emails.",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,splitting the reports into multiple emails (per 13MB),,,,,,,,ELTS,,,,,,,,,,,,,,,,4233600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,19/Jul/21 13:44,,[],,,,,,,,None,,,M7T,,,,"2|i00bon:",9223372036854775807,,,,No,,,,,,,,,,mail server does not let in emails bigger than 15MB,,,,,,,,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":112893,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"22/Jul/21 15:53;dp007;The main DBG mail server deletes the split archives, meaning instead of the original attachment (for instance AP_raw-data-2021-07-19.zip) the email contains an attachment added by the mail server, in our case AP_raw-data-2021-07-19.zip.txt and inside it says: _This attachment was removed._ Also when the split archives is zipped again, or even renamed and zipped again.

On the other hand EPEX's mailserver accepts split archives (tested with Juan Francisco Fernandez from EPEX). 

Resolution of the problem:
 * The archives will be split only if they reach a critical size (13MB?), such report will be accepted by EPEX, if needed, DBG will get the report directly from EBSM.
 * LogParser config will be enhanced by a new integer parameter _compressDataFileSize_ indicating the byte size when the split will be applied (10485760=10MB; 13631488=13MB).

The updated LogParser script will be deployed tomorrow to all DPU hosts.","29/Jul/21 11:00;dp007;LogParser updated on all three instances: testdpu, simudpu, proddpu.",,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD: 12.7. and 15.7. at 03:03:23 - Journal was blocked for 50sec - OPS analyses,M7P-8641,112836,112829,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pw231,pw231,16/Jul/21 13:27,24/Aug/21 13:05,16/Sep/21 14:11,09/Aug/21 09:14,,7tops_sprint123,,,,,,,,6.11_Blocker,7tops,M7PRODOPS,OPS,,,,"Based on information revealed in M7P-8640, we can state that in two different days (12.7. and 15.7. ), at the very same time (03:03:23), something blocked Journaller for 50 seconds.

Suspects are :  
- network
- glusterfs
- ESX hypervisor

Is there some maintenance scheduled in this time on these services?
Eitherway, please analyze the logs on these particular days and time to gather more information.",,cs687,pd122,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-854,,,,,M7P-8877,SERVICE-10503,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3283200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00bc7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 123 (PS),Magnificent 7 Sprint 124 (PS),Magnificent 7 Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112836,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jul/21 13:44;pw231;11.7. and 13.7., same time, same issue, only cca 20 seconds delay","19/Jul/21 10:38;pw231;*UPDATE*: [it happened again over the weekend|https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&var-host=m7eltsprodm7c1%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-interval=10m&var-exchangeId=EPEX&from=1626479588000&to=1626574502000&fullscreen&panelId=3] and this time *the processing times were over 1.5 minute* and at the same very time.

it is getting very problematic now...","19/Jul/21 11:19;pd122;glusterfs logs excerpts from the past week (m7prodpdb[1-4]):

 
{code:java}
pdb1:
[2021-07-11 01:19:01.519155] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-11 01:19:01.512554] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-16 01:24:01.900118] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-16 01:24:01.906343] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing

===
pdb2:
[2021-07-11 01:15:01.545600] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-13 01:42:01.540870] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-13 01:42:01.543545] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-18 01:47:01.163576] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-18 01:47:01.165590] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing

===
pdb3:
[2021-07-13 01:09:01.355524] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-13 01:09:01.354234] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-13 01:09:01.355698] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-18 01:40:01.185267] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-18 01:40:01.186297] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing

===
pdb4:
[2021-07-11 01:10:02.032052] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
[2021-07-18 01:31:01.565114] I [MSGID: 100011] [glusterfsd.c:1438:reincarnate] 0-glusterfsd: Fetching the volume file from server...
[2021-07-18 01:31:01.570488] I [glusterfsd-mgmt.c:1950:mgmt_getspec_cbk] 0-glusterfs: No change in volfile,continuing
{code}
Not sure how much impact these could have on performance.  Will try to involve someone with significant gluster knowledge in the investigation.

 ","19/Jul/21 15:46;pd122;Load spikes noticed in sar logs on the DB cluster from the past week (CPU %user %nice %system %iowait %steal %idle)

11/7 (pdb1):

03:00:01 AM all 1.11 0.00 1.80 0.02 0.00 97.08
 03:10:01 AM all 2.08 0.00 1.87 0.02 0.00 96.03
 03:20:01 AM all 1.33 0.01 1.43 0.02 0.00 97.21

 

12/7 (pdb1):

03:00:01 AM all 1.11 0.00 0.70 0.01 0.00 98.17
 03:10:01 AM all 2.69 0.00 0.90 0.01 0.00 96.40
 03:20:01 AM all 1.78 0.00 1.24 0.11 0.00 96.86

 

15/7 (pdb1):

3:00:01 AM all 0.69 0.00 0.77 0.01 0.00 98.53
 03:10:01 AM all 2.26 0.00 0.98 0.02 0.00 96.74
 03:20:01 AM all 0.65 0.00 0.79 0.01 0.00 98.55

 

15/7 (pdb4):

02:10:01 AM all 1.40 0.00 0.89 0.02 0.00 97.70
 02:20:01 AM all 2.81 0.00 0.91 0.02 0.00 96.26
 02:30:02 AM all 4.48 0.00 1.10 0.02 0.00 94.41
 02:40:01 AM all 4.41 0.00 1.00 0.03 0.00 94.56
 02:50:01 AM all 1.65 0.00 0.88 0.02 0.00 97.45

 

16/7 (pdb1):

03:00:01 AM all 0.98 0.00 0.80 0.02 0.00 98.20
 03:10:01 AM all 1.21 0.00 1.01 0.01 0.00 97.76
 03:20:01 AM all 0.89 0.00 0.93 0.03 0.00 98.15

 

17/7 (pdb4):

02:10:01 AM all 1.51 0.00 1.00 0.03 0.00 97.46
 02:20:01 AM all 2.95 0.00 1.22 0.06 0.00 95.77
 02:30:01 AM all 4.47 0.00 1.31 0.05 0.00 94.18
 02:40:01 AM all 4.52 0.00 1.19 0.05 0.00 94.25
 02:50:01 AM all 1.77 0.00 0.98 0.03 0.00 97.22

 

17/7 (pdb1):

3:00:01 AM all 1.02 0.00 1.00 0.02 0.00 97.96
 03:10:01 AM all 5.88 0.00 1.32 0.02 0.00 92.78
 03:20:02 AM all 2.15 0.00 1.12 0.02 0.00 96.71

 

 

18/7 (pdb4):

02:10:01 AM all 1.39 0.00 1.90 0.03 0.00 96.68
 02:20:01 AM all 2.86 0.00 1.96 0.04 0.00 95.15
 02:30:01 AM all 4.37 0.00 2.02 0.03 0.00 93.58
 02:40:01 AM all 4.36 0.00 1.93 0.04 0.00 93.68
 02:50:01 AM all 2.04 0.00 1.96 0.04 0.00 95.96
 03:00:01 AM all 1.18 0.00 1.82 0.03 0.00 96.97

 

18/7 (pdb1):

03:00:01 AM all 0.89 0.00 1.91 0.02 0.00 97.18
 03:10:01 AM all 1.89 0.00 2.09 0.02 0.00 96.01
 03:20:01 AM all 0.84 0.00 1.44 0.02 0.00 97.70

 

 

Doesn't neccessarily mean anything but perhaps it's worth noting the times corresponding with journaler peaks.  Could not identify any related crontab activity.  Will discuss potential DB issues with the team.","20/Jul/21 10:24;pd122;requested SYSENG assistance in SYSENGINT-854","22/Jul/21 09:32;pd122;we have temporarily disabled backups on that env to see if it makes any difference, no spikes were recorded since (could be a coincidence though)

also no other environment seems to be impacted","26/Jul/21 08:09;cs687;Backup were disabled from 19-24 of July and were running in the night of 25th of July successfully. 
So far we got no further spikes anymore. 

pressured the created SYSENG ticket by Kaan to analyze more details. 
So far we can not do further analyzes anymore. ","28/Jul/21 14:15;cs687;Hey [~pw231] just received the update from SYSENG in ticket https://jira.deutsche-boerse.com/browse/SYSENGINT-854

when I am checking the grafana page i see that we received no further spikes anymore, the latest one was happening on 18th of July. 

+On SYSENG side we checked:+
 * vCenter -> no events happened between 12am and 6am 
 * CheckMK -> also showed us nothing suspicious regarding CPU utilization/disks/network 
 * no warning/errors in GlusterFS logs cluster wide 
 * ESX issue we could also more and less exclude because on the same *esx fresxegy1003.deutsche-boerse.de* we have also hosts running like m7hupxprodm7b1 and m7plpxprodm7b1

+On 7tops side we checked the following:+
 * postgres logfiles
 * journalctl & message logfiles
 * auth.log
 * deactivating backup from 20th until 24th of July

At the moment we have really no clue, why this spikes are happening and don´t know how to continue the analyzing. 

I would keep it open until [~cv179] is coming back and ask him, if he has an idea to somehow analyze it in a different way. 

I mean it makes also no sense to run a tcp-dump even if we don´t see any network related issues, and besides that don´t know when this issue with the spikes will occur again. Hopefully that would be okay for you? ","29/Jul/21 08:18;cs687;Unfortunately the spikes came back again and even with another one around 4am today in the morning 

[https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1627514479129&to=1627537036866&fullscreen&panelId=3&var-host=All&var-client=elts&var-client_env=prod&var-interval=10m&var-exchangeId=EPEX]
the first one started again around 2:50am and ended 3:10am 

the *second one* started at 4am and ended up at 4:20am

 

checking the logfiles now!","29/Jul/21 10:29;cs687;h2. Glusterfs Differences on ELTS-PROD 

After another detailed root cause analyzes with SYSENG we found out the following: 

Unfortunately the glustefs configuration of ELTS-PROD differs with the configuration of all other ENV´s. 
h3. Configuration for ICSC-PROD (same looks for all others!)

 
{code:java}
Volume Name: journal_m7cicscprodapp
Type: Replicate
Volume ID: a6e5ab05-4a5b-4fc5-a82e-1b63a6e8ee5f
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: m7prodpdb1:/opt/gluster_volumes/journal/m7cicscprodapp
Brick2: m7prodpdb2:/opt/gluster_volumes/journal/m7cicscprodapp
Brick3: m7prodpdb3:/opt/gluster_volumes/journal/m7cicscprodapp
Brick4: m7prodpdb4:/opt/gluster_volumes/journal/m7cicscprodapp
Options Reconfigured:
performance.nfs.write-behind-window-size: 100MB
performance.write-behind-window-size: 100MB
performance.nl-cache-positive-entry: on
network.inode-lru-limit: 50000
performance.nl-cache-timeout: 600
performance.nl-cache: on
features.cache-invalidation-timeout: 600
features.cache-invalidation: on
performance.cache-size: 128MB
nfs.acl: on
network.ping-timeout: 20
transport.address-family: inet
nfs.disable: off
performance.client-io-threads: on  {code}
h3. Configuration for ELTS-PROD (differs with few missing parameters!) 
{code:java}
Volume Name: journal_m7eltsprodm7c
Type: Replicate
Volume ID: 4591df1b-8e75-4a40-8d0e-985613fc9a8a
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 4 = 4
Transport-type: tcp
Bricks:
Brick1: m7prodpdb1:/opt/gluster_volumes/journal/m7eltsprodm7c
Brick2: m7prodpdb2:/opt/gluster_volumes/journal/m7eltsprodm7c
Brick3: m7prodpdb3:/opt/gluster_volumes/journal/m7eltsprodm7c
Brick4: m7prodpdb4:/opt/gluster_volumes/journal/m7eltsprodm7c
Options Reconfigured:
performance.client-io-threads: off
nfs.disable: off
transport.address-family: inet
network.ping-timeout: 20
nfs.acl: on{code}
In ticket https://jira.deutsche-boerse.com/browse/M7P-7696 it is described what we changed to fix slower journaler in ELTS-PROD! 
{code:java}
gluster volume set $VOLUME performance.cache-size 128MB
gluster volume set $VOLUME group nl-cache
gluster volume set $VOLUME nl-cache-positive-entry on
gluster volume set $VOLUME performance.write-behind-window-size 100MB
gluster volume set $VOLUME performance.nfs.write-behind-window-size 100MB
gluster volume set $VOLUME performance.client-io-threads on
gluster volume set $VOLUME network.inode-lru-limit 50000
gluster volume set $VOLUME features.cache-invalidation on
gluster volume set $VOLUME features.cache-invalidation-timeout 600{code}
during that time it was tested for *ELTS-ASIM, XRPM-PROD* and also planned with that SERVICE Deployment ticket to onboard the changes to ELTS-PROD beginning of February. 
So far the changes were not done and just a umount/mount were triggered during that time. 
https://jira.deutsche-boerse.com/browse/SERVICE-9618



The Issue from past was more like slower journaler and nowadays we have like blocking journaler anyways we should definitely update the glusterfs config for ELTS-PROD as well how we have it running for the others. 
Would like to schedule a planned meeting with [~rehapav] and [~cv179] to talk about this points to properly coordinate it during 6.11 for ELTS-PROD 

[~pw231] was informed about the findings.

 ","30/Jul/21 08:29;pw231;we have some big problem here.
similar behaviour (waiting for journaler) but much more often [we experience on syt1|https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&var-host=m7tenrgsyt1m7c2%20-%20tomcat%20-%20m7_shrd_syt1&var-client=shrd&var-client_env=syt1&var-interval=30s&var-exchangeId=EPEX&from=1627484263343&to=1627624280382].
It happens on load peaks when load-runner sends cca 700 orders/sec so network might be overloaded and traffic to glusterFS is at biggest.","03/Aug/21 14:51;cs687;Just had a discussion with [~cv179] and [~up809]

1.) we will def. deploy glusterfs changes to ELTS-PROD during planned deployment in august - how it was originally planned in https://jira.deutsche-boerse.com/browse/SERVICE-9618
[~yq577] we will update the SERVICE ticket with the necessary steps. 

2.) creating a ticket for SYSENG to activate network tapping on the hosts m7eltsprodm7c1/2 and m7prodpdb2 (host were currently DB Leader is running on it) 
to analyze more details, at the moment it´s still a blackbox and we need more info´s. 

 ","09/Aug/21 09:17;cs687;Closing the ticket, we found no proper root cause analyzes. 
checked a lot of things like monitoring of network, glusterfs, ESX Hypervisor, deactivated backup.

What we found out is, that we are running with a different glusterfs confiugration for ELTS-PROD which will be like refreshed during 6.11 Deployment in ELTS-PROD. 
We need some additional network details and asked SYSENG to activate network tapping to get some more details. 

https://jira.deutsche-boerse.com/browse/SYSENGINT-907
Network tapping is not running for a while, so we can not analyze further things and have to close this ticket. 
In case its escalating we have to activate the network tapping ones again to get some more details and see the whole picture. 

 ",,,,,,,,,,,,,,,
OpsGenie SoD/Auth Concept Documents ,M7P-8614,112673,112668,Sub-task,To Do,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,tj898,rl336,sw455,12/Jul/21 15:39,08/Sep/21 15:17,16/Sep/21 14:11,,,,,,,,,,,7tops,RiskAssessment,,,,,,"If Energy IT OpsGenie (AID925) is going to be onboarded to PAM/IIQ, it will need a Segregation of Duties (SoD) and Authorization Concept

First task:
Clarify with ESO if this is required. From my (Alex Thorne) side, IIQ implementation here is very low priority - it does not add significant value (neither in ease of user management or additional security. User management is very low effort in OpsGenie, and data kept there is negligible in sensitivity)

If documentation is needed, we can also maybe just refer to the very clear documentation of the service provider:
https://support.atlassian.com/opsgenie/docs/learn-user-roles-and-permissions/ ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5616000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|i00adz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112673,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Energy OpsGenie - Risk Assessment,M7P-8613,112672,112668,Sub-task,To Do,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,tj898,rl336,sw455,12/Jul/21 15:39,14/Sep/21 12:56,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"*Task:* Perform a self-risk assessment for Energy OpsGenie AID925 (fill in linked RA form)

RAP ticket: {color:#0747a6} https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Risk%20Assessments/OpsGenie/DBG_IS_Risk_Assessment_Tool_AID925_OpsGenie.xlsm?d=w6cd9cb4ac5964932b25df4a8b1ad97ac&csf=1&e=x0MLDG{color}

*All security documents for OpsGenie kept here:*

[https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Risk%20Assessments/OpsGenie] 
 Template from GIS for Risk Assessment tool copied at above linked under name ""DBG_IS_Risk_Assessment_Tool_effective_2021-07-01.xlsm

 

*Hint:* Use the form: ""RA_Energy IT Toolchain AID623_v2.6"" from the link below as reference (many comments and answers can be reused from there to make this faster)
 [https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Risk%20Assessments/Energy%20IT%20Toolchain]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5616000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|i00adr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112672,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Energy OpsGenie - Create and approve Security Document,M7P-8611,112670,112668,Sub-task,To Do,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,tj898,rl336,sw455,12/Jul/21 15:39,08/Sep/21 15:17,16/Sep/21 14:11,,,,,,,,,,,7tops,SecurityDocumentation,,,,,,"*Task:* Draft the ""Security Document"" for Energy OpsGenie (MEGA ID: AID925), submit to ESO team for review
 *Why:* Required for compliance for all MEGA applications
 *Due date:* September 15th (we should have at least two weeks for review with ESO, *1st September to ESO* review is a better ""due date"" internally.)

 

 

*Template is already prepared for document, and stored here:*

[https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Risk%20Assessments/OpsGenie] 
 *  Please refer to the existing security documents (i.e. for [Energy Toolchain|https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/02%20General%20topics/Security/Risk%20Assessments/Energy%20IT%20Toolchain]) for reference

 

 

 

Template and user guides for Security Documentation from GIS kept here (for reference only):

[Information Security - Mandatory Control Framework - Security Documentation - All Documents (deutsche-boerse.de)|https://bluebook.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?id=%2Fsites%2Fsp0823%2F400%5FPublication%2FIS%20Risk%20Management%2FMandatory%20Control%20Framework%20%2D%20Security%20Documentation] 

 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5616000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|i00adb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112670,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OpsGenie AID925 - Risk Assessment,M7P-8609,112668,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,tj898,rl336,sw455,12/Jul/21 15:39,08/Sep/21 15:17,16/Sep/21 14:11,,,,,,,,,,,7tops,RiskAssessment,SecurityDocumentation,,,,,"Risk Assessment for Energy Toolchain with all subtasks:
1. fill out Information Classification with approval (/)
2. Create Security Document
3. Create SSD - Mandatory Controls 
4. Self Risk Assessment
5. GIS Risk Assessment",,,,,,,,,,,,,,,,,,,,,ESO-337,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5616000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|i00lbo:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112668,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stalker Upgrade to Version 1.1.x ,M7P-8595,112563,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,pd122,cs687,cs687,08/Jul/21 10:16,16/Sep/21 14:09,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,stalker,,,,,"Hey [~rehapav] we need to upgrade stalker version 1.1.x to more or less to all the stalker instances on the hosts m7shrdintestk1, m7shrdextestk1 and m7shrdprodstk1

Here the list of the deployed versions in *SIMULATION*:  ""Xmx512m""
{code:java}
Here the list what is deployed atm
/shrd/xsop-simu-stk1 -> stalker-1.0.84
/shrd/xsop-cute-stk1 -> stalker-1.1.108
/shrd/xsop-asim-stk1 -> stalker-1.0.84
/shrd/xrpm-simu-stk1 -> stalker-1.0.35
/shrd/xrpm-lipa-stk1 -> stalker-1.0.35
/shrd/plpx-simu-stk1 -> stalker-1.0.84
/shrd/plpx-lipa-stk1 -> stalker-1.0.35
/shrd/hupx-simu-stk1 -> stalker-1.0.84
/shrd/hupx-cute-stk1 -> stalker-1.1.108
/shrd/hupx-asim-stk1 -> stalker-1.0.84
/shrd/elts-simu-stk1 -> stalker-1.0.84
/shrd/elts-lipa-stk1 -> stalker-1.0.35
/shrd/elts-cute-stk1 -> stalker-1.1.108
/shrd/elts-ctpb-stk1 -> stalker-1.0.84
/shrd/elts-asim-stk1 -> stalker-1.1.99
/shrd/elts-acut-stk1 -> stalker-1.0.84
{code}

list of deployed versions in *PRODUCTION*: ""Xmx1g""
{code:java}
/shrd/elts-prod-stk1 -> stalker-1.0.84 
/shrd/hupx-prod-stk1 -> stalker-1.0.84
/shrd/plpx-prod-stk1 -> stalker-1.0.84
/shrd/xrpm-prod-stk1 -> stalker-1.0.84
/shrd/xsop-prod-stk1 -> stalker-1.0.84
{code}

btw its also necessary to change for the bigger env´s the Xmx setting, like elts-asim and elts-prod like syt1 has it atm. *-Xms256m -Xmx1536m*
currently all the stalker instances have like an Xmx setting of 512m, properly 1g Xmx should be enough for elts-asim, for elts-prod we will increase it to 1.5g and the rest we can keep it like it is. ",,cs687,HO764,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8591,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,117,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i005pa:x",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Technical Debt/Improvements,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112563,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jul/21 10:32;cs687;ELTS-ASIM was already deployed with new Xmx setup 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2869
{code:java}
[root@m7shrdextestk1 ~]# ps -ef | grep elts-asim
tomcat    53392      1 99 10:26 ?        00:00:33 java -Xms256m -Xmx1024m -classpath /shrd/elts-asim-stk1/stalker-1.1.99/
{code}


Same will happen for ELTS-PROD 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2870
{code:java}
[root@m7shrdprodstk1 ~]# ps -ef | grep elts-prod
tomcat   18367     1 65 10:35 ?        00:00:22 java -Xms256m -Xmx1536m -classpath /shrd/elts-prod-stk1/stalker-1.0.84/
{code}
","08/Jul/21 14:26;cs687;We discussed about the stalker topic in last OPS-Meeting!
All of us agreed to set the stalker in Production to a WARNING level, to avoid any calls during ONCALL 
and in case some stalker is crashing during night we can fix it the day afterwards in the morning. 
[~rehapav] want do you think about it? 
 ","12/Jul/21 11:35;rehapav;Approved, please proceed with the deployment.

 ","15/Sep/21 14:46;pd122;external tests - stalker updated to 1.1.148:

XSOP SIMU: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12397/console]

XSOP ASIM: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12398/console]

XRPM LIPA: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12399/console]

XRPM SIMU: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12400/console]

PLPX LIPA: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12401/console]

PLPX SIMU: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12402/console]

HUPx CUTE: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12403/console]

HUPX SIMU: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12404/console]

HUPX ASIM: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12405/console]

ELTS CTPB: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12406/console]

ELTS ACUT: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12407/console]

ELTS LIPA: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12408/console]

ELTS SIMU: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12409/console]

ELTS CUTE: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12410/console]

ELTS ASIM: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12411/console","16/Sep/21 14:09;pd122;production updates:

XSOP PROD: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12420/console]

XRPM PROD: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12421/console]

PLPX PROD: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12422/console]

HUPX PROD: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12423/console]

ELTS PROD: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12424/console",,,,,,,,,,,,,,,,,,,,,,,
Member Activity Report update,M7P-8594,112560,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,dp007,xc363,xc363,08/Jul/21 09:32,08/Sep/21 15:15,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"Member Activity Reports should take into account : 
 * All inquiry and management requests already in its scope

 * Plus the following ones : 

 ** AllUsersReq

 ** ChgPwdReq

 ** H2HAreaInfoReq

 ** HubToHubReq

 ** Upcoming 6.12 ThrottlingStatusReq

 ** Any other requests we would have missed (available in M7 but not in the tool static list)",,xc363,,,,,,,,,,,,,,,,,SERVICE-10607,,,,,,,,,,,,,,,,,,,,,,"08/Jul/21 09:32;xc363;M72021xx_Member Activity Report API requests list update.docx;https://jira.deutsche-boerse.com/secure/attachment/97135/M72021xx_Member+Activity+Report+API+requests+list+update.docx",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,6048000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i009p3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,6.12 non RC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112560,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing expiration policy for response queues - PRODUCTION STAGING,M7P-8589,112536,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,PB446,cs687,cs687,07/Jul/21 14:03,15/Jul/21 10:25,16/Sep/21 14:11,12/Jul/21 15:18,,7Tops_Sprint121,,,,,,,,M7PRODOPS,Stability,,,,,,"Like it happened already for the non-prod env´s we need to add a new policy. more detailed info will be found here https://jira.deutsche-boerse.com/browse/M7P-8588

no need to prepare any further pull-request: *everything already im-place* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2724

necessary env´s which need a redeployment of RabbitMQ:

||Environment||Status||
|ELTS-PROD||
|HUPX-PROD||
|PLPX-PROD||
|XRPM-PROD||
|XSOP-PROD||

The re-deployment will be coordinated with [~yq577] and the plan is to do it during 6.11 Deployment. 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Handled in service ticket 6.11.,,,,,,,,,,,,,,,,,,,,,,,,6134400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:ni",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112536,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing expiration policy for response queues - EXTERNAL STAGING,M7P-8588,112535,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,07/Jul/21 13:43,15/Jul/21 10:25,16/Sep/21 14:11,08/Jul/21 09:11,,6.12.107,7Tops_Sprint121,,,,,,,M7PRODOPS,Stability,,,,,,"we need to redeploy AMQ (discussed in ticket https://jira.deutsche-boerse.com/browse/M7P-7975) on all non-prod env´s 
For that we have to stop backend (core, enq), redeploy rabbitmq and start up the backend again. 

Staging will be proceed with [~yq577].
for elts-ctpb and elts-asim we have to proceed before business hour, the other env´s can be done anytime. 

OPEN Point: 
Preparation Pull-Request: [~HO764]
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2724

*Table with all env*

||Environment||Status||
|xsop-cute|(/)|
|xsop-asim|(/)|
|xsop-simu|(/)|
|xrpm-lipa|(/)|
|xrpm-simu|(/)|
|plpx-lipa|(/)|
|plpx-simu|(/)|
|hupx-asim|(/)|
|hupx-cute|(/)|
|hupx-simu|(/)|
|elts-acut|(/)|
|elts-asim|(/)|
|elts-ctpb|(/)|
|elts-cute|(/)|
|elts-lipa|(/)|
|elts-simu|(/)|


",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"redeployed on all non-prod env´s 
RabbitMQ which were deleting the old policy ""*respQ-master-locator*"" and replaced it with the new one ""*respQ*"" with additional expire attribute",,,,,,,,,,,,,,,,,,,,,,,,6048000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i009jj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 121,,,,,,,,,,,,,,,,,,,,,,,,,,see comments and ticket https://jira.deutsche-boerse.com/browse/M7P-7975,,,,,,,,,,"{""issueId"":112535,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/21 16:15;cs687;finished all non-prod customer excluding elts 
ELTS will be finished tomorrow morning","08/Jul/21 09:11;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
[OPS] NAS shares for all postgres databases which needs to be backed up (M7),M7P-8558,112305,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,cs687,cs687,30/Jun/21 13:29,08/Sep/21 15:15,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"* Request NAS shares from db backup volume from SYSENG, one share for each env group
 ** Test - ?? --> _*necessary at all, personally I would skip it*_
 ** Simu - 1.5TB (currently we have used ~465G for backup FS) 
 ** Prod - 1.5TB (currently we have used ~415G for backup FS)

In case we skip TEST PDB´s we can do some tests with showcase or dst patroni cluster!

 * Estimate sizing for and then multiply 3x to have enough buffer.
 * Specify to which hosts it should be mounted
 * Umount old backup volumes
 * Modify patroni/postgres config with new archive commands
 * Mount new NAS shares
 * Copy over all files
 * Mount new NAS share to old location and update fstab
 * Test fail-over/switch-over of patroni nodes
 * Test if backup/restore is working",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6739200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzxu6:zi",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112305,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change Zookeeper paths similar to Broker's new path alignment ,M7P-8557,112304,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,nz893,nz893,30/Jun/21 12:58,01/Sep/21 11:20,16/Sep/21 14:11,13/Aug/21 13:55,,6.12.120,7tops_sprint124,,,,,,,Kafka,M7PRODOPS,,,,,,"Copy new Kafka broker path alignment:

 

The new Kafka path structure is defined this way (hostname contains elts pattern):
{noformat}
/elts/kafka/data
/elts/kafka/config
/elts/logs/kafka/
{noformat}
 - for mechines where are more customers (hostname contains shrd pattern):

{noformat}
/shrd/kafka/data
/shrd/kafka/config
/shrd/logs/kafka
{noformat}
data and log dir would have its own mount point (if there will be logical volume I'll leave up to Lambert's decision).",,cs687,nz893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-870,SYSENGINT-748,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"both envs are correct now 

ELTS-PROD is using 
{code:java}
/elts/kafka/data
/elts/kafka/config
/elts/logs/kafka{code}
and SHRD-PERF
{code:java}
/shrd/kafka/data
/shrd/kafka/config
/shrd/logs/kafka{code}",,,,,,,,,,,,,,,,,,,,,,,,2937600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i0085b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,"Preparation done by SYSENG SYSENGINT-870

redeployment of whole cluster",,,,,,,,,,"{""issueId"":112304,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/21 08:36;cs687;*SHRD-INTE Cluster:* (/) 
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-shrd-inte-kafka-zookeeper-*"" -m shell -a ""df -h | grep shrd"" -b -k -K
/dev/mapper/rootvg-lv_shrd           976M  4.0M  905M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  2.6M  907M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd           976M  4.0M  905M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  4.8M  904M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd           976M  4.2M  905M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  4.8M  904M   1% /shrd/logs
{code}

*SHRD-EXTE Cluster:* (/) 
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-shrd-exte-kafka-zookeeper-*"" -m shell -a ""df -h | grep shrd"" -b -k -K
/dev/mapper/rootvg-lv_shrd           976M  2.6M  907M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  2.6M  907M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd           976M  2.6M  907M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  2.6M  907M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd           976M  2.6M  907M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs      976M  2.6M  907M   1% /shrd/logs
{code}


*SHRD-PROD Cluster:* (/) 
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-shrd-prod-kafka-zookeeper-*"" -m shell -a ""df -h | grep shrd"" -b -k -K
/dev/mapper/rootvg-lv_shrd              976M  2.8M  906M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs         976M  4.3M  905M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd              976M  3.2M  906M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs         976M  8.4M  901M   1% /shrd/logs

/dev/mapper/rootvg-lv_shrd              976M  3.0M  906M   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs         976M  8.0M  901M   1% /shrd/logs
{code}


*ELTS-ASIM Cluster:* (/)
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-elts-asim-kafka-zookeeper-*"" -m shell -a ""df -h | grep elts"" -b -k -K
m7t-elts-asim-kafka-zookeeper-2 | SUCCESS | rc=0 >>
/dev/mapper/rootvg-lv_elts           976M  2.6M  907M   1% /elts
/dev/mapper/rootvg-lv_elts_logs      976M  2.6M  907M   1% /elts/logs

/dev/mapper/rootvg-lv_elts           976M  2.6M  907M   1% /elts
/dev/mapper/rootvg-lv_elts_logs      976M  2.6M  907M   1% /elts/logs

/dev/mapper/rootvg-lv_elts           976M  4.7M  905M   1% /elts
/dev/mapper/rootvg-lv_elts_logs      976M  2.6M  907M   1% /elts/logs
{code}

_________________________________________________________________________________________

*PERF Cluster:* (x) 
*necessary to prepare a ticket for that*
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-shrd-perf-kafka-zookeeper-*"" -m shell -a ""df -h | grep shrd"" -b -k -K
m7t-shrd-perf-kafka-zookeeper-4 | FAILED | rc=1 >>
non-zero return code

m7t-shrd-perf-kafka-zookeeper-5 | FAILED | rc=1 >>
non-zero return code

m7t-shrd-perf-kafka-zookeeper-2 | FAILED | rc=1 >>
non-zero return code

m7t-shrd-perf-kafka-zookeeper-1 | FAILED | rc=1 >>
non-zero return code

m7t-shrd-perf-kafka-zookeeper-3 | FAILED | rc=1 >>
non-zero return code

m7t-shrd-perf-kafka-zookeeper-6 | FAILED | rc=1 >>
non-zero return code
{code}

*ELTS-PROD Cluster:* (x)
*necessary to prepare a ticket for that*
{code:java}
[cs687@enprodauto1 {skip-elts L | ✔} ~/energy.automation.deployments]$ ansible ""m7t-elts-prod-kafka-zookeeper-*"" -m shell -a ""df -h | grep elts"" -b -k -K
m7t-elts-prod-kafka-zookeeper-5 | FAILED | rc=1 >>
non-zero return code

m7t-elts-prod-kafka-zookeeper-1 | FAILED | rc=1 >>
non-zero return code

m7t-elts-prod-kafka-zookeeper-3 | FAILED | rc=1 >>
non-zero return code

m7t-elts-prod-kafka-zookeeper-2 | FAILED | rc=1 >>
non-zero return code

m7t-elts-prod-kafka-zookeeper-4 | FAILED | rc=1 >>
non-zero return code

m7t-elts-prod-kafka-zookeeper-6 | FAILED | rc=1 >>
non-zero return code
{code}

","21/Jul/21 09:17;cs687;Requested the changes with an additional ticket to Lambert 
https://jira.deutsche-boerse.com/browse/SYSENGINT-870

Ones this is implemented we have to do the same changes for perf-cluster like we did for the other env´s above and follow up the ELTS-PROD Cluster deployment","21/Jul/21 09:25;nz893;The pipeline was update to count with new Zookeeper path alignment. https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1664/files","13/Aug/21 13:55;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Investigate processing times spike,M7P-8556,112299,,Bug,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,cv179,oy574,oy574,30/Jun/21 11:27,16/Sep/21 08:20,16/Sep/21 14:11,,,,,,,Database,RE,,,7tops,,,,,,,"On 30.6.2020, there was a big spike in core processing times from ~4:40-5:40: [https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1625020153727&to=1625025865577&var-host=m7eltsprodm7c2%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-interval=30s&var-exchangeId=EPEX]. This correlates with the generation of TC540 report, which results in generation of temporary files (because of long running query), which is then replicated to other nodes. 

Replicating core journal files during this time seems to be slowed, so glfs takes additional time to confirm the write, hence Journalling times are increased in this period as well. See this slack thread for additional details: [https://dbg-devops.slack.com/archives/G451D1RQB/p1625039336157600]",,cv179,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21089,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,30/Jun/21 11:27,,[],,,,,,,,None,,,M7T,,,,"2|i00847:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112299,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/21 14:19;cv179;Asked cybertec for ideas

 

Options:
 * Test NAS for journal (to split impact of DB on journalling)
 * setup dedicated hosts for journal (costly)
 * check impact of using leader vs replica on RE
 * stop replication for report generation?
 * also stop glusterfs on the report db server?
 * split glusterfs and database leader hosts? (use 2 out of 4 for leader, other 2 for database leaders?)
 * improve database config or query parameters (wait for cybertec result)","30/Jun/21 16:50;cv179;Summary from the discussion with Julian (cybertec):
Next steps on our side: * get {{pg_stat_statements}} working with pgwatch2 so we can create us the overview similar to this one: [https://demo.pgwatch.com/d/9a37629d7/stat-statements-top?orgId=1&var-dbname=test&var-top=15&var-hide_pgwatch_generated=yes]

for some reason, neither the table/view nor any function exists so perhaps we need to activate the sub(system?). * We also will consider moving the report generation to a different time window (shift by half an hour at least) to exclude potential collision with backups or other side effects.
 * I'll also try to catch suspicious queries on the leader at the given time by randomly dumping the process tables... maybe we'll catch a fish with this.



Input from Laurenz Albe (cybertec):
Temporary files are created when {{work_mem}} is not big enough to contain intermediary data.
Can you enable {{track_io_timing}} and run one of these expensive statements with {{EXPLAIN (ANALYZE, BUFFERS)}} to verify that it generates temp files, and that I/O time is actually the problem?
Raising {{work_mem}} can help, but only up to a certain limit. You don't want to go OOM.
I would try to optimize the queries so that they use less resources. That's the most promising approach.","31/Aug/21 09:12;cv179;Further directions for analysis:
 * Network tapping reactivation was rejected, packet monitoring could be attempted differently - perhaps packetbeat
 * Virtual glusterfs hosts with local and fast storage (not SAN) - maybe VSAN
 * pg_stat_statements activation seems tricky, will continue to set it up","16/Sep/21 08:20;cv179;There is a new known issue we discovered on the vsphere logs: Sometimes, esx seems to lose connection to SAN for just a few seconds. This blocks IO and perhaps just freezes all VMs for a short time. To most systems, this would probably not be visible, but in our case, it is a significant issue.

Right now, this is being evaluated with the storage team. Error messages show up like this:

 08/31/2021, 10:52:38 AM Lost access to volume 5e8ee8dc-f9b384f8-5c77-9440c91d5dc0 (san.clustegyprod.r1ha.emc.101) due to connectivity issues. Recovery attempt is in progress and outcome will be reported shortly.

 

Further processing time spike events should be attempted to correlate against those log entries.

 ",,,,,,,,,,,,,,,,,,,,,,,,
XSOP - 6.11 (rehersal) production installation test,M7P-8545,112224,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Won't Do,cs687,rehapav,yq577,29/Jun/21 09:14,05/Aug/21 13:26,16/Sep/21 14:11,19/Jul/21 09:28,,7tops_sprint122,,,,cor,,,30/Oct/20 00:00,6.11_Blocker,7tops_comm,S,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.11 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.10 
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  XSOP PROD data snapshot

*Preparation*
 * *get dump from XSOP PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.11

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.10.246
 * load dump into system test environment
 * deploy 6.11.263 software version *confirmed*
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.11 software were successfully exectued
 * measure migration timeline
 * do not start the environment

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions",,cs687,yq577,,,,,,,,,,,,,,,,,,M7P-8543,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"I want to formally inform you (before ELTS PROD deployment ) that we have – after sensitive risk assessment – decided to skip ELTS PROD dbcleanup/conversion test.

 The test itself has been successfully executed for all 3 other small customers with M7 6.11 in their PROD environments – BSP, HUPX, and OPCOM – and of course, we planned it for ETLS PROD well.

While discussing execution details of this test on ELTS PROD database, we faced an issue (not present for other customers) with an extremely big ELTS PROD database size (>1 TB).

At the moment, we have no technical solution to run a full test on such a big db (we are waiting for db hosts) in our test environment (no disk space).

We (Roma) had some innovative ideas on how to execute this test in an alternative way with non-trivial extraordinary efforts (such as running it on read-only “dbr hosts”), yet we concluded that it’s not worth the efforts.

Considering that we already run dbcleanup script 3 times successfully on 6.10 ELTS PROD database directly in production (and that is a significant part of the test), we are confident this part does not need to be tested again.

Flyway scripts – another part of the deployment sequence – have been thoroughly tested on the other clients/test environments and, from its nature, has no different requirements/specifics on ETLS PROD.

The rest of the deployment, like OS upgrade, software deployment, small technical changes, has also been tested already, and we have our experienced guys doing it.

We agreed to have more robust review process for preparation and have 3 techops + 2 developers working on the deployment preparation and execution.
 
After constructive team negotiation, I found the risk of not running this test as acceptable.",,,,,,,,,,,,,,,,,,,,,,,,5097600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00785:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,"can be closed, it´s enough like it was already handled with elts-prod data-set
https://jira.deutsche-boerse.com/browse/M7P-8543
",,,,,,,,,,"{""issueId"":112224,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/21 09:28;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Reports for June 2021,M7P-8544,112223,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,dp007,dp007,29/Jun/21 09:12,15/Jul/21 10:25,16/Sep/21 14:11,13/Jul/21 10:50,,6.12.107,7Tops_Sprint121,,,EBSM,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD|   12-07-2021(Volkan)|    13-07-2021(Volkan)|
| M7 EPEX ASIM|  02-07-2021(Volkan)|     13-07-2021(Volkan) |
| M7 HUPX|   12-07-2021(Volkan)|     13-07-2021(Volkan) |
| M7 XSOP|   02-07-2021(Volkan)|     13-07-2021(Volkan) |
| M7 TGE|   02-07-2021(Volkan)|     13-07-2021(Volkan) |
| M7 OPCOM|   02-07-2021(Volkan)|     13-07-2021(Volkan) |
| M7 SHRD SYT1|   13-07-2021(Volkan)  |     13-07-2021(Volkan)  |
| M7 AUCTION|   02-07-2021(Volkan)| 08-07-2021(Tom) |
| ICS / Swissgrid|   02-07-2021(Volkan)| 08-07-2021(Tom) |
| ICS / CH-AT|   02-07-2021(Volkan)| 08-07-2021(Tom) |

[https://bluebook.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?id=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2021%2D06]

Greenlight requesting email was sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Martin Komberec <martin.komberec@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>;{code}",,dp007,oh856,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,June SLA reports have been generated and sent to customer,,,,,,,,,,,,,,,,,,,,,,,,5616000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i007nr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":112223,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/21 10:01;oh856;All SLA reports have been generated and sent. ",,,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD - 6.11 (rehersal) production installation test,M7P-8543,112222,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cv179,rehapav,yq577,29/Jun/21 09:09,25/Aug/21 10:21,16/Sep/21 14:11,16/Jul/21 13:02,,6.12.114,7tops_sprint122,,,cor,,,30/Oct/20 00:00,7tops_comm,S,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.11 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.10
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ELTS PROD data snapshot

*Preparation*
 * *get dump from ELTS PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.11

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.10.246
 * load dump into system test environment
 * deploy 6.11.258 software version *confirmed*
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.11 software were successfully exectued
 * measure migration timeline
 * {color:#de350b}*newly with 6.12 please also generate TC540 report to see the performance*{color}
 * do not start the environment

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions",,cv179,yq577,,,,,,,,,,,,,,,,,,M7P-7033,,,,,,,,,,,,,,M7P-8608,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"I want to formally inform you (before ELTS PROD deployment o) that we have – after sensitive risk assessment – decided to skip ELTS PROD dbcleanup/conversion test.

 The test itself has been successfully executed for all 3 other small customers with M7 6.11 in their PROD environments – BSP, HUPX, and OPCOM – and of course, we planned it for ETLS PROD well.

While discussing execution details of this test on ELTS PROD database, we faced an issue (not present for other customers) with an extremely big ELTS PROD database size (>1 TB).

At the moment, we have no technical solution to run a full test on such a big db (we are waiting for db hosts) in our test environment (no disk space).

We (Roma) had some innovative ideas on how to execute this test in an alternative way with non-trivial extraordinary efforts (such as running it on read-only “dbr hosts”), yet we concluded that it’s not worth the efforts.

Considering that we already run dbcleanup script 3 times successfully on 6.10 ELTS PROD database directly in production (and that is a significant part of the test), we are confident this part does not need to be tested again.

Flyway scripts – another part of the deployment sequence – have been thoroughly tested on the other clients/test environments and, from its nature, has no different requirements/specifics on ETLS PROD.

The rest of the deployment, like OS upgrade, software deployment, small technical changes, has also been tested already, and we have our experienced guys doing it.

We agreed to have more robust review process for preparation and have 3 techops + 2 developers working on the deployment preparation and execution.
 
After constructive team negotiation, I found the risk of not running this test as acceptable.",,,,,,,,,,,,,,,,,,,,,,,,5356800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00786:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":112222,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/21 08:25;cv179;* choice of systemtest environment: can be SYT1 or SYT3 (both double sided); using SYSTEMTEST3 (growing db and dropping it back)

OLD STATE of SYT3:
 * db size: 140g
 * Core version: 6.11.184
 * RE version: 6.5.29.9
 * reporter version: 1.0.158
 * H2H: 2.1.5
 * MTT: 1.2.10.3

 

OLD STATE OF ELTS PROD:
 * db size: 580g used / 800g capacity
 * Core version: 6.10.199
 * RE: 6.4.78
 * H2H: 2.0.79
 * MTT: 1.0.124
 * Stalker: 1.0.84
 * Harvester: 1.0.35

 

DUMP database of ELTS PROD:
 * connect to replica
 * make sure to have enough space for a compressed dump: df /var/lib/pgsql_m7teltsprodasync/data
 * connect to leader and watch data filesystem
 * start the dump and mark the time of start

{code:java}
ssh m7proddbr1
sudo -iu postgres
cd /var/lib/pgsql_m7teltsprodasync/data
mkdir dump
cd dump
for comp in m7b rep mtt; do echo Processing m7teltsprod${comp}; pg_dump --port=20002 -d m7teltsprod${comp} -n m7teltsprod${comp} | gzip > m7teltsprod${comp}.sql.gz; done{code}
monitor it e.g.
{code:java}
df -h /var/lib/pgsql_m7teltsprodasync/data; ls -lh /var/lib/pgsql_m7teltsprodasync/data/dump  {code}
 

DUMP database of SHRD SYT3:
 * stop the target environment to get a consistent database snapshot
 * connect to testpdb1 
 * check disk space
 * start the dump

{code:java}
ssh m7testpdb1
sudo -iu postgres
cd /var/lib/pgsql_m7tshrdsyt3async/data
mkdir dump
cd dump
for comp in m7b rep mtt; do echo Processing m7tshrdsyt3${comp}; pg_dump --port=26006 -d m7tshrdsyt3${comp} -n m7tshrdsyt3${comp} | gzip > m7tshrdsyt3${comp}.sql.gz; done {code}
 

 

 

 COPY DATA
 * copy data to englobauto1 (home large enough)
 * copy data to testpdb2
 * delete data from proddbr and jumphosts

{code:java}
scp m7proddbr1:/var/lib/pgsql_m7teltsprodasync/data/dump/* ./
scp * m7testpdb2:/var/lib/pgsql_m7tshrdsyt3async/data/dumprestore/ {code}
 

 

RESTORE PROD DB IN TEST
 * resezie filesystems
 * drop old db
 * create empty dbs
 * restore dump (sed to change file contents)
 * fix permissions
 * mask user data

 resize FS on ALL cluster nodes
{code:java}
lvresize -L 800g -r /dev/mapper/datavg-lv_pgsql_m7tshrdsyt3async_data {code}
drop and create db (similar to ADMIN scripts)
{code:java}
DROP DATABASE IF EXISTS   m7tshrdsyt3m7b;
DROP ROLE     IF EXISTS   m7tshrdsyt3m7b;
DROP ROLE     IF EXISTS   uapp01m7tshrdsyt3m7b;
DROP ROLE     IF EXISTS   udev01m7tshrdsyt3m7b;DROP DATABASE IF EXISTS   m7tshrdsyt3mtt;
DROP ROLE     IF EXISTS   m7tshrdsyt3mtt;
DROP ROLE     IF EXISTS   uapp01m7tshrdsyt3mtt;
DROP ROLE     IF EXISTS   udev01m7tshrdsyt3mtt;DROP DATABASE IF EXISTS   m7tshrdsyt3rep;
DROP ROLE     IF EXISTS   m7tshrdsyt3rep;
DROP ROLE     IF EXISTS   uapp01m7tshrdsyt3rep;
DROP ROLE     IF EXISTS   udev01m7tshrdsyt3rep;CREATE ROLE       m7tshrdsyt3m7b WITH LOGIN;
CREATE DATABASE   m7tshrdsyt3m7b WITH OWNER   m7tshrdsyt3m7b;
ALTER  DATABASE   m7tshrdsyt3m7b SET SEARCH_PATH TO m7tshrdsyt3m7b;
CREATE ROLE uapp01m7tshrdsyt3m7b WITH LOGIN;
CREATE ROLE udev01m7tshrdsyt3m7b WITH LOGIN;CREATE ROLE       m7tshrdsyt3mtt WITH LOGIN;
CREATE DATABASE   m7tshrdsyt3mtt WITH OWNER   m7tshrdsyt3mtt;
ALTER  DATABASE   m7tshrdsyt3mtt SET SEARCH_PATH TO m7tshrdsyt3mtt;
CREATE ROLE uapp01m7tshrdsyt3mtt WITH LOGIN;
CREATE ROLE udev01m7tshrdsyt3mtt WITH LOGIN;CREATE ROLE       m7tshrdsyt3rep WITH LOGIN;
CREATE DATABASE   m7tshrdsyt3rep WITH OWNER   m7tshrdsyt3rep;
ALTER  DATABASE   m7tshrdsyt3rep SET SEARCH_PATH TO m7tshrdsyt3rep;
CREATE ROLE uapp01m7tshrdsyt3rep WITH LOGIN;
CREATE ROLE udev01m7tshrdsyt3rep WITH LOGIN;
{code}
 

import data:
{code:java}
for i in m7b rep mtt; do zcat m7teltsprod${i}.sql.gz | sed 's/m7teltsprod/m7tshrdsyt3/g' | /usr/pgsql-11/bin/psql -p 26006 -d m7tshrdsyt3${i}; done {code}
run remaining ADMIN scripts to fix permissions
{code:java}
030_ALTER_ROLE.sql
031_REVOKE_FROM_PUBLIC.sql
034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql {code}
mask user data:
{code:java}
postgres=# \c m7tshrdsyt3m7b;
You are now connected to database ""m7tshrdsyt3m7b"" as user ""postgres"".

UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1='',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';

UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number = '';

UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');



{code}
 

DEPLOY APPLICATION
 * delete journal data OR import journal data (might be tricky)
 * if journal data has been deleted, truncate revision index
 * deploy OLD PROD version
 * perform migration / start environment as required
 * perform tests

 

 ","14/Jul/21 08:59;cv179;syt3 dump finished:
{code:java}
Filesystem                                         Size  Used Avail Use% Mounted on
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt3async_data  140G   86G   54G  62% /var/lib/pgsql_m7tshrdsyt3async/data
total 5.9G
-rw-r--r-- 1 postgres postgres 5.9G Jul 14 08:45 m7tshrdsyt3m7b.sql.gz
-rw-r--r-- 1 postgres postgres  589 Jul 14 08:45 m7tshrdsyt3mtt.sql.gz
-rw-r--r-- 1 postgres postgres 3.0K Jul 14 08:45 m7tshrdsyt3rep.sql.gz
 {code}
 

 

 ","14/Jul/21 09:48;cv179;elts prod dump finished:
{code:java}
Filesystem                                         Size  Used Avail Use% Mounted on
/dev/mapper/datavg-lv_pgsql_m7teltsprodasync_data  720G  598G  123G  83% /var/lib/pgsql_m7teltsprodasync/data
total 40G
-rw-r--r-- 1 postgres postgres  40G Jul 14 09:47 m7teltsprodm7b.sql.gz
-rw-r--r-- 1 postgres postgres  587 Jul 14 09:47 m7teltsprodmtt.sql.gz
-rw-r--r-- 1 postgres postgres 3.6K Jul 14 09:47 m7teltsprodrep.sql.gz
 {code}
 

 ","14/Jul/21 10:11;cv179;copied all elts prod dumps to m7testpdb2 via englobauto1 home","14/Jul/21 11:22;cv179;deleted dumps from englobauto1 and from m7proddbr1 - always clean up early to not forget it. we just need to make sure, one set of the files still exists.","14/Jul/21 12:13;cv179;restore in progress 118 gb restored size... about 400g to go...","14/Jul/21 14:04;cv179;* import finished (~ 2.5 hours)
 * user data masked

{code:java}
-bash-4.2$ cat 099_CLEAN_PRODDATA.sql
UPDATE cx_260_member
SET address_city            = '',
    clearing_contact_fax    = '',
    clearing_contact_name1  = '',
    clearing_contact_name2  = '',
    clearing_contact_phone1 = '',
    clearing_contact_phone2 = '',
    trading_contact_fax     = '',
    trading_contact_name1   = '',
    trading_contact_name2   = '',
    trading_contact_phone1  = '',
    trading_contact_phone2  = ''
;UPDATE cx_282_user
SET email_address = 'test@deutsche-boerse.com',
    phone_number  = ''
;UPDATE cx_600_configuration
SET value = 'test@deutsche-boerse.com'
WHERE id IN (
             'smsAddressee',
             'mailAddressee',
             'quoteRequestSMSMailExtension'
    );
 
-bash-4.2$ psql -p 26006 -d m7tshrdsyt3m7b -f 099_CLEAN_PRODDATA.sql UPDATE 554 UPDATE 6997 UPDATE 3 {code}
 * admin scripts 030 and 034 executed (password changed to syt3 and privileges updated)","14/Jul/21 14:12;cv179;* journal files and old backend instances moved to backup folder ""syt3old""
 * running deployment of old prod version
 * truncate revision index

{code:java}
m7tshrdsyt3m7b=# select * from m7_999_revision_index;
       index       |   timestamp
-------------------+---------------
 20695007860067022 | 1626242874013
(1 row)m7tshrdsyt3m7b=# truncate m7_999_revision_index;  {code}
 
 * start rabbitmq cluster
 * start cor1

 

cor1 is UP AND RUNNING
{code:java}
[tomcat@m7tenrgsyt3m7b1 shrd-syt3-cor1]$ ./check.sh
{ ""rc"": 0, ""code"": ""200"", ""info"": {""app"":""m7-core"",""build"":{""version"":""6.10.199""},""profiles"":""default,epex,remote-sob,epex-prodlike-data,env,non-prod""}, ""health"": {""status"":""UP"",""components"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""ping"":{""status"":""UP""},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}} }
 {code}","15/Jul/21 08:29;cv179;M7P Version 6.11.263

Deployment with migration is running:

[https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FCD-Pipeline%2FM7T_deploy_custom/detail/M7T_deploy_custom/1642/pipeline]

 ","15/Jul/21 08:43;cv179;Deployment and migration finished successfully, no errors, took about 10 minutes","16/Jul/21 09:35;cv179;reverting syt3 to M7P 6.11.258

 
 * stopping syt3 -> done
 * drop all databases -> done
 * stop patroni on pdb1 -> done
 * move old dump away from data partition -> done (to backup part)
 * resize data partition on pdb1 (delete and create empty)
 * start partoni on pdb1
 * reinit pdb1
 * switch to pdb1
 * stop pdb2, delete and resize FS, start pdb2, reinit
 * run db import steps (admin scripts, import, admin scripts)
 * clear journal
 * clear revision index
 * start the environment

 
{code:java}
systemctl stop patroni_m7tshrdsyt3async.service
cd /var/lib/pgsql_m7tshrdsyt3async/data
mv dump /var/lib/pgsql_m7tshrdsyt3async/backup/
cd ..
umount data
lvresize -f -L 140g /dev/mapper/datavg-lv_pgsql_m7tshrdsyt3async_data
mkfs.xfs -f /dev/mapper/datavg-lv_pgsql_m7tshrdsyt3async_data
mount data
chown postgres:postgres data
systemctl start patroni_m7tshrdsyt3async.service
patronictl -c /etc/patroni_m7tshrdsyt3async/config.yml list

# init file blocks replication, removed them on pdb2:
find -iname ""*.init.*"" -exec rm {} \;{code}
 
{code:java}
su - postgres
cd /var/lib/pgsql_m7tshrdsyt3async/backup/dump
for i in m7b rep mtt; do zcat m7tshrdsyt3${i}.sql.gz | /usr/pgsql-11/bin/psql -p 26006 -d m7tshrdsyt3${i}; done {code}
 

 ","16/Jul/21 13:01;cv179;Restore finished. Syt3 redeployed but db migration has issues. Asked in m7-test slack channel for help.

Rehearsal test finished.",,,,,,,,,,,,,,,,
Missing report alert for Reporter,M7P-8510,111970,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,ax460,ax460,22/Jun/21 13:14,08/Sep/21 15:14,16/Sep/21 14:11,,,,,,,Reporter,,,,7tops,,,,,,,"For ELTS
 * PROD,
 * CTPB,
 * SIMU and
 * ASIM

environments introduce alert that will trigger alert into SLACK in case
 # no report was generated within expected time. (newest report must be at least X minutes old)
 # generated file is empty (count bytes = 0)

Expected time = 15 minutes + 'trading period duration in minutes' / 6

Trading period is configurable, see [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/m7treporter/defaults/main.yml#L54]

Alternatively report name determines the period as well, eg. TC550_20200409T0000Z-20200409T0100Z.xml.zip -> 60minutes",,ax460,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6993,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,1036800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzwcu:i",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111970,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/21 13:44;ax460;please also update https://github.deutsche-boerse.de/dev/m7.reporter#alerting","03/Sep/21 13:48;iu252;[~ax460], questions regarding two alerts:
1. When I check metrics in chronograf, there is a tag ""m7_rpr_rpt_gen_time"". Is it the correct one for the alert? 

2. Is the tag ""m7_rpr_rpt_gen_size"" correct one for the alert?","03/Sep/21 15:28;ax460;[~iu252] I am not aware of those tags at all. Ideal solution would be check actual report file on file system instead of checking values in chronograf. Theoretically value may be there but actual report not present on file system.",,,,,,,,,,,,,,,,,,,,,,,,,
Upgrading pg_watch version PROD,M7P-8506,111935,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,21/Jun/21 16:04,08/Sep/21 09:06,16/Sep/21 14:11,23/Jun/21 10:44,,7tops_sprint120,,,,,,,,M7PRODOPS,,,,,,,"like we did in M7P-8028 we have to deploy new pg_watch2 version 1.8.4 for the following hosts: 
* m7prodpdb1
* m7prodpdb2
* m7prodpdb3
* m7prodpdb4
* m7proddbr1
* m7proddbr2",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"upgraded pgwatch2 with version 1.8.4 on all production database hosts in TRADING/AUCTION/CAPACITY
",,,,,,,,,,,,,,,,,,,,,,,,7344000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|i005xj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,see https://jira.deutsche-boerse.com/browse/M7P-8505,,,,,,,,,,"{""issueId"":111935,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"23/Jun/21 09:07;cs687;In the influxdb we saw that few fields were existing double with different types 
{code:java}
> SHOW FIELD KEYS ON metrics_m7_shared FROM table_stats
name: table_stats
fieldKey                   fieldType
--------                   ---------
analyze_count              integer
autoanalyze_count          integer
autovacuum_count           integer
idx_scan                   integer
idx_tup_fetch              integer
is_part_root               integer
n_dead_tup                 integer
n_live_tup                 integer
n_tup_del                  integer
n_tup_hot_upd              integer
n_tup_ins                  integer
n_tup_upd                  integer
no_autovacuum              integer
relpersistence             string
seconds_since_last_analyze float
seconds_since_last_analyze integer
seconds_since_last_vacuum  float
seconds_since_last_vacuum  integer
seq_scan                   integer
seq_tup_read               integer
table_size_b               integer
toast_size_b               integer
total_relation_size_b      integer
tx_freeze_age              integer
vacuum_count               integer
> SHOW FIELD KEYS ON metrics_xbid FROM table_stats
name: table_stats
fieldKey                   fieldType
--------                   ---------
analyze_count              integer
autoanalyze_count          integer
autovacuum_count           integer
idx_scan                   integer
idx_tup_fetch              integer
n_tup_del                  integer
n_tup_hot_upd              integer
n_tup_ins                  integer
n_tup_upd                  integer
seconds_since_last_analyze float
seconds_since_last_vacuum  float
seq_scan                   integer
seq_tup_read               integer
table_size_b               integer
toast_size_b               integer
total_relation_size_b      integer
vacuum_count               integer
{code}

seems like the old pgwatch2 client could not handle it and crashed during night. 
Upgraded the client 1.8.4 on host m7prodpdb4 and all is fine and working
","23/Jun/21 09:53;cs687;doing the rest for m7prodpdb1/2/3 and m7proddbr1/2 as well","23/Jun/21 10:44;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Upgrading pg_watch version SIMU,M7P-8505,111934,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,21/Jun/21 16:02,08/Sep/21 09:06,16/Sep/21 14:11,22/Jun/21 16:35,,7tops_sprint120,,,,,,,,M7PRODOPS,,,,,,,"like we did in M7P-8028 we have to deploy pg_watch2 with version 1.8.4 for the following hosts 
* m7simupdb1 (/)
* m7simupdb2 (/)
* m7simupdb3 (/)
* m7simupdb4 (/)
* m7simudbr1
* m7simudbr2",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,pg_watch version 1.8.4 were deployed for all simu database hosts for TRADING/AUCTION/CAPACITY ,,,,,,,,,,,,,,,,,,,,,,,,7344000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|i005xb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":111934,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/21 10:47;cs687;+*M7SIMUPDB4*+

1.) stopping old pg_watch service & run ""yum clean all"" 
* [root@m7simupdb4 ~]# systemctl stop pg_watch2.service

2.) cleaning up the old directory structure by the following: 
* rm -rf /etc/pg_watch2/
* rm -rf /etc/init.d/pg_watch2/
* rm -rf /opt/pg_watch2/
* rm -rf /etc/systemd/system/pg_watch2.service

*deployed the config for all the database instances*
{code:java}
-rw-r--r--  1 pgwatch2 pgwatch2  885 Jun 22 11:02 m7a-ampr-cute-pdb-sync4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  885 Jun 22 11:03 m7a-ampr-simu-pdb-sync4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  885 Jun 22 11:05 m7a-xeer-asim-pdb-sync4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  885 Jun 22 11:04 m7a-xeer-cute-pdb-sync4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  885 Jun 22 11:06 m7a-xeer-simu-pdb-sync4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:59 m7c-icsc-cute-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 11:22 m7c-shrd-dst1-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:44 m7t-elts-acut-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:46 m7t-elts-asim-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:48 m7t-elts-ctpb-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:45 m7t-elts-cute-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:43 m7t-elts-lipa-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:47 m7t-elts-simu-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:41 m7t-hupx-asim-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:39 m7t-hupx-cute-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:42 m7t-hupx-simu-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:50 m7t-plpx-lipa-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:51 m7t-plpx-simu-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 11:24 m7t-shrd-dst1-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 11:10 m7t-shrd-show-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 11:44 m7t-shrd-exte-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:52 m7t-xrpm-lipa-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:53 m7t-xrpm-simu-pdb-async4.yml

-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:32 m7t-xsop-asim-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:31 m7t-xsop-cute-pdb-async4.yml
-rw-r--r--  1 pgwatch2 pgwatch2  873 Jun 22 10:34 m7t-xsop-simu-pdb-async4.yml
{code}

and did it for all the other hosts as well!

","22/Jun/21 13:58;cs687;no errors came up, all fine! 
{code:java}
[root@m7simupdb3 ~]# systemctl status pgwatch2.service
● pgwatch2.service - pgwatch2
   Loaded: loaded (/etc/systemd/system/pgwatch2.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2021-06-22 13:56:00 CEST; 1min 41s ago
  Process: 37787 ExecStopPost=/bin/rm -rf /run/pgwatch2 (code=exited, status=0/SUCCESS)
  Process: 37784 ExecStop=/bin/kill -s TERM $MAINPID (code=exited, status=0/SUCCESS)
  Process: 37794 ExecStartPre=/bin/chown -R pg_watch2:pg_watch2 /run/pgwatch2 (code=exited, status=0/SUCCESS)
  Process: 37792 ExecStartPre=/bin/mkdir /run/pgwatch2 (code=exited, status=0/SUCCESS)
 Main PID: 37797 (pgwatch2-daemon)
   CGroup: /system.slice/pgwatch2.service
           └─37797 /bin/pgwatch2-daemon -c /etc/pgwatch2/pgwatch2.d -m /etc/pgwatch2/metrics/ --issl=true --ihost=influxdb.energy.svc.dbgcloud.io --iport=443 --iretentionname=autogen --idbname=metrics_m7_shared --conn-pooling=off

Jun 22 13:56:00 m7simupdb3 systemd[1]: Starting pgwatch2...
Jun 22 13:56:00 m7simupdb3 systemd[1]: Started pgwatch2.
{code}
","22/Jun/21 16:35;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Additional large Jenkins workers,M7P-8491,111866,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,xt853,xt853,18/Jun/21 09:07,15/Jul/21 10:25,16/Sep/21 14:11,02/Jul/21 08:31,,6.12.99,7Tops_Sprint121,,,,,,,jenkins,M7PRODOPS,,,,,,"*Description:* 

Create additional 8 Jenkins workers with greater computing capacity. At least 24GiB ram and with 8 cpu. Solely for m7, thus labeled like e.g. ""large-m7-trading"".

*Expected outcome:*

Current ""englobwkr"" workers are on the edge now, with running test consuming almost 13GiB ram leaving just 1GiB for caches, buffers, and future test expansion. Also some tests are substantially slower than on linux desktop, due to cpu load.

Expecting Jenkins pipelines won't fail on timeouts or insufficient memory.

*Main user:* m7-trading as sole user 

*Acceptance criteria:* 
 * .The ""large"" workers available to be used by m7-trading pipelines.",,cs687,xt853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"added the new aws instances with terraform deployment. 
deployed with ansible the necessary OS packages 
refer pull-reuqest

Created manually 8 jenkins nodes in jenkins platform ",,,,,,,,,,,,,,,,,,,,,,,,6566400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzn6ek:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 120,7tops Sprint 121,,,,,,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":111866,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/21 07:33;cs687;Prepare all the necessary changes and merged it to master 
https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/111/files

With terraform I deployed the freshly new AWS instances, and with ansible I deployed the OS and some necessary packages.

Last but not least I created 8 docker nodes in jenkins 
https://englobjci1.deutsche-boerse.de/computer/englobwkr-m7-large0/","02/Jul/21 08:31;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
remove EPEX ASIM environment data from inventory,M7P-8489,111854,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pd122,pd122,17/Jun/21 15:46,30/Jun/21 12:13,16/Sep/21 14:11,24/Jun/21 10:18,,7tops_sprint120,,,,Documentation,,,,7tops,inventory,,,,,,remove EPEX ASIM environment from inventory as well as Confluence versions table (https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=9603437),,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-784,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"environment removed from inventory, environment info and had its gluster volumes removed",,,,,,,,EPEX,,,,,,,,,,,,,,,,7344000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i005fr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111854,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"18/Jun/21 15:06;pd122;directories/instances removed:
* englobmon2
** /epex/epex-asim-coda1/
** /epex/epex-asim-lb-cardio1/
** /epex/m7t-epex-asim-cardio-lb.bkp/
** /epex/m7t-epex-asim-cardio.bkp
** /epex/logs/
*m7shrdextessl[1-4]
** /shrd/epex-asim-app-haproxy[1-4]/
** /shrd/epex-fsim-app-haproxy[1-4]/
* m7shrdextebha[1-2]
** /shrd/epex-asim-extbe-haproxy[1-2]/
** /shrd/logs/epex-asim-extbe-haproxy[1-2]/
* m7shrdextestk1
** /shrd/epex-asim-stk1/
* m7shrdexterep[1-2]
** /shrd/epex-asim-rep[1-2]/
** /shrd/epex-cute-rep[1-2]/
* m7shrdexteprx1
** /etc/xinetd.d/epex-asim-ixe
** /etc/xinetd.d/epex-fsim-ixe
** /etc/xinetd.d/epex-simu-ixe
** /etc/xinetd.d/epex-acut-ixe
* m7shrdexteprx2
** /etc/xinetd.d/epex-asim-hau
** /etc/xinetd.d/epex-fsim-hau
** /etc/xinetd.d/epex-simu-hau
** /etc/xinetd.d/epex-acut-hau
* m7shrdexteweb[1-2]
** /shrd/m7t-epex-asim-app-web[1-2]
** /shrd/m7t-epex-asim-rep-web[1-2]
** /shrd/logs/epex-asim-app-web[1-2]
** /shrd/logs/epex-asim-rep-web1[1-2]","18/Jun/21 15:15;pd122;volumes removed:
* m7simudbr[1-2]
** /epex/logs
** /epex","18/Jun/21 16:05;pd122;[SYSENGINT-784 ] created to remove epex leftover gluster volumes","21/Jun/21 10:03;pd122;PR https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2835 mered","22/Jun/21 16:28;pd122;PR https://github.deutsche-boerse.de/dev/energy.deployment.versions/pull/10 merged",,,,,,,,,,,,,,,,,,,,,,,
update grouping for external test envs (shared components) monitoring ,M7P-8487,111835,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,pd122,pd122,17/Jun/21 10:16,17/Jun/21 13:03,16/Sep/21 14:11,,,,,,,Monitoring,,,,7tops,monitoring,,,,,,"tag/group external test for shared infra (db, web, proxies,..) as SIMU (it is TEST currently)
- change _client_environment_ tag for telegraf: *shrd* -> *simu*",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7862400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:zd",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111835,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testing autovacuum parameters in SYT1,M7P-8468,111656,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,,cs687,cs687,14/Jun/21 14:30,08/Sep/21 13:47,16/Sep/21 14:11,03/Sep/21 10:55,,7tops_sprint125,,,,,,,,M,M7PRODOPS,,,,,,"After our GLUSTER FS performance issues we analyzed few things, like network, glusterfs configuration and the postgres database on m7prodpdb1/2/3/4 

all was discussed here: 
https://dbg-devops.slack.com/archives/G3X4L43GW/p1623219672108700

in cybertec channel we also talked about some few changes of our autovacuum parameters 
https://dbg-devops.slack.com/archives/CC9M54FDE/p1623227491061000 
which might be helpful to test it in systemtest1. 

Suggestion from [~fj021] and me was to test these few listed changes in SYT1 Database to see if it improves, atm it´s still unclear what the root-cause was for the higer glusterfs performance, could be a mixture of more things like autovacuum and market-start and such ",,cs687,,,,,,,,,,,,,,,,,M7P-8451,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzwcs:i",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111656,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/21 10:55;cs687;agreed with Aurelien to close the ticket. 
SYT1 is few month now blocked because of some kafka root cause analyzes. 
Plan is to get rid of this issue with 6.12 and not mess up SYT1 to manipulate maybe some test-results for KAFKA ",,,,,,,,,,,,,,,,,,,,,,,,,,,
ATE4 LB is pointing only to second instance,M7P-8467,111639,,Bug,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,oy574,oy574,14/Jun/21 11:59,14/Jun/21 14:32,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"ATE4 LB for Reporting Engine is pointing only to second instance, if that is not running, apache returns 503.

Please also check other environments if we don't have the same misconfiguration.",,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8121600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,14/Jun/21 11:59,,[],,,,,,,,None,,,M7T,,,,"2|hzzxu6:u",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111639,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[ESP] API structure,M7P-8465,111610,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,nz893,op211,op211,11/Jun/21 15:35,16/Jun/21 11:17,16/Sep/21 14:11,14/Jun/21 08:25,,7tops_sprint119,,,,,,,,7tops,,,,,,,"Define the API:
 * data structure for a JSON/StatusDB/StatusFile
 * filters
 * other parameters",,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Not needed.,,,,,,,,,,,,,,,,,,,,,,,,8294400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00413:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111610,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Internal Env´s prod/customer product like (certificates) ,M7P-8457,111572,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Trivial,,cs687,cs687,cs687,10/Jun/21 14:19,24/Jun/21 11:35,16/Sep/21 14:11,,,,,,,,,,,certificates,M7PRODOPS,,,,,,"Talked with Kamil Ondrak about the topic in M7P-8286 and we came to the following agreement:
After replacing new certificates (from syt1) and accessing the trading GUI via IP-Address in Browser, it says that the certificates are valid, but Firefox complains about

{code:java}
Websites prove their identity via certificates. Firefox does not trust this site because it uses a certificate that is not valid for 10.136.20.12:61800. The certificate is only valid for *.shrd.m7.deutsche-boerse.com.
{code}

The reason for that might be, that we have self-signed certificates and these are not really matching with name * .shrd.m7.deutsche-boerse.com

So the idea is to communicate with CCI to add the proper changes on LB to make this possible and afterwards we have to create our Certificate by SSL-Admin. 

This changes need some time, so we have to count with 2-3 Sprints for that.",,cs687,fh971,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5260,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7257600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:yi",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111572,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jun/21 07:54;cs687;updated the M7_Environment.xlsx Sheet with the proper URL´s:
+SYSTEMTEST+
* syt1|2|3-1.enrg.m7.deutsche-boerse.com
* syt1|2|3-2.enrg.m7.deutsche-boerse.com","24/Jun/21 11:35;cs687;send out a email to CCI 

{code:java}
Hi CCI,

we need to setup new URLs with DNS and Public IPs for already existing LoadBalancer configs.
Attached you find an Excel with the mapping.

It’s about the following new URLs:

	syt1-1.enrg.m7.deutsche-boerse.com
	syt1-2.enrg.m7.deutsche-boerse.com
	syt2-1.enrg.m7.deutsche-boerse.com
	syt2-2.enrg.m7.deutsche-boerse.com
	syt3-1.enrg.m7.deutsche-boerse.com
	syt3-2.enrg.m7.deutsche-boerse.com
	ate2.enrg.m7.deutsche-boerse.com
	ate3.enrg.m7.deutsche-boerse.com
	ate4.enrg.m7.deutsche-boerse.com

Thanks in advance,

Cheers,
Steffen
{code}

Tickets goes into waiting!",,,,,,,,,,,,,,,,,,,,,,,,,,
Make Component field in Jira as not mandatory,M7P-8388,111062,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,yq577,sJ194,sJ194,27/May/21 12:17,16/Jun/21 11:17,16/Sep/21 14:11,07/Jun/21 08:51,,6.12.70,7tops_sprint119,,,,,,,M7PRODOPS,S,,,,,,"Make component field not required (not mandatory) in transition screen (→ Resolved) in Jira in M7P workflow. 

Motivation: We discussed it and agreed on it during overall retrospective meeting that this field is not usable for any specific data analysis, so it would not make any sense to keep it as a mandatory field

 ",,sJ194,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8261,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Issue fixed,,,,,,,,,,,,,,,,,,,,,,,,8726400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzth0:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 119,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":111062,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/21 12:10;yq577;Hi [~sJ194],

I disable the mandatory option for component field in Jira.
Please check and confirm if all is fine.

Thanks and Regards,
sharad","07/Jun/21 08:50;yq577;Hi [~sJ194],

I am resolving this ticket.
If any issue please revert.

Thanks and Regards,
Sharad",,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: M7 API PROD - TRAILSTONE - AMQP disconnections,M7P-8355,110717,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,op211,tj898,tj898,19/May/21 14:58,08/Sep/21 15:23,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"dear Support team,

TRAILSTONE suffers from frequent AMQP disconnections and tries to identify the root cause.

As shown on the attached graph for CXTREW20 / app_id TRSTITN_0, they experience 4 or more disconnections a day, with a peak of 15. (list of disconnections and timestamps attached).

On top of that TRAILSTONE provided on Friday 14 May a case where they got disconnected at the same time of ASIM and PROD at 14:28 CEST (Word doc attached), with the same error: 
2021-05-14 14:28:55,100 [EpexConnection] INFO  - Shutdown Message: Connection Shutdown caused by: Library, Reply Code: 541, ReplyText: Unexpected Exception
2021-05-14 14:28:55,100 [EpexConnection] INFO  - Cause: System.Net.Sockets.SocketException (0x80004005): A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

Could you please check what you have in your logs:
-  for this event/time on Friday
- and another one from the provided Excel list ?

Many thanks and regards,
JM",,oy574,tj898,yq577,,,,,,,,,,,,,,,,,SERVICE-10431,,,,,,,,,,,,,,,,,,,,"19/May/21 14:58;tj898;202105 TRAILSTONE Disconnects 20210401-20210506.xlsx;https://jira.deutsche-boerse.com/secure/attachment/95461/202105+TRAILSTONE+Disconnects+20210401-20210506.xlsx","19/May/21 14:58;tj898;202105 TRAILSTONE disconnections.pptx;https://jira.deutsche-boerse.com/secure/attachment/95462/202105+TRAILSTONE+disconnections.pptx","19/May/21 14:58;tj898;20210514 ASIM PROD disconnection.docx;https://jira.deutsche-boerse.com/secure/attachment/95463/20210514+ASIM+PROD+disconnection.docx",,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,Report a problem or bug,,,,,,,,,,8121600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzwcn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 118 (PS),7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110717,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"19/May/21 14:58;jm.pournin@epexspot.com;

[^202105 TRAILSTONE Disconnects 20210401-20210506.xlsx] _(21 kB)_

[^202105 TRAILSTONE disconnections.pptx] _(48 kB)_

[^20210514 ASIM PROD disconnection.docx] _(20 kB)_","19/May/21 14:58;jm.pournin@epexspot.com;Please check the M7 logs and Load Balancer logs. I ask TRAILSTONE their IP address.","19/May/21 14:58;tj898;Hi [~jm.pournin@epexspot.com], good morning.

I'll have a look into this, and will post our findings here.

Cheers,

Hugo","19/May/21 14:58;lu515;This ticket was discussed in the OPAC meeting to be handled as a chargeable additional service. For approval that it will be charged please use that usual approval process (but someone else than Samet, as he is on sick leave for another few weeks) ","19/May/21 14:58;s.morin@epexspot.com;Hello Hugo, 

Please find below TrailStone IP addresses:

1/ PROD leased line:             10.136.150.16
    Internet circuits
        - Primary:               217.110.96.138
        - Secondary:          88.84.137.242
                                
 2/ UAT leased line:                10.136.148.20

Thanks

Sophie","21/May/21 10:52;oy574;Quick check showed no obvious problem on our side. RabbitMQ logs contained good old ""Client unexpectedly closed TCP connection"", which indicates the problem is on client side. I suggest they try to run ComTrader alongside their client and see if they're seeing the disconnects as well.","07/Jun/21 14:02;oy574;Flow of single connection of the user from RMQ logs:

May 7th 2021, 00:22:20.385 INFO

 
{noformat}
<0.3340.1739> connection <0.3340.1739> (10.136.151.248:55640 -> 10.139.53.202:50060): user 'CXTREW20' authenticated and granted access to vhost 'app'{noformat}
May 7th 2021, 00:23:05.389 ERROR
{noformat}
<0.3340.1739> closing AMQP connection <0.3340.1739> (10.136.151.248:55640 -> 10.139.53.202:50060): {inet_error,enotconn}{noformat}
ENOTCONN is a socket error when the socket is no longer connected.

In other cases, e.g. 0.3627.1720, there was a WARNING  stating that _client unexpectedly closed TCP connection._

Also, in some cases, e.g. 0.16730.1739, the connection was terminated because server didn't receive AMQP heartbeats from client: _missed heartbeats from client, timeout: 30s._
The problem doesn't seem to be caused by the application (M7). Might be on the client side, or in the infrastructure (LB, FW, HA, ...)","14/Jun/21 10:55;yq577;Update in SAP ticket 20924524 regarding the Log


{code:java}
No drop in the firewall on May 30th 2021 at 08:01:09.954 between 10.136.151.247:34878 and 10.139.53.200:50060
No drop in the firewall on  May 14th 2021 at 14:59:02.289 between 10.136.151.247:59360 and  10.139.53.200:50060
No drop in the firewall on May 26th 2021 at 12:09:36.603  between 10.136.151.250:56266  and 10.139.53.200:50060
No drop in the firewall on May 15th 2021, 14:49:31.206 between 10.136.151.250:37882 and 10.139.53.200:50060
nodrop in firewall on May 15th 2021 at 14:44:48.130 between 10.136.151.247:43532 and 10.139.53.202:50060
no drop in the firewall on May 14th 2021 at 14:58:53.674 between 10.136.151.250:40500 and 10.139.53.202:50060
no drop in the firewall on May 14th 2021 at 10:24:56.062 between 10.136.151.248:54696 and 10.139.53.202:50060
no drop in the firewall on May 15th 2021 at 11:36:09.341 between 10.136.151.250:35066 and 10.139.53.168:50060
no drop in the firewall on May 14th 2021 at 10:25:01.606 between 10.136.151.248:37134 and 10.139.53.168:50060
no drop in the firewall on  May 13th 2021 at 02:01:51.917 between 10.136.151.247:50978 and 10.139.53.168:50060
10.136.151.248:45536 -> 10.139.53.169:50060
10.136.151.247:41750 -> 10.139.53.169:50060
10.136.151.250:37266 -> 10.139.53.169:50060
10.136.151.248:48184 -> 10.139.53.170:50060
10.136.151.247:51638 -> 10.139.53.170:50060
10.136.151.250:45658 -> 10.139.53.170:50060
no drop in the firewall on May 13th 2021 at 16:35:27.161 between 10.136.151.248:45536 and  10.139.53.169:50060
no drop in the firewall on May 15th 2021 at 10:50:21.369 between 10.136.151.247:41750 and 10.139.53.169:50060
no drop in the firewall on May 15th 2021 at 03:49:13.150 between 10.136.151.250:37266 and 10.139.53.169:50060
no drop in the firewall on May 14th 2021 between 10.136.151.248:48184 and 10.139.53.170:50060
no drop in the firewall on May 14th 2021 between 10.136.151.247:51638 and 10.139.53.170:50060
no drop in the firewall on May 14th 2021 between 10.136.151.250:45658 and 10.139.53.170:50060
{code}
",,,,,,,,,,,,,,,,,,,,
Migrate disk space alerts for postgres to check-mk,M7P-8346,110693,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,cv179,cv179,19/May/21 12:19,14/Jun/21 10:54,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"* keep levels for tick as they are
 * add opsgenie techops hotline notification to checkmk
 * add rules based on:

 ** free disk space %
 ** free disk space GB
 ** projection

 ",,cv179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10368000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzxu4:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110693,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create EBSM database at M7PRODDBR1/2,M7P-8321,110489,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,14/May/21 11:20,30/Jun/21 12:13,16/Sep/21 14:11,22/Jun/21 15:08,,6.12.80,7tops_sprint120,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,Create the db dump of the current ebsm db (m7simupdbX:24059) and clone it to the new location (M7PRODDBR1/2),,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"ebsm db cluster created on m7proddbr1/2, data migrated from old ebsm",,,,,,,,,,,,,,,,,,,,,,,,8726400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztg7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110489,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"26/May/21 14:11;iu252;Ports for db are already defiened: https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/ports.yml#L127-L128","07/Jun/21 10:25;iu252;Changed ports for enshrdprodebsm: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2818","07/Jun/21 10:26;iu252;Created vault entries: https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/energy/shrd/prod/db/","07/Jun/21 10:31;iu252;Deployed patroni cluster:

{noformat}
[iu252@enprodauto1 {master L | ?1} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_patroni.yml --limit ""en*shrd*prod*dbr-ebsm*"" -k -K -b  --tags ebsm
SSH password:
SUDO password[defaults to SSH password]:

PLAY [deploy patroni resources to an environment] *******************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************
ok: [energy-shrd-prod-dbr-ebsm2]
ok: [energy-shrd-prod-dbr-ebsm1]

TASK [patroni : install patroni for RedHat] *************************************************************************************************************************************************
ok: [energy-shrd-prod-dbr-ebsm2]
ok: [energy-shrd-prod-dbr-ebsm1]

TASK [patroni : install postgresql package] *************************************************************************************************************************************************
ok: [energy-shrd-prod-dbr-ebsm2] => (item=postgresql11)
ok: [energy-shrd-prod-dbr-ebsm1] => (item=postgresql11)
ok: [energy-shrd-prod-dbr-ebsm2] => (item=postgresql11-server)
ok: [energy-shrd-prod-dbr-ebsm1] => (item=postgresql11-server)
ok: [energy-shrd-prod-dbr-ebsm2] => (item=postgresql11-contrib)
ok: [energy-shrd-prod-dbr-ebsm1] => (item=postgresql11-contrib)
ok: [energy-shrd-prod-dbr-ebsm2] => (item=postgresql11-debuginfo)
ok: [energy-shrd-prod-dbr-ebsm1] => (item=postgresql11-debuginfo)
ok: [energy-shrd-prod-dbr-ebsm2] => (item=expect)
ok: [energy-shrd-prod-dbr-ebsm1] => (item=expect)
..........
..........
{noformat}
","07/Jun/21 10:32;iu252;Patroni cluster status:

{noformat}
[root@m7proddbr1 ~]# patronictl -c /etc/patroni_enshrdprodebsm/config.yml list
+ Cluster: enshrdprodebsm (6970965744247103912) -------+----+-----------+
|   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------+----------------------+--------+---------+----+-----------+
| m7proddbr1 | 10.139.135.221:20022 | Leader | running |  1 |           |
| m7proddbr2 | 10.139.135.222:20022 |        | running |  1 |         0 |
+------------+----------------------+--------+---------+----+-----------+
[root@m7proddbr1 ~]#
{noformat}
","07/Jun/21 12:35;iu252;Created ADMIN/INSTALL directory and copied the scripts:

{noformat}
-bash-4.2$ hostname
m7proddbr1
-bash-4.2$ pwd
/var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL
-bash-4.2$ ls -l
total 24
-rwxr-xr-x 1 postgres postgres 101 Jun  7 12:29 001_DROP_DATABASE.sql
-rwxr-xr-x 1 postgres postgres 189 Jun  7 12:29 010_CREATE_DATABASE.sql
-rwxr-xr-x 1 postgres postgres  75 Jun  7 12:29 020_CREATE_SCHEMA.sql
-rwxr-xr-x 1 postgres postgres 116 Jun  7 12:33 030_ALTER_ROLE.sql
-rwxr-xr-x 1 postgres postgres 761 Jun  7 12:29 034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
-rwxr-xr-x 1 postgres postgres 137 Jun  7 12:29 035_CREATE_NETBACKUP_ROLE.sql
{noformat}
","07/Jun/21 12:39;iu252;Executed ADMIN-scripts:

{noformat}
-bash-4.2$ psql -p 20022
psql (11.9)
Type ""help"" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(3 rows)

postgres=# \i /var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql
psql:/var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql:1: NOTICE:  database ""ebsm"" does not exist, skipping
DROP DATABASE
psql:/var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql:2: NOTICE:  role ""ebsm"" does not exist, skipping
DROP ROLE
psql:/var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql:3: NOTICE:  role ""ebsadmin"" does not exist, skipping
DROP ROLE
postgres=# \i /var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql
CREATE ROLE
CREATE DATABASE
ALTER DATABASE
psql:/var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql:4: ERROR:  role ""ebsm"" already exists
CREATE ROLE
postgres=# \i /var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/020_CREATE_SCHEMA.sql
You are now connected to database ""ebsm"" as user ""postgres"".
CREATE SCHEMA
DROP SCHEMA
ebsm=# \i /var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/030_ALTER_ROLE.sql
ALTER ROLE
ALTER ROLE
ebsm=# \i /var/lib/pgsql_enshrdprodebsm/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
ebsm=>
ebsm=> \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 ebsm      | ebsm     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/ebsm             +
           |          |          |             |             | ebsm=CTc/ebsm        +
           |          |          |             |             | ebsmadmin=c/ebsm
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

ebsm=>
{noformat}
",,,,,,,,,,,,,,,,,,,,,
m7proddpu: set up monitoring,M7P-8320,110488,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,iu252,dp007,dp007,14/May/21 11:18,08/Sep/21 15:23,16/Sep/21 14:11,,,,,,,EBSM,,,,7tops,EBSM,M7PRODOPS,,,,,,,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,777600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztfz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110488,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/21 14:50;iu252;1. clarify if some of FS can be excluded from monitoring.
2. clarify with Andrei if it's possible to solve the issues with swap-FS usage.",,,,,,,,,,,,,,,,,,,,,,,,,,,
reroute the log sending tool from all prod-like envs,M7P-8319,110487,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,14/May/21 11:16,08/Sep/21 13:47,16/Sep/21 14:11,25/Aug/21 11:27,,7tops_sprint125,,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,"Please reroute the log sending tool from all prod environments so it will send logs to *proddata.srv.energy* instead of m7shrdebsm1 using new copy script:
 * m7a_xeer
 * m7c_icsc
 * m7t_elts
 * m7t_hupx
 * m7t_plpx
 * m7t_xrpm
 * m7t_xsop
 * xb_xbid",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,rerouted the log sending tool from all prod-like envs,,,,,,,,,,,,,,,,,,,,,,,,7344000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztfr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110487,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"22/Jun/21 15:18;iu252;M7 part done.","22/Jun/21 15:18;iu252;Working on XBID PROD",,,,,,,,,,,,,,,,,,,,,,,,,,
copy ebsm scripts to proddpu.srv.energy,M7P-8318,110486,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,14/May/21 11:10,30/Jun/21 12:13,16/Sep/21 14:11,22/Jun/21 15:16,,6.12.80,7tops_sprint120,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,"1) create users on new ebsm dpu host (proddpu.srv.energy)
 * ebsmrun:ebsmrun
 * logmover:logmover
 * logreader:logreader
 * transfer:transfer

2) Copy ebsm script resources to proddpu.srv.energy: (ebsmrun:ebsmrun)

/opt/ebsm/m7/
/opt/ebsm/xbid/

3) Copy logmover scripts from /opt/logmover/ (logmover:logmover)

4) Copy all files from /home/logreader/logparser/ (logreader:logreader)

5) Copy all subfolders from /home/logmover/ (logmover:logmover)",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,scripts migrated,,,,,,,,,,,,,,,,,,,,,,,,10800000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztfj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110486,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Requesting/Replace Certificates for XRPM-SIMU,M7P-8291,110255,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,10/May/21 13:43,19/May/21 11:28,16/Sep/21 14:11,17/May/21 08:53,,6.12.30,7tops_sprint117,,,Certificates,,,,M7PRODOPS,,,,,,,"{code:java}
[root@m7shrdexteweb1 conf.d]# openssl x509 -in /shrd/ssl/cute1.epex-lts.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            fb:89:3f:84:87:ff:61:15:d6:c7:5e:16:10:58:84:e2
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: May  9 00:00:00 2019 GMT
            Not After : May  8 23:59:59 2021 GMT
{code}

added the env to the certificate repository
https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/25/files
{code:java}
      simu:
        - ""simu1.opcom.m7.deutsche-boerse.com""
        - ""simu2.opcom.m7.deutsche-boerse.com""
{code}

DESCRIPTION:
* for requesting new certs we have to do the following steps:
** Project A. Generate CSR (Ansible Deployment)
** Create Service Request and forward the mail to ssl-admin
** Ones we got the new certs back - save as Certificate only, PEM encoded
** uploaded the new ones with the following jenkins job Project B. Import Cert to Vault (Ansible Deployment)

*  for replacing the new certs we have to do the following steps 
** backuping the old certificates on the hosts m7shrdextewebX & m7shrdextesslX 
** replacing the certs with the command: 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-simu-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-simu-app-haproxy*"" --tags certs -k -K -b
** checking the results afterwards
** restarting the instances like this 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-simu-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-simu-app-haproxy*"" --tags stop,start -k -K -b
** checking the web-gui if certs were replaced ",,cs687,iu252,,,,,,,,,,,,,,,,M7P-8124,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"can be closed, handled by alex orlov ",,,,,,,,OPCOM,,,,,,,,,,,,,,,,10540800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzvyn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":110255,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"11/May/21 06:47;iu252;Generated csr: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/108/console","11/May/21 06:48;iu252;Created IT-Service Request 1A5778, waiting for approval.","17/May/21 08:47;iu252;Certificate replaced on Saturday.","17/May/21 08:53;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Fix TLS certificates on internal environemts,M7P-8286,110189,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,jv861,jv861,07/May/21 12:15,16/Jun/21 11:17,16/Sep/21 14:11,10/Jun/21 14:12,,6.12.70,7tops_sprint119,,,,,,,M7PRODOPS,S,,,,,,"Current TLS certificates on internal envs (ATEs and SYTs) for enquiry are not correct. They are expired and issued for different domains.

Could you please provide valid certificates (and maybe also some automatic process of renewal, if possible)?",,cs687,jv861,PB446,wn626,,,,,,,,,,,,,,M7P-5260,,,,,,,,,,,M7P-8463,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"the following things was done: 

* 1.) copied the certificates in vault from syt1 to all the mentioned envs above -> https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/shrd/syt1/cert/
* 2.) redeployed apache: ansible-playbook playbooks/deploy_apache.yml --limit ""m7t-shrd-syt3-app-web*"" --tags certs -k -K -b *# tags certs to replace the new certs*
* 3.) redeployed haproxy:  ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t-shrd-syt2-app-ssl*"" --tags certs -k -K -b
* 4.) restarted apache: ansible-playbook playbooks/deploy_apache.yml --limit ""m7t-shrd-syt3-app-web*"" --tags stop,start -k -K -b
* 5.) restarted haproxy:  ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t-shrd-syt2-app-ssl*"" --tags stop,start -k -K -b

Double checking the Trading GUI if the certificates proper replaced

Talked with [~jv861] about the topic and we came to the following agreement: 
After replacing the certificates and accessing the trading GUI via IP-Address in Browser, it says that the certificates are valid, *but* Firefox complains about 
{code:java}
Websites prove their identity via certificates. Firefox does not trust this site because it uses a certificate that is not valid for 10.136.20.12:61800. The certificate is only valid for *.shrd.m7.deutsche-boerse.com.
{code}
The reason for that might be, that we have self-signed certificates and these are not really matching with name * *.shrd.m7.deutsche-boerse.com*
So the idea is to create another ticket which will be linked to the topic above and we are requesting new LoadBalancer entries for these env´s that we are also able to use the proper names syt2.shrd.m7.deutsche-boerse.com to open the Trading GUI. For that we need to contact CCI for the LB changes and SSL-ADMIN for creating fresh new certificates and redeploy apache and HA ones again. 

We should calculate around 2-3 Sprints for that. ",,,,,,,,,,,,,,,,,,,,,,,,8380800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-8368,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztgw:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 119,,,,,,,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":110189,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/21 15:31;PB446;Shadow follower: [~wn626]
","09/Jun/21 13:37;cs687;*SYT2:* (/)
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/syt2.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:17:e9:47:c1:c4:42:7b:1f:33:a2:dc:58:54:7e:2a
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jan 18 00:00:00 2019 GMT
            Not After : Jan 17 23:59:59 2021 GMT
{code}

*SYT3* (/)
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/syt3.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:17:e9:47:c1:c4:42:7b:1f:33:a2:dc:58:54:7e:2a
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jan 18 00:00:00 2019 GMT
            Not After : Jan 17 23:59:59 2021 GMT
{code}

*ATE2* (/)
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/ate2.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:17:e9:47:c1:c4:42:7b:1f:33:a2:dc:58:54:7e:2a
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jan 18 00:00:00 2019 GMT
            Not After : Jan 17 23:59:59 2021 GMT
{code}

*ATE3* (/)
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/ate3.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:17:e9:47:c1:c4:42:7b:1f:33:a2:dc:58:54:7e:2a
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jan 18 00:00:00 2019 GMT
            Not After : Jan 17 23:59:59 2021 GMT
{code}

*ATE4* (/)
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/ate4.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0c:17:e9:47:c1:c4:42:7b:1f:33:a2:dc:58:54:7e:2a
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jan 18 00:00:00 2019 GMT
            Not After : Jan 17 23:59:59 2021 GMT
{code}

all the env´s have an expired certificate at 17 of January 2021 and even with a wrong CN ""*syt2.xbid.m7.deutsche-boerse.com*"", mostly copied&paste 

*{color:#00875A}For SYT1 the certificate looks like valid and also proper issues with CN{color}*
{code:java}
[root@m7tshrdinteweb1 conf.d]# openssl x509 -in /shrd/ssl/syt1.shrd.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            41:c2:0c:d0:f2:0f:d0:81:c2:7c:2f:48:2f:8a:2d:38:0e:4e:88:05
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=DE, L=Eschborn, O=Deutsche Boerse Group, CN=DBG CLIENT CA M7T TEST
        Validity
            Not Before: Jan 19 11:08:29 2021 GMT
            Not After : Jan 19 11:08:58 2023 GMT
        Subject: O=Deutsche Boerse, OU=shrd-app, CN=*.shrd.m7.deutsche-boerse.com
{code}
","10/Jun/21 11:06;cs687;h2. The following steps were made:

* 1.) copied the certificates in vault from syt1 to all the mentioned envs above -> https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/shrd/syt1/cert/
* 2.) redeployed apache: ansible-playbook playbooks/deploy_apache.yml --limit ""m7t-shrd-syt3-app-web*"" --tags certs -k -K -b *# tags certs to replace the new certs*
* 3.) redeployed haproxy:  ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t-shrd-syt2-app-ssl*"" --tags certs -k -K -b
* 4.) restarted apache: ansible-playbook playbooks/deploy_apache.yml --limit ""m7t-shrd-syt3-app-web*"" --tags stop,start -k -K -b
* 5.) restarted haproxy:  ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t-shrd-syt2-app-ssl*"" --tags stop,start -k -K -b

Double checking the Trading GUI if the certificates proper replaced

Talked with [~jv861] about the topic and we came to the following agreement: 
After replacing the certificates and accessing the trading GUI via IP-Address in Browser, it says that the certificates are valid, *but* Firefox complains about 
{code:java}
Websites prove their identity via certificates. Firefox does not trust this site because it uses a certificate that is not valid for 10.136.20.12:61800. The certificate is only valid for *.shrd.m7.deutsche-boerse.com.
{code}
The reason for that might be, that we have self-signed certificates and these are not really matching with name * *.shrd.m7.deutsche-boerse.com*
So the idea is to create another ticket which will be linked to the topic above and we are requesting new LoadBalancer entries for these env´s that we are also able to use the proper names syt2.shrd.m7.deutsche-boerse.com to open the Trading GUI. For that we need to contact CCI for the LB changes and SSL-ADMIN for creating fresh new certificates and redeploy apache and HA ones again. 

We should calculate around 2-3 Sprints for that. ","10/Jun/21 14:12;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
MW for HP critical dbpatching pdb1/2/3/4 on PROD + shared PROD VMs OS upgrade,M7P-8273,110133,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,yq577,rehapav,rehapav,06/May/21 10:19,15/Sep/21 10:27,16/Sep/21 14:11,15/Sep/21 10:27,,,,,,,,,,7tops,,,,,,,"On <date> <time>, please
 * Upgrade OS to RH 7.9
 * Oranizeze HP critical patch for our database servers

Details 

*HP Patching*
 * [https://github.deutsche-boerse.de/pages/dev/energy.infra.hw/inventory/#view=inventory&filter=hw_manufacturer%20%3D%20HPE%20AND%20x_group%20!~%20A2A%20AND%20x_purpose%20~%20Core%7CDB%20AND%20(hw_fw_ver%20%3D%20U30.v2.32%20OR%20hw_fw_ver%20%3D%20P89.v1.52)]
 * Its quite critical, requires 1 hour per db
 * Separate MW recommended outside of any release

PDBs:
 * m7prodpdb1
 * m7prodpdb2
 * m7prodpdb3
 * m7prodpdb4

What about dbrs?
 * m7proddbr1
 * m7proddbr2

 

*Upgrade OS to RH 7.9*

for environments
 * SHARED PROD#
 * list of VMs - tbd

Impacted PROD envs
 * ELTS PROD
 * OPCOM PROD
 * TGE PROD
 * BSP PROD
 * HUPX PROD
 * M7A XEER PROD
 * M7A AMPR PROD
 * ICSC PROD

todo
 * agreed MW cca 3 hours in September in business hour
 * Announce it with 2 weeks lead time to all the customers
 * organize syseng (1 ppl)+techops support (2 ppl)",,rehapav,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-10313,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Change completed successfully,,,,,,,,,,,,,,,,,,,,,,,,5702400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzkgv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110133,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jul/21 09:06;yq577;Alexis is a resource from Syseng team to support on this task",,,,,,,,,,,,,,,,,,,,,,,,,,,
HP critical dbpatching firmware upgrade - internal test,M7P-8271,110131,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,06/May/21 10:17,02/Jun/21 10:44,16/Sep/21 14:11,21/May/21 07:29,,6.12.44,7tops_sprint118,,,Database,,,,M7PRODOPS,,,,,,,"Oranizeze HP critical patch firmware upgrade for our database servers
 * [https://github.deutsche-boerse.de/pages/dev/energy.infra.hw/inventory/#view=inventory&filter=hw_manufacturer%20%3D%20HPE%20AND%20x_group%20!~%20A2A%20AND%20x_purpose%20~%20Core%7CDB%20AND%20(hw_fw_ver%20%3D%20U30.v2.32%20OR%20hw_fw_ver%20%3D%20P89.v1.52)]
 * Its quite critical, requires 1 hour per db
 * Separate MW recommended outside of any release

PDBs:

m7testpdb1

m7testpdb2

 

scheduled together with systemtest1 OS upgrade - SERVICE-9844",,cs687,cv524,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-10313,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,firmeware was updated on both hosts m7testpdb1/2,,,,,,,,,,,,,,,,,,,,,,,,10195200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzth3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":110131,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/May/21 15:02;cv524;h2. {color:#FF8B00}Consulted with [~wm282].{color}
{color:#00875A}*I have got all necessary instructions to be able execute necessary operation*{color} of {color:#00875A}*upgrading firmware version*{color} on involved physical hosts.
In case of final confirmation, {color:#00875A}*I will be able to run mentioned operations*{color} with preliminary agreement on {color:#00875A}*Thursday 20.05.2021 afternoon.*{color}

Created dedicated SYSENGINT-692 ticket to track the operation from ""System Engineering"" side.","20/May/21 11:14;cs687;1.) checked that all the leader nodes are running on m7testpdb1 - starting with *m7testpdb2*
*just switched leader for syt3*
 
2.) stopped all patroni instances on m7testpdb2
{code:java}
for i in `ls /etc/ |grep patroni_`;do echo $i; systemctl stop $i;done
{code}

3.) had over to lambert to do the update - action takes round about ~45 minutes


the same was done for *m7testpdb1*","21/May/21 07:29;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Trading - enable hot plug feature for VMs - non-PROD,M7P-8268,110123,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,yq577,rehapav,rehapav,06/May/21 09:38,08/Sep/21 15:13,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"*Acceptance criteria*
 * Hot Plug is enabled for CPU and memory

*Requires* 
 * shut down
 * and start-up of VM

VMs:
|m7eltsctpbamq1|
|m7eltsctpbamq2|
|m7eltslipaamq1|
|m7eltslipaamq2|
|m7hupxsimuamq1|
|m7hupxsimuamq2|
|m7hupxsimuamq3|

|m7shrdexteprx1||Done|SERVICE-10344|
|m7shrdexteprx2||Done|SERVICE-10344|
|m7shrdextessl1|
|m7shrdextessl2|
|m7shrdextessl3|
|m7shrdextessl4|
|m7shrdexteweb1|
|m7shrdexteweb2|

|m7shrdsimuglfs1|
|m7shrdsimuglfs2|
|m7xsopsimuamq1|
|m7xsopsimuamq2|
|m7xsopsimuamq3|
|m7xsopsimum7b1|
|m7xsopsimum7b2|",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-10345,SERVICE-10312,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11491200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzkfz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":110123,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Requesting/Replace Certificates for EPEX-CUTE,M7P-8251,109940,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,op211,cs687,cs687,04/May/21 07:43,19/May/21 11:28,16/Sep/21 14:11,07/May/21 11:13,,7tops_sprint117,,,,uknown,,,10/May/21 00:00,certificates,M7PRODOPS,,,,,,"{code:java}
[root@m7shrdexteweb1 conf.d]# openssl x509 -in /shrd/ssl/cute1.epex-lts.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            fb:89:3f:84:87:ff:61:15:d6:c7:5e:16:10:58:84:e2
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: May  9 00:00:00 2019 GMT
            Not After : May  8 23:59:59 2021 GMT
{code}

added the env to the certificate repository
https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/25/files
{code:java}
      simu:
        - ""simu1.opcom.m7.deutsche-boerse.com""
        - ""simu2.opcom.m7.deutsche-boerse.com""
{code}

DESCRIPTION:
* for requesting new certs we have to do the following steps:
** Project A. Generate CSR (Ansible Deployment)
** Create Service Request and forward the mail to ssl-admin
** Ones we got the new certs back - save as Certificate only, PEM encoded
** uploaded the new ones with the following jenkins job Project B. Import Cert to Vault (Ansible Deployment)

*  for replacing the new certs we have to do the following steps 
** backuping the old certificates on the hosts m7shrdextewebX & m7shrdextesslX 
** replacing the certs with the command: 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-simu-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-simu-app-haproxy*"" --tags certs -k -K -b
** checking the results afterwards
** restarting the instances like this 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-simu-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-simu-app-haproxy*"" --tags stop,start -k -K -b
** checking the web-gui if certs were replaced ",,cs687,,,,,,,,,,,,,,,,,M7P-8124,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Certificates replaced.,,,,,,,,,,,,,,,,,,,,,,,,11664000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzzubr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109940,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"04/May/21 07:56;cs687;*1.) Creating CSR-Request*
Project A. Generate CSR (Ansible Deployment)
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/

Afterwards we received an email for SSL-Team and added two new entries in vault
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/elts/cute/cert/

Request_cute1.epex-lts.m7.deutsche-boerse.com
Request_cute2.epex-lts.m7.deutsche-boerse.com
Created: IT-Service Request with the ID-No: 7B6567

#######################################################
EMAIL to SSL-ADMIN Team
{code:java}
Good Morning SSL-Admin Team, 

Could you please create the following certificate, 
as soon it is approved by @Alexander Thorne

Thanks in Advance!
Cheers, 
Steffen
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
Reduce memory (RAM) of non-prod amq hosts ,M7P-8248,109928,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,03/May/21 14:05,19/May/21 11:28,16/Sep/21 14:11,17/May/21 11:26,,6.12.30,7tops_sprint117,,,RabbitMQ,,,,M,M7PRODOPS,,,,,,"Like we discussed with [~pw231] and [~zq813] from SYSENG, we are planning to shrink the memory of all amq (non-prod) hosts. 

The proper list is mentioned in https://jira.deutsche-boerse.com/browse/SYSENGINT-652

We need to check if we can stop amq nodes one by one during business hours and reduce RAM on the machine, reboot it and start the node again. 

",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,did all the Memory changes for the listed VMs in the SYSENG ticket. ,,,,,,,,,,,,,,,,,,,,,,,,10540800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwsv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":109928,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/May/21 09:42;rehapav;[~cs687]you have green light to start with this change 1 by 1

I decided not to announce to the customers, disconnects from rabbits are acceptable, they must have reconnect implemented anyway","11/May/21 13:33;cs687;starting with *ELTS-CTPB* (/)
amq3 node by node 

1.) stopped amq3 instance 
2.) SYSENG reduced Mem und powered off the machine
3.) starting amq3 instance again 
4.) check cluster_status ","11/May/21 13:47;cs687;same done for 
*ELTS-CUTE* (/)
*ELTS-LIPA* (/)
*ELTS-SIMU* (/)","11/May/21 14:22;cs687;*HUPX-CUTE* (/)
*HUPX-SIMU* (/)
*HUPX-ASIM* (/)","11/May/21 14:29;cs687;*PLPX-LIPA* (/)
*PLPX-SIMU* (/)","11/May/21 14:50;cs687;*XRPM-LIPA* (/)
*XRPM-SIMU* (/)","17/May/21 11:01;cs687;*XSOP-CUTE* (/)
*XSOP-SIMU* (/)
*XSOP-ASIM* (/)","17/May/21 11:26;cs687;done",,,,,,,,,,,,,,,,,,,,
Postgres internal backup not working for m7tshrdprodasync on m7prodpdb4,M7P-8231,109863,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cs687,op211,op211,30/Apr/21 03:11,05/May/21 11:17,16/Sep/21 14:11,30/Apr/21 07:56,,6.12.12,7tops_sprint116,,,Database,,,,7tops,M7PRODOPS,,,,,,"The data dir ran full on 30.04.2021 2:00 am with many WAL files in data/.../pg_wal:

[https://dbg-devops.slack.com/archives/C941CV942/p1619741280094800]

The internal backup of WALs from data to backup is not working probably, because the folder structure under backup does not exist:
{noformat}
-bash-4.2$ pwd
/var/lib/pgsql_m7tshrdprodasync/backup
-bash-4.2$ ls -la
total 0
drwxr-xr-x 2 postgres postgres  6 Jan 12 13:57 .
drwxr-xr-x 6 postgres postgres 56 Apr  9  2020 ..
-bash-4.2$
{noformat}
Error message from Postgres log:
{noformat}
<time= Fri Apr 30 00:03:01 CEST 2021 > Starting archiving xlogs to separate xlog archive directory
 cp: cannot create regular file ‘/var/lib/pgsql_m7tshrdprodasync/backup/11/pg_xlog_archive/00000006.history’: No such file or directory
 <time= Fri Apr 30 00:03:01 CEST 2021 > Archiver error: rsync failed!
 <time=2021-04-30 00:03:01.356 CEST user= db= host= pid=28282 > LOG: archive command failed with exit code 1
 <time=2021-04-30 00:03:01.356 CEST user= db= host= pid=28282 > DETAIL: The failed archive command was: /var/lib/pgsql_m7tshrdprodasync/ADMIN/TASK_SCRIPTS/RSYNC_WAL.sh pg_wal/00000006.history /var/lib/pgsql_m7tshrdprodasync/backup/11/pg_xlog_archive/00000006.history
 <time=2021-04-30 00:03:01.356 CEST user= db= host= pid=28282 > WARNING: archiving write-ahead log file ""00000006.history"" failed too many times, will try again later{noformat}
Database leader was switched from pdb2/3 to pdb4 for maintenance reasons (OS upgrade). Please also doublecheck the backup infrastructure on all 4 pdb hosts.

For the immediate problem resolution, m7tshrdprodasync database has been switched from pdb4 to pdb1.",,cs687,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"added the missing directories to following envs
* m7tshrdprod on m7prodpdb4
* m7txsopprod on m7prodpdb4
* m7aamprprod on m7prodpdb2",,,,,,,,,,,,,,,,,,,,,,,,12009600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwqn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":109863,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/21 07:52;cs687;Properly during last disk space capacity issues we umounted some few backup-FS for few env´s.
After mounting them again, the proper directories were missing. 

added them for these env´s with owner postgres
* /var/lib/pgsql_m7<clustername>/backup/11/pg_xlog_archive
* /var/lib/pgsql_m7<clustername>/backup/netbackup/ampgsql

*M7PRODPDB4:*
{code:java}
/var/lib/pgsql_m7tshrdprodasync/backup:
total 0
drwxr-xr-x 2 postgres postgres  6 Jan 12 13:57 .
drwxr-xr-x 6 postgres postgres 56 Apr  9  2020 ..
{code}


{code:java}
/var/lib/pgsql_m7txsopprodasync/backup:
total 0
drwxr-xr-x 2 postgres postgres  6 Jan 12 13:57 .
drwxr-xr-x 6 postgres postgres 56 Feb 19  2020 ..
{code}

*M7PRODPDB2*
{code:java}
/var/lib/pgsql_m7aamprprodsync/backup:                
total 0                                               
drwxr-xr-x 2 postgres postgres  6 Mar  2 13:40 .      
drwxr-xr-x 6 postgres postgres 56 May  8  2020 ..     
{code}
","30/Apr/21 07:56;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Update M7P deployment script,M7P-8230,109852,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,ax460,ax460,29/Apr/21 14:12,06/Sep/21 15:04,16/Sep/21 14:11,,,,,,,,,,,7tops,toilwork,,,,,,"Update deployment of M7P components so it never takes version of separate component but always only M7P version. Eg. deployment of core takes always M7P version, which defines version of core.

 

*Acceptance criteria*: variable m7p_version is always available during deployment of any m7p component.

 

*Rationalization*: Deployment of Core and Enquiry module should be aware of M7P version - see  M7P-8228 and M7P-8229
----
More details

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/shrd/ate3/m7tcor/vars.yml#L4]

in inventory we have component version eg.
{code:java}
app_version: ""{{m7t_version}}""
{code}
we need to keep this. m7p defines all component version, see [components.yml|https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/m7/m7-product/m7p-reports/6.11.240/m7p-reports-6.11.240-components.yml]

On the top of that we need to have m7p version in inventory eg.
{code:java}
app_version: ""{{m7t_version}}""
another_variable: ""{{m7p_version}}""
{code}
so we it can be displayed in Enquiry and Core (SystemInfoResp)

 

 ",,ax460,op211,,,,,,,,,,,,,,,,M7P-8304,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10454400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztev:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109852,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"29/Apr/21 14:26;ax460;eg. [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/]

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/dev-trigger/job/M7T_deploy_upgrade/]

 ","18/May/21 13:50;op211;After refinement:

DEV would like to make the product version ""m7p_version"" available for the components like Core or Enquiry, because they don't know by themselves, to which product version they belong. They will use the variable m7p_version in application properties file to make the version number string (e.g. ""6.11.234"") available for the running application, e.g. to display the number on the GUI.

In order to not fill the inventory with the product version, the proposal would be to inject the number during deployment time, e.g. here:  

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/20bbbafd9dc3eb6dc6a07c1eee5a4b8d35ecc0e9/jenkins/deploy_lib_m7t.groovy#L105]

Additionally: The old jobs like M7T Ansible Deployment should not be used anymore. Only adapt CD-Pipeline jobs.",,,,,,,,,,,,,,,,,,,,,,,,,,
create a role to deploy log rotating mechanism/changes,M7P-8224,109785,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pd122,pd122,28/Apr/21 11:32,05/Aug/21 13:25,16/Sep/21 14:11,27/Jul/21 15:24,,6.12.114,7tops_sprint122,,,,,,,7tops,7tops_comm,ansible,Logs,M,,,"# https://www.elastic.co/guide/en/beats/filebeat/current/file-log-rotation.html#:~:text=When%20an%20input%20log%20file,file%20during%20the%20next%20scan.
# use a custom script to do the compression of rotated files - the sketch of this script follows:

{code:java}
#!/bin/sh
# base directory containing the logs
BASE_DIR=~/logs
# the name of the main logfile that is not yet rotated
BASE_LOG_NAME=reporter.log
# rollover directory where we move compressed files
ROLLOVER_DIR=$BASE_DIR/rollover
# ignore files younger that this number of minutes
# this is a safety threshold for filebeat to finish reading
TIMEOUT=15
find ""$BASE_DIR"" -maxdepth 1 -type f -mmin +$TIMEOUT -not -name ""$BASE_LOG_NAME"" -not -name '*.gz' -exec sh '-c' ""gzip '{}' && mv '{}'.gz $ROLLOVER_DIR/"" \;
{code}

Note:  the application is to rotate files without actual compression

Need to apply/process all logs known to filebeat.
Use stalker for initial testing/deployment.
Consider EBSM transfer script when designing/implementing.",,pd122,sJ194,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,new *logarch* role (to be either integrated with other module deployments or deployed standalone) created,,,,,,,,,,,,,,,,,,,,,,,,4320000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztdb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109785,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,new_log_rotation,master,true,"13/Jul/21 15:11;sJ194;[~pd122]  and [~PB446]  what is the status of this Jira pls? M7P-6238  is blocked by this one and it is in progress for a long time, so we would like to know, what is the estimated time to finish it. Thx","27/Jul/21 10:22;pd122;PR [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1694] created","27/Jul/21 15:19;pd122;PR merged => new *logarch* role is now available (to be either included with deployment of other components or deployed separately via _deploy_logarch.yml_ playbook).  Requires _become_user_ variable to be set.","27/Jul/21 15:23;pd122;Also, it is now possible to specify log retention period per instance (via _log_max_age_ variable) as old logs are no longer being removed by ebsm transfer script (where update has been deployed).",,,,,,,,,,,,,,,,,,,,,,,,
Upgrade SonarQube to 8.9 LTS,M7P-8220,109758,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,jv861,jv861,28/Apr/21 08:42,15/Jul/21 10:25,16/Sep/21 14:11,07/Jul/21 10:51,,6.12.107,6.12.99,7Tops_Sprint121,,,,,,M,M7PRODOPS,,,,,,"Our current Sonar ( sonar.energy.svc.dbgcloud.io ) has some limitations regarding analyzing Kotlin 1.4 source code (see https://community.sonarsource.com/t/support-for-kotlin-1-4/31147 ) - it is fixed in the latest version.

Also, new Sonar LTS version 8.9 was released on 4th May: https://blog.sonarsource.com/sonarqube-lts-89-standby
",,cs687,HO764,jI663,jv861,ll664,PB446,zs244,zv517,,,,,,,,,,XP-5079,,,,,,,,,,,,,,,,,,,,,,"06/Jul/21 12:50;zs244;database_snapshot.png;https://jira.deutsche-boerse.com/secure/attachment/97101/database_snapshot.png","06/Jul/21 11:23;cs687;image-2021-07-06-11-23-07-719.png;https://jira.deutsche-boerse.com/secure/attachment/97099/image-2021-07-06-11-23-07-719.png","06/Jul/21 12:56;cs687;sonar_upgraded_1.png;https://jira.deutsche-boerse.com/secure/attachment/97103/sonar_upgraded_1.png","06/Jul/21 12:56;cs687;sonar_upgraded_2.png;https://jira.deutsche-boerse.com/secure/attachment/97102/sonar_upgraded_2.png",,,,,,,,,,,,sw455,,,,,,,,"upgraded sonar from 7.9.4 to 7.9.6 and finally to latest *8.9.1*
all steps are followed by the migration plan here: https://docs.sonarqube.org/latest/setup/upgrading/#header-3
",,,,,,,,,,,,,,,,,,,,,,,,6134400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztgx:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,,,,,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":109758,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/21 15:36;PB446;Shadow follower: [~pd122]","24/Jun/21 08:46;jI663;Hi, there are also problems with parsing of JS sources (ECMAScript 2020) with SonarJS plugin version (5.7.x) of our current SonarQube 7.9.x. Actually, JS files using the latest syntax possibilities are not parsable and actually are not checked at all. Our Sonar accepts SonarJS version 6.2.2 which is pretty old (and also does not support latest syntax). So update to lates 8.9 LTS is highly appreciated. Thanks.","02/Jul/21 16:21;cs687;h2. Deployed the newer version from *7.9.4* to *7.9.6* 
to follow the migration path to version 8.x
https://docs.sonarqube.org/latest/setup/upgrading/


{code:java}
± |piotr U:1 ✗| → ansible-playbook playbooks/sonar.yml -u centos

PLAY [Sonar Docker Setup] ***************************************************************************************************************************************************************************************************************************************************************************************************
[WARNING]: While constructing a mapping from /home/ansible/steffen/energy.sonar/ansible/inventory/group_vars/all.yml, line 3, column 1, found a duplicate dict key (https_proxy). Using last defined value only.

[WARNING]: While constructing a mapping from /home/ansible/steffen/energy.sonar/ansible/inventory/group_vars/all.yml, line 3, column 1, found a duplicate dict key (hashi_vault_token). Using last defined value only.

[WARNING]: While constructing a mapping from /home/ansible/steffen/energy.sonar/ansible/inventory/group_vars/all.yml, line 3, column 1, found a duplicate dict key (lvm_create_lv). Using last defined value only.


TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [lvm-manage-2 : Install lvm package] ***********************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [lvm-manage-2 : Create mount directories] ******************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'key': 'sonar', 'value': {'dev': '/dev/vgsonar/lvsonar', 'fstype': 'xfs', 'opts': 'noatime,nodiratime', 'mountpoint': '/var/lib/sonar', 'dump': '0', 'passno': '2', 'state': 'mounted'}})

TASK [lvm-manage-2 : Creating volume groups] ********************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'key': 'vgsonar', 'value': {'pvs': ['/dev/xvdh']}})

TASK [lvm-manage-2 : Conduct resize test of physical volumes] ***************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item=/dev/xvdh)

TASK [lvm-manage-2 : Resize physical volumes] *******************************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'changed': False, 'end': '2021-07-02 15:18:10.580556', 'stdout': '  Physical volume ""/dev/xvdh"" changed\n  1 physical volume(s) resized or updated / 0 physical volume(s) not resized', 'cmd': 'pvresize /dev/xvdh -v -t', 'rc': 0, 'start': '2021-07-02
 15:18:10.551377', 'stderr': '  TEST MODE: Metadata will NOT be updated and volumes will not be (de)activated.\n    Test mode: Skipping archiving of volume group.\n    Resizing volume ""/dev/xvdh"" to 83886080 sectors.\n    No change to size of physical volume /dev/xvdh.\n    Updating physical volume ""/dev/xvdh""\n
Test mode: Skipping backup of volume group.', 'delta': '0:00:00.029179', 'invocation': {'module_args': {'creates': None, 'executable': None, '_uses_shell': True, 'strip_empty_ends': True, '_raw_params': 'pvresize /dev/xvdh -v -t', 'removes': None, 'argv': None, 'warn': True, 'chdir': None, 'stdin_add_newline': True,
 'stdin': None}}, 'stdout_lines': ['  Physical volume ""/dev/xvdh"" changed', '  1 physical volume(s) resized or updated / 0 physical volume(s) not resized'], 'stderr_lines': ['  TEST MODE: Metadata will NOT be updated and volumes will not be (de)activated.', '    Test mode: Skipping archiving of volume group.', '
Resizing volume ""/dev/xvdh"" to 83886080 sectors.', '    No change to size of physical volume /dev/xvdh.', '    Updating physical volume ""/dev/xvdh""', '    Test mode: Skipping backup of volume group.'], 'failed': False, 'item': '/dev/xvdh', 'ansible_loop_var': 'item'})

TASK [lvm-manage-2 : Creating/extending logical volumes] ********************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'name': 'lvsonar', 'vg': 'vgsonar', 'size': '+100%FREE'})

TASK [lvm-manage-2 : Format filesystems] ************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'key': 'sonar', 'value': {'dev': '/dev/vgsonar/lvsonar', 'type': 'xfs', 'opts': ''}})

TASK [lvm-manage-2 : Mount filesystems] *************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'key': 'sonar', 'value': {'dev': '/dev/vgsonar/lvsonar', 'fstype': 'xfs', 'opts': 'noatime,nodiratime', 'mountpoint': '/var/lib/sonar', 'dump': '0', 'passno': '2', 'state': 'mounted'}})

TASK [java : Ensure Java is installed.] *************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item=java-11-openjdk)

TASK [java : Set JAVA_HOME if configured.] **********************************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Get RDS credentials from Vault] *******************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Create sonar group] *******************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Create sonar user] ********************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Download Sonar.] **********************************************************************************************************************************************************************************************************************************************************************************************
changed: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Unzip Sonar.] *************************************************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Move Sonar into place.] ***************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Change Owner of sonar] ****************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Change Owner of sonar data LVM] *******************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Configure SonarQube JDBC settings for Postgres.] **************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.jdbc.username', 'line': 'sonar.jdbc.username=sonar'})
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.jdbc.password', 'line': 'sonar.jdbc.password=$UKh!}1IAF!lSIMn'})
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.jdbc.url', 'line': 'sonar.jdbc.url=jdbc:postgresql://energy-svc-sonar.cgke75kbfejl.eu-central-1.rds.amazonaws.com:5432/sonar'})
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.web.context', 'line': 'sonar.web.context='})
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.path.data', 'line': 'sonar.path.data=/var/lib/sonar/'})
ok: [ip-10-115-64-130.eu-central-1.compute.internal] => (item={'regexp': '^sonar.log.rollingPolicy', 'line': 'sonar.log.rollingPolicy=time:yyyy-MM-dd'})

TASK [sonar : Symlink sonar bin.] *******************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Add sonar as init script for service management.] *************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Find and replace runasuser in service  management] ************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Copy SonarQube systemd unit file into place (for systemd systems).] *******************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Download Kotlin plugin] ***************************************************************************************************************************************************************************************************************************************************************************************
changed: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Deploy Backup Script] *****************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Setup cron jobs to create sonar backups] **********************************************************************************************************************************************************************************************************************************************************************
[WARNING]: The value 2 (type int) in a string field was converted to u'2' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change.

ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Ensure Sonar is running and set to start on boot.] ************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Allow Sonar time to build on first start.] ********************************************************************************************************************************************************************************************************************************************************************
skipping: [ip-10-115-64-130.eu-central-1.compute.internal]

TASK [sonar : Make sure Sonar is responding on the configured port.] ********************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

RUNNING HANDLER [sonar : restart sonar] *************************************************************************************************************************************************************************************************************************************************************************************
changed: [ip-10-115-64-130.eu-central-1.compute.internal]

RUNNING HANDLER [sonar : wait for sonar] ************************************************************************************************************************************************************************************************************************************************************************************
ok: [ip-10-115-64-130.eu-central-1.compute.internal]

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
ip-10-115-64-130.eu-central-1.compute.internal : ok=26   changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0
{code}

after redeployment we figured the following error:
{code:java}
2021.07.02 15:25:31 ERROR web[][o.s.s.p.Platform] Web server startup failed: Found two versions of the plugin SonarKotlin [kotlin] in the directory extensions/plugins. Please remove one of sonar-kotlin-plugin-1.4.0.155.jar or sonar-kotlin-plugin-1.5.0.315.jar.
{code}
*Solution:*
* removed old tar.gz file in */usr/local/sonar/extensions/plugins/*

{code:java}
2021.07.02 15:38:07 INFO  web[][o.s.s.q.ProjectsInWarningDaemon] Counting number of projects in warning is not started as there are no projects in this situation.
2021.07.02 15:38:07 INFO  web[][o.s.s.p.p.PlatformLevelStartup] Running Developer Edition
2021.07.02 15:38:07 INFO  web[][o.s.s.p.Platform] WebServer is operational
{code}

after changing the versions to 7.9.6 in the files:
https://github.deutsche-boerse.de/dev/energy.sonar/blob/1e9cb54e6bf8061ec486e630b2202afc3ef1c2f1/ansible/roles/sonar/defaults/main.yml#L6
https://github.deutsche-boerse.de/dev/energy.sonar/blob/1e9cb54e6bf8061ec486e630b2202afc3ef1c2f1/ansible/roles/sonar/tasks/setup_plugins.yml#L15
https://github.deutsche-boerse.de/dev/energy.sonar/blob/1e9cb54e6bf8061ec486e630b2202afc3ef1c2f1/ansible/roles/sonar/tasks/setup_plugins.yml#L16
* sonar_version: 7.9.6

we figured out that still the old version 7.9.4 is started up  
-*proper fix would be* copying the binaries from sonarqube-7.9.6 to ""bin"" and restart.-

{code:java}
drwxrwxr-x.  6 sonar sonar   94 Jul 28  2020 bin
drwxrwxr-x.  2 sonar sonar   50 Jul  2 15:54 conf
drwxrwxr-x.  2 sonar sonar   24 Jul 28  2020 data
drwxrwxr-x.  7 sonar sonar  131 Jul 28  2020 elasticsearch
drwxrwxr-x.  5 sonar sonar   57 Sep 15  2020 extensions
drwxrwxr-x.  7 sonar sonar  144 Jul 28  2020 lib
drwxrwxr-x.  2 sonar sonar 4096 Jul  2 15:38 logs
drwxrwxr-x. 11 sonar sonar  141 Mar  1 09:21 sonarqube-7.9.6
drwxrwxr-x.  8 sonar sonar  134 Jul  2 16:20 temp
drwxrwxr-x.  7 sonar sonar 4096 Jul 28  2020 web
{code}

prepared pull-request:
https://github.deutsche-boerse.de/dev/energy.sonar/pull/1

upgrade from 7.9.4 to 7.9.6 is working
{code:java}
SonarQube™ technology is powered by SonarSource SA
Community EditionVersion 7.9.6 (build 41879)LGPL v3CommunityDocumentationGet SupportPluginsWeb APIAbout
{code}

","06/Jul/21 11:03;cs687;for sonar 8.9.x we have to upgrade also the postgresql database 
https://docs.sonarqube.org/latest/setup/lts-to-lts-upgrade-notes/
{code:java}
Database support updated (8.9)
SonarQube 8.9 supports the following database versions:

PostgreSQL versions 9.6 to 13. PostgreSQL versions <9.6 are no longer supported.
MSSQL Server 2014, 2016, 2017, and 2019.

h2. After upgrading to version 8.9.1.sonarqube-8.9.1.44547.zip

Oracle XE, 12C, 18C, and 19C. Oracle 11G is no longer supported.
{code}

At the moment we have already postgres version 9.6 installed. 

with sonar 8.5 the plugins changed as we can see here
https://community.sonarsource.com/t/tips-for-upgrading-sonarqube-to-8-9-from-7-1/45663/3
https://community.sonarsource.com/t/sonarqube-v8-5-and-beyond-where-did-all-the-plugins-go/32792

h2. After upgrading to version 8.9.1.44547
We can see warnings with Database upgrade:
{code:java}
2021.07.06 11:17:15 WARN  app[][startup] ################################################################################
2021.07.06 11:17:15 WARN  app[][startup] The database must be manually upgraded. Please backup the database and browse /setup. For more information: https://docs.sonarqube.org/latest/setup/upgrading
2021.07.06 11:17:15 WARN  app[][startup] ################################################################################
{code}

Browse to https://sonar.energy.svc.dbgcloud.io/setup and follow the setup instructions
 !image-2021-07-06-11-23-07-719.png! 
In this step, SonarQube will apply the necessary changes to the database.

just noticed that we have no active backup running for *energy-sonar-backup-sz*
it´s also not configured with that s3_bucket name
{code:java}
[root@ip-10-115-64-130 sonar-06-07-2021-11:48:56]# crontab -l
#Ansible: ucmdb job for reboot
@reboot /opt/HP/Discovery/cloud-uid.sh
#Ansible: cron for backups
5 2 * * 2 S3_BUCKET=""energy-sonar-backup-dev"" /var/lib/sonar/sonar-backup.sh backup
{code}

*run a manual backup:*
We have to add it to the playbook as well!
currently no backup will be done at all!
{code:java}
[root@ip-10-115-64-130 sonar]# S3_BUCKET=""energy-sonar-backup-sz"" /var/lib/sonar/sonar-backup.sh backup
Backing up ES database sonar to /var/lib/sonar/backup/sonar-06-07-2021-11:49:47
Sending sonar backup directory /var/lib/sonar/backup/sonar-06-07-2021-11:49:47 to S3
Removed latest sonar backup s3://energy-sonar-backup-sz/sonar-latest/ from S3
Backup directory copied to s3://energy-sonar-backup-sz/sonar-latest
Backup directory copied to s3://energy-sonar-backup-sz/sonar-06-07-2021-11:49:47
Cleaning up local files from /var/lib/sonar/backup/sonar-06-07-2021-11:49:47
Done
{code}

{color:#DE350B}*Created SNAPSHOT from aws database node*{color}","06/Jul/21 12:50;zs244;Snapshot created
 !database_snapshot.png! ","06/Jul/21 12:56;cs687; !sonar_upgraded_2.png!  !sonar_upgraded_1.png! 
h1. *Sonar upgraded successfully to 8.9.1*","06/Jul/21 13:02;cs687;done","07/Jul/21 09:28;HO764;The server lincence has not been preserved, see [https://sonar.energy.svc.dbgcloud.io/admin/marketplace.] Before, we had Developer edition, now there is a free version.","07/Jul/21 10:51;cs687;Sonar developer version has been deployed again.
We figured out that the path changed like it was deployed before. ",,,,,,,,,,,,,,,,,,,
PoC testing new NBU9.0 client and new infrastructure ,M7P-8193,109496,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,21/Apr/21 13:10,26/Jul/21 13:00,16/Sep/21 14:11,18/May/21 09:20,,6.12.30,7tops_sprint117,,,Database,,,26/Apr/21 00:00,7tops_comm,M7PRODOPS,,,,,,"Going to test with NBU Admins the new netbackup client + new provided infrastructure. Properly it will be tested on m7testpdb1/2 machines.

Going to have a call with nbu this week, to talk about few open points before. 

{code:java}
Good morning Steffen,

Our new environment is up and running and I want to test the new features in NBU9.0.
Can you let me know when you are available ?

Kind Regards,
Michael Lievens

Mobile : +352 621 629 074
{code}
",,cs687,zv517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"all PoC tests are described detailed in the comments. 
Will address the findings in the OPS meeting and in the energy_ops_team channel ",,,,,,,,,,,,,,,,,,,,,,,,5270400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzzthb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 117,,,,,,,,,,,,,,,,,,,,,,,,,,see comments. ,,,,,,,,,,"{""issueId"":109496,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/21 13:11;cs687;h2. *{color:#DE350B}Preparation for the tests:{color}*
added server endpoint in: /usr/openv/netbackup/bp.conf
the others have to stay there, because it will be used for proper old restoration´s.
{code:java}
SERVER = nbufrpux4.deutsche-boerse.de
SERVER = nbufrpuxms41
SERVER = nbufrpuxms42
SERVER = nbufrpuxcc41.deutsche-boerse.de
SERVER = nbufrpuxcc42.deutsche-boerse.de
{code}

added static routes for new endpoint netbackup host and also added them to 
/etc/sysconfig/network-scripts/route-bond-admin

{code:java}
ip route add 10.139.252.0/24  via 10.139.117.11
ip route add 10.139.255.0/24  via 10.139.117.11
{code}

getting CA Certificate for new nbu-server
{code:java}
[root@m7testpdb1 ~]# /usr/openv/netbackup/bin/nbcertcmd -getCACertificate -server nbufrpux4.deutsche-boerse.de
Authenticity of root certificate cannot be established.
The SHA1 fingerprint of root certificate is 7E:E1:A3:32:5F:4D:BE:34:E8:E3:09:91:54:D3:6D:C2:98:EB:8F:F2.
Are you sure you want to continue using this certificate ? (y/n): y
The validation of root certificate fingerprint is successful.
CA certificate stored successfully from server nbufrpux4.deutsche-boerse.de.
{code}

getting Certificate
{code:java}
[root@m7testpdb1 ~]# /usr/openv/netbackup/bin/nbcertcmd -getCertificate -server nbufrpux4.deutsche-boerse.de -token WXTPEAMGEXNBBKWG
Host certificate and certificate revocation list received successfully from server nbufrpux4.deutsche-boerse.de.
{code}

on host *m7testpdb1/2* the backup agent 8.1.2 is already installed during our last test, described here 
https://jira.deutsche-boerse.com/browse/TECHLOG-3043?jql=text%20~%20%228.1.2%22

{code:java}
-bash-4.2$ cat /usr/openv/netbackup/bin/version
NetBackup-RedHat2.6.32 8.1.2
{code}

","29/Apr/21 13:47;cs687;h2. {color:#DE350B}*successfully backup on systemtest2:* {color}
the following archive commands should be specified and patroni config reloaded afterwards:
{code:java}
patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml edit-config
    archive_command: test ! -f /var/lib/pgsql_m7tshrdsyt2async/backup/11/pg_xlog_archive/%f && cp %p /var/lib/pgsql_m7tshrdsyt2async/backup/11/pg_xlog_archive/%f
    archive_mode: 'on'
    archive_timeout: 0
{code}


the binary and log/config are stored here in that path: */var/lib/pgsql_m7tshrdsyt2async/NBPostgreSQLAgent*
{code:java}
total 7448
drwxr-xr-x 2 postgres postgres      94 Apr 29 13:19 .
drwxr-xr-x 7 postgres postgres      81 Apr 28 15:02 ..
-rw-r--r-- 1 postgres postgres   17891 May 31  2018 I18N_EN
-rwxr-xr-x 1 postgres postgres 3659863 May 31  2018 nbpgsql
-rw-r--r-- 1 postgres postgres    5812 Apr 28 16:16 nbpgsql.conf
-rw-r--r-- 1 postgres postgres 3692411 Apr 29 13:41 nbpgsql.log
-rw-r--r-- 1 postgres postgres      37 May 31  2018 version.txt
{code}

In nbpgsql.conf the following parameters should be defined
{code:java}
MASTER_SERVER_NAME=nbufrpux4.deutsche-boerse.de
PGSQL_LIB_INSTALL_PATH=/usr/pgsql-11/lib
SCHEDULE_NAME=F2W,I2W    --> default SCHEDULE NAME
SNAPSHOT_SIZE=   --> have to double check how big it should be, depending on database 
{code}

how i started the backup:
{code:java}
./nbpgsql -o backup -S nbufrpux4.deutsche-boerse.de -P UX4_POSTGRESQL -s F2W
......
PostgreSQL database backup is successful!
Number of files backed up:  2559
Completed the  backup  operation
{code}

query made backups
{code:java}
[root@m7testpdb1 NBPostgreSQLAgent]# ./nbpgsql -o query -P UX4_POSTGRESQL
Warning! Log size is not set or 0. Setting the log-size to 10 MB
Query initiated from XBSA ...
Setting the policy : UX4_POSTGRESQL
Query is successful!
============================================================================
DBBackupID      ObjectInfo      ResourceType        BackupTime
============================================================================
1619695875      Linux           PGSQL v11.9         Thu Apr 29 13:31:15 2021
1619695222      Linux           PGSQL v11.9         Thu Apr 29 13:20:22 2021
{code}



","04/May/21 08:05;cs687;h2. {color:#DE350B}*successfully backup on systemtest3 with Restore!*{color}

* 2 Fullbackups were done with Policy ""*UX4_POSTGRESQL_FB*"" & ""*UX4_POSTGRESQL_IB*""
* After first backup I did some changes in the database and after these I triggered the second backup 
{code:java}
postgres=# CREATE user test;
postgres=# drop user backup;
DROP ROLE
postgres=# drop user restore;
DROP ROLE
{code}

* put patroni cluster in maintenance mode 
* stopped patroni nodes and executed the following commands 
{code:java}
rm -rf /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async
mkdir /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async
chown -R postgres:postgres /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async
chmod 0700 /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async
{code}

* triggered the restore like this 
{code:java}
[root@m7testpdb1 NBPostgreSQLAgent]# ./nbpgsql -o restore -S nbufrpux4.deutsche-boerse.de -t /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async -id 1620036211
Warning! Log size is not set or 0. Setting the log-size to 10 MB
Restore initiated from XBSA
PostgreSQL database restore is in progress
.....

Number of files restored:  3211                                                                         
Write Ahead Log (WAL) files path:  /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async/pgarchive   
Update the ""restore_command"" with the Write Ahead Log (WAL) files path in the recovery.conf             
PostgreSQL database restore is successful!                                                              
Completed the  restore  operation     
{code}

{code:java}
[root@m7testpdb1 NBPostgreSQLAgent]# ./nbpgsql -o query -P UX4_POSTGRESQL_FB
============================================================================
DBBackupID      ObjectInfo      ResourceType        BackupTime
============================================================================
1620036211      Linux           PGSQL v11.9         Mon May  3 12:03:31 2021

[root@m7testpdb1 NBPostgreSQLAgent]# ./nbpgsql -o query -P UX4_POSTGRESQL_IB
============================================================================
DBBackupID      ObjectInfo      ResourceType        BackupTime
============================================================================
1620037856      Linux           PGSQL v11.9         Mon May  3 12:30:56 2021
{code}

* create recovery.conf in data-dir with the following content and start database with pg_ctl command: 
{code:java}
recovery_target_action = pause
recovery_target_timeline = current                        
recovery_target_time = 2021-05-03 12:45:00 CEST       
restore_command = ""cp /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/%f %p""  
{code}

with recovery_target_action = pause it can be tested step by step if proper wal_segement was loaded!

the restored *{color:#DE350B}pgarchive {color}* folder can not be used for point_in_time recovery, so actually we have to use the transaction logfiles in the backup-FS. 
For the future it would make sense to copy over the transaction logfiles to a SAN and remove all backup-FS. We just have to check that the archive command can connect properly to the SAN storage, otherwise the data-FS with pg_wal will also went full! 

* start patroni on previous master and resume cluster 
{code:java}
+ Cluster: m7tshrdsyt3async (6792140113763393373) ---+----+-----------+
|   Member   |         Host         | Role |  State  | TL | Lag in MB |
+------------+----------------------+------+---------+----+-----------+
| m7testpdb1 | 10.139.117.253:26006 |      | running | 32 |        52 |
+------------+----------------------+------+---------+----+-----------+
{code}
May 04 11:51:35 m7testpdb1 patroni[15127]: 2021-05-04 11:51:35,961 INFO: My wal position exceeds maximum replication lag

In the logs in the list command output we can see a LAG and no leader, this can be fixed like this!

{code:java}
[root@m7testpdb1 m7tshrdsyt3async]# patronictl -c /etc/patroni_m7tshrdsyt3async/config.yml pause
Success: cluster management is paused

[root@m7testpdb1 m7tshrdsyt3async]# su - postgres
Last login: Tue May  4 11:54:15 CEST 2021
-bash-4.2$ psql -p 26006
psql (11.9)
Type ""help"" for help.

postgres=# select pg_is_in_recovery();
 pg_is_in_recovery
-------------------
 t
(1 row)

-bash-4.2$ /usr/pgsql-11/bin/pg_ctl -D /var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async promote
waiting for server to promote.... done
server promoted
{code}

Afterwards we can see one node running as leader, for all others we have to run a reinit.
{code:java}
-bash-4.2$ patronictl -c /etc/patroni_m7tshrdsyt3async/config.yml list
+ Cluster: m7tshrdsyt3async (6792140113763393373) -----+----+-----------+
|   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------+----------------------+--------+---------+----+-----------+
| m7testpdb1 | 10.139.117.253:26006 | Leader | running | 33 |           |
+------------+----------------------+--------+---------+----+-----------+
{code}
","04/May/21 15:42;cs687;h2. {color:#DE350B}Conclusion:{color}
we tested the netbackup client 8.1.2 on host m7testpdb1, like it was tested in the past (ticket ""TECHLOG-3043"") 
and with the new netbackup server infrastructure behind it.

For 2 years netbackup somehow told us that with the new coming nbu-infrastructure we would have more options to do backups on shared-databases hosts, which seems like not correct.
Also upgrading the client to a higher version (currently used 8.1.2) like version 9, is not providing us the proper options, regarding the documentation. 

As far we can see now, it changed nothing, we still can not identify which backup belongs to which database env, by using 2 Policies, one for Full-Backups and one for Incremental Backups!

Michael Lievens, will create Veritas ticket again, and ask for support! 

When we find no solution for that, we have to deal with it, that netbackup *have to* create for each Database a separate Policy for full and incremental backups.

Besides that we have to check the following points:
* How Restore behaves, needs to be properly tested! (/) _tested see comment above_
* How to do Point in Time Recovery, at least there is no backuptype Incremental existing
*Properly the following could be an option for us*
** doing daily a fullbackup
** mounting central NAS with mount-point in backup-FS (already recommended by Cybertec)
** archiving command stays the same and just copy transaction wal_segments to the NAS
** after full-backup we can clean up the transaction logfiles in backup-FS (NAS) which is older than X hours
* cleaning up transaction logfiles have to be done somehow on our side
in our current backup we have in our script the following option to cleanup the backup-ed transaction logfiles, which is with the new setup not possible anymore.
{code:java}
cat /usr/bin/backup-ampgsql#m7tshrdsyt2#Full.sh

echo $COMMAND_PATH/postgres-backup \
.......
                        --property cleanupwal=$CLEANUPWAL \
{code}
* testing without lvm snapshots, which is provided with client version 9 

https://www.veritas.com/content/support/en_US/doc/129277259-144476565-0/v129276458-144476565
BACKUP_TYPE
Available options:
{code:java}
auto: Default option. Performs an auto discovery backup.

lvm: Agent forces to do a lvm snapshot.

nonlvm: Agent forces to do nonlvm way backup by using pg_start_backup and pg_stop_backup for Postgres with LVM snapshot disabled.
{code}
* measuring the time of few backups & restores
* polishing existing ansible role to onboard the new setup 


 

","11/May/21 10:28;cs687;h2. {color:#DE350B}*Installing the newest client on m7testpdb2*{color}
version before the installation
{code:java}
[cs687@m7testpdb2 ~]$ cat /usr/openv/netbackup/bin/version
NetBackup-RedHat2.6.32 8.1.2
{code}

unpacking the new client 
{code:java}
[cs687@m7testpdb2 ~]$ tar zxvf NetBackup_9.0-Linux-RedHat.tgz
NetBackup_9.0-RedHat/
NetBackup_9.0-RedHat/install
{code}

preparation before the installation like it happened on m7testpdb1
{code:java}
# added in /usr/openv/netbackup/bp.conf
SERVER = nbufrpux4.deutsche-boerse.de
SERVER = nbufrpuxms41
SERVER = nbufrpuxms42
SERVER = nbufrpuxcc41.deutsche-boerse.de
SERVER = nbufrpuxcc42.deutsche-boerse.de

ip route add 10.139.252.0/24  via 10.139.117.11
ip route add 10.139.255.0/24  via 10.139.117.11

[root@m7testpdb2 ~]# /usr/openv/netbackup/bin/nbcertcmd -getCACertificate -server nbufrpux4.deutsche-boerse.de
Authenticity of root certificate cannot be established.
The SHA1 fingerprint of root certificate is 7E:E1:A3:32:5F:4D:BE:34:E8:E3:09:91:54:D3:6D:C2:98:EB:8F:F2.
Are you sure you want to continue using this certificate ? (y/n): y
The validation of root certificate fingerprint is successful.
CA certificate stored successfully from server nbufrpux4.deutsche-boerse.de.

[root@m7testpdb2 ~]# /usr/openv/netbackup/bin/nbcertcmd -getCertificate -server nbufrpux4.deutsche-boerse.de -token WXTPEAMGEXNBBKWG
Host certificate and certificate revocation list received successfully from server nbufrpux4.deutsche-boerse.de.
{code}

installation as root 
{code:java}
[root@m7testpdb2 NetBackup_9.0-RedHat]# ./install
Veritas Installation Script
Copyright (c) 2020 Veritas Technologies LLC. All rights reserved.


        Installing NetBackup Client Software
....

Do you wish to continue? [y,n] (y)
{code}

after the installation 
{code:java}
[root@m7testpdb2 cs687]# cat /usr/openv/netbackup/bin/version
NetBackup-RedHat2.6.32 9.0
{code}

installation of the agent 
{code:java}
-rw-r--r--  1 cs687 users 300024 May 11 10:12 VRTSnbpostgresqlagent.rpm
rpm -i VRTSnbpostgresqlagent.rpm

[root@m7testpdb2 openv]# rpm -qa | grep VRTSnbpostgresqlagent
VRTSnbpostgresqlagent-9.0.0.0-1601019441.x86_64

[root@m7testpdb2 NBPostgreSQLAgent]# rpm -ql VRTSnbpostgresqlagent-9.0.0.0-1601019441.x86_64
/usr/NBPostgreSQLAgent
/usr/NBPostgreSQLAgent/I18N_EN
/usr/NBPostgreSQLAgent/README
/usr/NBPostgreSQLAgent/nbpgsql
/usr/NBPostgreSQLAgent/version.txt
{code}

after the Agent installation copied over the binary and the conf file to the postgres home-directory of the tested db-instance 
{code:java}
/var/lib/pgsql_m7tshrdsyt3async/NBPostgreSQLAgent

-rw-r--r-- 1 root root   21520 May 17 07:38 I18N_EN
-rwxr-xr-x 1 root root 1277717 May 17 07:38 nbpgsql
-rw-r--r-- 1 root root    6839 May 17 08:00 nbpgsql.conf
-rw-r--r-- 1 root root  264261 May 18 08:24 nbpgsql.log
-rw-r--r-- 1 root root    2709 May 17 07:38 README
-rw-r--r-- 1 root root      35 May 17 07:38 version.txt
{code}

Changes with the new client 9 can find in the nbpgsql.conf file:
* DB_INSTANCE_NAME
{code:java}
#------------------------------------------------------------------------------------------------------------
# Optional parameter for PostgreSQL backup.
# Configure this parameter to map database instance name to PostgreSQL backup while querying for backups.
# PostgreSQL database instance name.
# For example, DB_PORT=db_instance_1
#------------------------------------------------------------------------------------------------------------
DB_INSTANCE_NAME=Systemtest3
{code}
Properly with that identifier we can identify which backup-id belongs to which shared-database instance. 

* BACKUP_TYPE
started backup without lvm option 

started full-backup with SYSTEMTEST3 *without lvm option*
* *base-size* 44G
* *dir-size* 48G 
Start-Time 8:19 -> End-Time: 8:47 ~ {color:#DE350B}*28 minutes! {color}

also started the backup with option *lvm*
it took 11 minutes then it broke up with the following error. Regarding the last time the backup with lvm option was also not faster, anyways I would recommend to use it without lvm 
{code:java}
Error! The backup has failed.
Error unmounting the snapshot directory:  /mnt/pgsqlsnap_1621321185 - Invalid argument
{code}


{code:java}
./nbpgsql -o backup -S nbufrpux4.deutsche-boerse.de -P UX4_POSTGRESQL_FB -s F2W
{code}

after the backup, we can query the backup with instance_name: systemtest3
{code:java}
[root@m7testpdb2 NBPostgreSQLAgent]# ./nbpgsql -o query -P UX4_POSTGRESQL_FB
Warning! Log size is not set or 0. Setting the log-size to 10 MB
Query initiated from XBSA ...
Setting the policy : UX4_POSTGRESQL_FB
Setting the database instance name : Systemtest3
PostgreSQL backups matching the search criteria:
============================================================================================================================
DBBackup ID      Version          Mode      Client OS      DB Port             Backup Time                     DB Instance
============================================================================================================================
1621317402        11.9          postgres      Linux         26006         Tue May 18 07:56:42 2021         Systemtest3
{code}

","18/May/21 14:11;cs687;h2. {color:#DE350B}*Archiving logfiles (transaction logfiles) which will be cleaned up*{color}

*archiving command with cleanup!*
{code:java}
[root@m7testpdb2 NBPostgreSQLAgent]# ls -all /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/
-rw------- 1 postgres postgres 16777216 May 18 09:11 000000220000011800000088
-rw------- 1 postgres postgres 16777216 May 18 09:11 000000220000011800000089
-rw------- 1 postgres postgres 16777216 May 18 09:11 00000022000001180000008A
-rw------- 1 postgres postgres 16777216 May 18 09:11 00000022000001180000008B
-rw------- 1 postgres postgres 16777216 May 18 09:11 00000022000001180000008C
-rw------- 1 postgres postgres 16777216 May 18 09:12 00000022000001180000008D
-rw------- 1 postgres postgres 16777216 May 18 09:12 00000022000001180000008E
-rw------- 1 postgres postgres 16777216 May 18 09:12 00000022000001180000008F
-rw------- 1 postgres postgres 16777216 May 18 09:13 000000220000011800000090
-rw------- 1 postgres postgres 16777216 May 18 09:13 000000220000011800000091
{code}
{color:#DE350B}this will also remove pg_xlog_archive folder, needs to be double-checked{color}
*Michael Lievens i starting a veritas session and asking for support!*

{code:java}
# -s tells us the schedulename for ""A""archiving ""3M"" 3 month on the server ""nbufrpux4.deutsche-boerse.de""
/usr/openv/netbackup/bin/bparchive -p UX4_USR_BCK -s A3M -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive

[root@m7testpdb2 11]# ls -all /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive
total 0
drwxr-xr-x 2 postgres postgres  6 May 18 14:58 .
drwxr-xr-x 4 postgres postgres 33 Apr 21  2020 ..
{code}

*listing the archived backups*
{code:java}
[root@m7testpdb2 bin]# /usr/openv/netbackup/bin/bplist -A -l -C m7testpdb2.deutsche-boerse.de -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/
drwxr-xr-x postgres  postgres            0 May 18 09:13 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/
drwxr-xr-x postgres  postgres            0 May 18 09:13 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/
drwxr-xr-x postgres  postgres            0 May 18 09:13 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/
drwxr-xr-x postgres  postgres            0 May 18 09:13 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/

# and to see the files...
[root@m7testpdb2 11]# /usr/openv/netbackup/bin/bplist -A -C m7testpdb2.deutsche-boerse.de -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_
archive/*
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000C5
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000C6
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000C7
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000C8
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000C9
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000CA
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000CB
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/0000002200000114000000CC
{code}


*restoring the archived backups*
{code:java}
[root@m7testpdb2 11]# /usr/openv/netbackup/bin/bprestore -A -C m7testpdb2.deutsche-boerse.de -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive
.....

[root@m7testpdb2 11]# ls -all /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive
total 4594768
drwxr-xr-x 2 postgres postgres    12288 May 18 15:33 .
drwxr-xr-x 3 postgres postgres       29 May 18 15:32 ..
-rw------- 1 postgres postgres 16777216 May 17 09:08 0000002200000114000000F3
-rw------- 1 postgres postgres 16777216 May 17 09:08 0000002200000114000000F4
-rw------- 1 postgres postgres 16777216 May 17 09:08 0000002200000114000000F5
-rw------- 1 postgres postgres 16777216 May 17 09:08 0000002200000114000000F6
-rw------- 1 postgres postgres 16777216 May 17 09:08 0000002200000114000000F7
....
{code}

to see if the job is still running
{code:java}
[root@m7testpdb2 pg_xlog_archive]# /usr/openv/netbackup/bin/bpps -x
NB Processes
------------
root     33974     1  0 May11 ?        00:00:24 /usr/openv/netbackup/bin/vnetd -proxy inbound_proxy -number 0
root     33975     1  0 May11 ?        00:00:07 /usr/openv/netbackup/bin/vnetd -proxy outbound_proxy -number 0
root     34035     1  0 May11 ?        00:00:26 /usr/openv/netbackup/bin/vnetd -standalone
root     34041     1  0 May11 ?        00:00:05 /usr/openv/netbackup/bin/bpcd -standalone
root     34082     1  0 May11 ?        00:00:51 /usr/openv/netbackup/bin/nbdisco
postgres 49044     1  1 16:41 ?        00:00:01 bpbkar -r 8035200 -dt 0 -to 0 -bpstart_time 1621347817 -clnt m7testpdb2.deutsche-boerse.de -class UX4_USR_BCK -sched A3M -st UARC -bpstart_to 300 -bpend_to 300 -read_to 300 -ru postgres -rg postgres -archive -use_otm -fso -U -IEL -b m7testpdb2.deutsche-boerse.de_1621347516 -kl 28 -S nbufrpux4.deutsche-boerse.de -use_ofb

Shared Veritas Processes
-------------------------
root     31715     1  0 May11 ?        00:00:00 /opt/VRTSpbx/bin/pbx_exchange
{code}


Some additional information from netbackup team
{code:java}
Add the next lines in bp.conf as SERVER
nbufrpux3.deutsche-boerse.de
nbufrpuxms31.deutsche-boerse.de
nbufrpuxms32.deutsche-boerse.de
nbufrpuxcc31.deutsche-boerse.de
nbufrpuxcc32.deutsche-boerse.de
nbufrpux4.deutsche-boerse.de
nbufrpuxms41.deutsche-boerse.de
nbufrpuxms42.deutsche-boerse.de
nbufrpuxcc41.deutsche-boerse.de
nbufrpuxcc42.deutsche-boerse.de

Policies with retention 3 month for the Postgresql DB 
UX3_POSTGRESQL
	UX4_POSTGRESQL
Command for backup/restore/list nbpgsql 

Policies for logs
-	UX3_USR_BCK
-	UX4_USR_BCK
=> schedulename
U3M
U2Y
A3M
A2Y
Started with U => backup and use command bpbackup (no cleanup for your sever)
Started with A => archive and use command bparchive  (remove files for your server)
To restore : bprestore
To list : bplist
{code}
","16/Jul/21 15:48;cs687;h1. *+{color:#DE350B}FINALLY{color}+*
the *archiving*, *listing* and *restoring* was tested and all the open bugs were fixed with new version

What is necessary: 
Installing the new client, before we do that we need to stop netbackup service : 
{code:java}
[root@m7testpdb2 pg_xlog_archive]# ls -all /tmp/eebinstaller_4041532_1_linuxR_x86_2_6_32-210716091619_
-rwxr-xr-x 1 cs687 users 2669441 Jul 16 14:52 /tmp/eebinstaller_4041532_1_linuxR_x86_2_6_32-210716091619_
{code}

{code:java}
[root@m7testpdb2 tmp]# /etc/init.d/netbackup stop
[root@m7testpdb2 tmp]# ./eebinstaller_4041532_1_linuxR_x86-210629071439_

This program performs an installation of files related to
PET4040163, SET4041532, EEB1 on platform linuxR_x86.

DISCLAIMER:
-----------
NOTE: These binaries are intended to help address a certain issue or enhance
a certain feature within the Veritas software for which these binaries were
created. They are intended solely for the recipient and must not be further
distributed to other parties, as they may not be generally available. Their
use is subject to the terms and conditions of your applicable Veritas license
and support agreements. They have not been fully tested by Veritas in all
environments, so please do not install these binaries unless instructed to
do so by Veritas.

Do you acknowledge this disclaimer?   [y,n] (y) y

This installer will use the following as the base installation directory:
  /usr/openv

Is this the correct path?   [y,n] (y) y

Veritas Bug ID: 4041532
NetBackup_9.0 linuxR_x86

Deliverables:
-------------
/lib/libnbclient.so
/lib/libnbclientcST.so
/lib/libnbclientcSECST.so
/lib/libnbclientST.so
/netbackup/bin/bpbkar
/netbackup/bin/bpbrm

Additional Notes:
-----------------
This EEB needs to be installed on both the clients and media servers which will be backing up the clients.  One of these media servers may be the NetBackup Primary server if it also hosts a storage unit which is used by one of policies backing up a client.

File checksum(s):
-----------------
383783899 428324 libnbclient.so
557528394 375516 libnbclientcST.so
2035291392 375516 libnbclientcSECST.so
2055953520 428096 libnbclientST.so
844943424 915665 bpbkar
3389706294 5785443 bpbrm

Recommended Service State:
--------------------------
Shutdown all NetBackup services and then run this installer. Restart all services after the installation succeeds.

Continue?  [y,n] (y) y
...
Extracting...
/usr/openv/lib/libnbclientcST.so
/usr/openv/lib/libnbclientST.so
/usr/openv/netbackup/bin/bpbkar
/usr/openv/lib/libnbclientcSECST.so
/usr/openv/lib/libnbclient.so

Installation complete.

[root@m7testpdb2 tmp]# /etc/init.d/netbackup start
{code}


*creating empty files:*
{code:java}
/var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive
[root@m7testpdb2 pg_xlog_archive]# touch test1
[root@m7testpdb2 pg_xlog_archive]# touch test2
[root@m7testpdb2 pg_xlog_archive]# touch test3
{code}

*archiving the files and clean them up locally (A3M means like stored for 3 month)*

{code:java}
[root@m7testpdb2 pg_xlog_archive]# /usr/openv/netbackup/bin/bparchive -p UX4_USR_BCK -s A3M -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/*

[root@m7testpdb2 pg_xlog_archive]# ll
total 0
{code}

*list all the test-archives*
{code:java}
[root@m7testpdb2 pg_xlog_archive]# /usr/openv/netbackup/bin/bplist -A -l -C m7testpdb2.deutsche-boerse.de -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/test*
-rw-r--r-- root      root                6 Jul 16 15:36 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/test1
-rw-r--r-- root      root                6 Jul 16 15:36 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/test2
-rw-r--r-- root      root                6 Jul 16 15:36 /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/test3
{code}

*finally restore them*
{code:java}
[root@m7testpdb2 pg_xlog_archive]# /usr/openv/netbackup/bin/bprestore -A -C m7testpdb2.deutsche-boerse.de -S nbufrpux4.deutsche-boerse.de /var/lib/pgsql_m7tshrdsyt3async/backup/11/pg_xlog_archive/test*

[root@m7testpdb2 pg_xlog_archive]# ll
total 12
-rw-r--r-- 1 root root 6 Jul 16 15:36 test1
-rw-r--r-- 1 root root 6 Jul 16 15:36 test2
-rw-r--r-- 1 root root 6 Jul 16 15:36 test3
{code}

",,,,,,,,,,,,,,,,,,,,,
Requesting/Replace Certificates for OPCOM-LIPA,M7P-8192,109493,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,21/Apr/21 12:39,05/May/21 11:17,16/Sep/21 14:11,27/Apr/21 11:32,,6.12.12,7tops_sprint116,,,Certificates,,,23/Apr/21 00:00,M7PRODOPS,,,,,,,"{code:java}
[root@m7shrdexteweb1 ssl]# openssl x509 -in lipa1.opcom.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            41:49:19:7c:09:09:03:04:1e:b0:71:ce:8a:a2:8b:5e
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: May  6 00:00:00 2019 GMT
            Not After : May  5 23:59:59 2021 GMT
{code}

added the env to the certificate repository, done here: https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/24/files

DESCRIPTION:
* for requesting new certs we have to do the following steps:
** Project A. Generate CSR (Ansible Deployment)
** Create Service Request and foward the mail to ssl-admin
** Ones we got the new certs back - save as Certificate only, PEM encoded
** uploade the new ones with the following jenkins job Project B. Import Cert to Vault (Ansible Deployment)

*  for replacing the new certs we have to do the following steps 
** backuping the old certificates on the hosts m7shrdextewebX & m7shrdextesslX 
** replacing the certs with the command: 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-lipa-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-lipa-app-haproxy*"" --tags certs -k -K -b
** checking the results afterwards
** restarting the instances like this 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-lipa-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-lipa-app-haproxy*"" --tags stop,start -k -K -b
** checking the web-gui if certs were replaced ",,cs687,,,,,,,,,,,,,,,,,M7P-8124,,,,,,,,,,,,,,,,,,,,,,"27/Apr/21 11:32;cs687;opcom-lipa-cert-replacement.png;https://jira.deutsche-boerse.com/secure/attachment/94827/opcom-lipa-cert-replacement.png",,,,,,,,,,,,,,,sw455,,,,,,,,"certificates replaced, double checked with the webgui afterwards. ",,,,,,,,OPCOM,,,,,,,,,,,,,,,,12268800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzke7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,done,,,,,,,,,,"{""issueId"":109493,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,LIPA,,,,"21/Apr/21 12:43;cs687;1.) *Creating CSR-Request*
Project A. Generate CSR (Ansible Deployment)
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/

Afterwards we received an email for SSL-Team and added two new entries in vault
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/xrpm/lipa/cert/

Request_lipa1.opcom.m7.deutsche-boerse.com
Request_lipa2.opcom.m7.deutsche-boerse.com
Created: IT-Service Request with the ID-No: 7B5921

#######################################################
EMAIL to SSL-ADMIN Team 
{code:java}
Hello SSL-Admin Team,

Please sign the attached CSR as soon ""ITSR 7B5921"" is approved by @Alexander Thorne

Thank you in Advance!

Cheers, 
Steffen 
{code}
","27/Apr/21 10:59;cs687;2.) downloaded the certificates (server-cert & Intermediate) and uploaded with jenkins job ""Project B. Import Cert to Vault (Ansible Deployment)""

after checking vault and the updated certificates, I backuped the old existing certs on m7shrdexteweb1/2 and m7shrdextessl1-4 in /tmp/opcom-cert

replacing the new certificates with the old one:
{code:java}
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-lipa-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-lipa-app-haproxy*"" --tags certs -k -K -b
{code}

{code:java}
[root@m7shrdexteweb2 ssl]# ls -all | grep opcom
-rw-r-----   1 apache apache  2986 Apr 27 11:23 lipa2.opcom.m7.deutsche-boerse.com_cert.pem
-rw-r-----   1 apache apache  1794 Apr 27 11:22 lipa2.opcom.m7.deutsche-boerse.com_chain.pem
-rw-r-----   1 apache apache  1675 Apr 27 11:22 lipa2.opcom.m7.deutsche-boerse.com_key.pem

[root@m7shrdexteweb1 ssl]# openssl x509 -in lipa1.opcom.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            06:d5:20:64:8f:7e:c7:69:21:f1:51:67:92:2e:c4:b4
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1
        Validity
            Not Before: Apr 26 00:00:00 2021 GMT
            Not After : May  4 23:59:59 2022 GMT
{code}


{code:java}
[root@m7shrdextessl1 xrpm-lipa-app-haproxy1]# ll
total 16
-rw-r----- 1 sslsrv sslsrv 6015 Apr 27 11:27 server.pem
-rw-r----- 1 sslsrv sslsrv 5640 Apr 14  2020 trustedCAs.pem

[root@m7shrdextessl1 xrpm-lipa-app-haproxy1]# openssl x509 -in server.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            06:d5:20:64:8f:7e:c7:69:21:f1:51:67:92:2e:c4:b4
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1
        Validity
            Not Before: Apr 26 00:00:00 2021 GMT
            Not After : May  4 23:59:59 2022 GMT
{code}


","27/Apr/21 11:29;cs687;3.) restarting the haproxy´s and apaches for activating the certificate

{code:java}
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xrpm-lipa-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xrpm-lipa-app-haproxy*"" --tags stop,start -k -K -b
{code}
","27/Apr/21 11:32;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Requesting/Replace Certificates for XSOP-ASIM,M7P-8191,109492,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,21/Apr/21 12:21,05/May/21 11:17,16/Sep/21 14:11,29/Apr/21 10:10,,6.12.12,7tops_sprint116,,,Certificates,,,23/Apr/21 00:00,M7PRODOPS,,,,,,,"{code:java}
[root@m7shrdexteweb1 ssl]# openssl x509 -in asim1.xsop.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            e4:ad:24:b6:34:8a:61:83:74:a4:71:4d:ee:f8:62:d1
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Apr 30 00:00:00 2019 GMT
            Not After : Apr 29 23:59:59 2021 GMT
{code}

added the env to the certificate repository, done here: https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/24/files

DESCRIPTION:
* for requesting new certs we have to do the following steps:
** Project A. Generate CSR (Ansible Deployment)
** Create Service Request and foward the mail to ssl-admin
** Ones we got the new certs back - save as Certificate only, PEM encoded
** uploade the new ones with the following jenkins job Project B. Import Cert to Vault (Ansible Deployment)

*  for replacing the new certs we have to do the following steps 
** backuping the old certificates on the hosts m7shrdextewebX & m7shrdextesslX 
** replacing the certs with the command: 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xsop-asim-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xsop-asim-app-haproxy*"" --tags certs -k -K -b
** checking the results afterwards
** restarting the instances like this 
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xsop-asim-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xsop-asim-app-haproxy*"" --tags stop,start -k -K -b
** checking the web-gui if certs were replaced ",,cs687,,,,,,,,,,,,,,,,,M7P-8124,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,certificates replaced ,,,,,,,,Southpool,,,,,,,,,,,,,,,,12096000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzkdz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see coments,,,,,,,,,,"{""issueId"":109492,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"21/Apr/21 12:23;cs687;1.) *Creating CSR-Request*
Project A. Generate CSR (Ansible Deployment)
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/

Afterwards we received an email for SSL-Team and added two new entries in vault
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/xsop/asim/cert/

Request_asim1.xsop.m7.deutsche-boerse.com
Request_asim2.xsop.m7.deutsche-boerse.com
Created: IT-Service Request with the ID-No: 7B5821

#######################################################
EMAIL to SSL-ADMIN Team 
{code:java}
Hello SSL-Admin Team,

Please sign the attached CSR as soon ""ITSR 7B5821"" is approved by @Alexander Thorne

Thank you in Advance!

Cheers, 
Steffen 
{code}
","29/Apr/21 09:25;cs687;2.) downloaded the certificates (server-cert & Intermediate) and uploaded with jenkins job ""Project B. Import Cert to Vault (Ansible Deployment)""

after checking vault and the updated certificates, I backuped the old existing certs on m7shrdexteweb1/2 and m7shrdextessl1-4 in /tmp/xsop-cert
replacing the new certificates with the old one:
{code:java}
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xsop-asim-app-web*"" --tags certs -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xsop-asim-app-haproxy*"" --tags certs -k -K -b
{code}
","29/Apr/21 09:25;cs687;3.) restarting the haproxy´s and apaches for activating the certificate at 10:00

{code:java}
ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*xsop-asim-app-web*"" --tags stop,start -k -K -b
ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*xsop-asim-app-haproxy*"" --tags stop,start -k -K -b
{code}","29/Apr/21 10:10;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Create generic ansible procedure to upgrade Kafka seamlessly ,M7P-8187,109453,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,nz893,nz893,20/Apr/21 15:02,03/Sep/21 09:36,16/Sep/21 14:11,,,,,,,,,,,7tops_comm,ansible,kafka,,,,,"Kafka needed to be updated regularly. So, we need to have automated way how to upgrade kafka.  The upgrade should be seamless.",,nz893,op211,,,,,,,,,,,,,,,,M7P-8390,M7P-5634,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,1123200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztdr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109453,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/21 13:25;nz893;Intitial upgrade needs to be done in two steps. First upgrade from 4.4.2 to 5.5.1 and then from 5.5.1 to 6.1 as recommended in https://docs.confluent.io/platform/current/installation/upgrade.html.","17/May/21 14:27;nz893;working on it.","17/May/21 23:06;nz893;kafka upgrade branch - https://github.deutsche-boerse.de/dev/energy.automation.deployments/compare/master...kafka-upgrade","02/Jun/21 10:34;nz893;The playbook is almost ready to go. It's working (is functional), but dirty.","03/Sep/21 09:36;op211;Taken out of current sprint. Need to be put into new sprint again later on.",,,,,,,,,,,,,,,,,,,,,,,
collect a list of M7 hosts sending logs to ebsm,M7P-8177,109367,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,19/Apr/21 09:10,30/Jun/21 12:13,16/Sep/21 14:11,22/Jun/21 15:15,,6.12.80,7tops_sprint120,,,EBSM,,,,7tops_comm,EBSM,XS,,,,,"Each host sending logs to EBSM will have an *NFS share mounts*, therefore we need a list of all M7 hosts sending logs to EBSM.

The logs used to sent via SCP but we would like to take advantage of nfs share and so we are implementing a way of sending logs to ebsm.

We plan to split the work in the following way:
 * 7TOPS (Alex Orlov) will deliver the list of hosts
 * SYSENG (Andrei Nazarenko) will mount the nfs shares
 * 7TOPS (Alex Orlov) will adjust and deploy the transfer script

 ",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,done,,,,,,,,,,,,,,,,,,,,,,,,9676800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzoxz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109367,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"21/Apr/21 13:12;iu252;List of M7T/A/C hosts:

{noformat}
M7HUPXCUTEAMQ2
M7HUPXASIMAMQ2
M7HUPXASIMAMQ1
M7HUPXCUTEAMQ3
M7HUPXCUTEAMQ1
M7XSOPCUTEAMQ1
M7HUPXASIMAMQ3
M7HUPXSIMUAMQ3
M7HUPXSIMUAMQ1
M7HUPXSIMUAMQ2
M7XSOPCUTEAMQ2
M7XSOPASIMAMQ2
M7XSOPASIMAMQ1
M7XSOPCUTEAMQ3
M7XSOPASIMAMQ3
M7XSOPSIMUAMQ1
M7XSOPSIMUAMQ2
M7ELTSLIPAAMQ1
M7XSOPSIMUAMQ3
M7ELTSLIPAAMQ2
M7ELTSLIPAAMQ3
M7ELTSACUTAMQ1
M7ELTSCUTEAMQ3
M7ELTSACUTAMQ3
M7ELTSACUTAMQ2
M7ELTSASIMAMQ1
M7ELTSCUTEAMQ2
M7ELTSCUTEAMQ1
M7ELTSASIMAMQ2
M7ELTSASIMAMQ3
M7ELTSASIMAMQ4
M7ELTSASIMAMQ5
M7ELTSSIMUAMQ3
M7ELTSSIMUAMQ2
M7ELTSCTPBAMQ3
M7ELTSCTPBAMQ2
M7ELTSSIMUAMQ1
M7PLPXLIPAAMQ1
M7ELTSCTPBAMQ1
M7PLPXLIPAAMQ2
M7PLPXLIPAAMQ3
M7PLPXSIMUAMQ2
M7PLPXSIMUAMQ1
M7PLPXSIMUAMQ3
M7XRPMLIPAAMQ1
M7XRPMLIPAAMQ3
M7XRPMLIPAAMQ2
M7XRPMSIMUAMQ1
M7XRPMSIMUAMQ2
M7XRPMSIMUAMQ3
M7SHRDSHOWAMQ1
M7SHRDSHOWAMQ2
M7SHRDSHOWAMQ3
M7SHRDDST1AMQ1
M7HUPXCUTEM7B2
M7HUPXCUTEM7B1
M7SHRDDST1AMQ2
M7SHRDDST1AMQ3
M7HUPXASIMM7B2
M7HUPXASIMM7B1
M7HUPXSIMUM7B2
M7XSOPCUTEM7B2
M7HUPXSIMUM7B1
M7XSOPCUTEM7B1
M7XSOPASIMM7B2
M7XSOPASIMM7B1
M7XSOPSIMUM7B1
M7ELTSLIPAM7B1
M7XSOPSIMUM7B2
M7ELTSLIPAM7B2
M7ELTSACUTM7B2
M7ELTSCUTEM7B1
M7ELTSCUTEM7B2
M7ELTSACUTM7B1
M7ELTSASIMM7B1
M7ELTSASIMM7B2
M7ELTSSIMUM7C2
M7ELTSCTPBM7B1
M7ELTSCTPBM7B2
M7PLPXLIPAM7B2
M7PLPXSIMUM7B2
M7PLPXLIPAM7B1
M7PLPXSIMUM7B1
M7XRPMSIMUM7B2
M7XRPMSIMUM7B1
M7XRPMLIPAM7B2
M7XRPMLIPAM7B1
M7SHRDSHOWM7B2
M7SHRDSHOWM7B1
M7SHRDDST1M7B1
M7SHRDDST1APP2
M7SHRDDST1APP1
M7SHRDDST1M7B2
M7SHRDEXTEREP1
M7SHRDEXTEREP2
M7AAMPRSIMUAPP2
M7AXEERCUTEAPP2
M7AAMPRCUTEAPP2
M7AAMPRSIMUAPP1
M7AXEERCUTEAPP1
M7AAMPRCUTEAPP1
M7AXEERASIMAPP1
M7AXEERSIMUAPP2
M7AXEERSIMUAPP1
M7AXEERCUTEAMQ1
M7AXEERCUTEAMQ2
M7AXEERASIMAMQ1
M7AXEERASIMAMQ2
M7AXEERASIMAPP2
M7AXEERSIMUAMQ1
M7AXEERSIMUAMQ2
m7cicsccuteapp1
m7cicsccuteapp2
m7cicsccuteamq3
m7cicsccuteamq2
m7cicsccuteamq1
{noformat}
","21/Apr/21 14:52;iu252;SYSENG ticket created: https://jira.deutsche-boerse.com/browse/SYSENGINT-613
Informed [~wm282]","27/May/21 07:03;iu252;Transfer script deployed to all simu like M7 tomcat/rabbitmq-hosts.",,,,,,,,,,,,,,,,,,,,,,,,,
m7*glfs Hosts in SIMU and PROD: Migrate heapdump and decom,M7P-8169,109300,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,op211,op211,op211,16/Apr/21 11:02,26/Aug/21 09:35,16/Sep/21 14:11,28/May/21 14:36,,7tops_sprint118,,,,uknown,,,,7tops_comm,,,,,,,"It's about the following hosts:
{noformat}
m7shrdprodglfs1
m7shrdprodglfs2
m7shrdsimuglfs1
m7shrdsimuglfs2{noformat}
They are not really used anymore, only for heap dumps. Steps for decom:
 * Create heap dump folders on pdb hosts (SYSENGINT-599)
 * Migrate heap dump mounts to pdb for all accessing m7 hosts
 * Final check, if no more gluster volumes are used by m7 environments
 * Shutdown and decom glfs hosts",,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,See comments,,,,,,,,,,,,,,,,,,,,,,,,9504000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzztdz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":109300,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"20/May/21 08:58;op211;*SIMU*
{noformat}
Client connections for volume m7_heapdump
----------------------------------------------
Brick : m7shrdsimuglfs1:/m7/data/heapdump
Clients connected : 20
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.59.101:1018                                      64850252        69996664           31305
10.139.59.100:1020                                      64448012        69714476           31305
10.139.59.8:1021                                        64554276        69788532           31305
10.139.59.11:1021                                       65465452        70463948           31305
10.139.59.7:1020                                        64895972        70033516           31305
10.139.59.69:1017                                       66405792        71150920           31305
10.139.59.204:1021                                      66841104        71458052           31305
10.139.59.12:1021                                       65882212        70754396           31305
10.139.59.195:1021                                     169820200       146140512           31305
10.139.59.66:1018                                       66275308        71063132           31305
10.139.59.60:852                                             932             460           31101
10.139.59.60:847                                        55273648        48329860           31101
10.139.59.203:1017                                      66357340        71115880           31305
10.139.59.52:951                                            1164             756           31101
10.139.59.52:910                                            2776            1916           31101
10.139.59.205:1016                                      34333604        29127748           31305
10.139.59.177:1021                                      11434872        11488724           31305
10.139.59.92:1016                                       11395152        11460628           31305
10.139.59.93:1019                                       11404992        11467908           31305
10.139.59.175:1020                                      26783572        22623632           31305
----------------------------------------------
Brick : m7shrdsimuglfs2:/m7/data/heapdump
Clients connected : 20
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.59.203:1021                                      50671480        54133452           31305
10.139.59.60:906                                            1040             612           31101
10.139.59.60:902                                             932             464           31101
10.139.59.69:1015                                       50705732        54157868           31305
10.139.59.11:1020                                       50371284        53907580           31305
10.139.59.52:855                                             932             464           31101
10.139.59.52:847                                        41658728        36425248           31101
10.139.59.7:1021                                        49627464        53302420           31305
10.139.59.66:1021                                       50611600        54093152           31305
10.139.59.100:1021                                      49234956        53020428           31305
10.139.59.101:1021                                      49571464        53259788           31305
10.139.59.8:1020                                        49338492        53090936           31305
10.139.59.204:1020                                      51068288        54420272           31305
10.139.59.12:1020                                       50729452        54164908           31305
10.139.59.205:1011                                      34381668        29193400           31305
10.139.59.177:1019                                      11472972        11541124           31305
10.139.59.92:1018                                       11432676        11512628           31305
10.139.59.93:1015                                       11442260        11519120           31305
10.139.59.175:1019                                      26821596        22676296           31305
10.139.59.195:1017                                      21492580        18060644           31305
----------------------------------------------
{noformat}","20/May/21 09:16;op211;SIMU environments:
 * -hupxasim-
 * -xrpmsimu-
 * -xrpmlipa-
 * -xsopasim-
 * -hupxsimu-
 * -xsopsimu-
 * -eltssimu (m7b and m7c)-","21/May/21 12:06;op211;All SIMU environments above have been changed to m7simupdb1/2 hosts.
{noformat}
Client connections for volume m7_heapdump
----------------------------------------------
Brick : m7shrdsimuglfs1:/m7/data/heapdump
Clients connected : 4
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.59.60:852                                             932             460           31101
10.139.59.60:847                                        55658428        48666304           31101
10.139.59.52:951                                            1164             756           31101
10.139.59.52:910                                            2776            1916           31101
----------------------------------------------
Brick : m7shrdsimuglfs2:/m7/data/heapdump
Clients connected : 4
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.59.60:906                                            1040             612           31101
10.139.59.60:902                                             932             464           31101
10.139.59.52:855                                             932             464           31101
10.139.59.52:847                                        42043508        36761692           31101
----------------------------------------------
{noformat}
Gluster service has been disabled on m7shrdsimuglfs12 and hosts have been restarted, to see if there are no issues. ","21/May/21 12:13;op211;*PROD*
{noformat}
----------------------------------------------Client connections for volume m7_heapdump
----------------------------------------------
Brick : m7shrdprodglfs1:/m7/data/heapdump
Clients connected : 17
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.53.195:941                                            932             464           31101
10.139.53.195:925                                       80477804        70356456           31101
10.139.53.184:1018                                      36271988        35630408           31305
10.139.53.223:1020                                      33204564        32603732           31305
10.139.53.203:1021                                      33245024        32631228           31305
10.139.53.249:1021                                      12633088        12952972           70000
10.139.53.194:1005                                           932             464           31101
10.139.53.182:1020                                      10108648         9938176           31305
10.139.53.201:1020                                      10101444         9932232           31305
10.139.53.226:1017                                       9018896         8864032           31305
10.139.53.228:1021                                       8488912         8349112           31305
10.139.53.242:1017                                       7977432         7834952           31305
10.139.53.194:1010                                          1040             612           31101
10.139.53.229:1018                                       2196996         2155508           31305
10.139.53.237:1015                                       2182500         2144992           31305
10.139.53.236:1015                                       2145508         2110640           31305
10.139.53.240:1016                                        225232          219332           31305
----------------------------------------------
Brick : m7shrdprodglfs2:/m7/data/heapdump
Clients connected : 16
Hostname                                               BytesRead    BytesWritten       OpVersion
--------                                               ---------    ------------       ---------
10.139.53.194:950                                       80472732        70352816           31101
10.139.53.194:932                                            932             464           31101
10.139.53.182:1019                                      34349740        34047544           31305
10.139.53.195:986                                            936             464           31101
10.139.53.223:1015                                      10213364        10119808           31305
10.139.53.203:1019                                      10239396        10140268           31305
10.139.53.226:1020                                      10202028        10115204           31305
10.139.53.184:1020                                      10206936        10115564           31305
10.139.53.228:1015                                      10175224        10092228           31305
10.139.53.201:1019                                      10186036        10103572           31305
10.139.53.242:1020                                       8045076         7970388           31305
10.139.53.236:1019                                       2162732         2145520           31305
10.139.53.240:1019                                        758028          748288           31305
10.139.53.195:1011                                          1044             612           31101
10.139.53.237:1018                                        224364          220624           31305
10.139.53.229:1020                                        227980          223248           31305
----------------------------------------------
{noformat}","21/May/21 12:21;op211;PROD environments:
 * -xrpmprod-
 * -xsopprod-
 * -eltsprod (m7b and m7c)-
 * -shrdprodrep-
 * -hupxprod-
 * -plpxprod-","26/May/21 15:56;op211;All PROD environments above have been changed to m7prodpdb1/2 hosts. Gluster service has been disabled on m7shrdprodglfs12 and all glusterd processes have been killed, to see if there are no issues. ","28/May/21 14:06;op211;All 4 hosts taken out of monitoring and stopped.","28/May/21 14:36;op211;Decom ticket created: https://jira.deutsche-boerse.com/browse/SYSENGINT-727

 ",,,,,,,,,,,,,,,,,,,,
Create Jenkins job to restart customer facing Envs (including PROD),M7P-8144,108983,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,wn626,wn626,12/Apr/21 10:57,11/Jun/21 12:12,16/Sep/21 14:11,01/Jun/21 09:11,,6.12.70,7tops_sprint118,,,jenkins,,,,7tops_comm,M7PRODOPS,S,,,,,"Create Jenkins job to restart customer facing Envs (including PROD) 

components need to be restarted in correct order

BizOps should have access to do it",,cs687,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Job was created in the new repository https://github.deutsche-boerse.de/dev/energy.automation.jenkins,,,,,,,,,,,,,,,,,,,,,,,,9244800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzzoy7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":108983,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"31/May/21 14:02;cs687;prepared pull-request which is stopping/starting the following instances without provided 
component/product version 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1614/files
* core
* enq
* reporting-engine
* h2h4u
* mtt
* rabbitmq (in stopping stage *it will be already started*)
* apache (in stopping stage *it will be already started*)
* haproxy (in stopping stage *it will be already started*)
* 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_restart_full/

tested it with ate4 environment:
https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FCD-Pipeline%2FM7T_restart_full/detail/M7T_restart_full/1/pipeline/103

needs to be approved from dev and double checked from the detective :) 
","01/Jun/21 09:10;cs687;Migrated the jenkins job to the new repository 
https://englobjci1.deutsche-boerse.de/job/Operations/job/04-M7T/job/restart_m7t_full/

https://github.deutsche-boerse.de/dev/energy.automation.jenkins/pull/28/files
https://github.deutsche-boerse.de/dev/energy.automation.jenkins/pull/29","01/Jun/21 09:11;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Access to ELTS PROD MTT,M7P-8142,108978,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,jv861,jv861,12/Apr/21 09:59,21/Apr/21 11:28,16/Sep/21 14:11,13/Apr/21 07:20,,6.11.230,7tops_sprint115,,,MTT,,,,M7PRODOPS,,,,,,,"On the Production Access page, there is no link to ELTS PROD's MTT - https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=8073347

After I guessed the link as https://prod1.epex.m7.deutsche-boerse.com:60044/mtt/admin I found out, the username password on that page doesn't work!

Can someone please find out the correct password to MTT? It is important for some production issues.

According to infrastructure excel, the MTT link above should point to Apaches running {{m7shrdprodwebX}}, listening on port {{60044}}. So I would start the investigation there, to check how does Apache does the authentication.

",,iu252,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-10050,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Password for user admin stored in vault,,,,,,,,,,,,,,,,,,,,,,,,13564800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzznv3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108978,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Apr/21 13:32;iu252;After analyses with [~dp007] we found the password for user ""admin"".
Martin already updated confluence page. 

Unfortunately we have different MTT password on HUPX PROD and ELTS PROD.
To fix this, we need to change the password for ELTS in vault (https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/elts/prod/mtt2/web_console_password) and redeploy MTT.

[~rehapav] please plan this activity for the next deployment on ELTS PROD.",,,,,,,,,,,,,,,,,,,,,,,,,,,
"Disable password history, expiration and lock on ATE2, ATE3 and ATE4",M7P-8141,108976,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,vp223,vp223,12/Apr/21 08:56,05/May/21 11:17,16/Sep/21 14:11,05/May/21 10:08,,6.12.12,7tops_sprint116,,,LDAP,,,,7tops,7tops_comm,S,,,,,"Please disable for ATE2, ATE3 and ATE4 password history and password expiration.
{code}
passwordCheckSyntax: on
passwordExp: off
passwordHistory: off
passwordLockout: off
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0{code}

Technical users
{code}
passwordCheckSyntax: on
passwordExp: off
passwordHistory: off
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0{code}",,cs687,pd122,pn508,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"change the the necessary attributes:
passwordExp: off
passwordHistory: off 
passwordLockout: off

and removed attribute:
passwordInHistory ",,,,,,,,,,,,,,,,,,,,,,,,11577600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzoxb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":108976,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Apr/21 15:16;pn508;we will use the standard set as described here [https://confluence.energy.svc.dbgcloud.io/display/M7T/M7+-+Password+Policy] ([~nn236], [~vp223] FYI)","22/Apr/21 10:50;cs687;just checked the password policy for ate2:
*command to list all the password policies*
{code:java}
ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $password -b cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test ""(&(objectclass=ldapsubentry)(objectclass=*))""
{code}

{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 5
objectClass: top
objectClass: extensibleObject
objectClass: ldapsubentry
objectClass: passwordpolicy
passwordCheckSyntax: on
passwordExp: on
passwordLockout: on
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0
cn: cn=nsPwPolicyEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 5
objectClass: top
objectClass: extensibleObject
objectClass: ldapsubentry
objectClass: passwordpolicy
passwordCheckSyntax: on
passwordExp: off
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
cn: cn=nsNoExpPwPolicyEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=cn\3DnsPwTemplateEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: top
objectClass: extensibleObject
objectClass: costemplate
objectClass: ldapsubentry
cosPriority: 1
cn: cn=nsPwTemplateEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}
","22/Apr/21 11:18;cs687;The following changes needs to be done for 2 policies: 
* *3DnsPwPolicyEntry*
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

  1.) remove passwordInHistory: 5
  2.) set passwordLockout: off
  3.) set passwordExp: off
  4.) add passwordHistory: off

* *3DnsNoExpPwPolicyEntry*
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

   1.) remove passwordInHistory: 5
   2.) add passwordHistory: off","22/Apr/21 11:23;cs687;*Action for the necessary changes above:*
*3DnsPwPolicyEntry*
{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapmodify -h m7shrdtestldp1.deutsche-boerse.de -D ""cn=Directory Manager"" -w $password
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordHistory
passwordHistory: off
-
replace: passwordLockout
passwordLockout: off
-
replace: passwordExp
passwordExp: off
-
delete: passwordInHistory

modifying entry ""cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test""

^C
{code}

*3DnsNoExpPwPolicyEntry*
{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapmodify -h m7shrdtestldp1.deutsche-boerse.de -D ""cn=Directory Manager"" -w $password
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordHistory
passwordHistory: off
-
delete: passwordInHistory

modifying entry ""cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test""

^C
{code}

*checking the policies after the changes:*
{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $password -b cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test ""(&(objectclass=ldapsubentry)(objectclass=passwordpolicy))""
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordExp: off
passwordLockout: off
passwordWarning: 0
passwordUnlock: off
passwordMaxFailure: 5
passwordMaxAge: 7776000
objectClass: top
objectClass: extensibleObject
objectClass: ldapsubentry
objectClass: passwordpolicy
passwordCheckSyntax: on
passwordMinCategories: 3
passwordMinLength: 8
cn: cn=nsPwPolicyEntry,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 5
objectClass: top
objectClass: extensibleObject
objectClass: ldapsubentry
objectClass: passwordpolicy
passwordCheckSyntax: on
passwordExp: off
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
cn: cn=nsNoExpPwPolicyEntry,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}

{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $password -b cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test ""(&(objectclass=ldapsubentry)(objectclass=passwordpolicy))"" passwordHistory
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordHistory: off

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordHistory: off
{code}
","22/Apr/21 12:26;cs687;The same has to be done for the env´s *ate3* and *ate2*, but *ate2* will be finished by [~pd122] ones he is done with his tests on ate2. 
The ticket will be still set to closed.

open commands for *ate2*:


{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapmodify -h m7shrdtestldp1.deutsche-boerse.de -D ""cn=Directory Manager"" -w $password
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordHistory
passwordHistory: off
-
replace: passwordLockout
passwordLockout: off
-
replace: passwordExp
passwordExp: off
-
delete: passwordInHistory
{code}



{code:java}
[cs687@m7shrdtestldp1 ~]$ ldapmodify -h m7shrdtestldp1.deutsche-boerse.de -D ""cn=Directory Manager"" -w $password
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordHistory
passwordHistory: off
-
delete: passwordInHistory
{code}

","22/Apr/21 12:46;cs687;done","05/May/21 10:07;pd122;ATE2 now modified in as requested:

{code:java}
[pd122adm@m7shrdtestldp1 ~]$  ldapmodify -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $pw
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordHistory
passwordHistory: off
-
replace: passwordLockout
passwordLockout: off
-
replace: passwordExp
passwordExp: off
-
delete: passwordInHistory

modifying entry ""cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test""

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
replace: passwordHistory
passwordHistory: off
-
delete: passwordInHistory

modifying entry ""cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test""

^C

{code}
",,,,,,,,,,,,,,,,,,,,,
Analyze M7 HUPX VMs,M7P-8131,108839,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,cs687,zq813,zq813,07/Apr/21 14:14,05/May/21 11:17,16/Sep/21 14:11,03/May/21 13:41,,7tops_sprint116,,,,cor,enq,,,7tops_comm,cute,Infra,m7,S,simu,,"1) Analyze the load characteristics in Grafana

2) Fix it if needed

 

Hello,

Following March CPM report, it appears that multiple VMs in the HUPX SIMU and CUTE environments are oversized. In order to preserve resources of the VMware cluster, would it be possible to shrink the following VMs:
|Host|Current memory allocated (GB)|VMMEMUSAGEMiB2SD
 (Average memory usage over February in MiB)|Proposed memory allocation (GB)|
|m7hupxcutem7b1|8|11.8|4|
|m7hupxcutem7b2|8|10.03|4|
|m7hupxsimum7b1|8|21.5|4|
|m7hupxsimum7b2|8|11.47|4|

 ",,cs687,pw231,zq813,,,,,,,,,,,,,,,,,M7P-7886,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Current RAM/Memory utilization is fine, double checked it in grafana.
So in that case we will not touch any tomcat VM for shrinking memory, unless we will not figure out the root cause for the huge difference between CPM report & grafana.

What might be is helpful, would be to shrink the Memory setting for our non-prod rabbitmq hosts to (2GB) and ELTS-ASIM (4G). Syt1 will be skipped. 



",,,,,,,,HUPX,,,,,,,,,,,,,,,,11750400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzt9z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":108839,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"29/Apr/21 11:32;zq813;[~cs687] I've added information about m7hupxcutem7b1 VM too. ","29/Apr/21 11:34;cs687;Had a discussion with [~zq813] about the topic above. 

First of all we agreed on it, that we have the same amount of Memory setup on both m7b machines and not making any differences because on m7b2 host less tomcat instances are running, like *""h2h4u, mtt and harvester""*
These instances are not deployed on second m7b host but maybe in the future of some emergency situation they can be used as an active running instance and then we have to change also the memory setup: 

Checked the tomcat Xmx and Xms setup for the mentioned hosts above, with the following result:

*m7hupxcutem7b1* ~6G + OS ~2G => 8G
||tomcat instance||Xms||Xmx||
|cor|780m|1950m|
|enq|2340m|3120m|
|harvester|12m|16m|
|h2h4u|512m|512m|
|mtt|512m|512|

*m7hupxcutem7b2*  => same Memory setup like above!
||tomcat instance||Xms||Xmx||
|cor|780m|1950m|
|enq|2340m|3120m|

*m7hupxsimum7b1*  ~6.6G + OS ~1.G => 8G
||tomcat instance||Xms||Xmx||
|cor|780m|1950m|
|enq|2340m|3120m|
|harvester|12m|16m|
|h2h4u|512m|512m|
|mtt|1024m|1024m|

*m7hupxsimum7b2*  => same Memory setup like above!
||tomcat instance||Xms||Xmx||
|cor|780m|1950m|
|enq|2340m|3120m|

Question is now if we can shrink down our Xmx at all or is it not safe enough to touch them at all? Will double check it with proper Dev´s 

at least that is the report of the last month
{code:java}
m7hupxcutem7b1 -> 0.944 G in last month
m7hupxcutem7b2 -> 0.8024 G in last month
m7hupxsimum7b1 -> 1.72G in last month
m7hupxsimum7b2 -> 0.9175G in last month
{code}

","29/Apr/21 13:12;cs687;[~pw231] will handle the ticket in the current PS sprint","03/May/21 10:08;pw231;We checked with [~cs687] and proposing the following change:
- m7bX - no change - [the usage is fair enough|https://grafana.energy.svc.dbgcloud.io/d/PhgXqCNik/system?orgId=2&from=now-30d&to=now&var-product=m7t&var-host=All&var-client=elts&var-client=hupx&var-client=plpx&var-client=xrpm&var-client=xsop&var-client_env=asim&var-group=tomcat&var-interval=10m]
- amqX - 2GB must be enough ([max usage is around 400MB|https://grafana.energy.svc.dbgcloud.io/d/PhgXqCNik/system?orgId=2&from=now-30d&to=now&var-product=m7t&var-host=All&var-client=elts&var-client=hupx&var-client=plpx&var-client=xrpm&var-client=xsop&var-client_env=asim&var-group=rabbitmq&var-interval=10m]) - for all non-prod envs but elts-asim
- elts-asim amqX - let's have 4GB (usage is around 500MB) ","03/May/21 13:41;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
re-deploy external test web servers to allow for local telegraf monitoring access,M7P-8117,108758,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pd122,pd122,06/Apr/21 14:30,21/Apr/21 11:28,16/Sep/21 14:11,12/Apr/21 12:15,,6.11.230,7tops_sprint115,,,apache,,,,7tops,toilwork,Web,,,,,change from [M7P-7996] to be rolled out to all M7T external test envs,,pd122,,,,,,,,,,,,,,,,,M7P-6576,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"web servers re-deployed, fixed issue (undefined variable used) find in ""global"" ELTS ASIM inventory",,,,,,,,,,,,,,,,,,,,,,,,13564800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjmf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108758,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"07/Apr/21 12:45;pd122;deployed
- XRPM LIPA
- PLPX LIPA
- ELTS LIPA
- ELTS ACUT
- ELTS CTPB
- ELTS CUTE
- XSOP CUTE
- HUPX CUTE","09/Apr/21 12:39;pd122;deployed:
- XRPM SIMU
- PLPX SIMU
- HUPX SIMU
- HUPX ASIM
- XSOP ASIM
- ELTS SIMU","09/Apr/21 14:53;pd122;ELTS ASIM deployment failed with

{code:java}
failed: [m7t-elts-asim-app-web2] (item={'source': 'm7_intraday.conf.j2', 'target': 'conf.d/m7_intraday.conf'}) => {
    ""changed"": false,
    ""item"": {
        ""source"": ""m7_intraday.conf.j2"",
        ""target"": ""conf.d/m7_intraday.conf""
    }
}

MSG:

AnsibleUndefinedVariable: 'amqp_port' is undefined
{code}

The problem seems to be

{code:java}
energy.automation.inventory/inventory/m7t/elts/asim/vars.yml:amqp_addresses_ext: [ ""10.136.148.23:{{ amqp_port }}"", ""10.136.20.18:{{ amqp_port }}"" ]
{code}

as this variable is not defined in the inventory , only in these deployment roles:
* coda
* m7c_enq
* cardio
* m7tenq
* stalker

In the inventory, there are only 3 environment wide definitions usng this variable:
* SHRD SYT1
* ELTS ASIM
* ELTS PROD

For other environments, the definition is part of *cardio* and *coda* modules inventory only:

{code:java}
[pd122adm@enprodauto1 {master L | ✔} ~/Sources/energy.automation.inventory/inventory/m7t]$ grep -Rl amqp_port 
shrd/syt3/coda/vars.yml
shrd/syt3/cardio/main.yml
shrd/ate4/coda/vars.yml
shrd/ate4/cardio/main.yml
shrd/syt1/vars.yml
shrd/syt1/cardio/main.yml
epex/asim/vars.yml
elts/asim/vars.yml
elts/simu/cardio/main.yml
elts/acut/cardio/main.yml
elts/ctpb/cardio/main.yml
elts/prod/vars.yml
elts/prod/cardio/main.yml
elts/lipa/cardio/main.yml
elts/cute/cardio/main.yml
{code}
","09/Apr/21 15:09;pd122;PR https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2678 created to fix","12/Apr/21 12:13;pd122;PR merged, ELTS ASIM web instances re-deployed",,,,,,,,,,,,,,,,,,,,,,,
Increase journal disk space for all ATE envs (ATE1 - ATE4) ,M7P-8102,108646,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,ef759,ef759,01/Apr/21 09:41,13/Apr/21 16:46,16/Sep/21 14:11,01/Apr/21 13:13,,6.11.223,7tops_sprint114,,,uknown,,,,7tops,M7PRODOPS,,,,,,"Actual disk space set for */shrd/journal* on all ATE hosts is not sufficient. High load on XBID side is causing huge journal files (around 900 MB for a single day) on each host.
Please unify the configuration for all ATE envs (Not same config on all hosts) and increase the disk space by at least 3GB for journal. Total allocated disk size after increase should be 5G for each host

Please create also a dedicated mount point for journal on ATE4

ATE1 /dev/mapper/rootvg-lv_local_journal    *4.0G*   2.0M    3.8G     1%   */shrd/journal*
ATE2 /dev/mapper/rootvg-lv_local_journal  *992M*   1.3M  929M     1%   */shrd/journal*
ATE3 /dev/mapper/rootvg-lv_local_journal    *2.0G*  703M    1.2G   38%   */shrd/journal*
ATE4 /dev/mapper/rootvg-lv_shrd                 *2.4G*    1.2G    1.2G   49%   */shrd*",,ef759,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Journal disk space for ATE1-4 increased.,,,,,,,,,,,,,,,,,,,,,,,,14515200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzmj3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108646,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/21 13:11;op211;For all 4 environments:

/ extended to 6g
/var/log extended to 2g
/shrd extended to 5g
/shrd/logs extended to 5g
/shrd/journal extended to 5g

New file system for /shrd/journal on ATE4 created.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade docker-compose to version 1.28,M7P-8099,108617,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,ax460,ax460,31/Mar/21 13:02,04/May/21 23:22,16/Sep/21 14:11,15/Apr/21 11:25,,6.12.12,7tops_sprint115,,,jenkins,,,,7tops,jenkins,,,,,,"On Jenkins workers there is older version (1.23) of docker compose - [https://github.deutsche-boerse.de/dev/energy.docker.hosts/blob/master/ansible/roles/energy.docker/defaults/main.yml#L8]

We need latest 1.28 in order to use [https://docs.docker.com/compose/environment-variables/]

 
----
I have reverted [https://github.deutsche-boerse.de/dev/m7.m7-product/pull/1348] and waiting until new docker-compose is ready on jenkins nodes

 

Status: 
||docker nodes||status||
|auto0|(/)|
|auto1|(/)|
|auto2|(/)|
|auto3|(/)|
|auto4|(/)|
|auto5|(/)|
|auto6|(/)|
|auto7|(/)|
|auto8|(/)|
|auto9|(/)|
|auto10|(/)|
|auto11|(/)|
|auto12|(/)|
|auto13|(/)|
|auto14|(/)|
|auto15|(/)|
|auto16|(/)|
|auto17|(/)|
|auto18|(/)|
|auto19|(/)|
|auto20|(/)|
|auto21|(/)|
|auto22|(/) |
|auto23|(/)|
|auto24|(/) |
|auto25|(/) |
|auto26|(/) |
|auto27|(/)|
|auto28|(/) |
|auto29|(/) |
|auto30|(/)|
|auto31|(/)|
|auto32|(/)|
|auto33|(/)|
|auto34|(/) |
|auto35|(/) |
|auto36|(/) |
|auto37|(/) |
|auto38|(/)|
|auto39|(/)|
|auto40|(/)|
|auto41|(/)|
|auto42|(/)|
|auto43|(/)|
|auto44|(/) |
|auto45|(/)|
|auto46|(/)|
|auto47|(/)|
|auto48|(/)|
|auto49|(/)|
|shared-medium0|(/)|
|shared-medium1|(/)|
|shared-medium2|(/) |
|small0|(/) |
|medium0|(/)  |
|large0|(/)  |

 ",,ax460,cs687,,,,,,,,,,,,,,,,M7P-7750,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,all jenkins docker nodes have python3.6.8 and docker-compose 1.28 deployed. ,,,,,,,,,,,,,,,,,,,,,,,,13305600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjlr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 115,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,,,,,see comments ,,,,,,,,,,"{""issueId"":108617,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/21 11:46;cs687;We checked it yesterday and deployed locally the newest version docker-compose 1.28.6 on auto1-node:

for this docker version python 3.6 or later is required, currently we are running python 2.7.5 
https://pypi.org/project/docker-compose/
 * after we upgraded the python version to 3.6 our ansible with version 2.8.7 were not able to run anymore.

It will be def. not support task which will be finished in the next minutes because of this unknown dependencies. 
First it needs a proper refinement and we should check all the required steps, deploy it on one of the test aws-nodes and re-write the playbook and test everything. 

 ","01/Apr/21 13:40;cs687;1.) Test to upgrade {color:#FF0000}*docker-compose:*{color}

{color:#172b4d}* remove old docker-compose installed by pip and install python36
{color}
{code:java}

{code}
*pip uninstall docker-compose*
*yum install python36*

In that case I found out that we have an old pip version running 

 

 
{code:java}
You are using pip version 8.1.2, however version 21.0.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.{code}
* upgrading new docker-compose version with pip
{code:java}
pip install docker-compose
{code}
 
{code:java}
Collecting docker-compose
  Downloading https://files.pythonhosted.org/packages/f7/2d/32fe3c141baea96b8064bf52d6bca9ddf8ef03ccdf468988df8d0e792756/docker_compose-1.28.6-py2.py3-none-any.whl (114kB)
    100% |████████████████████████████████| 122kB 5.4MB/s
Requirement already satisfied (use --upgrade to upgrade): cached-property<2,>=1.2.0; python_version < ""3.8"" in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): backports.ssl-match-hostname<4,>=3.5; python_version < ""3.5"" in /usr/lib/python2.7/site-packages (from docker-compose)
Collecting distro<2,>=1.5.0 (from docker-compose)
  Downloading https://files.pythonhosted.org/packages/25/b7/b3c4270a11414cb22c6352ebc7a83aaa3712043be29daa05018fd5a5c956/distro-1.5.0-py2.py3-none-any.whl
Collecting docker[ssh]<5,>=4.4.4 (from docker-compose)
  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)
    100% |████████████████████████████████| 153kB 5.6MB/s
Requirement already satisfied (use --upgrade to upgrade): websocket-client<1,>=0.32.0 in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): PyYAML<6,>=3.10 in /usr/lib64/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): jsonschema<4,>=2.5.1 in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): dockerpty<1,>=0.4.1 in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): requests<3,>=2.20.0 in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): texttable<2,>=0.9.0 in /usr/lib/python2.7/site-packages (from docker-compose)
Requirement already satisfied (use --upgrade to upgrade): docopt<1,>=0.6.1 in /usr/lib/python2.7/site-packages (from docker-compose)
Collecting python-dotenv<1,>=0.13.0 (from docker-compose)
  Downloading https://files.pythonhosted.org/packages/3d/7b/4a0bcac71bf24e5a63d043e53e3f56e1838a91c760638e1a0fc5338a36aa/python_dotenv-0.16.0-py2.py3-none-any.whl
Requirement already satisfied (use --upgrade to upgrade): six>=1.4.0 in /usr/lib/python2.7/site-packages (from docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): ipaddress>=1.0.16; python_version < ""3.3"" in /usr/lib/python2.7/site-packages (from docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): paramiko>=2.4.2; extra == ""ssh"" in /usr/lib/python2.7/site-packages (from docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): functools32; python_version == ""2.7"" in /usr/lib/python2.7/site-packages (from jsonschema<4,>=2.5.1->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): urllib3<1.25,>=1.21.1 in /usr/lib/python2.7/site-packages (from requests<3,>=2.20.0->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): chardet<3.1.0,>=3.0.2 in /usr/lib/python2.7/site-packages (from requests<3,>=2.20.0->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): idna<2.8,>=2.5 in /usr/lib/python2.7/site-packages (from requests<3,>=2.20.0->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): certifi>=2017.4.17 in /usr/lib/python2.7/site-packages (from requests<3,>=2.20.0->docker-compose)
Collecting typing; python_version < ""3.5"" (from python-dotenv<1,>=0.13.0->docker-compose)
  Downloading https://files.pythonhosted.org/packages/3b/c0/e44213fcb799eac02881e2485724ba5b0914600bc9df6ed922e364fdc059/typing-3.7.4.3-py2-none-any.whl
Requirement already satisfied (use --upgrade to upgrade): pyasn1>=0.1.7 in /usr/lib/python2.7/site-packages (from paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): bcrypt>=3.1.3 in /usr/lib64/python2.7/site-packages (from paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): cryptography>=1.5 in /usr/lib64/python2.7/site-packages (from paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): pynacl>=1.0.1 in /usr/lib64/python2.7/site-packages (from paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): cffi>=1.1 in /usr/lib64/python2.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): enum34; python_version < ""3"" in /usr/lib/python2.7/site-packages (from cryptography>=1.5->paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): asn1crypto>=0.21.0 in /usr/lib/python2.7/site-packages (from cryptography>=1.5->paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Requirement already satisfied (use --upgrade to upgrade): pycparser in /usr/lib/python2.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2; extra == ""ssh""->docker[ssh]<5,>=4.4.4->docker-compose)
Installing collected packages: distro, docker, typing, python-dotenv, docker-compose
  Found existing installation: docker 3.7.3
    Uninstalling docker-3.7.3:
      Successfully uninstalled docker-3.7.3
Successfully installed distro-1.5.0 docker-4.4.4 docker-compose-1.28.6 python-dotenv-0.16.0 typing-3.7.4.3
You are using pip version 8.1.2, however version 21.0.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
{code}
Afterwards we end up with an error and the reason for that is the following: 

 

 
{code:java}
Traceback (most recent call last):
File ""/usr/local/bin/pip"", line 9, in
load_entry_point('pip==21.0', 'console_scripts', 'pip')()
File ""/usr/local/lib/python2.7/site-packages/pkg_resources.py"", line 339, in load_entry_point
return get_distribution(dist).load_entry_point(group, name)
File ""/usr/local/lib/python2.7/site-packages/pkg_resources.py"", line 2470, in load_entry_point
return ep.load()
File ""/usr/local/lib/python2.7/site-packages/pkg_resources.py"", line 2184, in load
['name'])
File ""/usr/local/lib/python2.7/site-packages/pip/_internal/cli/main.py"", line 60
sys.stderr.write(f""ERROR: {exc}""){code}
 

[https://github.com/pypa/pip/issues/9500]
{code:java}
For users who are using python 2.7, this is a better solution:
https://bootstrap.pypa.io/2.7/get-pip.py
It supports pip20.3.4.
{code}
So there might be an issue with the version pip21 

 

2.) so the {color:#de350b}*second test*{color} were happening like that: 

* installing pip 20.3.4 and python36
{code:java}
pip install --upgrade pip==20.3.4
yum install python36{code}
* upgrading docker-compose 
{code:java}
pip install --upgrade docker-compose
{code}
and we are ending up with a version *1.26.2*

in case when i am using pip3 for upgrading docker-compose we are ending up with some dependencies between python2.7.5/python3.6. The most described fix in the net were not helping with upgrading setuptools 
{code:java}
Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-build-tnq4gdhg/cryptography/
{code}
 

 

 

 

 

 ","01/Apr/21 13:55;cs687;I guess the solution must be to remove old python2.7.5 version and deploy python3.6 
 or make it possible to run both versions. 

 

upgraded pip3 version to pip 21.0.1

and run the command 
{code:java}
pip3 install --upgrade docker-compose==1.28.6 
[root@ip-10-115-90-43 ~]# /usr/local/bin/docker-compose --version docker-compose version 1.28.6, build unknown{code}
#############################################

currently we have python2.7.5, and python34 running.. how we installed docker-compose, we did the following: 
 * install python36
 * upgraded pip to version 20.3.4
 * upgraded pip3 to 21.0.1
 * pip3 install --upgrade docker-compose==1.28.6","08/Apr/21 13:54;cs687;* Current Status after re-create: 

{code:java}
[root@ip-10-115-71-235 ~]# pip --version
pip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.7)
{code}
{code:java}
[root@ip-10-115-71-235 ~]# pip3 --version
pip 8.1.2 from /usr/lib/python3.4/site-packages (python 3.4)
{code}
{code:java}
lrwxrwxrwx. 1 root root 7 Apr 8 11:48 /usr/bin/python -> python2 
lrwxrwxrwx. 1 root root 9 Apr 8 11:48 /usr/bin/python2 -> python2.7


-rwxr-xr-x. 1 root root 7144 Nov 16 23:23 /usr/bin/python2.7 
-rwxr-xr-x. 1 root root 1835 Nov 16 23:23 /usr/bin/python2.7-config 
lrwxrwxrwx. 1 root root 16 Apr 8 11:48 /usr/bin/python2-config -> python2.7-config 
lrwxrwxrwx. 1 root root 9 Mar 27 2019 /usr/bin/python3 -> python3.4 -rwxr-xr-x. 2 root root 11392 Feb 5 2019 /usr/bin/python3.4 
-rwxr-xr-x. 2 root root 11392 Feb 5 2019 /usr/bin/python3.4m 
lrwxrwxrwx. 1 root root 14 Apr 8 11:48 /usr/bin/python-config -> python2-config
{code}
 * Required Steps to install *docker-compose 1.28.6

1.) yum upgrade python3

2.) install docker-compose [https://docs.docker.com/compose/install/]
{code:java}
curl L ""https://github.com/docker/compose/releases/download/1.28.6/docker-compose$(uname s)$(uname -m)"" -o /usr/local/bin/docker-compose
{code}
3.) chmod +x /usr/local/bin/docker-compose

4.) ln -s /usr/local/bin/docker-compose /bin/docker-compose 

 

[~ax460] is testing it on auto1 
{code:java}
[root@ip-10-115-71-235 ~]# /bin/docker-compose --version
docker-compose version 1.28.6, build 5db8d86f
{code}","09/Apr/21 10:44;cs687;pull-request for the proper changes:
 [https://github.deutsche-boerse.de/dev/energy.docker.hosts/commit/c98cc0ece80af349316f9487bf19698c4104542c]
 Tested it with recreate job on:

 ","15/Apr/21 11:25;cs687;done",,,,,,,,,,,,,,,,,,,,,,
Explore possibility of providing site24x7 status page for our customers,M7P-8057,108360,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,dp007,lw641,lw641,25/Mar/21 12:43,08/Sep/21 15:18,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"site24x7 comes with a status page feature where we can list upcoming maintenances, history of incidents and, of course, current service status as it seen from public internet. having such feature might be interesting for some of our customers (i.e. EPEX) as (additional) service?",,dp007,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15033600,,,dm700,lw641,ox626,rehapav,sw455,,,,XP-4785,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzkfb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108360,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/21 13:15;dp007;TODOs (for now):
 # organize a meeting for ACM + Kombi + Peter
 # find a way how to bundle a status page directly into Customer Portal using site24x7's REST API (StatusIQ).

Billing tiers: [https://www.site24x7.com/help/statuspage/admin/statusiq-subscription.html#:~:text=StatusIQ%20offers%20a%20subscription%20model,Green%2C%20Basic%2C%20and%20Free]",,,,,,,,,,,,,,,,,,,,,,,,,,,
Check if product monitors are correct - M7,M7P-8055,108357,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Not a Bug,wn626,lw641,lw641,25/Mar/21 12:40,25/May/21 23:40,16/Sep/21 14:11,29/Mar/21 12:28,,7tops_sprint114,,,,site24x7,,,,M7PRODOPS,,,,,,,Please check both for M7T and M7C.,,lw641,wn626,,,,,,,";29/Mar/21 12:28;wn626;1680",,0,1680,,,0,1680,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14774400,,,dm700,lw641,ox626,rehapav,sw455,,,,XP-4785,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzkfj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108357,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Mar/21 12:27;wn626;All links are correct:

https://prod1.epex.m7.deutsche-boerse.com:60040/ https://portal.m7.epexspot.com/https://prod1.epex.m7.deutsche-boerse.com:60040/ https://portal.m7.epexspot.com/https://prod2.epex.m7.deutsche-boerse.com:60040/ https://portal.m7.energy/semo/ https://prod1.tge.m7.deutsche-boerse.com:60020/ https://portal.m7.energy/plpx/https://prod2.tge.m7.deutsche-boerse.com:60020/ https://prod1.opcom.m7.deutsche-boerse.com:60080/ https://portal.m7.energy/xrpm/https://prod2.opcom.m7.deutsche-boerse.com:60080/ 
https://prod1.ics.m7c.deutsche-boerse.com/ https://prod2.ics.m7c.deutsche-boerse.com/ https://prod1.xsop.m7.deutsche-boerse.com:60050/ https://portal.m7.energy/xsop/https://prod2.xsop.m7.deutsche-boerse.com:60050/ https://prod1.hupx.m7.deutsche-boerse.com:60030/ https://portal.m7.energy/hupx/https://prod2.hupx.m7.deutsche-boerse.com:60030/",,,,,,,,,,,,,,,,,,,,,,,,,,,
TEST stage for ELK/TICK Monitoring stack,M7P-8036,108271,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,jv861,jv861,23/Mar/21 17:06,08/Sep/21 15:18,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"For development of tick scripts (and probably also for other purposes) it would be useful to have some test environment with Influx/Kapacitor instance.

Proposed requirements (open to discussion):
* Accessible by both techops and developers
* Having some reasonable data in influx for testing or/and option to easily ""connect"" it to some existing M7 instance (probably internal test) or option to copy some subset of data from current Influx db",,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15206400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzkfr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108271,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create Slack alerts for newly added MTT metrics,M7P-8035,108269,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,ef759,ef759,23/Mar/21 16:48,19/May/21 11:28,16/Sep/21 14:11,10/May/21 12:21,,6.12.18,7tops_sprint117,,,Monitoring,,,,M7PRODOPS,,,,,,,"Create a slack channel alerts triggered by the value change of newly added MTT statsd metrics.

Newly added metrics:
# limit.processing.timeout
# ems.processing.timeout
# settlement.processing.timeout

Alerts should be warnings (not trigger calls to BizOps) and alert should be sent after each increment (+1) of particular metric value.

The alerts are sufficient in Production for clients that use Cash limit functionality of MTT (currently EPEX and HUPX).

This JIRA follows on https://jira.deutsche-boerse.com/browse/M7P-7763

Monitoring threshold value should be set to 0. Value 0 means no timeout occurred. Every value higher than 0 displays number of timeout occurrences for specific metric. ",,cs687,ef759,nn236,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-7763,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"ticket can be closed, all 3 alerts are tested and sending slack messages in ""m7_alerts""
It was proper tested with ate4 Env. ",,,,,,,,,,,,,,,,,,,,,,,,11145600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-2800,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjmn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,,,,,,,,,,,,,,,,,,,,,,,,"example how it was solved with the alert settlement.processing.timeout
https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1271
all other timeouts were implemented in the same way. ",,,,,,,,,,"{""issueId"":108269,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/21 16:06;cs687;Hey [~ef759], 

for the later implementation we will create 3 subtickets.

To start working on the ticket we need to new things like 
* monitoring threshold for each checks 
* time period etc..



could you please provide us this info, then we can work on it by tomorrow. thanks","07/Apr/21 17:04;ef759;Monitoring threshold value should be set to 0. Value 0 means no timeout occurred. Every value higher than 0 displays number of timeout occurrences for specific metric. ","19/Apr/21 13:19;cs687;Thanks [~ef759] for that, one additional question would be: 
{code:java}
Monitoring threshold value should be set to 0. Value 0 means no timeout occurred. Every value higher than 0 displays number of timeout occurrences for specific metric.
{code}

That means after each triggered alert, the threshold must be back to ""0"" as default again? 

Or is there something like a counter necessary, all starting with 0 and ones it is increasing to a higher value than the previous was, we have to trigger an alert? ","19/Apr/21 14:20;ef759;The second variant is correct. Metric start with value 0 and every increment will increase the value +1. So after three timeout occurrences the metric value will be 3. And I would like to trigger an alert after each value increment of the metric. ","21/Apr/21 13:02;cs687;FYI: [~iu252]
example for *limit.processing.timeout*
https://grafana.energy.svc.dbgcloud.io/d/xh0G4vBiz/mtt?orgId=2&refresh=5s&var-host=All&var-client=shrd&var-client_env=ate4&var-group=All&var-interval=$__auto_interval_interval&from=now-30d&to=now

... ems.processing.timeout
https://grafana.energy.svc.dbgcloud.io/d/xh0G4vBiz/mtt?orgId=2&refresh=5s&var-host=All&var-client=shrd&var-client_env=ate4&var-group=All&var-interval=$__auto_interval_interval&from=now-30d&to=now

","23/Apr/21 12:40;cs687;pull-request for the first check 
timeout_processing_timeout: https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1256/files

needs to be approved by [~iu252][~hw120]and proper tested. 

Final State of ""*mtt_limit_processing_timeout"" is in-place:
https://github.deutsche-boerse.de/dev/energy.monitoring/blob/master/ansible/roles/kapacitor-alerts/templates/tasks/mtt_limit_processing_timeout_alert.tick

{code:java}
kapacitorAPP  9:05 AM
WARNING on m7tenrgate4m7b1 | MTT Limit Processing Timeout: 4
{code}

UPDATE: 05.05.21 
In the meeting we agreed that the current setup is not giving us the proper result what Dev´s want to see. Here an example of a time series:

3,3,3,3,3 in this case 3 > 3 => *alert will be not triggered, as long time series stays with the same value*

3,3,3,3,3,4,4 in this case 4 > 3 => alert will be triggered *but* ones the time series is back to same value after couple of minutes like ""4,4,4,4,4"" then we will get OK message back, which should not be happening. So the plan is like to reset the state , that the alert will be still triggered. We should also test how the alerting behaves ones we are stopping the application or restarting telegraf.  
","06/May/21 13:46;cs687;Final version for *mtt_limit_processing_timeout_alert*

was proper tested, the rest will be implemented on monday. 
https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1260/files","10/May/21 08:33;cs687;Final version for mtt_ems_processing_timeout_alert
https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1261/files","10/May/21 12:09;cs687;Final version for mtt_settlement_processing_timeout_alert
https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1271

all tested ticket can be closed!","10/May/21 12:21;cs687;done",,,,,,,,,,,,,,,,,,
Allow developers to prepare and test TICK scripts - short term measure,M7P-8034,108268,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,jv861,jv861,23/Mar/21 16:44,08/Sep/21 15:14,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"Currently there is no way to for developers to test TICK scripts on some environment. As a short term solution, selected developers should get some basic explanation from Techops about the current Kapacitor setup in Energy and how to test scripts there without disturbing existing services.

In a long term, there should be test environment with Kapacitor ready.

Developers that applied for getting the basic training and access to Kapacitor:
[~fp407]
[~jv861]",,jv861,,,,,,,,,,,,,,,,,M7P-7653,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15206400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzki7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108268,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
include M7C details in Energy environment Overview,M7P-8032,108262,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,pd122,pd122,pd122,23/Mar/21 14:56,23/Mar/21 17:12,16/Sep/21 14:11,,,,,,,,,,,7tops,M7C,,,,,,update scripts in energy.deployment.versions repo to list M7C details (in addition to existing M7T and XB reports) at https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions,,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15206400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzzkdb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108262,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-8032,,true,"23/Mar/21 17:12;pd122;M7C components included in daily report:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1460",,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup transfer of Stalker's messages logs to EBSM,M7P-8031,108245,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,nn481,nn481,23/Mar/21 10:32,19/May/21 11:28,16/Sep/21 14:11,18/May/21 07:45,,6.12.30,7tops_sprint117,,,EBSM,,,,7tops,,,,,,,"Ensure that Stalker's message logs are tranfered to EBSM and deleted from rollover directory. (Note: they might be potentionally large, hunderds of MBs, it can create a pressure on EBSM).

Logs should be also deleted from Stalker's host (after transfer) to not bloat it. Deletion is done by Stalker itself in rollover dir.

Current location: 
{noformat}
/{{ basedir_path }}/messages-logs/{{ instance_name }}/rollover{noformat}
Location on SYT1: 
{noformat}
/shrd/messages-logs/shrd-syt1-stk1/rollover{noformat}
 

Keep in mind that location could change: https://jira.deutsche-boerse.com/browse/M7P-7782

 

When done disable deletion policy in Stalker's config: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/b0d798f66d21cd80cd9f1f7bd563a3e9b4e8b931/roles/stalker/templates/log4j2.xml.j2#L35]",,cs687,dp007,iu252,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"all necessary scripts were deployed with ansible on the stalker hosts 
double checked on new ebms host if the logs are visible ",,,,,,,,,,,,,,,,,,,,,,,,10454400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjm7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,,,,,,,,,,,,,,,,,,,,,,,,more details in comments,,,,,,,,,,"{""issueId"":108245,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/21 15:12;dp007;[~nn481] please give me few log filename examples, I see:
{code:java}
<Property name=""SYSTEM_FAMILY"" value=""{\{ ENERGY_AREA }}_\{{ customer }}_\{{ env }}_\{{ hosttype }}-\{{ INSTANCENUM }}""/>
...
<RollingFile name=""file"" fileName=""{{ log_location }}/${SYSTEM_FAMILY}_standard_{{ LOCATION }}.log""
                     filePattern=""{{ log_location }}/rollover/${SYSTEM_FAMILY}_standard_{{ LOCATION }}_%i{}_%d{yyyy-MM-dd}.log.gz"">
{code}
Especially, what will be the hosttype?","14/May/21 07:59;iu252;Requested NFS share for m7tshrdintestk1 (similar to m7tshrdinterep1): 

{noformat}
m7testdata1.deutsche-boerse.de:/        973M  1.2M  972M   1% /net/m7testdata1.deutsche-boerse.de
m7testdata1.deutsche-boerse.de:/m7-tmp  100G   91M  100G   1% /net/m7testdata1.deutsche-boerse.de/m7-tmp
{noformat}
","17/May/21 18:34;iu252;Deployed logstoebsm for SYT1:

{noformat}
[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$  ansible-playbook playbooks/deploy_logstoebsm.yml --limit ""m7t*-shrd-syt1-stk1"" -k -K -b
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy logstoebsm on application instances] ********************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : get user home directory] **************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : debug output] *************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : get user home directory] **************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : set home] *****************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : debug] ********************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1] => {}

MSG:

my network address: 10.139.117.238


TASK [logstoebsm : debug] ********************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1] => {
    ""network_hosts"": {
        ""10.136.152.0/28"": ""xbsimtdata3.deutsche-boerse.de"",
        ""10.136.152.16/28"": ""xbsimudata3.deutsche-boerse.de"",
        ""10.136.24.0/28"": ""xbsimtdata2.deutsche-boerse.de"",
        ""10.136.24.16/28"": ""xbsimudata2.deutsche-boerse.de"",
        ""10.139.117.0/24"": ""m7testdata1.deutsche-boerse.de"",
        ""10.139.40.0/23"": ""xbsimtdata1.deutsche-boerse.de"",
        ""10.139.42.0/23"": ""xbsimudata1.deutsche-boerse.de"",
        ""10.139.52.0/23"": ""m7proddata1.deutsche-boerse.de"",
        ""10.139.56.0/22"": ""m7simudata1.deutsche-boerse.de"",
        ""127.0.0.0/24"": ""localhost""
    }
}

TASK [logstoebsm : testing network] **********************************************************************************************************************************************************************
skipping: [m7t-shrd-syt1-stk1] => (item=127.0.0.0/24)
skipping: [m7t-shrd-syt1-stk1] => (item=10.139.42.0/23)
skipping: [m7t-shrd-syt1-stk1] => (item=10.136.24.16/28)
skipping: [m7t-shrd-syt1-stk1] => (item=10.136.152.16/28)
skipping: [m7t-shrd-syt1-stk1] => (item=10.139.40.0/23)
skipping: [m7t-shrd-syt1-stk1] => (item=10.136.24.0/28)
skipping: [m7t-shrd-syt1-stk1] => (item=10.136.152.0/28)
skipping: [m7t-shrd-syt1-stk1] => (item=10.139.56.0/22)
ok: [m7t-shrd-syt1-stk1] => (item=10.139.117.0/24)
skipping: [m7t-shrd-syt1-stk1] => (item=10.139.52.0/23)

TASK [logstoebsm : create prodscripts directory] *********************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : create transfer script] ***************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : Get a pseudo-random minute] ***********************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

TASK [logstoebsm : create cronjob] ***********************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-stk1]

PLAY [Deploy logstoebsm on rabbitmq instances] ***********************************************************************************************************************************************************
skipping: no hosts matched

PLAY [Deploy logstoebsm on apache instances] *************************************************************************************************************************************************************
skipping: no hosts matched

PLAY [Deploy logstoebsm on haproxy instances] ************************************************************************************************************************************************************
skipping: no hosts matched

PLAY RECAP ***********************************************************************************************************************************************************************************************
m7t-shrd-syt1-stk1         : ok=12   changed=0    unreachable=0    failed=0

[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$
{noformat}
","17/May/21 18:35;iu252;Crontab check on host:

{noformat}
[tomcat@m7tshrdintestk1 ~]$ crontab -l
#Ansible: transfer_log_app
5 0,6,10,14,18 * * * /shrd/prodscripts/transfer_log.sh
#Ansible: Log Archiving
10 2 * * * /shrd/prodscripts/archive_logs.sh
[tomcat@m7tshrdintestk1 ~]$
{noformat}
","17/May/21 18:35;iu252;Test run of transfer script:

{noformat}
[tomcat@m7tshrdintestk1 ~]$ /shrd/prodscripts/transfer_log.sh
/shrd/logs/shrd-syt1-stk1/m7t_shrd_syt1_stalker-1_standard_ixe.log is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-16.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-16.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_2_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_2_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-16.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-16.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_1_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_1_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_3_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_3_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_4_2021-05-17.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_4_2021-05-17.log.gz.sent touched
/shrd/logs/shrd-syt1-stk1/rollover/m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-16.log.gz is successfully transferred
/shrd/logs/shrd-syt1-stk1/rollover/transferred/m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-16.log.gz.sent touched
[tomcat@m7tshrdintestk1 ~]$
{noformat}
","17/May/21 18:39;iu252;Check on testdpu:

{noformat}
/net/testdata1.srv.energy/m7-logs/2currentDay/syt1/m7t_shrd
[logmover@testdpu m7t_shrd]$ ll *stalker*
-rw-r--r-- 1 logmover logmover 52428910 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_1_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428813 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_2_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428954 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_3_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428961 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_4_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428903 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428883 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-17.log
-rw-r--r-- 1 logmover logmover 52428818 May 17 16:36 m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-17.log
-rw-r--r-- 1 logmover logmover 41293277 May 17 16:31 m7t_shrd_syt1_stalker-1_standard_ixe.log
[logmover@testdpu m7t_shrd]$



[logmover@testdpu m7-logs]$ cd 3unarchivedLogs/syt1/m7t_shrd/
[logmover@testdpu m7t_shrd]$ ll
total 364
drwxr-xr-x 2 logmover logmover 49152 May 11 06:53 2021-05-10
drwxr-xr-x 2 logmover logmover 49152 May 13 06:23 2021-05-11
drwxr-xr-x 2 logmover logmover 49152 May 17 06:18 2021-05-12
drwxr-xr-x 2 logmover logmover 49152 May 15 14:53 2021-05-13
drwxr-xr-x 2 logmover logmover 49152 May 15 06:53 2021-05-14
drwxr-xr-x 2 logmover logmover 49152 May 16 14:53 2021-05-15
drwxr-xr-x 2 logmover logmover 49152 May 17 18:38 2021-05-16
[logmover@testdpu m7t_shrd]$ ll */*stalker*
-rw-r--r-- 1 logmover logmover 52428913 May 17 16:36 2021-05-16/m7t_shrd_syt1_stalker-1_standard_ixe_5_2021-05-16.log
-rw-r--r-- 1 logmover logmover 52428948 May 17 16:36 2021-05-16/m7t_shrd_syt1_stalker-1_standard_ixe_6_2021-05-16.log
-rw-r--r-- 1 logmover logmover 39388265 May 17 16:36 2021-05-16/m7t_shrd_syt1_stalker-1_standard_ixe_7_2021-05-16.log
[logmover@testdpu m7t_shrd]$
{noformat}
","18/May/21 07:45;cs687;done",,,,,,,,,,,,,,,,,,,,,
Upgrading pg_watch version,M7P-8028,108237,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,23/Mar/21 09:03,30/Jun/21 12:13,16/Sep/21 14:11,21/Jun/21 16:06,,6.12.80,7tops_sprint120,,,,,,,M7PRODOPS,,,,,,,"With the time we noticed that our pg_watch2 agent failed with the following error message 
{code:java}
Mar 19 07:16:09 xbprodpdb3 pg_watch2[36278]: github.com/lib/pq.(*conn).recv(0xc000672000, 0xc00012eca8, 0x0)
Mar 19 07:16:09 xbprodpdb3 pg_watch2[36278]: /home/rd476/go/src/github.com/lib/pq/conn.go:991 +0x7b fp=0xc00012ebb0 sp=0xc00012eb70 pc=0x739feb
Mar 19 07:16:09 xbprodpdb3 pg_watch2[36278]: github.com/lib/pq.(*conn).startup(0xc000672000, 0xc0001e85a0)
{code}

So far this happened for hosts *m7simupdb4* and for XBID it´s more unluckily, because therefore its happening in production with the host *xbprodpdb3*, which is escalating a call! 

Also, that looks like the pgwatch2 daemon was installed from source or via go get, maybe the reason for that might be, that during that time no packages were existing. 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/pg_watch2

Anyways, currently we are running version *pg_watch2_version: 1.4.5* and yesterday in a meeting with CYBERTEC (participants: [~zl246], [~iu252], [~nz893], Julian Markwort and myself) we decided to deploy on *m7testpdb1* the newest client 1.8.4 
*pgwatch2_v1.8.4-SNAPSHOT-04f06dd_linux_64-bit.rpm*

This client is also providing us some few more metrics in /etc/pgwatch2/metrics which might be helpful for other purposes 

here a short overview about it: 
{code:java}
drwxr-xr-x 19 root root 4096 Mar 22 12:09 00_helpers                           
drwxr-xr-x  3 root root   67 Mar 22 12:09 archiver                             
drwxr-xr-x  7 root root   85 Mar 22 12:09 backends                             
drwxr-xr-x  3 root root   42 Mar 22 12:09 backup_age_pgbackrest                
drwxr-xr-x  3 root root   42 Mar 22 12:09 backup_age_walg                      
drwxr-xr-x  4 root root   53 Mar 22 12:09 bgwriter                             
drwxr-xr-x  3 root root   42 Mar 22 12:09 blocking_locks                       
drwxr-xr-x  3 root root   67 Mar 22 12:09 buffercache_by_db                    
drwxr-xr-x  3 root root   67 Mar 22 12:09 buffercache_by_type                  
drwxr-xr-x  3 root root   34 Mar 22 12:09 change_events                        
drwxr-xr-x  3 root root   17 Mar 22 12:09 configuration_hashes                 
drwxr-xr-x  3 root root   67 Mar 22 12:09 cpu_load                             
drwxr-xr-x  3 root root   17 Mar 22 12:09 database_conflicts                   
drwxr-xr-x  3 root root   42 Mar 22 12:09 db_size                              
drwxr-xr-x  8 root root   95 Mar 22 12:09 db_stats                             
drwxr-xr-x  4 root root   77 Mar 22 12:09 db_stats_aurora                      
drwxr-xr-x  3 root root   17 Mar 22 12:09 index_hashes                         
drwxr-xr-x  5 root root   38 Mar 22 12:09 index_stats                          
drwxr-xr-x  3 root root   17 Mar 22 12:09 instance_up                          
drwxr-xr-x  6 root root   74 Mar 22 12:09 kpi                                  
drwxr-xr-x  3 root root   42 Mar 22 12:09 locks                                
drwxr-xr-x  3 root root   42 Mar 22 12:09 locks_mode                           
drwxr-xr-x  3 root root   41 Mar 22 12:09 logical_subscriptions                
drwxr-xr-x  3 root root   15 Mar 22 12:09 pgbouncer_stats                      
drwxr-xr-x  3 root root   17 Mar 22 12:09 pgpool_stats                         
-rw-rw-r--  1 root root 6063 Feb  8 15:06 preset-configs.yaml                  
drwxr-xr-x  3 root root   17 Mar 22 12:09 privilege_changes                    
drwxr-xr-x  3 root root   67 Mar 22 12:09 psutil_cpu                           
drwxr-xr-x  3 root root   67 Mar 22 12:09 psutil_disk                          
drwxr-xr-x  3 root root   42 Mar 22 12:09 psutil_disk_io_total                 
drwxr-xr-x  3 root root   67 Mar 22 12:09 psutil_mem                           
-rw-r--r--  1 root root  600 Sep 11  2019 README_metrics.md                    
drwxr-xr-x  3 root root   42 Mar 22 12:09 reco_add_index                       
drwxr-xr-x  3 root root   42 Mar 22 12:09 reco_add_index_ext_qualstats_2.0     
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_default_public_schema           
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_disabled_triggers               
drwxr-xr-x  4 root root   28 Mar 22 12:09 reco_drop_index                      
drwxr-xr-x  3 root root   17 Mar 22 12:09 recommendations                      
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_nested_views                    
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_partial_index_candidates        
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_sprocs_wo_search_path           
drwxr-xr-x  3 root root   17 Mar 22 12:09 reco_superusers                      
drwxr-xr-x  4 root root   77 Mar 22 12:09 replication                          
drwxr-xr-x  4 root root   77 Mar 22 12:09 replication_slots                    
drwxr-xr-x  3 root root   17 Mar 22 12:09 server_log_event_counts              
drwxr-xr-x  3 root root   17 Mar 22 12:09 settings                             
drwxr-xr-x  4 root root   27 Mar 22 12:09 show_plans_realtime                  
drwxr-xr-x  3 root root   17 Mar 22 12:09 smart_health_per_disk                
drwxr-xr-x  3 root root   17 Mar 22 12:09 sproc_hashes                         
drwxr-xr-x  3 root root   17 Mar 22 12:09 sproc_stats                          
drwxr-xr-x  6 root root   49 Mar 22 12:09 stat_activity_realtime               
drwxr-xr-x  3 root root   42 Mar 22 12:09 stat_ssl                             
drwxr-xr-x  5 root root   38 Mar 22 12:09 stat_statements                      
drwxr-xr-x  4 root root   27 Mar 22 12:09 stat_statements_calls                
drwxr-xr-x  5 root root   63 Mar 22 12:09 stat_statements_no_query_text        
drwxr-xr-x  3 root root   67 Mar 22 12:09 table_bloat_approx_stattuple         
drwxr-xr-x  4 root root   52 Mar 22 12:09 table_bloat_approx_summary           
drwxr-xr-x  4 root root   52 Mar 22 12:09 table_bloat_approx_summary_sql       
drwxr-xr-x  4 root root   28 Mar 22 12:09 table_hashes                         
drwxr-xr-x  4 root root   27 Mar 22 12:09 table_io_stats                       
drwxr-xr-x  6 root root   74 Mar 22 12:09 table_stats                          
-rwxrwxr-x  1 root root 8141 Jul 10  2020 test_all_metrics.py                  
drwxr-xr-x  3 root root   17 Mar 22 12:09 vmstat                               
drwxr-xr-x  4 root root   77 Mar 22 12:09 wal                                  
drwxr-xr-x  4 root root   77 Mar 22 12:09 wal_receiver                         
drwxr-xr-x  4 root root   77 Mar 22 12:09 wal_size                            
{code}

What we did: 
* stopped old pg_watch2 daemon on m7testpdb1
* installed the new rpm-package 
** rpm -i pgwatch2_v1.8.4-SNAPSHOT-04f06dd_linux_64-bit.rpm
* some required changes in the new pgwatch2 service file ""/etc/systemd/system/pgwatch2.service""
** Description = pgwatch2
** PIDFile = /run/pgwatch2/pgwatch2.pid
** ExecStartPre = /bin/mkdir /run/pgwatch2
** ExecStart = /bin/pgwatch2-daemon  -c /etc/pg_watch2/pg_watch2.d -m /opt/pg_watch2/metrics/ --issl=true --ihost=influxdb.energy.svc.dbgcloud.io --iport=443 --iretentionname=autogen --idbname=metrics_m7_shared --conn-pooling=off
** ExecStopPost = /bin/rm -rf /run/pgwatch2
* also the same happened for the config files in /etc/pg_watch2/pg_watch2.d/...
**  dbtype: postgres-continuous-discovery

*+The Idea is now+*, that we analyze with DEV the behavior of the new deployed pg_watch2 instance on m7testpdb1 database instance. Comparing the collected metrics in chronograf, if they are useful how they are collected there. 
And besides that we can think about to onboard new metrics/dashboard´s which are provided with the newer version. 

Ones we came to a conclusion, we should prepare the mentioned playbook above and deploy the changes on all db-hosts. 
",,cs687,zl246,zv517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8506,M7P-8505,SYSENGINT-787,XP-5030,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1640/files
upgraded the ansible role and installed pgwatch with version 1.8.4 
",,,,,,,,,,,,,,,,,,,,,,,,7430400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjlj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,,,,,,,,,,,,,,,,,,,,"* stopped the old instance
* prepared the ansible changes https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1640/files
* removed old dir´s which are not used anymore
* double checked status of pgwatch and metrics in chronograf",,,,,,,,,,"{""issueId"":108237,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"10/May/21 09:33;cs687;Announced it in the team meeting 06/05/21 and asked XBID/Capacity and Auction team to test the new agent 
with the proper config changes. Ones all of us are fine we change the current ansible role and can deploy it everywhere.  ","16/Jun/21 14:09;zl246;Tested changed on xbtestpdb2 and worked fine. (/) from XBID to integrate the new version into the ansible role","21/Jun/21 14:08;cs687;requested to add the pgwatch rpm-package to RH Satellite 
{code:java}
pgwatch2.x86_64 : pgwatch2 metrics collector with metric definitions and sample YAML config

  Name and summary matches only, use ""search all"" for everything.
Uploading Enabled Repositories Report
Loaded plugins: langpacks, product-id, subscription-manager
[root@m7testpdb1 ~]# yum info pgwatch2.x86_64
Loaded plugins: enabled_repos_upload, langpacks, package_upload, product-id, search-disabled-repos, subscription-
              : manager
Installed Packages
Name        : pgwatch2
Arch        : x86_64
Version     : 1.8.4
Release     : 0.1.SNAPSHOT-04f06dd
Size        : 21 M
Repo        : installed
Summary     : pgwatch2 metrics collector with metric definitions and sample YAML config
URL         : https://github.com/cybertec-postgresql/pgwatch2
License     : BSD 3-Clause License
Description : pgwatch2 metrics collector with metric definitions and sample YAML config
{code}

deployed it for m7testpdb1/2 and dbr´s and confirmed the deployed with metrics in chronograf (/) 
for that we are closing this ticket and creating freshly new one for SIMU & PROD staging. 

proper pull-request prepared and merged: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1640/files
","21/Jun/21 15:43;cs687;+*for the cleanup I removed the old non-used files:*+
{color:#DE350B}before the deployment i stopped the old running pg_watch2{color}
* /etc/systemd/system/pg_watch2.service
* /etc/pg_watch2/
* /opt/pg_watch2/
* /etc/init.d/pg_watch2

new dirs are 
* /etc/pgwatch2/.... metrics|pgwatch2.d","21/Jun/21 16:06;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
Password policy lock is not working,M7P-8025,108232,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,pd122,vp223,vp223,22/Mar/21 17:48,26/May/21 12:37,16/Sep/21 14:11,04/May/21 16:33,,7tops_sprint116,,,,LDAP,M7T BE,,,7tops_comm,L,,,,,,"Tested on ATE2 version 6.11.132

*Scenario:*
# M7ADM001 is login in Web GUI
# The attacker tries to find out the pwd and starts his brute force script on this user
# After a couple of tries (e.g. 8 ) (s)he success
# The lock is not applied probably because of point 1
# Normally should the account be locked after 5 attempts

CT is locked.

Expected outcome:
M7ADM001 stays logged but the account is locked",,pd122,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8030,M7P-7871,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11577600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,22/Mar/21 17:48,,[],,,,,,,,None,,,M7T,,,,"2|hzzoxj:",9223372036854775807,,,,No,,,,,,,,,,Reported behavior is a consequence of employed application authentication design/method.  Application authentication would need to be redesigned to fix (ie.  _basic auth_ needs to go).,,,,,,,,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108232,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/21 15:07;pd122;Successful login attempt:

{code:java}
[26/Mar/2021:11:39:32.133912318 +0100] conn=132797 fd=66 slot=66 SSL connection from 10.136.162.252 to 10.139.117.206
[26/Mar/2021:11:39:32.137055997 +0100] conn=132797 TLS1.2 256-bit AES
[26/Mar/2021:11:39:32.137392741 +0100] conn=132797 op=0 BIND dn="""" method=128 version=3
[26/Mar/2021:11:39:32.137444112 +0100] conn=132797 op=0 RESULT err=0 tag=97 nentries=0 etime=0.003463904 dn=""""
[26/Mar/2021:11:39:32.137810695 +0100] conn=132797 op=1 SRCH base=""ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" scope=2 filter=""(&(objectClass=*)(uid=M7ADM003))"" attrs=""uid""
[26/Mar/2021:11:39:32.138155197 +0100] conn=132797 op=1 RESULT err=0 tag=101 nentries=1 etime=0.000407216 notes=U
[26/Mar/2021:11:39:32.138583980 +0100] conn=132797 op=2 BIND dn=""uid=M7ADM003,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" method=128 version=3
[26/Mar/2021:11:39:32.139137880 +0100] conn=132797 op=2 RESULT err=0 tag=97 nentries=0 etime=0.000626869 dn=""uid=m7adm003,ou=ate2,ou=shrd-apa,o=m7,dc=energy,dc=test""
[26/Mar/2021:11:44:32.699479821 +0100] conn=132797 op=-1 fd=66 closed error 11 (Resource temporarily unavailable) - T1
{code}
","26/Mar/21 15:09;pd122;5th unsuccessful attempt in a row (resulting in locked out account):

{code:java}
[26/Mar/2021:11:47:19.576750483 +0100] conn=132835 fd=81 slot=81 SSL connection from 10.136.162.252 to 10.139.117.206
[26/Mar/2021:11:47:19.579501325 +0100] conn=132835 TLS1.2 256-bit AES
[26/Mar/2021:11:47:19.580507737 +0100] conn=132835 op=0 BIND dn="""" method=128 version=3
[26/Mar/2021:11:47:19.580544276 +0100] conn=132835 op=0 RESULT err=0 tag=97 nentries=0 etime=0.003693765 dn=""""
[26/Mar/2021:11:47:19.581036325 +0100] conn=132835 op=1 SRCH base=""ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" scope=2 filter=""(&(objectClass=*)(uid=M7ADM003))"" attrs=""uid""
[26/Mar/2021:11:47:19.581250613 +0100] conn=132835 op=1 RESULT err=0 tag=101 nentries=1 etime=0.000273036 notes=U
[26/Mar/2021:11:47:19.581793319 +0100] conn=132835 op=2 BIND dn=""uid=M7ADM003,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" method=128 version=3
[26/Mar/2021:11:47:19.592224007 +0100] conn=132835 op=2 RESULT err=49 tag=97 nentries=0 etime=0.010469521 - Invalid credentials
[26/Mar/2021:11:47:19.592749694 +0100] conn=132835 op=3 UNBIND
[26/Mar/2021:11:47:19.592757809 +0100] conn=132835 op=3 fd=81 closed - U1

time: 20210326114719
dn: uid=M7ADM003,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
result: 0
changetype: modify
replace: passwordRetryCount
passwordRetryCount: 5
-
replace: accountUnlockTime
accountUnlockTime: 19700101000000Z
{code}
","26/Mar/21 15:11;pd122;Permanently locked out:

{code:java}
dn: uid=M7ADM003,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordRetryCount: 5
accountUnlockTime: 19700101000000Z
retryCountResetTime: 20210326105701Z
passwordGraceUserTime: 0
modifyTimestamp: 20210326103821Z
pwdPolicySubEntry: cn=cn\3DnsPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}
","26/Mar/21 15:12;pd122;Authentication attempt (with correct credentials)  resulting in successful login after the account has been locked out permanently:

{code:java}
[26/Mar/2021:11:47:23.614796532 +0100] conn=132836 fd=81 slot=81 SSL connection from 10.136.162.252 to 10.139.117.206
[26/Mar/2021:11:47:23.617427950 +0100] conn=132836 TLS1.2 256-bit AES
[26/Mar/2021:11:47:23.617751745 +0100] conn=132836 op=0 BIND dn="""" method=128 version=3
[26/Mar/2021:11:47:23.617788284 +0100] conn=132836 op=0 RESULT err=0 tag=97 nentries=0 etime=0.002939245 dn=""""
[26/Mar/2021:11:47:23.618165840 +0100] conn=132836 op=1 SRCH base=""ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" scope=2 filter=""(&(objectClass=*)(uid=M7ADM003))"" attrs=""uid""
[26/Mar/2021:11:47:23.618392811 +0100] conn=132836 op=1 RESULT err=0 tag=101 nentries=1 etime=0.000285510 notes=U
[26/Mar/2021:11:47:23.618792082 +0100] conn=132836 op=2 BIND dn=""uid=M7ADM003,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"" method=128 version=3
[26/Mar/2021:11:47:23.619245810 +0100] conn=132836 op=2 RESULT err=19 tag=97 nentries=0 etime=0.000526687
[26/Mar/2021:11:47:23.619786745 +0100] conn=132836 op=3 UNBIND
[26/Mar/2021:11:47:23.619794477 +0100] conn=132836 op=3 fd=81 closed - U1
{code}
","26/Mar/21 15:17;pd122;LDAP return codes:
- 1st (successful) login attempt : *err=0 -> LDAP_SUCCESS*
- unsuccessful login with invalid credentials: *err=49 -> LDAP_INVALID_CREDENTIALS* 
- (successful) login attempt after the account has been locked out: *err=19 -> LDAP_CONSTRAINT_VIOLATION*","26/Mar/21 15:31;pd122;Relevant part of Apache (web server) config:

{code:java}
AuthType                     Basic
BasicProvider               ldap
AuthName                   ""ATE2 SHRD""
AuthLDAPUrl                ""ldaps://m7shrdtestldp1:636 m7shrdtestldp2:636/ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test?uid""
Require                         valid-user
{code}
","26/Mar/21 15:33;pd122;It would appear that Apache's *mod_authnz_ldap* allows the authentication to pass given the user does exist and the credentials supplied are valid.","30/Apr/21 10:03;pd122;Case #02930377 opened with RedHat support.","04/May/21 16:24;pd122;The reason behind this observed behavior is that successful authentication result is cached and thus the user is very likely to be granted access after providing *correct* credentials *while* another parallel session is ongoing (or has just recently finished) even though the account is already locked out in LDAP. 
If the cache is disabled (or cache TTL reduced to just a couple of seconds), each request within a parallel session will result in LDAP access request which will reset LDAP's *passwordRetryCount*, in effect preventing the user from being ever locked out. 

To fix properly , access control would need to be redesigned for the app.",,,,,,,,,,,,,,,,,,,
upgrade PostreSQL to 12 on Confluence,M7P-8015,108167,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,pd122,pd122,19/Mar/21 17:21,22/Mar/21 08:55,16/Sep/21 14:11,,,,,,,Database,,,14/Jan/22 00:00,7tops,AWS,Confluence,Postgresql,,,,"Hi,

Amazon RDS for PostgreSQL 9.6 will reach EOL on January 18, 2022. You have database instances that are impacted by this in the Service Zone account:

Energy-confluence

Please upgrade the RDS instance to major version 12 or greater before that.
If you do not upgrade the database before it reaches EOL, RDS will upgrade your PostgreSQL 9.6 to 12 during a scheduled maintenance window between January 18, 2022 00:00:01 UTC and February 22 00:00:01 UTC.

Some documentation from AWS to help with the migration:
[1] Upgrading a DB instance engine version - Amazon Relational Database Service
[2] PostgreSQL 12.0 Now Available in Amazon RDS Database Preview Environment
[3] PostgreSQL 13 Beta 1 Now Available in Amazon RDS Database Preview Environment

Please reach out to me if you have any questions or need support.

Thank you

Best,
Mahak Patil
",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15552000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzjvr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":108167,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make sure the kafka setup-application-entities jenkins job is able to delete entities,M7P-8009,108143,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fp407,fp407,19/Mar/21 14:51,07/Apr/21 12:31,16/Sep/21 14:11,25/Mar/21 15:52,,6.11.223,7tops_sprint114,,,Reporter,,,,M7PRODOPS,S,,,,,,"Currently 

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Kafka/job/setup-application-entities/build?delay=0sec

Uses --add and thus is able only to add or modify existing properties to entities.

Make it possible to delete entities on demant.",,cs687,fp407,nz893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"necessary changes are listed here 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1477",,,,,,,,,,,,,,,,,,,,,,,,15033600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjkf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,see pull-request,,,,,,,,,,"{""issueId"":108143,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Mar/21 14:30;cs687;Prepared a pull-Request (branch M7P-8009) 
gonna to test it tomorrow in *syt2*

{code:java}
[cs687@enprodauto1 {M7P-8009 L | ✔} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/remove_kafka_credentials.yml -l m7t-shrd-ate3-kafka-* -e av_product=m7t -e av_customer=shrd -e av_env=ate3 -e credentials_location_role=m7tkafka -k -K -b -C
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Remove Kafka Credentials] ***********************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ********************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate3-kafka-zookeeper-1]
ok: [m7t-shrd-ate3-kafka-zookeeper-2]
ok: [m7t-shrd-ate3-kafka-zookeeper-3]

TASK [Check required variables] ***********************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=av_product)
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=av_customer)
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=av_env)
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=credentials_location_role)

TASK [Display input parameters] ***********************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate3-kafka-zookeeper-1] => {}

MSG:

Setting up with parameters:
    Zookeeper: m7tshrdintekzk1:2181
    Application Vector: product=m7t, customer=shrd, environment=ate3
    credentials location role=m7tkafka


TASK [m7tkafka : set fact workaround] *****************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate3-kafka-zookeeper-1]

TASK [Remove ACLs] ************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'access': 'producer', 'user': 'm7core', 'topic': 'm7-core-events', 'idempotent': True})
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'access': 'consumer', 'user': 'm7core', 'topic': 'm7-core-events'})
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'access': 'consumer', 'user': 'm7reporter', 'topic': 'm7-core-events'})
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'access': 'producer', 'user': 'm7reporter', 'topic': 'm7-reporter-config'})
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'access': 'consumer', 'user': 'm7reporter', 'topic': 'm7-reporter-config'})

TASK [Delete Users] ***********************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=m7core)
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item=m7reporter)

TASK [Delete Topics] **********************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'key': 'm7-core-events', 'value': {'replication_factor': 3, 'partitions': 1, 'config': 'cleanup.policy=delete, min.insync.replicas=2, retention.ms=604800000, segment.ms=604800000\n'}})
skipping: [m7t-shrd-ate3-kafka-zookeeper-1] => (item={'key': 'm7-reporter-config', 'value': {'replication_factor': 3, 'partitions': 1, 'config': 'cleanup.policy=compact, min.insync.replicas=2\n'}})

PLAY RECAP ********************************************************************************************************************************************************************************************************************************************************************
m7t-shrd-ate3-kafka-zookeeper-1 : ok=3    changed=0    unreachable=0    failed=0
m7t-shrd-ate3-kafka-zookeeper-2 : ok=1    changed=0    unreachable=0    failed=0
m7t-shrd-ate3-kafka-zookeeper-3 : ok=1    changed=0    unreachable=0    failed=0
{code}

For this purpose we will prepare a separate Jenkins file 
jenkins/kafka/Jenkinsfile_remove_application_entities
and a dedicated Jenkins job in https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Kafka/ ","24/Mar/21 15:04;cs687;*+Before we tested the playbook on SYT2+* the following 

acl-topics of SYT2 were existing: 
{code:java}
[root@m7tshrdintekzk1 ~]# zookeeper-shell localhost:2181 ls /kafka-acl/Topic
[.......topic_m7tshrdsyt2_m7-core-events, topic_m7tshrdsyt2_m7-reporter-config]
{code}

Users of SYT2 were existing:
{code:java}
[root@m7tshrdintekzk1 ~]# zookeeper-shell localhost:2181 ls /config/users
[...... user_m7tshrdsyt2_m7core, user_m7tshrdsyt2_m7reporter]
{code}

Topics of SYT2 were existing:
{code:java}
[root@m7tshrdintekzk1 ~]# zookeeper-shell localhost:2181 ls /config/topics
[.....topic_m7tshrdsyt2_m7-core-events, topic_m7tshrdsyt2_m7-reporter-config]
{code}

{color:red}*_After triggering the job the mentioned entities above are gone! _*{color}
* ACL 
* Topics ""kafka-topics --zookeeper m7tshrdintekzk1:2181 --delete --topic topic_m7tshrdsyt2_m7-core-events""
* remove user password 
* remove user","25/Mar/21 09:42;nz893;
{noformat}
[root@m7tshrdintekzk1 bin]# kafka-configs --zookeeper m7tshrdintekzk1:2181 --alter --delete-config 'SCRAM-SHA-256' --entity-type users --entity-name user_m7tshrdsyt2_m7reporter
Completed Updating config for entity: user-principal 'user_m7tshrdsyt2_m7reporter'.
root@m7tshrdintekzk1 bin]# zookeeper-shell localhost:2181 ls -R /config/users|grep m7tshrdsyt2
/config/users/user_m7tshrdsyt2_m7core
/config/users/user_m7tshrdsyt2_m7reporter
[root@m7tshrdintekzk1 bin]# zookeeper-shell localhost:2181 get /config/users/user_m7tshrdsyt2_m7reporter
Connecting to localhost:2181
WATCHER::
WatchedEvent state:SyncConnected type:None path:null
{""version"":1,""config"":{}}
[root@m7tshrdintekzk1 bin]#
{noformat}
","25/Mar/21 15:19;cs687;Prepared and tested this pull-request: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1477/files
","25/Mar/21 15:52;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
use correct web server name/alias when monitoring via telegraf,M7P-7996,108065,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pd122,pd122,18/Mar/21 10:26,22/Apr/21 06:54,16/Sep/21 14:11,06/Apr/21 09:04,,6.11.223,7tops_sprint114,,,Monitoring,,,,7tops,L,Monitoring,MONITORING,,,,"update to web server configuration broke the monitoring relying on accessing web servers via ""localhost"" URL (from the localhost)
 likely solution - telegraf configuration to be updated to allow for custom Host header (using destination's proper name or alias) in its http request query

Note: potential impact on XBID",,cs687,nz893,pd122,,,,,,,,,,,,,,,M7P-6576,,,,,,,,,,,M7P-8117,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Ticket can be closed, fix is provided in that pull-request 

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1484] 

Redeployment of apache instances are required. ",,,,,,,,,,,,,,,,,,,,,,,,14083200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjl3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":108065,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"26/Mar/21 13:14;nz893;We tried to change settings for m7t-shrd-ate2-app-web1.conf (port 60200) from 'localhost' to m7tshrdinteweb1, 10.136.162.252 or 127.0.0.1. In both cases we saw the error again:

When we used 127.0.0.1 we saw the error:


{noformat}
[root@m7tshrdinteweb1 telegraf.d]# systemctl status telegraf.service -l
● telegraf.service - The plugin-driven server agent for reporting metrics into InfluxDB
   Loaded: loaded (/usr/lib/systemd/system/telegraf.service; enabled; vendor preset: disabled)
   Active: active (running) since Fri 2021-03-26 13:09:52 CET; 56s ago
     Docs: https://github.com/influxdata/telegraf
 Main PID: 118410 (telegraf)
   CGroup: /system.slice/telegraf.service
           └─118410 /usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d

Mar 26 13:10:40 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:40Z E! [inputs.apache] Error in plugin: error on request to https://localhost:61700/server-status?auto : Get https://10.136.148.11:61700/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:45 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:45Z E! [inputs.apache] Error in plugin: error on request to http://localhost:62300/server-status?auto : Get http://10.136.148.16:62300/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:45 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:45Z E! [inputs.apache] Error in plugin: error on request to https://localhost:61800/server-status?auto : Get https://10.136.148.12:61800/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:45 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:45Z E! [inputs.apache] Error in plugin: error on request to https://localhost:60300/server-status?auto : Get https://10.136.148.35:60300/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:46 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:46Z E! [inputs.apache] Error in plugin: error on request to http://localhost:62900/server-status?auto : Get http://10.136.148.16:62900/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:46 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:46Z E! [inputs.apache] Error in plugin: error on request to http://localhost:62800/server-status?auto : Get http://10.136.148.16:62800/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:46 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:46Z E! [inputs.apache] Error in plugin: error on request to https://127.0.0.1:60200/server-status?auto : Get https://10.136.148.30:60200/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:47 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:47Z E! [inputs.apache] Error in plugin: error on request to http://localhost:62200/server-status?auto : Get http://10.136.20.16:62200/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:48 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:48Z E! [inputs.apache] Error in plugin: error on request to https://localhost:60400/server-status?auto : Get https://10.136.148.36:60400/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
Mar 26 13:10:48 m7tshrdinteweb1 telegraf[118410]: 2021-03-26T12:10:48Z E! [inputs.apache] Error in plugin: error on request to https://localhost:61700/server-status?auto : Get https://10.136.148.11:61700/server-status?auto: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
{noformat}
","26/Mar/21 13:52;nz893;No change helped. We tried to use http connection, but apache returned empty page. 

{noformat}
[root@m7tshrdinteweb1 telegraf.d]# curl https://m7tshrdinteweb1:60200/server-status?auto --insecure
<!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">
<html><head>
<title>301 Moved Permanently</title>
</head><body>
<h1>Moved Permanently</h1>
<p>The document has moved <a href=""https://10.136.148.30:60200/server-status?auto"">here</a>.</p>
</body></html>
{noformat}
","29/Mar/21 10:00;nz893;To summarize what we did. We changed configuration to every possible choice (eve to redirection address), but non of these changes made a progress. 


{noformat}
[nz893adm@m7tshrdinteweb1 ~]$ curl http://10.136.20.16:62200/server-status?auto -v
* About to connect() to 10.136.20.16 port 62200 (#0)
*   Trying 10.136.20.16...
^C
[nz893adm@m7tshrdinteweb1 ~]$ curl https://10.136.148.30:60200/server-status?auto --insecure -v
* About to connect() to 10.136.148.30 port 60200 (#0)
*   Trying 10.136.148.30...
^C
[nz893adm@m7tshrdinteweb1 ~]$ telnet 10.136.148.30 60200
Trying 10.136.148.30...
^C
{noformat}
","31/Mar/21 08:33;cs687;{code:java}
-H, --header LINE Custom header to pass to server (H)
 -i, --include Include protocol headers in the output (H/F)
 -L, --location Follow redirects (H){code}
all of them is not working
{code:java}
[root@m7tshrdinteweb1 ~]# curl -H ""Host = ate2.shrd.m7.deutsche-boerse.com"" 
 https://localhost:60200/server-status?auto
 --insecure
 <!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">
 <html><head>
 <title>301 Moved Permanently</title>
 </head><body>
 <h1>Moved Permanently</h1>
 <p>The document has moved <a href=""
 https://10.136.148.30:60200/server-status?auto
 "">here</a>.</p>
 </body></html>{code}
at least when i am checking for ""*301 Moved Permantly*"" I found in the internet that curl -H / or curl -Li should help out, what is not the case.
 also tried out this [https://httpd.apache.org/docs/2.4/howto/access.html]
{code:java}
<Location ""/server-status"">
 SetHandler server-status
 Require host localhost
 AuthType None
 </Location>{code}
to modify the service-status location with * Require ip ip.address

I have no idea anymore. Did you guys find something out?","31/Mar/21 11:43;nz893;I found a workaround (after we found out if curl is forced to stick with localhost the output works). The workaround is simply don't allow any redirection when connection use localhost:


{noformat}
-bash-4.2$ curl https://localhost:61800/server-status?auto --insecure -v
* About to connect() to localhost port 61800 (#0)
*   Trying 127.0.0.1...
* Connected to localhost (127.0.0.1) port 61800 (#0)
* Initializing NSS with certpath: sql:/etc/pki/nssdb
* skipping SSL peer certificate verification
* SSL connection using TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
* Server certificate:
*       subject: CN=syt2.xbid.m7.deutsche-boerse.com,OU=Multi-Domain SSL,OU=Hosted by Deutsche Borse Aktiengesellschaft,OU=Cash & Derivatives IT Operations,O=Deutsche Boerse AG,STREET=Mergenthalerallee 61,L=Eschborn,ST=Hessen,postalCode=65760,C=DE
*       start date: Jan 18 00:00:00 2019 GMT
*       expire date: Jan 17 23:59:59 2021 GMT
*       common name: syt2.xbid.m7.deutsche-boerse.com
*       issuer: CN=Sectigo RSA Organization Validation Secure Server CA,O=Sectigo Limited,L=Salford,ST=Greater Manchester,C=GB
> GET /server-status?auto HTTP/1.1
> User-Agent: curl/7.29.0
> Host: localhost:61800
> Accept: */*
>
< HTTP/1.1 200 OK
< Date: Wed, 31 Mar 2021 09:38:55 GMT
< Server: Apache
< Content-Length: 371
< Connection: close
< Content-Type: text/plain; charset=ISO-8859-1
<
Total Accesses: 0
Total kBytes: 0
Uptime: 4
ReqPerSec: 0
BytesPerSec: 0
BusyWorkers: 1
IdleWorkers: 4
Scoreboard: W____...........................................................................................................................................................................................................................................................
* Closing connection 0
{noformat}

add into /shrd/m7t-shrd-syt2-app-web1/config/conf.d: 
{noformat}
<VirtualHost *:61800>
  ServerName      localhost

  SSLEngine on
  SSLProtocol all -SSLv3 -TLSv1 -TLSv1.1
  SSLHonorCipherOrder on
  SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
  SSLCertificateFile /shrd/ssl/syt2.shrd.m7.deutsche-boerse.com_cert.pem
  SSLCertificateKeyFile /shrd/ssl/syt2.shrd.m7.deutsche-boerse.com_key.pem
  SSLCertificateChainFile /shrd/ssl/syt2.shrd.m7.deutsche-boerse.com_chain.pem

        <Location ""/server-status"">
                SetHandler server-status
                Require host localhost
                AuthType None
        </Location>


</VirtualHost>

{noformat}

","31/Mar/21 11:52;cs687;proper fix: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1484]
gonna test that on internal test apache hosts, starting DC by DC","31/Mar/21 15:46;pd122;proper fix would be to update monitoring to use the host's name (as suggested in the issue's title) - this seems to be an effort than no one is quite ready to undertake at the moment
instead a workaround has been proposed : setting up separate virtual host just for monitoring purposes - https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1484","31/Mar/21 15:48;pd122;suggested workaround has been deployed to ATE2 APP environment and the resulting stats compared:

{code:java}
[pd122adm@m7tshrdinteweb1 ~]$ curl -k https://localhost:60200/server-status?auto
Total Accesses: 979
Total kBytes: 7792
CPULoad: .0141181
Uptime: 9633
ReqPerSec: .10163
BytesPerSec: 828.299
BytesPerReq: 8150.16
BusyWorkers: 1
IdleWorkers: 6
Scoreboard: _W_____.........................................................................................................................................................................................................................................................
{code}


{code:java}
[pd122adm@m7tshrdinteweb1 ~]$ curl -k --resolve ate2.shrd.m7.deutsche-boerse.com:60200:127.0.0.1 https://ate2.shrd.m7.deutsche-boerse.com:60200/server-status?auto
Total Accesses: 980
Total kBytes: 7800
CPULoad: .0141152
Uptime: 9635
ReqPerSec: .101713
BytesPerSec: 828.978
BytesPerReq: 8150.2
BusyWorkers: 1
IdleWorkers: 6
Scoreboard: _____W_.........................................................................................................................................................................................................................................................
{code}
","01/Apr/21 13:21;pd122;deployed to XSOP SIMU, looks good
PR https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1484 merged","06/Apr/21 09:04;cs687;done",,,,,,,,,,,,,,,,,,
Missing expiration policy for response queues,M7P-7975,107946,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,pn508,pn508,16/Mar/21 10:51,15/Jul/21 10:25,16/Sep/21 14:11,07/Jul/21 14:07,,6.12.107,7Tops_Sprint121,,,M7T BE,RabbitMQ,,,6.11,7tops_comm,,,,,,"*Problem*: clients might have some response queues without a consumer and with auto_delete flag = TRUE. Such queues are never automatically deleted because x-expires is not set for those. This might have potentially a negative impact on RabbitMQ.

*Solution*: let's add expiry policy to response queues:

rabbitmqctl set_policy expiry ""m7.private.responseQueues.*"" '\{""expires"":360000}' --apply-to queues

*Open question*: Will the new policy be applied on already existing queues or not?

 

*Suggested solution:*

Add this policy to the ansible template of RMQ configuration. Then, deploy it preferably in blue-green way.",,cs687,HO764,nn236,pn508,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/21 12:00;cs687;after_adding_queue.png;https://jira.deutsche-boerse.com/secure/attachment/97125/after_adding_queue.png","02/Jul/21 13:15;cs687;image-2021-07-02-13-15-45-291.png;https://jira.deutsche-boerse.com/secure/attachment/97042/image-2021-07-02-13-15-45-291.png","07/Jul/21 11:59;cs687;image-2021-07-07-11-59-33-416.png;https://jira.deutsche-boerse.com/secure/attachment/97124/image-2021-07-07-11-59-33-416.png","02/Jul/21 08:40;cs687;policy_syt2.png;https://jira.deutsche-boerse.com/secure/attachment/97023/policy_syt2.png","02/Jul/21 13:12;cs687;policy_syt2_afterwards.png;https://jira.deutsche-boerse.com/secure/attachment/97041/policy_syt2_afterwards.png","02/Jul/21 12:54;cs687;queues_syt2.png;https://jira.deutsche-boerse.com/secure/attachment/97040/queues_syt2.png","07/Jul/21 11:57;cs687;two_policies.png;https://jira.deutsche-boerse.com/secure/attachment/97123/two_policies.png","02/Jul/21 14:29;cs687;xsop_cute_private_repsone_queue.png;https://jira.deutsche-boerse.com/secure/attachment/97059/xsop_cute_private_repsone_queue.png",,,,,,,,sw455,,,,,,,,"tested the new policy setup in SYSTEMTEST2 and also in XSOP-CUTE 
non-used private.response.queues were deleted by the new policy. 

Also faced out that we can not do it seamlessly or by adding the new policy. 
So we have to schedule deployments for all customers. 

Staging looks like this: 
SIMU STAGING https: /jira.deutsche-boerse.com/browse/M7P-8588 (planned for this week 08-09.7.2021)
PROD STAGING https://jira.deutsche-boerse.com/browse/M7P-8589 (planned for 6.11 Deployments)
INTERNAL STAGING can be done by developers, already tested in SYSTEMTEST2, no need to have a dedicated ticket for it.",,,,,,,,,,,,,,,,,,,,,,,,6134400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzztdj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,,,,,,,,,,,,,,,,,,,,,see comments,2.0,,,,,,,,,"{""issueId"":107946,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"28/Apr/21 13:42;HO764;Adding a new policy is not the correct fix - only one policy with the same condition expression is applied. Therefore, an existing rule has been extended and renamed. Tested on ate2 (single noded) - no blue-green deployment yet. The queue policy is applied to a queue created by CT. The actual expiration has not been tested.

PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2724]

I believe that the next steps are on release manager and ops - plan and schedule deployment, gradually from less sensitive envs to more production.

If needed, I can split the PR not to enable this change everywhere, but somehow per-env.","02/Jul/21 08:04;cs687;Agree with [~HO764] lets not change it globally and start from the bottom to the top. 
I will take this point to our daily and schedule it with [~rehapav]

Can we do that seamlessly and deploy rabbitmq-nodes node by node, or should we do a fresh stop, clean, deploy and start for the whole cluster? 
 ","02/Jul/21 08:25;cs687;prepared pull-request for the internal test env´s to do a proper proof of concept:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2859/files
","02/Jul/21 08:40;cs687;!policy_syt2.png! 
!queues_syt2.png!

Information from [~oy574]: 
we should keep in mind one important thing - *changing the policy* makes seamlessly deployment *impossible*. We already tried it in the past for a queue that enquiry declares, and the problem was that when we start a new instance that tries to declare a queue with different parameters, but the old one still exists, the rmq library will throw an exception and the app startup will fail. The queue either has to be gone, or the parameter needs to be exactly the same. 

*So better to do it without seamlessly deployment*","02/Jul/21 13:11;cs687;h2. +What I did+

* 1.) stopped SYT2 backend on host m7tenrgsyt2m7b1/2 with Core, Enq and H2H4U
* 2.) merged pull-request https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2859/files
* 3.) redeployed rabbitmq with stop,clean,deploy,start, with the same version like it was running before 
* 4.) starting the stopped tomcat instances again 
* 5.) checking the rabbitmq Management GUI 
* 6.) login with ComTrader to create a private.responseQueue to see if the queue will expire after reaching the configured time

*changed policy* 
 !policy_syt2_afterwards.png! 

*after app is running again*
 !image-2021-07-02-13-15-45-291.png! 

h2. *we also made the test with xsop-cute* (i)
logged in into ComTrader. *{color:#DE350B}10:43{color}* (on)
!xsop_cute_private_repsone_queue.png! 
","05/Jul/21 10:49;cs687;*Two things* was tested to see if the m7.private.responseQueue will be expired:
* killed the ComTrader process on local laptop over taskmanager, *but this was also deleting the queues in a proper way*
* same happened with disabling network and killing the process with taskmanager
* also tried it to kill the process on windows in a forced way 
{code:java}
C:\Users\cs687>tasklist | sort
javaw.exe 	17472 Console  		1		704,980 K

C:\Users\cs687>taskkill /F /PID 17472
SUCCESS: The process with PID 17472 has been terminated.
{code}
this is also deleting the queues in a proper way. 
Hard to test the expiration value, can it be depending on the ComTrader Version that the queues will be not deleted with all the versions, or how can it happen that customer have some   hanging private.responseQueues running? 



asking [~pw231] for support if we can use a test-client what might be used in the past to test such of this changes. ","07/Jul/21 09:31;cs687;Had a call with [~pw231] and we tested the new policy by adding manually queue in RabbitMQ Management GUI with the following parameters:
* Virtual Host: app
* Type: classic
* Durability: Durable 
* Auto delete: Yes

*After 6 minutes the manually created queue was deleted with the new added policy!* (/)

(i)The next plan would be to test it, if we could avoid an deployment in general, by adding additional policy with rabbitmqctl command and test it ones again. 
In case it´s working out, we could avoid further deployments. 

added the policy manually to SYT2 and SYT1
{code:java}
rabbitmqctl set_policy respQ -p ""app"" '^(m7\.private\.responseQueue.*)' '{""expires"":360000}' --apply-to queues
{code}

* *added the additional policies, without any deployment*
 !two_policies.png! 
* *Policy ""respQ"" were not tagged!*
 !after_adding_queue.png! 
so this is the proof that multiple policies with the same pattern are not working out for the queues and just the old one will be touched. The open question is if we can do it without deployment for further planning's. ","07/Jul/21 09:49;HO764;[~cs687] Please note that adding a policy blindly doesn't work, one needs to modify the existing policy, as it was done by the PR. Otherwise, the new policy would replace the existing one. But I agree, a solution without redeployment should be possible.","07/Jul/21 11:56;pw231;[~HO764]: I believe it is possible to have multiple policies on a single queue and as long as they define different features, it should all work nicely.","07/Jul/21 14:04;cs687;We agreed with [~yq577] that we will close this ticket and create 3 Staging tickets and link it to https://jira.deutsche-boerse.com/browse/M7P-5582
* *SIMU STAGING* https: /jira.deutsche-boerse.com/browse/M7P-8588 (planned for this week 08-09.7.2021)
* *PROD STAGING* https://jira.deutsche-boerse.com/browse/M7P-8589 (planned for 6.11 Deployments)
* *INTERNAL STAGING* can be done by developers, already tested in SYSTEMTEST2, no need to have a dedicated ticket for it. ","07/Jul/21 14:07;cs687;done",,,,,,,,,,,,,,,,,
Create Jenkins job to kill queues,M7P-7968,107922,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,wn626,wn626,15/Mar/21 13:08,12/Apr/21 10:54,16/Sep/21 14:11,15/Mar/21 15:47,,6.11.213,7tops_sprint113,,,RabbitMQ,,,,M7PRODOPS,reducingtoil,toilwork,,,,,Create Jenkins job to kill queues on specific ENV for requested user,,cv179,wn626,,,,,,,,,,,,,,,,,,SERVICE-9524,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Jenkins job created for killing queues on specific ENV for requested user.,,,,,,,,,,,,,,Report a problem or bug,,,,,,,,,,15897600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzg2n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107922,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Mar/21 13:09;cv179;job created. Rebuild this to execute:

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/M7T%20RabbitMQ%20delete%20user%20queues/9/rebuild/parameterized","15/Mar/21 15:14;cv179;queues are successfully being deleted...

[https://grafana.energy.svc.dbgcloud.io/d/0tsoVdIiz/rabbitmq?orgId=2&refresh=30s&var-host=m7hupxsimuamq1%20-%20rabbitmq%20-%20m7_hupx_simu&var-group=All&var-inter=30s&var-client=hupx&var-client_env=simu&from=1615806839112&to=1615817639112&fullscreen&panelId=6]

 

this job output will contain all deleted queues:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/M7T%20RabbitMQ%20delete%20user%20queues/13/console]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,
copy ebsm scripts to simudpu.srv.energy,M7P-7961,107855,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,12/Mar/21 10:33,07/Apr/21 12:31,16/Sep/21 14:11,06/Apr/21 09:29,,6.11.223,7tops_sprint114,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,"1) create users on new ebsm dpu host (simudpu.srv.energy)
 * ebsmrun:ebsmrun
 * logmover:logmover
 * logreader:logreader
 * transfer:transfer

2) Copy ebsm script resources to simudpu.srv.energy: (ebsmrun:ebsmrun)

/opt/ebsm/ebsm-etl.jar
 /opt/ebsm/artifacts/
 /opt/ebsm/backup/
 /opt/ebsm/bash/
 /opt/ebsm/logs/
 /opt/ebsm/properties/
 /opt/ebsm/sql/

3) Copy logmover scripts from /opt/logmover/ (logmover:logmover)

4) Copy all files from /home/logreader/logparser/ (logreader:logreader)

5) Copy all subfolders from /home/logmover/ (logmover:logmover)",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,done,,,,,,,,,,,,,,,,,,,,,,,,15120000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjk7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107855,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"25/Mar/21 10:04;iu252;1. users and groups
Created suitable migration files on ""m7shrdebsm1"" host

{noformat}
[root@m7shrdebsm1 ~]# cat /etc/passwd | grep -e tomcat -e logmover -e ebsmrun -e logreader -e transfer -e ebsmbox > passwd_20210325.bak
[root@m7shrdebsm1 ~]# cat /etc/shadow | grep -e tomcat -e logmover -e ebsmrun -e logreader -e transfer -e ebsmbox > shadow_20210325.bak
[root@m7shrdebsm1 ~]# cat /etc/group  | grep -e tomcat -e logmover -e ebsmrun -e logreader -e transfer -e ebsmbox > group_20210325.bak
[root@m7shrdebsm1 ~]# vi accounts_migration_list_20210325.txt
[root@m7shrdebsm1 ~]# cat accounts_migration_list_20210325.txt
/root/group_20210325.bak
/root/passwd_20210325.bak
/root/shadow_20210325.bak
/home/tomcat/.bash_history
/home/tomcat/.bash_logout
/home/tomcat/.bash_profile
/home/tomcat/.bashrc
/home/tomcat/.cache
/home/tomcat/.config
/home/tomcat/.kshrc
/home/tomcat/.oracle_jre_usage
/home/tomcat/.ssh
/home/tomcat/.viminfo
/opt/data/home/logmover/.bash_history
/opt/data/home/logmover/.bash_logout
/opt/data/home/logmover/.bash_profile
/opt/data/home/logmover/.bashrc
/opt/data/home/logmover/.cache
/opt/data/home/logmover/.config
/opt/data/home/logmover/.lesshst
/opt/data/home/logmover/.local
/opt/data/home/logmover/.oracle_jre_usage
/opt/data/home/logmover/.pki
/opt/data/home/logmover/.ssh
/opt/data/home/logmover/.viminfo
/opt/data/home/logmover/.viminfo.tmp
/opt/data/home/logmover/.viminfy.tmp
/opt/data/home/logmover/.viminfz.tmp
/opt/data/home/logmover/.vimrc
/opt/data/home/logmover/.Xauthority
/home/ebsm/.bash_history
/home/ebsm/.cache
/home/ebsm/.config
/home/ebsm/.lesshst
/home/ebsm/.ssh
/home/ebsm/.viminfo
/home/ebsm/.viminfo.tmp
/opt/data/home/logreader/.bash_history
/opt/data/home/logreader/.bash_logout
/opt/data/home/logreader/.bash_profile
/opt/data/home/logreader/.bashrc
/opt/data/home/logreader/.cache
/opt/data/home/logreader/.config
/opt/data/home/logreader/.lesshst
/opt/data/home/logreader/.oracle_jre_usage
/opt/data/home/logreader/.ssh
/opt/data/home/logreader/.viminfo
/opt/data/home/logreader/.Xauthority
/opt/data/home/transfer/.bash_history
/opt/data/home/transfer/.cache
/opt/data/home/transfer/.config
/opt/data/home/transfer/.lesshst
/opt/data/home/transfer/.ssh
/opt/data/home/transfer/.viminfo
/opt/data/home/ebsmbox/.bash_history
/opt/data/home/ebsmbox/.bash_logout
/opt/data/home/ebsmbox/.bash_profile
/opt/data/home/ebsmbox/.bashrc
/opt/data/home/ebsmbox/.cache
/opt/data/home/ebsmbox/.config
/opt/data/home/ebsmbox/.lesshst
/opt/data/home/ebsmbox/.ssh
/opt/data/home/ebsmbox/.viminfo
[root@m7shrdebsm1 ~]# 
[root@m7shrdebsm1 ~]# tar cvzf accounts_migration_20210325.tgz -T accounts_migration_list_20210325.txt
{noformat}

Creating the accounts on target ""simudpu.srv.energy"" host

{noformat}
[root@simudpu ~]# ll /tmp/accounts_migration_20210325.tgz
-rwxr-xr-x 1 iu252 users 77404 Mar 25 09:47 /tmp/accounts_migration_20210325.tgz
[root@simudpu ~]#
{noformat}

{noformat}
[root@simudpu ~]# cd /
[root@simudpu /]# tar xvzf /tmp/accounts_migration_20210325.tgz
root/group_20210325.bak
root/passwd_20210325.bak
root/shadow_20210325.bak
home/tomcat/.bash_history
home/tomcat/.bash_logout
home/tomcat/.bash_profile
home/tomcat/.bashrc
home/tomcat/.cache/
home/tomcat/.cache/abrt/
home/tomcat/.cache/abrt/lastnotification
home/tomcat/.config/
home/tomcat/.config/abrt/
home/tomcat/.kshrc
home/tomcat/.oracle_jre_usage/
home/tomcat/.oracle_jre_usage/2f63c57bbf5cc3cb.timestamp
home/tomcat/.ssh/
home/tomcat/.ssh/authorized_keys
home/tomcat/.viminfo
opt/data/home/logmover/.bash_history
opt/data/home/logmover/.bash_logout
opt/data/home/logmover/.bash_profile
opt/data/home/logmover/.bashrc
opt/data/home/logmover/.cache/
opt/data/home/logmover/.cache/abrt/
opt/data/home/logmover/.cache/abrt/lastnotification
opt/data/home/logmover/.config/
opt/data/home/logmover/.config/abrt/
opt/data/home/logmover/.config/htop/
opt/data/home/logmover/.config/htop/htoprc
opt/data/home/logmover/.lesshst
opt/data/home/logmover/.local/
opt/data/home/logmover/.local/lib/
opt/data/home/logmover/.local/lib/python2.7/
opt/data/home/logmover/.local/lib/python2.7/site-packages/
opt/data/home/logmover/.oracle_jre_usage/
opt/data/home/logmover/.oracle_jre_usage/2f63c57bbf5cc3cb.timestamp
opt/data/home/logmover/.oracle_jre_usage/8b89543b21813651.timestamp
opt/data/home/logmover/.pki/
opt/data/home/logmover/.pki/nssdb/
opt/data/home/logmover/.ssh/
opt/data/home/logmover/.ssh/id_rsa
opt/data/home/logmover/.ssh/id_rsa.pub
opt/data/home/logmover/.ssh/known_hosts
opt/data/home/logmover/.ssh/authorized_keys
opt/data/home/logmover/.viminfo
opt/data/home/logmover/.viminfo.tmp
opt/data/home/logmover/.viminfy.tmp
opt/data/home/logmover/.viminfz.tmp
opt/data/home/logmover/.vimrc
opt/data/home/logmover/.Xauthority
home/ebsm/.bash_history
home/ebsm/.cache/
home/ebsm/.cache/abrt/
home/ebsm/.cache/abrt/lastnotification
home/ebsm/.config/
home/ebsm/.config/abrt/
home/ebsm/.lesshst
home/ebsm/.ssh/
home/ebsm/.ssh/sockets/
home/ebsm/.ssh/authorized_keys
home/ebsm/.ssh/config
home/ebsm/.ssh/id_rsa
home/ebsm/.ssh/id_rsa.pub
home/ebsm/.ssh/known_hosts
home/ebsm/.viminfo
home/ebsm/.viminfo.tmp
opt/data/home/logreader/.bash_history
opt/data/home/logreader/.bash_logout
opt/data/home/logreader/.bash_profile
opt/data/home/logreader/.bashrc
opt/data/home/logreader/.cache/
opt/data/home/logreader/.cache/abrt/
opt/data/home/logreader/.cache/abrt/lastnotification
opt/data/home/logreader/.config/
opt/data/home/logreader/.config/abrt/
opt/data/home/logreader/.lesshst
opt/data/home/logreader/.oracle_jre_usage/
opt/data/home/logreader/.oracle_jre_usage/2f63c57bbf5cc3cb.timestamp
opt/data/home/logreader/.oracle_jre_usage/8b89543b21813651.timestamp
opt/data/home/logreader/.ssh/
opt/data/home/logreader/.ssh/known_hosts
opt/data/home/logreader/.ssh/authorized_keys
opt/data/home/logreader/.viminfo
opt/data/home/logreader/.Xauthority
opt/data/home/transfer/.bash_history
opt/data/home/transfer/.cache/
opt/data/home/transfer/.cache/abrt/
opt/data/home/transfer/.cache/abrt/lastnotification
opt/data/home/transfer/.config/
opt/data/home/transfer/.config/abrt/
opt/data/home/transfer/.lesshst
opt/data/home/transfer/.ssh/
opt/data/home/transfer/.ssh/authorized_keys
opt/data/home/transfer/.viminfo
opt/data/home/ebsmbox/.bash_history
opt/data/home/ebsmbox/.bash_logout
opt/data/home/ebsmbox/.bash_profile
opt/data/home/ebsmbox/.bashrc
opt/data/home/ebsmbox/.cache/
opt/data/home/ebsmbox/.cache/abrt/
opt/data/home/ebsmbox/.cache/abrt/lastnotification
opt/data/home/ebsmbox/.config/
opt/data/home/ebsmbox/.config/abrt/
opt/data/home/ebsmbox/.lesshst
opt/data/home/ebsmbox/.ssh/
opt/data/home/ebsmbox/.ssh/known_hosts
opt/data/home/ebsmbox/.ssh/authorized_keys
opt/data/home/ebsmbox/.viminfo
[root@simudpu /]#
{noformat}

{noformat}
[root@simudpu /]# cat /root/group_20210325.bak >> /etc/group
[root@simudpu /]# cat /root/passwd_20210325.bak >> /etc/passwd
[root@simudpu /]# cat /root/shadow_20210325.bak >> /etc/shadow
[root@simudpu /]#
{noformat}

Integration with ""sssd"" authentication service
{noformat}
[root@simudpu /]# vi /etc/sssd/sssd.conf
[root@simudpu /]#
[root@simudpu /]# cat /etc/sssd/sssd.conf | grep -e filter_users -e filter_groups
filter_users = root,bin,daemon,adm,lp,sync,shutdown,halt,mail,operator,games,ftp,nobody,systemd-network,dbus,polkitd,postfix,ntp,tss,sshd,nscd,ansible,globmon,scanmgr,sssd,tomcat,logmover,ebsmrun,logreader,transfer,ebsmbox
filter_groups = root,bin,daemon,sys,adm,tty,disk,lp,mem,kmem,wheel,cdrom,mail,man,dialout,floppy,games,tape,video,ftp,lock,audio,nobody,users,utmp,utempter,input,systemd-journal,systemd-network,dbus,polkitd,ssh_keys,postdrop,postfix,ntp,tss,sshd,nscd,screen,ansible,globmon,scanmgr,printadmin,sssd,tomcat,logmover,ebsmrun,logreader,transfer,ebsmbox
[root@simudpu /]#
[root@simudpu /]# systemctl restart sssd.service
[root@simudpu /]#
{noformat}

ssh config

{noformat}
[root@simudpu ssh]# vi /etc/ssh/sshd_config
[root@simudpu ssh]# cat /etc/ssh/sshd_config | grep -e tomcat -e ebsmrun -e ebsmbox -e logreader -e logmover -e transfer
Match User ansible,globmon,scanmgr,tomcat,logmover,ebsmrun,logreader,transfer,ebsmbox
[root@simudpu ssh]#
[root@simudpu ssh]# systemctl restart sshd.service
[root@simudpu ssh]#
{noformat}
","25/Mar/21 10:26;iu252;2. ebsm script resources

{noformat}
[root@simudpu opt]# ls -l /opt/ebsm/
total 17252
drwxr-xr-x 2 ebsmrun ebsmrun     4096 Mar 25 10:18 artifacts
drwxr-xr-x 2 ebsmrun ebsmrun     4096 Mar 25 10:18 backup
drwxr-xr-x 3 ebsmrun ebsmrun     4096 Mar 25 10:18 bash
-rw-r--r-- 1 ebsmrun ebsmrun 17638986 Mar 25 10:18 ebsm-etl.jar
drwxr-xr-x 2 ebsmrun ebsmrun     4096 Mar 25 10:18 logs
drwxr-xr-x 2 ebsmrun ebsmrun     4096 Mar 25 10:18 properties
drwxr-xr-x 2 ebsmrun ebsmrun     4096 Mar 25 10:18 sql
[root@simudpu opt]#
{noformat}
","25/Mar/21 10:36;iu252;3. logmover scripts

{noformat}
[root@simudpu opt]# ls -l /opt/logmover/
total 46140
drwxr-xr-x 2 logmover logmover    4096 May  4  2018 artifacts
drwxr-xr-x 6 logmover logmover    4096 Sep  5  2018 backup
drwxr-xr-x 2 logmover logmover    4096 Mar  8 13:12 bash
-rw-rw-r-- 1 logmover logmover 8325094 Jan  3  2019 logmover-all.jar
-rw-rw-r-- 1 logmover logmover 8324841 Dec 17 13:17 logmover-archiver.jar
-rw-rw-r-- 1 logmover logmover 8325118 Dec 10  2018 logmover-daymonth_backup.jar
-rw-r--r-- 1 logmover logmover 8324842 Dec 17 12:46 logmover-daymonth.jar
-rw-rw-r-- 1 logmover logmover 8325096 Jan  3  2019 logmover-inbox.jar
-rw-rw-r-- 1 logmover logmover 5594858 Aug 24  2018 logmover.jar
drwxr-xr-x 2 logmover logmover    4096 Jan 25 13:59 properties
[root@simudpu opt]#
{noformat}
","25/Mar/21 10:56;iu252;4. logreader/logparser files

{noformat}
[root@simudpu home]# ls -l /home/logreader/
total 4
drwxrwxr-x 4 logreader logreader 4096 Mar 10 13:48 logparser
[root@simudpu home]# ls -l /home/logreader/logparser/
total 191456
-rw-rw-r-- 1 logreader logreader 77075069 Sep  3  2020 API_raw-data-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader  8841839 Sep  3  2020 API_raw-data-2020-08-27.zip
-rw-rw-r-- 1 logreader logreader 81523978 Sep  3  2020 API_raw-data-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader  8671709 Sep  3  2020 API_raw-data-2020-09-01.zip
-rw-rw-r-- 1 logreader logreader   390548 Sep  3  2020 API_report-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader    41801 Sep  3  2020 API_report-2020-08-27.zip
-rw-rw-r-- 1 logreader logreader   397969 Sep  3  2020 API_report-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader    42832 Sep  3  2020 API_report-2020-09-01.zip
-rw-rw-r-- 1 logreader logreader      837 Mar  2 11:07 API_report-2021-02-20.zip
-rw-rw-r-- 1 logreader logreader      714 Mar  2 11:07 API_report-2021-02-21.zip
-rw-rw-r-- 1 logreader logreader     2056 Mar  2 11:08 API_report-2021-02-22.zip
-rw-rw-r-- 1 logreader logreader     2631 Mar  2 10:51 API_report-2021-02-23.zip
-rw-rw-r-- 1 logreader logreader     1684 Mar  1 11:49 API_report-2021-02-24.zip
-rw-rw-r-- 1 logreader logreader     3765 Mar  1 11:49 API_report-2021-02-25.zip
-rw-rw-r-- 1 logreader logreader     1398 Mar  1 11:49 API_report-2021-02-26.zip
-rw-rw-r-- 1 logreader logreader     1890 Mar  2 10:52 API_report-2021-02-27.zip
-rw-rw-r-- 1 logreader logreader     2877 Mar  1 11:50 API_report-2021-02-28.zip
-rw-rw-r-- 1 logreader logreader     2877 Mar  1 11:43 API_report-2021-03-01.zip
-rw-rw-r-- 1 logreader logreader     1293 Oct  4  2017 conf.properties
-rw-rw-r-- 1 logreader logreader  4776432 Sep  3  2020 CT_raw-data-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader   538112 Sep  3  2020 CT_raw-data-2020-08-27.zip
-rw-rw-r-- 1 logreader logreader  3942170 Sep  3  2020 CT_raw-data-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader   444835 Sep  3  2020 CT_raw-data-2020-09-01.zip
-rw-rw-r-- 1 logreader logreader   696931 Sep  3  2020 CT_report-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader    67579 Sep  3  2020 CT_report-2020-08-27.zip
-rw-rw-r-- 1 logreader logreader   654233 Sep  3  2020 CT_report-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader    63202 Sep  3  2020 CT_report-2020-09-01.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  2 11:07 CT_report-2021-02-20.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  2 11:07 CT_report-2021-02-21.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  2 11:08 CT_report-2021-02-22.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  2 10:51 CT_report-2021-02-23.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  1 11:49 CT_report-2021-02-24.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  1 11:49 CT_report-2021-02-25.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  1 11:49 CT_report-2021-02-26.zip
-rw-rw-r-- 1 logreader logreader      164 Mar  2 10:52 CT_report-2021-02-27.zip
-rw-rw-r-- 1 logreader logreader      361 Mar  1 11:50 CT_report-2021-02-28.zip
-rw-rw-r-- 1 logreader logreader      361 Mar  1 11:43 CT_report-2021-03-01.zip
-rw-rw-r-- 1 logreader logreader     1575 Mar  2 11:07 elts-asim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1544 Sep  4  2020 elts-prod-2days-configuration.properties
-rw-rw-r-- 1 logreader logreader     1544 Nov  2 11:20 elts-prod-configuration.properties
-rw-rw-r-- 1 logreader logreader     1607 Sep 26 11:40 elts-simu-configuration.properties
-rw-rw-r-- 1 logreader logreader     1575 Aug 11  2020 epex-asim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1571 Aug 11  2020 epex-fsim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1550 Aug 11  2020 flex-prod-configuration.properties
-rw-rw-r-- 1 logreader logreader    16270 Oct 25  2018 hs_err_pid38432.log
-rw-r--r-- 1 logreader logreader     1393 Oct 15  2018 kombi2-configuration.properties
-rw-rw-r-- 1 logreader logreader     1463 Aug 11  2020 kombi-configuration.properties
-rw-r--r-- 1 logreader logreader     1371 Oct 11  2018 logback.xml
-rw-rw-r-- 1 logreader logreader  3838439 Jul 16  2019 logparser_backup.jar
-rw-rw-r-- 1 logreader logreader  3838573 Aug 11  2020 logparser.jar
drwxr-xr-x 3 logreader logreader     4096 Mar 10 07:25 logs
drwxrwxr-x 2 logreader logreader     4096 Aug 11  2020 report-backup
[root@simudpu home]#
{noformat}
","25/Mar/21 12:25;iu252;5. logmover subdirectories

{noformat}
[root@simudpu m7]# ll /home/logmover/
total 0
lrwxrwxrwx 1 root root 33 Mar 25 12:20 m7 -> /net/simudata.srv.energy/m7-logs/
lrwxrwxrwx 1 root root 35 Mar 25 12:21 xbid -> /net/simudata.srv.energy/xbid-logs/
[root@simudpu m7]# ll /home/logmover/m7/
total 24
drwxrwxrwx 2 logmover logmover 4096 Mar 25 12:22 1inbox
drwxrwxrwx 2 logmover logmover 4096 Mar 25 12:22 2currentDay
drwxrwxrwx 2 logmover logmover 4096 Mar 25 12:22 3unarchivedLogs
drwxrwxrwx 2 logmover logmover 4096 Mar 25 12:22 4archiveDays
drwxrwxrwx 2 logmover logmover 4096 Mar 25 12:22 5archiveMonths
drwxrwxr-x 2 logmover logmover 4096 Mar 25 12:22 6ignoredFiles
[root@simudpu m7]#
{noformat}

{noformat}
[root@simudpu m7]# ll 9sla/
total 72
drwxr-xr-x 3 logmover logmover 4096 Mar 25 13:35 asim
drwxr-xr-x 2 logmover logmover 4096 Mar 25 13:36 backup
drwxr-xr-x 3 logmover logmover 4096 Mar 25 13:35 ctpb
-rwxr-xr-x 1 logmover logmover  395 Mar 25 13:36 filter_cor_logs.py
-rwxr-xr-x 1 logmover logmover 4658 Mar 25 13:35 generate_report_kombi.py
-rw-r--r-- 1 logmover logmover 6529 Mar 25 13:35 generate_report.py
-rwxr-xr-x 1 logmover logmover 4935 Mar 25 13:35 generate_report.py.bck
-rwxr-xr-x 1 logmover logmover 5186 Mar 25 13:35 generate_report_wo_exclusion.py
drwxr-xr-x 2 logmover logmover 4096 Mar 25 13:35 input
-rw-r--r-- 1 logmover logmover  113 Mar 25 13:36 input.txt
drwxr-xr-x 2 logmover logmover 4096 Mar 25 13:35 kombi
-rw-r--r-- 1 logmover logmover  208 Mar 25 13:35 kombi_test1.csv
-rwxr-xr-x 1 logmover logmover 4311 Mar 25 13:36 parse_cor_logs_to_get_raw_perf_data.sh
[root@simudpu m7]#

{noformat}
",,,,,,,,,,,,,,,,,,,,,,,
reroute the log sending tool from all simu-like envs,M7P-7960,107854,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,12/Mar/21 10:29,30/Jun/21 12:13,16/Sep/21 14:11,22/Jun/21 15:17,,6.12.80,7tops_sprint120,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,"1) Please reroute the log sending tool from all non prod environments (except syt1 which is already covered in M7P-7641) so it will send logs to *simudata.srv.energy* instead of m7shrdebsm1 using _ebsmbox@simudpu.srv.energy:/net/simudata.srv.energy/m7-inbox/_:
 * -acut: elts-
 * asim: -elts-, -hupx-, -xsop-, -xeer (auction)-
 * ctpa: xbid
 * ctpb: -elts-, xbid
 * ctpc: xbid
 * ctpd: xbid
 * ctpe: xbid
 * ctpf: xbid
 * ctpg: xbid
 * ctph: xbid
 * ctpi: xbid
 * ctpj: xbid
 * ctpk: xbid
 * ctpl: xbid
 * ctpm: xbid
 * ctpn: xbid
 * ctso: xbid
 * cute: -elts-, -hupx-, -xsop-, -icsc-, xbid, -xeer-, -ampr-
 * -dst1: m7c_shrd, m7_shrd-
 * lipa: -elts-, -plpx-, xbid, xrpm
 * lipb: xbid
 * -show: m7_shrd-
 * simu: -elts-, -hupx-, -xsop-, -xeer-, xbid, -ampr-. plpx, xrpm
* m7a/c/t-shared components(apache,haproxy, rep-engine)

2) Create corresponding folder structure (no files, just folders):
 * /home/ebsm/m7
 * /home/ebsm/m7/failed/
 * /home/ebsm/m7/history/
 * /home/ebsm/m7/inbox/
 * /home/ebsm/m7/logs/
 * /home/ebsm/m7/outbox/
 * /home/ebsm/m7/queue/
 * /home/ebsm/m7/temp/
 * /home/ebsm/xbid
 * /home/ebsm/xbid/failed/
 * /home/ebsm/xbid/history/
 * /home/ebsm/xbid/inbox/
 * /home/ebsm/xbid/logs/
 * /home/ebsm/xbid/outbox/
 * /home/ebsm/xbid/queue/
 * /home/ebsm/xbid/temp/
 *",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,done,,,,,,,,,,,,,,,,,,,,,,,,11577600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjjz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107854,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"26/Mar/21 12:54;iu252;Rerouted the log sending tool for plpx-lipa:

{noformat}
[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_logstoebsm.yml --limit ""m7*plpx*lipa*"" -k -K -b
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy logstoebsm on application instances] *******************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-stk1]
ok: [m7t-plpx-lipa-rep2]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-stk1]
ok: [m7t-plpx-lipa-rep2]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-rep2]
ok: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-rep2]
ok: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-rep2]
ok: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : create ssh directory] ****************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-rep2]
ok: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : provide dpu host ssh key] ************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-cor1]
changed: [m7t-plpx-lipa-rep1]
changed: [m7t-plpx-lipa-rep2]
changed: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : provide ssh config] ******************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-enq2]
changed: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-enq1]
changed: [m7t-plpx-lipa-rep2]
changed: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : create prodscripts directory] ********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-enq1]
changed: [m7t-plpx-lipa-rep1]
changed: [m7t-plpx-lipa-rep2]
changed: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : create transfer script] **************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-enq1]
changed: [m7t-plpx-lipa-rep1]
changed: [m7t-plpx-lipa-rep2]
changed: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : Get a pseudo-random minute] **********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor1]
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-enq1]
ok: [m7t-plpx-lipa-enq2]
ok: [m7t-plpx-lipa-rep1]
ok: [m7t-plpx-lipa-rep2]
ok: [m7t-plpx-lipa-stk1]

TASK [logstoebsm : create cronjob] **********************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-cor2]
ok: [m7t-plpx-lipa-cor1]
changed: [m7t-plpx-lipa-enq2]
changed: [m7t-plpx-lipa-enq1]
changed: [m7t-plpx-lipa-rep1]
changed: [m7t-plpx-lipa-stk1]
changed: [m7t-plpx-lipa-rep2]

PLAY [Deploy logstoebsm on rabbitmq instances] **********************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq3]
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq2]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq2]
ok: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq2]
ok: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq3]
ok: [m7t-plpx-lipa-amq2]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq2]
ok: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : create ssh directory] ****************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq2]
changed: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : provide dpu host ssh key] ************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-amq2]
changed: [m7t-plpx-lipa-amq3]
changed: [m7t-plpx-lipa-amq1]

TASK [logstoebsm : provide ssh config] ******************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-amq1]
changed: [m7t-plpx-lipa-amq2]
changed: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : create prodscripts directory] ********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq2]
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : create transfer script] **************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-amq2]
changed: [m7t-plpx-lipa-amq1]
changed: [m7t-plpx-lipa-amq3]

TASK [logstoebsm : Get a pseudo-random minute] **********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-amq1]
ok: [m7t-plpx-lipa-amq3]
ok: [m7t-plpx-lipa-amq2]

TASK [logstoebsm : create cronjob] **********************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-amq3]
changed: [m7t-plpx-lipa-amq1]
changed: [m7t-plpx-lipa-amq2]

PLAY [Deploy logstoebsm on apache instances] ************************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]
ok: [m7t-plpx-lipa-app-web1]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web2]
ok: [m7t-plpx-lipa-rep-web1]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : create ssh directory] ****************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-rep-web2]
ok: [m7t-plpx-lipa-rep-web1]

TASK [logstoebsm : provide dpu host ssh key] ************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-app-web2]
changed: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-rep-web2]
ok: [m7t-plpx-lipa-rep-web1]

TASK [logstoebsm : provide ssh config] ******************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-app-web2]
changed: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : create prodscripts directory] ********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]
ok: [m7t-plpx-lipa-app-web2]

TASK [logstoebsm : create transfer script] **************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-rep-web1]
changed: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : Get a pseudo-random minute] **********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-web1]
ok: [m7t-plpx-lipa-app-web2]
ok: [m7t-plpx-lipa-rep-web1]
ok: [m7t-plpx-lipa-rep-web2]

TASK [logstoebsm : create cronjob] **********************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-app-web2]
changed: [m7t-plpx-lipa-app-web1]
changed: [m7t-plpx-lipa-rep-web1]
changed: [m7t-plpx-lipa-rep-web2]

PLAY [Deploy logstoebsm on haproxy instances] ***********************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-extbe-haproxy2]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : get user home directory] *************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : debug output] ************************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : create ssh directory] ****************************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy3]
changed: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : provide dpu host ssh key] ************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-extbe-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy3]
changed: [m7t-plpx-lipa-app-haproxy2]
changed: [m7t-plpx-lipa-app-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy4]
changed: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : provide ssh config] ******************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-app-haproxy1]
changed: [m7t-plpx-lipa-extbe-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy2]
changed: [m7t-plpx-lipa-app-haproxy3]
changed: [m7t-plpx-lipa-app-haproxy4]
changed: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : create prodscripts directory] ********************************************************************************************************************************************************
changed: [m7t-plpx-lipa-app-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy2]
changed: [m7t-plpx-lipa-extbe-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy4]
changed: [m7t-plpx-lipa-app-haproxy3]
changed: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : create transfer script] **************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-extbe-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy2]
changed: [m7t-plpx-lipa-app-haproxy3]
changed: [m7t-plpx-lipa-app-haproxy4]
changed: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : Get a pseudo-random minute] **********************************************************************************************************************************************************
ok: [m7t-plpx-lipa-app-haproxy2]
ok: [m7t-plpx-lipa-extbe-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy1]
ok: [m7t-plpx-lipa-app-haproxy3]
ok: [m7t-plpx-lipa-app-haproxy4]
ok: [m7t-plpx-lipa-extbe-haproxy2]

TASK [logstoebsm : create cronjob] **********************************************************************************************************************************************************************
changed: [m7t-plpx-lipa-extbe-haproxy1]
changed: [m7t-plpx-lipa-app-haproxy4]
changed: [m7t-plpx-lipa-app-haproxy2]
changed: [m7t-plpx-lipa-app-haproxy1]
changed: [m7t-plpx-lipa-extbe-haproxy2]
changed: [m7t-plpx-lipa-app-haproxy3]

PLAY RECAP **********************************************************************************************************************************************************************************************
m7t-plpx-lipa-amq1         : ok=12   changed=4    unreachable=0    failed=0
m7t-plpx-lipa-amq2         : ok=12   changed=4    unreachable=0    failed=0
m7t-plpx-lipa-amq3         : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-app-haproxy1 : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-app-haproxy2 : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-app-haproxy3 : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-app-haproxy4 : ok=12   changed=6    unreachable=0    failed=0
m7t-plpx-lipa-app-web1     : ok=12   changed=3    unreachable=0    failed=0
m7t-plpx-lipa-app-web2     : ok=12   changed=4    unreachable=0    failed=0
m7t-plpx-lipa-cor1         : ok=12   changed=0    unreachable=0    failed=0
m7t-plpx-lipa-cor2         : ok=12   changed=0    unreachable=0    failed=0
m7t-plpx-lipa-enq1         : ok=12   changed=1    unreachable=0    failed=0
m7t-plpx-lipa-enq2         : ok=12   changed=1    unreachable=0    failed=0
m7t-plpx-lipa-extbe-haproxy1 : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-extbe-haproxy2 : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-rep-web1     : ok=12   changed=2    unreachable=0    failed=0
m7t-plpx-lipa-rep-web2     : ok=12   changed=1    unreachable=0    failed=0
m7t-plpx-lipa-rep1         : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-rep2         : ok=12   changed=5    unreachable=0    failed=0
m7t-plpx-lipa-stk1         : ok=12   changed=5    unreachable=0    failed=0

[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$
{noformat}
","31/Mar/21 09:41;iu252;Rerouted the log sending tool for elts-ctpb:
# stop transfer script on m7eltsctpbm7b1
# wait 30 minutes
# move existing logs from m7shrdebsm1 to simudpu (2currentDay-, 3unarchivedLogs-, 4archiveDays-, 5archiveMonths-directory in /home/logmover/)
# start transferring logs to simudpu","01/Apr/21 12:11;iu252;Rerouted the log sending tool for elts-acut:

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*elts_acut*
-rwxrwxrwx 1 ebsmbox ebsmbox      5539 Apr  1 08:48 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_enq-2_session_hau_0_2021-03-31.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    589543 Apr  1 08:49 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_enq-2_standard_hau_0_2021-03-31.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   3086429 Apr  1 10:25 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox    661628 Apr  1 12:07 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     81439 Mar 28 03:42 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log-20210328.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     84991 Mar 29 03:29 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log-20210329.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     85841 Mar 30 03:38 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log-20210330.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     88741 Mar 31 03:32 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log-20210331.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     88842 Apr  1 03:15 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-1_standard_ixe.log-20210401.gz
-rwxrwxrwx 1 ebsmbox ebsmbox 317564106 Apr  1 12:09 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rabbitmq-3_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox         0 Sep 13  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox       573 Sep  9  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log-20190909.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       552 Sep 10  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log-20190910.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       583 Sep 11  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log-20190911.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       538 Sep 12  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log-20190912.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      2724 Sep 12  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_acut_rmq-1_standard_ixe.log-20190913.gz
[root@simudpu m7]#

{noformat}
","01/Apr/21 12:59;iu252;Rerouted the log sending tool for hupx-asim

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*hupx_asim*
-rwxrwxrwx 1 ebsmbox ebsmbox 17348367 Apr  1 12:54 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_cor-1_gc-pid23500_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   814311 Apr  1 12:58 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 16321106 Apr  1 10:31 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_enq-1_gc-pid23200_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       66 Mar 30 13:26 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_enq-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     6568 Mar 30 13:26 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_enq-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     1036 Apr  1 09:32 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 32103572 Apr  1 12:58 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  1069061 Apr  1 12:58 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_harvester-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  2662552 Apr  1 12:58 /net/simudata.srv.energy/m7-inbox/m7_hupx_asim_mtt2-1_standard_ixe.log
[root@simudpu m7]#
{noformat}
","01/Apr/21 15:29;iu252;Rerouted the log sending tool for xsop-asim:

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xsop_asim*
-rwxrwxrwx 1 ebsmbox ebsmbox 14380256 Apr  1 15:27 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_cor-1_gc-pid30358_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 38307003 Apr  1 15:28 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  3912647 Apr  1 14:06 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_enq-1_gc-pid27080_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    12413 Apr  1 09:02 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 34576775 Apr  1 15:28 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  1276018 Apr  1 15:28 /net/simudata.srv.energy/m7-inbox/m7_xsop_asim_harvester-1_standard_ixe.log
[root@simudpu m7]#
{noformat}
","06/Apr/21 16:11;iu252;Rerouted the log sending tool for xeer-asim (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xeer*
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Oct 21  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_access_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     5362 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_database_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    23303 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid115334_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  3467763 Apr  6 15:19 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid21476_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 20971897 May 15  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid24362_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox   481914 May 28  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid24362_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox 10256134 Oct 21 10:14 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid3151_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    22034 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid48359_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    30054 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid49180_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    27460 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid59845_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 20971886 Jun 12  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid7550_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox  1332458 Jul  9  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid7550_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox  8199294 Oct 27 10:38 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid83159_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  5102549 Oct  2  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid9338_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  3754548 Oct 29 08:29 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_gc-pid93483_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Oct 21  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_perfromance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Oct 21  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   138354 Oct 22  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox      222 Jan 14 07:32 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_access_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox      506 Jan 14 04:32 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_database_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   849717 Oct 21 10:14 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid114673_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  3858536 Apr  6 16:07 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid21690_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  3296786 Oct 27 10:38 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid48164_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  2190580 Oct 29 08:29 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid52997_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 10221104 Oct  2  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid63043_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  2243142 May 28  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid7753_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  2016308 Jul  9  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_gc-pid97249_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Apr 30  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_session_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   216021 Apr  6 16:09 /net/simudata.srv.energy/m7-inbox/m7a_xeer_asim_app-2_standard_hau.log
{noformat}
","06/Apr/21 18:06;iu252;Rerouted the log sending tool for xeer-cute (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xeer_cute*
-rwxrwxrwx 1 ebsmbox ebsmbox 4252737 Apr  6 17:37 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-1_gc-pid5706_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   21351 Apr  6 18:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 3648545 Apr  6 16:31 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-2_gc-pid9318_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  245347 Apr  6 18:05 /net/simudata.srv.energy/m7-inbox/m7a_xeer_cute_app-2_standard_hau.log
[root@simudpu m7]#
{noformat}
","06/Apr/21 18:33;iu252;
Rerouted the log sending tool for xsop-cute (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xsop_cute*
-rwxrwxrwx 1 ebsmbox ebsmbox     83414 Apr  2 00:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_cor-1_standard_ixe_1_2021-04-01.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   8440539 Apr  6 18:29 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_gc-pid40569_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      6147 Apr  5 13:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_10.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6092 Apr  5 14:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_11.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6065 Apr  5 15:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_12.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6174 Apr  5 16:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_13.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6116 Apr  5 17:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_14.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6189 Apr  5 18:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_15.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6076 Apr  5 19:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_16.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6236 Apr  5 20:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_17.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6113 Apr  5 21:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_18.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6162 Apr  5 22:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_19.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6148 Apr  5 23:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_20.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6112 Apr  6 00:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_21.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6134 Apr  6 01:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_22.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6137 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-05_23.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6149 Apr  6 03:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-06_00.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6087 Apr  6 04:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-06_01.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      6129 Apr  6 05:00 /net/simudata.srv.energy/m7-inbox/m7_xsop_cute_enq-1_performance_ixe_0_2021-04-06_02.log.gz

{noformat}
","06/Apr/21 18:54;iu252;Rerouted the log sending tool for hupx-cute (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*hupx_cute*
-rwxrwxrwx 1 ebsmbox ebsmbox  19782878 Apr  6 18:45 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_cor-1_gc-pid57222_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   8864971 Apr  6 18:50 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_cor-1_gc-pid65927_ixe.log.2.current
-rwxrwxrwx 1 ebsmbox ebsmbox   1182310 Apr  6 18:52 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 213136918 Apr  6 18:53 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  16031196 Apr  6 15:03 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_enq-1_gc-pid56939_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   6393182 Apr  6 16:27 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_enq-1_gc-pid65294_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      1377 Apr  1 14:11 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox      1377 Apr  1 14:11 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  11063712 Apr  6 18:52 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   1555775 Apr  6 18:52 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_harvester-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   5764195 Apr  6 18:52 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_mtt2-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  94893289 Apr  1 14:11 /net/simudata.srv.energy/m7-inbox/m7_hupx_cute_rabbitmq-3_standard_ixe.log
[root@simudpu m7]#
{noformat}
","06/Apr/21 20:54;iu252;Rerouted the log sending tool for elts-cute (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*elts_cute*
-rwxrwxrwx 1 ebsmbox ebsmbox  19407665 Apr 14  2021 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-1_gc-pid112899_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   6359054 Apr  6 20:46 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-1_gc-pid71281_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   8601236 Apr 14  2021 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-1_gc-pid75584_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  11587902 Apr  6 20:47 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-1_gc-pid78468_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 201272007 Apr  6 20:52 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  13723857 Apr  6 20:53 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  12840356 Apr 14  2021 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-1_gc-pid112461_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  11618831 Apr 14  2021 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-1_gc-pid75460_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   8299721 Apr  6 20:49 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-1_gc-pid77096_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   4322873 Apr  6 20:52 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-1_gc-pid82566_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    192792 Apr  1 14:13 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    192984 Apr  1 14:13 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  46304921 Apr  6 20:52 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  58778732 Apr  1 14:13 /net/simudata.srv.energy/m7-inbox/m7_elts_cute_rabbitmq-3_standard_ixe.log
[root@simudpu m7]#
{noformat}
","06/Apr/21 21:57;iu252;Rerouted the log sending tool for plpx-lipa (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*plpx_lipa*
-rwxrwxrwx 1 ebsmbox ebsmbox   18434098 Apr  6 21:54 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_gc-pid101911_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   20971814 Apr  3 09:36 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_gc-pid107065_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox    5691978 Apr  6 21:50 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_gc-pid107065_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox    2540581 Apr  6 18:24 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_standard_ixe_5_2021-04-06.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    2189868 Apr  6 21:42 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_standard_ixe_6_2021-04-06.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    3305797 Apr  6 21:54 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    6273351 Apr  6 21:54 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox    6818447 Apr  6 21:46 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_enq-1_gc-pid101784_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox    6889304 Apr  6 21:24 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_enq-1_gc-pid106692_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox        376 Apr  6 19:02 /net/simudata.srv.energy/m7-inbox/m7_plpx_lipa_enq-1_performance_ixe_0_2021-04-06_16.lo             g.gz

{noformat}
","06/Apr/21 22:26;iu252;Rerouted the log sending tool for elts-lipa (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*elts_lipa*
-rw-rw-r-- 1 ebsmbox ebsmbox 286591770 Apr  6 22:25 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-1_standard_ixe.log
-rw-r--r-- 1 ebsmrun ebsmrun   1495896 Apr  6 22:26 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-2_standard_hau_0_2021-04-01.log
-rw-r--r-- 1 ebsmrun ebsmrun   1495812 Apr  6 22:26 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-2_standard_hau_0_2021-04-03.log
-rw-r--r-- 1 ebsmrun ebsmrun   1495860 Apr  6 22:26 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-2_standard_hau_0_2021-04-04.log
-rw-r--r-- 1 ebsmrun ebsmrun   1495860 Apr  6 22:26 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-2_standard_hau_0_2021-04-05.log
-rw-rw-r-- 1 ebsmbox ebsmbox   1398244 Apr  6 22:25 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_cor-2_standard_hau.log
-rw-rw-r-- 1 ebsmbox ebsmbox       265 Apr  1 11:21 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_enq-1_session_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox    536563 Apr  1 11:21 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_enq-1_standard_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox        99 Apr  1 11:21 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_enq-2_session_hau.log
-rw-rw-r-- 1 ebsmbox ebsmbox      3309 Apr  1 11:22 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_enq-2_standard_hau.log
-rw-rw-r-- 1 ebsmbox ebsmbox  29110226 Apr  6 22:25 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_h2h4u-1_standard_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox   6141889 Apr  6 22:25 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_mtt2-1_standard_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox 251534678 Apr  6 22:23 /net/simudata.srv.energy/m7-inbox/m7_elts_lipa_rabbitmq-3_standard_ixe.log
[root@simudpu m7]#
{noformat}
","07/Apr/21 11:06;iu252;Rerouted the log sending tool for shrd-show (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*show*
-rwxrwxrwx 1 ebsmbox ebsmbox   9421706 Apr  7 11:01 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_cor-1_gc-pid35398_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  10448874 Apr  7 11:04 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_cor-1_gc-pid52336_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  54668980 Apr  7 11:04 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    690742 Apr  7 11:04 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox    510392 Apr  7 10:18 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_enq-1_gc-pid43017_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   3534534 Apr  7 08:26 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_enq-1_gc-pid68780_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 237084601 Apr  7 11:05 /net/simudata.srv.energy/m7-inbox/m7_shrd_show_rabbitmq-3_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox       274 Dec 16 11:07 /net/simudata.srv.energy/m7-inbox/shrd-show-amq3@m7shrdshowamq3_upgrade.log
-rwxrwxrwx 1 ebsmbox ebsmbox      1942 Aug  7  2020 /net/simudata.srv.energy/m7-inbox/shrd-show-amq3_upgrade.log
[root@simudpu m7]#
{noformat}
","07/Apr/21 12:32;iu252;Rerouted the log sending tool for shrd-dst1 (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*dst1*
-rwxrwxrwx 1 ebsmbox ebsmbox     0 Oct 15 03:21 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  1321 Sep 23  2020 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log-20200924.gz
-rwxrwxrwx 1 ebsmbox ebsmbox 21844 Sep 24  2020 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log-20200925.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   653 Sep 26  2020 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log-20200926.gz
-rwxrwxrwx 1 ebsmbox ebsmbox  6284 Oct 13 20:28 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log-20201014.gz
-rwxrwxrwx 1 ebsmbox ebsmbox  1540 Oct 14 12:04 /net/simudata.srv.energy/m7-inbox/m7c_shrd_dst1_rabbitmq-2_standard_hau.log-20201015.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     0 Jan 30 03:14 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox 67842 Nov  1 06:35 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log-20201102.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   166 Nov  8 16:07 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log-20201109.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   183 Jan 15 12:31 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log-20210116.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   148 Jan 17 02:38 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log-20210117.gz
-rwxrwxrwx 1 ebsmbox ebsmbox  1454 Jan 29 13:19 /net/simudata.srv.energy/m7-inbox/m7_shrd_dst1_rabbitmq-2_standard_hau.log-20210130.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     0 Nov  2 03:33 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2@m7shrddst1amq2_upgrade.log
-rwxrwxrwx 1 ebsmbox ebsmbox   183 Oct 31 21:36 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2@m7shrddst1amq2_upgrade.log-20201102.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     0 Oct 14 03:15 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log
-rwxrwxrwx 1 ebsmbox ebsmbox   128 Aug  7  2020 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log-20200808.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   102 Sep 17  2020 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log-20200918.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   103 Sep 18  2020 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log-20200919.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   167 Sep 24  2020 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log-20200925.gz
-rwxrwxrwx 1 ebsmbox ebsmbox   101 Oct 13 10:44 /net/simudata.srv.energy/m7-inbox/shrd-dst1-amq2_upgrade.log-20201014.gz
[root@simudpu m7]#
{noformat}
","07/Apr/21 13:16;iu252;Rerouted the log sending tool for hupx-simu (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*hupx_simu*
-rwxrwxrwx 1 ebsmbox ebsmbox   6658976 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_cor-1_gc-pid87592_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  14786408 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_cor-1_gc-pid92948_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox 157270377 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    825730 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   4780106 Apr  7 13:00 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_gc-pid86958_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   4131854 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_gc-pid92244_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       246 Apr  7 10:19 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_performance_ixe_0_2021-04-07_07.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       250 Apr  7 11:15 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_performance_ixe_0_2021-04-07_08.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       257 Apr  7 12:15 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_performance_ixe_0_2021-04-07_09.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       256 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_performance_ixe_0_2021-04-07_10.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox        74 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     77590 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    444806 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox       261 Apr  7 11:00 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_performance_hau_0_2021-04-07_08.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       253 Apr  7 12:00 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_performance_hau_0_2021-04-07_09.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       272 Apr  7 13:00 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_performance_hau_0_2021-04-07_10.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox       519 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox      6256 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_session_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox    417342 Apr  7 13:12 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   7212178 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   1092607 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_harvester-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  10979466 Apr  7 13:14 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_mtt2-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    735155 Apr  7 13:15 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_rabbitmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     93123 Apr  3 03:33 /net/simudata.srv.energy/m7-inbox/m7_hupx_simu_rabbitmq-1_standard_ixe.log-20210403.gz
{noformat}
","07/Apr/21 13:43;iu252;Rerouted the log sending tool for xsop-simu (not yet the logs from shared hosts):

{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xsop_simu*
-rwxrwxrwx 1 ebsmbox ebsmbox 20971890 Apr  4 11:49 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_cor-1_gc-pid11136_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox  3874172 Apr  7 12:28 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_enq-1_gc-pid8342_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      674 Apr  6 02:16 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   743665 Apr  7 13:41 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    86936 Apr  3 03:49 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log-20210403.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    83186 Apr  4 03:08 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log-20210404.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    86230 Apr  5 03:24 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log-20210405.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    85221 Apr  6 03:19 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log-20210406.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    86810 Apr  7 03:46 /net/simudata.srv.energy/m7-inbox/m7_xsop_simu_rabbitmq-1_standard_ixe.log-20210407.gz
[root@simudpu m7]#
{noformat}
","07/Apr/21 14:05;iu252;Rerouted the log sending tool for elts-simu (not yet the logs from shared hosts):

{noformat}
root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*elts_simu*
-rwxrwxrwx 1 ebsmbox ebsmbox  19750437 Apr  7 14:00 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_cor-1_gc-pid20879_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox  13391954 Apr  7 14:01 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_cor-1_gc-pid20879_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox 177860014 Apr  7 14:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    876245 Apr  7 14:03 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_cor-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   2837660 Apr  7 13:38 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-1_gc-pid22409_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox   4156239 Apr  7 14:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-1_gc-pid23996_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       100 Apr  7 12:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     44609 Apr  7 14:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox        33 Apr  7 12:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-2_session_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox     43056 Apr  7 14:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_enq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox  48672084 Apr  7 14:03 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    781465 Apr  7 14:04 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     94316 Apr  3 04:01 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log-20210403.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     94127 Apr  4 04:01 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log-20210404.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    100936 Apr  5 04:01 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log-20210405.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     96413 Apr  6 04:01 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log-20210406.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     94259 Apr  7 04:02 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rabbitmq-1_standard_ixe.log-20210407.gz
-rw-rw-r-- 1 ebsmbox ebsmbox    248040 Jul 14  2019 /net/simudata.srv.energy/m7-inbox/m7_elts_simu_rmq-1_standard_ixe.log-20190714.gz.filepart
[root@simudpu m7]#
{noformat}
","07/Apr/21 15:06;iu252;Rerouted the log sending tool for xeer-simu (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*xeer_simu*
-rwxrwxrwx 1 ebsmbox ebsmbox  8783904 Apr  7 14:22 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-1_gc-pid58802_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      200 Apr  7 06:30 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    18145 Apr  7 15:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 11529500 Apr  7 14:04 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-2_gc-pid110103_hau.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  7 02:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   199047 Apr  7 15:02 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_app-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 May 29  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox      424 May 25  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20200525.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2822 May 26  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20200526.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2817 May 27  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20200527.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2941 May 28  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20200528.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      883 May 28  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20200529.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2238 Apr  3 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20210403.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      632 Apr  4 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20210404.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2142 Apr  5 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20210405.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2236 Apr  6 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20210406.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2991 Apr  7 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard_ixe.log-20210407.gz
-rwxrwxrwx 1 ebsmbox ebsmbox        0 May 29  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard-sasl_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox      254 Aug  2  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard-sasl_ixe.log-20190803.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      452 Aug  5  2019 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard-sasl_ixe.log-20190806.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      481 May 28  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-1_standard-sasl_ixe.log-20200529.gz
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Mar 25  2018 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox     5742 Mar 24  2017 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20180325.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      639 Apr  3 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20210403.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      594 Apr  4 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20210404.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     1809 Apr  5 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20210405.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     3180 Apr  6 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20210406.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     1821 Apr  7 03:00 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard_hau.log-20210407.gz
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Feb 23  2017 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard-sasl_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 May 29  2020 /net/simudata.srv.energy/m7-inbox/m7a_xeer_simu_rmq-2_standard-sasl_hau.log.filepart
{noformat}
","07/Apr/21 16:53;iu252;Rerouted the log sending tool for amp-cute (not yet the logs from shared hosts):

{noformat}
[root@simudpu ~]# ll /net/simudata.srv.energy/m7-inbox/*ampr_cute*
-rw-rw-r-- 1 ebsmbox ebsmbox   1419 Jan 27 10:03 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_database_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  4 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_performance_ixe_0_2021-04-04.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  5 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_performance_ixe_0_2021-04-05.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_performance_ixe_0_2021-04-06.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  7 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_performance_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox 701973 Apr  5 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_standard_ixe_0_2021-04-04.log
-rw-rw-r-- 1 ebsmbox ebsmbox 682612 Apr  6 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_standard_ixe_0_2021-04-05.log
-rw-rw-r-- 1 ebsmbox ebsmbox 682843 Apr  7 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_standard_ixe_0_2021-04-06.log
-rw-rw-r-- 1 ebsmbox ebsmbox 446858 Apr  7 16:50 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-1_standard_ixe.log
-rw-rw-r-- 1 ebsmbox ebsmbox   1419 Jan 27 10:04 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_database_hau.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  4 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_performance_hau_0_2021-04-04.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  5 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_performance_hau_0_2021-04-05.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_performance_hau_0_2021-04-06.log
-rw-rw-r-- 1 ebsmbox ebsmbox     50 Apr  7 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_performance_hau.log
-rw-rw-r-- 1 ebsmbox ebsmbox 622201 Apr  5 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_standard_hau_0_2021-04-04.log
-rw-rw-r-- 1 ebsmbox ebsmbox 622201 Apr  6 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_standard_hau_0_2021-04-05.log
-rw-rw-r-- 1 ebsmbox ebsmbox 622201 Apr  7 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_standard_hau_0_2021-04-06.log
-rw-rw-r-- 1 ebsmbox ebsmbox 384396 Apr  7 16:49 /net/simudata.srv.energy/m7-inbox/m7a_ampr_cute_app-2_standard_hau.log
[root@simudpu ~]#
{noformat}
","07/Apr/21 16:59;iu252;Rerouted the log sending tool for amp-simu (not yet the logs from shared hosts):

{noformat}
[root@simudpu ~]# ll /net/simudata.srv.energy/m7-inbox/*ampr_simu*
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Feb 15 10:04 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_access_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox      253 Mar 25 10:51 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_database_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox 20971691 Feb  1 23:43 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_gc-pid21245_ixe.log.2
-rwxrwxrwx 1 ebsmbox ebsmbox  9218999 Feb 15 10:02 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_gc-pid21245_ixe.log.3.current
-rwxrwxrwx 1 ebsmbox ebsmbox 20972251 Mar 17 02:35 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_gc-pid67925_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox 14237146 Apr  7 16:56 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_gc-pid67925_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  4 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_performance_ixe_0_2021-04-04.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  5 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_performance_ixe_0_2021-04-05.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_performance_ixe_0_2021-04-06.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  7 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Feb 15 10:04 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   701371 Apr  5 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_standard_ixe_0_2021-04-04.log
-rwxrwxrwx 1 ebsmbox ebsmbox   682407 Apr  6 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_standard_ixe_0_2021-04-05.log
-rwxrwxrwx 1 ebsmbox ebsmbox   682202 Apr  7 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_standard_ixe_0_2021-04-06.log
-rwxrwxrwx 1 ebsmbox ebsmbox   449742 Apr  7 16:57 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Feb 15 10:04 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_access_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox      506 Mar 25 10:51 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_database_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox 20971920 Dec 18 21:42 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid21140_hau.log.1
-rwxrwxrwx 1 ebsmbox ebsmbox 20971819 Jan 14 18:51 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid21140_hau.log.2
-rwxrwxrwx 1 ebsmbox ebsmbox 20971852 Feb 10 06:43 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid21140_hau.log.3
-rwxrwxrwx 1 ebsmbox ebsmbox  4303502 Feb 15 10:02 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid21140_hau.log.4.current
-rwxrwxrwx 1 ebsmbox ebsmbox 20972131 Mar  4 23:48 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid3587_hau.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox 20972166 Mar 29 17:03 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid3587_hau.log.1
-rwxrwxrwx 1 ebsmbox ebsmbox  7639264 Apr  7 16:57 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_gc-pid3587_hau.log.2.current
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  4 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_performance_hau_0_2021-04-04.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  5 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_performance_hau_0_2021-04-05.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  6 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_performance_hau_0_2021-04-06.log
-rwxrwxrwx 1 ebsmbox ebsmbox       50 Apr  7 02:00 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox        0 Feb 15 10:04 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_session_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox   622201 Apr  5 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_standard_hau_0_2021-04-04.log
-rwxrwxrwx 1 ebsmbox ebsmbox   622201 Apr  6 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_standard_hau_0_2021-04-05.log
-rwxrwxrwx 1 ebsmbox ebsmbox   622201 Apr  7 01:59 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_standard_hau_0_2021-04-06.log
-rwxrwxrwx 1 ebsmbox ebsmbox   388306 Apr  7 16:58 /net/simudata.srv.energy/m7-inbox/m7a_ampr_simu_app-2_standard_hau.log

{noformat}
","07/Apr/21 17:19;iu252;Rerouted the log sending tool for icsc-cute (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*icsc_cute*
-rwxrwxrwx 1 ebsmbox ebsmbox       84 Apr  7 01:30 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox       85 Apr  2 23:36 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox    15408 Apr  7 01:30 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox     2549 Apr  7 15:00 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_performance_hau_0_2021-04-07_14.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2510 Apr  7 16:00 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_performance_hau_0_2021-04-07_15.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     2523 Apr  7 17:00 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_performance_hau_0_2021-04-07_16.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox    12263 Apr  7 17:15 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_performance_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox      425 Apr  6 13:24 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_session_hau.log
-rwxrwxrwx 1 ebsmbox ebsmbox 17802121 Apr  7 17:15 /net/simudata.srv.energy/m7-inbox/m7c_icsc_cute_cmi-2_standard_hau.log
{noformat}
","07/Apr/21 18:35;iu252;Rerouted the log sending tool for elts-asim (not yet the logs from shared hosts):
{noformat}
[root@simudpu m7]# ll /net/simudata.srv.energy/m7-inbox/*elts_asim*
-rwxrwxrwx 1 ebsmbox ebsmbox  20971723 Apr  5 14:53 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_cor-1_gc-pid111481_ixe.log.0
-rwxrwxrwx 1 ebsmbox ebsmbox   4089413 Apr  7 18:20 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_cor-1_gc-pid111481_ixe.log.1.current
-rwxrwxrwx 1 ebsmbox ebsmbox   1146397 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_cor-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  10690417 Apr  7 18:22 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_gc-pid106289_ixe.log.0.current
-rwxrwxrwx 1 ebsmbox ebsmbox      6866 Apr  7 15:00 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_performance_ixe_0_2021-04-07_12.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      7502 Apr  7 16:00 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_performance_ixe_0_2021-04-07_13.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      7021 Apr  7 17:00 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_performance_ixe_0_2021-04-07_14.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox      4531 Apr  7 18:00 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_performance_ixe_0_2021-04-07_15.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox     14561 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_performance_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   3008075 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_session_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox  21029397 Apr  7 15:42 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_standard_ixe_4_2021-04-07.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox 241196522 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_enq-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   1855049 Apr  7 17:17 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_h2h4u-1_standard_ixe_11_2021-04-07.log.gz
-rwxrwxrwx 1 ebsmbox ebsmbox  19164352 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_h2h4u-1_standard_ixe.log
-rwxrwxrwx 1 ebsmbox ebsmbox   1526436 Apr  7 18:23 /net/simudata.srv.energy/m7-inbox/m7_elts_asim_harvester-1_standard_ixe.log
[root@simudpu m7]#
{noformat}
","14/Apr/21 14:00;iu252;Updated transfer script (ignore *_upgrade.log from rabbits): https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1523


{noformat}
-rw-rw-r-- 1 ebsmbox ebsmbox  137 Nov  2 12:15 icsc-cute-amq3@m7cicsccuteamq3_upgrade.log
-rw-rw-r-- 1 ebsmbox ebsmbox  999 Mar 10 16:57 icsc-cute-amq3_upgrade.log
-rw-rw-r-- 1 ebsmbox ebsmbox    0 Oct  3  2020 m7a-xeer-simu-amq1_upgrade.log
-rw-rw-r-- 1 ebsmbox ebsmbox    0 Oct  3  2020 m7a-xeer-simu-amq2_upgrade.log
-rw-rw-r-- 1 ebsmbox ebsmbox    0 Nov  3 03:46 plpx-lipa-amq1@m7plpxlipaamq1_upgrade.log
{noformat}
","04/May/21 19:09;iu252;New transfer script rolled out on:
ELTS: CTPB, ASIM, CUTE, LIPA
HUPX: ASIM, CUTE, SIMU
XSOP: ASIM, CUTE, SIMU
PLPX: LIPA, SIMU
XRPM: LIPA, SIMU
SHRD: DST1, SHOW
XEER: CUTE, ASIM, SIMU
AMPR: CUTE, SIMU
ICSC: CUTE",,,,
create EBSM database at M7SIMUDBR1/2,M7P-7959,107853,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,12/Mar/21 10:29,13/Apr/21 15:26,16/Sep/21 14:11,26/Mar/21 10:27,,6.11.223,7tops_sprint114,,,EBSM,,,,EBSM,M,M7PRODOPS,,,,,"Create the db dump of the current ebsm db (m7simupdbX:24059) and clone it to the new location (M7SIMUDBR1/2)

If more info needed please contact Andrei Nazarenko.",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/21 10:36;dp007;ebsmsimudb_cleanup.sql;https://jira.deutsche-boerse.com/secure/attachment/94096/ebsmsimudb_cleanup.sql",,,,,,,,,,,,,,,sw455,,,,,,,,db created on m7simudbr1/2,,,,,,,,,,,,,,,,,,,,,,,,15033600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjjr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107853,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"24/Mar/21 09:22;iu252;Created and merged after approval https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2658.","24/Mar/21 09:58;iu252;Current disk space situation on m7simudbr1/2

{noformat}
[root@m7simudbr1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  datavg   5  23   0 wz--n- 459.98g 30.98g
  rootvg   1   7   0 wz--n- <79.51g 59.44g
[root@m7simudbr1 ~]#
{noformat}

{noformat}
[root@m7simudbr2 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  datavg   5  23   0 wz--n- 459.98g  30.98g
  rootvg   1   7   0 wz--n- <79.51g <59.93g
[root@m7simudbr2 ~]#
{noformat}

Requested disc extension: https://jira.deutsche-boerse.com/browse/SYSENGINT-530

","24/Mar/21 13:12;iu252;Created vault entries: (https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/energy/shrd/simu/db/)
* secret/energy/shrd/simu/db/postgres_db_password
* secret/energy/shrd/simu/db/replication_db_password","24/Mar/21 13:16;iu252;Deployed patroni cluster:

{noformat}
[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_patroni.yml --limit ""en*shrd*simu*dbr-ebsm*"" -k -K -b --tags ebsm
SSH password:
SUDO password[defaults to SSH password]:

PLAY [deploy patroni resources to an environment] ********************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1]
ok: [energy-shrd-simu-dbr-ebsm2]

TASK [patroni : install patroni for RedHat] **************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2]
ok: [energy-shrd-simu-dbr-ebsm1]

TASK [patroni : install postgresql package] **************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2] => (item=postgresql11)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=postgresql11)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=postgresql11-server)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=postgresql11-server)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=postgresql11-contrib)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=postgresql11-contrib)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=postgresql11-debuginfo)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=postgresql11-debuginfo)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=expect)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=expect)

TASK [patroni : LVM Volumes creation data] ***************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})

TASK [patroni : Filesystem creation] *********************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})

TASK [patroni : Mountpoint definition] *******************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})

TASK [patroni : Filesystem mount definition in ""/etc/fstab""] *********************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
ok: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})
ok: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})

TASK [patroni : change fs permissions] *******************************************************************************************************************************************************************************
changed: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
changed: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'data', 'size': '20g', 'fstype': 'xfs', 'path': 'data'})
changed: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
changed: [energy-shrd-simu-dbr-ebsm1] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})
 [WARNING]: Consider using the file module with owner rather than running chown.  If you need to use command because file is insufficient you can add warn=False to this command task or set command_warnings=False
in ansible.cfg to get rid of this message.

changed: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'log', 'size': '5g', 'fstype': 'xfs', 'path': 'log'})
changed: [energy-shrd-simu-dbr-ebsm2] => (item={'vg': 'datavg', 'lv': 'backup', 'size': '5g', 'fstype': 'xfs', 'path': 'backup'})

TASK [patroni : create patroni config folder] ************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1] => (item=/etc/patroni_enshrdsimuebsm)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=/etc/patroni_enshrdsimuebsm)

TASK [patroni : copy patroni.yml template] ***************************************************************************************************************************************************************************
changed: [energy-shrd-simu-dbr-ebsm2]
changed: [energy-shrd-simu-dbr-ebsm1]

TASK [patroni : copy patroni service file] ***************************************************************************************************************************************************************************
changed: [energy-shrd-simu-dbr-ebsm2]
changed: [energy-shrd-simu-dbr-ebsm1]

TASK [patroni : enable and restart patroni service] ******************************************************************************************************************************************************************
changed: [energy-shrd-simu-dbr-ebsm2]
changed: [energy-shrd-simu-dbr-ebsm1]

TASK [patroni : giving the process time to start] ********************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1]
ok: [energy-shrd-simu-dbr-ebsm2]

TASK [patroni : allow postgres user to read journal] *****************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2]
ok: [energy-shrd-simu-dbr-ebsm1]

TASK [patroni : create user bin folder] ******************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1]
ok: [energy-shrd-simu-dbr-ebsm2]

TASK [patroni : copy tools] ******************************************************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm1] => (item=update-cluster-info)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=update-cluster-info)
ok: [energy-shrd-simu-dbr-ebsm1] => (item=show-cluster-info)
ok: [energy-shrd-simu-dbr-ebsm2] => (item=show-cluster-info)

TASK [patroni : add bashrc extension block to root .bashrc] **********************************************************************************************************************************************************
ok: [energy-shrd-simu-dbr-ebsm2]
ok: [energy-shrd-simu-dbr-ebsm1]

PLAY RECAP ***********************************************************************************************************************************************************************************************************
energy-shrd-simu-dbr-ebsm1 : ok=17   changed=4    unreachable=0    failed=0
energy-shrd-simu-dbr-ebsm2 : ok=17   changed=4    unreachable=0    failed=0

[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.deployments]$
{noformat}


Cluster status:

{noformat}
[root@m7simudbr1 ~]# patronictl -c /etc/patroni_enshrdsimuebsm/config.yml list
+----------------+------------+----------------------+--------+---------+----+-----------+
|    Cluster     |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+----------------+------------+----------------------+--------+---------+----+-----------+
| enshrdsimuebsm | m7simudbr1 | 10.139.134.221:24062 | Leader | running |  1 |         0 |
| enshrdsimuebsm | m7simudbr2 | 10.139.134.222:24062 |        | running |  1 |         0 |
+----------------+------------+----------------------+--------+---------+----+-----------+
[root@m7simudbr1 ~]#
{noformat}
","24/Mar/21 13:23;iu252;Created ADMIN/INSTALL directory and copied the scripts:

{noformat}
-bash-4.2$ pwd
/var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL
-bash-4.2$ ll
total 24
-rwxr-xr-x 1 postgres postgres 101 Mar 24 13:22 001_DROP_DATABASE.sql
-rwxr-xr-x 1 postgres postgres 189 Mar 24 13:22 010_CREATE_DATABASE.sql
-rwxr-xr-x 1 postgres postgres  75 Mar 24 13:22 020_CREATE_SCHEMA.sql
-rwxr-xr-x 1 postgres postgres 133 Mar 24 13:22 030_ALTER_ROLE.sql
-rwxr-xr-x 1 postgres postgres 761 Mar 24 13:22 034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
-rwxr-xr-x 1 postgres postgres 137 Mar 24 13:22 035_CREATE_NETBACKUP_ROLE.sql
-bash-4.2$
{noformat}
","24/Mar/21 13:26;iu252;Executed ADMIN-scripts:


{noformat}
-bash-4.2$ psql -p 24062
psql (11.5)
Type ""help"" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(3 rows)

postgres=# \i tmp
postgres=# \i /var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql
psql:/tmp/001_DROP_DATABASE.sql:1: NOTICE:  database ""ebsm"" does not exist, skipping
DROP DATABASE
psql:/var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql:2: NOTICE:  role ""ebsm"" does not exist, skipping
DROP ROLE
psql:/var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/001_DROP_DATABASE.sql:3: NOTICE:  role ""ebsadmin"" does not exist, skipping
DROP ROLE
postgres=# \i /var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql
CREATE ROLE
CREATE DATABASE
ALTER DATABASE
psql:/var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql:4: ERROR:  role ""ebsm"" already exists
CREATE ROLE
postgres=# \i /var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/020_CREATE_SCHEMA.sql
You are now connected to database ""ebsm"" as user ""postgres"".
CREATE SCHEMA
DROP SCHEMA
ebsm=# \i /var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/030_ALTER_ROLE.sql
ALTER ROLE
ALTER ROLE
ebsm=# \i /var/lib/pgsql_enshrdsimuebsm/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
ebsm=> \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 ebsm      | ebsm     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/ebsm             +
           |          |          |             |             | ebsm=CTc/ebsm        +
           |          |          |             |             | ebsmadmin=c/ebsm
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

ebsm=> \q
-bash-4.2$
{noformat}
","24/Mar/21 14:04;iu252;New db-dump on m7simupdb4 created:

{noformat}
-bash-4.2$  /usr/pgsql-11/bin/pg_dump --port=24059 -d ebsm -n ebsm | gzip > ebsm_simu.sql.gz
-bash-4.2$ ll
total 8985652
-rw-r--r-- 1 postgres postgres 4642741709 Mar 24 13:54 ebsm_simu.sql.gz
-rwxrwxrwx 1 postgres postgres 4558562343 Mar  3 17:53 ebsm_test.sql.gz
{noformat}
","24/Mar/21 14:07;iu252;File system on m7simudbr1/2 extended:

{noformat}
[root@m7simudbr1 ~]# df -h | grep ebsm
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data     20G  113M   20G   1% /var/lib/pgsql_enshrdsimuebsm/data
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_log     5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/log
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_backup  5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/backup
[root@m7simudbr1 ~]# lvextend -r -L +105g /dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data
  Size of logical volume datavg/lv_pgsql_enshrdsimuebsm_data changed from 20.00 GiB (5120 extents) to 125.00 GiB (32000 extents).
  Logical volume datavg/lv_pgsql_enshrdsimuebsm_data successfully resized.
meta-data=/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data isize=512    agcount=4, agsize=1310720 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=5242880, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 5242880 to 32768000
[root@m7simudbr1 ~]# df -h | grep ebsm
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data    125G  114M  125G   1% /var/lib/pgsql_enshrdsimuebsm/data
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_log     5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/log
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_backup  5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/backup
[root@m7simudbr1 ~]#
{noformat}



{noformat}
[root@m7simudbr2 ~]# df -h | grep ebsm
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data     20G   97M   20G   1% /var/lib/pgsql_enshrdsimuebsm/data
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_log     5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/log
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_backup  5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/backup
[root@m7simudbr2 ~]# lvextend -r -L +105g /dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data
  Size of logical volume datavg/lv_pgsql_enshrdsimuebsm_data changed from 20.00 GiB (5120 extents) to 125.00 GiB (32000 extents).
  Logical volume datavg/lv_pgsql_enshrdsimuebsm_data successfully resized.
meta-data=/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data isize=512    agcount=4, agsize=1310720 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=5242880, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 5242880 to 32768000
[root@m7simudbr2 ~]# df -h | grep ebsm
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_data    125G   98M  125G   1% /var/lib/pgsql_enshrdsimuebsm/data
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_log     5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/log
/dev/mapper/datavg-lv_pgsql_enshrdsimuebsm_backup  5.0G   33M  5.0G   1% /var/lib/pgsql_enshrdsimuebsm/backup
[root@m7simudbr2 ~]#
{noformat}
","24/Mar/21 18:30;iu252;Date restored

{noformat}
[root@m7simudbr1 ~]# ll /ebsmtmp
total 4533928
-rwxr-xr-x 1 iu252 users 4642741709 Mar 24 14:36 ebsm_simu.sql.gz
-bash-4.2$ zcat ebsm_simu.sql.gz | psql -p 24062 -d ebsm
SET
SET
SET
SET
SET
 set_config
------------

(1 row)

SET
SET
SET
SET
ERROR:  schema ""ebsm"" already exists
ALTER SCHEMA
CREATE FUNCTION
ALTER FUNCTION
.....
....
....
{noformat}

{noformat}
postgres=# \c ebsm
You are now connected to database ""ebsm"" as user ""postgres"".
ebsm=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 ebsm      | ebsm     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/ebsm             +
           |          |          |             |             | ebsm=CTc/ebsm        +
           |          |          |             |             | ebsmadmin=c/ebsm
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

ebsm=# \dt
                       List of relations
 Schema |               Name               | Type  |   Owner
--------+----------------------------------+-------+-----------
 ebsm   | cpcy_agg_responsetimes_d1        | table | ebsmadmin
 ebsm   | cpcy_agg_responsetimes_d2        | table | ebsmadmin
 ebsm   | cpcy_agg_responsetimes_h1        | table | ebsmadmin
 ebsm   | cpcy_agg_responsetimes_m1        | table | ebsmadmin
 ebsm   | cpcy_dim_logevents               | table | ebsmadmin
 ebsm   | cpcy_dim_methodgroups            | table | ebsmadmin
 ebsm   | cpcy_dim_methods                 | table | ebsmadmin
 ebsm   | cpcy_dim_tso                     | table | ebsmadmin
 ebsm   | cpcy_dim_users                   | table | ebsmadmin
 ebsm   | cpcy_kpi_availability            | table | ebsmadmin
 ebsm   | cpcy_kpi_measures                | table | ebsmadmin
 ebsm   | cpcy_kpi_slas                    | table | ebsmadmin
 ebsm   | cpcy_kpi_valuesday               | table | ebsmadmin
 ebsm   | cpcy_kpi_valuesmonth             | table | ebsmadmin
 ebsm   | cpcy_log_be_responsetimes        | table | ebsmadmin
 ebsm   | cpcy_log_concurrentusers         | table | ebsmadmin
 ebsm   | cpcy_log_scanresults             | table | ebsmadmin
 ebsm   | cxhu_agg_responsetimes_d1        | table | ebsmadmin
 ebsm   | cxhu_agg_responsetimes_h1        | table | ebsmadmin
 ebsm   | cxhu_agg_responsetimes_m1        | table | ebsmadmin
 ebsm   | cxhu_dim_logevents               | table | ebsmadmin
 ebsm   | cxhu_dim_methodgroups            | table | ebsmadmin
 ebsm   | cxhu_dim_methods                 | table | ebsmadmin
 ebsm   | cxhu_dim_users                   | table | ebsmadmin
 ebsm   | cxhu_kpi_availability            | table | ebsmadmin
 ebsm   | cxhu_kpi_calendar                | table | ebsmadmin
 ebsm   | cxhu_kpi_fepercentilen           | table | ebsmadmin
 ebsm   | cxhu_kpi_measures                | table | ebsmadmin
 ebsm   | cxhu_kpi_slas                    | table | ebsmadmin
 ebsm   | cxhu_kpi_valuesday               | table | ebsmadmin
 ebsm   | cxhu_kpi_valuesmonth             | table | ebsmadmin
 ebsm   | cxhu_log_be_responsetimes        | table | ebsmadmin
....
....
....
{noformat}

","26/Mar/21 10:36;dp007;[^ebsmsimudb_cleanup.sql] script applied",,,,,,,,,,,,,,,,,,
"Implement full password policy on  ATE2, ATE3, ATE4",M7P-7956,107797,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,vp223,vp223,10/Mar/21 15:42,13/Apr/21 10:56,16/Sep/21 14:11,17/Mar/21 15:39,,6.11.217,7tops_sprint113,,,LDAP,,,,7tops,toilwork,,,,,,"For *ATE3* and *ATE4* please set up
{code:java}
 passwordCheckSyntax: on
 passwordExp: on
 passwordInHistory: 6
 passwordHistory: on
 passwordLockout: on
 passwordMaxAge: 7776000
 passwordMaxFailure: 5
 passwordMinCategories: 3
 passwordMinLength: 8
 passwordUnlock: off
 passwordWarning: 0{code}
and here's tested test policy for technical users:
{code:java}
 passwordCheckSyntax: on
 passwordExp: off
 passwordInHistory: 6
 passwordHistory: on
 passwordLockout: off
 passwordMinCategories: 3
 passwordMinLength: 8
 passwordWarning: 0{code}
*For ATE2*
{code:java}
passwordCheckSyntax: on
passwordExp: on
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0{code}
Technical users should have another policy:
{code:java}
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordHistory: on
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
{code}
Technical users:
||Environment||User||Additional info||
|ATE2, ATE3, ATE4|SADMIN01|Test0101|
|ATE2|binding user|[Vault|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/shrd/ate2/m7core/sob_user]|
|ATE3|binding user|[Vault|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/shrd/ate3/m7core/sob_user]|
|ATE4|binding user|[Vault|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/shrd/ate4/m7core/sob_user]|",,pd122,vp223,,,,,,,,,,,,,,,,M7P-7871,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,new PP objects created and existing ones modified as requested,,,,,,,,,,,,,,,,,,,,,,,,15724800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzg1r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107797,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Mar/21 13:20;pd122;Existing LDAP password policies in respective environments:

ATE2:

{code:java}
dn: cn=cn\3DnsTestPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordExp: on
passwordMaxAge: 86400
passwordWarning: 0
{code}

ATE3:

{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordMustChange: on
passwordChange: on
passwordMinAge: 0
passwordExp: on
passwordGraceLimit: 0
passwordMaxAge: 7776000
passwordWarning: 7000000
passwordInHistory: 6
{code}


ATE4:

{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordCheckSyntax: on
passwordMinCategories: 3
passwordMinLength: 8

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
{code}
","17/Mar/21 15:29;pd122;PP objects for ATE3,4 modified accordingly; for ATE2 these new objects were created:

{code:java}
dn: cn=""cn=nsPwPolicyEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: ldapsubentry
objectclass: passwordpolicy
passwordCheckSyntax: on
passwordExp: on
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0

dn: cn=""cn=nsNoExpPwPolicyEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: ldapsubentry
objectclass: passwordpolicy
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordHistory: on
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0

dn: cn=""cn=nsPwTemplateEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: costemplate
objectclass: ldapsubentry
cosPriority: 1
pwdpolicysubentry: cn=""cn=nsPwPolicyEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=m7tpwdpolicy_cos,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
objectclass: top
objectclass: LDAPsubentry
objectclass: cosSuperDefinition
objectclass: cosPointerDefinition
cosTemplateDn: cn=""cn=nsPwTemplateEntry,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
cosAttribute: pwdpolicysubentry default operational-default
{code}
","17/Mar/21 15:35;pd122;PP for specified accounts set as requested:

{code:java}
dn: uid=shrd-apa-ate2-adm,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: uid=SADMIN01,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: uid=shrd-apa-ate3-adm,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoPwPolicyEntry\2Cou\3Date3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: uid=SADMIN01,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoPwPolicyEntry\2Cou\3Date3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: uid=shrd-apa-ate4-adm,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: uid=SADMIN01,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}
","17/Mar/21 15:38;pd122;requested password for SADMIN01 accounts set",,,,,,,,,,,,,,,,,,,,,,,,
Create dump backups for non-prod databases,M7P-7955,107796,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,nz893,nz893,nz893,10/Mar/21 14:33,08/Sep/21 15:18,16/Sep/21 14:11,,,,,,,Database,,,,7tops,,,,,,,"Create dump backups for non-prod databases

Create generic ansible parametrized playbook which will be able to generate postgres binary dumps and copy them to testdpu || simudpu. The dump file should contains date, database name (env, customer) and should be used for schemas (not entire database).

The script should be able to backup patroni databases and single one too.",,nz893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16329600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzg1z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107796,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test fully encrypted internal communication,M7P-7946,107755,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cv179,cv179,10/Mar/21 09:19,29/Jun/21 14:50,16/Sep/21 14:11,18/May/21 16:40,,6.12.30,7tops_sprint117,,,infrastructure,,,,M,M7PRODOPS,,,,,,"After discussing ESO-405 we need an analysis about the impact of encrypted internal communication. In order to estimate possible consequences on production, this test should be done on SYT1 with production load.

Encrypted communication should include at least:
 * Apache to Backend (AJP and HTTP)
 * Haproxy to RabbitMQ (AMQPS)
 * Backend to RabbitMQ (AMQPS)
 * -Backend to Database (Postgres)-
 * Apache/Backend (/)/RabbitMQ to LDAP (LDAPS) (x)
 * Other possible communication channels (Email, ECP, H2H, XBID) unless encryption is already in place
 * -Core to GlusterFS (TLS enabled)-

 

Respective certificates should be automatically issued from VAULT during deployment.

Certificates should properly match the used host addresses - make use of wildcard or Subject alternative names if possible.

Truststores should also automatically include respective CA certificate from VAULT. A refactoring might be required to store the truststore base set as list of b64 certs and generate the p12 store from the list (instead of hardcoded base64 truststore in vault). Alternatively, the base64 entry in vault should be updated dynamically.

Deployment roles should be adjusted so that internal encryption can be selectively enabled/disabled.

 

Please also keep track of estimated implementation and configuration efforts (one-time, regular, per enviroment) so that we can estimate the overall efforts and cost.

Recommendation:
 * Start with an internal M7P environment, check effort for certificate management & implementation
 * Check what is easily possible (quick wins) and check whether any issues occur
 * Collect numbers/effort for: implementation, certificate management, performance impact
 * Provide numbers and risk resulting of that to Antoine & GIS for decision (continue with (partial) implementation or take the risks)",,cs687,cv179,dm700,ne232,nn481,pd122,sw455,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,XP-5314,M7P-8450,M7A-2589,M7A-2574,SYSENGINT-569,ESO-405,"18/May/21 16:52;vp223;AFTER_SYT1_AuditMainPage.html;https://jira.deutsche-boerse.com/secure/attachment/95411/AFTER_SYT1_AuditMainPage.html","18/May/21 16:52;vp223;After_SYT1_AuditMainPage.json;https://jira.deutsche-boerse.com/secure/attachment/95409/After_SYT1_AuditMainPage.json","18/May/21 16:52;vp223;After_SYT1_PerfStats.json;https://jira.deutsche-boerse.com/secure/attachment/95408/After_SYT1_PerfStats.json","11/May/21 10:07;vp223;Before_AuditMainPage.html;https://jira.deutsche-boerse.com/secure/attachment/95214/Before_AuditMainPage.html","11/May/21 10:07;vp223;Before_AuditMainPage.json;https://jira.deutsche-boerse.com/secure/attachment/95213/Before_AuditMainPage.json","11/May/21 10:07;vp223;Before_PerfStats.json;https://jira.deutsche-boerse.com/secure/attachment/95215/Before_PerfStats.json","19/May/21 11:25;vp223;Before_SYT1_AuditMainPage.json;https://jira.deutsche-boerse.com/secure/attachment/95442/Before_SYT1_AuditMainPage.json","19/May/21 11:25;vp223;Before_SYT1_AuditMainPage2.html;https://jira.deutsche-boerse.com/secure/attachment/95441/Before_SYT1_AuditMainPage2.html","19/May/21 11:26;vp223;Before_SYT1_PerfStats.json;https://jira.deutsche-boerse.com/secure/attachment/95440/Before_SYT1_PerfStats.json","15/Apr/21 16:56;cs687;after_changes.png;https://jira.deutsche-boerse.com/secure/attachment/94578/after_changes.png","15/Apr/21 16:56;cs687;before_changes.png;https://jira.deutsche-boerse.com/secure/attachment/94577/before_changes.png","15/Apr/21 07:56;cs687;journaler-performance-last2days.png;https://jira.deutsche-boerse.com/secure/attachment/94555/journaler-performance-last2days.png",,,,sw455,,,,,,,,"ticket can be closed!

the following encryption was tested:
* Apache to Backend (AJP and HTTP) (/)
* Apache/Backend /RabbitMQ to LDAP (LDAPS) (x)
* Core to GlusterFS (TLS enabled) (x)",,,,,,,,,,,,,,,,,,,,,,,,10281600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzjlb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":107755,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"31/Mar/21 14:52;cv179;[https://www.redhat.com/en/blog/hardening-gluster-installations-tls]

 ","06/Apr/21 13:55;cs687; 
{code:java}
To use TLS in GlusterFS both sides should negotiate as there are no mixed mode connections; if one side is configured to use TLS the other side can only communicate using TLS encryption otherwise connections will be rejected. {code}
Important for developers: 

 
{code:java}
This statement provides the information, all of ""systemtest"" environments have to be migrated to encrypted communication, if they should be effectively working.{code}
in case we are activating TLS for syt1 we have to activate it for all systemtest otherwise the rest will not work effectively. Have to double check it with dev if that would be okay for a short term of time. 

 

 ","07/Apr/21 13:46;cs687;[Steffen|https://app.slack.com/team/U7BU3EE12]  [2 minutes ago|https://dbg-devops.slack.com/archives/G451D1RQB/p1617795727138600?thread_ts=1617708732.132100&cid=G451D1RQB]

Announced to developers, that we will encrypt the Glusterfs Server/Client communication in Systemtest1 *by next wednesday 14.04.2021 from 10am -> 3pm* 
Afterwards we leave running the application with enabled TLS configuration, so the see differences. Ones we have the proof that our performance will suffer, we will roll it back to the normal state again.
Be aware of it, that other Test env´s which are also using glusterfs with m7testpdb1/2 can also not work effectively, because they need to be configured on the client side as well.","14/Apr/21 12:17;cs687; 

1.) stopped loadrunner and core instances on syt1 machines

*GlusterFS changes handled by Lambert # {color:#de350b}TLS enabled at 12:xx{color}*

2.) unmount clients
 3.) stopping ""glusterfs"" services on servers
 4.) copying certificates (client/server)
 5.) Creation of necessary configuration settings on GlusterFS server to enable TLS 

Lambert confirmed that GlusterFS servers are communicating between themselves with TLS encryption, going to continue with client part. 

 

Started application with TLS encryption around 2:17pm

[~xt853] will check the env and also grafana StatsD regrading performance. ","15/Apr/21 07:56;cs687;After activating TLS, we could see that core performance shows journaler spikes occasionally, properly depending on the caused load. 

Regarding Event times - Event handler processing times, we could see that the journaller is two times slower then it was before under load. That should be a show-blocker for us and not encrypt our application communication. On the other hand we will get rid of glusterfs in 6.12 replaced by kafka.

We compared the Timeslots *13.04.2021 07:37:00 - 13.04.2021 13:04:19* with the same times from today. 

 ","15/Apr/21 16:56;cs687;*before the changes*
 !before_changes.png!  

*after the changes*
!after_changes.png! ","21/Apr/21 15:22;cs687;We agreed on it with [~ne232], [~cv179] and [~pn508]
that we will skip glusterfs & database which will have a performance impact. 

During the sprint 116 we will try to encrypt and collect some feedback about:  
* Apache to Backend (AJP and HTTP)
* Apache/Backend/RabbitMQ to LDAP (LDAPS)

[~ne232] also got the confirmation from GIS, that there is no need to encrypt all the listed component in the description.
 

","23/Apr/21 13:23;cs687;1.) Checked the *Apache LDAP part*

seems like for apache we already connect to ldaps - here an example in elts-prod
{code:java}
cat /shrd/m7t-elts-prod-app-web1/config/conf.d/m7_intraday.conf
AuthLDAPUrl                     ""ldaps://m7shrdprodldp1:636 m7shrdprodldp2:636/ou=prod,ou=elts-app,o=M7,dc=energy,dc=prod?uid""
{code}

Proper ansible apache role:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/fbb7400d68bfc2e4293701e318b539854828e479/roles/apache_instance/templates/m7_intraday.conf.j2#L40
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/5e337f1526a4cabd60d532371d8c414f7834b01d/inventory/m7t/vars.yml#L18

2.) Same is existing for backend *core* and *enq*: 
{code:java}
ldap.hostname=m7shrdprodldp1,m7shrdprodldp2
ldap.port=636,636
{code}


3.) For *Rabbitmq* we need to change the ports:
{code:java}
rabbitmq@m7eltsprodamq1:[/elts/elts-prod-amq1/etc/rabbitmq]$ vim rabbitmq.config
    {rabbitmq_auth_backend_ldap,
        [
            {servers,
                [""m7shrdprodldp1"",""m7shrdprodldp2""]
            },
            {port,389},
            {timeout, 5000 },
            {user_dn_pattern, ""uid=${username},ou=prod,ou=elts-app,o=M7,dc=energy,dc=prod""},
            {resource_access_query,
                {for,
{code}

ansible role, which might be needed to change the port from 389 to 636
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/fbb7400d68bfc2e4293701e318b539854828e479/roles/rabbitmq_instance/templates/3.5.x/rabbitmq.config.j2#L89

{code:java}
rabbitmq@m7eltsprodamq1:[/elts/elts-prod-amq1/etc/rabbitmq]$ telnet m7shrdprodldp1 636
Trying 10.139.53.193...
Connected to m7shrdprodldp1.
Escape character is '^]'.
{code}

################################

trying to enable ssl for rabbitmq in systemtest1 by next week
{code:java}
  {rabbitmq_auth_backend_ldap, [
     {servers, [""m7shrdinteldp1"", ""m7shrdinteldp2""]},
     {port,    636}
     {use_ssl,     true},
     {ssl_options, [{fail_if_no_peer_cert, true}]}
   ]}
{code}
https://www.rabbitmq.com/ldap.html#ldap-tls

UPDATE: 04/05/21 double checked it with [~cv179] FYI: [~ne232]
So far we found no solution to enable TLS for our current rabbitmq setup. 
{code:java}
TLS client: In state hello received SERVER ALERT: Fatal - Handshake Failure
LDAP network traffic: Connect: ""ldap.server"" failed {error,{tls_alert,""handshake failure""}}
{code}

we end up with the following error, described here: 
https://github.com/rabbitmq/rabbitmq-server/issues/1651

We will try it again, ones we are deploying a newer version ","05/May/21 12:10;cs687;*Apache to Backend (AJP and HTTP):*

after researching possibilities to encrypt ajp-connections, I found out the following: 
{code:java}
When using AJP you cannot do anything to ensure it is secure. It isn't. There is no SSL version. You would have to use HTTPS. AJP is designed for the usual case where HTTPD and Tomcat are in the same private LAN and security isn't an issue.
{code}
https://stackoverflow.com/questions/12460422/how-do-ensure-that-apache-ajp-to-tomcat-connection-is-secure-encrypted

https://liferay.dev/blogs/-/blogs/tomcat-9-0-31-ghostcat-and-ajp
{code:java}
 AJP is thought of as dangerous, thus it needs to be enabled explicitly. It's dangerous if your AJP port is open to the world - e.g. if third-party webservers could connect to it: They'll have quite some power of tricking tomcat into believing in the request that's coming. This is also the reason why ""just enabling it"" won't be enough, but you'll need to configure the mentioned ""secret"" as non-null, non-blank string. Notice also that AJP is totally and utterly unencrypted - cleartext (well clearbinary) by design. If you require encryption on that connection, consider going https - or establish a tunnel or VPN between the servers. I love AJP, due to the features that David already mentioned. It'll just be even more work once tomcat comes ""secure by design"". By the way, this change is also incorporated into tomcat 8.5.51 and 7.0.100
{code}

+*so properly the action would be to change ajp connector to https*+
{code:java}
cat /shrd/m7t-elts-asim-app-web1/config/conf.d/m7_intraday.conf
......
    RedirectMatch ^/(?!server-status)$ /intraday/
        <Proxy balancer://cluster>
         BalancerMember  ajp://m7eltsasimm7b1:8009 loadfactor=1 keepalive=On route=elts-asim-app1
         BalancerMember  ajp://m7eltsasimm7b2:8009 status=+H keepalive=On route=elts-asim-app2
{code}

the same for reporting engine
{code:java}
    RedirectMatch ^/(?!server-status)$ /reporting-engine-app/
     <Proxy balancer://cluster>
         BalancerMember  http://m7shrdexterep1:62260 loadfactor=1 keepalive=On route=elts-asim-rep1
         BalancerMember  http://m7shrdexterep2:62260 status=+H keepalive=On route=elts-asim-rep2
{code}
","05/May/21 14:22;pd122;Alternatively one could tunnel the connection (e.g. via ssh) but unless the  bandwidth is an issue, https seems like a better option to me.","06/May/21 10:03;nn481;I see https as a good option. Only concern I have is perfomance penalty. It should be ensured that it is somehow evaluated.","11/May/21 09:14;vp223;Propose test:
* Login
* Send message (switch tab)
* System halt/unhalt
* Switch to user management (loading different page)
* Click create a user and set up rights
[~nn481] can you have a look that it make sense in the scope of this ticket?","17/May/21 16:18;cs687;*Final test for Apache to Backend (AJP)*

we have to prepare a pull-request to add a new additional tomcat connector 
{code:java}
    <Connector port=""8443"" protocol=""HTTP/1.1"" SSLEnabled=""true""
               maxThreads=""150"" scheme=""https"" secure=""true""
               clientAuth=""false"" sslProtocol=""TLS""
               keystoreType=""PKCS12""
               keystoreFile=""/home/tomcat/62511884_.deutsche-boerse.de.p12""
               keystorePass=""xxx""
    />
{code}

and also some required apache config changes: 
{code:java}
    SSLProxyEngine on
    SSLProxyVerify none
    SSLProxyCheckPeerCN off
    SSLProxyCheckPeerName off
        <Proxy balancer://cluster>
         BalancerMember  https://m7tenrgsyt2m7b2:8443 loadfactor=1 keepalive=On route=shrd-syt2-apa2
         BalancerMember  https://m7tenrgsyt2m7b1:8443 status=+H keepalive=On route=shrd-syt2-apa1

{code}


and have to create p12 keystore file with the following commands, afterwards it can be stored in /home/tomcat on the m7b hosts (or somewhere else): 
{code:java}
openssl pkcs12 -export -in 62511884_.deutsche-boerse.de.cert -inkey 62511884_.deutsche-boerse.de.key -out 62511884_.deutsche-boerse.de.p12 -CAfile deutsche-boerse.de.crt -name tomcat -caname root
{code}

p12 can be listed like this 
{code:java}
openssl pkcs12 -info -in 62511884_.deutsche-boerse.de.p12 -nodes
{code}

[~vp223] has to run the test above and compare it with the previous results and in graphana we checking intraday metrics in the next days as well


we did the tests also in SYT1 and we did not find anything suspicious. https://grafana.energy.svc.dbgcloud.io/d/FmQ9WC8Gz/java-statsd-enq?orgId=2&var-host=m7tenrgsyt1m7b1%20-%20tomcat%20-%20m7_shrd_syt1&var-host=m7tenrgsyt1m7b2%20-%20tomcat%20-%20m7_shrd_syt1&var-client=shrd&var-client_env=syt1&var-group=All&var-interval=30s&from=1621175579486&to=1621348379487

ticket can be closed","18/May/21 16:40;cs687;done","19/May/21 11:34;vp223;For the testing there was used 2 methods: 
# Audit from dev tool (https://developers.google.com/web/tools/lighthouse) the metrics are described here: https://web.dev/performance-scoring/
# Performence recoded dev tool here previous mention test was performed 

*Results*
For Audit, there is a huge difference where the performance score went from 57-44 to 14 ( [^Before_AuditMainPage.html]  and  [^AFTER_SYT1_AuditMainPage.html] )
Regarding the Performance recording test the values were 457 ms before the change and 368 ms after the change ( [^Before_PerfStats.json] and  [^After_SYT1_PerfStats.json] ) 

It would be nice if [~nn481] and [~cs687] can also provide their inside into the results :)","20/May/21 12:51;nn481;Perfstats do not show any major perf degradation. There was not observed any perf degradation. So I think we can say that SSL does not have any visible impact on perf as expected.",,,,,,,,,,,,
Disrupt connection between M7 and XBID 09.03.2021 at 15:15 on CTPB and re-establish it later on,M7P-7927,107677,107665,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,nz893,nn236,nn236,08/Mar/21 13:38,10/Mar/21 11:18,16/Sep/21 14:11,09/Mar/21 15:53,,7tops_sprint112,,,,,,,,M7PRODOPS,,,,,,,"Tomorrow (09.03.2021) on CTPB environment a test of the fix for M7P-7589 is being performed with EPEX. As a part of the test, we need TechOps to run scripts to ungracefully disrupt the connection with XBID on CTPB environment and later on, put the connection back up.

*09.03.2021 at 15:15*: run the scripts for ungraceful disruption between M7 and XBID on the *CTPB* environment

*09.03.2021shortly after 15:15,* *upon confirmation from the Development**:* run scripts to put connection back up between M7 and XBID on *CTPB* environment.",,cs687,nn236,nz893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16416000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzgqf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 112 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107677,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Mar/21 14:37;cs687;hi [~nn236], explained [~nz893] the steps and he will do the action from our side. 
I will stay as standby in case he needs me.

cheers.","08/Mar/21 14:41;nn236;Hi [~cs687], [~nz893] Thanks to you both!","09/Mar/21 15:45;nz893;I did have some issues related to execution of the playbook due to missing ssh password.

 
{noformat}
[nz893adm@enprodauto1 {master L | ✔} ~/git]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit ""m7t-elts-ctpb-cor*"" --tags block -k -K -b
SSH password:  [ERROR]: User interrupted execution{noformat}
 

Then I realize I don't need one, so I executed the requested distributed connection on CTPB environment:

 
{noformat}
[nz893adm@enprodauto1 {master L | ✔} ~/git]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit ""m7t-elts-ctpb-cor*"" --tags block -bPLAY [block SOB connection] *****************************************************************************************************************************************************************************************************************TASK [Gathering Facts] **********************************************************************************************************************************************************************************************************************
ok: [m7t-elts-ctpb-cor2]
ok: [m7t-elts-ctpb-cor1]TASK [debug] ********************************************************************************************************************************************************************************************************************************
ok: [m7t-elts-ctpb-cor1] => (item=m7shrdexteprx1:55460) => {}MSG:/sbin/iptables -A INPUT -s m7shrdexteprx1 -j DROPok: [m7t-elts-ctpb-cor1] => (item=m7shrdexteprx2:55460) => {}MSG:/sbin/iptables -A INPUT -s m7shrdexteprx2 -j DROPok: [m7t-elts-ctpb-cor2] => (item=m7shrdexteprx1:55460) => {}MSG:/sbin/iptables -A INPUT -s m7shrdexteprx1 -j DROPok: [m7t-elts-ctpb-cor2] => (item=m7shrdexteprx2:55460) => {}MSG:/sbin/iptables -A INPUT -s m7shrdexteprx2 -j DROP
TASK [block sob] ****************************************************************************************************************************************************************************************************************************
changed: [m7t-elts-ctpb-cor1] => (item=m7shrdexteprx1:55460)
changed: [m7t-elts-ctpb-cor2] => (item=m7shrdexteprx1:55460)
changed: [m7t-elts-ctpb-cor1] => (item=m7shrdexteprx2:55460)
changed: [m7t-elts-ctpb-cor2] => (item=m7shrdexteprx2:55460)PLAY RECAP **********************************************************************************************************************************************************************************************************************************
m7t-elts-ctpb-cor1         : ok=3    changed=1    unreachable=0    failed=0
m7t-elts-ctpb-cor2         : ok=3    changed=1    unreachable=0    failed=0{noformat}
with result: 
{noformat}
[nz893adm@m7eltsctpbm7b2 ~]$ date Tue Mar 9 15:30:10 CET 2021
[nz893adm@m7eltsctpbm7b2 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""components"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""ping"":{""status"":""UP""},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}
[nz893adm@m7eltsctpbm7b2 ~]${noformat}

{noformat}
 
  

 ","09/Mar/21 15:50;nz893;after another request I re-establish it using: 

{noformat}
[nz893adm@enprodauto1 {master L | ✔} ~/git]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit ""m7t-elts-ctpb-cor*"" --tags flush -b

PLAY [block SOB connection] *****************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************************************************
ok: [m7t-elts-ctpb-cor2]
ok: [m7t-elts-ctpb-cor1]

TASK [debug] ********************************************************************************************************************************************************************************************************************************
ok: [m7t-elts-ctpb-cor1] => {}

MSG:

/sbin/iptables -F

ok: [m7t-elts-ctpb-cor2] => {}

MSG:

/sbin/iptables -F


TASK [flush iptables] ***********************************************************************************************************************************************************************************************************************
changed: [m7t-elts-ctpb-cor2]
changed: [m7t-elts-ctpb-cor1]

PLAY RECAP **********************************************************************************************************************************************************************************************************************************
m7t-elts-ctpb-cor1         : ok=3    changed=1    unreachable=0    failed=0
m7t-elts-ctpb-cor2         : ok=3    changed=1    unreachable=0    failed=0

[nz893adm@enprodauto1 {master L | ✔} ~/git]$
{noformat}

with result:


{noformat}
[nz893adm@m7eltsctpbm7b2 ~]$ date
Tue Mar  9 15:33:36 CET 2021
[nz893adm@m7eltsctpbm7b2 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""components"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""ping"":{""status"":""UP""},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[nz893adm@m7eltsctpbm7b2 ~]$
[nz893adm@m7eltsctpbm7b2 ~]$
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,
Enhance reporter alerting,M7P-7913,107555,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,HO764,HO764,05/Mar/21 09:59,26/Mar/21 10:57,16/Sep/21 14:11,23/Mar/21 12:24,,6.11.217,7tops_sprint113,,,Monitoring,,,,7tops_comm,,,,,,,"Enhance alerting introduced in M7P-7692 by checking for message

No offset found for ... and ...

If this message is in the logs too often, it is worth noticing - indicates some problem with kafka.

 

Also, introduce alerting for

Order creation timestamp not available, orderId=..., revision=..., using revision creation time ... instead

Any occurrence of this error means a problem, so alert even with a single instance of this message.",,HO764,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Created watcher alert for reporter cleaning order offset.,,,,,,,,,,,,,,,,,,,,,,,,15033600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz89z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107555,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"23/Mar/21 10:05;iu252;Created new watcher (offset): https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1242

Deployed watcher: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Elasticsearch%20Watcher%20Alerts/10/console

{noformat}
TASK [elasticsearch-setup : Watcher alert for reporter cleaning order offset] ***
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
{noformat}
","23/Mar/21 10:39;iu252;[~HO764] pls create a new ticket for another watcher:

{noformat}
Also, introduce alerting for

Order creation timestamp not available, orderId=..., revision=..., using revision creation time ... instead

Any occurrence of this error means a problem, so alert even with a single instance of this message.
{noformat}
","23/Mar/21 10:40;iu252;[~HO764] please check out the watcher message in m7_alerts:

watcherAPP  10:38 AM
Reporter Cleaning Order Offset alert
Encountered 6 Reporter error(s) in the last 5 minutes. 
*m7tshrdinterep2*m7_shrd_ate4* - 2021-03-23T09:34:53.803Z 
2021-03-23T10:40:49.523Z [amqReqExec-7] WARN  ""No offset found for {abc} and {xyz}"". [<?xml version=""1.0"" encoding=""UTF-8""?>
*m7tshrdinterep2*m7_shrd_ate4* - 2021-03-23T09:36:03.795Z 
2021-03-23T10:40:49.523Z [amqReqExec-7] WARN  ""No offset found for {abc} and {xyz}"". [<?xml version=""1.0"" encoding=""UTF-8""?>
 Show more","23/Mar/21 12:24;iu252;Created watcher alert for reporter cleaning order offset.","26/Mar/21 10:57;HO764;Just for the record, the second alert for

Order creation timestamp not available, orderId=..., revision=..., using revision creation time ... instead

is no longer needed. It was not created inside this jira, so there is no longer the need to report it as a new jira.",,,,,,,,,,,,,,,,,,,,,,,
Deactivating not-required database-backups (non-prod env´s) ,M7P-7911,107548,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,nz893,cs687,cs687,05/Mar/21 09:14,08/Sep/21 15:18,16/Sep/21 14:11,,,,,,,Database,,,,7tops,,,,,,,"Like we discussed in our OPS-Meeting 04.03.2021 
we are gonna to deactivate for our internal test database environments the archiving process and the fully/incremental backup trigger. 

_*the following env´s could be deactivated*_ to reduce the load on nbu-servers, and besides that the main reason for that is, that we are backup-ing pretty to much which is not even necessary based on the contracts. 

{code:java}
M7A:
- m7a-shrd-syt1-pdb-sync
- m7a-shrd-syt2-pdb-sync

M7C:
- m7c-shrd-ate1-pdb-async
- m7c-shrd-ate5-pdb-async

M7T:
- m7t-shrd-ate1-pdb-async
- m7t-shrd-ate2-pdb-async
- m7t-shrd-ate3-pdb-async
- m7t-shrd-ate4-pdb-async
- m7t-shrd-ate5-pdb-async
- m7t-shrd-syt1-pdb-async --> already deactivated 
- m7t-shrd-syt2-pdb-async
- m7t-shrd-syt3-pdb-async

XBID:
- xb-xbid-perf-edb
- xb-xbid-perf-pdb-async
- xb-xbid-perf-pdb-sync
- xb-xbid-syt1-pdb-async
- xb-xbid-syt1-pdb-sync
- xb-xbid-syt3-pdb-async
- xb-xbid-syt3-pdb-sync
- xb-xbid-syt2-pdb1
{code}

the main idea was:
* create a jenkins job which will trigger a backup for all (non-prod database env´s)
* store the compressed backup files on a shared host like ebsm or on the db-host itself 
* in case something breaks down, we are able to restore the data for that time when the backup were done. 

which steps need to be done, for deactivating the backup: 
1.) edit the live config of the patroni-nodes 
{code:java}
patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml edit-config
{code}
2.) replace archive_command with following and save it
{code:java}
archive_command: /usr/bin/true
{code}
3.) in case of reverting the change, we can just look it up how the previous archive_command looked like in file ""/etc/patroni_m7tshrdsyt1async/config.yml""
4.) also restricted the env in the jenkins jobs with the pattern !m7t-shrd-syt1*
* https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/job/Start%20Full%20Backup%20All/
* https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/job/Start%20Incremental%20Backup%20All/",,cs687,nz893,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-7955,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16243200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzg1j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":107548,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"08/Mar/21 14:17;nz893;With [~cs687] we deactivated backups as describe above for M7T and M7C and also XBID instances.","11/Mar/21 14:43;nz893;I deactivated backups for m7a-shrd-syt[12]-pdb-sync too",,,,,,,,,,,,,,,,,,,,,,,,,,
"users cannot login ELTS ASIM CT after ""renaming""",M7P-7836,107102,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,wn626,wn626,wn626,23/Feb/21 10:58,10/Mar/21 11:18,16/Sep/21 14:11,26/Feb/21 13:03,,6.11.210,7tops_sprint112,,,LDAP,,,,M7PRODOPS,,,,,,,"Some of the users getting following error and not able to connect to CT:

!image-2021-02-23-10-56-15-885.png!

 

User examples:

CXEAMI01

CXZNSP05

CXLTOM09

CXLTOM15 (recently created user)

CXNSPE07 (recently created user)

 

User who can successfully connect:

CXFGTI04 

CXENQX01

CXENQX02

 

Maybe issue is affecting all newly created users",,pd122,wn626,,,,,,,,,,,,,,,,,,SERVICE-6348,,,,,,,,,,,,,,,,,,,,"23/Feb/21 10:56;wn626;image-2021-02-23-10-56-15-885.png;https://jira.deutsche-boerse.com/secure/attachment/93171/image-2021-02-23-10-56-15-885.png",,,,,,,,,,,,,,,sw455,,,,,,,," 
 ProxyPass /elts-app-asim balancer://newctpcluster/profile-storage
 ProxyPassReverse /elts-app-asim  balancer://newctpcluster/profile-storage",,,,,,,,ELTS,,,,,,Request for New Environment,,,,,,,,,,17452800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,23/Feb/21 10:58,,[],,,,,,,,None,,,M7T,,,,"2|hzzdlb:",9223372036854775807,,,,No,,,,,,,,,,Missed 1 line configuration for LDAP,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NA,,,,,,,,,,"{""issueId"":107102,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"23/Feb/21 12:19;pd122;CXEAMI01:
[23/Feb/2021:11:36:18.115627401 +0100] conn=109355 op=5 BIND dn=""uid=CXEAMI01,ou=asim,ou=epex-app,o=M7,dc=energy,dc=test"" method=128 version=3
[23/Feb/2021:11:36:18.121491665 +0100] conn=109355 op=5 RESULT err=49 tag=97 nentries=0 etime=0.006046773 - Invalid credentials

CXZNSP05:
[23/Feb/2021:09:15:13.309031122 +0100] conn=107761 op=84933 BIND dn=""uid=CXZNSP05,ou=asim,ou=elts-app,o=M7,dc=energy,dc=test"" method=128 version=3
[23/Feb/2021:09:15:13.316375589 +0100] conn=107761 op=84933 RESULT err=49 tag=97 nentries=0 etime=0.007426916 - Invalid credentials

CXLTOM09:
no BIND request for this user in the logs

CXLTOM15:
I can see the user was created yesterday afternoon, but no authentication attempt n the logs

CXNSPE07 :
ditto","23/Feb/21 12:31;pd122;I can see that our profile web servers still point to old LDAP tree for ELTS ASIM  profiles:


{code:java}
<Location /elts-app-asim/>
            AuthType            Basic
            AuthBasicProvider       ldap
            AuthName          ""Secured Area: CTP ASIM EPEX ""
            AuthLDAPUrl     ""ldaps://m7shrdsimuldp1:636 m7shrdsimuldp2:636/ou=asim,ou=epex-app,o=M7,dc=energy,dc=test?uid""
            Require               valid-user
            Order deny,allow
            Satisfy any
            Deny from all
            Allow from env=noauth
 </Location>
{code}


Perhaps that would explain at least some of the issues we're seeing.
","23/Feb/21 12:59;pd122;PR https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/750 created to fix.  [~fh971], can you, have a look and verify there's nothing else to change, pls?","23/Feb/21 16:59;wn626;we changed the configuration:
AuthLDAPUrl     ""ldaps://m7shrdsimuldp1:636 m7shrdsimuldp2:636/ou=asim,ou=epex-app,o=M7,dc=energy,dc=test?uid""
to:
AuthLDAPUrl     ""ldaps://m7shrdsimuldp1:636 m7shrdsimuldp2:636/ou=asim,ou=elts-app,o=M7,dc=energy,dc=test?uid""
 
Looks like it fixes the issue. I'm asking EPEX to check from their side","26/Feb/21 13:03;wn626;https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/750/files",,,,,,,,,,,,,,,,,,,,,,,
"Migration ELTS ASIM and error ""Login was refused using authentication mechanism PLAIN""",M7P-7827,107048,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,wn626,wn626,wn626,22/Feb/21 10:45,10/Mar/21 11:18,16/Sep/21 14:11,26/Feb/21 13:01,,7tops_sprint112,,,,LDAP,,,,M7PRODOPS,,,,,,,"A lot of users are not able to login to ELTS ASIM after ""renaming"".

Error message:

""System.Exception: Authentication failed for Login to EPEX. Please check username and password! ---> RabbitMQ.Client.Exceptions.AuthenticationFailureException: ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.
 at RabbitMQ.Client.Framing.Impl.Connection.StartAndTune()
 at RabbitMQ.Client.Framing.Impl.Connection.Open(Boolean insist)
 at RabbitMQ.Client.Framing.Impl.AutorecoveringConnection.Init(IFrameHandler fh)
 at RabbitMQ.Client.ConnectionFactory.CreateConnection(IEndpointResolver endpointResolver, String clientProvidedName)""

 

Most of the issues can be resolved via password reset, but we want to know the root cause.

 

Example of affected users:

CXZNSP05
CXFISF02
CXSTSP01

 ",,pd122,wn626,,,,,,,,,,,,,,,,,,SERVICE-6348,,,,,,,,,,,,,,,,,,,,"22/Feb/21 13:12;wn626;image-2021-02-22-13-12-40-533.png;https://jira.deutsche-boerse.com/secure/attachment/93130/image-2021-02-22-13-12-40-533.png",,,,,,,,,,,,,,,sw455,,,,,,,,"nothing was changed, decided to leave it as it is",,,,,,,,ELTS,,,,,,Request for New Environment,,,,,,,,,,17452800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,22/Feb/21 10:45,,[],,,,,,,,None,,,M7T,,,,"2|hzzdcv:",9223372036854775807,,,,No,,,,,,,,,,LDAP data were exported and imported as of date 28/9/2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,NA,,,,,,,,,,"{""issueId"":107048,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"22/Feb/21 12:49;pd122;Password policy in effect for ELTS ASIM users:

{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
passwordMaxFailure: 5
passwordResetFailureCount: 600
passwordLockout: on
passwordStorageScheme: ssha
passwordChange: on
passwordMinAge: 0
passwordExp: off
passwordMustChange: off
cn: cn=nsPwPolicyEntry,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
{code}
","22/Feb/21 12:57;pd122;There's no requirement to change passwords in that policy.  Must have been invalid password provided/set.","22/Feb/21 13:12;wn626;User CXEAMI01 is not able to login to CT after the password reset. I tested it by myself, can you please check the user?

 

Error message:

!image-2021-02-22-13-12-40-533.png!","22/Feb/21 13:44;wn626;Same issue with CXZNSP05 and CXLTOM09. I cannot login to CT after password reset.

[~pd122], is it something we can check or it should go to DEVs?","23/Feb/21 09:58;pd122;Re CXEAMI01, it would seem this user has been *created * 22/2/2021:1227 CET by ELTS ASIM LDAP admin account (from within the app), with a new password:

{code:java}
time: 20210222112709
dn: uid=CXEAMI01,ou=asim,ou=elts-app,o=M7,dc=energy,dc=test
result: 0
changetype: add
objectClass: inetOrgPerson
objectClass: organizationalPerson
objectClass: person
objectClass: top
cn: trader
sn: trader
uid: CXEAMI01
creatorsName: uid=elts-app-asim-adm,ou=asim,ou=elts-app,o=m7,dc=energy,dc=test
modifiersName: uid=elts-app-asim-adm,ou=asim,ou=elts-app,o=m7,dc=energy,dc=test
createTimestamp: 20210222102709Z
modifyTimestamp: 20210222102709Z

time: 20210222112709
dn: uid=CXEAMI01,ou=asim,ou=elts-app,o=M7,dc=energy,dc=test
result: 0
changetype: modify
replace: userpassword
userpassword:: e1NTSEF9U3VyaXlqcCtrN3U1V2lBWVpidHYyUVZ6SXArM1B0VW9za3g1WWc9PQ==
-
replace: modifiersname
modifiersname: cn=server,cn=plugins,cn=config
-
replace: modifytimestamp
modifytimestamp: 20210222102709Z
-

time: 20210222112709
dn: uid=CXEAMI01,ou=asim,ou=elts-app,o=M7,dc=energy,dc=test
result: 0
changetype: modify
replace: passwordRetryCount
passwordRetryCount: 0
-
replace: passwordgraceusertime
passwordgraceusertime: 0
{code}","23/Feb/21 10:16;wn626;[~pd122], I did a password reset for CXEAMI01 right now at 10:14, and at 10:15 I'm not able to login CT (error as on screenshot)","23/Feb/21 10:20;wn626;EPEX reported about 2 more users with this issue: CXLTOM15 and CXNSPE07.

It's becoming major, possibly all newly created users are affected","23/Feb/21 11:00;wn626;Let's separate 2 issues:

M7P-7827 - is raised for issue with error message ""Login was refused using authentication mechanism PLAIN"". Which appear after migration

M7P-7836 - is raised for issue with some users who cannot login to CT after password reset","23/Feb/21 11:32;pd122;Note: The LDAP data were exported and imported on 28/9/2020, so (depending on the date the environment has been handed over to the customer) it may not be what customers expect...  That would possibly explain some incorrect logging attempts (forcing password resets).","26/Feb/21 13:01;wn626;LDAP data were exported and imported as of date 28/9/2020",,,,,,,,,,,,,,,,,,
Patroni Increase wal_keep_segments config,M7P-7814,106979,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,sw455,sw455,19/Feb/21 10:01,25/May/21 23:39,16/Sep/21 14:11,01/Mar/21 13:36,,11.0.0,7tops_sprint112,,,Database,,,,7tops_comm,Database,M7PRODOPS,S/M,,,,"[~hw120] worked with Cybertec to address an issues on patroni instances getting stuck during initialization. Ultimately the suggestion was to increase the value for the WAL_KEEP_SEGMENTS configuration from the default (9) to at least 200 (might need to be larger for instances like ELTS Prod). At 200 the resulting size is something around ~3gb, so the change should be fine per storage concerns.

Should be done on all patroni instances.

 
 * Update patroni deployment to set *wal_keep_segments: 200*
 * Change can then be applied online to running instances as needed 

{code:java}
sudo su - patronictl -c /etc/patroni_[%NODE]/config.yml edit-config
{code}
 * Check hosts' config to make sure it was applied

{code:java}
ssh [host]
sudo su - patronictl -c /etc/patroni_[%NODE]/config.yml edit-config
su - postgres
psql -p 25101
postgres=# SELECT * FROM pg_settings WHERE name = 'wal_keep_segments';
{code}
 

 

??Peter's discussion with Cybertec, for reference??
{quote}Hello, We had problem with some patroni replica instances when I stopped and then started patroni service, they got stuck in ""starting"" state and I had to reinit those nodes.
 In logs, postgres was complaining about missing wal files.
 Is it known problem? (PostgreSQL 12.4, Patroni 1.6.5)
 16:50
 Julian Markwort The primary regularly discards old WAL files that it no longer needs...
 Patroni can use replication slots to let the primary know that a replica still needs some WAL to catch up, but this might not be enabled in your environment.
 16:51
 Kaarel Moppel Yes, sounds like the most common replication problem at all :slightly_smiling_face: [https://stackoverflow.com/questions/47645487/postgres-streaming-replication-error-requested-wal-segment-has-already-been-rem]
 16:51
 by default Postgres doesn't reserve any extra WAL for replication purposes
 16:51
 Julian Markwort could it simply be that the replica was already lagging quite a bit behind or that the stop and start took quite a while?
 16:53
 I think most of your patroni clusters are configured with no replication slots and only a few hundred wal_keep_segments...
 wal_keep_segments tells the primary to keep at least that many WAL files, even if it does not need them any more.
 17:13
 Peter Pruchnerovic:house_with_garden: no, before the stop operation, it was all in sync, 0 lag
 17:14
 We did more extensive test where we were stopping and starting multiple instances of 4 node cluster. End state was only one node running.
 17:14
 No problem on sync cluster, only on async one.
 17:24
 Peter Pruchnerovic:house_with_garden: We have set wall_keep_segments = '8'
 17:26
 What parameters should I configure and on which nodes? Should Leader have something different in the config? What if Leader goes to another server?
 17:27
 Julian Markwort it really only makes sense to define wal_keep_segments for all hosts, i.e. in ""dynamic config"", using patronictl edit-config (or appropriate http requests)
 17:28
 wal_keep_segments = '8' is way too low, I would say. depending on your settings, 8 WAL switches are very quickly reached even with almost IDLE load on the database
 17:28
 one WAL segment is 16MB...so it is usually no issue to keep 100 or 200 of them around
 17:45
 Julian Markwort another possible solution that I've brought up a few times already is to use a proper WAL archive that can be accessible to all cluster members...
 This would mean that the primary does not need to keep any more WAL than it really needs or that the replication slots dictate that it must.
 If the replicas fall far behind, they can simply ask the WAL archive to give them the necessary files and catch up.Additionally, a WAL archive usually goes hand-in-hand with backups and you can have PITR (point in time recovery) to any point in between backups, as long as you have the WAL segments that where produced in the meantime between backups
 17:55
 Peter Pruchnerovic:house_with_garden: Interesting, but it would mean to have large and fast NAS storage and mounted single filesystem to all nodes, right?
 18:06
 Andriy Nazarenko fast and NAS - oxymoron
 18:06
 Julian Markwort The WAL archive only needs to be able to keep up with WAL creation on average...
 A high latency e.g. Is not a big issue when dealing with WAL archive
 18:24
 Andriy Nazarenko but what happens when network connection breaks between wal archive and real wal / actual DB host?
 18:24
 if we are discussing NAS (shared storage) option for WAL archive
 18:25
 or worse, NFS is known to ""lock up"" entire IO on the NFS client, if the NFS server unexpectedly goes away.
 18:38
 Julian Markwort when wal archiving is properly configured, files are only deleted if
 - they are no longer needed by the primary for crash recovery
 - they are no longer needed to satify replication slots (if those are enabled)
 - the archive command ran successfully (usually a test ""is the file already archived?"" and the copying of the file itself)

that means an indefinitely broken connection to the archive will lead to the primary never deleting WAL and filling its disk, unless the archive_command is temporarily changed to something like /bin/true, which of course renders the archive unusable for catching up or doing PITR but at least allows the primary to continue running.
 18:39
 any temporary issues are handled by archive_command simply through retrying until the command returns success
 18:42
 instead of NFS directly mounted into all cluster members, I would rather suggest to use a proper tool for this purpose, like pgBackRest.
 That can take care of validating the chain of WAL on the replica for completeness and it can validate the checksum of the WAL files before returning to the caller.
 Additionally, it's very easy to setup pgBackRest so that it can only be pushed to and pulled from, not deleted from the outside. And further, pgBackRest does not allow overwriting of existing WAL files...
 18:47
 Julian Markwort if you'd like to we can discuss this more in-depth at some point...
 We could probably replace the backup system that is breaking more often than we'd all like to in the same sweep :)
 19:10
 Peter Pruchnerovic:house_with_garden: Thanks @Julian Markwort for your help, I will increase wal_keep_segments to 200.
{quote}",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"patroni role updated with the proper parameter ""wal_keep_segements""
* deployed it in test/simu/prod cluster 
* no outage no issues detected 

",,,,,,,,,,,,,,,,,,,,,,,,17107200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz89j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":106979,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Mar/21 08:07;cs687;For m7testpdb1/2 it was handled on friday the 26.02.2021 *2:58 PM*
by [~cv179]

For m7simupdb1/2/3/4 its planned today 1.3.2021
Same for Production happened","01/Mar/21 13:36;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
ICSC PROD - cmm-web log rotation/deletion,M7P-7812,106974,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,fj021,fj021,19/Feb/21 08:45,21/Apr/21 09:03,16/Sep/21 14:11,09/Mar/21 11:15,,7tops_sprint112,,,,apache,,,,7tops_comm,M,,,,,,"h2. Context

Thread at the origin of this ticket : [https://dbg-devops.slack.com/archives/GKBT41X8W/p1613030321074600]

Issue on *ICSC PROD* since the launch of *6.8 on 26.01*, we are having a lot more error logs (separate ticket to figure out why) and it put into light the fact that we don't compress the error logs during rotation nor cleanup the logs and they can bloat up the server.

 
{code:java}
[root@m7shrdprodweb1 ~]# du -sh /shrd/logs/m7c-icsc-prod-cmm-web1/*
12K     /shrd/logs/m7c-icsc-prod-cmm-web1/error_log
176M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_portal_standard-cron_ixe.log
25M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-26_00.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-27_00.log
7.0M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-27_22.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-28_00.log
19M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-28_19.log
93M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-29_00.log
88M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-30_00.log
67M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-01-31_00.log
79M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-01_00.log
61M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-02_00.log
70M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-03_00.log
70M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-04_00.log
63M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-05_00.log
61M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-06_00.log
53M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-07_00.log
54M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-08_00.log
72M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-09_00.log
68M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-10_00.log
17M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_access_ixe_2021-02-11_00.log
53M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-26_00.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-27_00.log
46M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-27_17.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-28_00.log
65M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-28_14.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-29_00.log
40M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-29_17.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-30_00.log
35M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-30_17.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-31_00.log
24M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-01-31_19.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-01_00.log
5.9M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-01_22.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-02_00.log
14M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-02_21.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-03_00.log
21M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-03_19.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-04_00.log
28M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-04_19.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-05_00.log
12M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-05_21.log
89M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-06_00.log
84M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-07_00.log
95M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-08_00.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-09_00.log
8.4M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-09_22.log
101M    /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-10_00.log
12M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-10_21.log
34M     /shrd/logs/m7c-icsc-prod-cmm-web1/m7c_icsc_prod_web-app-1_error_ixe_2021-02-11_00.log
{code}

{code:java}
[root@m7shrdprodweb1 ~]# df -h /shrd/logs/
Filesystem                       Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_shrd_logs  4.0G  3.6G  215M  95% /shrd/logs
{code}


h2. Task

Check and improve log rotation and deletion on m7shrdprodweb1:/shrd/logs/m7c-icsc-prod-cmm-web1/ it shouldn't be able to bloat the server this way.",,cs687,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9913,M7P-7813,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"* discussion with customer is ongoing to avoid/stop the log flooding with the connection bot
* deployed the compress.sh script with changing the apache config in ate1 - which proofed everything is working 
* pull-request for capacity and trading to compress the logfiles 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1418
* hand over to BO, to plan in the next days an apache deployment for capacity icsc-cute/prod",,,,,,,,,,,,,,,,,,,,,,,,16502400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzz893:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,,see description and comments ,,,,,,,,,,"{""issueId"":106974,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"23/Feb/21 09:05;iu252;Other hosts are also affected:

{noformat}
WARNING on m7shrdprodweb5 | Mount: /shrd/logs - used: 86% - 5.1 GB/6.3 GB Used/Total
{noformat}



{noformat}
[root@m7shrdprodweb5 logs]# du -hs * | grep G
4.4G    m7c-icsc-prod-cmm-web5
[root@m7shrdprodweb5 logs]#

[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# df -h /shrd/logs/
Filesystem                       Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_shrd_logs  5.9G  4.8G  858M  86% /shrd/logs
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]#
{noformat}
","01/Mar/21 10:45;fj021;Hello hello, I'm working on related M7P-7813. While looking into it found a few things that might helps on this one, so might as well post them here.
h3. Rotation

We already have apache rotation in place ([link to said config|https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/7314b25d232b9ab44083ba0cda2b22288b8c15cc/roles/m7c_apache/templates/m7c.conf.j2#L29]), but we might benefit from compressing those rotated logs.

A solution for that could be [the following|https://serverfault.com/questions/343776/how-to-gzip-logs-created-by-rotatelogs] :

Editing this line of ours :
{code:java}
	ErrorLog ""|/usr/sbin/rotatelogs  /shrd/logs/\{{ apache_instancename }}/\{{ apache_energy_area }}_\{{ apache_customer }}_\{{ apache_env }}_web-\{{ apache_component }}-\{{ apache_instancenum }}_error_\{{ apache_location }}_%Y-%m-%d_%H.log 86400 100M""
{code}
into
{code:java}
	ErrorLog ""|/usr/sbin/rotatelogs -p /<path_to_compresser>/compress.sh  /shrd/logs/\{{ apache_instancename }}/\{{ apache_energy_area }}_\{{ apache_customer }}_\{{ apache_env }}_web-\{{ apache_component }}-\{{ apache_instancenum }}_error_\{{ apache_location }}_%Y-%m-%d_%H.log 86400 100M""
{code}
and adding this script to apache role :
 _compress.sh_
{code:java}
#!/bin/bash
file_to_compress=""${2}""
compress_exit_code=0if [[ ""${file_to_compress}"" ]]; then
    echo ""Compressing ${file_to_compress} ...""
    tar --gzip --create --file --remove-files ""${file_to_compress}.tar.gz"" ""${file_to_compress}""    compress_exit_code=${?}    if [[ ${compress_exit_code} == 0 ]]; then
        echo ""File ${file_to_compress} was compressed.""
    else
        echo ""Error compressing file ${file_to_compress} (tar exit code: ${compress_exit_code}).""
    fi
fiexit ${compress_exit_code}
{code}
h3. Deletion

This one is (if I'm not mistaken) linked to an issue I noticed during investigation, those logs aren't transferred to EBSM, which also mean that they are not cleaned up (since it's done by the same process, transfer -> cleanup)

So transfer of those logs (daily) would completely fix our bloating situation.","02/Mar/21 13:46;cs687;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1406
provided fix from [~fj021], we deployed it on m7shrdexteweb1 for cmi and app apache instances and so far so good.

posted error-logs, like these one suddenly stopped 
{code:java}
[Tue Mar 02 13:38:03.286711 2021] [access_compat:error] [pid 17612] [client 127.0.0.1:58250] AH01797: client denied by server configuration: /var/www/html/server-status
[Tue Mar 02 13:38:32.099380 2021] [access_compat:error] [pid 487] [client 127.0.0.1:58462] AH01797: client denied by server configuration: /var/www/html/server-status
{code}

successfully server-status is also visible in access logfiles 
{code:java}
localhost - - [02/Mar/2021:13:44:02 +0100] ""GET /server-status?auto HTTP/1.1"" 200 408
localhost - - [02/Mar/2021:13:44:34 +0100] ""GET /server-status?auto HTTP/1.1"" 200 409
-rw-r--r-- 1 apache apache 131666 Mar  2 13:45 m7c_icsc_cute_web-app-1_access_ixe_2021-03-02_00.log
{code}

this might be the fix for the flooding error loglines. 


UPDATE:
also changed it for *m7shrdexteweb2*
We will leave it running until it goes finally to production. ","02/Mar/21 15:56;cs687;about the topic to compress and cleanup the apache logfiles like access & error logfiles we will discuss this week in the ops-meeting 04.02.2021
Martin M. clarified that we need to store the logfiles for *a six-month period, starting with the creation of any such log file.*

so idea would be to
* in general compress the log files which are mentioned above, like with prepared solution from [~fj021]
* and store the logfiles locally on the host itself and clean it up with an cronjob, at least the files which are older then 6 month 
* or alternative to upload it to ebsm 

*will discuss that in the meeting and come back with an update.*
*{color:red}UPDATE: 04.03.2021 - outcome from the meeting{color}*
* compressing of log-files makes totally sense and we should try it out 
* configuring cronjob when not already existing in /etc/cron.d/clean_webserver_logfiles 
{code:java}
#Ansible: clean webserver-logfiles
30 5 * * * root /usr/bin/find /*/logs/*web*/ -name ""*.log*"" -type f -mtime +4 -exec rm {} \;
{code}
","03/Mar/21 09:33;cs687;It happened again clients are flooding our logfiles for cmm this time m7shrdprodweb5
{code:java}
WARNING on m7shrdprodweb5 | Mount: /shrd/logs - used: 86% - 5.1 GB/6.3 GB Used/Total
{code}

{code:java}
4.4G    /shrd/logs/m7c-icsc-prod-cmm-web5
{code}

In comments above there are already some solution provided, 
like compressing the logfiles, uploading them to ebsm or keep it on host itself and delete/clean it up it after 6 month, what the contract is requiring from us.

Anyways this will not solve the problem at all! 
I collected now a top list of client connections of a time term +*of (soon) one month 10.02 - 3.3.2021*+

{code:java}
* 91.223.193.34
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""91.223.193.34"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
126971

* 2.109.67.222
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""2.109.67.222"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
835340

* 91.228.114.1
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""91.228.114.1"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
432950

* 185.30.132.97
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""185.30.132.97"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
115936

* 194.56.48.107
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""194.56.48.107"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
10260

* 195.47.211.8
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""195.47.211.8"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
173415

* 158.140.150.243
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""158.140.150.243"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
70283

* 91.232.232.180
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""91.232.232.180"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
256400

* 165.225.95.49
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""165.225.95.49"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
127375

* 86.188.199.50
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""86.188.199.50"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
625998

* 194.56.219.114
[root@m7shrdprodweb5 m7c-icsc-prod-cmm-web5]# grep ""194.56.219.114"" m7c_icsc_prod_web-app-5_error_ixe_2021-0* | wc -l
286920
{code}

For us it seems like this mostly happening during night on all shared web-servers around midnight and 1/2am.
Looks like it is caused with a client bot which tries to connect to https://www.intraday-capacity.com/m7c/pages/allocation/overview.faces & https://prod1.ics.m7c.deutsche-boerse.com/m7c/pages/allocation/overview.faces

Hand it over to BO to contact the clients and ask them kindly for the reason and maybe if they can stop it. 

compressed the access/error files
{code:java}
tar -zcvf m7c_icsc_prod_web-app-5_access_ixe_2021-02.tar.gz m7c_icsc_prod_web-app-5_access_ixe_2021-02-*
{code}
","05/Mar/21 09:56;cs687;activated the compressing script in m7c-shrd-ate1-app-web1, m7c-shrd-ate1-cmi-web1, m7c-shrd-ate1-cmm-web1
Script is located in /shrd/prodscripts/

*ls -all /shrd/logs/m7c-shrd-ate1-app-web1/*
{code:java}
-rw-r--r--  1 apache apache    572 Mar  4 10:47 error_log
-rw-r--r--  1 apache apache 539891 Mar  5 00:59 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache 181460 Mar  5 09:47 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache 587493 Mar  4 17:50 m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-04_00.log
{code}

*ls -all /shrd/logs/m7c-shrd-ate1-cmi-web1/*
{code:java}
-rw-r--r--  1 apache apache    572 Mar  3 15:08 error_log
-rw-r--r--  1 apache apache 101652 Mar  4 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-03_00.log
-rw-r--r--  1 apache apache 260450 Mar  5 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache  90902 Mar  5 09:48 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache    376 Mar  3 15:08 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-03_00.log
-rw-r--r--  1 apache apache   4596 Mar  4 14:56 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-04_00.log
{code}

*ls -all /shrd/logs/m7c-shrd-ate1-cmm-web1/*
{code:java}
-rw-r--r--  1 apache apache 101652 Mar  4 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-03_00.log
-rw-r--r--  1 apache apache 542271 Mar  5 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache 328474 Mar  5 09:48 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache    376 Mar  3 15:08 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-03_00.log
-rw-r--r--  1 apache apache 646336 Mar  5 00:59 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache 559815 Mar  5 09:48 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-05_00.log
{code}

changed this line in m7c.conf for the 3 apache configs and restarted the apaches on m7tshrdinteweb1
{code:java}
ErrorLog ""|/usr/sbin/rotatelogs -p /shrd/prodscripts/compress.sh /shrd/logs/m7c-shrd-ate1-app-web1/m7c_shrd_ate1_web-apa-1_error_ixe_%Y-%m-%d_%H.log 86400 100M""
{code}


*UPDATE:*

removed --remove-file from the script which caused an error.
triggered the scripted after the lately changes and it could confirm with [~fj021]that it is working fine. 

{code:java}
-bash-4.2$ /shrd/prodscripts/compress.sh 0 /shrd/logs/m7c-shrd-ate1-app-web1/m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-04_00.log
Compressing /shrd/logs/m7c-shrd-ate1-app-web1/m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-04_00.log ...
tar: Removing leading `/' from member names
File /shrd/logs/m7c-shrd-ate1-app-web1/m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-04_00.log was compressed.

-rw-r--r--  1 apache apache   1254 Mar  5 09:58 error_log
-rw-r--r--  1 apache apache 539891 Mar  5 00:59 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache 495360 Mar  6 00:59 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache 495360 Mar  7 00:59 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-06_00.log
-rw-r--r--  1 apache apache 495360 Mar  8 00:59 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-07_00.log
-rw-r--r--  1 apache apache 168904 Mar  8 09:10 m7c_shrd_ate1_web-apa-1_access_ixe_2021-03-08_00.log
-rw-r--r--  1 apache apache  26277 Mar  8 09:08 m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-04_00.log.tar.gz
-rw-r--r--  1 apache apache    378 Mar  5 09:58 m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache    320 Mar  8 09:04 m7c_shrd_ate1_web-apa-1_error_ixe_2021-03-05_00.log.tar.gz
{code}

new script version: 
{code:java}
...
tar --gzip --create --file ""${file_to_compress}.tar.gz"" ""${file_to_compress}""
....
{code}

We will keep running it until tomorrow and then activate it for m7c-cute and later on for production once it is finally merged in the ansible role. 
","09/Mar/21 08:21;cs687;{color:red}*End-Result:* {color}

m7c-shrd-ate1-cmm-web1 rotated and compressed the logfile from yesterday, the other apps were not producing new logfiles 
creating pull-request to deploy it everywhere, where it makes sense. 

{code:java}
m7c-shrd-ate1-cmm-web1:
total 9924
drwxr-xr-x  2 apache apache    4096 Mar  9 05:30 .
drwxr-xr-x 19 apache apache    4096 Mar  3 15:08 ..
-rw-r--r--  1 apache apache    2034 Mar  9 01:00 error_log
-rw-r--r--  1 apache apache  542271 Mar  5 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache  888942 Mar  6 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache  886407 Mar  7 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-06_00.log
-rw-r--r--  1 apache apache  886015 Mar  8 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-07_00.log
-rw-r--r--  1 apache apache  886446 Mar  9 00:59 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-08_00.log
-rw-r--r--  1 apache apache  269466 Mar  9 08:17 m7c_shrd_ate1_web-app-1_access_ixe_2021-03-09_00.log
-rw-r--r--  1 apache apache  646336 Mar  5 00:59 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-04_00.log
-rw-r--r--  1 apache apache 1515673 Mar  6 00:59 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-05_00.log
-rw-r--r--  1 apache apache 1510554 Mar  7 00:59 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-06_00.log
-rw-r--r--  1 apache apache 1510554 Mar  8 00:59 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-07_00.log
-rw-r--r--  1 apache apache   77041 Mar  9 01:00 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-08_00.log.tar.gz
-rw-r--r--  1 apache apache  459330 Mar  9 08:17 m7c_shrd_ate1_web-app-1_error_ixe_2021-03-09_00.log
{code}

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1418/files

*deployed ate1 with the new changes, also added the compress.sh script to the CustomLog (access-logs)*
{code:java}
ansible-playbook playbooks/deploy_m7c_apache.yml --limit ""m7c-shrd-ate1-app-web1:m7c-shrd-ate1-cmi-web1:m7c-shrd-ate1-cmm-web1"" --tags deploy -k -K -b -C
....
TASK [m7c_apache : Check if compress script exists] **********************************************************************************************************
ok: [m7c-shrd-ate1-app-web1]
ok: [m7c-shrd-ate1-cmi-web1]
ok: [m7c-shrd-ate1-cmm-web1]
TASK [m7c_apache : Create prodscript directory if not exists] ************************************************************************************************
skipping: [m7c-shrd-ate1-app-web1]
skipping: [m7c-shrd-ate1-cmi-web1]
skipping: [m7c-shrd-ate1-cmm-web1]
TASK [m7c_apache : copy script compress.sh] ******************************************************************************************************************
changed: [m7c-shrd-ate1-app-web1]
changed: [m7c-shrd-ate1-cmi-web1]
changed: [m7c-shrd-ate1-cmm-web1]

{code}
","09/Mar/21 11:15;cs687;done",,,,,,,,,,,,,,,,,,,,
Renew Server Certificates for PLPX-LIPA,M7P-7791,106748,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,15/Feb/21 07:01,10/Mar/21 11:18,16/Sep/21 14:11,01/Mar/21 13:34,,6.11.210,7tops_sprint112,,,infrastructure,,,08/Mar/21 00:00,7tops_comm,Certificates,M7PRODOPS,S,,,,"For PLPX LIPA the server Certificates will expire on 24 March 2021 

Therefore we need to request new Certificates for both URLS and renew them:
{code:java}
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            f7:94:a4:81:ca:4d:c8:1b:bb:ec:2f:ef:d0:33:2c:99
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Mar 25 00:00:00 2019 GMT
            Not After : Mar 24 23:59:59 2021 GMT
{code}
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,renewed the certificates and restarted HAproxy and Apache,,,,,,,,TGE,,,,,,,,,,,,,,,,17107200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8bb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,,,,,,,,,,,,,,,,,,,,,,,,,,see description and comments,,,,,,,,,,"{""issueId"":106748,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,LIPA,,,,"25/Feb/21 08:15;cs687;1.) 
* triggered the jenkins job *""A. Generate CSR (Ansible Deployment) #generate_csr_m7t_plpx_lipa""*
* following secret items are existing in vault 
** Request_lipa1.tge.m7.deutsche-boerse.com
** Request_lipa2.tge.m7.deutsche-boerse.com

creating the IT SERVICE Approval Ticket with the ID: *7B3161* and sending out the mail to ssl-admins


","01/Mar/21 08:25;cs687;2.) 

* new certs were generated by SSL-Admin team 
* triggered job ""*Project B. Import Cert to Vault (Ansible Deployment)*""

next step rolling out the new certs and restart HA/APACHE with an proper SERVICE-Ticket

*+backup-ed +*the current certificates in */tmp/plpx-old-cert/*","01/Mar/21 08:49;cs687;3.) 

* renewed certificates with the following commands:
** ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*plpx-lipa-app-web*"" --tags certs -k -K -b
** ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*plpx-lipa-app-haproxy*"" --tags certs -k -K -b

validating the results: 
APACHE:
{code:java}
-rw-r-----  1 apache apache 1.7K Mar  1 08:46 lipa1.tge.m7.deutsche-boerse.com_key.pem
-rw-r-----  1 apache apache 1.8K Mar  1 08:46 lipa1.tge.m7.deutsche-boerse.com_chain.pem
-rw-r-----  1 apache apache 2.8K Mar  1 08:46 lipa1.tge.m7.deutsche-boerse.com_cert.pem
{code}

{code:java}
[root@m7shrdexteweb1 ssl]# openssl x509 -in lipa1.tge.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0b:5e:5e:e3:71:fa:57:e2:8d:45:61:31:36:16:ea:27
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1
        Validity
            Not Before: Feb 26 00:00:00 2021 GMT
            Not After : Mar  2 23:59:59 2022 GMT
{code}

HA:
{code:java}
[root@m7shrdextessl1 plpx-lipa-app-haproxy1]# openssl x509 -in server.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0b:5e:5e:e3:71:fa:57:e2:8d:45:61:31:36:16:ea:27
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1
        Validity
            Not Before: Feb 26 00:00:00 2021 GMT
            Not After : Mar  2 23:59:59 2022 GMT
{code}


","01/Mar/21 08:50;cs687;4.)  last step: we need to restart apache and haproxy app´s, that the new certs will be finally used

stopped & started app´s
* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t-plpx-lipa-app-haproxy*"" --tags stop,start -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t-plpx-lipa-app-web*"" --tags stop,start -k -K -b","01/Mar/21 13:34;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
Renew Server Certificates for PLPX-SIMU ,M7P-7790,106747,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,15/Feb/21 06:59,10/Mar/21 11:18,16/Sep/21 14:11,01/Mar/21 13:35,,6.11.210,7tops_sprint112,,,infrastructure,,,08/Mar/21 00:00,7tops_comm,Certificates,M7PRODOPS,S,,,,"For PLPX SIMU the server Certificates will expire on 24 March 2021 

Therefore we need to request new Certificates for both URLS and renew them:
{code:java}
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            b1:06:28:65:0d:cf:c6:37:d7:f3:c9:db:77:c9:be:52
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Mar 25 00:00:00 2019 GMT
            Not After : Mar 24 23:59:59 2021 GMT
{code}
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,renewed the certificates and restarted HAproxy and Apache,,,,,,,,TGE,,,,,,,,,,,,,,,,17107200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8b3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,,,,,,,,,,,,,,,,,,,,,,,,,,see description and comments,1.0,,,,,,,,,"{""issueId"":106747,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"25/Feb/21 08:20;cs687;1.) 
* triggered the jenkins job *""A. Generate CSR (Ansible Deployment) #generate_csr_m7t_plpx_simu""*
* following secret items are existing in vault 
** Request_simu1.tge.m7.deutsche-boerse.com
** Request_simu2.tge.m7.deutsche-boerse.com

creating the IT SERVICE Approval Ticket with the ID: *7B3162* and sending out the mail to ssl-admins
","01/Mar/21 08:51;cs687;2.)

* new certs were generated by SSL-Admin team
* triggered job ""Project B. Import Cert to Vault (Ansible Deployment)""
next step rolling out the new certs and restart HA/APACHE with an proper SERVICE-Ticket

+backup-ed +*the current certificates in */tmp/plpx-old-cert/*","01/Mar/21 08:58;cs687;3.) 

* renewed certificates with the following commands:
** ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*plpx-simu-app-web*"" --tags certs -k -K -b
** ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*plpx-simu-app-haproxy*"" --tags certs -k -K -b

validating the results: 
APACHE:
{code:java}
-rw-r-----  1 apache apache 1.7K Mar  1 08:54 simu1.tge.m7.deutsche-boerse.com_key.pem   
-rw-r-----  1 apache apache 1.8K Mar  1 08:54 simu1.tge.m7.deutsche-boerse.com_chain.pem 
-rw-r-----  1 apache apache 2.8K Mar  1 08:54 simu1.tge.m7.deutsche-boerse.com_cert.pem  
{code}

{code:java}
[root@m7shrdexteweb1 ssl]# openssl x509 -in simu1.tge.m7.deutsche-boerse.com_cert.pem -noout -text         
Certificate:                                                                                               
    Data:                                                                                                  
        Version: 3 (0x2)                                                                                   
        Serial Number:                                                                                     
            06:ef:7a:1d:30:6c:5b:bc:2b:34:33:98:2d:ea:2a:39                                                
    Signature Algorithm: sha256WithRSAEncryption                                                           
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1                                  
        Validity                                                                                           
            Not Before: Feb 26 00:00:00 2021 GMT                                                           
            Not After : Mar  2 23:59:59 2022 GMT                                                           
{code}

HA:
{code:java}
[root@m7shrdextessl1 plpx-simu-app-haproxy1]# openssl x509 -in server.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            06:ef:7a:1d:30:6c:5b:bc:2b:34:33:98:2d:ea:2a:39
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=US, O=DigiCert Inc, CN=DigiCert TLS RSA SHA256 2020 CA1
        Validity
            Not Before: Feb 26 00:00:00 2021 GMT
            Not After : Mar  2 23:59:59 2022 GMT
{code}","01/Mar/21 08:59;cs687;4.) last step: we need to restart apache and haproxy app´s, that the new certs will be finally used","01/Mar/21 13:35;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
Changing Stalker message-log's directory/FS,M7P-7782,106664,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,fj021,fj021,11/Feb/21 12:04,09/Aug/21 14:51,16/Sep/21 14:11,,,,,,,Stalker,,,,7tops,M,M7PRODOPS,,,,,"h2. Context

Currently we have two types of logs coming from Stalker :
 * *Message logs*, coming from M7 (Stalker's ""job"") : Stored in /<customer>/message-logs/<instance_name>. Which is in application FS (everything in /<customer/ except /<customer>/logs . Those logs are also sent directly to ElasticSearch using its API (not using filebeat)
 * *Stalker's logs*, logs coming from Stalker itself (startup, errors in processing etc...) : Stored in /<customer>/logs/<instance_name> like every other application's logs.

 Issue here is that we're bloating the application FS with logs. Usually those don't really get extended.
h2. Task

This PR would change where the logs are stored : [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1378]

 

Before merging it we would need to :
 * Check if current /<customer>/logs FS is big enough to sustain current size of message-logs from Stalker. If not extend it on all environment. 
 * Ensure that filebeat won't consume message-logs but will keep consuming application's log. (Since message-logs are sent directly to elastic already, with different info/fields than ""normal logs"")
 * Ensure that cleanup/transfer to EBSM will be done on those logs once moved

 
h2. Additional information

This topic came about after discussion with [~iu252] so if more information is needed you can reach out to him or myself. ",,fj021,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8031,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8294400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:r",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106664,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-7782,,true,"04/Mar/21 15:41;jenkins;Commits related to this ticket are merged into released acceptance increment (6.10.285), but the field {{Change Description}} is empty, so fixed verions was not set to this ticket and is not in the the changelog. 
 
PLEASE VERIFY AND FIX BOTH *CHANGELOG* AND *FIX VERSION* MANUALLY!

Link to increment build: https://englobjci1.deutsche-boerse.de/job/Energy/job/m7-product-sprint-increment%20-%20acceptance%20and%20hotfix/80/ 

Related commits:
 https://github.deutsche-boerse.de/dev/m7.h2h4u/commit/6b520ae3d4660d87d81c37e676756b6589f58cc1 
https://github.deutsche-boerse.de/dev/m7.h2h4u/commit/d5f342548007d3863f2d458d8a6df0c08eb18c7a 
","04/Mar/21 15:43;jv861;Ignore commetn above - there was a typo in commit message","28/Apr/21 11:07;jenkins;Commits related to this ticket are merged into released hotfix increment (6.10.294), but the field {{Change Description}} is empty, so fixed verions was not set to this ticket and is not in the the changelog. 
 
PLEASE VERIFY AND FIX BOTH *CHANGE DESCRIPTION* AND *FIX VERSION* MANUALLY AND GENERATE UPDATED CHANGELOG!

For detailed instructions, see https://confluence.energy.svc.dbgcloud.io/display/M7T/Issue+handling#Issuehandling-slack-warning 

Link to increment build: https://englobjci1.deutsche-boerse.de/job/Energy/job/m7-product-sprint-increment%20-%20acceptance%20and%20hotfix/99/ 

Related commits:
 https://github.deutsche-boerse.de/dev/m7.h2h4u/commit/6b520ae3d4660d87d81c37e676756b6589f58cc1 
https://github.deutsche-boerse.de/dev/m7.h2h4u/commit/d5f342548007d3863f2d458d8a6df0c08eb18c7a 
","28/Apr/21 11:09;jv861;^ same typo, different branch","11/Jun/21 15:01;fj021;Raised priority to Major (at least) after discussing with [~xt853] that, rightfully so, pointed that because of this EBSM doesn't save the logs, so we only have ""long"" historic for truncated messages (Elastic) but not for complete messages (Disk) which can be problematic.

FYI [~pn508]",,,,,,,,,,,,,,,,,,,,,,,
prepare input for MTT double sided deployment ,M7P-7780,106656,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,11/Feb/21 10:56,25/Aug/21 11:25,16/Sep/21 14:11,,,,,,,,,,,7tops,7tops_comm,,,,,,"*Background*

MTT is running as single instance at the moment

*Constrain*

Consul readiness was resolved

 
{code:java}
Roman Krewer I think consul is ready in prod for almost 2 years...  ... patroni uses it. but before we talk about prod, we should have mtt with consul in test, no? {code}
 https://jira.deutsche-boerse.com/browse/TECHLOG-1999

*Todo*

1) *Product team* Prepare input of what is needed to do for 
 * HUPX SIMU
 * HUPX ASIM
 * HUPX CUTE
 * ELTS LIPA
 * ELTS SIMU
 * SHRD DST

to deploy MTT double sided (PRs)

2) Product team request Pavel Rehak to  deploy MTT based on instructions from (1) to all above listed environments

3) Pavel Rehak make sure that once (2) is successfully completed, we prepare PRs also for ELTS PROD and HUPX PROD

4) explicitly let [~hw120]  to review  

*Comment from Milos Gregor*

also, please involve [@kamil.ondrak|https://dbg-devops.slack.com/team/U4K61TL1Z] since he was dealing with that topic on dev side",,pw231,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-8803,M7P-7364,SERVICE-9844,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17712000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwrg:js",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106656,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"23/Feb/21 10:32;pw231;findings from Arch CoP:
- we can and will reuse the consuls used for patroni (they are shared among all products and envs)
- @7tops/[~hw120] to decide on the tree structure (suggestion : copy inventory)
- @7tops to configure mtt and deploy to shrd, then cutes",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: PROD - TC540 - EPEX - Report not available,M7P-7762,106519,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,cs687,dp007,dp007,10/Feb/21 09:37,24/Feb/21 11:26,16/Sep/21 14:11,12/Feb/21 14:15,,6.11.196,7tops_sprint111,,,Database,RE,,,M7PRODOPS,,,,,,,"Dear DBAG,

The TC540 report for EPEX has not been generated for trading day 09.02.2021. It is critical to EPEX processes to retrieve and integrate this report in a timely manner. Therefore we would like to request that the report be generated as soon as possible.

Kind regards,
Matteo",,cs687,dp007,,,,,,,,,,,,,,,,,,SERVICE-9731,,,,,,,,,,,,,,,,,,,,"12/Feb/21 13:46;cs687;m7proddbr1.png;https://jira.deutsche-boerse.com/secure/attachment/92797/m7proddbr1.png","12/Feb/21 14:13;cs687;m7simudbr1.png;https://jira.deutsche-boerse.com/secure/attachment/92799/m7simudbr1.png",,,,,,,,,,,,,,sw455,,,,,,,,"* changed shared_buffers for replica in the patroni ansible role 
* changed the setting on the cluster configuration on the hosts m7simu/proddbr1/2 
* reloaded the changes and restarted the nodes to update DCS 
* reboot the hosts itself",,,,,,,,EPEX,,,,,,Report a Non-Critical Incident,,,,,,,,,,18576000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,Communication -> Customer,10/Feb/21 04:24,,[],,,,,,,,None,,,M7T,,,,"2|hzz8bj:",9223372036854775807,,,,No,,,,,,,,,,"issue solved, 
reduced the shared_buffers for all the db-cluster which are running on m7simudbr1/2 and m7proddbr1/2, from 2GB default -> to 1GB 

",,,,,,,,7tops Sprint 111,,,,,,,,,,,,,,,,,,,,,,,,,,see change description ,,,,,,,,,,"{""issueId"":106519,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"10/Feb/21 10:27;cs687;Reports crahsed during memory issue on m7prodbr1/2 hosts 

postgres logs: 
{code:java}
<time=2021-02-10 01:55:03.118 CET user= db= host= pid=81604 > LOG:  temporary file: path ""base/pgsql_tmp/pgsql_tmp81604.0"", size 47538176
<time=2021-02-10 01:55:03.143 CET user=uapp01m7teltsprodrep db=m7teltsprodm7b host=10.139.53.249 pid=66672 > ERROR:  out of memory
<time=2021-02-10 01:55:03.143 CET user=uapp01m7teltsprodrep db=m7teltsprodm7b host=10.139.53.249 pid=66672 > DETAIL:  Failed on request of size 7787928 in memory context ""TupleSort main"".

<time=2021-02-10 01:55:03.154 CET user= db= host= pid=87134 > LOG:  background worker ""parallel worker"" (PID 81604) exited with exit code 1
<time=2021-02-10 01:55:03.186 CET user= db= host= pid=87134 > LOG:  background worker ""parallel worker"" (PID 81603) exited with exit code 1
{code}

the statement was the following: 
{code:java}
<time=2021-02-10 01:55:03.144 CET user= db= host= pid=81603 > STATEMENT:  SELECT orderHistory.REV as orderHistoryId, orderHistory.ORDER_ID as orderId,orderHistory.INITIAL_ORDER_ID as initialOrderId, orderHistory.PARENT_ID as parentOrderId, orderHistory.PRE_AOT_ID as preAotId, orderHistory.LAST_UPDATE_TIME as lastUpdateTime, orderHistory.BALANCING_GROUP_EIC as traderBgEic,orderHistory.ACTION as modificationType,contractHistory.PRODUCT_LONG_NAME as productLongName,product.PRODUCT_DISPLAY_NAME as productDisplayName,product.CURRENCY_CODE as currencyCode,product.DECIMAL_SHIFT_COMMODITY as decimalShiftCommodity,product.DECIMAL_SHIFT_PRICE as decimalShiftPrice,balancingGroup.MEMBER_ID as memberId,orderHistory.USER_CODE as traderId,orderHistory.EXECUTION_PRICE as priceCent,orderHistory.VERSION as version,orderHistory.CONTRACT_ID as contractId,DELIVERY_STARTDATE as contractStartDate,DELIVERY_ENDDATE as contractEndDate,orderHistory.TSO_AREA_EIC as tsoEicAreaCode,orderHistory.BUY_CODE as buy,orderHistory.QUANTITY as quantity,orderHistory.TEXT as text,orderHistory.LAST_UPDATE_USER as lastUpdateUser,contractHistory.LONG_NAME as contractLongName,orderHistory.ACCOUNT as account,orderHistory.RESTRICTION_CODE as restriction,orderHistory.TARGET_BG_EIC as targetBgEicPartyCode,orderHistory.ORDER_ENTRY_TIME as creationTime,orderHistory.ORDER_TYPE_CODE as orderTypeCode,orderHistory.HIDDEN_QUANTITY as hiddenQuantity,orderHistory.PEAK_SIZE_QUANTITY as peakSizeQuantity,orderHistory.VALIDITY_RESTRICTION as validityRestriction,orderHistory.EXPIRATION_DATE as expirationTime,orderHistory.LIST_EXEC_INST as listExecInst,orderHistory.BASKET_ID as basketId,orderHistory.PEAK_PRICE_DELTA as peakPriceDelta,orderHistory.OPEN_CLOSE_IND as openCloseInd,orderHistory.STOP_PRICE as stopPriceCent,orderHistory.BROKER_USER_ID as brokerUserId,orderHistory.MATCHED_PRICE as matchedPrice,orderHistory.AGGR_IND as aggressorIndicator,orderHistory.EXTERNAL_ID as externalId,orderHistory.EXTERNAL_REVISION as externalVersion,orderHistory.AOT_ENABLED as aotEnabled,orderHistory.REMOTE_REVISION_NO_TIME as remoteRevisionNoTime,usr.MEMBER_ID as brokerMemberId,usr.USER_CODE as brokerUserCode,session.APP_ID as applicationId,session.APP_VERSION as applicationVersion from m7teltsprodm7b.cx_101_order_history as orderHistory  join  (  select * from m7teltsprodm7b.cx_211_contract_history as ch WHERE ch.rev IN  ( select max(rev) from m7teltsprodm7b.cx_211_contract_history group by contract_id )  )  contractHistory  on contractHistory.CONTRACT_ID=orderHistory.CONTRACT_ID and contractHistory.PRODUCT_LONG_NAME in ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24, $25, $26, $27, $28, $29, $30, $31, $32, $33, $34, $35, $36, $37, $38, $39, $40, $41, $42, $43, $44) left join m7teltsprodm7b.cx_282_user as usr on usr.USER_ID=orderHistory.BROKER_USER_ID  left join  (  select session_id, max(app_id) as app_id, max(app_version) as app_version from m7teltsprodm7b.cx_296_session_history group by session_id  )  as session on session.SESSION_ID=orderHistory.SESSION_ID , m7teltsprodm7b.cx_200_product as product  , m7teltsprodm7b.cx_270_balancing_group as balancingGroup  where orderHistory.REVTYPE in ($45, $46) and orderHistory.LAST_UPDATE_TIME>=$47 and orderHistory.LAST_UPDATE_TIME<$48  and orderHistory.BALANCING_GROUP_EIC in (select BALANCING_GROUP_EIC from m7teltsprodm7b.cx_270_balancing_group where MEMBER_ID = $49 )  and ORDER_TYPE_CODE in ($50, $51, $52, $53, $54, $55) and orderHistory.ACTION in ($56, $57, $58, $59, $60, $61, $62, $63, $64, $65, $66, $67, $68, $69, $70, $71, $72, $73, $74) and product.PRODUCT_LONG_NAME = contractHistory.PRODUCT_LONG_NAME and balancingGroup.BALANCING_GROUP_EIC = orderHistory.BALANCING_GROUP_EIC and (contractHistory.EXTERNAL_REVISION is null or orderHistory.EXTERNAL_REVISION is not null) order by contractHistory.PRODUCT_LONG_NAME desc, orderHistory.USER_CODE asc, orderHistory.CONTRACT_ID asc, orderHistory.ORDER_ID asc, orderHistory.VERSION asc, orderHistory.LAST_UPDATE_TIME asc, orderHistory.REV asc
{code}

were in a discussion with cybertec and the confirmed that it might be not related to the memory-parameters like work_mem etc. 
its more about the OS memory. 

regarding the monitoring, at least we could see about 20g free (or buffered) memory all the times, 
the most severe visible peak was a growth of ""used"" memory in OS going from 1.8gb to 2.1gb

the failed report was manually triggered again, after repointing RE to pdb3 MASTER again. 
With cybertec we will analyze the root issue in a separate session ","10/Feb/21 12:15;cs687;We run the reports again on m7proddbr1,
it took around 25-30 minutes and finished successfully!

used memory was not higher then 2G
","10/Feb/21 12:52;cs687;Outcome of the meeting!

we will log vmstat output during the night and in case it crashes again, we will have some more info´s about memory behavior.
Ticket will be in waiting. ","10/Feb/21 13:22;dp007;it crashed on the same member EFIEX, the first crash is the ADMIN report, the second crash is when it generated the member's report. Seem potentially like a data related problem.
ADMIN / 00:55:00 UTC
{code}
2021-02-10 00:54:59.588 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.b.AbstractReportBuilder90 - Start creating Market Supervision Report Tc540 for member part 103/534 : EDPEX
2021-02-10 00:55:00.948 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.b.AbstractReportBuilder90 - End   creating Market Supervision Report Tc540 for member part 103/534 : EDPEX
2021-02-10 00:55:00.948 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.b.AbstractReportBuilder90 - Start creating Market Supervision Report Tc540 for member part 104/534 : EFIEX
2021-02-10 00:55:03.210 [schedulerFactory_Worker-1] ERROR c.d.e.r.s.ReportServiceImpl - A problem happened while generating report
com.deutscheboerse.encore.report.service.ReportServiceException: Failed to generate report
	at com.deutscheboerse.encore.report.service.ReportServiceImpl.generateReport(ReportServiceImpl.java:126)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Caused by: javax.persistence.PersistenceException: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:154)
	at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1542)
Caused by: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:47)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
Caused by: org.postgresql.util.PSQLException: ERROR: out of memory
  Detail: Failed on request of size 7787928 in memory context ""TupleSort main"".
  Where: parallel worker
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2532)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2267)
{code} 
 
MEMBER / 01:09:33 UTC
{code}	
2021-02-10 01:09:33.617 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.ReportServiceImpl - Generating report reportTC540 for day 10.02.2021 for member EFIEX and platform elts
2021-02-10 01:09:33.617 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.b.AbstractReportBuilder - Daily Order Maintenance Report for elts has these products [Quarterly_Hour_Power_50Hz, Pre_Trade_Peak_OTC, GB_Baseload, Pre_Trade_Base_OTC, Quarterly_Hour_Power_Amprion, Quarterly_Hour_Power_Tennet, Quarterly_Hour_Power_TransnetBW, Half_Hour_Power_Amprion, Half_Hour_Power_Tennet, Half_Hour_Power_50Hz, Half_Hour_Power_TransnetBW, Intraday_Power_50Hz, Intraday_Power_Tennet, Intraday_Power_TransnetBW, Intraday_Power_Amprion, Intraday_Power_D, Intraday_Quarter_Hour_Power, SEMOpx_Half_Hour_Power, SEMOpx_Baseload, SEMOpx_2_Hour_Power, SEMOpx_8_Hour_Power, SEMOpx_4_Hour_Power, Intraday_Hour_Power, After_Market_Hour_Power_NL, After_Market_Hour_Power_BE, Continuous_Power_Peak, GB_Half_Hour_Power, Half_Hour_Power, GB_Hour_Power, GB_2_Hour_Power, Continuous_Power_Base, GB_4_Hour_Power, GB_Peakload, GB_3_Plus_4, GB_Overnight, GB_Extended_Peak, Hourly_Blocks, Quarterly_Hour_Power, Intraday_Half_Hour_Power, After_Market_Quarter_Hour_Power_BE, XBID_Quarter_Hour_Power, XBID_Hour_Power, After_Market_Quarter_Hour_Power_NL, XBID_Half_Hour_Power]2021-02-10 01:09:35.430 [schedulerFactory_Worker-1] ERROR c.d.e.r.s.ReportServiceImpl - A problem happened while generating report
com.deutscheboerse.encore.report.service.ReportServiceException: Failed to generate report
	at com.deutscheboerse.encore.report.service.ReportServiceImpl.generateReport(ReportServiceImpl.java:126)
	at sun.reflect.GeneratedMethodAccessor262.invoke(Unknown Source)
Caused by: javax.persistence.PersistenceException: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:154)
	at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1542)
Caused by: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:47)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
Caused by: org.postgresql.util.PSQLException: ERROR: out of memory
  Detail: Failed on request of size 7787928 in memory context ""TupleSort main"".
  Where: parallel worker
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2532)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2267)
{code}

But when we generated the admin report in the morning it crashed on a different user: ADGEX
{code}
2021-02-10 07:58:36.454 [schedulerFactory_Worker-1] INFO  c.d.e.r.s.b.AbstractReportBuilder90 - Start creating Market Supervision Report Tc540 for member part 24/534 : ADGEX
2021-02-10 07:58:38.994 [schedulerFactory_Worker-1] ERROR c.d.e.r.s.s.InstantReportGenerationJob - Failed generate report
com.deutscheboerse.encore.report.service.ReportServiceException: Failed to generate report
	at com.deutscheboerse.encore.report.service.ReportServiceImpl.generateReport(ReportServiceImpl.java:126)
	at sun.reflect.GeneratedMethodAccessor262.invoke(Unknown Source)
Caused by: javax.persistence.PersistenceException: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:154)
	at org.hibernate.query.internal.AbstractProducedQuery.list(AbstractProducedQuery.java:1542)
Caused by: org.hibernate.exception.GenericJDBCException: could not extract ResultSet
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:47)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
Caused by: org.postgresql.util.PSQLException: ERROR: out of memory
  Detail: Failed on request of size 3145728 in memory context ""TupleSort main"".
  Where: parallel worker
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2532)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2267)
{code}","11/Feb/21 08:21;cs687;With the usual setup connecting to M7PRODDBR1/2 it were running tonight.
{code:java}
kapacitorAPP  4:00 AM
OK on m7t - elts - prod | M7 ADMIN TC540 report generation
{code}

EDIT: which is not the case, it failed tonight as well!
","11/Feb/21 12:11;cs687;We came to the conclusion that we are going to reduce the shared_buffers on the replica nodes form default 2GB to 1GB 
We also prepare it in advance for Simu-DBR
Just for ELTS-PROD and maybe EPEX-ASIM we keep 2G shared_buffers

gonna prepare a pull-requests for it and change the confi.yml files on the M7PROD/SIMUDBR1/2 hosts.
After reloading the config changes and restarting the nodes we will also reboot the machine itself. 

The memory hickup *+could+* happen because of this lately changes 
{code:java}
[root@m7proddbr1 sysctl.d]# cat 98-db.conf
## Cybertec recommendations

# don't overcommit memory
vm.overcommit_memory = 2

# only commit as much memory as we have RAM
# overcommit_ratio = ( (RAM - swap) / RAM ) * 100
vm.overcommit_ratio = 83

# Minimize swapping
vm.swappiness = 1

# reloading the cahnges 
sysctl -p/etc/sysctl.d/98-db.conf
{code}


FYI: [~cv179]

*necessary changes:*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2540/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1380/files
","11/Feb/21 13:14;cs687;Changed shared_buffers for all the replica nodes on m7proddbr1/2 
and reloaded/restarted the cluster-nodes

after reboot of the hosts we have new committed-memory value:
*before reboot:* 22.83GB
*after reboot:* 13.39GB","12/Feb/21 13:46;cs687;Report was working without any crash!
So the action with reducing the shared_bufferes + reboot helped out. 

 !m7proddbr1.png! ","12/Feb/21 14:13;cs687;also reduced the shared_buffers for m7simudbr1/2

 !m7simudbr1.png! ","12/Feb/21 14:15;cs687;done",,,,,,,,,,,,,,,,,,
Collect the figures for storage - EPEX load of 6/8/10 million OMTs,M7P-7748,106446,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,iu252,iu252,09/Feb/21 11:27,24/Feb/21 11:26,16/Sep/21 14:11,19/Feb/21 10:31,,6.11.205,7tops_sprint111,,,uknown,,,,7tops_comm,M,,,,,,"Please double check the following figures and confirm/adjust them. Check the values against the current CPM ([https://teams.deutsche-boerse.de/sites/sp0232/SP] - Energy/09 Teams/02 Systems Engineering/003 Processes/Capacity and Performance Management Process/Monthly Reporting/Energy whole/January2021/Energy IT CPM January 2021.pdf) and request an increase whenever needed. 

*1) Database storage*

6Mio
 ELTS PROD - to be doubled in comparison to the current state - provide exact target value
 ELTS ASIM - to be doubled in comparison to the current state - provide exact target value

8Mio

6Mio values * 1.33

Please note that the current storage was increased as per https://jira.deutsche-boerse.com/browse/SERVICE-9481, the question is whether it's enough and whether we should invoice EPEX (to be discussed with ACM)

*2) EBSM logs storage - partitions to be checked*

6 Mio
 ELTS PROD - increase to 1.33 TB
 ELTS ASIM - increase to 1.33 TB

8Mio

ELTS PROD - increase to 1.8 TB
 ELTS ASIM - increase to 1.8 TB

*3) EBSM Database storage*

6 Mio

ELTS PROD - increase to 2.25 TB
 ELTS ASIM - increase to 2.25 TB

8 Mio

ELTS PROD - increase to 3 TB
 ELTS ASIM - increase to 3 TB

*4) Stalker logs storage -* [~iu252] please discuss with [~fj021] if you need more details about Stalker

6 Mio
 ELTS PROD - increase to 232.8 GB
 ELTS ASIM - increase to 232.8 GB

8 Mio

ELTS PROD - increase to 310 GB
 ELTS ASIM - increase to 310 GB

*5) Grafana/Kibana - EC2 instances*

6 Mio
 ELTS PROD - increase to 40 GB
 ELTS ASIM - increase to 40 GB
 SystemTest 1 - increase to 40 GB

8 Mio

ELTS PROD - increase to 54 GB
 ELTS ASIM - increase to 54 GB
 SystemTest 1 - increase to 54 GB

*6) Elastic -  EC2 instances(?)*

6 Mio

overall increase to 23.6 TB

8 Mio

overall increase to 31.2 TB

*7) NetBackups*

6 Mio
 ELTS PROD - to be doubled

By (ideally) the end of April 2021

8 Mio

ELTS PROD - to be increased by a factor of 2.66 (2 * 1.33)

By (ideally) the end of September 2021 - to be confirmed, please do not contact netbackups team",,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,figures provided,,,,,,,,ELTS,,,,,,,,,,,,,,,,18403200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8br:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 111,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106446,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"12/Feb/21 07:19;iu252;*1) Database storage*

The current situation on ELTS PROD is:


{noformat}
[iu252@m7prodpdb3 ~]$ df -h | grep elts| grep data
/dev/mapper/datavg-lv_pgsql_m7teltsprodasync_data    1.1T  338G  789G  30% /var/lib/pgsql_m7teltsprodasync/data

{noformat}

After disk extension we are in comfortable position:

{noformat}
[root@m7prodpdb3 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2  35   0 wz--n-   <4.37t  <2.45t
[root@m7prodpdb3 ~]#

[root@m7prodpdb4 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2  35   0 wz--n-   <4.37t   2.55t
[root@m7prodpdb4 ~]#

[root@m7prodpdb2 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2  32   0 wz--n-   <4.37t   2.67t
[root@m7prodpdb2 ~]#

[root@m7prodpdb1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   1  35   0 wz--n-   <1.46t  <5.80g
[root@m7prodpdb1 ~]#
{noformat}


Disk extension on pdb1 is not done yet:
https://jira.deutsche-boerse.com/browse/SYSENGINT-51
01.02.2021
Important note by Lambert Neky
At this date is not processed the only host:
m7prodpdb1
Waiting for suitable downtime occasion, host will be processed and new disks will be implemented according to demand.


EPEX ASIM looks also good enough:


{noformat}
[root@m7simupdb1 ~]# df -h | grep epexasim

/dev/mapper/datavg-lv_pgsql_m7tepexasimasync_data    200G  117G   84G  59% /var/lib/pgsql_m7tepexasimasync/data
[root@m7simupdb1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2 106   0 wz--n-   <4.37t   3.17t
[root@m7simupdb1 ~]#

[root@m7simupdb2 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2 105   0 wz--n-   <4.37t  <3.23t
[root@m7simupdb2 ~]#

[root@m7simupdb3 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2 105   0 wz--n-   <4.37t   3.18t
[root@m7simupdb3 ~]#

[root@m7simupdb4 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   2 105   0 wz--n-   <4.37t  <3.23t
 [root@m7simupdb4 ~]#
{noformat}
","12/Feb/21 09:28;iu252;*2) EBSM logs storage*
*3) EBSM Database storage*
Confirmed Martin's estimation!","12/Feb/21 09:30;iu252;*4) Stalker logs storage*

Current situation 

*PROD:*


{noformat}
[root@m7shrdprodstk1 ~]# df -h /shrd/logs/
Filesystem                       Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_shrd_logs  976M  2.8M  906M   1% /shrd/logs
[root@m7shrdprodstk1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize  VFree
  rootvg   2   7   0 wz--n- 64.50g <4.93g
[root@m7shrdprodstk1 ~]#
{noformat}


*Disc extension needed! Additional 300 GB.*


*ASIM:*


{noformat}
[root@m7shrdextestk1 ~]# df -h /shrd/logs
Filesystem                       Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_shrd_logs  976M   95M  815M  11% /shrd/logs
[root@m7shrdextestk1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   7   0 wz--n- <99.51g <40.93g
[root@m7shrdextestk1 ~]#
{noformat}


*Disc extension needed! Additional 300 GB.*","12/Feb/21 09:40;iu252;*5) Kibana Logs*

Last year we added 2 TB to each data node (we have 8 data nodes) for existing data.
Our expectation is that we will  buy additional 2 TB for each data node (*8 x 2 TB*) with higher load.

*Cost estimation*
We are using gp2 EBS storage type.
According to AWS pricing (https://aws.amazon.com/ebs/pricing/):
{noformat}
General Purpose SSD (gp2) Volumes	$0.119 per GB-month of provisioned storage
{noformat}
","12/Feb/21 09:50;iu252;*6) Elastic -  EC2 instances*

The current situation is: https://kibana.energy.svc.dbgcloud.io/app/monitoring#/elasticsearch/nodes?_g=h@1caae07
Memory consumption is more critical part here.

In case we will reach heap/memory/cpu usage, we have to increase instance size from m4.2xlarge to m4.4xlarge for data nodes (we have 8 nodes).

According to AWS pricing:
{noformat}
m4.2xlarge	8	26	32 GiB	EBS Only	$0.61 per Hour
m4.4xlarge	16	53.5	64 GiB	EBS Only	$1.09 per Hour
{noformat}
","15/Feb/21 11:36;iu252;*2) EBSM logs storage*

6 Mio
 ELTS PROD - additional storage 1.33 TB
 ELTS ASIM - additional storage 1.33 TB

8Mio

ELTS PROD - additional storage 1.8 TB
 ELTS ASIM - additional storage 1.8 TB
",,,,,,,,,,,,,,,,,,,,,,
Kafka - request necessery FWs,M7P-7747,106444,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,09/Feb/21 11:13,24/Mar/21 11:26,16/Sep/21 14:11,22/Mar/21 08:32,,6.11.217,7tops_sprint113,,,Reporter,,,,M7PRODOPS,S,,,,,,"SYSENGINT-307 Kafka - cluster for SHARED SIMU

SYSENGINT-305 Kafka - cluster for ELTS PROD

SYSENGINT-306 Kafka - cluster for ELTS ASIM

SYSENGINT-308 Kafka - cluster for SHARED INTERNAL TEST

SYSENGINT-309 Kafka - cluster for internal systemtest1/pre-prod

 

In above listed tickets we are requesting VMs for all Kafka clusters.

todo:
 * As part of this ticket specify and request all necesery FWs

*A Kafka Cluster requires following ports to be open:*
 - External (client) communication: 9092
 - Internal kafka communication (intra-node):
 ** brokers among each other: 9092
 ** zookeepers among each other: 2888, 3888
 ** brokers vs zookeepers: 2181
- Monitoring: should be able to access e.g.: https://influxdb.energy.svc.dbgcloud.io

Note: Current version of Kafka uses an old version of zookeeper, which does not support encrypted communication. The zookeeper (sub)cluster MUST only be accessible by that particular cluster's brokers. For both security and performance reasons, never share the zookeeper (sub)cluster among kafka clusters!",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed and provided the following kafka cluster:
* SHARED SIMU 
* ELTS ASIM
* SHARED INTERNAL TEST

Cluster for 
* ELTS PROD
* PRE PROD SYT1
will be handled in the ticket https://jira.deutsche-boerse.com/browse/M7P-7643
",,,,,,,,,,,,,,,,,,,,,,,,15379200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwo7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":106444,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/21 07:48;cs687;Checking Firewall-Setting for ELTS-ASIM:

*open port on m7eltsasimkb2*:
{code:java}
[root@m7eltsasimkbr2 ~]# nc -l -4 -v 9092
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Listening on 0.0.0.0:9092
Ncat: Connection from 10.139.59.253.
Ncat: Connection from 10.139.59.253:38622.
{code}

*checking the connection from m7eltsasimkbr1*:
{code:java}
[root@m7eltsasimkbr1 ~]# telnet m7eltsasimkbr2 9092
Trying 10.139.59.200...
Connected to m7eltsasimkbr2.
Escape character is '^]'.
{code}

*open ports on m7eltsasimkzk2:*
{code:java}
[root@m7eltsasimkzk2 ~]# nc -4 -l -v 2888
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Listening on 0.0.0.0:2888

# and later
# [root@m7eltsasimkzk2 ~]# nc -4 -l -v 3888
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Listening on 0.0.0.0:3888
{code}

*checking the connection from m7eltsasimkzk1:*
{code:java}
[root@m7eltsasimkzk1 ~]# telnet m7eltsasimkzk2 2888
Trying 10.139.59.130...
Connected to m7eltsasimkzk2.
Escape character is '^]'.

# and later
[root@m7eltsasimkzk1 ~]# telnet m7eltsasimkzk2 3888
Trying 10.139.59.130...
Connected to m7eltsasimkzk2.
Escape character is '^]'.
{code}

*open port on m7eltsasimkzk1:*
{code:java}
[root@m7eltsasimkzk1 ~]# nc -4 -l -v 2181
Ncat: Version 7.50 ( https://nmap.org/ncat )
Ncat: Listening on 0.0.0.0:2181
{code}
*checking th connection from m7eltsasimkbr1:*
{code:java}
[root@m7eltsasimkbr1 ~]# telnet m7eltsasimkzk1 2181
Trying 10.139.59.131...
Connected to m7eltsasimkzk1.
Escape character is '^]'.
{code}

*open ports on m7eltsasimkbr1:*
{code:java}
[root@m7eltsasimkbr1 ~]# nc -4 -l -v 9092     
Ncat: Version 7.50 ( https://nmap.org/ncat )  
Ncat: Listening on 0.0.0.0:9092               
{code}
*checking the connection from m7eltsasimm7b1/2*
{code:java}
[cs687@m7eltsasimm7b1 ~]$ telnet m7eltsasimkbr1 9092   
Trying 10.139.59.253...                                
Connected to m7eltsasimkbr1.                           
Escape character is '^]'.                             
{code}


* *brokers among each other: 9092* (/)
* *zookeepers among each other: 2888, 3888* (/)
* *brokers vs zookeepers: 2181* (/)
* *External (client) communication: 9092* (/)","22/Mar/21 08:32;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
"Monitoring: Telegraf should write into own logfile, not into stout /var/log/messages",M7P-7746,106437,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,cs687,op211,op211,09/Feb/21 09:43,07/Apr/21 12:31,16/Sep/21 14:11,26/Mar/21 12:43,,7tops_sprint114,,,,Monitoring,,,,M,M7PRODOPS,,,,,,"Based on M7P-7743 and a full file system in Syst1, we found out, that Telegraf logs into /var/log/messages instead of an own logfile. More details here:

[https://github.com/influxdata/telegraf/issues/4174]

Tasks:
 * Check, if the current behavior is intended (maybe we want it this way)
 * If not, change Telegraf config (telegraf.conf) to log into own log file:

{noformat}
logfile = ""/var/log/telegraf/telegraf.log""{noformat}
 * Rollout to all stages",,cs687,nz893,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"see last comment. 
nothing to do which is worth enough. ",,,,,,,,,,,,,,,,,,,,,,,,14947200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzzjkn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 114,,,,,,,,,,,,,,,,,,,,,,,,,,see change description & comments,,,,,,,,,,"{""issueId"":106437,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/21 11:21;cs687;Just checked the situation on *m7tenrgsyt1m7c1*, for me it looks like nonsense to change the telegraf config, to save the logfiles in /var/log/telegraf/telegraf.log

+*why?*+

* Currently the telegraf is writing log-lines in /var/log/messages  
* /var/log/messages and such will be rotated and cleaned up via logrotate  
{code:java}
[root@m7tenrgsyt1m7c1 logrotate.d]# cat /etc/logrotate.conf
.....
# keep 4 weeks worth of backlogs
rotate 4

[root@m7tenrgsyt1m7c1 logrotate.d]# cat /etc/logrotate.d/syslog
/var/log/cron
/var/log/maillog
/var/log/messages
/var/log/secure
/var/log/spooler
{
    missingok
    sharedscripts
    postrotate
        /bin/kill -HUP `cat /var/run/syslogd.pid 2> /dev/null` 2> /dev/null || true
    endscript
}
{code}
* the same will not happen when we will point telegraf logfiles to /var/log/telegraf/telegraf.log, so we need also the add rotation/cleanup 

In case File-System went full like it happened in SYT1, because of an misbehavior of telegraf, it will also went full when we would change the logging in the telegraf to /var/log/telegraf/telegraf.log 
both are running on the same Filesystem 
{code:java}
/dev/mapper/rootvg-lv_var_log           1.9G  192M  1.6G  11% /var/log
{code}

I would do nothing and keep it, running like it is. 
It´s not worth enough to create a dedicated FS for telegraf logfiles. 

FYI: [~op211]","26/Mar/21 12:43;cs687;done","26/Mar/21 12:56;nz893;Closing based on comment from Steffen.","26/Mar/21 14:51;op211;Nonsense!? Ok, ok ... ;)",,,,,,,,,,,,,,,,,,,,,,,,
M7 SIMU - Running out of swap on database hosts/Check swap,M7P-7727,106382,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,08/Feb/21 08:18,10/Feb/21 11:29,16/Sep/21 14:11,08/Feb/21 13:05,,6.11.192,7tops_sprint110,,,Database,,,,M7PRODOPS,,,,,,,"Like described in M7P-6948
we have to check the hosts m7simupdb1/2/3/4 and m7simudbr1/2",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-362,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"created a config file /etc/sysctl.d/98-db.conf
on the hosts m7simupdb1/2/3/4 and m7simudbr1/2

and configured the parameter vm.overcommit_ratio depending on the swap and total memory settings.",,,,,,,,,,,,,,,,,,,,,,,,19008000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz9af:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":106382,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 09:49;cs687;Like we solved it already in M7P-7726, we will do it the same way for M7SIMUDBR1/2:

{code:java}
[root@m7simudbr1 ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:           7803         926         213        3505        6662        2966
Swap:          3999        3213         786
{code}

Afterwards we can check if the alert will change:
https://alerta.energy.svc.dbgcloud.io/#/alert/7dbb2f87-a305-49b7-854a-220831a2fa4f

To show the exact calculation:
(RAM - swap) / RAM * 100
(7803- 3999) / 7803 * 100 = 48,7504
*So 48 is a safe value*

7GB RAM, 3GB SWAP, *overcommit_ratio = 48*

*m7simudbr1/2 crashed*
{code:java}
[root@m7simudbr1 sysctl.d]# free -m
-bash: fork: Cannot allocate memory
{code}
*had to reboot the machines - increase memory to 25G and* 
*changed the overcommit_ratio parameter to 84*

currently we have 9 active clusters running. in the end it will be 10 in total and each cluster has 2GB shared_buffers ","08/Feb/21 12:51;cs687;m7simupdb1-4 have the following memory setup: 
{code:java}
[root@m7simupdb4 ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:         128418        4340         492       24958      123584       98219
Swap:          7999          13        7986
{code}

To show the exact calculation:
(RAM - swap) / RAM * 100
(128418 - 7999) / 128418 * 100 = 93,7711
*So 93 is a safe value*

128GB RAM, 8GB SWAP, *overcommit_ratio = 93*
","08/Feb/21 12:52;cs687;*Added the file ""/etc/sysctl.d/98-db.conf""*

M7SIMUPDB1/2/3/4
{code:java}
## Cybertec recommendations                                     
                                                                
# don't overcommit memory                                       
vm.overcommit_memory = 2                                        
                                                                
# only commit as much memory as we have RAM                     
# # overcommit_ratio = ( (RAM - swap) / RAM ) * 100             
vm.overcommit_ratio = 93                                        
                                                                
# Minimize swapping                                             
vm.swappiness = 1    
{code}

to apply the setting, we have to run:
{code:java}
sysctl -p/etc/sysctl.d/98-db.conf
{code}

","08/Feb/21 13:05;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
M7 TEST - Running out of swap on database hosts/Check swap ,M7P-7726,106381,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,08/Feb/21 08:17,10/Feb/21 11:29,16/Sep/21 14:11,08/Feb/21 12:00,,6.11.192,7tops_sprint110,,,Database,,,,M7PRODOPS,,,,,,,"Like described in M7P-6948
we have to check the hosts m7testpdb1/2  and m7testdbr1/2 ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"created a config file /etc/sysctl.d/98-db.conf
on the hosts m7testpdb1/2 and m7testdbr1/2 

and configured the parameter *vm.overcommit_ratio* depending on the swap and total memory settings. ",,,,,,,,,,,,,,,,,,,,,,,,19008000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzza53:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":106381,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 08:34;cs687;*m7testpdb1/2:*
{code:java}
[root@m7testpdb1 ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:         128425        3426         513       15075      124485      109018
Swap:         32767          28       32739
{code}

To show the exact calculation:
(RAM - swap) / RAM * 100
(128425 - 32767) / 128425 * 100 = 74,485
*So 74 is a safe value*

128GB RAM, 32GB SWAP, *overcommit_ratio* = 74
","08/Feb/21 09:28;cs687;*m7testdbr1/2:*
{code:java}
[root@m7testdbr1 ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:           7802         784         132        2211        6885        4463
Swap:          3999         467        3532
{code}

To show the exact calculation:
(RAM - swap) / RAM * 100
(7802 - 3999) / 7802 * 100 = 48
*So 48 is a safe value*

7GB RAM, 3GB SWAP, overcommit_ratio = 48

","08/Feb/21 09:36;cs687;Added the file ""*/etc/sysctl.d/98-db.conf*""

*M7TESTPDB1/2*
{code:java}
## Cybertec recommendations                                     
                                                                
# don't overcommit memory                                       
vm.overcommit_memory = 2                                        
                                                                
# only commit as much memory as we have RAM                     
# # overcommit_ratio = ( (RAM - swap) / RAM ) * 100             
vm.overcommit_ratio = 74                                        
                                                                
# Minimize swapping                                             
vm.swappiness = 1                                                                                                         
{code}


*M7TESTDBR1/2*
{code:java}
## Cybertec recommendations

# don't overcommit memory
vm.overcommit_memory = 2

# only commit as much memory as we have RAM
# overcommit_ratio = ( (RAM - swap) / RAM ) * 100
vm.overcommit_ratio = 48

# Minimize swapping
vm.swappiness = 1
{code}

*to apply the setting, we have to run:*
{code:java}
sysctl -p/etc/sysctl.d/98-db.conf
{code}

","08/Feb/21 12:00;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: M7 API - Add the list of supported cipher suites in the API documentation,M7P-7713,106242,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,tj898,tj898,03/Feb/21 15:16,21/Jul/21 10:58,16/Sep/21 14:11,22/Mar/21 12:57,,6.11.217,7tops_sprint113,,,apache,,,,7tops_comm,S,,,,,,"The list of supported cipher suites should be added to the DFS180 or any other document.

The information is not private. At the moment there are 2 different sets of ciphers available to connecting clients, one for web, another for haproxy (RMQ conns). This should be taken into consideration when updating the documentation.

There's a list of ciphers in https://jira.deutsche-boerse.com/browse/SERVICE-9327, so this list should be verified/enriched and then documented.

*Refinement*: If it needs to be in the document, better find an automated way. But better would be, to document a way, how to find out from the server, because the list changes over time and documents get outdated.

Maybe: [https://github.com/rbsec/sslscan]",,nn236,pd122,tj898,,,,,,,,,,,,,,,,,SERVICE-9539,,,,,,,,,,,,,,M7P-8658,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,EPEX,,,,,,Information Request,,,,,,,,,,15379200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8av:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":106242,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Feb/21 13:13;nn236;Based on [~pn508] feedback, putting to Refined.","22/Feb/21 15:53;tj898;Apache Web Server
{code:java}
[pd122@m7shrdprodweb1 ~]$ nmap -sV --script ssl-enum-ciphers -p 60060 localhost

Starting Nmap 6.40 ( http://nmap.org ) at 2020-12-22 11:59 CET
Nmap scan report for localhost (127.0.0.1)
Host is up (0.000038s latency).
Other addresses for localhost (not scanned): 127.0.0.1
PORT      STATE SERVICE  VERSION
60060/tcp open  ssl/http Apache httpd
| ssl-enum-ciphers:
|   SSLv3: No supported ciphers found
|   TLSv1.2:
|     ciphers:
|       TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - strong
|       TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - strong
|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
|     compressors:
|       NULL
|_  least strength: strong
{code}","22/Feb/21 15:53;tj898;HAPproxy 
{code:java}
[pd122@m7shrdprodssl0 ~]$  cat /shrd/elts-prod-app-haproxy0/haproxy.cfg | sed -n ""s/.*ssl-default-bind-ciphers */openssl ciphers -v '/p"" | sed ""s/$/'/"" | sh
ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256) Mac=AEAD
ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128) Mac=AEAD
ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(256) Mac=AEAD
ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(128) Mac=AEAD
DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(256) Mac=AEAD
DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(128) Mac=AEAD

{code}","24/Feb/21 09:41;nn236;[~tj898] EPEX asked us on OPAC meeting how they will be notified about the changes in the list of supported cipher suites (EPEXMT-2841). If the process was manual, I would expect we'd have a ticket labelled as Release Notes Yes and its Change description would inform customers about the change. Not sure how this could work in case of an automated solution. Can this be please taken into account during the design of the solution? Thanks!","22/Mar/21 12:48;pd122;Does not seem to be possible to get the information remotely (firewall blocks the requests).  [~nn236]  the cipher change is not automatic, in the sense that that the app configuration has to be altered in order for it to change (for the completeness' sake I feel the need to add that it is also possible to trigger the change via the ssl library update, not very likely to happen though). No info was provided as it was not clear the customer requires it.

One more thing to mention: the change has been applied to all test environments weeks (months in some cases) before the production.  If customer only noticed it after the production deployment it is either because of limited testing/usage of its test environments or difference in their (test and production) client setup.","22/Mar/21 12:51;pd122;As stated above, ciphers in use today:
 * Web Servers
 ** TLS_DHE_RSA_WITH_AES_128_GCM_SHA256
 ** TLS_DHE_RSA_WITH_AES_256_GCM_SHA384
 ** TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
 ** TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
 * HAProxy
 ** ECDHE-ECDSA-AES256-GCM-SHA384
 ** ECDHE-ECDSA-AES128-GCM-SHA256
 ** ECDHE-RSA-AES256-GCM-SHA384
 ** ECDHE-RSA-AES128-GCM-SHA256
 ** DHE-RSA-AES256-GCM-SHA384
 ** DHE-RSA-AES128-GCM-SHA256

 ",,,,,,,,,,,,,,,,,,,,,,
SYT1 Stability tests SLA report via Power BI,M7P-7709,106225,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,pn508,pn508,03/Feb/21 13:17,24/Feb/21 11:26,16/Sep/21 14:11,15/Feb/21 10:40,,6.11.196,7tops_sprint111,,,EBSM,,,,EBSM,M7PRODOPS,PowerBI,,,,,"Please create SLA report for internal M7T Systemtest1 environment were the Stability tests are running.
 * The report should consist of Daily performance statistics (like the previous version of the customer facing reports).
 * Report should be accessible directly in Power BI or via Citrix
 * It should be possible to refresh the statistics
 * _SYT1: it should be able to see even yesterday's figures_
 * keep *internally* ELTS PROD SLA daily report",,dp007,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,report template created,,,,,,,,,,,,,,,,,,,,,,,,18403200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz99j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106225,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Feb/21 10:39;dp007;Report is ready: S:\Energie\Prod_DEVELOP\003 Business Operations\Applications\M7\EPEX\SLAreporting\SHRD-SYT1_2021A.pbix

Regarding the requirement: _SYT1: it should be able to see even yesterday's figures_
This cannot be achieved as the input/source for the Performance SLA is a CSV report coming from EBSM which is generated monthly.",,,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD : journal took 1 minute !!!,M7P-7696,106174,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cv179,pw231,pw231,02/Feb/21 15:48,24/Aug/21 13:07,16/Sep/21 14:11,08/Feb/21 15:48,,6.11.192,7tops_sprint110,,,cor,,,,7tops,,,,,,,"h4. Problem
Between 17:37 and 17:51, the journal was very slow. and one maximum was up to 1 minute!
See https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&var-host=m7eltsprodm7c1%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-interval=30s&var-exchangeId=EPEX&from=1612196705655&to=1612198545604&fullscreen&panelId=41

This blocked order processing and could lead to many logouts...

While the max journal times were up to 1 minute. the journal was slow for the whole period:
 !screenshot-1.png!  

",,cv179,pw231,,,,,,,,,,,,,,,,,,,M7P-6184,,,,,,,,,,,,,M7P-8877,,,,,,"03/Feb/21 09:49;pw231;image-2021-02-03-09-49-15-795.png;https://jira.deutsche-boerse.com/secure/attachment/92312/image-2021-02-03-09-49-15-795.png","03/Feb/21 08:51;pw231;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/92310/screenshot-1.png",,,,,,,,,,,,,,sw455,,,,,,,,see comments below,,,,,,,,ELTS,,,,,,,,,,,,,,,,18921600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz90f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106174,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"03/Feb/21 09:41;cv179;This was during a reinit of a replication node after the hardware maintenance to extend disks of m7prodpdb2.

The reinit obviously utilized a significant amount of network capacity so the glusterfs-internal replication was throttled down and unable to commit IO in the usual manner.

As this was the first time that we experienced the issue in this severity, we will change the plan for the next (and last) extension and only reinitialize the cluster during the market halt / downtime.","03/Feb/21 09:42;cv179;https://jira.deutsche-boerse.com/browse/SERVICE-9481?focusedCommentId=314595&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-314595

 ","03/Feb/21 09:47;pw231;today, it happened again - two times : https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&var-host=m7eltsprodm7c1%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-interval=30s&var-exchangeId=EPEX&from=1612266481817&to=1612333354220&fullscreen&panelId=41

 !image-2021-02-03-09-49-15-795.png! ","03/Feb/21 11:55;pw231;waiting for feedback from @7tops","04/Feb/21 10:51;cv179;taking it into the 7tops.

Current next steps:

 

Configure SYT1 back to NFS

Block nfs port in 10s intervals

Reproduce the issue

Configure syt1 to GLFS

Reproduce the issue again

 ","05/Feb/21 11:21;cv179;Played with some settings on client and server side and came to this solution:

 
 # Reconfigure glfs volumes for best performance (e.g. on m7testpdb1):

 
{code:java}
VOLUME=journal_m7shrdsyt1apa
 gluster volume set $VOLUME performance.cache-size 128MB
 gluster volume set $VOLUME group nl-cache
gluster volume set $VOLUME nl-cache-positive-entry on
 gluster volume set $VOLUME performance.write-behind-window-size 100MB
 gluster volume set $VOLUME performance.nfs.write-behind-window-size 100MB
gluster volume set $VOLUME performance.client-io-threads on
gluster volume set $VOLUME network.inode-lru-limit 50000
gluster volume set $VOLUME features.cache-invalidation on
gluster volume set $VOLUME features.cache-invalidation-timeout 600
 
{code}
 
 # Reconfigure core mount points to use Glusterfs client instead of NFS e.g. on m7shrdsyt1apa1:

 

Remove existing fstab entry (or comment out):

m7testpdb1:/journal_m7shrdsyt1apa  /shrd/journal nfs defaults,_netdev,nodiratime,noatime 0 0


 cor1:
{code:java}
SERVER1=m7testpdb1
 SERVER2=m7testpdb2
 VOLUME=m7shrdsyt1apa
 MOUNT=/shrd/journal
  
AFTER:
 
${SERVER1}:/journal_${VOLUME}  ${MOUNT} glusterfs defaults,_netdev,backup-volfile-servers=${SERVER2},log-level=WARNING,log-file=/var/log/glusterfs/glusterfs.log,direct-io-mode=disable 0 0
{code}
 

 
 # Remount during slave status of core:
 
 umount /shrd/journal
 mount /shrd/journal

 ","08/Feb/21 08:20;pw231;another case last night : https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1612694558433&to=1612763119785&fullscreen&panelId=41","08/Feb/21 15:20;cv179; 

Applied on EPEX-ASIM and XRPM-PROD during this morning already.

 

Applied to remaining internal TEST envs around noon.

 

Also applied to ALL remaining SIMU environments using this batching method with ansible:

 
{code:bash}


# adapt all configs on one host
gluster volume list | grep journal | while read VOLUME; do gluster volume info $VOLUME; gluster volume set $VOLUME performance.cache-size 128MB; gluster volume set $VOLUME group nl-cache; gluster volume set $VOLUME nl-cache-positive-entry on; gluster volume set $VOLUME performance.write-behind-window-size 100MB; gluster volume set $VOLUME performance.nfs.write-behind-window-size 100MB;gluster volume set $VOLUME performance.client-io-threads on; gluster volume set $VOLUME network.inode-lru-limit 50000; gluster volume set $VOLUME features.cache-invalidation on; gluster volume set $VOLUME features.cache-invalidation-timeout 600; done



SIMU:
# validate change and backup old file
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'cat /etc/fstab | sed ""s/^m7simupdb/#m7simupdb/g""; cp /etc/fstab /etc/fstab.bak-210208' -b

# update new fstab file
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'sed -i ""s/^m7simupdb/#m7simupdb/g"" /etc/fstab' -b

# write the new entry
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'grep ""^m7simupdb"" /etc/fstab; SERVER1=m7simupdb{{ instance[-1] }}; SERVER2=m7simupdb{{ (((instance[-1] | int)%2)+1)}}; VOLUME=m7{{ customer }}{{ env }}{{ ansible_host[-4:-1] }}; MOUNT=/{{ customer }}/journal; echo ${SERVER1}:/journal_${VOLUME}  ${MOUNT} glusterfs defaults,_netdev,backup-volfile-servers=${SERVER2},log-level=WARNING,log-file=/var/log/glusterfs/glusterfs.log,direct-io-mode=disable 0 0 | tee -a /etc/fstab; curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""; echo; df -hT /{{customer}}/journal;' -b

# validate the difference
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'diff /etc/fstab /etc/fstab.bak-210208'

# remount SLAVE mounts
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal; if [ ""$MASTERSTATUS"" == ""SLAVE"" ]; then umount /{{customer}}/journal; mount /{{customer}}/journal; fi' -b

# check situation
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal;'

# restart MASTER
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal; if [ ""$MASTERSTATUS"" == ""MASTER"" ]; then /{{customer}}/{{customer}}-{{env}}-{{instance}}/tomcat/bin/stop.sh; /{{customer}}/{{customer}}-{{env}}-{{instance}}/tomcat/bin/start.sh;  fi' -b --become-user tomcat --forks 70

# validate situation
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal;'

# remount old masters
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal; if [ ""$MASTERSTATUS"" == ""SLAVE"" ]; then umount /{{customer}}/journal; mount /{{customer}}/journal; fi' -b

# last validation
ansible 'all:!*epex-asim*:!*elts-asim*:!*prod*:!*shrd*:&m7tcor' -m shell -a 'MASTERSTATUS=$(curl -s http://localhost:8079/m7core/health | sed ""s/.*\(MASTER\|SLAVE\).*/\1/g""); echo $MASTERSTATUS; df -hT /{{customer}}/journal;'

 {code}","08/Feb/21 15:25;cv179;ELTS PROD change is planned here: https://jira.deutsche-boerse.com/browse/SERVICE-9618

 ","08/Feb/21 15:47;cv179;All production fstab entries are already updated. Only a manual remount is required after the next failover. Eventually with the next reboot the mount point will be correct.",,,,,,,,,,,,,,,,,,
Reporter functional alerting,M7P-7692,106166,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ax460,ax460,02/Feb/21 14:13,24/Mar/21 11:26,16/Sep/21 14:11,19/Mar/21 09:35,,6.11.217,7tops_sprint113,,,Reporter,,,,7tops_comm,M,,,,,,"Setup an functional alerts for customer envs (SYT1, SYT3, ELTS ASIM & PROD)
 * OrderService cleanup
{code:java}
log.warn(""Cleaning order (id:${o.getId()}, revNo:${o.revisions.last().revisionNo}) in non terminal state"")
{code}
This cleans orders from memory, but such a situation should never happen. If it happens it requires analysis. So lets setup an alert.
 * OrderService cleanup
{code:java}
log.error(""No offset found for {} and {}"", entry.key, replayTimestamp)
{code}
This cleans orders from memory, but such a situation should never happen. If it happens it requires analysis. So lets setup an alert.

 ",,ax460,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Added reporter cleaning order watcher.,,,,,,,,,,,,,,,,,,,,,,,,15638400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz88n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106166,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"10/Feb/21 16:01;iu252;Created https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1234, waiting for review and approval","23/Feb/21 09:31;iu252;Example of the log message:

{code:java}
Cleaning order (id:11111111, revNo:6) in non terminal state
{code}
","04/Mar/21 14:42;ax460;Lets also introduce another alert for logline
{code:java}
No offset found for {String eg. m7-core-events} and {ISO_8601_TIME eg. 2020-10-24T18:05:30.0Z}
{code}","04/Mar/21 14:49;iu252;[~ax460] please create a new ticket for new alert. Thanks.","04/Mar/21 15:17;ax460;(y)","09/Mar/21 20:11;iu252;Test execution:
- append following lines into the reporter log:

{noformat}
[tomcat@m7tshrdinterep2 shrd-ate4-rpr2]$ echo -e ""  `date +\""%Y-%m-%dT%H:%M:%S\""`   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state\n"" >> m7t_shrd_ate4_m7treporter-2_standard_hau.log
[tomcat@m7tshrdinterep2 shrd-ate4-rpr2]$ echo -e ""  `date +\""%Y-%m-%dT%H:%M:%S\""`   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state\n"" >> m7t_shrd_ate4_m7treporter-2_standard_hau.log
[tomcat@m7tshrdinterep2 shrd-ate4-rpr2]$ echo -e ""  `date +\""%Y-%m-%dT%H:%M:%S\""`   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state\n"" >> m7t_shrd_ate4_m7treporter-2_standard_hau.log
[tomcat@m7tshrdinterep2 shrd-ate4-rpr2]$
{noformat}


- send following request in Kibana dev tools:

{noformat}
GET m7-tomcat-*/_search
{
         ""query"": {
           ""bool"": { 
             ""must"": [
               {
                 ""query_string"": {
                   ""fields"": [
                     ""logline""
                   ],
                   ""default_operator"": ""AND"",
                   ""query"": ""(Cleaning order non terminal state)""
                 }
               },
               {
                 ""range"": {
                   ""@timestamp"": {
                      ""gte"": ""now-5m"",
                      ""lt"": ""now""
                   }
                 }
               }
             ]
           }
         }
       }
{noformat}

- result of the reguest:

{noformat}
{
  ""took"" : 10,
  ""timed_out"" : false,
  ""_shards"" : {
    ""total"" : 46,
    ""successful"" : 46,
    ""skipped"" : 0,
    ""failed"" : 0
  },
  ""hits"" : {
    ""total"" : 1,
    ""max_score"" : 68.36072,
    ""hits"" : [
      {
        ""_index"" : ""m7-tomcat-2021.03.09"",
        ""_type"" : ""doc"",
        ""_id"" : ""NqxAGHgBLG_xxjxBS-76"",
        ""_score"" : 68.36072,
        ""_source"" : {
          ""product"" : ""m7t"",
          ""instance"" : ""rpr2"",
          ""offset"" : 12965778,
          ""log"" : {
            ""file"" : {
              ""path"" : ""/shrd/logs/shrd-ate4-rpr2/m7t_shrd_ate4_m7treporter-2_standard_hau.log""
            },
            ""flags"" : [
              ""multiline""
            ]
          },
          ""module"" : ""m7_shrd_ate4"",
          ""log_level"" : ""INFO"",
          ""prospector"" : {
            ""type"" : ""log""
          },
          ""datacenter"" : ""hausen"",
          ""source"" : ""/shrd/logs/shrd-ate4-rpr2/m7t_shrd_ate4_m7treporter-2_standard_hau.log"",
          ""error"" : ""field [time] not present as part of path [time]"",
          ""client_environment"" : ""ate4"",
          ""input"" : {
            ""type"" : ""log""
          },
          ""logline"" : """"""
2021-03-09T19:29:14   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state

  2021-03-09T19:29:19   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state

  2021-03-09T19:29:20   [main] WARN  Cleaning order (id:11111111, revNo:6) in non terminal state
"""""",
          ""@timestamp"" : ""2021-03-09T18:29:24.217Z"",
          ""beat"" : {
            ""hostname"" : ""m7tshrdinterep2"",
            ""name"" : ""m7tshrdinterep2"",
            ""version"" : ""6.8.6""
          },
          ""client"" : ""shrd"",
          ""group"" : ""tomcat""
        }
      }
    ]
  }
}
{noformat}
https://kibana.energy.svc.dbgcloud.io/app/kibana#/dev_tools/console?_g=h@6efb341

Test was successful.","09/Mar/21 20:17;iu252;[~ax460] are you OK with following parameter in my PR:
- ""interval"" : ""5m""
- ""gte"": ""now-5m"",","16/Mar/21 10:35;iu252;Merged https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1234","16/Mar/21 13:07;ax460;[~iu252] as I mentioned in PR 
{code:java}
""query"": ""(Cleaning order non terminal state)""
{code}
is not valid query, so please update it after your successful test.

To your previous question (sorry I have missed it before). Since there might be more such a messages (during cleaning), it is ok to rise only one alert. Cleaning should happen once a day, so I dont expect there would be more such a messages on that day (or after another 5minutes)","16/Mar/21 22:58;iu252;[~ax460] it's not only the query... 
Do not forget the operator ""AND"".



{noformat}
""default_operator"": ""AND"",
 ""query"": ""(Cleaning order non terminal state)""
{noformat}

Please also check my tests in Kibana DevTools.","17/Mar/21 09:59;ax460;I see, the brackets were confusing for me. Are they just redundant in query if AND operator is used?","19/Mar/21 09:32;iu252;Last change: https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1241","19/Mar/21 09:33;iu252;Redeployed watcher: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Elasticsearch%20Watcher%20Alerts/8/console",,,,,,,,,,,,,,,
File system on m7eltsprodm7b1 went full,M7P-7679,106046,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,iu252,iu252,01/Feb/21 08:16,16/Feb/21 23:21,16/Sep/21 14:11,16/Feb/21 10:50,,6.11.196,,,,uknown,,,,7tops_comm,,,,,,,File system /elts on m7eltsprodm7b1 went full at 07.22 (100%),,cs687,cv179,ek615,iu252,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9642,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Application fix was provided by developers and already deployed.,,,,,,,,ELTS,,,,,,,,,,,,,,,,19612800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz88f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,7tops Sprint 111,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":106046,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"01/Feb/21 08:20;iu252;/dev/mapper/rootvg-lv_elts              1.5G  1.4G   24K 100% /elts

Extended file system:

{noformat}
[root@m7eltsprodm7b1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   4  11   0 wz--n- <99.50g 9.99g
[root@m7eltsprodm7b1 ~]# lvextend -r -L +1g /dev/mapper/rootvg-lv_elts
  Size of logical volume rootvg/lv_elts changed from 1.50 GiB (384 extents) to 2.50 GiB (640 extents).
  Logical volume rootvg/lv_elts successfully resized.
resize2fs 1.42.9 (28-Dec-2013)
Filesystem at /dev/mapper/rootvg-lv_elts is mounted on /elts; on-line resizing required
old_desc_blocks = 1, new_desc_blocks = 1
The filesystem on /dev/mapper/rootvg-lv_elts is now 655360 blocks long.

[root@m7eltsprodm7b1 ~]# df -h
Filesystem                              Size  Used Avail Use% Mounted on

/dev/mapper/rootvg-lv_elts              2.5G  1.4G  968M  60% /elts

{noformat}

","01/Feb/21 08:21;iu252;[~cs687] found some errors in logs:

{noformat}
2021-02-01T06:29:15.141Z [amqReqExec-5] ERROR c.d.m.e.a.EnquiryMessageListener - Cannot process message.
org.springframework.transaction.TransactionSystemException: Could not roll back Hibernate transaction; nested exception is org.hibernate.TransactionException: Unable to rollback against JDBC Connection
{noformat}


{noformat}
2021-02-01T06:29:15.141Z [amqReqExec-5] ERROR c.d.m.e.a.EnquiryMessageListener - Cannot process message.
org.springframework.transaction.TransactionSystemException: Could not roll back Hibernate transaction; nested exception is org.hibernate.TransactionException: Unable to rollback against JDBC Connection
{noformat}


{noformat}
2021-02-01T06:29:15.141Z [amqReqExec-5] ERROR c.d.m.e.a.EnquiryMessageListener - Cannot process message.
org.springframework.transaction.TransactionSystemException: Could not roll back Hibernate transaction; nested exception is org.hibernate.TransactionException: Unable to rollback against JDBC Connection
{noformat}
","01/Feb/21 08:22;iu252;Restarted enq1 and later also enq2.","01/Feb/21 08:37;cs687;After first analyzes:

customer set market to halt at 07:17
and downloaded this file afterwards 
{code:java}
-rw-r----- 1 tomcat tomcat 688598 Feb  1 07:19 M7_TradeFlowDownload_2021-02-01-07-19-01.zip
drwxr-x--- 2 tomcat tomcat   4096 Feb  1 07:22 M7_TradeFlowDownload_2021-02-01-07-22-26
-rw-r----- 1 tomcat tomcat 642292 Feb  1 07:22 M7_TradeFlowDownload_2021-02-01-07-22-29.zip
{code}

{code:java}
[root@m7eltsprodm7b1 heapdump]# du -sh /elts/elts-prod-enq1/*
800M    /elts/elts-prod-enq1/tomcat/M7_TradeFlowDownload_2021-02-01-07-22-26
{code}

yeah afterwards /elts filesystem were to full and instances crashed 
","01/Feb/21 10:14;cv179;I moved the M7_Trade* files to /elts/logs/tradeflow and compressed the folder.",,,,,,,,,,,,,,,,,,,,,,,
Remove some alerts from #m7_alerts,M7P-7662,105908,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,oy574,oy574,28/Jan/21 10:23,19/May/21 14:32,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"As this channels contains too many of unnecessary warnings that shouldn't be paid attention to, please remove them from #m7_alerts slack channel. List of alerts to be removed:

Remove from *test envs*, keep on *customer facing envs*:
 * MTT AS2 file sending failed
 * Tomcat Failover
 * Application health check status
 * sending health status data
 * sending JVM data
 * sending Apache data
 * Mount: /xsop/logs - used: 86% - 2.5 GB/3.1 GB Used/Total
 * Crossed orderbook alert - TEMPORARY
 * M7 ADMIN TC540 report generation
 * Average Response Time
 * System Load
 * CPU

Also, please adjust the warning/critical level on all envs:
 * Disk space (Mount: /xsop/logs - used: 86% - 2.5 GB/3.1 GB Used/Total) - warning on 95%, critical on 100%",,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19958400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwuf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105908,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Oversized shared_buffers/effective_cache_size on m7 Prod postgres instances,M7P-7659,105892,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,28/Jan/21 08:34,25/May/21 23:40,16/Sep/21 14:11,09/Feb/21 09:35,,11.0.0,7tops_sprint110,,,Database,,,,Database,M7PRODOPS,,,,,,"In Production we have the same faulty memory setup like it happened for M7 TEST/SIMU CLUSTERS

{code:java}
/var/lib/pgsql_m7aamprprodsync/data/11/m7aamprprodsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeerprodsync/data/11/m7axeerprodsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync/postgresql.conf:shared_buffers = '4GB' --> 8G
/var/lib/pgsql_m7thupxprodasync/data/11/m7thupxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tplpxprodasync/data/11/m7tplpxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdprodasync/data/11/m7tshrdprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmprodasync/data/11/m7txrpmprodasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
{code}

Proposal of memory settings is described in 
https://jira.deutsche-boerse.com/browse/M7P-7549
https://jira.deutsche-boerse.com/browse/M7P-7658

Will coordinate it with Pavel Rehak (dbg ops) and Auction team!",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9633,SERVICE-9632,SERVICE-9618,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"resized the shared_buffers for the following env´s
* m7aamprprodsync
* m7axeerprodsync
* m7teltsprodasync
* m7txrpmprodasync
* m7txsopprodasync",,,,,,,,,,,,,,,,,,,,,,,,18921600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz7cn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,,,,,,,,,,,,,,,,,,see change description and comments ,,,,,,,,,,"{""issueId"":105892,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"29/Jan/21 08:12;cs687;changed for all the clustes the patroni config.yml file:
* patroni_m7aamprprodsync/  -> 4G
* patroni_m7tplpxprodasync/  -> 4G
* patroni_m7axeerprodsync/  -> 4G 
* patroni_m7tshrdprodasync/  -> 4G
* patroni_m7cicscprodasync/  -> 4G 
* patroni_m7txrpmprodasync/   -> 4G
* patroni_m7teltsprodasync/   -> 8G
* patroni_m7txsopprodasync/   -> 4G
* patroni_m7thupxprodasync/   -> 4G

the following clusters needs to be changed with edit-config command and restarting the nodes one by one 
* -*m7aamprprodsync*-
* -*m7axeerprodsync*-
* *m7teltsprodasync*
* -*m7txrpmprodasync*-
* *m7txsopprodasync*


","29/Jan/21 08:51;cs687;*before:*
{code:java}
/var/lib/pgsql_m7aamprprodsync/data/11/m7aamprprodsync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7axeerprodsync/data/11/m7axeerprodsync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7thupxprodasync/data/11/m7thupxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tplpxprodasync/data/11/m7tplpxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdprodasync/data/11/m7tshrdprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmprodasync/data/11/m7txrpmprodasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/postgresql.conf:shared_buffers = '32104MB'
{code}

*after editing the cluster-node config, restarts are required:*
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7txrpmprodasync | m7proddbr1 | 10.139.135.221:20014 |        | running |  6 |           |                 |
| m7txrpmprodasync | m7proddbr2 | 10.139.135.222:20014 |        | running |  6 |         0 |                 |
| m7txrpmprodasync | m7prodpdb1 | 10.139.53.176:20014  |        | running |  6 |           |        *        |
| m7txrpmprodasync | m7prodpdb2 | 10.139.53.173:20014  |        | running |  6 |         0 |        *        |
| m7txrpmprodasync | m7prodpdb3 | 10.139.53.172:20014  | Leader | running |  6 |         0 |        *        |
| m7txrpmprodasync | m7prodpdb4 | 10.139.53.171:20014  |        | running |  6 |           |        *        |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7txsopprodasync | m7proddbr1 | 10.139.135.221:20012 |        | running |  8 |         0 |                 |
| m7txsopprodasync | m7proddbr2 | 10.139.135.222:20012 |        | running |  8 |         0 |                 |
| m7txsopprodasync | m7prodpdb1 | 10.139.53.176:20012  |        | running |  8 |         0 |        *        |
| m7txsopprodasync | m7prodpdb2 | 10.139.53.173:20012  |        | running |  8 |           |        *        |
| m7txsopprodasync | m7prodpdb3 | 10.139.53.172:20012  | Leader | running |  8 |         0 |        *        |
| m7txsopprodasync | m7prodpdb4 | 10.139.53.171:20012  |        | running |  8 |           |        *        |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7teltsprodasync | m7proddbr1 | 10.139.135.221:20002 |        | running | 14 |           |                 |
| m7teltsprodasync | m7proddbr2 | 10.139.135.222:20002 |        | running | 14 |         0 |                 |
| m7teltsprodasync | m7prodpdb1 | 10.139.53.176:20002  |        | running | 14 |         0 |        *        |
| m7teltsprodasync | m7prodpdb2 | 10.139.53.173:20002  |        | running | 14 |         1 |        *        |
| m7teltsprodasync | m7prodpdb3 | 10.139.53.172:20002  | Leader | running | 14 |         0 |        *        |
| m7teltsprodasync | m7prodpdb4 | 10.139.53.171:20002  |        | running | 14 |           |        *        |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
|     Cluster     |   Member   |         Host         |     Role     |  State  | TL | Lag in MB | Pending restart |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
| m7axeerprodsync | m7proddbr1 | 10.139.135.221:20018 |              | running |  4 |           |                 |
| m7axeerprodsync | m7proddbr2 | 10.139.135.222:20018 |              | running |  4 |           |                 |
| m7axeerprodsync | m7prodpdb1 | 10.139.53.176:20018  |              | running |  4 |           |        *        |
| m7axeerprodsync | m7prodpdb2 | 10.139.53.173:20018  | Sync standby | running |  4 |           |        *        |
| m7axeerprodsync | m7prodpdb3 | 10.139.53.172:20018  |    Leader    | running |  4 |         0 |        *        |
| m7axeerprodsync | m7prodpdb4 | 10.139.53.171:20018  |              | running |  4 |           |        *        |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
|     Cluster     |   Member   |         Host         |     Role     |  State  | TL | Lag in MB | Pending restart |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
| m7aamprprodsync | m7proddbr1 | 10.139.135.221:20016 |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7proddbr2 | 10.139.135.222:20016 |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7prodpdb1 | 10.139.53.176:20016  |    Leader    | running |  4 |         0 |        *        |
| m7aamprprodsync | m7prodpdb2 | 10.139.53.173:20016  |              | running |  4 |         0 |        *        |
| m7aamprprodsync | m7prodpdb3 | 10.139.53.172:20016  | Sync standby | running |  4 |         0 |        *        |
| m7aamprprodsync | m7prodpdb4 | 10.139.53.171:20016  |              | running |  4 |         0 |        *        |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
{code}

","29/Jan/21 08:59;cs687;Ending-Result: 
*just the leader patroni-nodes have to be restarted*

{code:java}
[root@m7prodpdb1 ~]# patronictl -c /etc/patroni_m7aamprprodsync/config.yml list
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
|     Cluster     |   Member   |         Host         |     Role     |  State  | TL | Lag in MB | Pending restart |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
| m7aamprprodsync | m7proddbr1 | 10.139.135.221:20016 |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7proddbr2 | 10.139.135.222:20016 |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7prodpdb1 | 10.139.53.176:20016  |    Leader    | running |  4 |         0 |        *        |
| m7aamprprodsync | m7prodpdb2 | 10.139.53.173:20016  |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7prodpdb3 | 10.139.53.172:20016  |              | running |  4 |         0 |                 |
| m7aamprprodsync | m7prodpdb4 | 10.139.53.171:20016  | Sync standby | running |  4 |         0 |                 |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
{code}

{code:java}
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
|     Cluster     |   Member   |         Host         |     Role     |  State  | TL | Lag in MB | Pending restart |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
| m7axeerprodsync | m7proddbr1 | 10.139.135.221:20018 |              | running |  4 |           |                 |
| m7axeerprodsync | m7proddbr2 | 10.139.135.222:20018 |              | running |  4 |           |                 |
| m7axeerprodsync | m7prodpdb1 | 10.139.53.176:20018  | Sync standby | running |  4 |         0 |                 |
| m7axeerprodsync | m7prodpdb2 | 10.139.53.173:20018  |              | running |  4 |           |                 |
| m7axeerprodsync | m7prodpdb3 | 10.139.53.172:20018  |    Leader    | running |  4 |         0 |        *        |
| m7axeerprodsync | m7prodpdb4 | 10.139.53.171:20018  |              | running |  4 |           |                 |
+-----------------+------------+----------------------+--------------+---------+----+-----------+-----------------+
{code}

{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7teltsprodasync | m7proddbr1 | 10.139.135.221:20002 |        | running | 14 |           |                 |
| m7teltsprodasync | m7proddbr2 | 10.139.135.222:20002 |        | running | 14 |         1 |                 |
| m7teltsprodasync | m7prodpdb1 | 10.139.53.176:20002  |        | running | 14 |         0 |                 |
| m7teltsprodasync | m7prodpdb2 | 10.139.53.173:20002  |        | running | 14 |         1 |                 |
| m7teltsprodasync | m7prodpdb3 | 10.139.53.172:20002  | Leader | running | 14 |         0 |        *        |
| m7teltsprodasync | m7prodpdb4 | 10.139.53.171:20002  |        | running | 14 |           |                 |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
{code}

{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7txrpmprodasync | m7proddbr1 | 10.139.135.221:20014 |        | running |  6 |         0 |                 |
| m7txrpmprodasync | m7proddbr2 | 10.139.135.222:20014 |        | running |  6 |         0 |                 |
| m7txrpmprodasync | m7prodpdb1 | 10.139.53.176:20014  |        | running |  6 |           |                 |
| m7txrpmprodasync | m7prodpdb2 | 10.139.53.173:20014  |        | running |  6 |           |                 |
| m7txrpmprodasync | m7prodpdb3 | 10.139.53.172:20014  | Leader | running |  6 |         0 |        *        |
| m7txrpmprodasync | m7prodpdb4 | 10.139.53.171:20014  |        | running |  6 |           |                 |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
{code}

{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7txsopprodasync | m7proddbr1 | 10.139.135.221:20012 |        | running |  8 |           |                 |
| m7txsopprodasync | m7proddbr2 | 10.139.135.222:20012 |        | running |  8 |           |                 |
| m7txsopprodasync | m7prodpdb1 | 10.139.53.176:20012  |        | running |  8 |           |                 |
| m7txsopprodasync | m7prodpdb2 | 10.139.53.173:20012  |        | running |  8 |           |                 |
| m7txsopprodasync | m7prodpdb3 | 10.139.53.172:20012  | Leader | running |  8 |         0 |        *        |
| m7txsopprodasync | m7prodpdb4 | 10.139.53.171:20012  |        | running |  8 |           |                 |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
{code}








","29/Jan/21 09:02;cs687;{code:java}
/var/lib/pgsql_m7aamprprodsync/data/11/m7aamprprodsync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7axeerprodsync/data/11/m7axeerprodsync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync/postgresql.conf:shared_buffers = '8GB'
/var/lib/pgsql_m7thupxprodasync/data/11/m7thupxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tplpxprodasync/data/11/m7tplpxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdprodasync/data/11/m7tshrdprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmprodasync/data/11/m7txrpmprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/postgresql.conf:shared_buffers = '4GB'
{code}
","29/Jan/21 14:29;cs687;m7txrpmprodasync, m7aamprprod and m7axeerprod done (/)","09/Feb/21 09:35;cs687;done",,,,,,,,,,,,,,,,,,,,,,
Oversized shared_buffers/effective_cache_size on m7 SIMU postgres instances,M7P-7658,105891,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,28/Jan/21 08:31,10/Feb/21 11:29,16/Sep/21 14:11,28/Jan/21 15:21,,6.8.151,7tops_sprint110,,,Database,,,,Database,M7PRODOPS,,,,,,"In Simulation we have the same faulty memory setup like it happened for M7 TEST CLUSTERS 

Proposal of memory settings is descriped in https://jira.deutsche-boerse.com/browse/M7P-7549
Will coordinate it with [~rehapav] and Auction team!

{code:java}
/var/lib/pgsql_enshrdebsmasync/data/11/enshrdebsmasync/postgresql.conf:shared_buffers = '4GB'  --> 2G
/var/lib/pgsql_m7aamprcutesync/data/11/m7aamprcutesync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7aamprsimusync/data/11/m7aamprsimusync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeerasimsync/data/11/m7axeerasimsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeercutesync/data/11/m7axeercutesync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeersimusync/data/11/m7axeersimusync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7cicsccuteasync/data/11/m7cicsccuteasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cshrddst1async/data/11/m7cshrddst1async/postgresql.conf:shared_buffers = '4GB' --> 2G
/var/lib/pgsql_m7teltsacutasync/data/11/m7teltsacutasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltsasimasync/data/11/m7teltsasimasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsctpbasync/data/11/m7teltsctpbasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltscuteasync/data/11/m7teltscuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltslipaasync/data/11/m7teltslipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltssimuasync/data/11/m7teltssimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tepexasimasync/data/11/m7tepexasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxasimasync/data/11/m7thupxasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxcuteasync/data/11/m7thupxcuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxsimuasync/data/11/m7thupxsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tplpxlipaasync/data/11/m7tplpxlipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tplpxsimuasync/data/11/m7tplpxsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrddst1async/data/11/m7tshrddst1async/postgresql.conf:shared_buffers = '32104MB' --> 2G
/var/lib/pgsql_m7tshrdexteasync/data/11/m7tshrdexteasync/postgresql.conf:shared_buffers = '4GB' --> 2G
/var/lib/pgsql_m7txrpmlipaasync/data/11/m7txrpmlipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txrpmsimuasync/data/11/m7txrpmsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopasimasync/data/11/m7txsopasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopcuteasync/data/11/m7txsopcuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopsimuasync/data/11/m7txsopsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
{code}

To-Do is descriped in ticket https://jira.deutsche-boerse.com/browse/M7P-7519
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,changed shared_buffers for all the simu patroni clustes.,,,,,,,,,,,,,,,,,,,,,,,,19872000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz7cf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,done,,,,,,,,,,"{""issueId"":105891,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"28/Jan/21 12:28;cs687;action done for following cluster: 
* enshrdebsmasync
* m7aamprcutesync
* m7aamprsimusync
* m7axeerasimsync
* m7axeersimusync
* m7axeercutesync
* m7cshrddst1async
* m7teltsacutasync
* m7tshrdexteasync
* m7tshrddst1async
* m7teltscuteasync
* m7teltsctpbasync
* m7teltslipaasync
* m7teltslipaasync
* m7thupxcuteasync
* m7thupxasimasync
* m7thupxsimuasync
* m7tplpxlipaasync
* m7tplpxsimuasync
* m7txrpmlipaasync
* m7txrpmsimuasync
* m7tepexasimasync
* m7txsopasimasync
* m7txsopcuteasync
* m7txsopsimuasync","28/Jan/21 14:11;cs687;ones I touched m7teltsacutasync cluster, 
core switched over to HAUSEN and H2H4U crashed and sob was/is obviosity not connected anymore, even the health-check is saying something different
{code:java}
tomcat@m7eltsacutm7b2:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""components"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""ping"":{""status"":""UP""},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7eltsacutm7b2:[/elts]$
{code}

afterwards I stopped cor2 and switch back to cor1 as MASTER nothing changed!
{code:java}
2021-01-28T13:09:52.443Z [taskScheduler-1] ERROR sob-gateway - java.util.concurrent.CancellationException
java.util.concurrent.CompletionException: java.util.concurrent.CancellationException
{code}

","28/Jan/21 15:21;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Add CPUs to m7shrdinterep1 and m7shrdinterep2 to be 6,M7P-7654,105830,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,op211,pw231,pw231,27/Jan/21 09:15,02/Feb/21 23:20,16/Sep/21 14:11,27/Jan/21 09:33,,6.11.184,7tops_sprint109,,,uknown,,,,7tops,OPS,PERFORMANCE,,,,,"h4. problem
Currently, there is only 2 cpus on the machines.
However, we are deploying all reporters here (reporters are more CPU based than reporting engine, especial on envs like syt1).

h4. solution
in order to deploy all the reporters onside with reporting-engines, we need more cpus there, suggested : 6.",,pw231,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,20044800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwnz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105830,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/21 09:29;yo218;both hosts have 6 cores now",,,,,,,,,,,,,,,,,,,,,,,,,,,
test 6.11 deployment including TC550 and Kafka cluster,M7P-7646,105739,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,25/Jan/21 13:47,24/Mar/21 11:26,16/Sep/21 14:11,22/Mar/21 08:22,,6.11.217,7tops_sprint113,,,ansible,,,,7tops_comm,S,,,,,,"Perform test of consolidated deployment of
 * Kafka clsuter
 * 6.11 software including TC550 into

 
 * into ETLS CTPB",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"every changes are described in 
https://jira.deutsche-boerse.com/browse/SERVICE-9981",,,,,,,,,,,,,,,,,,,,,,,,15379200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz89r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,,all detailed information are described in SERVICE-9981,,,,,,,,,,"{""issueId"":105739,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 16:18;rehapav;[http://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Kafka]
we have there Setup procedure & Links to Jenkins Ansible Deployments  & Monitoring","22/Mar/21 08:22;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
test Kafka cluster deployment - internal test environment,M7P-7644,105735,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,rehapav,rehapav,25/Jan/21 13:09,24/Mar/21 11:26,16/Sep/21 14:11,22/Mar/21 08:28,,6.11.217,7tops_sprint113,,,Reporter,,,,7tops_comm,S,,,,,,"Kafka architecture has been agreed within discussion around document

[https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?spaceKey=BIZOPS&title=Kafka]

Necessary VMs have been requested in tickets: tbd

 

 

As part of this ticket PRODUCT team please: 
 * test deployment of Kafka cluster to Shared internal test environments ates*/sys* etc",,cs687,fp407,rehapav,,,,,,,,,,,,,,,,,M7P-7643,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Internal Test Kafka Cluster was successfully deployed 
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/shrd/inte/kafka_broker/main.yml
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/shrd/inte/kafka_zookeeper/main.yml

the following steps were executed:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/playbooks/kafka/readme.md
Chapter: *Cluster deployment procedure*",,,,,,,,,,,,,,,,,,,,,,,,15379200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz88v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,"refer ""change description""",,,,,,,,,,"{""issueId"":105735,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/21 16:01;fp407;[~rehapav] [~pn508] tested - deployment works, this ticket should not be blocking anything (especially because cluster delivery from syseng will take a some non-trivial time)","22/Mar/21 08:28;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
test Kafka cluster deployment - customer test environments,M7P-7643,105734,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,25/Jan/21 13:09,05/May/21 11:17,16/Sep/21 14:11,29/Apr/21 08:20,,6.11.217,6.12.12,7tops_sprint116,,devops,,,,M7PRODOPS,S,,,,,," 

 

Kafka architecture has been agreed within discussion around document

[https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?spaceKey=BIZOPS&title=Kafka]

Necessary VMs have been requested in tickets: tbd

 

As part of this tickettechops  please:
 * -test deployment of Kafka cluster to ELTS PROD-
 * -test deployment of Kafka cluster to ETLS ASIM-
 * -test deployment of Kafka cluster to Share test environments ELTS ACUT/CUTE/LIPA/CTPB/SIMU-
 * test deployment of Kafka cluster to systemtest1 (later on to pre-prod)

 

VMs for Kafka in ELTS ASIM are ready SYSENGINT-306 ",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,done all clusters provided ,,,,,,,,,,,,,,,,,,,,,,,,12096000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwon:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":105734,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 16:18;rehapav;[http://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Kafka]
we have there Setup procedure & Links to Jenkins Ansible Deployments  & Monitoring","15/Feb/21 08:24;cs687;ELTS-ASIM Deployment: 
before the deploymnet 
* checked the firewall-setting, described in M7P-7747
""added a comment - 15/Feb/21 07:48""
* added vault secret ""m7t/elts/asim/kafka/users/application/user_m7teltsasim_m7core""

* Jobs triggered: generate-certificates-and-technical-users
** certs and technical users are created on the zookeeper hosts 
** items are saved in vault m7t/elts/asim/kafka/certs/
* Jobs triggered: deploy_cluster 
** we failed because of missing RH Satellite packages ""confluent-platform-2.11.noarch""
** waiting SYSENGINT to add the package to the proper channel 

UPDATE:
* after adding the proper channels to the elts-asim kafka hosts, the deployment of kafka cluster were running without any issues. 
* deployed monitoring clients on the kafka machines

{code:java}
[root@m7eltsasimkbr3 ~]# systemctl status telegraf.service
● telegraf.service - The plugin-driven server agent for reporting metrics into InfluxDB
   Loaded: loaded (/usr/lib/systemd/system/telegraf.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2021-02-17 08:10:12 CET; 43s ago
     Docs: https://github.com/influxdata/telegraf
 Main PID: 106598 (telegraf)
   CGroup: /system.slice/telegraf.service
           └─106598 /usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d

Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de systemd[1]: Started The plugin-driven server agent for reporting metrics into InfluxDB.
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Starting Telegraf 1.13.2
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Loaded inputs: system processes cpu mem net kernel swap ping dns_query disk diskio jolokia2_agent
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Loaded aggregators:
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Loaded processors:
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Loaded outputs: influxdb
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! Tags enabled: client=elts client_environment=asim datacenter=equinix group=kafka host=m7eltsasimkbr3 host_group_module=m7eltsasi...im product=m7t
Feb 17 08:10:12 m7eltsasimkbr3.deutsche-boerse.de telegraf[106598]: 2021-02-17T07:10:12Z I! [agent] Config: Interval:30s, Quiet:false, Hostname:""m7eltsasimkbr3"", Flush Interval:30s
Hint: Some lines were ellipsized, use -l to show in full.


[root@m7eltsasimkbr3 ~]# systemctl status filebeat.service
● filebeat.service - filebeat
   Loaded: loaded (/usr/lib/systemd/system/filebeat.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2021-02-17 08:09:32 CET; 1min 32s ago
     Docs: https://www.elastic.co/guide/en/beats/filebeat/current/index.html
 Main PID: 105843 (filebeat)
   CGroup: /system.slice/filebeat.service
           └─105843 /usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat -strict.perms=false

Feb 17 08:09:32 m7eltsasimkbr3.deutsche-boerse.de systemd[1]: Started filebeat.
{code}

*looks like monitoring is working for elts-asim kafka-cluster*
https://grafana.energy.svc.dbgcloud.io/d/GF7EmQBGz/kafka-clusters?orgId=2&refresh=5s&var-client=elts&var-client_env=asim

*cluster is up and running - checking on zookeeper host:*
{code:java}

[root@m7eltsasimkzk3 ~]# zookeeper-shell localhost:2181 ls /brokers/ids
Connecting to localhost:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[1, 2, 3]
[root@m7eltsasimkzk3 ~]#
{code}

","18/Feb/21 07:43;cs687;SHARED SIMU Deployment:
before the deployment

* checked the firewall-settings, described in M7P-7747
* triggered Job: ""generate-certificates-and-technical-users""
** checked refreshed vault-settings: ""m7t/shrd/simu/kafka/""
* triggered Job: ""deploy_cluster""
* triggered Job: ""Monitoring Clients""

*before the deployment:*
{code:java}
[root@m7shrdsimukzk1 ~]# zookeeper-shell localhost:2181 ls /brokers/ids
Connecting to localhost:2181
KeeperErrorCode = ConnectionLoss for /brokers/ids
{code}

*after the deployment:*
{code:java}
[root@m7shrdsimukzk1 ~]# zookeeper-shell localhost:2181 ls /brokers/ids
Connecting to localhost:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[1, 2, 3]
{code}

","22/Mar/21 08:30;cs687;Waiting for provisioning of the following machines:
* https://jira.deutsche-boerse.com/browse/SYSENGINT-309 *systemtest1/pre-prod*
* https://jira.deutsche-boerse.com/browse/SYSENGINT-305 *Kafka - cluster for ELTS PROD*

","29/Apr/21 08:20;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
copy ebsm scripts to testdpu.srv.energy,M7P-7642,105726,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,25/Jan/21 12:17,07/Apr/21 12:31,16/Sep/21 14:11,01/Apr/21 12:38,,6.11.223,7tops_sprint114,,,EBSM,,,,7tops_comm,EBSM,M,,,,,"1) create users on new ebsm dpu host (testdpu.srv.energy)
 * ebsmrun:ebsmrun
 * logmover:logmover
 * logreader:logreader
 * transfer:transfer

2) Copy ebsm script resources to testdpu.srv.energy: (ebsmrun:ebsmrun)

/opt/ebsm/ebsm-etl.jar
 /opt/ebsm/artifacts/
 /opt/ebsm/backup/
 /opt/ebsm/bash/
 /opt/ebsm/logs/
 /opt/ebsm/properties/
 /opt/ebsm/sql/

3) Copy logmover scripts from /opt/logmover/ (logmover:logmover)

4) Copy all files from /home/logreader/logparser/ (logreader:logreader)

5) Copy all subfolders from /home/logmover/ (logmover:logmover)",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,15638400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8af:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105726,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Mar/21 09:01;iu252;1) users and groups - done (Thanks to [~cv524] https://jira.deutsche-boerse.com/browse/SYSENGINT-483):

{noformat}
tomcat:x:500:500::/home/tomcat:/bin/bash
logmover:x:2002:2002::/opt/data/home/logmover:/bin/bash
ebsmrun:x:2001:2001::/home/ebsm:/bin/bash
logreader:x:2009:2009::/opt/data/home/logreader:/bin/bash
transfer:x:2010:2010::/opt/data/home/transfer:/bin/bash
[root@testdpu ~]#
{noformat}

created additional one: ebsmbox","09/Mar/21 09:10;iu252;2) directories created:


{noformat}
[root@testdpu ebsm]# pwd
/opt/ebsm
[root@testdpu ebsm]# ll
total 24
drwxr-xr-x 2 root    ebsmrun 4096 Mar  9 09:05 artifacts
drwxr-xr-x 2 root    root    4096 Mar  9 09:05 backup
drwxr-xr-x 2 root    ebsmrun 4096 Mar  9 09:06 bash
drwxr-xr-x 2 root    root    4096 Mar  9 09:06 logs
drwxrwxr-x 2 ebsmrun ebsmrun 4096 Mar  9 09:06 properties
drwxrwxr-x 2 ebsmrun ebsmrun 4096 Mar  9 09:06 sql
[root@testdpu ebsm]#
{noformat}
","09/Mar/21 09:32;iu252;scripts:

{noformat}
[root@testdpu ebsm]# ll ebsm-etl.jar
-rw-r--r-- 1 ebsmrun ebsmrun 17638986 Mar  9 09:12 ebsm-etl.jar
[root@testdpu ebsm]#
{noformat}

{noformat}
[root@testdpu ebsm]# ll artifacts/
total 284
-rw-r--r-- 1 root ebsmrun  32875 Aug  1  2018 truezip-driver-tar-7.7.10.jar
-rw-r--r-- 1 root ebsmrun 253158 Aug  1  2018 truezip-driver-zip-7.7.10.jar
[root@testdpu ebsm]#
{noformat}


{noformat}
[root@testdpu ebsm]# ll backup
total 174476
-rw-r--r-- 1 root ebsmrun 13665905 Aug  1  2018 ebsm-etl-01.jar
-rw-r--r-- 1 root ebsmrun 13660942 Aug  1  2018 ebsm-etl-02.jar
-rw-r--r-- 1 root ebsmrun 13663888 Aug  1  2018 ebsm-etl-03.jar
-rw-r--r-- 1 root ebsmrun 13664051 Aug  1  2018 ebsm-etl-04.jar
-rw-r--r-- 1 root ebsmrun 13714697 Aug  1  2018 ebsm-etl-05.jar
-rw-r--r-- 1 root ebsmrun 13714696 Aug  1  2018 ebsm-etl-06.jar
-rw-r--r-- 1 root ebsmrun 13732692 Aug  1  2018 ebsm-etl-09.jar
-rw-r--r-- 1 root ebsmrun 13732692 Aug 22  2018 ebsm-etl-10.jar
-rw-r--r-- 1 root ebsmrun 13816321 Aug 22  2018 ebsm-etl-11.jar
-rw-r--r-- 1 root root    13816599 Aug 24  2018 ebsm-etl-12.jar
-rw-r--r-- 1 root root    13816333 Aug 24  2018 ebsm-etl-13.jar
-rw-r--r-- 1 root root    13816488 Aug 30  2018 ebsm-etl-14.jar
-rw-r--r-- 1 root root    13816506 Sep  5  2018 ebsm-etl-15.jar
{noformat}

{noformat}
[root@testdpu ebsm]# ll bash
total 48
drwxr-xr-x 2 root    root    4096 Aug  7  2018 backup
-rwxr-xr-x 1 root    ebsmrun 4391 Aug  1  2018 ebsmDaily.sh
-rwxr-xr-x 1 root    ebsmrun 3880 Aug  1  2018 ebsmMonthly.sh
-rwxrwxrwx 1 ebsmrun ebsmrun 9824 Jun 23  2020 ebsmscript_db2.sh
-rwxr-xr-x 1 ebsmrun ebsmrun 9788 Jun 23  2020 ebsmscript.sh
-rwxrwxrwx 1 root    root      14 Aug 18  2018 ebsmtest.log
-rwxrwxrwx 1 root    root      64 Aug 18  2018 ebsmtest.sh
{noformat}


{noformat}
root@testdpu ebsm]# ll logs
total 0
-rw-r--r-- 1 root root 0 Mar  9 09:28 ebsmrun
[root@testdpu ebsm]#
{noformat}


{noformat}
[root@testdpu ebsm]# ll properties
total 12
-rw-r--r-- 1 ebsmrun ebsmrun  500 Jan 17 10:46 GnrlSysJobs.properties
-rw-rw-r-- 1 ebsmrun ebsmrun 1545 Jul 13  2020 log4j.properties
-rw-rw-r-- 1 ebsmrun ebsmrun 1393 Jan 25 14:00 Logfile.properties
[root@testdpu ebsm]#
{noformat}

sql-directory is empty","11/Mar/21 11:16;iu252;3) done

{noformat}
[root@testdpu m7-logs]# ls -l /opt/logmover/
total 46140
drwxr-xr-x 2 logmover logmover    4096 May  4  2018 artifacts
drwxr-xr-x 6 logmover logmover    4096 Sep  5  2018 backup
drwxr-xr-x 2 logmover logmover    4096 Mar  8 13:12 bash
-rw-rw-r-- 1 logmover logmover 8325094 Jan  3  2019 logmover-all.jar
-rw-rw-r-- 1 logmover logmover 8324841 Dec 17 13:17 logmover-archiver.jar
-rw-rw-r-- 1 logmover logmover 8325118 Dec 10  2018 logmover-daymonth_backup.jar
-rw-r--r-- 1 logmover logmover 8324842 Dec 17 12:46 logmover-daymonth.jar
-rw-rw-r-- 1 logmover logmover 8325096 Jan  3  2019 logmover-inbox.jar
-rw-rw-r-- 1 logmover logmover 5594858 Aug 24  2018 logmover.jar
drwxr-xr-x 2 logmover logmover    4096 Jan 25 13:59 properties
[root@testdpu m7-logs]#
{noformat}
","11/Mar/21 11:17;iu252;4) /home/logreader/logparser/:

{noformat}
[root@testdpu m7-logs]# ll /home/logreader/logparser/
total 173084
-rw-rw-r-- 1 logreader logreader 77075069 Sep  3  2020 API_raw-data-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader 81523978 Sep  3  2020 API_raw-data-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader   390548 Sep  3  2020 API_report-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader   397969 Sep  3  2020 API_report-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader     1293 Oct  4  2017 conf.properties
-rw-rw-r-- 1 logreader logreader  4776432 Sep  3  2020 CT_raw-data-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader  3942170 Sep  3  2020 CT_raw-data-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader   696931 Sep  3  2020 CT_report-2020-08-27.csv
-rw-rw-r-- 1 logreader logreader   654233 Sep  3  2020 CT_report-2020-09-01.csv
-rw-rw-r-- 1 logreader logreader     1575 Mar  2 11:07 elts-asim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1544 Sep  4  2020 elts-prod-2days-configuration.properties
-rw-rw-r-- 1 logreader logreader     1544 Nov  2 11:20 elts-prod-configuration.properties
-rw-rw-r-- 1 logreader logreader     1607 Sep 26 11:40 elts-simu-configuration.properties
-rw-rw-r-- 1 logreader logreader     1575 Aug 11  2020 epex-asim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1571 Aug 11  2020 epex-fsim-configuration.properties
-rw-rw-r-- 1 logreader logreader     1550 Aug 11  2020 flex-prod-configuration.properties
-rw-rw-r-- 1 logreader logreader    16270 Oct 25  2018 hs_err_pid38432.log
-rw-r--r-- 1 logreader logreader     1393 Oct 15  2018 kombi2-configuration.properties
-rw-rw-r-- 1 logreader logreader     1463 Aug 11  2020 kombi-configuration.properties
-rw-r--r-- 1 logreader logreader     1371 Oct 11  2018 logback.xml
-rw-rw-r-- 1 logreader logreader  3838439 Jul 16  2019 logparser_backup.jar
-rw-rw-r-- 1 logreader logreader  3838573 Aug 11  2020 logparser.jar
drwxr-xr-x 3 logreader logreader     4096 Mar 10 07:25 logs
drwxrwxr-x 2 logreader logreader     4096 Aug 11  2020 report-backup
[root@testdpu m7-logs]#
{noformat}
","11/Mar/21 11:19;iu252;Installed missing java:

{noformat}
 yum install XBID-zulu-8.x86_64
{noformat}
","11/Mar/21 11:22;iu252;Modified /etc/ssh/sshd_config:


{noformat}
# Make exception for automation users to allow locally stored public keys
Match User ansible,globmon,scanmgr,tomcat,ebsmbox,logmover,logreader,ebsmrun
  AuthorizedKeysFile .ssh/authorized_keys
{noformat}

restarted ssh daemon

{noformat}
[root@testdpu ssh]# systemctl restart sshd
[root@testdpu ssh]#
{noformat}
","11/Mar/21 11:26;iu252;Created symbolic link:


{noformat}
[root@testdpu ebsm]# ln -s /net/testdata.srv.energy/m7-inbox /var/log/ebsm/inbox
[root@testdpu ebsm]# ll /var/log/ebsm
total 0
lrwxrwxrwx 1 root root 33 Mar 11 10:48 inbox -> /net/testdata.srv.energy/m7-inbox
[root@testdpu ebsm]#
{noformat}
","19/Mar/21 09:45;iu252;5. done

{noformat}
[root@testdpu ~]# ll /home/logmover/m7/
total 28
drwxrwxrwx 2 logmover logmover 4096 Mar 19 09:28 1inbox
drwxrwxrwx 4 logmover logmover 4096 Mar 10 14:35 2currentDay
drwxrwxrwx 4 logmover logmover 4096 Mar 17 13:50 3unarchivedLogs
drwxrwxrwx 3 logmover logmover 4096 Mar 12 14:32 4archiveDays
drwxrwxrwx 2 logmover logmover 4096 Mar 10 10:07 5archiveMonths
drwxrwxr-x 2 logmover logmover 4096 Mar 17 13:50 6ignoredFiles
drwxrwxrwx 4 logmover logmover 4096 Mar 18 09:30 9sla
{noformat}
",,,,,,,,,,,,,,,,,,,
reroute the log sending tool for SYT1,M7P-7641,105725,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,25/Jan/21 12:14,24/Mar/21 11:26,16/Sep/21 14:11,19/Mar/21 09:43,,6.11.217,7tops_sprint113,,,EBSM,,,,7tops_comm,EBSM,M,,,,,"1) Please reroute the log sending tool for SYT1 so it will send logs to *testdata.srv.energy* instead of m7shrdebsm1.

2) Create corresponding folder structure (no files, just folders):
 * /home/ebsm/
 * /home/ebsm/failed/
 * /home/ebsm/history/
 * /home/ebsm/inbox/
 * /home/ebsm/logs/
 * /home/ebsm/outbox/
 * /home/ebsm/queue/
 * /home/ebsm/temp/",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,15638400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz8a7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105725,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/21 09:37;iu252;1. done

{noformat}
[tomcat@m7tenrgsyt1m7c1 ~]$ crontab -l
#Ansible: clean_journal.ksh
0 6 * * * /shrd/prodscripts/clean_journal.ksh
#Ansible: transfer_log_app
53 0,6,10,14,18 * * * /shrd/prodscripts/transfer_log.sh
[tomcat@m7tenrgsyt1m7c1 ~]$
[tomcat@m7tenrgsyt1m7c1 ~]$
[tomcat@m7tenrgsyt1m7c1 ~]$
[tomcat@m7tenrgsyt1m7c1 ~]$ grep dpu /shrd/prodscripts/transfer_log.sh
dpu_user=""ebsmbox""
dpu_host=""testdpu.srv.energy""
dpu_path=""/net/testdata.srv.energy/m7-inbox""
        scp -p ${file} ${dpu_user}@${dpu_host}:${dpu_path}/${filename}.filepart
        ssh ${dpu_user}@${dpu_host} chmod 777 ${dpu_path}/${filename}.filepart
        ssh ${dpu_user}@${dpu_host} mv ${dpu_path}/${filename}.filepart ${dpu_path}/${filename}
[tomcat@m7tenrgsyt1m7c1 ~]$
{noformat}
","19/Mar/21 09:40;iu252;2. done

{noformat}
[root@testdpu ~]# ll /home/ebsm/
total 8
drwxr-xr-x 8 ebsmrun ebsmrun 4096 Mar 17 09:26 m7
drwxr-xr-x 8 ebsmrun ebsmrun 4096 Mar 17 09:33 xbid
[root@testdpu ~]# ll /home/ebsm/m7/
total 24
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 10 09:56 failed
drwxr-xr-x 3 ebsmrun ebsmrun 4096 Mar 18 11:56 history
lrwxrwxrwx 1 root    root      33 Mar 17 09:26 inbox -> /net/testdata.srv.energy/m7-inbox
drwxr-xr-x 3 ebsmrun ebsmrun 4096 Mar 19 09:26 logs
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 19 07:28 outbox
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 10 09:56 queue
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 10 09:56 temp
[root@testdpu ~]# ll /home/ebsm/xbid/
total 24
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:32 failed
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:32 history
lrwxrwxrwx 1 root    root      35 Mar 17 09:29 inbox -> /net/testdata.srv.energy/xbid-inbox
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:36 logs
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:32 outbox
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:33 queue
drwxr-xr-x 2 ebsmrun ebsmrun 4096 Mar 17 09:33 temp
[root@testdpu ~]#
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,
create EBSM database at M7TESTDBR1/2,M7P-7640,105722,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,dp007,dp007,25/Jan/21 12:04,24/Mar/21 11:26,16/Sep/21 14:11,22/Mar/21 11:50,,6.11.217,7tops_sprint113,,,EBSM,,,,7tops_comm,EBSM,M,,,,,"Create the db dump of the current ebsm db (m7simupdbX:24059) and clone it to the new location (M7TESTDBR1/2)

If more info needed please contact Andrei Nazarenko.",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/21 10:14;dp007;ebsmtestdb_cleanup.sql;https://jira.deutsche-boerse.com/secure/attachment/93475/ebsmtestdb_cleanup.sql",,,,,,,,,,,,,,,sw455,,,,,,,,EBSM-testdb created on m7testdbr1/2,,,,,,,,,,,,,,,,,,,,,,,,16848000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwwv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105722,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"18/Feb/21 11:37;iu252;Merged PR after review and approval:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2554","25/Feb/21 11:48;iu252;Patroni cluster deployed:


{noformat}
[root@m7testpdb1 INSTALL]# patronictl -c /etc/patroni_enshrdtestebsm/config.yml list
+----------------+------------+----------------------+--------+------------------+----+-----------+
|    Cluster     |   Member   |         Host         |  Role  |      State       | TL | Lag in MB |
+----------------+------------+----------------------+--------+------------------+----+-----------+
| enshrdtestebsm | m7testdbr1 | 10.139.133.221:26034 |        | creating replica |    |   unknown |
| enshrdtestebsm | m7testdbr2 | 10.139.133.222:26034 |        | creating replica |    |   unknown |
| enshrdtestebsm | m7testpdb1 | 10.139.58.178:26034  | Leader |     running      |  3 |         0 |
| enshrdtestebsm | m7testpdb2 | 10.139.58.177:26034  |        |     running      |  2 |        16 |
+----------------+------------+----------------------+--------+------------------+----+-----------+

{noformat}
","25/Feb/21 11:49;iu252;Created admin scripts:


{noformat}
[root@m7testpdb1 ~]# cd /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/
[root@m7testpdb1 INSTALL]# ll
total 24
-rwx------ 1 postgres postgres 101 Feb 24 13:44 001_DROP_DATABASE.sql
-rwx------ 1 postgres postgres 189 Feb 24 13:45 010_CREATE_DATABASE.sql
-rwx------ 1 postgres postgres  75 Feb 24 13:46 020_CREATE_SCHEMA.sql
-rwx------ 1 postgres postgres 133 Feb 24 13:48 030_ALTER_ROLE.sql
-rwx------ 1 postgres postgres 761 Feb 24 13:58 034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
-rwx------ 1 postgres postgres 137 Feb 24 13:53 035_CREATE_NETBACKUP_ROLE.sql
{noformat}
","25/Feb/21 11:50;iu252;Executed scripts:


{noformat}
-bash-4.2$ psql -p 26034
psql (11.5)
Type ""help"" for help.

postgres=# \i /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql
psql:/var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql:1: ERROR:  role ""ebsm"" already exists
psql:/var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql:2: ERROR:  database ""ebsm"" already exists
ALTER DATABASE
psql:/var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/010_CREATE_DATABASE.sql:4: ERROR:  role ""ebsm"" already exists
CREATE ROLE
postgres=# \i /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/020_CREATE_SCHEMA.sql
You are now connected to database ""ebsm"" as user ""postgres"".
CREATE SCHEMA
DROP SCHEMA
ebsm=# \i /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/03
030_ALTER_ROLE.sql                          034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql  035_CREATE_NETBACKUP_ROLE.sql
ebsm=# \i /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/030_ALTER_ROLE.sql
ALTER ROLE
ALTER ROLE
ebsm=# \i /var/lib/pgsql_enshrdtestebsm/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
You are now connected to database ""ebsm"" as user ""ebsm"".
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
ALTER DEFAULT PRIVILEGES
GRANT
GRANT
ebsm=> \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 ebsm      | ebsm     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/ebsm             +
           |          |          |             |             | ebsm=CTc/ebsm        +
           |          |          |             |             | ebsmadmin=c/ebsm
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

ebsm=>

{noformat}
","05/Mar/21 10:14;dp007;cleanup script [^ebsmtestdb_cleanup.sql]executed",,,,,,,,,,,,,,,,,,,,,,,
EBSM technical changes,M7P-7622,105603,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,dp007,dm700,dm700,21/Jan/21 15:30,21/Apr/21 11:28,16/Sep/21 14:11,15/Apr/21 10:00,,7tops_sprint115,,,,EBSM,,,,7tops,,,,,,,"- Create user 
- prepare EBSM database
- modify scripts to send logs",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,13305600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwxb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105603,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/21 10:00;dp007;closing, ticket duplicating multiple subtasks which are in various states of affair",,,,,,,,,,,,,,,,,,,,,,,,,,,
EBSM basic reconfiguration,M7P-7621,105602,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,dp007,dm700,dm700,21/Jan/21 15:28,21/Apr/21 11:28,16/Sep/21 14:11,15/Apr/21 09:58,,7tops_sprint115,,,,EBSM,,,,7tops,,,,,,,,,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,N/A,,,,,,,,,,,,,,,,,,,,,,,,13305600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwx3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105602,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/21 09:58;dp007;ticket replaced with:
 * M7P-7959
 * M7P-7960
 * M7P-7961",,,,,,,,,,,,,,,,,,,,,,,,,,,
alerting not working properly,M7P-7620,105599,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pd122,pd122,21/Jan/21 15:11,10/Feb/21 11:29,16/Sep/21 14:11,02/Feb/21 15:15,,6.11.184,7tops_sprint110,,,Monitoring,,,,7tops_comm,Alarm_Tilt,AlarmTILT,Monitoring,MONITORING,,,"There were several critical aletrs received in the m7_prod_alerts Slack channel on Sunday 17/1/2021:

07:51
jenkinsAPP 
Service PROBLEM notification
Host: m7prodpdb1 (IP: 10.139.53.176)
Service: Filesystem /var/lib/pgsql_m7teltsprodasync/data
State: CRITICAL
Additional Info
CRIT - 95.06% used (755.59 of 794.85 GB), (warn/crit at 90.0%/95.0%), trend: +164.57 GB / 24 hours
Please take a look: @opsgenie, @cmkadmin
Check_MK notification: Sun Jan 17 07:51:19 CET 2021

08:01
kapacitorAPP 
CRITICAL on m7prodpdb1 | Mount: /var/lib/pgsql_m7teltsprodasync/data - used: 96% - 816 GB/854 GB Used/Total

08:26
kapacitorAPP 
CRITICAL on m7eltsprodm7b1 - m7t - elts - prod - h2h4u1 | Application health check status: DOWN

08:27
watcherAPP 
Tomcat Failover
Encountered 3 failover(s) in the last 5 minutes.
m7eltsprodm7c2 - 2021-01-17T07:24:21.660Z

************ FAILOVER *****************
** Node Id     : cor2
** Node Status : MASTER
**************************************
m7eltsprodm7c1 - 2021-01-17T07:24:13.252Z

************ FAILOVER *****************
** Node Id     : cor1
** Node Status : SLAVE
**************************************
m7eltsprodm7c2 - 2021-01-17T07:24:52.893Z

************ FAILOVER *****************
** Node Id     : cor2
** Node Status : SLAVE
**************************************

08:28
kapacitorAPP 
CRITICAL on m7eltsprodm7b1 - m7t - elts - prod - enq1 | Application health check status: DOWN
08:28
CRITICAL on m7eltsprodm7c1 - m7t - elts - prod - cor1 | Application health check status: DOWN
08:28
CRITICAL on m7shrdprodrep2 - m7t - elts - prod - rep2 | Application health check status: DOWN
08:28
CRITICAL on m7shrdprodrep1 - m7t - elts - prod - rep1 | Application health check status: DOWN
08:28
CRITICAL on m7eltsprodm7c2 - m7t - elts - prod - cor2 | Application health check status: DOWN
08:29
CRITICAL on m7eltsprodm7b2 - m7t - elts - prod - enq2 | Application health check status: DOWN

08:31
jenkinsAPP 
@channel please check m7eltsprodm7c2 - after failover, no MASTER was detected! A manual restart might be required. omg..

08:32
kapacitorAPP 
m7prodpdb1 - m7t - elts - prod - pdb-async1 is not sending postgres data.

08:48
kapacitorAPP 
m7prodpdb1 - m7t - elts - prod - pdb-async1 is sending postgres data.
08:52
m7prodpdb1 - m7t - elts - prod - pdb-async1 is not sending postgres data.

All those alerts resulted in 5 phone calls at given times (phone screenshots attached):
8:26
8:28
8:29
8:32
8:52

There were additional critical alerts later on that day but they did not trigger any phone calls.",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-4425,,,,,,"26/Jan/21 12:21;pd122;1st_critical_alerts_in Slack_on_17_1_2021.png;https://jira.deutsche-boerse.com/secure/attachment/92065/1st_critical_alerts_in+Slack_on_17_1_2021.png","26/Jan/21 12:19;pd122;AlarmTilt_Voice_Messages_on_17_1_2021.png;https://jira.deutsche-boerse.com/secure/attachment/92064/AlarmTilt_Voice_Messages_on_17_1_2021.png","21/Jan/21 15:11;pd122;IMG_3562.PNG;https://jira.deutsche-boerse.com/secure/attachment/91952/IMG_3562.PNG","21/Jan/21 15:11;pd122;IMG_3563.PNG;https://jira.deutsche-boerse.com/secure/attachment/91951/IMG_3563.PNG",,,,,,,,,,,,sw455,,,,,,,,fixed in [XP-4425],,,,,,,,,,,,,,,,,,,,,,,,20131200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyrj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105599,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"25/Jan/21 19:12;pd122;Based on Alermtilt history, the first alert that went off on 17/11 was 8:28:02  - which was indeed the 1st call I have received.  This means there were *no calls* triggered by 3 preceding critical alerts or tomcat failover on production that followed the failure of the 1st core.  The alert that seems to have actually triggered the call was complete app failure at 8:28. At this time the DB data volume on leader was already at 100%.","26/Jan/21 12:23;pd122;screenshot of *1st critical alerts* in Slack *m7_prod_alerts* channel on the morning of 17/1/2021 is now attached.",,,,,,,,,,,,,,,,,,,,,,,,,,
S3 Bucket for Terraform State File and Terraform Apply Changes,M7P-7611,105504,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,zs244,zs244,20/Jan/21 14:37,04/May/21 23:23,16/Sep/21 14:11,15/Apr/21 11:07,,6.12.12,7tops_sprint115,,,devops,,,,M7PRODOPS,,,,,,,"h2. Goal
 * s3-bucket for tf-state file for master & piotr4 (piro)
 * proper terraform apply on master & piotr4 --> diff=0 (prio)

h2.  Log
 - check if there is a s3-bucket in AWS ([https://signin.aws.amazon.com/saml)]
{quote} Account: dbg-product-sz (147020635585)
----
 EnergyDevelopment
 -> EnergyOperations
{quote}
 - master branch has S3 Bucket (s3-dbg-${var.PRODUCT_NAME}-${var.ENVIRONMENT}-docker-tfstate${var.DEPLOY_NAME}) with PRODUCT_NAME = ""energy"" and ENVIRONMENT = ""svc""

 ",,cs687,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/21 15:02;zs244;image-2021-01-20-15-02-53-079.png;https://jira.deutsche-boerse.com/secure/attachment/91892/image-2021-01-20-15-02-53-079.png",,,,,,,,,,,,,,,sw455,,,,,,,,"tf-state are saved in s3-buckets 

proper terraform apply on master is worker for all the docker nodes 
{code:java}

.....
~ module.docker-host.aws_instance.ec2_englob_wkr_auto_instance[48]
      tags.%:                  ""15"" => ""14""
      tags.PrincipalId:        ""AROAICTEVCXZ3IHEN4I4W:1618297579881387907"" => """"
      volume_tags.%:           ""14"" => ""12""
      volume_tags.DetachTime:  ""Tue Apr 13 2021 07:06:27 GMT+0000 (UTC)"" => """"
      volume_tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1618297579881387907"" => """"  ~ module.docker-host.aws_instance.ec2_englob_wkr_auto_instance[49]
      tags.%:                  ""15"" => ""14""
      tags.PrincipalId:        ""AROAICTEVCXZ3IHEN4I4W:1618472220739761344"" => """"
      volume_tags.%:           ""13"" => ""12""
      volume_tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1618472220739761344"" => """"Plan: 0 to add, 148 to change, 0 to destroy
{code}",,,,,,,,,,,,,,,,,,,,,,,,13305600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-6985,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz3n3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,done,,,,,,,,,,"{""issueId"":105504,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/21 15:02;zs244;!image-2021-01-20-15-02-53-079.png!","20/Jan/21 15:34;zs244;Seems like there is no tf-state bucket for piotr4 branch. Further investigation regarding the master branch tf-state files","20/Jan/21 16:27;zs244;[~cs687], terraform apply on master with englobautowkr 88 changes due to AWS interface changes. (49 nodes)
{quote}~ module.docker-host.aws_instance.ec2_englob_wkr_auto_instance[47]
 tags.%: ""15"" => ""14""
 tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """"
 volume_tags.%: ""13"" => ""12""
 volume_tags.Name: ""ebs-energy-svc-englob-wkr-auto-jenkins-volume"" => ""ec2-energy-svc-englob-wkr-auto-volume""
 volume_tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """" ~ module.docker-host.aws_instance.ec2_englob_wkr_auto_instance[48]
 tags.%: ""15"" => ""14""
 tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """"
 volume_tags.%: ""13"" => ""12""
 volume_tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """" ~ module.docker-host.aws_instance.ec2_englob_wkr_auto_instance[49]
 tags.%: ""15"" => ""14""
 tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """"
 volume_tags.%: ""13"" => ""12""
 volume_tags.PrincipalId: ""AROAICTEVCXZ3IHEN4I4W:1588747005757597118"" => """"Plan: 0 to add, 88 to change, 0 to destroy.
  
{quote}","17/Feb/21 17:15;zs244;Done with [~cs687]:
 * remove node *englobwkr-large0* from AWS
 * new branch of master, add ""englobwkr-large"" with s3-bucket
 * added terraform structure for ""englobwkr-large"" and made changes:

{quote}energy.docker.hosts/terraform/englobwkr-large/dbg-product-svc/backends.tfvars

key = ""energy-svc-englobwkr-large.tfstate""

 

vars.tfvars

DH_NODES_AUTO_COUNT = 1

DH_INSTANCE_SIZE = ""t2.large""

 

energy.docker.hosts/terraform/modules/englobwkr-large/main.tf

:s substitute all the copy-pasted ""englobwkr_auto"" to ""englobwkr_large""

 

energy.docker.hosts/terraform/englobwkr-large/main.tf
module ""docker-host"" {
  source = ""../modules/englobwkr-large""{quote} * cleaned the current tfstate
 * terraform apply so that ""englobwkr-large"" instance is created

{color:#de350b}#### open points{color}
 * {color:#de350b}Ansible playbook for englobwkr-large{color}
 * {color:#de350b}git merge to master{color}
 * {color:#de350b}same procedure for remaining piotr ""englobwkr-medium"", ""englobwkr-medium-shared"" and ""englobwkr-small""{color}
 * {color:#de350b}delete old instances from AWS (? terraform destroy from piotr branch ?){color}

 

{color:#de350b}#### further{color}
 * {color:#0747a6}{color:#de350b}englobwkr-auto apply (93 changes open){color}{color}
 * {color:#0747a6}{color:#de350b}check englobwkr-test {color}{color}","18/Feb/21 13:43;cs687;* destroyed old englobwkr-large0 node
{code:java}

Plan: 0 to add, 0 to change, 5 to destroy.

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

module.englobwkr-large.aws_route53_record.r53_record[0]: Destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A]
module.englobwkr-large.aws_route53_record.r53_record[0]: Still destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A, 10s elapsed]
module.englobwkr-large.aws_route53_record.r53_record[0]: Still destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A, 20s elapsed]
module.englobwkr-large.aws_route53_record.r53_record[0]: Still destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A, 30s elapsed]
module.englobwkr-large.aws_route53_record.r53_record[0]: Still destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A, 40s elapsed]
module.englobwkr-large.aws_route53_record.r53_record[0]: Still destroying... [id=ZFDCDES3AD7A3_englobwkr-large0.svc.dbgcloud.io._A, 50s elapsed]
{code}

* merged pull-request 
** https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/97
** executed: terraform apply
** executed: ansible-playbook docker-large.yml
** last but not leased, relaunched jenkins node 
https://englobjci1.deutsche-boerse.de/computer/englobwkr-large0/

Next Step: cleaning up all the other shared, medium nodes.
* englobwkr-medium (/)
* englobwkr-small (/)","15/Apr/21 11:07;cs687;done",,,,,,,,,,,,,,,,,,,,,,
Install HP Fortify tools version 20.2 on jenkins workers,M7P-7580,105367,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,HO764,HO764,18/Jan/21 09:00,10/Feb/21 11:29,16/Sep/21 14:11,02/Feb/21 12:48,,6.11.184,7tops_sprint110,,,infrastructure,,,,M7PRODOPS,,,,,,,"Please install HPF tools 20.2 (in addition to the tools already installed) to all jenkins workers of all types. Tools are at
https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2fsites%2fsp0823%2f400%5fPublication%2fIS%20IT%20Services%2fIS%20service%20catalogue%2fSSCA%20%2d%20Static%20Source%20Code%20Analysis%2fFortify%2fOfficial%20Releases%2f20%2e2%2e0&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6",,cs687,HO764,,,,,,,,,,,,,,,,M7P-7582,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/95/files
https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/96/files
prepared proper pull-request and redeployed it on all docker-nodes 

* ansible-playbook playbooks/docker-wkr.yml --limit englobwkr-auto*
",,,,,,,,,,,,,,,,,,,,,,,,19526400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzz4of:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":105367,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jan/21 11:05;cs687;just checked the repository (Master) 
* https://github.deutsche-boerse.de/dev/energy.docker.hosts/tree/master/ansible/roles/energy.hpefortify18
* https://github.deutsche-boerse.de/dev/energy.docker.hosts/tree/master/ansible/roles/energy.hpefortify19

seems like that are just copied paste ansible roles for different versions. 
need to add the proper ""tar.gz"" File to our antifactory and if we want to keep that structure copy&paste and add a new role energy.hpefortify20
and deploy all docker nodes with ansible. ","29/Jan/21 11:54;cs687;added the new version to the antifactory ->https://artifactory.dbgcloud.io/artifactory/webapp/#/artifacts/browse/tree/General/energy-prod-local/hpefortify

and prepared the pull-request for the new version 
https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/95/files

cleaned up the HPF_Version ansible roles and create a more generic one. 
also corrected the antifactory url.

","29/Jan/21 15:03;cs687;installed on auto3
{code:java}
± |master U:2 ✗| → ansible-playbook playbooks/docker-wkr.yml --limit englobwkr-auto3

PLAY [configure docker hosts] ***************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************************************************
ok: [englobwkr-auto3]

TASK [energy.hpefortify : Make sure untar and installation directories exist] ***************************************************************************************************************************************************************
ok: [englobwkr-auto3] => (item=/var/hpefortify)
ok: [englobwkr-auto3] => (item=/sw/cmqa/tools/HPEFortify/20.2.0)

TASK [energy.hpefortify : Fetch the HPE Fortify SCA tarball if needed] **********************************************************************************************************************************************************************
changed: [englobwkr-auto3]

TASK [energy.hpefortify : Unpack the HPE Fortify SCA tarball if needed] *********************************************************************************************************************************************************************
changed: [englobwkr-auto3]

TASK [energy.hpefortify : Get the HPE Fortify SCA licence file] *****************************************************************************************************************************************************************************
ok: [englobwkr-auto3]

TASK [energy.hpefortify : Execute the installation command] *********************************************************************************************************************************************************************************
changed: [englobwkr-auto3]

TASK [energy.hpefortify : Fetch the Fortify Certs and write it to a temp file] **************************************************************************************************************************************************************
ok: [englobwkr-auto3] => (item=PROD-DBG-CA)
ok: [englobwkr-auto3] => (item=PROD-DBG-ROOT-CA)
ok: [englobwkr-auto3] => (item=TEST-DBG-CA)
ok: [englobwkr-auto3] => (item=TEST-DBG-ROOT-CA)

TASK [energy.hpefortify : Import Fortify Certs to the store] ********************************************************************************************************************************************************************************
changed: [englobwkr-auto3] => (item=PROD-DBG-CA)
changed: [englobwkr-auto3] => (item=PROD-DBG-ROOT-CA)
changed: [englobwkr-auto3] => (item=TEST-DBG-CA)
changed: [englobwkr-auto3] => (item=TEST-DBG-ROOT-CA)

PLAY RECAP **********************************************************************************************************************************************************************************************************************************
englobwkr-auto3            : ok=8    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
{code}
","29/Jan/21 15:06;cs687;Vladimir will check it and we will continue on monday. ","02/Feb/21 10:34;cs687;Tuesday: 02.02.2021 

*installed the tool HPEFortify 20.2.0 on all docker nodes:*
* englobwkr-autoX
* just few hosts are failing 14/19/28

[~ek615] asked me to update the client.properties with the proper auth_token.
{code:java}
[root@ip-10-115-67-81 ~]# cat /sw/cmqa/tools/HPEFortify/20.2.0/Core/config/client.properties
# Set proper client_auth_token value. Either plaintext token or token encoded by pwtool can be used.
client_auth_token=
{code}

ticket is in waiting","02/Feb/21 12:18;cs687;[~ek615] confirmed it is working 
proper pull-request: https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/96/files
depending on the version we are going to deploy client.propertie file. 

going to deploy all the docker nodes with the new version again. ","02/Feb/21 12:48;cs687;done",,,,,,,,,,,,,,,,,,,,,
Java (Azul) 11 installation in parallel with current Java 8 for Stalker,M7P-7569,105196,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,nn481,nn481,14/Jan/21 09:19,27/Jan/21 11:16,16/Sep/21 14:11,15/Jan/21 17:19,,6.11.167,7tops_sprint109,,,uknown,,,,7tops,,,,,,,"We would like to have installed Java 11 Azul in parallel to current Java 8 on these hosts:
* m7shrdextestk1
* m7shrdintestk1

Thanks",,nn481,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Java 11 installed on m7shrdintestk1 m7shrdextestk1,,,,,,,,,,,,,,,,,,,,,,,,20995200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz3rj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105196,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/21 17:18;op211;Following package has been installed:
{noformat}
zulu-11.x86_64 : Azul Systems Zulu JDK 11.39+15 (11.0.7-b10){noformat}
Java 8 is still default:
{noformat}
[root@m7shrdextestk1 /]# java -version
openjdk version ""1.8.0_242""
OpenJDK Runtime Environment (Zulu 8.44.0.11-CA-linux64) (build 1.8.0_242-b20)
OpenJDK 64-Bit Server VM (Zulu 8.44.0.11-CA-linux64) (build 25.242-b20, mixed mode)
[root@m7shrdextestk1 /]#{noformat}
To switch host wide java executable use *alternatives* command:
{noformat}
[root@m7shrdextestk1 /]# alternatives --config java

There are 2 programs which provide 'java'.

Selection    Command
-----------------------------------------------
 + 1           /usr/lib/jvm/zulu-8/jre/bin/java
*  2           /usr/lib/jvm/zulu-11/bin/java

Enter to keep the current selection[+], or type selection number:{noformat}
If you want to use Java 11 directly, please refer to the direct path

{{/usr/lib/jvm/zulu-11/bin/java}}",,,,,,,,,,,,,,,,,,,,,,,,,,,
enhance software version overview for previous components version,M7P-7564,105169,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,13/Jan/21 14:47,13/Jan/21 15:05,16/Sep/21 14:11,,,,,,,,,,,7tops,TO_CI/CDAutoDistributedSys,TO_MonCloud,TO_VersionTool,,,,"Quite frequently we need to know what was ""previous"" installed version deployed to the respective environment.

Please extend [https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#middleware=true]
to display, additional to already present components version, previously changed version?
(at the moment i allways go to historical deployment requests)",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21168000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz3mv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":105169,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"pg_watch add metrics ""pg_buffercache""",M7P-7549,105080,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,12/Jan/21 11:30,10/Feb/21 11:29,16/Sep/21 14:11,29/Jan/21 07:31,,6.11.184,7tops_sprint110,,,Database,,,,M7PRODOPS,,,,,,,"Like already described in ticket M7P-7519 we have in our patroni configuration oversized memory settings. 

In the ticket M7P-7519 is described how to analyze how much memory the database instances are currently consuming. 

*So the plan is*, before we are working on the ticket above and later on, at simu/prod staging we should collect proper pg_watch metrics to see in a longer term how much memory each shared database cluster-instance is using. 

Had a small discussion with Julian Markwort from cybertec about it and he also confirms that this is the safest way to see the real amount of memory what we have to use for each instance. 

For that we can try to use this queries to collect the proper pg_buffercache metrics and display them in grafana:

{code:java}
SELECT
    (extract(epoch FROM now()) * 1e9)::int8 AS epoch_ns,
    datname AS tag_database,
    count(
        CASE WHEN usagecount IS NULL THEN
            1
        END) * (current_setting('block_size')::int8) AS size_unused,
    count(
        CASE WHEN usagecount IS NOT NULL THEN
            1
        END) * (current_setting('block_size')::int8) AS size_used,
    count(*) * (current_setting('block_size')::int8) AS size_total
FROM
    pg_buffercache AS b,
    pg_database AS d
WHERE
    d.oid = b.reldatabase
GROUP BY
    ROLLUP (datname);
​{code}

*example Result:*
{code:java}
      epoch_ns       | tag_database | size_unused | size_used | size_total 
---------------------+--------------+-------------+-----------+------------
 1610447284142273792 |              |           0 |   3186688 |    3186688
 1610447284142273792 | postgres     |           0 |   2072576 |    2072576
 1610447284142273792 | konto        |           0 |    557056 |     557056
 1610447284142273792 | test         |           0 |    557056 |     557056
{code}

{code:java}
SELECT
    (extract(epoch FROM now()) * 1e9)::int8 AS epoch_ns,
    count(
        CASE WHEN usagecount IS NULL THEN
            1
        END) * (current_setting('block_size')::int8) AS size_unused,
    count(
        CASE WHEN usagecount IS NOT NULL THEN
            1
        END) * (current_setting('block_size')::int8) AS size_used,
    count(*) * (current_setting('block_size')::int8) AS size_total
FROM
    pg_buffercache AS b;
{code}

*example Result:*
{code:java}
      epoch_ns       | size_unused | size_used | size_total 
---------------------+-------------+-----------+------------
 1610447284149080064 |   130891776 |   3325952 |  134217728
{code}

once it is proofed how much space we need for each db-cluster instance we can set them in the inventory postgres.yml for each env and run the final action like described in ticket M7P-7519 continuing with simu/prod 

FYI: [~iu252],  [~hw120]",,cs687,cv179,hw120,,,,,,,,,,,,,,,M7P-7519,,,,,,,,,,,,,,,,M7P-7659,M7P-7658,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"going to prepare the memory setup how it was proposed in comment ""*added a comment - 27/Jan/21 15:37*""

For M7TEST and M7SIMU Database clusters its already rolled out.
Production-Clusters will come in a separate Maintenance. 

",,,,,,,,,,,,,,,,,,,,,,,,19872000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyrb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 109,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,see change description ,,,,,,,,,,"{""issueId"":105080,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"22/Jan/21 15:12;cs687;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1338/files
created a branch with adding the new metric in it. 

+*which steps are done:*+
deployed pg_watch2 with the new metric
{code:java}
[root@m7testpdb1 ~]# ls -all /opt/pg_watch2/metrics/buffercache_by_cluster/9.2/
total 4
drwxr-xr-x 2 pgwatch2 pgwatch2  24 Jan 22 14:09 .
drwxr-xr-x 3 pgwatch2 pgwatch2  17 Jan 22 14:09 ..
-rw-r--r-- 1 pgwatch2 pgwatch2 435 Jan 22 14:09 metric.sql
{code}

* Extension is already created and contrib package is installed
{code:java}
postgres=# CREATE EXTENSION pg_buffercache;      
ERROR:  extension ""pg_buffercache"" already exists
{code}

{code:java}
                                     List of installed extensions
        Name        | Version |   Schema   |                        Description
--------------------+---------+------------+-----------------------------------------------------------
 pg_buffercache     | 1.3     | public     | examine the shared buffer cache
 pg_stat_statements | 1.6     | public     | track execution statistics of all SQL statements executed
 pgstattuple        | 1.5     | public     | show tuple-level statistics
 plpgsql            | 1.0     | pg_catalog | PL/pgSQL procedural language
{code}

{code:java}
Installed Packages
Name        : postgresql11-contrib
Arch        : x86_64
Version     : 11.5
{code}


* we also made some changes in the *""preset-configs.yaml""*
and added the new metrics
{code:java}
- name: exhaustive
  description: almost all available metrics for a deeper performance understanding
  metrics:
.......
    buffercache_by_cluster: 60
{code}

* after restart of pg_watch2 we can see the following error:
{code:java}
Jan 22 16:00:36 m7testpdb1 pg_watch2[1806]: 2021/01/22 16:00:36 ERRO MetricsFetcher: failed to fetch metrics for 'm7t-shrd-syt1-pdb-async1_m7tshrdsyt1m7b', metric 'buffercache_by_cluster': pq: relation ""pg_buffercache"" does not exist
{code}



","25/Jan/21 09:39;cs687;seems like we had an permission issue!
{code:java}
postgres=# set role pgwatch2;
SET
postgres=>
postgres=> \i /tmp/pg_buffercache.sql
psql:/tmp/pg_buffercache.sql:13: ERROR:  permission denied for view pg_buffercache
{code}

* 1.) proper fix for that: 
{code:java}
postgres=# GRANT SELECT on pg_buffercache to pgwatch2;
GRANT
{code}

* afterwards it came up a new error no permission for function pg_buffercache_pages
{code:java}
postgres=> \i /tmp/pg_buffercache.sql
psql:/tmp/pg_buffercache.sql:13: ERROR:  permission denied for function pg_buffercache_pages
{code}

* 2.) proper fix for that: 
{code:java}
postgres=# GRANT EXECUTE ON FUNCTION pg_buffercache_pages TO pgwatch2;
GRANT
{code}


seems like its working after switching to role pgwatch2 and executing the SQL command. 
{code:java}
postgres=# set role pgwatch2;
SET
postgres=> \i /tmp/pg_buffercache.sql
      epoch_ns       | size_unused |  size_used  | size_total
---------------------+-------------+-------------+-------------
 1611563875745943040 |           0 | 33663483904 | 33663483904
(1 row)
{code}
","27/Jan/21 13:11;cs687;I had a meeting with Laurenz from CYBERTEC 

We came to the conclusion that we should not activate the monitoring for pg_watch because scanning all the shared buffers will be also have some performance impact and I guess we can 
not really risk that, specially when it goes to production. 

He recommended us the following:
* we should check and add the current configured shared buffers of all clusters in test/simu/prod
* compare this value with memory of the machine, which should be max 128G RAM
{code:java}
              total        used        free      shared  buff/cache   available
Mem:         128418        4247         465       22022      123705      101291
Swap:          7999         278        7721
{code}
* configure the shared_buffers depending on the customer-clusters that require more performance/load, or have a bigger database in general. Easily define them in the inventory postgres/vars.yml

A proper default value would be 4G shared buffers, that should be enough for most of our database, when we think about, that ELTS-PROD is running with this setup soon one year :) 
""effective_cache_size"" can be a higher value, it will be also not taken directly the memory of the machine. so I would leave it like we are calculating it atm
effective_cache_size: ""{{ (ansible_memtotal_mb*0.8) | int }}MB""

When we check the shared_buffers setting for our production hosts we can see following results:
{code:java}
/var/lib/pgsql_m7aamprprodsync/data/11/m7aamprprodsync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7axeerprodsync/data/11/m7axeerprodsync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7thupxprodasync/data/11/m7thupxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tplpxprodasync/data/11/m7tplpxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdprodasync/data/11/m7tshrdprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmprodasync/data/11/m7txrpmprodasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/postgresql.conf:shared_buffers = '32104MB'
{code}

we def. should reduce XRPM, XSOP, AMPR and XEER, 32G is like a way to high and I guess it was happening during a miss-configuration :facepalm:
So properly lets configure all the database-clusters with shared_buffers of 4G and ELTS-PROD we can increase to 8G then we would have in total 40G of 128G, 
which gives us the potential to have more prod-clusters in the future on these machines or we deploy with new machines! 
so the best average would be not using more than the half of the whole memory, so ~64G 

same happening here with the 32G, so properly change all of them to 3/4 and some elts/epex one to 4. In case we would use 4G as default we would have 108G
when it comes to SIMULATION its more chaotic it guess we have not 724G RAM :stuck_out_tongue: 
So for simu we should really change something otherwise onboarding new env´s will properly not work in the future. 
So we could reduce some of them like dst, shrd-exte to 2G/3G and the rest to 4G, depending on how much we are planning to onboard to this hosts in the future. 
{code:java}
/var/lib/pgsql_enshrdebsmasync/data/11/enshrdebsmasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7aamprcutesync/data/11/m7aamprcutesync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7aamprsimusync/data/11/m7aamprsimusync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7axeerasimsync/data/11/m7axeerasimsync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7axeercutesync/data/11/m7axeercutesync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7axeersimusync/data/11/m7axeersimusync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7cicsccuteasync/data/11/m7cicsccuteasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cshrddst1async/data/11/m7cshrddst1async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsacutasync/data/11/m7teltsacutasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7teltsasimasync/data/11/m7teltsasimasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsctpbasync/data/11/m7teltsctpbasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7teltscuteasync/data/11/m7teltscuteasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7teltslipaasync/data/11/m7teltslipaasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7teltssimuasync/data/11/m7teltssimuasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tepexasimasync/data/11/m7tepexasimasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7thupxasimasync/data/11/m7thupxasimasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7thupxcuteasync/data/11/m7thupxcuteasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7thupxsimuasync/data/11/m7thupxsimuasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tplpxlipaasync/data/11/m7tplpxlipaasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tplpxsimuasync/data/11/m7tplpxsimuasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrddst1async/data/11/m7tshrddst1async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdexteasync/data/11/m7tshrdexteasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmlipaasync/data/11/m7txrpmlipaasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txrpmsimuasync/data/11/m7txrpmsimuasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txsopasimasync/data/11/m7txsopasimasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txsopcuteasync/data/11/m7txsopcuteasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7txsopsimuasync/data/11/m7txsopsimuasync/postgresql.conf:shared_buffers = '32104MB'
{code}

I would start with that action in TEST, for that action we need to restart the patroni nodes. In case Patroni is taking this action fast we will have no failover. 
Where we can risk that, we should clean it up, for production we need to schedule it somehow. ","27/Jan/21 15:37;cs687;+*{color:red}Suggestion for the values:{color}*+
as default we keep shared_buffers: 4G 
later fix for m7a: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2515/files
m7t/c -> shared_buffers: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2517/files

PROD:
{code:java}
/var/lib/pgsql_m7aamprprodsync/data/11/m7aamprprodsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeerprodsync/data/11/m7axeerprodsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync/postgresql.conf:shared_buffers = '4GB' --> 8G
/var/lib/pgsql_m7thupxprodasync/data/11/m7thupxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tplpxprodasync/data/11/m7tplpxprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdprodasync/data/11/m7tshrdprodasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7txrpmprodasync/data/11/m7txrpmprodasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
{code}
*40G*

SIMU:
{code:java}
/var/lib/pgsql_enshrdebsmasync/data/11/enshrdebsmasync/postgresql.conf:shared_buffers = '4GB'  --> 2G
/var/lib/pgsql_m7aamprcutesync/data/11/m7aamprcutesync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7aamprsimusync/data/11/m7aamprsimusync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeerasimsync/data/11/m7axeerasimsync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeercutesync/data/11/m7axeercutesync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7axeersimusync/data/11/m7axeersimusync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7cicsccuteasync/data/11/m7cicsccuteasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cshrddst1async/data/11/m7cshrddst1async/postgresql.conf:shared_buffers = '4GB' --> 2G
/var/lib/pgsql_m7teltsacutasync/data/11/m7teltsacutasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltsasimasync/data/11/m7teltsasimasync/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7teltsctpbasync/data/11/m7teltsctpbasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltscuteasync/data/11/m7teltscuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltslipaasync/data/11/m7teltslipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7teltssimuasync/data/11/m7teltssimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tepexasimasync/data/11/m7tepexasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxasimasync/data/11/m7thupxasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxcuteasync/data/11/m7thupxcuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7thupxsimuasync/data/11/m7thupxsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tplpxlipaasync/data/11/m7tplpxlipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tplpxsimuasync/data/11/m7tplpxsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrddst1async/data/11/m7tshrddst1async/postgresql.conf:shared_buffers = '32104MB' --> 2G
/var/lib/pgsql_m7tshrdexteasync/data/11/m7tshrdexteasync/postgresql.conf:shared_buffers = '4GB' --> 2G
/var/lib/pgsql_m7txrpmlipaasync/data/11/m7txrpmlipaasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txrpmsimuasync/data/11/m7txrpmsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopasimasync/data/11/m7txsopasimasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopcuteasync/data/11/m7txsopcuteasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7txsopsimuasync/data/11/m7txsopsimuasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
{code}
*100G*


TEST:
{code:java}
/var/lib/pgsql_m7ashrdsyt1sync/data/11/m7ashrdsyt1sync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7ashrdsyt2sync/data/11/m7ashrdsyt2sync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7cshrdate1async/data/11/m7cshrdate1async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cshrdate5async/data/11/m7cshrdate5async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdate1async/data/11/m7tshrdate1async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdate2async/data/11/m7tshrdate2async/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdate3async/data/11/m7tshrdate3async/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdate4async/data/11/m7tshrdate4async/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdate5async/data/11/m7tshrdate5async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdinteasync/data/11/m7tshrdinteasync/postgresql.conf:shared_buffers = '32104MB' --> 2G
/var/lib/pgsql_m7tshrdshowasync/data/11/m7tshrdshowasync/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async/postgresql.conf:shared_buffers = '32104MB' --> 4G
/var/lib/pgsql_m7tshrdsyt4async/data/11/m7tshrdsyt4async/postgresql.conf:shared_buffers = '32104MB' --> 4G
{code}
*44G*



","27/Jan/21 15:59;cv179;Very good proposal!","29/Jan/21 07:31;cs687;done",,,,,,,,,,,,,,,,,,,,,,
Oversized shared_buffers/effective_cache_size on m7 test postgres instances,M7P-7519,104865,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,hw120,hw120,07/Jan/21 23:19,10/Feb/21 11:29,16/Sep/21 14:11,28/Jan/21 08:28,,6.8.151,7tops_sprint110,,,Database,,,,7tops_comm,M,M7PRODOPS,,,,,"Oversized allocation of shared_buffers caused the crash of core instances (sql error: ERROR: out of memory) on 11 XBID cute environments during Christmas Holliday. 
 Postgres instances were still running, but throwing out of memory error and therefore no failover happened and cor instances crashed.
 I identified and fixed the issue, but *I also identified it on most of the m7 database instances*. *Check PROD instances, specifically ELTS PROD.*

effective_cache_size is a bit tricky, it is used by query optimizer but also to adjust index creation strategy.
 For more details see [https://www.cybertec-postgresql.com/en/effective_cache_size-what-it-means-in-postgresql/]

Here is the situation on m7testpdb1:
{code:bash}
[root@m7testpdb1 ~]# grep ""shared_buffers ="" /var/lib/pgsql_*/data/*/*/postgresql.conf
/var/lib/pgsql_m7ashrdsyt1sync/data/11/m7ashrdsyt1sync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7ashrdsyt2sync/data/11/m7ashrdsyt2sync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7cshrdate1async/data/11/m7cshrdate1async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7cshrdate5async/data/11/m7cshrdate5async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdate1async/data/11/m7tshrdate1async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdate2async/data/11/m7tshrdate2async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdate3async/data/11/m7tshrdate3async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdate4async/data/11/m7tshrdate4async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdate5async/data/11/m7tshrdate5async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdinteasync/data/11/m7tshrdinteasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdshowasync/data/11/m7tshrdshowasync/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async/postgresql.conf:shared_buffers = '4GB'
/var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async/postgresql.conf:shared_buffers = '32104MB'
/var/lib/pgsql_m7tshrdsyt4async/data/11/m7tshrdsyt4async/postgresql.conf:shared_buffers = '32104MB'

[root@m7testpdb1 ~]# grep ""effective_cache_size ="" /var/lib/pgsql_*/data/*/*/postgresql.conf
/var/lib/pgsql_m7ashrdsyt1sync/data/11/m7ashrdsyt1sync/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7ashrdsyt2sync/data/11/m7ashrdsyt2sync/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7cshrdate1async/data/11/m7cshrdate1async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7cshrdate5async/data/11/m7cshrdate5async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdate1async/data/11/m7tshrdate1async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdate2async/data/11/m7tshrdate2async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdate3async/data/11/m7tshrdate3async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdate4async/data/11/m7tshrdate4async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdate5async/data/11/m7tshrdate5async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdinteasync/data/11/m7tshrdinteasync/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdshowasync/data/11/m7tshrdshowasync/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async/postgresql.conf:effective_cache_size = '102734MB'
/var/lib/pgsql_m7tshrdsyt4async/data/11/m7tshrdsyt4async/postgresql.conf:effective_cache_size = '102734MB'
{code}
What we have to do is to
 * Check actual usage of shared_buffers memory by all postgres instances on one server using the following commands
{code:bash}
ssh m7testpdb1/2
sudo su -
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done |grep Leader |awk '{ print $6}' |sed 's/\:/ /' |awk '{ print $2 }' > db_port_numbers
cp db_port_numbers /var/lib/pgsql
chown postgres:postgres /var/lib/pgsql/db_port_numbers 
su - postgres
# pg_buffercache extension is already enabled everywhere, so we can skip this step
#for i in `cat db_port_numbers`;do psql -p $i -c 'create extension pg_buffercache;';done
for i in `cat db_port_numbers`;do psql -p $i -c 'select count(bufferid), case when usagecount is null then false else true end as used from pg_buffercache group by rollup(used);';done > pg_buffercache.output
grep "" t"" pg_buffercache.output |awk '{ print $1 }'| awk '{ n += $1}; END{print n}' |awk '{ print ($1 * 8)/1024/1024"" GB"" }'
32.1601 GB

# And usage of each individual instance
grep "" t"" pg_buffercache.output |awk '{ print ($1 * 8)/1024"" MB"" }'
11.1875 MB
6.20312 MB
38.4062 MB
14.9688 MB
10.4688 MB
110.773 MB
140.32 MB
426.734 MB
17.75 MB
5.41406 MB
18.3594 MB
32104 MB
27.3516 MB
{code}

 * Fix proper default variables in the inventory, as those automatic calculations don't work for servers with multiple Postgres instances
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/search?q=shared_buffers&unscoped_q=shared_buffers]
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/search?q=effective_cache_size&unscoped_q=effective_cache_size]
 * Came up with reasonable default values so we don't cross maximum server memory, maybe we can consul it with cybertec
 * Redeploy patroni instances to get new config on the servers
 * Update running patroni/postgres config and restart nodes one by one to apply it
{code:bash}
patronictl -c /etc/patroni_<clustername>/config.yml edit-config
patronictl -c /etc/patroni_<clustername>/config.yml restart <clustername> <clustermember>
{code}

 * And check again if the configuration was correctly applied
{code:bash}
grep ""shared_buffers ="" /var/lib/pgsql_*/data/*/*/postgresql.conf
grep ""effective_cache_size ="" /var/lib/pgsql_*/data/*/*/postgresql.conf
{code}

 * We can investigate possible buffer usage metric collection as pgwatch2 provides two buffercache_by_* collectors and setup dashboard to watch it
 [https://github.com/cybertec-postgresql/pgwatch2/tree/master/pgwatch2/metrics]",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"changed all the memory settings from 32GB -> 4/2 GB shared-buffers and 
restarted the nodes.",,,,,,,,,,,,,,,,,,,,,,,,19958400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzyyrr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":104865,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/21 14:28;cs687;for m7t/c we have default values like this, what might be ok for me. 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/798226e935f78c39bd9714f052a23bc7524c2d88/inventory/m7t/postgres.yml#L18
{code:java}
# Configuring Postgresql
effective_cache_size: ""{{ (ansible_memtotal_mb*0.8) | int }}MB""
max_wal_size: ""2GB""
shared_buffers: ""4GB""
{code}

we just need to change it for auction!
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/f2519ff293c8ee6cf777569b22305248c23331ce/inventory/m7a/postgres.yml#L20

cluster status before the actiony:
{code:java}
[root@m7testpdb2 ~]# patronictl -c /etc/patroni_m7tshrdate1async/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tshrdate1async | m7testpdb1 | 10.139.117.253:26010 | Leader | running | 26 |         0 |
| m7tshrdate1async | m7testpdb2 | 10.139.117.254:26010 |        | running | 26 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

change the value with ""edit-config""
{code:java}
[root@m7testpdb2 ~]# patronictl -c /etc/patroni_m7tshrdate1async/config.yml edit-config
---
+++
@@ -19,7 +19,7 @@
     max_connections: 250
     max_wal_size: 2GB
     pg_stat_statements.track: all
-    shared_buffers: 32104MB
+    shared_buffers: 4GB
     shared_preload_libraries: pg_stat_statements,auto_explain
     work_mem: 32MB
   use_pg_rewind: true
{code}

With that changes we have to do a restart afterwards: 
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB | Pending restart |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
| m7tshrdate1async | m7testpdb1 | 10.139.117.253:26010 | Leader | running | 26 |         0 |        *        |
| m7tshrdate1async | m7testpdb2 | 10.139.117.254:26010 |        | running | 26 |         0 |        *        |
+------------------+------------+----------------------+--------+---------+----+-----------+-----------------+
{code}


{code:java}
patronictl -c /etc/patroni_m7tshrdate1async/config.yml restart m7tshrdate1async m7testpdb1
patronictl -c /etc/patroni_m7tshrdate1async/config.yml restart m7tshrdate1async m7testpdb2

Are you sure you want to restart members m7testpdb2? [y/N]: y
Restart if the PostgreSQL version is less than provided (e.g. 9.5.2)  []:
Success: restart on member m7testpdb2


+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tshrdate1async | m7testpdb1 | 10.139.117.253:26010 | Leader | running | 26 |         0 |
| m7tshrdate1async | m7testpdb2 | 10.139.117.254:26010 |        | running | 26 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}



","27/Jan/21 14:36;cs687;following cluster env´s are changed from 32G -> 4G shared_buffers:

* ate1 (/)
* ate5 (/) ","28/Jan/21 08:27;cs687;Changed the memory setting for all test clusters:
{code:java}
[root@m7testpdb1 lib]# grep ""shared_buffers ="" /var/lib/pgsql_*/data/*/*/postgresql.conf                
/var/lib/pgsql_m7ashrdsyt1sync/data/11/m7ashrdsyt1sync/postgresql.conf:shared_buffers = '4GB'           
/var/lib/pgsql_m7ashrdsyt2sync/data/11/m7ashrdsyt2sync/postgresql.conf:shared_buffers = '4GB'           
/var/lib/pgsql_m7cshrdate1async/data/11/m7cshrdate1async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7cshrdate5async/data/11/m7cshrdate5async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdate1async/data/11/m7tshrdate1async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdate2async/data/11/m7tshrdate2async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdate3async/data/11/m7tshrdate3async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdate4async/data/11/m7tshrdate4async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdate5async/data/11/m7tshrdate5async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdinteasync/data/11/m7tshrdinteasync/postgresql.conf:shared_buffers = '2GB'         
/var/lib/pgsql_m7tshrdshowasync/data/11/m7tshrdshowasync/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async/postgresql.conf:shared_buffers = '4GB'     
/var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async/postgresql.conf:shared_buffers = '4GB'         
/var/lib/pgsql_m7tshrdsyt3async/data/11/m7tshrdsyt3async/postgresql.conf:shared_buffers = '4GB'         
{code}

Just for few env´s a core-failover happened, the rest is running fine! ","28/Jan/21 08:28;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Add Reporter version to Energy Deployment Versions page,M7P-7517,104857,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,nn236,nn236,07/Jan/21 16:29,27/Jan/21 11:16,16/Sep/21 14:11,15/Jan/21 14:30,,6.11.167,7tops_sprint109,,,devops,Documentation,,,M7PRODOPS,,,,,,,"The page [https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/] shows an overview of versions deployed per environment. With M7T 6.11, a new component was introduced called 'Reporter'.

The page should be updated to include the new column 'Reporter' (e.g. after 'RE Dep' component). The value in each row should either show the actual version of the Reporter deployed for the respective environment, or be empty if the component wasn't deployed there.",,cs687,nn236,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"added the new instance to the version-table 
with the two pull-requests in the comment. ",,,,,,,,,,,,,,,,,,,,,,,,20995200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwv3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":104857,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/21 11:50;cs687;prepared the necessary pull-requests:
* https://github.deutsche-boerse.de/dev/energy.deployment.versions/pull/8/files
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1311/files

Let it check by dev´s and check it afterwards if everything is working. ","15/Jan/21 14:30;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Dedicated VM for cores on SYT1,M7P-7516,104854,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,pw231,pw231,07/Jan/21 15:35,27/Jan/21 11:22,16/Sep/21 14:11,,,,,,,,,,,7tops,OPS,TechOps,,,,,"h4. Desired setup
- m7shrdsyt1apa1/2 : 8 CPU, 12 GB (running enq, mtt, h2h, cardio etc.)
-* the disk space for logs might be reduced to 1/3 (cor is moving out)
- m7shrdsyt1cor1/2 : 8 CPU, 10 GB (running just core)
-* the required journal shall be mapped here
-* the disk for logs: 2/3 of current {{m7shrdsyt1apa1}} space
",,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21686400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4645,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz1rj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104854,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD database dump,M7P-7504,104696,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,nn481,nn481,04/Jan/21 15:41,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 07:24,,6.11.160,7tops_sprint108,,,Database,,,06/Jan/21 00:00,@7tops,M7PRODOPS,,,,,,"We need ELTS PROD db dump without history tables to test and tune following script: https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/240/files

We can import the dump locally so there is no need to import dump on some env.

This should be done before ELTS PROD DB deployment which is 12.1.2021 so setting due date to 6.1.2021 to have time for tests and tuning.",,cs687,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,created the dump with the mentioned command in the first comment and uploaded the dump to the ebsm host. ,,,,,,,,,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0xr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments. ,,,,,,,,,,"{""issueId"":104696,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jan/21 07:16;cs687;Starting the dump without history tables with the following command:
{code:java}
/usr/pgsql-11/bin/pg_dump -Fc --exclude-table='*history' --port 20002 -f /tmp/m7teltsprodm7b_without_history.dmp m7teltsprodm7b
{code}
storing the file temporarily in /tmp Filesystem and upload it to ebsm later on. 
","05/Jan/21 07:23;cs687;uploaded the file to ebsm host */home/transfer/dbdumps/elts_prod*
{code:java}
-rw-r--r-- 1 postgres postgres 1.3G Jan  5 07:18 m7teltsprodm7b_without_history.dmp
{code}","05/Jan/21 07:24;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Renewal of client certificate for the AS2-connections in January 2021,M7P-7503,104692,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,04/Jan/21 14:59,27/Jan/21 11:16,16/Sep/21 14:11,18/Jan/21 09:33,,6.11.167,7tops_sprint109,,,MTT,,,,7tops,S,,,,,,"Email from ECC (Gunar)

I would like to inform you that Global Sign  will withdraw a certificate from the certificate chain in February 2021  and thus our S/MIME certificate used will also become invalid. The new key certificate  is included. In January I will provide a date for the change for the two  agreements:

SMSS-PROD                        EPEX-M7-EMS-PROD 

SMSS-PROD                        EPEX-M7-LIM-PROD 

I wish you a Merry Christmas and a Happy New Year.

Best regards,

Gunar

 

todo
 * analyze the impact
 ** which environments are impacted
 ** which customers are impacted 
 * recommend steps to be taken",,cs687,op211,rehapav,,,,,,,,,,,,,,,,,SERVICE-9367,,,,,,,,,,,,,,SERVICE-9475,,,,,,"04/Jan/21 14:59;rehapav;pubKey-clearing@ecc.de.zip;https://jira.deutsche-boerse.com/secure/attachment/91444/pubKey-clearing%40ecc.de.zip",,,,,,,,,,,,,,,sw455,,,,,,,,"new certificates replaced in vault 
*ELTS PROD: https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/elts/prod/mtt2/client_cert*
*HUPX PROD: https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/hupx/prod/mtt2/client_cert*

after re-deployment of MTT it should be replaced and active running
",,,,,,,,,,,,,,,,,,,,,,,,20822400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyys7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":104692,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/21 14:39;sw455; 

??Mail thread to HUPX on this change:??

 
{quote}
Hi Tomi,

Thank you for e-mail. I wish you a happy and healthy New Year!

I propose to change the certificates for the three agreements on Monday, 18^th^ January 14:00 CET.

Can you please forward the key and the date to the colleagues from DBAG?

On my side the change is only a click will not take more than two minutes for all three connections. So from my point of view a market halt is not necessary, but I’m not sure about the system on DBAG-side.

Best regards,

Gunar

 

*Von:* Intraday Marketops <[idmarketops@hupx.hu|mailto:idmarketops@hupx.hu]> 
 *Gesendet:* Montag, 11. Januar 2021 12:15
 *An:* [idmarketops@hupx.hu|mailto:idmarketops@hupx.hu]; Gunar Schmidt <[gunar.schmidt@ecc.de|mailto:gunar.schmidt@ecc.de]>; Alexander Thorne <[alexander.thorne@deutsche-boerse.com|mailto:alexander.thorne@deutsche-boerse.com]>; Pekó Kriszta <[peko@hupx.hu|mailto:peko@hupx.hu]>
 *Betreff:* RE: Change of client certificate in AS2-Communication ECC- HIUPX in January 2021

 

Hi Gunar!

 

Could you please provide us a date for the change for the three agreements? Should we forward the pubKey-clearing zip you have attached to DBAG? Does this change require a market halt?

 

SMSS-PROD                        HUPX-M7-EMS-PROD 

SMSS-PROD                        HUPX-M7-LIM-PROD 

SMSS-TF-PROD                                 HUPX-M7-TF
{quote}","14/Jan/21 10:07;op211;*HUPX PROD*
{noformat}
tomcat@m7hupxprodm7b1:[/hupx/hupx-prod-mtt1]$ openssl x509 -in client.crt -text -noout
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            55:1a:cb:5a:80:58:ed:88:f6:38:e4:e2
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=BE, O=GlobalSign nv-sa, CN=GlobalSign PersonalSign 2 CA - SHA256 - G3
        Validity
            Not Before: Aug 28 10:35:34 2020 GMT
            Not After : Oct 14 11:16:04 2021 GMT
        Subject: C=DE, ST=Sachsen, L=Leipzig, O=European Commodity Clearing AG, CN=Clearing/emailAddress=clearing@ecc.de
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
{noformat}
*ELTS PROD*
{noformat}
tomcat@m7eltsprodm7b1:[/elts/elts-prod-mtt1]$ openssl x509 -in client.crt -text -noout
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            55:1a:cb:5a:80:58:ed:88:f6:38:e4:e2
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=BE, O=GlobalSign nv-sa, CN=GlobalSign PersonalSign 2 CA - SHA256 - G3
        Validity
            Not Before: Aug 28 10:35:34 2020 GMT
            Not After : Oct 14 11:16:04 2021 GMT
        Subject: C=DE, ST=Sachsen, L=Leipzig, O=European Commodity Clearing AG, CN=Clearing/emailAddress=clearing@ecc.de
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
{noformat}
{color:#de350b}*Conclusion: Same certificate!*{color}","14/Jan/21 10:56;op211;Steps for replacement:
 # Take the text from the zipped cert (-----BEGIN CERTIFICATE----- ... -----END CERTIFICATE-----) and replace the following values in Vault:
ELTS PROD: [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/elts/prod/mtt2/client_cert]
HUPX PROD: [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/hupx/prod/mtt2/client_cert]
 # Re-deploy MTT component.","14/Jan/21 15:29;rehapav;Hi Pavel,

hereby I confirm the dated for replacement of our certificates:

Monday 18/1 -10-12:

SMSS-PROD                        HUPX-M7-EMS-PROD 

SMSS-PROD                        HUPX-M7-LIM-PROD 

SMSS-TF-PROD                                 HUPX-M7-TF

 

Tuesday 19/1 - 20-23:

SMSS-PROD                        EPEX-M7-EMS-PROD 

SMSS-PROD                        EPEX-M7-LIM-PROD 

 

Best regards,

Gunar","18/Jan/21 09:33;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
Increase /shrd partition on m7shrdinterep1&2,M7P-7463,104482,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,op211,oy574,oy574,17/Dec/20 13:41,27/Jan/21 09:08,16/Sep/21 14:11,17/Dec/20 14:14,,6.11.156,7tops_sprint108,,,RE,,,,7tops,,,,,,,"Currently, the /shrd partition has 4.9GB. Since the admin reports from SYT1 are several GB big, it is not enough (this is shared for ALL test environments). The reports are stored in /shrd/data. Please, increase the size of the partition to at least to 10GB, but ideally 20GB, as reporter with the new reports is deployed there as well.

Apply this to both m7shrdinterep1 and m7shrdinterep2.",,op211,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Increased /shrd partition on m7shrdinterep1&2,,,,,,,,,,,,,,,,,,,,,,,,23500800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwvb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104482,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/20 14:07;op211; 
{noformat}
[root@m7shrdinterep1 ~]# df -h
Filesystem                        Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root        7.6G  2.0G  5.3G  27% /
devtmpfs                          3.8G     0  3.8G   0% /dev
tmpfs                             3.9G     0  3.9G   0% /dev/shm
tmpfs                             3.9G  362M  3.5G  10% /run
tmpfs                             3.9G     0  3.9G   0% /sys/fs/cgroup
/dev/sda1                         477M  155M  298M  35% /boot
/dev/mapper/rootvg-lv_tmp         1.9G  6.9M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_opt_energy  3.9G  1.7G  2.0G  47% /opt/energy
/dev/mapper/rootvg-lv_shrd         15G  3.2G   11G  23% /shrd
/dev/mapper/rootvg-lv_shrd_logs   5.9G  3.6G  2.1G  63% /shrd/logs
/dev/mapper/rootvg-lv_var         1.9G  1.2G  626M  66% /var
/dev/mapper/rootvg-lv_varlog      1.9G  398M  1.4G  22% /var/log
tmpfs                             781M     0  781M   0% /run/user/1984
tmpfs                             781M     0  781M   0% /run/user/519031
tmpfs                             781M     0  781M   0% /run/user/1985
tmpfs                             781M     0  781M   0% /run/user/996
tmpfs                             781M     0  781M   0% /run/user/509666
tmpfs                             781M     0  781M   0% /run/user/518783
tmpfs                             781M     0  781M   0% /run/user/513239
{noformat}
 
{noformat}
[root@m7shrdinterep2 ~]# df -h
Filesystem                        Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root        7.6G  1.9G  5.4G  26% /
devtmpfs                          9.8G     0  9.8G   0% /dev
tmpfs                             9.8G     0  9.8G   0% /dev/shm
tmpfs                             9.8G  907M  8.9G  10% /run
tmpfs                             9.8G     0  9.8G   0% /sys/fs/cgroup
/dev/sda1                         477M  155M  298M  35% /boot
/dev/mapper/rootvg-lv_tmp         1.9G  6.8M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_shrd        4.9G  2.1G  2.7G  44% /shrd
/dev/mapper/rootvg-lv_opt_energy  3.9G  1.2G  2.5G  31% /opt/energy
/dev/mapper/rootvg-lv_shrd_logs   5.9G  3.1G  2.6G  54% /shrd/logs
/dev/mapper/rootvg-lv_var         1.9G  1.2G  641M  65% /var
/dev/mapper/rootvg-lv_varlog      1.9G  216M  1.6G  12% /var/log
tmpfs                             2.0G     0  2.0G   0% /run/user/1984
tmpfs                             2.0G     0  2.0G   0% /run/user/996
tmpfs                             2.0G     0  2.0G   0% /run/user/1985
tmpfs                             2.0G     0  2.0G   0% /run/user/518783
tmpfs                             2.0G     0  2.0G   0% /run/user/513239{noformat}
 ","17/Dec/20 14:09;op211;FS sizes are not in sync. Available space:
{noformat}
[root@m7shrdinterep1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   8   0 wz--n- <44.51g <1.93g{noformat}
{noformat}
[root@m7shrdinterep2 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   8   0 wz--n- <44.51g <11.93g{noformat}","17/Dec/20 14:12;op211;Added 10GB to /shrd on *m7shrdinterep2*
{noformat}
[root@m7shrdinterep2 ~]# lvextend -r -L 15g /dev/mapper/rootvg-lv_shrd
  Size of logical volume rootvg/lv_shrd changed from 5.00 GiB (1280 extents) to 15.00 GiB (3840 extents).
  Logical volume rootvg/lv_shrd successfully resized.
resize2fs 1.42.9 (28-Dec-2013)
Filesystem at /dev/mapper/rootvg-lv_shrd is mounted on /shrd; on-line resizing required
old_desc_blocks = 1, new_desc_blocks = 2
The filesystem on /dev/mapper/rootvg-lv_shrd is now 3932160 blocks long.
[root@m7shrdinterep2 ~]# df -h | grep /shrd
/dev/mapper/rootvg-lv_shrd         15G  2.1G   13G  15% /shrd
/dev/mapper/rootvg-lv_shrd_logs   5.9G  3.1G  2.6G  55% /shrd/logs
[root@m7shrdinterep2 ~]#{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,
CheckMK hosts grouping and labeling. ,M7P-7436,104360,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,zq813,zq813,15/Dec/20 11:24,27/Jan/21 11:16,16/Sep/21 14:11,14/Jan/21 12:01,,6.11.167,7tops_sprint109,,,Monitoring,,,,M,M7PRODOPS,,,,,,"Hello. 

As you know we have new instances of checkmk - [https://globmon.srv.energy/]

For migrating existing hosts from englobmon2 to new nodes I would like to ask you to provide a list of virtual machines with proper host groups and labels.

Based on host groups and labels we can setup notifications and views. 

Virtual machines will be boarded via this playbook: [https://github.deutsche-boerse.de/dev/energy.infra.hw/blob/master/ansible/roles/checkmk_vm/tasks/main.yml]

 

Example of command: 
{code:java}
ansible-playbook playbooks/add_checkmk_vm.yml -e ""site_name=simumon1 product=m7 envi=test criticality=test"" -i inventory -k -K -v
{code}
Where:
 * criticality (critical, prod, simu, test)
 * envi - environment (TEST, SIMU PROD) 
 * product - hosts grouped in one product name
 * site_name - where hosts will be monitored. Prod hosts must be monitored from prod node. Same for rest environments. 

Due to limitations of checkmk webapi it's better to add new hosts instead of modifying existing ones.

Host lists even can be in excel sheet, just mention proper tags for them. Except listed tags you can define any new tags for segregation, I will create new tags in checkmk and assign them to listed hosts.

 ",,cs687,yo218,zq813,,,,,,,,,,,,,,,SYSENGINT-57,,,,,,,,,,,,,,,,,,,,,,"14/Jan/21 12:00;cs687;m7c_hosts_groups.csv;https://jira.deutsche-boerse.com/secure/attachment/91700/m7c_hosts_groups.csv","14/Jan/21 12:00;cs687;m7t_host_groups_with_shared.csv;https://jira.deutsche-boerse.com/secure/attachment/91699/m7t_host_groups_with_shared.csv",,,,,,,,,,,,,,sw455,,,,,,,,uploaded the two files which includes the VM´s of M7t and M7c and also shared hosts which are used for m7t/c/a ,,,,,,,,,,,,,,,,,,,,,,,,21168000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyrz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":104360,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jan/21 11:59;cs687;Like already discussed with you by phone and via slack. here the list of vms of product M7T/C and also including the shared hosts, which are used from m7a,t,c as well
 [^m7t_host_groups_with_shared.csv]  [^m7c_hosts_groups.csv] ","14/Jan/21 12:01;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Kibana query on recent index is timing out,M7P-7433,104340,,Bug,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,oy574,oy574,15/Dec/20 09:25,15/Dec/20 11:42,16/Sep/21 14:11,,,,,,,uknown,,,,7tops,,,,,,,"[https://kibana.energy.svc.dbgcloud.io/goto/c1814cef9356a8df261dabcf1c4365a9]

The following Kibana query for index on 10.12. is working alright (executed on 14.12.)
{noformat}
+client: elts +client_environment: prod +logline: (XBID_Quarter_Hour_Power AND ContractInfoRprt AND v1 AND ""Q13:45-14:00_XB""){noformat}
However, changing *v1* to *v6* in the query string causes timeout:
{noformat}
+client: elts +client_environment: prod +logline: (XBID_Quarter_Hour_Power AND ContractInfoRprt AND v6 AND ""Q13:45-14:00_XB""){noformat}
It might be caused by some caching, as I have executed the first query a day earlier. However. Since it's only 4 days old logs for the same month, it should still be *hot index*.",,hw120,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23760000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,15/Dec/20 09:25,,[],,,,,,,,None,,,M7T,,,,"2|hzyyzb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104340,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Dec/20 10:10;hw120;Recommendation from elastic support, how to investigate slow queries:
{quote}Hi Peter,
 
 My name is André Letterer and I am taking this case over.
 Do you know about the profile API?
 [https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html]
 We have a visual profiler in Kibana as well that makes use of the profile API:
 [https://www.elastic.co/guide/en/kibana/current/xpack-profiler.html]
 If you do that you can see better if this is really not expensive.
 
 From my experience adding stuff like asterisks * should be omitted as it is one of the more expensive actions.
 If without the regex the wrong results some back, you can think alternatively about more effective analyzers or tokenizers, that help your customers to get the correct results back without using regexes.
 Here you can read a bit about the topic and its expensive notes.
 [https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl-regexp-query.html]
 
 Best regards
 
 André Letterer
 Support Engineer @ Elastic
 
 Access Your Case: [https://support.elastic.co/customers/s/case/5004M00000YobgE]
{quote}","15/Dec/20 10:11;hw120;Also we can check recommendation in this article

[https://www.elastic.co/blog/advanced-tuning-finding-and-fixing-slow-elasticsearch-queries]

 ","15/Dec/20 11:23;hw120;I tried to test it in Kibana visual profiler, In Kibana Discover (first link in the ticket) I clicked on the Inspect button and then the Request tab to get a source of the query in JSON format which I copied.
{code:java}
{
  ""version"": true,
  ""size"": 500,
  ""sort"": [
    {
      ""@timestamp"": {
        ""order"": ""desc"",
        ""unmapped_type"": ""boolean""
      }
    }
  ],
  ""_source"": {
    ""excludes"": []
  },
  ""aggs"": {
    ""2"": {
      ""date_histogram"": {
        ""field"": ""@timestamp"",
        ""interval"": ""10m"",
        ""time_zone"": ""Europe/Berlin"",
        ""min_doc_count"": 1
      }
    }
  },
  ""stored_fields"": [
    ""*""
  ],
  ""script_fields"": {},
  ""docvalue_fields"": [
    {
      ""field"": ""@timestamp"",
      ""format"": ""date_time""
    },
    {
      ""field"": ""time"",
      ""format"": ""date_time""
    }
  ],
  ""query"": {
    ""bool"": {
      ""must"": [
        {
          ""query_string"": {
            ""query"": ""+client: elts +client_environment: prod +logline: (XBID_Quarter_Hour_Power AND ContractInfoRprt AND v6 AND \""Q13:45-14:00_XB\"")"",
            ""analyze_wildcard"": true,
            ""default_field"": ""logline""
          }
        },
        {
          ""range"": {
            ""@timestamp"": {
              ""gte"": 1607580000000,
              ""lte"": 1607612399999,
              ""format"": ""epoch_millis""
            }
          }
        }
      ],
      ""filter"": [],
      ""should"": [],
      ""must_not"": []
    }
  },
  ""highlight"": {
    ""pre_tags"": [
      ""@kibana-highlighted-field@""
    ],
    ""post_tags"": [
      ""@/kibana-highlighted-field@""
    ],
    ""fields"": {
      ""*"": {}
    },
    ""fragment_size"": 2147483647
  }
}
{code}
Then I went to Dev Tools menu, clicked on Search profiler and inserted query there.

I filled in index name m7-tomcat-2020.12.10.

I got this error
{code:java}
Error: err is undefined
      formatStack@https://kibana.energy.svc.dbgcloud.io/bundles/commons.bundle.js:3:977271
Notifier.prototype.error@https://kibana.energy.svc.dbgcloud.io/bundles/commons.bundle.js:3:518766
wrapper@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:32:35413
profileVizController/$scope.executeRemoteQuery/<@https://kibana.energy.svc.dbgcloud.io/bundles/kibana.bundle.js:2:2771699
processQueue@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:199687
scheduleProcessQueue/<@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:200662
$digest@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:210414
$apply@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:213219
done@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:132717
completeRequest@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:136337
requestLoaded@https://kibana.energy.svc.dbgcloud.io/built_assets/dlls/vendors.bundle.dll.js:441:135240
{code}","15/Dec/20 11:25;hw120;With v1 in search condition it works fine, but v6 throws error. We must open ticket with elasticsearch support as there is nothing more we can do.","15/Dec/20 11:42;hw120;[~iu252] will take it from here to create ticket on elastic support for further investigation.",,,,,,,,,,,,,,,,,,,,,,,
upcoming certificates expiry,M7P-7429,104293,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,lw641,lw641,14/Dec/20 09:07,13/Jan/21 11:31,16/Sep/21 14:11,16/Dec/20 16:05,,6.11.156,6.11.158,7tops_sprint108,,apache,,,,7tops,,,,,,,"Please renew certificates on the following hosts:
 * This cert will expire soon: CN=dst1.shrd.m7.deutsche-boerse.com (2020-12-14 00:00:00)
 * This cert will expire soon: CN=dst.xbid.m7.deutsche-boerse.com (2020-02-11 23:59:59GMT)
 * This cert will expire soon: CN=exte2.profiles.m7.deutsche-boerse.com (2020-02-11 23:59:59GMT)",,lw641,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9284,SERVICE-9285,SERVICE-9289,SERVICE-9288,SERVICE-9290,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"DST certificate is still valid - fixed the port in the configuration.

profile server apache certificates can now be managed and replaced using an ansible playbook. Documentation and examples can be found here:

[https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=29934082]

New certificates have been requested for exte and prod.

Exte certificate got installed and apaches restarted one by one.",,,,,,,,,,,,,,,,,,,,,,,,23846400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzyykf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104293,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SERVICE CLONE: certificates expiry, add to monitoring",M7P-7428,104309,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,wn626,wn626,14/Dec/20 10:51,13/Jan/21 11:31,16/Sep/21 14:11,23/Dec/20 14:16,,6.11.158,7tops_sprint108,,,Monitoring,,,,7tops,,,,,,,"We need to add ENVs to a semi automated documentation page [https://github.deutsche-boerse.de/pages/dev/energy.automation.certificate/#sort=expiry&order=asc]

 

ENVs:

[dst.xbid.m7.deutsche-boerse.com|http://dst.xbid.m7.deutsche-boerse.com/]

[exte2.profiles.m7.deutsche-boerse.com|http://exte2.profiles.m7.deutsche-boerse.com/]

syt1.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

syt2.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

syt3.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

advsimu1.epex.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9252

advsimu2.epex.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9252",,cv179,wn626,,,,,,,,,,,,,,,,,,M7P-7429,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"NOT ADDED:

[dst.xbid.m7.deutsche-boerse.com|http://dst.xbid.m7.deutsche-boerse.com/]

syt1.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

syt2.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

syt3.xbid.m7.deutsche-boerse.com - see https://jira.deutsche-boerse.com/browse/SERVICE-9107

 

Because those domains are not registered in DNS systems. So the respective certificates are not used in any valid way and can't be monitored at all. In order to onboard those, a proper DNS / alias needs to be onboarded and configured.

 

simulation profile servers and epex asim added.",,,,,,,,,,,,,,,,,,,,,,,,23587200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyqv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104309,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Dec/20 16:08;cv179;Please let's not call it ""monitoring"" as it does not fulfil the requirements... it's more a semi automated documentation page to help us, plan certificate replacements in advance before the replacement is actually due.","16/Dec/20 16:14;wn626;Description is updated",,,,,,,,,,,,,,,,,,,,,,,,,,
Troubleshoot comtrader connection issues,M7P-7425,104252,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,cv179,cv179,cv179,11/Dec/20 11:27,13/Jan/21 11:31,16/Sep/21 14:11,23/Dec/20 14:17,,7tops_sprint108,,,,Monitoring,,,,7tops,,,,,,,"[Jiri Simak|https://app.slack.com/team/U7DPQU4TE]  [09:16|https://dbg-devops.slack.com/archives/DEG7JG89K/p1607674588000100]
Hi Roman, I have a question on capturing traffic between Members and ELTS PROD. Do we have such possibility to do so?I am trying to find out why some Comtrader Members have so many disconnects per day: [Kibana|https://kibana.energy.svc.dbgcloud.io/goto/b7adae3e7e3bb7414bb34313eb8c6a78]
Maybe a TCP stream analysis could shed some light on it...",,cv179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Missing additional information... closing this one. Please reopen with more info if required.,,,,,,,,,,,,,,,,,,,,,,,,24105600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyc7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104252,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/20 11:37;cv179;To be clarified what type of capture we need, on what hosts we take it.

Then also what is the expected result and what will be the follow-up. A couple of times we already started the analysis and although we spend almost a week on capture and analysis, at the end, networks department was unable to find issues on our side.

Besides the logs in kibana - are there any reports? Could it be, that some members configured their client to look like comtrader but isn't? What happens, if members have a instable connection? We should ask affected members for a detailed connection report (traceroute etc.)","11/Dec/20 11:58;cv179;In addition, we should check what gets logged on a standard disconnect. I find 1200 disconnects a day with 600 members actually not too much if we get the same message on ""graceful"" disconnects. Also maybe people just close their comtrader or their computers are going to sleep / standby etc. - all of those cases we should check. ",,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance telegraf for CORE to include ping to all db servers,M7P-7415,104180,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,pw231,pw231,09/Dec/20 13:37,10/Feb/21 11:29,16/Sep/21 14:11,08/Feb/21 13:32,,6.11.192,7tops_sprint110,,,cor,,,,7tops,M,MONITORING,OPS,,,,"h4. Problem
On syt1, the performance drop down significantly with slight increase of network latencies between {{m7shrdsyt1apa1}} and {{m7testpdb1}}.
See M7P-7332 .

h4. Solution
Let's monitor the latencies so we can alert next time.

h4. Task
- Enahnce telegraf template so that for core, it will add all dbs url into the ping plugin. Currently we only ping kapacitor:
{code}
[[inputs.ping]]
  ## List of urls to ping
  urls = [""{{ telegraf_kapacitor_fqdn }}""]
  count = 3
  ping_interval = 3.0
  timeout = 3.0
  deadline = 10
{code}
- add WARN alert for values above 5ms",,iu252,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,New alert: ping response time from cor to pdb's.,,,,,,,,,,,,,,,,,,,,,,,,18921600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-176,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyr3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 108,7tops Sprint 109,7tops Sprint 110,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":104180,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-7415,master,true,"30/Dec/20 15:27;iu252;Testenvironment - ATE2

Changed telegraf config on m7shrdate2apa1:

{noformat}
........
[[inputs.ping]]
  ## List of urls to ping
  urls = [""kapacitor.energy.svc.dbgcloud.io""]
  count = 3
  ping_interval = 3.0
  timeout = 3.0
  deadline = 10
  [inputs.ping.tags]
    name = ""kapacitor""

[[inputs.ping]]
  ## List of urls to ping
  urls = [""m7testpdb1.deutsche-boerse.de""]
  count = 3
  ping_interval = 3.0
  timeout = 3.0
  deadline = 10
  [inputs.ping.tags]
    name = ""m7testpdb1""

[[inputs.ping]]
  ## List of urls to ping
  urls = [""m7testpdb2.deutsche-boerse.de""]
  count = 3
  ping_interval = 3.0
  timeout = 3.0
  deadline = 10
  [inputs.ping.tags]
    name = ""m7testpdb2""
........
{noformat}

And restarted telegraf.","30/Dec/20 15:49;iu252;Ping metrics for m7testpdb1/2 are there:
https://chronograf.energy.svc.dbgcloud.io/sources/3/chronograf/data-explorer?query=SELECT%20mean%28%22average_response_ms%22%29%20AS%20%22mean_average_response_ms%22%20FROM%20%22metrics_m7%22.%22autogen%22.%22ping%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A%20AND%20%22client%22%3D%27shrd%27%20AND%20%22client_environment%22%3D%27ate2%27%20AND%20%22host%22%3D%27m7shrdate2apa1%27%20AND%20%22url%22%3D%27m7testpdb1.deutsche-boerse.de%27%20GROUP%20BY%20time%28%3Ainterval%3A%29%20FILL%28null%29","05/Jan/21 08:50;pw231;Good stuff [~iu252]. I added a graph to System dashboard : https://grafana.energy.svc.dbgcloud.io/d/PhgXqCNik/system?orgId=2&from=now-1h&to=now&var-product=m7t&var-host=m7shrdate2apa1%20-%20tomcat%20-%20m7_shrd_ate2&var-client=shrd&var-client_env=ate2&var-group=All&var-interval=30s&fullscreen&panelId=310

When can we look forward to data from other VMs, mainly prod?","05/Jan/21 08:55;iu252;[~pw231] I did the config change manually on ATE2 to test metrics.
Yesterday I implemented following PR, which I need to test first https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1294.
Then (I hope today) we can deploy telegraf in prod.","05/Jan/21 09:02;iu252;[~pw231] next step would be to implement an alert. I guess warning is enough.  We plan to monitor average_response_ms. When should we trigger an alert?","05/Jan/21 16:17;iu252;[~pw231] do you want to have db ping plugin on all cor machines (prod and non-prod)?
Btw just redeployed telegraf for XRPM PROD. ","12/Jan/21 12:10;iu252;Finale version of telegraf ping plugin: 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1305

Alert: https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1227

Waiting for Peters review.

","12/Jan/21 14:52;iu252;[~pw231] the final version of telegraf is implemented and already deployed on SYT1.
Please use the tag name to create dashboards. 
Here are the  name tags for SYT1: 
* m7shrdsyt1apa1_m7testpdb1.deutsche-boerse.de (ping from cor1 to pdb1)
* m7shrdsyt1apa1_m7testpdb2.deutsche-boerse.de (ping from cor1 to pdb2)
* m7shrdsyt1apa2_m7testpdb1.deutsche-boerse.de (ping from cor2 to pdb1)
* m7shrdsyt2apa1_m7testpdb2.deutsche-boerse.de (ping from cor2 to pdb2)
","12/Jan/21 14:56;iu252;The alert is also ready, but not yet deployed.
We plan to do it end of this week.","18/Jan/21 12:29;iu252;[~pw231], FYI: to avoid false-positive alerts, we calculate average from 10 values https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1227/files#diff-435abc359c8a3562397ca8ebcdc1c5dcR14 of 30s samples.
But this also means we will not be able to detect short peaks in latency.","18/Jan/21 12:30;iu252;Both PRs merged.
New telegraf configuration is deployed on all internal test environments (ATE, SYT).
","18/Jan/21 15:31;iu252;Redeployed Kapacitor Alerts: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Kapacitor%20Alerts%20and%20Handlers/52/console","08/Feb/21 09:41;iu252;Merged 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1356
https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1232

Redeployed alerts again.

","08/Feb/21 13:29;iu252;Redeployed telegraf on all cor1/cor2.
The metrics are available.
An example of metrics: https://chronograf.energy.svc.dbgcloud.io/sources/3/chronograf/data-explorer?query=SELECT%20mean%28%22average_response_ms%22%29%20AS%20%22mean_average_response_ms%22%2C%20mean%28%22maximum_response_ms%22%29%20AS%20%22mean_maximum_response_ms%22%20FROM%20%22metrics_m7%22.%22autogen%22.%22ping%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A%20AND%20%22name%22%3D%27m7eltsprodm7c1_m7prodpdb1.deutsche-boerse.de%27%20GROUP%20BY%20time%28%3Ainterval%3A%29%20FILL%28null%29


metrics schema:

cor-host_pdb-host (m7eltsprodm7c1_m7prodpdb1.deutsche-boerse.de, m7eltsprodm7c1_m7prodpdb2.deutsche-boerse.de, m7eltsprodm7c1_m7prodpdb3.deutsche-boerse.de, m7eltsprodm7c1_m7prodpdb4.deutsche-boerse.de)",,,,,,,,,,,,,,
"ELTS PROD, every day 00:20-03:00 - huge peaks in persister and journal times",M7P-7389,103916,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,pw231,pw231,07/Dec/20 09:39,27/Aug/21 12:38,16/Sep/21 14:11,,,,,,,,,,,7tops,Operations_Support,,,,,,"h3. Problem

ELTS PROD: every day, between 00:20 and 3:30, we have huge peaks in persister and journal times (e.g. see {{Journaller - 99p}} in 
 [https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=now-7d&to=now&var-host=m7eltsprodm7c1%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-group=All&var-interval=10m&var-exchangeId=EPEX&fullscreen&panelId=41] )

We are close to processing time SLAs and we cannot effort such daily interruptions of the service.
h3. Possible Source Of The Problem
 - reporting engine being connected to the leader puts too much stress on the db server and network, or
 - some backup or maintenance job that would either
 ** put stress on db servers (disks/cpus/network card) or
 ** move lots of data on the same network components as core on \{{m7eltsprodm7c1 }} is using to connect to the db leader?
- async db tasks : covered by M7P-7377

h3. Tasks
- verify and improve
- first step might be to connect rep with {{db_server_type: ""preferSlave""}} and see the impact",,nn236,pn508,pw231,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1728000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7089,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzn3ri:zztr",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,6.13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":103916,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Dec/20 09:48;rehapav;While analyzing please take into the consideration that in BSP PROD shortly after 6.9 go live we merged this : SERVICE-6114

And decision was taken not to implement it into ELTS PROD","27/Aug/21 12:38;pn508;Reporting Engine reads from Replica, the issue seems not to occur any longer. To be verified by [~pw231] and potentially closed",,,,,,,,,,,,,,,,,,,,,,,,,,
XSOP Prod Server Certificates will expire ,M7P-7388,103910,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Duplicate,,cs687,cs687,07/Dec/20 08:16,16/Dec/20 11:16,16/Sep/21 14:11,07/Dec/20 08:22,,7tops_sprint107,,,,uknown,,,31/Dec/20 00:00,Certificates,M7PRODOPS,,,,,,"We got in ssl-admin channel informed that both server certificates for xsop prod will expire!

{code:java}
Your SSL certificate for http://prod2.xsop.m7.deutsche-boerse.com will expire soon. Date and time of expiration: 15/01/2021 23:59 GMT.

Certificate Details:
Common Name : http://prod2.xsop.m7.deutsche-boerse.com
Subject Alternative Names : http://prod2.xsop.m7.deutsche-boerse.com, http://www.prod2.xsop.m7.deutsche-boerse.com

Your SSL certificate for http://prod1.xsop.m7.deutsche-boerse.com will expire soon. Date and time of expiration: 15/01/2021 23:59 GMT.

Certificate Details:
Common Name : http://prod1.xsop.m7.deutsche-boerse.com
Subject Alternative Names : http://prod1.xsop.m7.deutsche-boerse.com, http://www.prod1.xsop.m7.deutsche-boerse.com
{code}

https://dbg-devops.slack.com/archives/CC51TP7HP/p1607307428039100
Please renew!

",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,Southpool,,,,,,,,,,,,,,,,24451200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzywq7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":103910,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"07/Dec/20 08:22;cs687;already on-going handled by [~iu252]",,,,,,,,,,,,,,,,,,,,,,,,,,,
Consul Deployment for M7 Test Replica Hosts (for SYT1),M7P-7384,103874,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,04/Dec/20 08:12,27/Jan/21 11:16,16/Sep/21 14:11,21/Jan/21 15:08,,6.11.178,7tops_sprint109,,,Database,,,04/Dec/20 00:00,M7PRODOPS,,,,,,,"We need to deploy Consul agents on the new hosts m7testdbr1 and m7testdbr2 and afterwards the patroni playbook with tag replica. 

To not impact the current test patroni clusters we have to set the patroni-cluster which are still active running in an maintaining mode, handled by this command:
https://patroni.readthedocs.io/en/latest/pause.html

{code:java}
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
{code}

then the consul redeployment can be run

{code:java}
(venv3) [hw120@enprodauto1 {master L | ?6} ~/git/energy.automation.deployments]$ 
export CONSUL_DC=energy-shrd-test && export CONSUL_BINARY=/usr/local/bin/consul
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass
{code}

after the deployment check with consul members if the new dbr-hosts are included
{code:java}
[root@m7testdbr1~]# export CONSUL_HTTP_TOKEN=XXXXXXXXXXX (see vault)
[root@m7testdbr1 ~]# consul members
{code}

and redeploy patroni replica 
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*shrd*syt1*dbr*"" -k -K -b  --tags replica
{code}

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2416/
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2417",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-189,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"* m7testpdb1/2 are running in the proper VLAN 
* and new consul enterprise-version is installed
* added for systemtest1 dbr-nodes ",,,,,,,,,,,,,,,,,,,,,,,,20476800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzywjj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":103874,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/20 08:36;cs687;Currently the virtual machines are not created, will be handled with SYSENG ticket
Waiting until they are up and running. ","07/Dec/20 09:36;cs687;added the missing static routes on m7testpdb1 & m7testpdb2: 
{code:java}
ip route add 10.139.133.221/32 via 10.139.117.3
ip route add 10.139.133.222/32 via 10.139.117.3
{code}
and changed it there as well */etc/sysconfig/network-scripts/route-bond2-admin*
{code:java}
# static routes for the interface bond2-admin dbr-hosts
10.139.133.221/32   via    10.139.117.3    dev     bond2-admin
10.139.133.222/32   via    10.139.117.3    dev     bond2-admin
{code}

added the missing routes on m7testdbr1 & m7testdbr2 as well 
{code:java}
[root@m7testdbr1 ~]# ip route add 10.139.130.241/32 via 10.139.133.1
[root@m7testdbr1 ~]# ip route add 10.139.130.242/32 via 10.139.133.1
[root@m7testdbr1 ~]# ip route add 10.139.130.243/32 via 10.139.133.1
[root@m7testdbr1 ~]# ip route add 10.139.130.244/32 via 10.139.133.1
[root@m7testdbr1 ~]# ip route add 10.139.130.245/32 via 10.139.133.1
{code}
and also changed the file *""/etc/sysconfig/network-scripts/route-ens192""*
","07/Dec/20 11:01;cs687;*asked cci to check the connection dbr-host -> consul hosts if everything is configured* waiting.
feedback from cci: 
{code:java}
[‎12/‎7/‎2020 12:32 PM]  Tobias Henkes:  
There was a part of the rule missing on the firewall. I corrected it. Very suspicious ...
{code}

all firewall-rules are working now #505388
","07/Dec/20 14:40;cs687;Deployed with patroni the dbr-hosts 
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml --limit '!*pdb*' -e ansible_python_interpreter=/usr/bin/python --ask-become-pass -k -K -b
{code}

{code:java}
[root@m7testpdb1 ~]# consul members
Node                       Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-test-cons1     10.139.130.241:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons2     10.139.130.242:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons3     10.139.130.243:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons4     10.139.130.244:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons5     10.139.130.245:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
m7t-shrd-test-consul-dbr1  10.139.133.221:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-dbr2  10.139.133.222:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-pdb1  10.139.117.253:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-pdb2  10.139.117.254:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
{code}

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2422

deploy patroni
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*shrd*syt1*dbr*"" -k -K -b  --tags replica
{code}
dbr-hosts are part of the cluster now:
{code:java}
[root@m7testdbr1 log]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml list
+ Cluster: m7tshrdsyt1async (6769123927737070962) --------------+----+-----------+------------------+
|   Member   |         Host         |  Role  |      State       | TL | Lag in MB | Tags             |
+------------+----------------------+--------+------------------+----+-----------+------------------+
| m7testdbr1 | 10.139.133.221:26002 |        | creating replica |    |   unknown | nofailover: true |
| m7testdbr2 | 10.139.133.222:26002 |        | creating replica |    |   unknown | nofailover: true |
| m7testpdb1 | 10.139.58.178:26002  |        |     running      | 20 |        13 |                  |
| m7testpdb2 | 10.139.58.177:26002  | Leader |     running      | 20 |           |                  |
+------------+----------------------+--------+------------------+----+-----------+-----------------+
{code}

patroni nodes m7testpdb1/2 are using the old IP´s
*10.139.58.178/10.139.58.177* and dbr´s are connecting to the new IP-address *10.139.177.253 and 10.139.117.254* so lets wait unitl the old interface is not used anymore and all is working fine. don´t want to do any workaround with that. Firewalls are fine

{code:java}
└─11615 /usr/pgsql-11/bin/pg_basebackup --pgdata=/var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async -X stream --dbname=dbname=postgres user=replicator host=10.139.58.177 port=26002
{code}

","21/Jan/21 13:00;cs687;m7testpdb1/2 database clusters were still running with the old IP, we need to change the ip-setting which are matched with DNS Name in patroni config.yml file and run a reload on primary/and secondary node 

* restapi-> connection_address &
* postgresql -> connection address has to be changed 

* patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml reload m7tshrdsyt2async m7testpdb1
* patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml reload m7tshrdsyt2async m7testpdb2

no restart, failover is necessary for that action, afterwards the new ip-address will be written in DCS and updated
","21/Jan/21 15:08;cs687;done",,,,,,,,,,,,,,,,,,,,,,
ELTS PROD: extremly bad Journaller times on 2.11. - SLAs broken - Investigation,M7P-7375,103832,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cv179,pw231,pw231,02/Dec/20 15:50,22/Dec/20 15:12,16/Sep/21 14:11,14/Dec/20 15:31,,6.11.145,7tops_sprint107,,,Database,,,,7tops,M,Operations,,,,,"h4. Problem

on 2.11. 9:00-9:11, we had very bad order times due to very slow journaler. see [this graph|https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1604303011573&to=1604305600034&var-host=m7eltsprodm7c1%20-%20tomcat%20-%20m7_elts_prod&var-client=elts&var-client_env=prod&var-group=All&var-interval=$__auto_interval_interval&var-exchangeId=EPEX&fullscreen&panelId=41]

It was enough to make the daily percentiles above the SLAs.
h4. Task
 * Was there some maintenance?
 * Investigate, what has happened and why
 * In case you find a problem, pls create a Fix task(s) or task for the introduction of new monitoring",,cv179,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"found the root cause - database reinit.

As a consequence, we will bring it to techops team meeting and let everyone know to be careful with reinits - only do it if really needed. Otherwise plan reinit for better suited day/time.",,,,,,,,ELTS,,,,,,,,,,,,,,,,23760000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4645,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwnr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 107,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":103832,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"14/Dec/20 15:08;cv179;Database was under severe network load at that time!

[https://grafana.energy.svc.dbgcloud.io/d/R1V77tRGz/system-shared-hosts?orgId=2&var-datasource=influxdb_m7_shared_services&var-product=m7&var-host=m7prodpdb1%20-%20postgres%20-%20shrd&var-client=All&var-client_env=All&var-group=All&var-interval=$__auto_interval_interval&from=1604302267221&to=1604306641232]

 ","14/Dec/20 15:10;cv179;To be checked: Was there a patroni cluster reinit at that time?","14/Dec/20 15:16;cv179;it WAS elts prod database reinit!

[https://dbg-devops.slack.com/archives/C941CV942/p1604303852215100]

 

See this was the recovery message and marks the start of the reinit. It took probably a couple of minutes in order to finish it. Master was on a different host most probably.","14/Dec/20 15:28;cv179;[https://grafana.energy.svc.dbgcloud.io/d/R1V77tRGz/system-shared-hosts?orgId=2&var-datasource=influxdb_m7_shared_services&var-product=m7&var-host=m7prodpdb1%20-%20postgres%20-%20shrd&var-client=All&var-client_env=All&var-group=All&var-interval=$__auto_interval_interval&from=1600176472641&to=1607956072641&fullscreen&panelId=14]

 

last 90 days we had this 2 times, the first one was the recovery after the issue on 2.11. and the second one was the reinit during elts prod deployment (after cleanup) - affecting all other customers only as ELTS was halted.",,,,,,,,,,,,,,,,,,,,,,,,
Alerta - split environment TEST to customer facing and internal ones,M7P-7323,102464,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,iu252,xt853,xt853,03/Nov/20 16:10,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"*Motivation*

Current Alerta has a ""TEST"" environment for both customer facing and internal environments on one pile. It makes if difficult to distinguish what's important for customers and what's for developers.

*Goal*

Split the TEST environment to separate customer facing and internal environments. 

*AC*

Extra ""tab"" in Alerta webgui with internal test environments only.",,xt853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,27302400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,,,,,"2|hzz0un:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102464,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,TECHLOG-3278-alerta-env,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Gap sequence detected on Asimu,M7P-7306,103257,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Not a Bug,fj021,dp007,dp007,18/Nov/20 14:30,02/Dec/20 12:45,16/Sep/21 14:11,19/Nov/20 10:14,,7tops_sprint106,,,,CT,M7T BE,,,M7PRODOPS,,,,,,,"Hello,

We have detected a Gap sequence on Asimu:
Date: 18-11-2020 03:49:44, Severity: ERROR, Msg: Error gap detected, routingKey: 6_0.prddlvr.XBID_Hour_Power.10YDK-2--------M : old sequence number: 338585 , new sequence number: 338587

Did you detect also gap with your monitoring tool ? if not, can you check the Rabbit MQ logs and investigate if the msg was not sent out ?

Best Regards,
Alaa Issa
",,dp007,fj021,,,,,,,,,,,,,,,,,,SERVICE-9057,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,Report a problem or bug,,,,,,,,,,26006400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,18/Nov/20 14:30,,[],,,,,,,,None,,,M7T,,,,"2|hzystj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 106 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":103257,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"19/Nov/20 09:01;fj021;Hello [~dp007]

Logs : [Kibana Stalker|https://kibana.energy.svc.dbgcloud.io/goto/a87bd7f917b32f20671055fa9eedf4c0]

We can see the three messages in order in Stalker.

To go a bit further on the Gap subject, this topic has been discussed in DevCOP and we are planning to update documentation to explain to customer that Gaps are part of the protocol itself so they should be expected and shouldn't be seen as a bug : https://jira.deutsche-boerse.com/browse/M7P-7171

We can take on this above-mentionned task in our PS.

Cheers

 ","19/Nov/20 09:27;dp007;That makes absolute sense Aurelien, thanks for your analysis and if you have a spare capacity, please consider onboarding it. 
M",,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: changing the password of an User in WebGUI,M7P-7298,103191,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Not a Bug,,dp007,dp007,16/Nov/20 15:31,18/Nov/20 10:40,16/Sep/21 14:11,16/Nov/20 16:32,,7tops_sprint105,,,,enq,,,,M7PRODOPS,PRODUCTION_BUG,,,,,,"Dear DBAG,

After changing the password of an User in WebGUI, the registered email address on that User is not receiving the new password by email (the ""Send password reset email"" is checked).

There are 2 emails received, one regarding the Login ID reminder and the second one only indicating that the password has been successfully changed, but not mentioning which is the new password.

Expected result: In the past, the second email also included the new password after the change has been done.
This behavior is in SIMU also.

KR,
Cristian",,dp007,xc363,,,,,,,,,,,,,,,,,,SERVICE-9026,,,,,,,,,,,,,,,,,,,,"16/Nov/20 15:31;dp007;MicrosoftTeams-image (1).png;https://jira.deutsche-boerse.com/secure/attachment/90010/MicrosoftTeams-image+%281%29.png","16/Nov/20 15:31;dp007;MicrosoftTeams-image.png;https://jira.deutsche-boerse.com/secure/attachment/90011/MicrosoftTeams-image.png",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,OPCOM,,,,,,Report a problem or bug,,,,,,,,,,26179200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,16/Nov/20 15:31,,[],,,,,,,,None,,,M7T,,,,"2|hzysgv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 105 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":103191,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"16/Nov/20 15:33;dp007;Dear Martin,

The user is ALLA1USR.
The password was reset at 11:20 CET.
We have the same behavior in SIMU.
KR,
Cristian

!MicrosoftTeams-image (1).png!

!MicrosoftTeams-image.png!","16/Nov/20 16:30;xc363;Dear Cristian,

The described behavior is correct.

We had to remove the functionality of sending the passwords in an open format via e-mail due to security reasons.

As an administrator, you now have two possibilities:

*1)* Modify the user details, including the password change and click ""Send password reset e-mail"". In such case, only the above mentioned e-mails are coming (user ID and general information about the change). You can use this possibility if you for example set up new users with a unified password that is agreed to be changed by the user upon their login.

The option 1) is rather a rest of the original functionality (= to preserve the possibility of changing the password by admins even if the password cannot be sent in open format anymore).

*2)* Click on the ""key"" icon in the User's Management screen. In such case a password reset link is sent to the user's e-mail address and the user themselves must finish the process of setting the password. This would be the most common option for admin users.

I hope this explanation helps!

Best regards,

Veronika",,,,,,,,,,,,,,,,,,,,,,,,,,
review M7 to XBID connectivity design - its considered suboptimal by OPS,M7P-7251,102974,,Task,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,pd122,rehapav,rehapav,10/Nov/20 11:14,30/Apr/21 10:37,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"*Current situation*

In case we would like to connect M7 environment to XBID environment we need
 * create standard trading user on XBID (usr1) with password stored in XBID LDAP (pwd1)
 * same usr1/pwd1 store on M7 side in vault / config files
 * upon startup of M7 or manual connect action M7 conensts to XBID using usr1/pwd1

*Problem*

In case pwd1 is changed/expires or usr1 is locked in XBID LDAP, it is no longer possible

to connect M7 to XBID.

Action required is
 * fix password on XBID side
 * provide M7 new password + redeploy or reconnect M7

 

This dependency is considered suboptimal by OPS.

Is it possible to find clever way of hand shaking?",,iv732,nn236,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-513,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23500800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyr8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102974,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/20 14:04;iv732;[~pd122] [~rehapav] [~zs244]
There are 2 options:
1. Create a new technical user for the connection. Password will be kept unchanged.
2. Use the current connection user (eg: OPCOM001 in case of OPCOM --> XBID LIPA), but we apply a new password policy for that user, so that its password will never expire --> customer will never receive any expiration alert --> hopefully they will not change the password.
Or we should educate customer, not to touch that user at all.

Question: how could it work so far if the connection user is not under our control, then how do we know the password that the customer set? ","15/Dec/20 14:44;rehapav;BID USM700 Password Policy - 
h2. 1.1     Exchange User ID

For every LTS which should be connected to XBID there exist two Exchange User IDs which are supposed to establish the connection: one active Exchange User ID and one not active backup Exchange User ID. In case DBAG will create both users, strong randomly created passwords will be provided to the PXs via sms. Just one of the two user IDs is allowed to be active at a time. This is not enforced technically by XBID but has to be ensured on operational level. Exchange User IDs will not be locked out in case of invalid login tries and the password will not expire.","17/Dec/20 14:04;pd122;[~rehapav] any idea how to get the list of these exchange users to check their LDAP (password policy) setup?  Assuming these are XBID users...","18/Dec/20 11:45;pd122;List of user accounts obtained from _sob_user_ secret of all M7 environments available in the vault:

epex/asim: XBEPEXX1
 xrpm/lipa: OPCOM001
 xrpm/prod: XBXRPMX1
 xrpm/prod: OPCAEX01
 xrpm/simu: OPCOM003
 plpx/lipa: XBTGEX01
 plpx/prod: XBTGEX01
 plpx/prod: XBTGEX02
 plpx/simu: XBTGEX01
 elts/asim: XBEPEXX1_new
 elts/prod: XBEPEXX1
 elts/ctpb: XBEPEXX1
 elts/simu: XBEPEXX1
 elts/cute: XBEPEXX1
 elts/acut: XBEPEXX2
 xsop/asim: XBBSP001
 xsop/prod: XBBSP001
 xsop/simu: XBBSP001
 xsop/cute: XBBSP001
 shrd/ate5: CXEPEX01
 shrd/ate4: ATE4EX02
 shrd/ate3: ATE3EX04
 shrd/dst1: XBEPEXX1
 shrd/syt3: XBEPEXX1
 shrd/syt1: SYT1EX02
 shrd/syt2: SYT2EX02
 shrd/ate2: ATE2EX01
 shrd/show: XBEPEXX1
 hupx/asim: XBHUPX03
 hupx/prod: XBHUPX03
 hupx/prod: XBHUPX04
 hupx/simu: XBHUPX04
 hupx/cute: XBHUPX03

 

Assuming these are exchange users and should have admin LDAP password policy set up (if any).",,,,,,,,,,,,,,,,,,,,,,,,
EBSM frequent error: IOException: Input is not in the .gz format,M7P-7247,102961,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,dp007,dp007,10/Nov/20 09:35,13/Jan/21 11:31,16/Sep/21 14:11,07/Jan/21 09:42,,6.11.160,7tops_sprint108,,,EBSM,,,,EBSM,M7PRODOPS,,,,,," EBSM complains many times a day about the following error:
{code:java}
05:11:07|ERROR|main      |Trace: 
java.io.IOException: Input is not in the .gz format
	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.init(GzipCompressorInputStream.java:164)
	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.<init>(GzipCompressorInputStream.java:137)
	at org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.<init>(GzipCompressorInputStream.java:102)
	at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_sys_ProcessInbox.gunZip(Gnrl_sys_ProcessInbox.java:211)
	at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_sys_ProcessInbox.unpackGzip(Gnrl_sys_ProcessInbox.java:194)
	at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_sys_ProcessInbox.processArchives(Gnrl_sys_ProcessInbox.java:144)
	at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_sys_ProcessInbox.processInbox(Gnrl_sys_ProcessInbox.java:130)
	at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_sys_ProcessInbox.main(Gnrl_sys_ProcessInbox.java:97)
{code}
TODO: analyze and fix the bug",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,The fix will just ignore such error and the file will be unzipped in the next iteration.,,,,,,,,,,,,,,,,,,,,,,,,21772800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,10/Nov/20 09:35,,[],,,,,,,,None,,,M7T,,,,"2|hzyr4v:",9223372036854775807,,,,No,,,,,,,,,,In some cases the files are still being transferred at the time the script wants to unzip them. This leads to the _Input is not in the .gz format error._,,,,,,,,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":102961,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/20 14:08;dp007;Logging enhanced.","07/Jan/21 09:40;dp007;In some cases the files are still being transferred at the time the script wants to unzip them. This leads to the _Input is not in the .gz format error._ 

The fix will just ignore such error and the file will be unzipped in the next itteration.",,,,,,,,,,,,,,,,,,,,,,,,,,
ICS 6.8 UAT - RTE Certificate Issue,M7P-7242,102950,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Not a Bug,pd122,qz412,qz412,09/Nov/20 15:59,24/Mar/21 12:26,16/Sep/21 14:11,16/Mar/21 20:22,,7tops_sprint113,,,,ICS,,,,7tops,,,,,,,"ICS in CuTE complains about issue sending files to RTE due to failure to retrieve certificates and key from Keystore (see the log message below)
{code:java}
Failed to send file ExportFile: Activity_Report_Capacity_CH-FR_20201104_20201105135039.csv (SENT, MAIL, com.deutscheboerse.energy.cmminteg.filetype.report.ActivityReportV2Legacy) for 10XFR-RTE------Q
com.deutscheboerse.energy.cmminteg.api.transport.TransportException: Could not send mail for ExportFile: Activity_Report_Capacity_CH-FR_20201104_20201105135039.csv (SENT, MAIL, com.deutscheboerse.energy.cmminteg.filetype.report.ActivityReportV2Legacy) for 10XFR-RTE------Q
	at com.deutscheboerse.energy.cmminteg.transport.mail.MailHandler.sendFile(MailHandler.java:154)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy178.sendFile(Unknown Source)
	at com.deutscheboerse.energy.cmminteg.transport.FileSenderProxy.sendFile(FileSenderProxy.java:61)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.integration.handler.support.MessagingMethodInvokerHelper$HandlerMethod.invoke(MessagingMethodInvokerHelper.java:1119)
	at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.invokeHandlerMethod(MessagingMethodInvokerHelper.java:628)
	at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:493)
	at org.springframework.integration.handler.support.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:362)
	at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:106)
	at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:93)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:123)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:176)
	at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:224)
	at org.springframework.integration.dispatcher.BroadcastingDispatcher.access$000(BroadcastingDispatcher.java:56)
	at org.springframework.integration.dispatcher.BroadcastingDispatcher$1.run(BroadcastingDispatcher.java:204)
	at org.springframework.integration.util.ErrorHandlingTaskExecutor.lambda$execute$0(ErrorHandlingTaskExecutor.java:57)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Failed to retrieve certificates and key from Keystore
	at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverterFactory.loadCertificates(SMIMEConverterFactory.java:95)
	at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverterFactory.getConverter(SMIMEConverterFactory.java:111)
	at com.deutscheboerse.energy.cmminteg.transport.mail.MailHandler.createMimeMessage(MailHandler.java:213)
	at com.deutscheboerse.energy.cmminteg.transport.mail.MailHandler.sendFile(MailHandler.java:149)
	... 33 common frames omitted
Caused by: java.security.UnrecoverableKeyException: Cannot recover key
	at sun.security.provider.KeyProtector.recover(KeyProtector.java:315)
	at sun.security.provider.JavaKeyStore.engineGetKey(JavaKeyStore.java:143)
	at sun.security.provider.JavaKeyStore$JKS.engineGetKey(JavaKeyStore.java:57)
	at sun.security.provider.KeyStoreDelegator.engineGetKey(KeyStoreDelegator.java:96)
	at sun.security.provider.JavaKeyStore$DualFormatJKS.engineGetKey(JavaKeyStore.java:71)
	at java.security.KeyStore.getKey(KeyStore.java:1023)
	at com.deutscheboerse.energy.commons.transport.mail.SMIMEConverterFactory.loadCertificates(SMIMEConverterFactory.java:87)
	... 36 common frames omitted{code}
Current Log entry for the issue: [https://kibana.energy.svc.dbgcloud.io/goto/88b31f6d83df757138bd1447d3f3f314]

This needs to be fixed as for the UATs RTE needs to be able to receive files.

This *may* be related to the issue we faced in PROD: https://jira.deutsche-boerse.com/browse/SERVICE-8469

*Acceptance Criteria:*
 * ICS is able to send encrypted files to RTE using the rte test certificate",,pd122,qz412,xc363,,,,,,,,,,,,,,,,,M7P-7225,,,,,,,,,,,,,,SERVICE-9755,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15206400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7292,,,,,,,,,,,,,09/Nov/20 15:21,,[],,,,,,,,None,,,M7C,,,,"2|hzn3fz:",9223372036854775807,,,,No,,,,,,,,,,expired key in the CMI application keystore replaced with the new valid one,,,,,,,,X-Men Sprint 105 (US),Magnificent 7 Sprint 106 (US),Schmetterling Sprint 107 (US),X-Men Sprint 108 (PS),Magnificent 7 Sprint 109 (PS),Schmetterling Sprint 110 (PS),X-Men Sprint 111 (PS),Magnificent 7 Sprint 112 (PS),Schmetterling Sprint 113 (PS),Schmetterling Sprint 114,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102950,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"18/Nov/20 08:40;qz412;The rte ICS CuTE certificate expired on 18.07.2020.

We have contacted RTE to provide new certificate to us and even after reminding them we are still waiting, no response.","12/Jan/21 13:03;qz412;Despite repeated urgencies in Dec 2020 RTE has not got back to us yet. We will urge again.","03/Feb/21 13:31;xc363;[~qz412] can we close the issue? It's flowing through all production shifts :)","08/Feb/21 13:16;qz412;[~xc363]: The issue is still there, RTE is not communicating at all. We are sending them reminders every week through e-mail and JIRAs, no response. I think it should remain open / tracked in some form and be handed over to XBID if RTE does not act until the handover. If you think that keeping the SERVICE open for the time they give us the cert and opening a new M7P / XP ticket once we get it is the right way ahead, no prob & close.","22/Feb/21 12:12;qz412;Customers finally reported issues with the file reception. They have the new certificate already in place on their side, we asked them to give it to us so that we can configure CuTE. The discussion runs here: https://jira.deutsche-boerse.com/browse/SERVICE-9487","15/Mar/21 16:45;fh971;We need to update keystore with {{rte}} id, update tbxi035_config with the new password and redeploy (like previously done in SERVICE-8469). ","16/Mar/21 16:28;pd122;vault secret _secret/m7c/icsc/cute/mail/keystore:keystore_ contains expired *rte *key:

{code:java}
Alias name: rte
Creation date: Sep 26, 2017
Entry type: PrivateKeyEntry
Certificate chain length: 1
Certificate[1]:
Owner: EMAILADDRESS=icscute@m7c.deutsche-boerse.com, CN=Icsccute ENVIRONMENT, OU=ISO 6523 - 999911XDBS-DE-NL---6, OU=Soft ID, O=Deutsche Borse Systems AG, C=EN
Issuer: CN=RTE Client Certification Authority, OU=0002 444619258, O=RESEAU DE TRANSPORT D'ELECTRICITE, C=FR
Serial number: 1121a0a1c50b410c44043db24c642a798915
Valid from: Tue Jul 18 16:06:38 CEST 2017 until: Sat Jul 18 16:06:38 CEST 2020
{code}
","16/Mar/21 16:52;pd122;*rte* key in the vault secret keystore replaced with new one:

{code:java}
Alias name: rte
Creation date: Mar 16, 2021
Entry type: PrivateKeyEntry
Certificate chain length: 1
Certificate[1]:
Owner: EMAILADDRESS=icscute@m7c-test.deutsche-boerse.com, CN=Icsccute ENVIRONMENT, OU=ISO 6523 - 999911XDBS-DE-NL---6, OU=Soft ID, O=Deutsche Borse Systems AG, C=EN
Issuer: CN=RTE Client Certification Authority, OU=0002 444619258, O=RESEAU DE TRANSPORT D'ELECTRICITE, C=FR
Serial number: 11213a2bf93b70755e94ff0641bab100f8bc
Valid from: Fri Mar 12 13:32:33 CET 2021 until: Tue Mar 12 13:32:33 CET 2024
Certificate fingerprints:
         MD5:  37:3B:12:29:9A:3A:48:B5:D4:7A:83:02:83:6C:6E:24
         SHA1: 19:AA:5D:B5:8D:DB:8D:81:95:AA:48:62:2C:91:93:DE:03:5C:FA:1B
         SHA256: A7:05:F9:63:8B:D4:32:E1:A1:9C:85:1B:2C:D5:73:48:E4:A7:0A:49:20:52:FD:17:96:52:BA:85:0F:EF:BC:3D
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3
{code}
","16/Mar/21 17:21;pd122;RTE password updated in the DB (config_value in tbxi035_config table where config_key is EMAIL_DECRYPT_PASSWORD  and party_id is'10XFR-RTE------Q') ","16/Mar/21 17:36;pd122;In order to update the actual keystore CMI module needs to be deployed","16/Mar/21 20:15;pd122;*cmi *re-deployed (product version 6.8.149): https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7C_deploy_full/54/console

there seems to be more expired certs than just the one replaced on that environment though:

{code:java}
2021-03-16 20:05:59.172 [executor-9]:[]        ERROR - c.d.e.c.t.FileSenderProxy - Failed to send file ExportFile: EMFIP_XATC_CH-AT_20210316.xml (SENT, WS, com.deutscheboerse.energy.cmminteg.filetype.emfip.XATC) for 10X1001A1001A450
com.deutscheboerse.energy.cmminteg.api.transport.TransportException: EMFIP sending failed for ExportFile: EMFIP_XATC_CH-AT_20210316.xml (SENT, WS, com.deutscheboerse.energy.cmminteg.filetype.emfip.XATC) for 10X1001A1001A450
Caused by: org.springframework.ws.client.WebServiceIOException: I/O error: No trusted certificate found; nested exception is javax.net.ssl.SSLHandshakeException: No trusted certificate found
Caused by: javax.net.ssl.SSLHandshakeException: No trusted certificate found
Caused by: sun.security.validator.ValidatorException: No trusted certificate found
{code}
","16/Mar/21 20:19;pd122;here's one expired key:

{code:java}
Alias name: cmi
Creation date: Sep 13, 2017
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=ICSCUTEMAIL, OU=mail, OU=icsc-app, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 68d16ddd86ae42f418cd17eb6d3aaa0c986b86c7
Valid from: Fri Sep 08 09:26:53 CEST 2017 until: Tue Sep 08 09:26:53 CEST 2020
Certificate fingerprints:
         MD5:  C1:D0:31:75:C3:56:3F:4D:E8:7E:01:B5:CA:6A:E4:8F
         SHA1: 9D:9B:AD:2B:24:DD:3A:88:F3:0B:22:C5:EF:EA:D3:23:85:AF:4E:54
         SHA256: F6:C3:43:5F:A4:25:F8:47:5B:6F:E2:5B:EF:75:EA:89:53:B4:DE:10:09:0B:77:16:4E:B7:4D:B5:EB:42:8F:62
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3
{code}
","17/Mar/21 13:41;qz412;Thank you for raising this, [~pd122]. The ""ERROR - c.d.e.c.t.FileSenderProxy - Failed to send file ExportFile: EMFIP_XATC_CH-AT_20210316.xml, No trusted certificate found"" is likely caused by problems with ENTSO-E certificate either being unavailable or unsuitable: Alias name would be like: icsc????entsoe (where ???? would likely be test or something like that, see https://jira.deutsche-boerse.com/browse/M7P-7013). Do we have such a cert in the CuTE keystore at all? I am not sure when the CuTE integration with the Transparency Platform last worked previously. We eventually should track this as a separate ticket.","24/Mar/21 12:26;qz412;Closing the issue, the certificate has been put in place. There are followup issues that will be addressed by XBID teams.",,,,,,,,,,,,,,
Make change log scrollable,M7P-7211,102543,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,04/Nov/20 14:25,30/Jun/21 12:13,16/Sep/21 14:11,25/Jun/21 09:14,,6.12.91,7tops_sprint120,,,Customer Portal,,,,M7PRODOPS,,,,,,,Customer portal changelog offers the bullet point list of M7 versions on the left side working as a quick link to corresponding change log item. But if this list overlaps the height of the panel there is no way how to get the hidden links as there is no scrollbar.,,dp007,,,,,,,,,,,,,,,,,,,,M7P-6925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,scrollbar added,,,,,,,,,,,,,,,,,,,,,,,,27216000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5772,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyosf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102543,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change VLANs of DB Test hosts with proper consul-hosts ,M7P-7209,102534,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,04/Nov/20 13:17,05/Jan/21 23:39,16/Sep/21 14:11,26/Nov/20 13:57,,6.8.148,7tops_sprint106,,,Database,,,05/Nov/20 00:00,Database,M7PRODOPS,,,,,,"Currently the m7 test DB-Hosts are running in a wrong VLAN ""M7CLOUD-SIM-BE-DATA-H1-FF"" - *network: 10.139.56.0*

this needs to be changed to the proper one ""M7CLOUD-TST-BE-DATA-H1-FF"" - *network: 10.139.117.0*

the new interface is already configured on the hosts *m7testpdb1 & m7testpdb2*
{code:java}
ifcfg-bond-admin (old one) 
ifcfg-bond2-admin (new one) with the additional interface ifcfg-eno6
 
DEVICE=bond2-admin
IPADDR=10.139.117.253
NETMASK=255.255.255.0
ONBOOT=yes
BOOTPROTO=none
USERCTL=no
BONDING_OPTS=""miimon=100 mode=6 updelay=300""
{code}

and we need to activate it with the command:
{code:java}
ifup bond2-admin
{code}

more and less we have to change the standard gateway, that it will use the proper one after changing the ip´s - but this can be done once all the test-application hosts are in the correct VLAN
so for that we are just editing the /etc/hosts file
{code:java}
[cs687@m7testpdb1 ~]$ cat /etc/sysconfig/network
# Created by anaconda
GATEWAY=10.139.56.3
NOZEROCONF=yes
{code}

maybe we have to change something for static-routes as well, at least correct them with the proper gateway. what is maintained by SYSENG in this repo https://github.deutsche-boerse.de/dev/energy.automation.os.install/tree/master/roles/os_network/templates
{code:java}
/etc/sysconfig/network-scripts/route-bond-admin
#
# Routing table for VLAN389 hosted on VMWare hosts
#
10.136.21.0/24    via     10.139.56.6     dev     bond-admin
10.136.20.0/24    via     10.139.56.6     dev     bond-admin
10.136.12.0/24    via     10.139.56.6     dev     bond-admin
10.136.9.0/25     via     10.139.56.6     dev     bond-admin
10.136.31.0/25    via     10.139.56.6     dev     bond-admin
10.136.31.128/25  via     10.139.56.6     dev     bond-admin
10.136.149.0/24   via     10.139.56.9     dev     bond-admin
10.136.148.0/24   via     10.139.56.9     dev     bond-admin
10.136.140.0/24   via     10.139.56.9     dev     bond-admin
10.136.137.0/25   via     10.139.56.9     dev     bond-admin
10.136.159.0/25   via     10.139.56.9     dev     bond-admin
10.136.159.128/25 via     10.139.56.9     dev     bond-admin
193.29.68.64/27   via     10.139.56.11    dev     bond-admin
{code}

While we are changing IPs on the db-hosts, we should rather put the clusters to maintenance mode or better shut them down what cybertec is recommending us to do!
{code:java}
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause;done
or
systemctl stop {{ clustername }}
{code}

Once we are done we will setup new consul cluster with 5 nodes entestcnsl1-5 and start up the patroni nodes/disable maintenance mode again.  

When all parties agree to it we would like to do this action tomorrow, and inform the guys in the proper channels about it.  ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,steps can be taken in the last comment ,,,,,,,,,,,,,,,,,,,,,,,,25315200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzyoqn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102534,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"04/Nov/20 14:58;cs687;*we need also do to:*
add the static routes (single hosts) consul-hosts *entestcnsl1-5* with standard gateway 10.139.117.3 :
* ip route add 10.139.130.241/32 via 10.139.117.3
* ip route add 10.139.130.242/32 via 10.139.117.3
* ip route add 10.139.130.243/32 via 10.139.117.3
* ip route add 10.139.130.244/32 via 10.139.117.3
* ip route add 10.139.130.245/32 via 10.139.117.3
and also add them to the file /etc/sysconfig/network-scripts/route-bond2-admin
{code:java}
10.139.130.241/32   via    10.139.117.3    dev     bond2-admin
10.139.130.242/32   via    10.139.117.3    dev     bond2-admin
10.139.130.243/32   via    10.139.117.3    dev     bond2-admin
10.139.130.244/32   via    10.139.117.3    dev     bond2-admin
10.139.130.245/32   via    10.139.117.3    dev     bond2-admin
{code}

and in /etc/hosts hardcoded pdb-servers to overwrite the dns as well 
*m7testpdb1:*
{code:java}
10.139.117.253 m7testpdb1.deutsche-boerse.de m7testpdb1
{code}

*m7testpdb2:*
{code:java}
10.139.117.254 m7testpdb2.deutsche-boerse.de m7testpdb2
{code}
","05/Nov/20 10:22;cs687;started the new interface 
*[root@m7testpdb2 ~]# ifup bond2-admin*


{code:java}
[root@m7testpdb2 ~]# ifconfig
bond2-admin: flags=5187<UP,BROADCAST,RUNNING,MASTER,MULTICAST>  mtu 1500
        inet 10.139.117.254  netmask 255.255.255.0  broadcast 10.139.117.255
        ether 48:df:37:7b:e7:98  txqueuelen 1000  (Ethernet)
        RX packets 102085316  bytes 8265598752 (7.6 GiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 6725904  bytes 403553340 (384.8 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

eno6: flags=6211<UP,BROADCAST,RUNNING,SLAVE,MULTICAST>  mtu 1500
        ether 48:df:37:7b:e7:98  txqueuelen 1000  (Ethernet)
        RX packets 51042524  bytes 4132787778 (3.8 GiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 3362938  bytes 201776100 (192.4 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
{code}

add static routes on both hosts: 
{code:java}
[root@m7testpdb2 network-scripts]# ip route add 10.139.130.241/32 via 10.139.117.3   
[root@m7testpdb2 network-scripts]# ip route add 10.139.130.242/32 via 10.139.117.3   
[root@m7testpdb2 network-scripts]# ip route add 10.139.130.243/32 via 10.139.117.3   
[root@m7testpdb2 network-scripts]# ip route add 10.139.130.244/32 via 10.139.117.3   
[root@m7testpdb2 network-scripts]# ip route add 10.139.130.245/32 via 10.139.117.3   
{code}

and created file for static routes 

checked the iptables on consulhosts and removed firewalld 
*iptables -L -n -v*
*yum remove firewalld*

afterwards connection established 
{code:java}
[root@m7testpdb2 network-scripts]# telnet 10.139.130.241 8301
Trying 10.139.130.241...
Connected to 10.139.130.241.
Escape character is '^]'.
Connection closed by foreign host.
[root@m7testpdb2 network-scripts]# telnet 10.139.130.241 8301
{code}

stopped patroni node on both sides:
{code:java}
for i in `ls /etc/ |grep patroni_`;do echo $i; systemctl stop $i;done
{code}




","05/Nov/20 11:56;cs687;*stopped consul-service*
{code:java}
""systemctl stop consul.service""
{code}

and saved the consul configuration files /etc/consul in /tmp on both hosts
{code:java}
drwx------   4 root root   80 Nov  5 11:55 .
drwxrwxrwt. 10 root root  264 Nov  5 11:55 ..
-rw-r--r--   1 root root 1887 Nov  5 11:55 config.json
-rw-r--r--   1 root root    0 Nov  5 11:55 .consul_bootstrapped
drwx------   2 root root    6 Nov  5 11:55 consul.d
drwxr-xr-x   2 root root  187 Nov  5 11:55 ssl
{code}

https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/consul_instance#new-cluster-deployment

deleted cleaned the vault secrets: 
*secrets/secret/global/consul*

* define in the inventory the server instances with the consul_node_role: server
and specified the consul_datacenter and groups
inventory/energy/shrd/test/consul/main.yml
inventory/m7t/shrd/test/consul/main.yml
inventory/m7t/shrd/test/consul/vars.yml

* created keys and certificates 
{code:java}
export CONSUL_DC=energy-shrd-test && \
export CONSUL_BINARY=/usr/local/bin/consul && \
roles/consul_instance/create-consul-cluster.sh
{code}

* deployed consul cluster:
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass --limit 'energy-shrd-test-cnsl*'
{code}

* after deployment we have to copy the bootstrap token to vault 
{code:java}
 /etc/consul/config.json to vault secret/global/consul/<dc_name>/bootstrap_token

vault write secret/global/consul/energy-shrd-test/bootstrap_token value=XXXX-XXX-XXXX-XXXX
vault write secret/global/consul/energy-shrd-test/acl_replication_token value=XXXX-XXX-XXXX-XXXX
vault write secret/global/consul/energy-shrd-test/acl_agent_token value=XXXX-XXX-XXXX-XXXX
{code}

* check if the consul cluster is up and running 
{code:java}
export CONSUL_HTTP_TOKEN=XXXXX-XXXX-XXX-XXX
consul members
{code}

* Deploy consul on all nodes of consul cluster including clients
{code:java}
ansible-playbook -e consul_group_name=consul_energy_shrd_test playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass
{code}


not all the conusl-members were shown up, pdb´s are missing:
{code:java}
[root@entestcnsl1 ~]# consul members
Node                    Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-test-cnsl1  10.139.130.241:8301  alive   server  1.8.5+ent  2         energy-shrd-test  <all>
energy-shrd-test-cnsl2  10.139.130.242:8301  alive   server  1.8.5+ent  2         energy-shrd-test  <all>
energy-shrd-test-cnsl3  10.139.130.243:8301  alive   server  1.8.5+ent  2         energy-shrd-test  <all>
energy-shrd-test-cnsl4  10.139.130.244:8301  alive   server  1.8.5+ent  2         energy-shrd-test  <all>
energy-shrd-test-cnsl5  10.139.130.245:8301  alive   server  1.8.5+ent  2         energy-shrd-test  <all>
{code}

changed the proper ip-address of the pdb-host in /etc/consul/config.json
{code:java}
    ""advertise_addr"": ""xxx.xxx.xxx.xxx."",
    ""advertise_addr_wan"": ""xxx.xxx.xxx.xxx."",
    ""bind_addr"":  ""xxx.xxx.xxx.xxx."",
{code}
and restart the consul.service

installed the packages ""python3-libselinux and deploy consul again
afterwards consul started up ","05/Nov/20 15:15;cs687;We have to stop the maintenance because the show-case environment is used by external tester Penetration-Testing which were lately decided to run it on the show-case env
Tests will finish at 16.11.2020

Will put the ticket to waiting!","26/Nov/20 13:48;cs687;Started with the maintenance:

* backup patroni configs in /etc/patroni_*
* backup consul config in /etc/consul
* backup consul data in /var/consul
* Stop patroni clusters/services
{code:java}
for i in `ls /etc/ |grep patroni_`;do echo $i; systemctl stop $i;done
{code}
* Stop consul services
{code:java}
systemctl stop consul 
{code}
* Stop first bond interface ""bond-admin"" on both servers m7testpdb1/2 
{code:java}
ifdown bond-admin
# afterwards log-in with ILO and add static route for the new bond2-admin interface
ip route add 0.0.0.0/0 via 10.139.117.1
# afterwards we can ssh the machines again 
{code}
* Check if networking is fine
* Deploy consul and see if it works
*updated consul deployment steps here*
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/consul_instance/README.md#new-cluster-deployment---example-for-energy-shrd-test
*clean up steps are here*
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/consul_instance/README.md#cleanup-tasks-in-the-case-when-you-have-to-do-clean-redeploy-of-consul-on-already-deployed-serversclients
*bring up bond-admin interface again*
{code:java}
ifup bond-admin
check route -n 
[cs687@m7testpdb2 ~]$ route -n                                                            
Kernel IP routing table                                                                   
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface             
0.0.0.0         10.139.56.3     0.0.0.0         UG    0      0        0 bond-admin        
10.136.9.0      10.139.56.6     255.255.255.128 UG    0      0        0 bond-admin        
10.136.12.0     10.139.56.6     255.255.255.0   UG    0      0        0 bond-admin        
10.136.20.0     10.139.56.6     255.255.255.0   UG    0      0        0 bond-admin        
10.136.21.0     10.139.56.6     255.255.255.0   UG    0      0        0 bond-admin        
10.136.31.0     10.139.56.6     255.255.255.128 UG    0      0        0 bond-admin        
10.136.31.128   10.139.56.6     255.255.255.128 UG    0      0        0 bond-admin        
10.136.137.0    10.139.56.9     255.255.255.128 UG    0      0        0 bond-admin        
10.136.140.0    10.139.56.9     255.255.255.0   UG    0      0        0 bond-admin        
10.136.148.0    10.139.56.9     255.255.255.0   UG    0      0        0 bond-admin        
10.136.149.0    10.139.56.9     255.255.255.0   UG    0      0        0 bond-admin        
10.136.159.0    10.139.56.9     255.255.255.128 UG    0      0        0 bond-admin        
10.136.159.128  10.139.56.9     255.255.255.128 UG    0      0        0 bond-admin        
10.139.56.0     0.0.0.0         255.255.252.0   U     0      0        0 bond-admin        
10.139.117.0    0.0.0.0         255.255.255.0   U     0      0        0 bond2-admin       
10.139.130.241  10.139.117.3    255.255.255.255 UGH   0      0        0 bond2-admin       
10.139.130.242  10.139.117.3    255.255.255.255 UGH   0      0        0 bond2-admin       
10.139.130.243  10.139.117.3    255.255.255.255 UGH   0      0        0 bond2-admin       
10.139.130.244  10.139.117.3    255.255.255.255 UGH   0      0        0 bond2-admin       
10.139.130.245  10.139.117.3    255.255.255.255 UGH   0      0        0 bond2-admin       
193.29.68.64    10.139.56.11    255.255.255.224 UG    0      0        0 bond-admin        
{code}

* If we can see all consul nodes communicating, we can remove patroni token workaround 
from ansible inventory
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2407/files
used token in vault https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/global/consul/energy-shrd-test/bootstrap_token
* Redeploy patroni on one env - syt3 and see if it works
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --tags deploy --limit m7a-shrd-syt2-pdb-sync* -b -K -k
{code}
* Continue with the rest

{code:java}
[root@m7testpdb1 global]# export CONSUL_HTTP_TOKEN=6179232f-6bed-5ece-9025-ee1fa52a0bc1
[root@m7testpdb1 global]# consul members
Node                       Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-test-cons1     10.139.130.241:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons2     10.139.130.242:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons3     10.139.130.243:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons4     10.139.130.244:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
energy-shrd-test-cons5     10.139.130.245:8313  alive   server  1.8.6+ent  2         energy-shrd-test  <all>
m7t-shrd-test-consul-pdb1  10.139.117.253:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
m7t-shrd-test-consul-pdb2  10.139.117.254:8301  alive   client  1.8.6+ent  2         energy-shrd-test  m7-test-patroni-cluster
{code}

","26/Nov/20 13:57;cs687;done",,,,,,,,,,,,,,,,,,,,,,
ICSC PROD - 6.8 (rehersal) production installation test,M7P-7204,102520,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,rehapav,rehapav,rehapav,04/Nov/20 10:18,27/Jan/21 09:02,16/Sep/21 14:11,22/Jan/21 16:47,,6.11.178,,,,uknown,,,08/Jan/21 00:00,-,+,6.8,7tops_comm,M,,,"*Business reason*
 - agreed mandatory test defined prior to 6.9 acceptance together by PO and  RM
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ICSC PROD data snapshot

*Preparation*
 * create a playbook SERVICE-8536
 * *get dump from ICSC PROD*environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment actual ICSC PROD version
 * load dump into system test environment
 * deploy 6.8 PROD ready software via Ansible / AZUL / Patronidb
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** flyway scripts for 6.10 software were successfully executed
 * measure migration timeline
 * *!!! do not start the environment !!!*

*Acceptance criteria*
 * complete rehearsal test was successful

 
  ",,cs687,op211,rehapav,,,,,,,,,,,,,,,,,M7P-7182,,,,,,,,,,,,,,SERVICE-8695,,,,,,"15/Dec/20 09:19;fj021;CMI_cleanup.sql;https://jira.deutsche-boerse.com/secure/attachment/91124/CMI_cleanup.sql","06/Jan/21 16:29;fj021;M7B_cleanup.sql;https://jira.deutsche-boerse.com/secure/attachment/91488/M7B_cleanup.sql",,,,,,,,,,,,,,sw455,,,,,,,,ICS PROD rehersal test performed,,,,,,,,,,,,,,,,,,,,,,,,20390400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7292,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyr5b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 107,7tops Sprint 108,7tops Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102520,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"18/Dec/20 16:45;op211;Database migration step is done from ICSC/EPEX PROD to Shared ATE5 database (m7testpdb1|2:26032). Detailed steps are in the playbook for PROD: [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/2021-01+ICSC+PROD+6.8]

Next step would be the Flyway migration, but here there was an issue in the first step for core DB (schema m7cshrdate5m7b):
{noformat}
Flyway 3.2.1 by BoxfuseDatabase: jdbc:postgresql://m7testpdb1.deutsche-boerse.de:26032/m7cshrdate5m7b (PostgreSQL 11.5)
Validated 134 migrations (execution time 00:00.095s)
ERROR: Unable to lock table ""m7cshrdate5m7b"".""schema_version""{noformat}
After Flyway migration for Core DB and CMI DB, next step is to deploy *without start* to trigger the rest of the Flyway migration.","15/Jan/21 15:55;cs687;+*Prepare database setup: *+

{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7c*icsc-prod*pdb-async3:m7c*icsc-prod*pdb-async4"" -k -K -b --tags deploy 
{code}

before i run the command above i added all the necessary vault-settings:
{code:java}
m7c/icsc/prod/db/postgres_db_password
m7c/icsc/prod/db/replication_db_password
m7c/icsc/prod/db/netbackup
{code}

{code:java}
[root@m7prodpdb3 ~]# patronictl -c /etc/patroni_m7cicscprodasync/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7cicscprodasync | m7prodpdb3 | 10.139.53.172:20020 |        | running |  1 |         0 |
| m7cicscprodasync | m7prodpdb4 | 10.139.53.171:20020 | Leader | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+

                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7cicscprodcmi | m7cicscprodcmi | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7cicscprodcmi                   +
                |                |          |             |             | m7cicscprodcmi=CTc/m7cicscprodcmi    +
                |                |          |             |             | uapp01m7cicscprodcmi=c/m7cicscprodcmi+
                |                |          |             |             | udev01m7cicscprodcmi=c/m7cicscprodcmi
 m7cicscprodm7b | m7cicscprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7cicscprodm7b                   +
                |                |          |             |             | m7cicscprodm7b=CTc/m7cicscprodm7b    +
                |                |          |             |             | uapp01m7cicscprodm7b=c/m7cicscprodm7b+
                |                |          |             |             | udev01m7cicscprodm7b=c/m7cicscprodm7b
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(5 rows)
{code}

*+Open-Points:+*
* deploy the cluster-nodes on m7prodpdb1/2/3 once we have the disk extensions ready (~ around 12 weeks are planned!) + monitoring + backup scripts!
* -SYSENG-Ticket to add more memory for m7proddbr1/2 and deploy replica-nodes-
{code:java}
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7c*icsc-prod-dbr-async*"" -k -K -b --tags replica 
{code}
* -deploy monitoring-clients for current deployed nodes-
* -deploy backup scripts on the hosts and request the policy by nbu-admin team-
* CREATE ROLE *uapp01m7cicscprodcmm* with proper password and Grand permissions
{code:java}
CREATE ROLE uapp01m7cicsccutecmm WITH LOGIN PASSWORD 'XXXX';
{code}
","18/Jan/21 11:48;cs687;deployed replica nodes: 
{code:java}
[root@m7proddbr1 ~]# patronictl -c /etc/patroni_m7cicscprodasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7cicscprodasync | m7proddbr1 | 10.139.135.221:20020 |        | running |  2 |         0 |
| m7cicscprodasync | m7proddbr2 | 10.139.135.222:20020 |        | running |  2 |         0 |
| m7cicscprodasync | m7prodpdb3 | 10.139.53.172:20020  | Leader | running |  2 |         0 |
| m7cicscprodasync | m7prodpdb4 | 10.139.53.171:20020  |        | running |  2 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

additional space was requested from SYSENG!

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1316
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1318

from cyberark its possible to access the database schemas cmi/m7b after triggering the jenkins job https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Temporary%20DB%20access%20(M7)/","18/Jan/21 13:49;cs687;deployed monitoring clients for pdb3/4 & dbr1/2:
{code:java}
PLAY RECAP *********************************************************************
m7c-icsc-prod-dbr-async1   : ok=21   changed=4    unreachable=0    failed=0   
m7c-icsc-prod-dbr-async2   : ok=21   changed=4    unreachable=0    failed=0   
m7c-icsc-prod-pdb-async3   : ok=27   changed=3    unreachable=0    failed=0   
m7c-icsc-prod-pdb-async4   : ok=21   changed=3    unreachable=0    failed=0
{code}

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/
touched instances: m7c-icsc-prod-pdb-async3:m7c-icsc-prod-pdb-async4:m7c-icsc-prod-dbr-async1:m7c-icsc-prod-dbr-async2

did the same for filebeat:
{code:java}
-rw-r--r-- 1 pgwatch2 pgwatch2 853 Jan 18 13:34 /etc/pg_watch2/pg_watch2.d/m7c-icsc-prod-dbr-async1.yml
-rw-r--r-- 1 beat beat  545 Jan 18 13:43 m7c-icsc-prod-dbr-async1.yml
{code}
","18/Jan/21 14:02;cs687;deployed pdb1/2 nodes with 100mb filesystem-size,
will stop the patroni-services until we have the proper disk extension done. 

{code:java}
ansible-playbook playbooks/deploy_patroni.yml -e ""postgres_data_fs_size=100m"" -e ""postgres_backup_fs_size=100m"" -e ""postgres_log_fs_size=100m"" --limit ""m7c*icsc-prod*pdb-async1:m7c*icsc-prod*pdb-async2"" -k -K -b --tags deploy
{code}

{code:java}
-bash-4.2$ patronictl -c /etc/patroni_m7cicscprodasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7cicscprodasync | m7proddbr1 | 10.139.135.221:20020 |        | running |  2 |           |
| m7cicscprodasync | m7proddbr2 | 10.139.135.222:20020 |        | running |  2 |           |
| m7cicscprodasync | m7prodpdb1 | 10.139.53.176:20020  |        | running |  2 |           |
| m7cicscprodasync | m7prodpdb2 | 10.139.53.173:20020  |        | running |  2 |           |
| m7cicscprodasync | m7prodpdb3 | 10.139.53.172:20020  | Leader | running |  2 |         0 |
| m7cicscprodasync | m7prodpdb4 | 10.139.53.171:20020  |        | running |  2 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

also deployed monitoring clients and backup scripts for it!
","18/Jan/21 14:44;cs687;deployed backup-scripts for all hosts and informed nbu about it. 

{code:java}
************* This message is automatically generated *************
***************** Please, do not reply to this e-mail *****************
 
A Ticket was created for your request.
To open the ticket within Citrix, please use this link: Link
To open the ticket outside Citrix, please use this test link: Link
 
Object ID:	20864025
Title:	ReqNBU New DB Backup M7 ICSCPROD
Contact Name:	Mr. Steffen Englert
Assignment Group:	IT INF Netbackup Administration
Status:	Open
Priority:	Medium
Category 1:	IT INF (IT Infrastructure) 
Category 2:	Request
Ticket Type:	IT Internal Ticket
 	 
E-Mail:
 The below email is classified: Internal
 
Hi nbu-team,
 
For our last database migration, we need one additional policy for ICSCPROD. 
Thanks in Advance!
{code}

backup is working: 
{code:java}
[root@m7prodpdb3 ~]# /usr/bin/backup-ampgsql#icscprod#Full.sh
Backup Started - Tue Jan 19 07:37:47 CET 2021
DATASTORE_SERVER =
DATASTORE_POLICY =
DATASTORE_SCHED  =
/usr/bin/postgres-backup --hostname nbuonline2.deutsche-boerse.de --policy PROD-M7-PGSQL-M7PRODPDB-ICSCPROD --schedule Full --client m7prodpdb3.deutsche-boerse.de --app pgsql --application ampgsql --disk /var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync --device /var/lib/pgsql_m7cicscprodasync/data/11/m7cicscprodasync --property statedir=/var/lib/pgsql_m7cicscprodasync/backup/netbackup/ampgsql --property db=template1 --property user=usernetbackup --property max-wal-wait= --property host=m7prodpdb3.deutsche-boerse.de --property cleanupwal=YES --property port=20020 --property passfile=/var/lib/pgsql/.pgpass --property tmpdir=/tmp --property psql-path=/usr/pgsql-11/bin/psql --property archivedir=/var/lib/pgsql_m7cicscprodasync/backup/11/pg_xlog_archive --property gnutar-path=/bin/tar --property verbose=on
copyId: 1 - 1611038302
MESG: | psql stdout:  pg_start_backup
MESG: | psql stdout: -----------------
MESG: | psql stdout:  0/1A000028
MESG: | psql stdout: (1 row)
MESG: | psql stderr: NOTICE:  pg_stop_backup complete, all required WAL segments have been archived
MESG: | psql stdout:  pg_stop_backup
MESG: | psql stdout: ----------------
MESG: | psql stdout:  0/1A0000F8
MESG: | psql stdout: (1 row)
Use of uninitialized value $maj in multiplication (*) at /usr/bin/ampgsql line 1058, <VERSOUT> line 1.
Use of uninitialized value $min in multiplication (*) at /usr/bin/ampgsql line 1058, <VERSOUT> line 1.
Use of uninitialized value $pat in addition (+) at /usr/bin/ampgsql line 1058, <VERSOUT> line 1.
Bytes backed up: 277381120
Finished Tue Jan 19 07:39:04 CET 2021
exit 0
{code}

","21/Jan/21 14:53;op211;CMM user created in Database:
{noformat}
CREATE ROLE uapp01m7cicscprodcmm WITH LOGIN PASSWORD 'xxx';
ALTER DEFAULT PRIVILEGES IN SCHEMA m7cicscprodm7b GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO uapp01m7cicscprodcmm;
ALTER DEFAULT PRIVILEGES IN SCHEMA m7cicscprodm7b GRANT USAGE ON SEQUENCES TO uapp01m7cicscprodcmm;
ALTER DEFAULT PRIVILEGES IN SCHEMA m7cicscprodm7b GRANT EXECUTE ON FUNCTIONS TO uapp01m7cicscprodcmm;
GRANT CONNECT ON DATABASE m7cicscprodm7b TO uapp01m7cicscprodcmm;
GRANT USAGE ON SCHEMA m7cicscprodm7b TO uapp01m7cicscprodcmm;{noformat}
Password from [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/icsc/prod/db/m7cicscprodcmm] field _password_","22/Jan/21 16:47;op211;Rehearsal test is done. Almost all steps from the database migration and flyway migration have been tested in ATE5 environment. The outcome was used to create the PROD playbook: [https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/2021-01+ICSC+PROD+6.8]

 ",,,,,,,,,,,,,,,,,,,,
Change alerting for Database free space level,M7P-7200,102461,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,cv179,wn626,wn626,03/Nov/20 15:05,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"Currently, all environments/customers have the following alerting level: 85% warning level; Critical level 95%

The agreement is to change all PROD environments to have: 60% warning level; Critical level at 75%

 

Monitoring/alerting is setup all for one now. All environments/customers need to get the new customized levels after the implementation.",,cv179,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,26006400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyob3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102461,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/20 09:00;cv179;Peter received a response with a possible solution to have different levels for the databases. It will be implemented and tested as soon as we have the disk extensions.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Include order data in hanging orders in pool alert,M7P-7183,102373,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,oy574,oy574,02/Nov/20 11:27,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"Currently, the scheduled check for inconsistent pool state ([https://englobjci1.deutsche-boerse.de/blue/organizations/jenkins/Energy-Operations%2FScheduled-tasks%2FM7-ELTS-hanging_orders_in_pools_check/activity)] is only reporting the amount of rows. The first thing we do in case we get the alert is run a select to get the ids, as well as other additional data, e.g.:
{code:java}
select o.order_id, o.external_id, o.mod_type_code, o.action, o.parent_id, o.external_revision, o.version, o.last_update_time, c.contract_id, c.inactive from CX_210_CONTRACT c join CX_100_ORDER o on c.contract_id = o.contract_id where c.inactive = true and o.mod_type_code <> 'IACT';{code}
Please, include the following fields to the console output:
 * CX_100_ORDER
 ** order_id
 ** external_id
 ** mod_type_code
 ** action
 ** contract_id
 ** version
 ** external_revision
 ** last_update_time",,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,27475200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzymb3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102373,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HUPX PROD - 6.10 (rehersal) production installation test,M7P-7182,102371,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,rehapav,rehapav,02/Nov/20 11:19,30/Mar/21 17:03,16/Sep/21 14:11,11/Nov/20 17:33,,6.11.178,6.11.91,7tops_sprint105,,Database,,,30/Oct/20 00:00,7tops_comm,M,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.10 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.9 (see linked item)
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ELTS PROD data snapshot

*Preparation*
 * *get dump from HUPX PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.10

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.9.150
 * load dump into system test environment
 * deploy 6.10.246 software
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.10 software were successfully exectued
 * measure migration timeline
 * *!!! do not start the environment !!!*

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions

 ",,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Rehersal test for HUPX PROD done. new core version deployed db migrated (with the same result as with XRPM test), cleanup scripts run, no issues found",,,,,,,,,,,,,,,,,,,,,,,,26611200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyr67:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 105,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102371,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/Nov/20 15:40;pd122;prod bd (core) exported:
{code:java}
$ /usr/pgsql-11/bin/pg_dump -p 20008 -d m7thupxprodm7b -n m7thupxprodm7b | sed 's/m7thupxprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz{code}","11/Nov/20 16:15;pd122;SYT2 6.9.150 deployed (core only): https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/10178/console","11/Nov/20 16:20;pd122;dropping SYT2 core db:

 
{code:java}
$ /usr/pgsql-11/bin/psql -p 26004
psql (11.5)
Type ""help"" for help.
postgres=# \l
 List of databases
 Name           | Owner          | Encoding | Collate     | Ctype       | Access privileges
----------------+----------------+----------+-------------+-------------+-----------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
postgres=# DROP DATABASE m7tshrdsyt2m7b;
DROP DATABASE
postgres=# CREATE DATABASE m7tshrdsyt2m7b WITH OWNER m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER DATABASE m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
{code}
 ","11/Nov/20 17:08;pd122;db imported:
{code:java}
$ zcat /tmp/m7tshrdsyt2m7b.sql.gz | /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b{code}","11/Nov/20 17:11;pd122;production data masked:
{code:java}
postgres=# \c m7tshrdsyt2m7b;
You are now connected to database ""m7tshrdsyt2m7b"" as user ""postgres"".
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1='',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 63
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number = '';
UPDATE 218
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 2{code}","11/Nov/20 17:20;pd122;cor 6.10.176 deployed: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/10180/console","11/Nov/20 17:31;pd122;cleanup scripts tested (no issue found), all completed rather quickly:
{code:java}
[pd122@m7testpdb1 ~]$ ls -l /tmp/cleanup/
total 44
-rw-r--r-- 1 pd122 users 931 Nov 11 17:24 R__002_cleanup_messages_history.sql
-rw-r--r-- 1 pd122 users 1044 Nov 11 17:24 R__003_cleanup_remote_public_trade_history.sql
-rw-r--r-- 1 pd122 users 1214 Nov 11 17:24 R__004_cleanup_contract_delivery_area_state_history.sql
-rw-r--r-- 1 pd122 users 932 Nov 11 17:24 R__005_cleanup_contract_history.sql
-rw-r--r-- 1 pd122 users 1077 Nov 11 17:24 R__006_cleanup_contract_closing_price_history.sql
-rw-r--r-- 1 pd122 users 840 Nov 11 17:24 R__007_cleanup_session_history.sql
-rw-r--r-- 1 pd122 users 796 Nov 11 17:24 R__008_cleanup_revision_index.sql
-rw-r--r-- 1 pd122 users 1111 Nov 11 17:24 R__009_cleanup_order_history.sql
-rw-r--r-- 1 pd122 users 912 Nov 11 17:24 R__010_cleanup_limit_history.sql
-rw-r--r-- 1 pd122 users 946 Nov 11 17:24 R__011_cleanup_settlement_history.sql
-rw-r--r-- 1 pd122 users 1575 Nov 11 17:24 R__013_cleanup_trade_history.sql{code}",,,,,,,,,,,,,,,,,,,,,
BSP PROD - 6.10 (rehersal) production installation test,M7P-7181,102370,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,rehapav,rehapav,02/Nov/20 11:19,18/Nov/20 10:40,16/Sep/21 14:11,12/Nov/20 16:19,,6.11.91,7tops_sprint105,,,cor,,,30/Oct/20 00:00,7tops_comm,M,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.10 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.9 (see linked item)
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ELTS PROD data snapshot

*Preparation*
 * *get dump from BSP PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.10

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.9.150
 * load dump into system test environment
 * deploy 6.10.246 software
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.10 software were successfully exectued
 * measure migration timeline
 * *!!! do not start the environment !!!*

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions

 ",,iu252,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Rehersal test for XSOP PROD done.,,,,,,,,,,,,,,,,,,,,,,,,26524800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyr5z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 105,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102370,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Nov/20 11:19;iu252;creating prod DB dump:

{noformat}
-bash-4.2$ hostname
m7prodpdb1
-bash-4.2$ /usr/pgsql-11/bin/psql -p 20012
psql (11.5)
Type ""help"" for help.

postgres=# \l
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7txsopprodm7b | m7txsopprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodm7b                   +
                |                |          |             |             | m7txsopprodm7b=CTc/m7txsopprodm7b    +
                |                |          |             |             | uapp01m7txsopprodm7b=c/m7txsopprodm7b+
                |                |          |             |             | uapp01m7txsopprodrep=c/m7txsopprodm7b+
                |                |          |             |             | udev01m7txsopprodm7b=c/m7txsopprodm7b+
                |                |          |             |             | ro_users=c/m7txsopprodm7b            +
                |                |          |             |             | pgwatch2=c/m7txsopprodm7b
 m7txsopprodmtt | m7txsopprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodmtt                   +
                |                |          |             |             | m7txsopprodmtt=CTc/m7txsopprodmtt    +
                |                |          |             |             | uapp01m7txsopprodmtt=c/m7txsopprodmtt+
                |                |          |             |             | udev01m7txsopprodmtt=c/m7txsopprodmtt+
                |                |          |             |             | pgwatch2=c/m7txsopprodmtt
 m7txsopprodrep | m7txsopprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodrep                   +
                |                |          |             |             | m7txsopprodrep=CTc/m7txsopprodrep    +
                |                |          |             |             | uapp01m7txsopprodrep=c/m7txsopprodrep+
                |                |          |             |             | udev01m7txsopprodrep=c/m7txsopprodrep+
                |                |          |             |             | pgwatch2=c/m7txsopprodrep            +
                |                |          |             |             | ro_users=c/m7txsopprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)

postgres=#
{noformat}


{noformat}
-bash-4.2$ /usr/pgsql-11/bin/pg_dump -p 20012 -d m7txsopprodm7b -n m7txsopprodm7b | sed 's/m7txsopprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz
{noformat}
","12/Nov/20 11:29;iu252;dumps copied over to the test server:

{noformat}
-bash-4.2$ scp /tmp/*.gz iu252@m7testpdb1:/tmp/
iu252@m7testpdb1's password:
m7tshrdsyt2m7b.sql.gz                                                                                     100% 1949MB 114.6MB/s   00:17
-bash-4.2$
{noformat}
","12/Nov/20 12:28;iu252; restore the dumps to syt2.
before the restoration:

{noformat}
[root@m7testpdb1 tmp]# patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 | Leader | running |  4 |         0 |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
[root@m7testpdb1 tmp]#

-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004
psql (11.5)
Type ""help"" for help.

postgres=# \l+
                                                                         List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |   Access privileges   |  Size   | Tablespace |                Desc
ription
----------------+----------------+----------+-------------+-------------+-----------------------+---------+------------+--------------------
------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 2232 MB | pg_default |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7841 kB | pg_default |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 8565 kB | pg_default |
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default | default administrat
ive connection database
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7817 kB | pg_default | unmodifiable empty
database
                |                |          |             |             | postgres=CTc/postgres |         |            |
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7957 kB | pg_default | default template fo
r new databases
                |                |          |             |             | postgres=CTc/postgres |         |            |
(6 rows)

postgres=#
{noformat}
","12/Nov/20 12:31;iu252;stopping environment: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_custom/959/console","12/Nov/20 12:34;iu252;preparing for production dump restore on SYT2:


{noformat}
postgres=# DROP DATABASE m7tshrdsyt2m7b;
DROP DATABASE
postgres=# CREATE DATABASE m7tshrdsyt2m7b WITH OWNER m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER DATABASE m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
postgres=#
{noformat}
","12/Nov/20 12:38;iu252;db imported:

{noformat}
zcat /tmp/m7tshrdsyt2m7b.sql.gz | /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b
{noformat}
","12/Nov/20 15:34;iu252;PROD data masked:

{noformat}
postgres=# \c m7tshrdsyt2m7b
You are now connected to database ""m7tshrdsyt2m7b"" as user ""postgres"".
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1='',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 48
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number = '';
UPDATE 231
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 1
m7tshrdsyt2m7b=#
{noformat}
","12/Nov/20 15:42;iu252;run deployment 6.10.246:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/658/console","12/Nov/20 15:51;iu252;tested cleanup scripts:

{noformat}
[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.inventory-sql/m7coredb/xsop/prod/cleanup]$ ll
total 44
-rw-r--r-- 1 iu252 users  931 Nov 12 15:48 R__002_cleanup_messages_history.sql
-rw-r--r-- 1 iu252 users 1044 Nov 12 15:48 R__003_cleanup_remote_public_trade_history.sql
-rw-r--r-- 1 iu252 users 1214 Nov 12 15:48 R__004_cleanup_contract_delivery_area_state_history.sql
-rw-r--r-- 1 iu252 users  932 Nov 12 15:48 R__005_cleanup_contract_history.sql
-rw-r--r-- 1 iu252 users 1077 Nov 12 15:48 R__006_cleanup_contract_closing_price_history.sql
-rw-r--r-- 1 iu252 users  840 Nov 12 15:48 R__007_cleanup_session_history.sql
-rw-r--r-- 1 iu252 users  796 Nov 12 15:48 R__008_cleanup_revision_index.sql
-rw-r--r-- 1 iu252 users 1111 Nov 12 15:48 R__009_cleanup_order_history.sql
-rw-r--r-- 1 iu252 users  912 Nov 12 15:48 R__010_cleanup_limit_history.sql
-rw-r--r-- 1 iu252 users  946 Nov 12 15:48 R__011_cleanup_settlement_history.sql
-rw-r--r-- 1 iu252 users 1575 Nov 12 15:48 R__013_cleanup_trade_history.sql
[iu252@enprodauto1 {master L | ✔} ~/git/energy.automation.inventory-sql/m7coredb/xsop/prod/cleanup]$
{noformat}
","12/Nov/20 15:57;iu252;*{color:red}2 sec{color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__002_cleanup_messages_history.sql -e
ALTER TABLE cx_151_messages_history RENAME TO cx_151_messages_history_old;
ALTER TABLE
CREATE TABLE cx_151_messages_history
(like cx_151_messages_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_151_messages_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_151_messages_history
  SELECT * FROM cx_151_messages_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 29526
TRUNCATE TABLE cx_151_messages_history_old;
TRUNCATE TABLE
DROP TABLE cx_151_messages_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_151_messages_history
    ADD CONSTRAINT cx_151_messages_history_pkey PRIMARY KEY (message_id, rev);
ALTER TABLE
-bash-4.2$ 
{noformat}
","12/Nov/20 15:57;iu252;*{color:red}45 sec{color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__003_cleanup_remote_public_trade_history.sql -e
ALTER TABLE cx_120_remote_public_trade_history RENAME TO cx_120_remote_public_trade_history_old;
ALTER TABLE
CREATE TABLE cx_120_remote_public_trade_history
(like cx_120_remote_public_trade_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_120_remote_public_trade_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_120_remote_public_trade_history
  SELECT * FROM cx_120_remote_public_trade_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 14925098
TRUNCATE TABLE cx_120_remote_public_trade_history_old;
TRUNCATE TABLE
DROP TABLE cx_120_remote_public_trade_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_120_remote_public_trade_history
    ADD CONSTRAINT cx_120_remote_public_trade_history_pkey PRIMARY KEY (id, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 15:58;iu252;*{color:red}2 sec{color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__004_cleanup_contract_delivery_area_state_history.sql -e
ALTER TABLE cx_441_contract_delivery_area_state_history RENAME TO cx_441_contract_delivery_area_state_history_old;
ALTER TABLE
CREATE TABLE cx_441_contract_delivery_area_state_history
(like cx_441_contract_delivery_area_state_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_441_contract_delivery_area_state_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_441_contract_delivery_area_state_history
  SELECT * FROM cx_441_contract_delivery_area_state_history_old WHERE contract_id in (SELECT contract_id FROM cx_211_contract_history WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days');
INSERT 0 112009
TRUNCATE TABLE cx_441_contract_delivery_area_state_history_old;
TRUNCATE TABLE
DROP TABLE cx_441_contract_delivery_area_state_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_441_contract_delivery_area_state_history
    ADD CONSTRAINT cx_441_contract_delivery_area_state_history_pkey PRIMARY KEY (id, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 15:59;iu252;*{color:red}2 sec {color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__005_cleanup_contract_history.sql -e
ALTER TABLE cx_211_contract_history RENAME TO cx_211_contract_history_old;
ALTER TABLE
CREATE TABLE cx_211_contract_history
(like cx_211_contract_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_211_contract_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_211_contract_history
  SELECT * FROM cx_211_contract_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 227151
TRUNCATE TABLE cx_211_contract_history_old;
TRUNCATE TABLE
DROP TABLE cx_211_contract_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_211_contract_history
    ADD CONSTRAINT cx_211_contract_history_pkey PRIMARY KEY (contract_id, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 16:00;iu252;*{color:red}1 sec{color}*


{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__006_cleanup_contract_closing_price_history.sql -e
ALTER TABLE cx_215_contract_closing_price_history RENAME TO cx_215_contract_closing_price_history_old;
ALTER TABLE
CREATE TABLE cx_215_contract_closing_price_history
(like cx_215_contract_closing_price_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_215_contract_closing_price_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_215_contract_closing_price_history
  SELECT * FROM cx_215_contract_closing_price_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 456
TRUNCATE TABLE cx_215_contract_closing_price_history_old;
TRUNCATE TABLE
DROP TABLE cx_215_contract_closing_price_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_215_contract_closing_price_history
    ADD CONSTRAINT cx_215_contract_closing_price_history_pkey PRIMARY KEY (id, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 16:01;iu252;no output ...
there are only comments in the script.
{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__007_cleanup_session_history.sql -e
{noformat}
","12/Nov/20 16:02;iu252;{color:red}*1 sec*{color}
{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__008_cleanup_revision_index.sql -e
ALTER TABLE m7_999_revision_index RENAME TO m7_999_revision_index_old;
ALTER TABLE
CREATE TABLE m7_999_revision_index
(like m7_999_revision_index_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
INSERT INTO m7_999_revision_index
  SELECT * FROM m7_999_revision_index_old WHERE index = (SELECT MAX (index) from m7_999_revision_index_old);
INSERT 0 1
TRUNCATE TABLE m7_999_revision_index_old;
TRUNCATE TABLE
DROP TABLE m7_999_revision_index_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY m7_999_revision_index
    ADD CONSTRAINT m7_999_revision_index_pkey PRIMARY KEY (index);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 16:02;iu252;*{color:red}2 sec{color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__009_cleanup_order_history.sql -e
ALTER TABLE cx_101_order_history RENAME TO cx_101_order_history_old;
ALTER TABLE
CREATE TABLE cx_101_order_history
(like cx_101_order_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_101_order_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_101_order_history
  SELECT * FROM cx_101_order_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 146948
TRUNCATE TABLE cx_101_order_history_old;
TRUNCATE TABLE
DROP TABLE cx_101_order_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_101_order_history
    ADD CONSTRAINT cx_101_order_history_pkey PRIMARY KEY (order_id, rev);
ALTER TABLE
CREATE INDEX idx101_001 ON cx_101_order_history USING btree (revtype, last_update_time, balancing_group_eic, order_type_code, action);
CREATE INDEX
CREATE INDEX idx101_002 ON cx_101_order_history USING btree (last_update_time);
CREATE INDEX
-bash-4.2$
{noformat}
","12/Nov/20 16:03;iu252;*{color:red}1sec{color}*


{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__010_cleanup_limit_history.sql -e
ALTER TABLE cx_262_limit_history RENAME TO cx_262_limit_history_old;
ALTER TABLE
CREATE TABLE cx_262_limit_history
(like cx_262_limit_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_262_limit_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_262_limit_history
  SELECT * FROM cx_262_limit_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 92330
TRUNCATE TABLE cx_262_limit_history_old;
TRUNCATE TABLE
DROP TABLE cx_262_limit_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_262_limit_history
    ADD CONSTRAINT cx_262_limit_history_pkey PRIMARY KEY (member_id, currency_code, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 16:04;iu252;*{color:red}1sec{color}*

{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__011_cleanup_settlement_history.sql -e
ALTER TABLE cx_119_settlement_history RENAME TO cx_119_settlement_history_old;
ALTER TABLE
CREATE TABLE cx_119_settlement_history
(like cx_119_settlement_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_119_settlement_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_119_settlement_history
  SELECT * FROM cx_119_settlement_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 87743
TRUNCATE TABLE cx_119_settlement_history_old;
TRUNCATE TABLE
DROP TABLE cx_119_settlement_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_119_settlement_history
    ADD CONSTRAINT cx_119_settlement_history_pkey PRIMARY KEY (id, rev);
ALTER TABLE
-bash-4.2$
{noformat}
","12/Nov/20 16:05;iu252;*{color:red}1sec{color}*
{noformat}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f /tmp/R__013_cleanup_trade_history.sql -e
ALTER TABLE cx_111_trade_history RENAME TO cx_111_trade_history_old;
ALTER TABLE
CREATE TABLE cx_111_trade_history
(like cx_111_trade_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
CREATE TABLE
ALTER TABLE cx_111_trade_history ALTER COLUMN rev TYPE int8;
ALTER TABLE
INSERT INTO cx_111_trade_history
  SELECT * FROM cx_111_trade_history_old WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days';
INSERT 0 87743
TRUNCATE TABLE cx_111_trade_history_old;
TRUNCATE TABLE
DROP TABLE cx_111_trade_history_old;
DROP TABLE
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_111_trade_history
    ADD CONSTRAINT cx_111_trade_history_pkey PRIMARY KEY (trade_id, rev);
ALTER TABLE
CREATE INDEX idx111_001 ON cx_111_trade_history USING btree (last_update_time);
CREATE INDEX
CREATE INDEX idx111_002 ON cx_111_trade_history USING btree (contract_id, order_id_buy, order_id_sell ,action);
CREATE INDEX
ALTER TABLE ONLY cx_111_trade_history
        ADD CONSTRAINT fk_esx7a3o7hndxfkx55r8f2flt2 FOREIGN KEY (bg_eic_buy) REFERENCES cx_270_balancing_group(balancing_group_eic);
ALTER TABLE
ALTER TABLE ONLY cx_111_trade_history
        ADD CONSTRAINT fk_qukjgc0375hjajrlcomao4nk9 FOREIGN KEY (bg_eic_sell) REFERENCES cx_270_balancing_group(balancing_group_eic);
ALTER TABLE
ALTER TABLE ONLY cx_111_trade_history
        ADD CONSTRAINT fk_byearfw2rvlxvy3gsn7lqh347 FOREIGN KEY (clearing_house_code) REFERENCES cx_275_clearing_house(code);
ALTER TABLE
-bash-4.2$
{noformat}
",,,,,,,,
TGE PROD - 6.10 (rehersal) production installation test,M7P-7180,102369,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,rehapav,rehapav,02/Nov/20 11:18,30/Nov/20 08:46,16/Sep/21 14:11,,,,,,,,,,30/Oct/20 00:00,7tops_comm,M,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.10 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.9 (see linked item)
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ELTS PROD data snapshot

*Preparation*
 * *get dump from TGE PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.10

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.9.150
 * load dump into system test environment
 * deploy 6.10.246 software
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.10 software were successfully exectued
 * measure migration timeline
 * *!!! do not start the environment !!!*

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions

 ",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,27475200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzym8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102369,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OPCOM PROD - 6.10 (rehersal) production installation test,M7P-7179,102368,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,rehapav,rehapav,02/Nov/20 11:14,27/Jan/21 09:09,16/Sep/21 14:11,04/Nov/20 17:26,,6.11.83,7tops_sprint105,,,Database,,,04/Nov/20 00:00,7tops_comm,M,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.10 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.9 (see linked item)
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  XRPM PROD data snapshot, do not start application

*Preparation*
 * *get dump from OPCOM PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.10

*Steps*
 * agree which systemtest environment to be used = systemtest2
 * install on systemtest environment 6.9.150
 * load dump into system test environment
 * deploy 6.10.239 software
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.10 software were successfully exectued
 * measure migration timeline
 * *!!! do not start the environment !!!*

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions

 ",,pd122,rehapav,,,,,,,,,,,,,,,,SERVICE-7888,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Opcom prod rehersal (6.10) test done,,,,,,,,OPCOM,,,,,,,,,,,,,,,,27216000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzympb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 104,7tops Sprint 105,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":102368,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"04/Nov/20 13:39;pd122;creating prod DB dump:

 
{code:java}
-bash-4.2$ hostname
m7prodpdb1
-bash-4.2$ /usr/pgsql-11/bin/psql -p 20014
psql (11.5)
Type ""help"" for help.
postgres=# \l
 List of databases
 Name           |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7txrpmprodm7b | m7txrpmprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodm7b +
                |                |          |             |             | m7txrpmprodm7b=CTc/m7txrpmprodm7b +
                |                |          |             |             | uapp01m7txrpmprodm7b=c/m7txrpmprodm7b+
                |                |          |             |             | uapp01m7txrpmprodrep=c/m7txrpmprodm7b+
                |                |          |             |             | udev01m7txrpmprodm7b=c/m7txrpmprodm7b+
                |                |          |             |             | ro_users=c/m7txrpmprodm7b +
                |                |          |             |             | pgwatch2=c/m7txrpmprodm7b
 m7txrpmprodmtt | m7txrpmprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodmtt +
                |                |          |             |             | m7txrpmprodmtt=CTc/m7txrpmprodmtt +
                |                |          |             |             | uapp01m7txrpmprodmtt=c/m7txrpmprodmtt+
                |                |          |             |             | udev01m7txrpmprodmtt=c/m7txrpmprodmtt+
                |                |          |             |             | pgwatch2=c/m7txrpmprodmtt
 m7txrpmprodrep | m7txrpmprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodrep +
                |                |          |             |             | m7txrpmprodrep=CTc/m7txrpmprodrep +
                |                |          |             |             | uapp01m7txrpmprodrep=c/m7txrpmprodrep+
                |                |          |             |             | udev01m7txrpmprodrep=c/m7txrpmprodrep+
                |                |          |             |             | pgwatch2=c/m7txrpmprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres +
                |                |          |             |             | postgres=CTc/postgres +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
{code}
{code:java}
-bash-4.2$ /usr/pgsql-11/bin/pg_dump -p 20014 -d m7txrpmprodm7b -n m7txrpmprodm7b | sed 's/m7txrpmprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump -p 20014 -d m7txrpmprodmtt -n m7txrpmprodmtt | sed 's/m7txrpmprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump -p 20014 -d m7txrpmprodrep -n m7txrpmprodrep | sed 's/m7txrpmprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz{code}
 ","04/Nov/20 14:24;pd122;dumps copied over to the test server:
{code:java}
-bash-4.2$ scp /tmp/*.gz pd122@m7testpdb1:/tmp/
pd122@m7testpdb1's password:
m7tshrdsyt2m7b.sql.gz 100% 1332MB 110.9MB/s 00:12
m7tshrdsyt2mtt.sql.gz 100%  589     1.1MB/s 00:00
m7tshrdsyt2rep.sql.gz 100% 3477     5.2MB/s 00:00{code}","04/Nov/20 14:40;pd122;6.9.150 (current XRPm PROD version) deployed to SYT2: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/639/console","04/Nov/20 15:32;pd122;preparing for production dump restore on SYT2:

 
{code:java}
-bash-4.2$ hostname
m7testpdb1
-bash-4.2$ patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |        Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 | Leader | running | 2  | 0         |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 |        | running | 2  | 0.        |
+------------------+------------+---------------------+--------+---------+----+-----------+
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004
psql (11.5)
Type ""help"" for help.
postgres=# \l
 List of databases
 Name | Owner | Encoding | Collate | Ctype | Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2m7b +
 | | | | | m7tshrdsyt2m7b=CTc/m7tshrdsyt2m7b +
 | | | | | uapp01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b+
 | | | | | uapp01m7tshrdsyt2rep=c/m7tshrdsyt2m7b+
 | | | | | udev01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2mtt +
 | | | | | m7tshrdsyt2mtt=CTc/m7tshrdsyt2mtt +
 | | | | | uapp01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt+
 | | | | | udev01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2rep +
 | | | | | m7tshrdsyt2rep=CTc/m7tshrdsyt2rep +
 | | | | | uapp01m7tshrdsyt2rep=c/m7tshrdsyt2rep+
 | | | | | udev01m7tshrdsyt2rep=c/m7tshrdsyt2rep
 postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
 | | | | | postgres=CTc/postgres
 template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +
 | | | | | postgres=CTc/postgres
(6 rows)
postgres=# DROP DATABASE m7tshrdsyt2m7b;
DROP DATABASE
postgres=# DROP DATABASE m7tshrdsyt2mtt;
DROP DATABASE
postgres=# DROP DATABASE m7tshrdsyt2rep;
DROP DATABASE
postgres=# CREATE DATABASE m7tshrdsyt2rep WITH OWNER m7tshrdsyt2rep;
CREATE DATABASE
postgres=# ALTER DATABASE m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;
ALTER DATABASE
postgres=# CREATE DATABASE m7tshrdsyt2m7b WITH OWNER m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER DATABASE m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
postgres=# CREATE DATABASE m7tshrdsyt2mtt WITH OWNER m7tshrdsyt2mtt;
CREATE DATABASE
postgres=# ALTER DATABASE m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;
ALTER DATABASE
{code}
 ","04/Nov/20 15:41;pd122;SYT2 DB volumes are too small to import XRPm PROD DB:
{code:java}
pd122@m7prodpdb1 ~]$ df -h | grep xrpm
/dev/mapper/datavg-lv_pgsql_m7txrpmprodasync_log      5.0G  33M 5.0G  1% /var/lib/pgsql_m7txrpmprodasync/log
/dev/mapper/datavg-lv_pgsql_m7txrpmprodasync_data    20G    18G 2.9G 86% /var/lib/pgsql_m7txrpmprodasync/data
/dev/mapper/datavg-lv_pgsql_m7txrpmprodasync_backup   5.0G 129M 4.9G  3% /var/lib/pgsql_m7txrpmprodasync/backup
/dev/mapper/datavg-lv_journal_m7xrpmprodm7b           5.0G 819M 4.2G 17% /opt/gluster_volumes/journal/m7xrpmprodm7b
 
{code}
but

 
{code:java}
[pd122@m7testpdb1 ~]$ df -h | grep syt2async
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_log     5.0G  90M 5.0G  2% /var/lib/pgsql_m7tshrdsyt2async/log
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_backup  5.0G 2.8G 2.3G  56% /var/lib/pgsql_m7tshrdsyt2async/backup
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_data    5.0G 5.0G 2.1M 100% /var/lib/pgsql_m7tshrdsyt2async/data
 
{code}
 ","04/Nov/20 15:44;pd122;data volume for SYT2 extended:
{code:java}
[pd122@m7testpdb1 ~]$ df -h | grep syt2async
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_log     5.0G  90M  5.0G  2% /var/lib/pgsql_m7tshrdsyt2async/log
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_backup  5.0G 2.8G  2.3G 56% /var/lib/pgsql_m7tshrdsyt2async/backup
/dev/mapper/datavg-lv_pgsql_m7tshrdsyt2async_data   20G   5.0G 16G   25% /var/lib/pgsql_m7tshrdsyt2async/data{code}","04/Nov/20 16:03;pd122;PROD data successfully imported via:
{code:java}
-bash-4.2$ for i in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${i}.sql.gz | /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2${i}; done{code}","04/Nov/20 16:11;pd122;PROD data masked:
{code:java}
postgres=# \c m7tshrdsyt2m7b;
You are now connected to database ""m7tshrdsyt2m7b"" as user ""postgres"".
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1='',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 192
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number = '';
UPDATE 438
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 0{code}","04/Nov/20 16:15;pd122;attempt to run 6.10.239 deployment has failed: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_full/642/console","04/Nov/20 16:17;pd122;""Migrate db"" task failed:

 
{code:java}
RROR: Validate failed: 
Migration checksum mismatch for migration version 004
-> Applied to database : -1162660476
-> Resolved locally : -1317865993 
{code}
perhaps DB import issue?","04/Nov/20 16:53;pd122;issue caused by a different app context for reportin engine app/db, core migration result:

 
{code:java}
TASK [m7tcor : always show flyway output] **************************************
ok: [m7t-shrd-syt2-cor1 -> localhost] => {}
MSG:
Flyway Community Edition 6.0.4 by Redgate
WARNING: Skipping filesystem location:/home/jenkins/workspace/Energy-Operations/CD-Pipeline/M7T_deploy_full/playbooks/envsql/repo/m7coredb/shrd/syt2 (not found)
Database: jdbc:postgresql://m7testpdb1.deutsche-boerse.de:26004,m7testpdb2.deutsche-boerse.de:26004/m7tshrdsyt2m7b (PostgreSQL 11.5)
Successfully validated 2 migrations (execution time 00:00.014s)
Current version of schema ""m7tshrdsyt2m7b"": 6.9.0.001
WARNING: outOfOrder mode is active. Migration of schema ""m7tshrdsyt2m7b"" may not be reproducible.
WARNING: Schema ""m7tshrdsyt2m7b"" has a version (6.9.0.001) that is newer than the latest available migration (1) !
Schema ""m7tshrdsyt2m7b"" is up to date. No migration necessary.
{code}
 ","04/Nov/20 17:13;pd122;tested cleanup scripts:
{code:java}
[pd122@enprodauto1 {master L | ✔} ~/Sources/energy.automation.inventory-sql/m7coredb/xrpm/prod/cleanup]$ ls -l
total 48
-rw-r--r-- 1 pd122 users 931 Nov 4 16:45 R__002_cleanup_messages_history.sql
-rw-r--r-- 1 pd122 users 1044 Nov 4 16:45 R__003_cleanup_remote_public_trade_history.sql
-rw-r--r-- 1 pd122 users 1214 Nov 4 16:45 R__004_cleanup_contract_delivery_area_state_history.sql
-rw-r--r-- 1 pd122 users 932 Nov 4 16:45 R__005_cleanup_contract_history.sql
-rw-r--r-- 1 pd122 users 1077 Nov 4 16:45 R__006_cleanup_contract_closing_price_history.sql
-rw-r--r-- 1 pd122 users 840 Nov 4 16:45 R__007_cleanup_session_history.sql
-rw-r--r-- 1 pd122 users 796 Nov 4 16:45 R__008_cleanup_revision_index.sql
-rw-r--r-- 1 pd122 users 1111 Nov 4 16:45 R__009_cleanup_order_history.sql
-rw-r--r-- 1 pd122 users 912 Nov 4 16:45 R__010_cleanup_limit_history.sql
-rw-r--r-- 1 pd122 users 946 Nov 4 16:45 R__011_cleanup_settlement_history.sql
-rw-r--r-- 1 pd122 users 1019 Nov 4 16:45 R__012_cleanup_trade_flow_history.sql
-rw-r--r-- 1 pd122 users 1575 Nov 4 16:45 R__013_cleanup_trade_history.sql{code}","04/Nov/20 17:14;pd122;Errors when running R__012_cleanup_trade_flow_history.sql:
{code:java}
-bash-4.2$ /usr/pgsql-11/bin/psql -p 26004 -d m7tshrdsyt2m7b -f R__012_cleanup_trade_flow_history.sql -e
ALTER TABLE cx_673_trade_flow_history RENAME TO cx_673_trade_flow_history_old;
psql:R__012_cleanup_trade_flow_history.sql:4: ERROR: relation ""cx_673_trade_flow_history"" does not exist
CREATE TABLE cx_673_trade_flow_history
(like cx_673_trade_flow_history_old)
WITH (autovacuum_enabled=true, toast.autovacuum_enabled=true);
psql:R__012_cleanup_trade_flow_history.sql:9: ERROR: relation ""cx_673_trade_flow_history_old"" does not exist
LINE 2: (like cx_673_trade_flow_history_old)
 ^
ALTER TABLE cx_673_trade_flow_history ALTER COLUMN rev TYPE int8;
psql:R__012_cleanup_trade_flow_history.sql:12: ERROR: relation ""cx_673_trade_flow_history"" does not exist
INSERT INTO cx_673_trade_flow_history
 SELECT * FROM cx_673_trade_flow_history_old WHERE trade_id IN
 (SELECT trade_id FROM cx_111_trade_history WHERE last_update_time > CURRENT_DATE - INTERVAL '60 days');
psql:R__012_cleanup_trade_flow_history.sql:17: ERROR: relation ""cx_673_trade_flow_history"" does not exist
LINE 1: INSERT INTO cx_673_trade_flow_history
 ^
TRUNCATE TABLE cx_673_trade_flow_history_old;
psql:R__012_cleanup_trade_flow_history.sql:20: ERROR: relation ""cx_673_trade_flow_history_old"" does not exist
DROP TABLE cx_673_trade_flow_history_old;
psql:R__012_cleanup_trade_flow_history.sql:21: ERROR: table ""cx_673_trade_flow_history_old"" does not exist
SET maintenance_work_mem = '1GB';
SET
ALTER TABLE ONLY cx_673_trade_flow_history
 ADD CONSTRAINT cx_673_trade_flow_history_pkey PRIMARY KEY (trade_flow_id, rev);
psql:R__012_cleanup_trade_flow_history.sql:27: ERROR: relation ""cx_673_trade_flow_history"" does not exist{code}","04/Nov/20 17:15;pd122;all other scripts executed without errors and in a few seconds","04/Nov/20 17:19;pd122;[~pw231], [~jv861], [~rehapav] please note there were issues when executing energy.automation.inventory-sql.git:m7coredb/xrpm/prod/cleanup/R__012_cleanup_trade_flow_history.sql on XRPM PROD DB:
{code:java}
ERROR: relation ""cx_673_trade_flow_history"" does not exist{code}",,,,,,,,,,,,,
Increase RAM on host m7shrdintestk1 to 4G,M7P-7150,102194,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,nn481,nn481,27/Oct/20 13:37,04/Nov/20 13:01,16/Sep/21 14:11,27/Oct/20 18:24,,6.11.66,7tops_sprint104,,,,,,,7tops,,,,,,,"We would like to increase RAM on m7shrdintestk1 to 4G.

Downtime is possible anytime.

Stalker needs more memory since Core/Enq is sending large messages (25MB) on syt1, several in row.",,iu252,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Memory increased on m7shrdintestk1,,,,,,,,,,,,,,,,,,,,,,,,27907200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzymp3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":102194,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/20 13:52;iu252;Created ticket for SYSENG: https://jira.deutsche-boerse.com/browse/SYSENGEXT-283.
Waiting for implementation.","27/Oct/20 18:23;iu252;System ingeneers increased memory:


{noformat}
[zq813@m7shrdintestk1 ~]$ cat /proc/meminfo
MemTotal: 3861508 kB
MemFree: 3154636 kB
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,
DB FS issue with growing WAL - Elts CTPB - Epex ASIM,M7P-7144,102144,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cs687,fj021,fj021,26/Oct/20 16:28,13/Jan/21 11:31,16/Sep/21 14:11,12/Jan/21 15:57,,6.11.160,7tops_sprint108,,,Database,,,,M7PRODOPS,XL,,,,,,"h2. *Context*

Harvester can't run on ELTS CTPB and EPEX ASIM because of DB disk space.
When we started (twice) Harvester on ELTS CTPB, /data FS got full and DB got stuck (app crashed).
After further investigation it seems that the WAL were getting huge (on ELTS CTPB : actualData : ~3gb, Wal : ~3gb).

Both ELTS CTPB and EPEX ASIM have high disk space usage : 
 * EPEX ASIM is still 100% on /backup, and peaking at 96% on /data
 * ELTS CTPB /data after getting an extension of 20g went from 89% to 36% on 23.10.2020 and got up to 40% on 26.10.2020, so 4% in 3 days. This trend doesn't seem healthy.

h2. *Task*

We need to fix this situation. I think what needs to be done is : 
 * To extend FS of EPEX ASIM of both /backup and /data
 * To investigate why we have a rapid growth of WAL (even with no harvester running)

h2. *Additional information*

SYT1 should have the same set up as Production, and an amount of data/transactions equivalent to Production. 
Harvester has been running there without crashing for quite a while now. 
We don't see those big movement in disk space for this environment.

 ",,cs687,cv179,fj021,HO764,rehapav,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-7890,SERVICE-7891,SERVICE-7887,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"* deployed harvester on m7epexasimm7b1
* run harvester with first cleanup round
* waited until pg_wal dir was cleaned up and started harvester again 
all details can be find in the service ticket, refer last comment. ",,,,,,,,,,,,,,,,,,,,,,,,21254400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzvi4n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":102144,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/20 08:07;cv179;{quote}When we started (twice) Harvester on ELTS CTPB, /data FS got full and DB got stuck (app crashed).
...
To investigate why we have a rapid growth of WAL (even with no harvester running)
{quote}
 to be clarified: Does harvester worsen the WAL situation or not? 

There is on any database a natural growth and a disk space pattern (as long as the backup mechanism works). If harvester changes this pattern (even slightly), we need to find out in which way and prepare (especially smaller) environments for it.

Disk space extension only works to a certain limit - there was a capacity design and if we exceed it, we need to add storage capacity first which will take significant amount of time.

 

100% on backup all the time is a bad backup state and needs to be checked.","27/Oct/20 10:04;fj021;[~cv179]
 * Does harvester worsen the WAL situation : In theory it would have an impact (running deletes every minute on a table in which a trigger is inserting in there continuously). In practice : it did on ELTS CTPB, on first deployment of harvester there /data just spiked at 100% after 2minutes and DB got stuck there. We could see a huge spike in WAL rate : [16th PG Overview|https://grafana.energy.svc.dbgcloud.io/d/5qbhAxvmz/postgresql-overview?orgId=2&from=1602799200000&to=1602885599000&var-product=m7t&var-group=postgres&var-host=m7simupdb1%20-%20postgres%20-%20m7_elts_ctpb&var-client=elts&var-client_env=ctpb&var-dbname=m7t-elts-ctpb-pdb-async1_m7teltsctpbm7b] and the spike to 100% /data [16th System - Shared host|https://grafana.energy.svc.dbgcloud.io/d/R1V77tRGz/system-shared-hosts?orgId=2&from=1602799200000&to=1602885599000&fullscreen&panelId=6&var-datasource=influxdb_m7_shared_services&var-product=m7&var-host=m7simupdb1%20-%20postgres%20-%20shrd&var-client=shrd&var-client_env=shrd&var-group=postgres&var-interval=1m]
 * How does harvester impacts this ""pattern"" : Bigger question, why does it impacts only ELTS CTPB ? The other ""small environments"" (HUPX ASIM-CUTE-SIMU, XRPM LIPA-SIMU, XSOP ASIM) and ""big environments"" (SHRD SYT1) don't seem to display this dramatic pattern.
 * We agree that disk space extension is a band-aid on an open wound. Works for a while but it is not the end all be all.

 

So what is the next step ? Do we require some help for Cybertec on this ?","19/Nov/20 12:52;rehapav;Increasing priority to CRITICAL, this is a showstopper to deploy HARVESTER to any PROD environment.","07/Dec/20 11:13;HO764;Any news on this issue?","09/Dec/20 15:04;cv179;Syt1 also observed big disk movement - it's just less visible as the filesystems are much larger, so I wouldn't exclude it from being ""affected"".

Before harvester can be started on any customer facing environment, we depend on storage extension on db servers.","09/Dec/20 15:27;HO764;Are we sure that the disk increase will actually fix the problem that was on EPEX ASIM? If so, then let's move this issue to waiting, clearly stating that we're waiting for HW upgrade.","16/Dec/20 11:48;rehapav;{quote}ETA for the disks is 21 Dec 2020 (information from supplier).{quote}
 
see
https://jira.deutsche-boerse.com/browse/ADM-1439
 
 
track the delivery there and put pressure on Kaan/SysEng via this ticket:
https://jira.deutsche-boerse.com/browse/SYSENGINT-51","06/Jan/21 14:53;cs687;After our netbackup meeting yesterday, there is not much to report.
Currently they are in process of moving to new infrastructure to resolve the current netbackup issues. 
That means we are at the same level of risk as in 2020, that some backups could still fail, but we can support them with disabling some Env´s to keep down the load. 
In M7 we disabled the Systemtest1 which is also a huge database and not that important like SIMU/PROD Env´s. 

FYI: [~cv179], [~fj021], [~HO764]

Current situation for elts-ctpb/epex-asim  
{code:java}
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_data     25G  7.7G   18G  31% /var/lib/pgsql_m7teltsctpbasync/data
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_backup  5.0G  257M  4.8G   6% /var/lib/pgsql_m7teltsctpbasync/backup

177M    /var/lib/pgsql_m7teltsctpbasync/data/11/m7teltsctpbasync/pg_wal
{code}

{code:java}
/dev/mapper/datavg-lv_pgsql_m7tepexasimasync_data    200G  110G   91G  55% /var/lib/pgsql_m7tepexasimasync/data
/dev/mapper/datavg-lv_pgsql_m7tepexasimasync_backup   16G  7.9G  8.2G  50% /var/lib/pgsql_m7tepexasimasync/backup

289M    /var/lib/pgsql_m7tepexasimasync/data/11/m7tepexasimasync/pg_wal
{code}

*For the next steps i would suggest the following:*
After deactivation systemtest1 archiving i would observe the next days the backup behavior and then we could start on monday next week harvester and control it during the week?","11/Jan/21 13:41;cs687;Harvester is started for elts-ctpb today: 
{code:java}
2021-01-11T10:50:00.118Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 105.06058ms to delete 13342 records from CX_151_MESSAGES_HISTORY
2021-01-11T10:50:03.130Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 10.617715ms to delete 1777 records from CX_120_REMOTE_PUBLIC_TRADE_HISTORY
2021-01-11T10:50:07.622Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 1491.203289ms to delete 988178 records from CX_211_CONTRACT_HISTORY
2021-01-11T10:50:10.631Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 8.328806ms to delete 2100 records from CX_215_CONTRACT_CLOSING_PRICE_HISTORY
2021-01-11T10:50:13.672Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 40.906688ms to delete 25846 records from CX_101_ORDER_HISTORY
2021-01-11T10:50:16.685Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 12.742409ms to delete 7536 records from CX_262_LIMIT_HISTORY
2021-01-11T10:50:19.703Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 16.899795ms to delete 7882 records from CX_119_SETTLEMENT_HISTORY
2021-01-11T10:50:22.721Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 18.020082ms to delete 6759 records from CX_111_TRADE_HISTORY
2021-01-11T10:50:22.721Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - cleanup process finished in 22710 ms
2021-01-11T10:51:00.001Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - starting cleanup process
2021-01-11T10:51:00.019Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 17.788525ms to delete 0 records from CX_151_MESSAGES_HISTORY
2021-01-11T10:51:03.023Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 3.447665ms to delete 0 records from CX_120_REMOTE_PUBLIC_TRADE_HISTORY
2021-01-11T10:51:06.348Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 324.267031ms to delete 0 records from CX_211_CONTRACT_HISTORY
2021-01-11T10:51:09.352Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 3.496174ms to delete 0 records from CX_215_CONTRACT_CLOSING_PRICE_HISTORY
2021-01-11T10:51:12.365Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 12.367514ms to delete 0 records from CX_101_ORDER_HISTORY
2021-01-11T10:51:15.368Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 3.438326ms to delete 0 records from CX_262_LIMIT_HISTORY
2021-01-11T10:51:18.375Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 5.701548ms to delete 0 records from CX_119_SETTLEMENT_HISTORY
2021-01-11T10:51:21.380Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - It took 4.557175ms to delete 0 records from CX_111_TRADE_HISTORY
2021-01-11T10:51:21.380Z [worker-1] INFO  c.d.e.m.h.c.DbHistoryHarvester - cleanup process finished in 21379 ms
{code}


{code:java}
before cleanup:
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_data     25G  8.6G   17G  35% /var/lib/pgsql_m7teltsctpbasync/data
after cleanup:
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_data     25G  8.0G   18G  32% /var/lib/pgsql_m7teltsctpbasync/data

before cleanup: 
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_backup  5.0G  161M  4.9G   4% /var/lib/pgsql_m7teltsctpbasync/backup
after cleanup:
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_backup  5.0G  1.7G  3.4G  33% /var/lib/pgsql_m7teltsctpbasync/backup
{code}
but it was probably the one-time activity that caused so much WALs to be written

","12/Jan/21 07:34;cs687;backup is working and harvester as well, FS today: 
{code:java}
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_backup  5.0G  145M  4.9G   3% /var/lib/pgsql_m7teltsctpbasync/backup
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_log     5.0G   51M  5.0G   1% /var/lib/pgsql_m7teltsctpbasync/log
/dev/mapper/datavg-lv_pgsql_m7teltsctpbasync_data     25G  7.8G   18G  31% /var/lib/pgsql_m7teltsctpbasync/data
{code}
","12/Jan/21 14:03;cs687;deployed and started harvester for epex-asim 
all info is listed here https://jira.deutsche-boerse.com/browse/SERVICE-9482
","12/Jan/21 15:57;cs687;done",,,,,,,,,,,,,,,,
https://10.136.148.41:60391/ endpoint not accessible,M7P-7120,101959,101904,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,pw231,pw231,22/Oct/20 08:08,04/Nov/20 13:01,16/Sep/21 14:11,02/Nov/20 11:20,,7tops_sprint104,,,,,,,,7tops,OPS,,,,,,,,iu252,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,28425600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyl9j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 104 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101959,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Oct/20 08:30;pw231;both main issue solved.

last optional todo: url redirect from https://10.136.148.41:60391 is not correct.","22/Oct/20 14:08;iu252;cmi-web1 was not running.
Started it.
Endpoint is now accessible (confirmed by [~pw231]).",,,,,,,,,,,,,,,,,,,,,,,,,,
OPS: ICS CUTE: cute1 endpoint not accessible,M7P-7109,101930,101904,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pw231,pw231,21/Oct/20 13:15,04/Nov/20 13:01,16/Sep/21 14:11,21/Oct/20 15:48,,7tops_sprint104,,,,,,,,7tops,M7PRODOPS,OPS,,,,,"https://cute1.ics.m7c.deutsche-boerse.com/m7c/index.faces is not accessible while https://cute2.ics.m7c.deutsche-boerse.com/m7c/index.faces works

cmm1 seems to be up and running,

please help.",,pd122,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,28425600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyl3z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 104 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101930,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/20 15:48;pd122;cmm web server was not running properly

all related processes terminated and server started again, looks ok now:

 
{code:java}
[pd122@m7shrdexteweb1 ~]$ ps -ef | grep icsc-cute-cmm
apache 17200 1 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start
apache 17201 17200 0 15:42 ? 00:00:00 /usr/sbin/rotatelogs /shrd/logs/icsc-cute-cmm-web1/m7c_icsc_cute_web-cmm-1_error_ixe_%Y-%m-%d_%H.log 86400 100M
apache 17202 17200 0 15:42 ? 00:00:00 /usr/sbin/rotatelogs /shrd/logs/icsc-cute-cmm-web1/m7c_icsc_cute_web-cmm-1_access_ixe_%Y-%m-%d_%H.log 86400 100M
apache 17203 17200 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start
apache 17204 17200 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start
apache 17205 17200 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start
apache 17206 17200 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start
apache 17207 17200 0 15:42 ? 00:00:00 /usr/sbin/httpd -f /shrd/icsc-cute-cmm-web1/config/httpd.conf -k start{code}
 

I am able to connect now:

 
{code:java}
$ nc -vz cute1.ics.m7c.deutsche-boerse.com 443
\Connection to cute1.ics.m7c.deutsche-boerse.com port 443 [tcp/https] succeeded!
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
OPS: ICS CUTE: configure correct db for CMI,M7P-7108,101929,101904,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,pw231,pw231,21/Oct/20 13:09,04/Nov/20 13:01,16/Sep/21 14:11,22/Oct/20 09:00,,7tops_sprint104,,,,,,,,7tops,OPS,,,,,,"we get lot's of these errors in cmi (ics cute) : {code}java.net.NoRouteToHostException: No route to host{code}

cmm seems to be able to connect well.

please, fix cmi config.",,iu252,pd122,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,28425600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyl3r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 104 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101929,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/20 14:19;pd122;Looks like DB shut down after it ran out of space:
{code:java}
[pd122@m7spg1 ~]$ df -h | grep icsc
/dev/vx/dsk/cuteicscdg/cuteicscdatavol
                       64G 19G 43G 30% /var/lib/ppas_cuteicsc_20308
/dev/vx/dsk/cuteicscdg/cuteicscbackupvol
                       58G 58G 0 100% /var/lib/ppas_cuteicsc_20308/ppas_backup
/dev/vx/dsk/cuteicscdg/cuteicsclogvol
                       16G 16G 5.8M 100% /var/lib/ppas_cuteicsc_20308/ppas_log{code}","21/Oct/20 14:36;pd122;after a while (failing over from node to node) and unable to start anywhere, the cluster failed completely:
{code:java}
[root@m7spg1 ~]# hares -state |grep cuteicsc
cuteicscSGbackupmnt State m7spg1 OFFLINE
cuteicscSGbackupmnt State m7spg2 OFFLINE
cuteicscSGbackupvol State m7spg1 OFFLINE
cuteicscSGbackupvol State m7spg2 OFFLINE
cuteicscSGdatamnt State m7spg1 OFFLINE
cuteicscSGdatamnt State m7spg2 OFFLINE
cuteicscSGdatavol State m7spg1 OFFLINE
cuteicscSGdatavol State m7spg2 OFFLINE
cuteicscSGdb State m7spg1 FAULTED
cuteicscSGdb State m7spg2 FAULTED
cuteicscSGdg State m7spg1 OFFLINE
cuteicscSGdg State m7spg2 OFFLINE
cuteicscSGdlogvol State m7spg1 OFFLINE
cuteicscSGdlogvol State m7spg2 OFFLINE
cuteicscSGip State m7spg1 OFFLINE
cuteicscSGip State m7spg2 OFFLINE
cuteicscSGlogmnt State m7spg1 OFFLINE
cuteicscSGlogmnt State m7spg2 OFFLINE
cuteicscSGnic_prx State m7spg1 ONLINE
cuteicscSGnic_prx State m7spg2 ONLINE{code}","21/Oct/20 14:39;pd122;volume group brought up:
{code:java}
[root@m7spg1 ~]# df -h | grep cute
/dev/vx/dsk/cuteicscdg/cuteicscdatavol
                       64G 19G 43G 30% /var/lib/ppas_cuteicsc_20308
/dev/vx/dsk/cuteicscdg/cuteicsclogvol
                       20G 16G 3.8G 81% /var/lib/ppas_cuteicsc_20308/ppas_log
/dev/vx/dsk/cuteicscdg/cuteicscbackupvol
                       66G 59G 7.5G 89% /var/lib/ppas_cuteicsc_20308/ppas_backup{code}
backup file system cleaned up","21/Oct/20 14:57;pd122;AS I realised that [~iu252] is already working on it (confirmed), assigning the ticket to him","21/Oct/20 15:32;iu252;Increased filesystems.
Db is now up and running:

{noformat}
edb=# \l
                                             List of databases
     Name      |     Owner     | Encoding |   Collate   |    Ctype    |          Access privileges
---------------+---------------+----------+-------------+-------------+-------------------------------------
 edb           | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 m7icsccutecmi | m7icsccutecmi | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7icsccutecmi=CTc/m7icsccutecmi    +
               |               |          |             |             | uapp01m7icsccutecmi=c/m7icsccutecmi+
               |               |          |             |             | udev01m7icsccutecmi=c/m7icsccutecmi+
               |               |          |             |             | umon01m7icsccutecmi=c/m7icsccutecmi
 postgres      | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0     | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                    +
               |               |          |             |             | enterprisedb=CTc/enterprisedb
 template1     | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                    +
               |               |          |             |             | enterprisedb=CTc/enterprisedb
(5 rows)

edb=#  select * from pg_stat_activity;
  datid  |    datname    |  pid  | usesysid |       usename       |    application_name    | client_addr  | client_hostname | client_port |          backen
---------+---------------+-------+----------+---------------------+------------------------+--------------+-----------------+-------------+----------------
 7844591 | m7icsccutecmi | 31967 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37394 | 21-OCT-20 14:42
 7844591 | m7icsccutecmi | 32335 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.89 |                 |       33996 | 21-OCT-20 14:42
 7844591 | m7icsccutecmi | 35718 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37412 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35723 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37416 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35725 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37420 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35728 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37424 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35759 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37428 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35766 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37432 | 21-OCT-20 14:43
 7844591 | m7icsccutecmi | 35768 |    16386 | uapp01m7icsccutecmi | PostgreSQL JDBC Driver | 10.139.59.87 |                 |       37436 | 21-OCT-20 14:43
   14313 | edb           | 34964 |       10 | enterprisedb        | psql.bin               |              |                 |          -1 | 21-OCT-20 15:30
(10 rows)
{noformat}
","21/Oct/20 18:09;iu252;Redeployed cmm and cmi: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Energy-Deploy/42317/console

No errors in the logs regarding db-connection, but ....

{noformat}
2020-10-21 17:58:40.023 [fileReceiveTaskScheduler-3]:[] ERROR - c.d.e.c.t.scp.JSchScpClient - Unable to fetch files via SCP (10XDE-RWENET---W)
2020-10-21 17:58:40.023 [fileReceiveTaskScheduler-3]:[] ERROR - c.d.e.c.t.scp.ScpHandler - Can not get SCP files for: 10XDE-RWENET---W
java.lang.IllegalStateException: SCP action failed
        at com.deutscheboerse.energy.commons.transport.scp.JSchScpClient.doWithMultiProxies(JSchScpClient.java:486)
        at com.deutscheboerse.energy.commons.transport.scp.JSchScpClient.get(JSchScpClient.java:134)
        at com.deutscheboerse.energy.cmminteg.transport.scp.ScpHandler.receive(ScpHandler.java:76)
        at sun.reflect.GeneratedMethodAccessor137.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{noformat}
",,,,,,,,,,,,,,,,,,,,,,
Customer Portal - XSDs as part of documentation,M7P-7106,101913,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,dp007,dp007,dp007,21/Oct/20 10:40,25/Aug/21 10:05,16/Sep/21 14:11,16/Aug/21 13:48,,6.12.118,7tops_sprint124,,,Customer Portal,,,,M7PRODOPS,,,,,,,"We will treat XSDs like any other document:
 [http://energy-m7-customer-portal-test.s3-website.eu-central-1.amazonaws.com/documentation/6.10/]
 In here we will have tabs:
 * Manuals
 * Functional Documentation
 * *XSDs*
 * Other

and when you click on XSDs you will have the list of XSDs and their descriptions (like by any other doc).

Some XSDs will be private (prompting a login dialog) and some will be public.

The only difference (compared to the regular docs) will be that they will have only Download link (no View) and this link will lead directly to some.xsd file.

Note from Jana:
 It seems that, with one exception (API messages about risk sets) one XSD file contains only the 'private' API messages and 2nd XSD file contains only the 'public' API messages. Which would mean we could use the same password for the private XSD file and let 2nd XSD file to be publicly viewable.
 There are also XSD files for Reporting Engine but those can be all public (we have one public document for RE too, DFS190).",,dp007,nn236,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2678400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5772,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzcyn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101913,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/21 11:20;nn236;[~dp007] I believe after our last discussions we might need to make all XSDs private, ideally not displayed at all, only after the user logs in.","16/Aug/21 13:48;nn236;The XSDs were added to Customer Portal - (EPEX) INT TEST and non-EPEX SIMU buckets - within https://jira.deutsche-boerse.com/browse/M7P-8797.",,,,,,,,,,,,,,,,,,,,,,,,,,
Check LDAP settings for ELTS CTPB,M7P-7082,101722,101599,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,xc363,nn236,nn236,16/Oct/20 16:59,17/Dec/20 13:04,16/Sep/21 14:11,18/Nov/20 17:20,,7tops_sprint106,,,,,,,,M7PRODOPS,,,,,,,"*Task:* please check the setting of LDAP for ELTS CTPB with regard to requirements on password strength and password history.

*Password strength:*

According to M7 password policy, users' passwords shall be at least 8 characters long and fulfil 3 of the 4 requirements (3/4):
 * at least one upper case letter
 * at least one lower case letter
 * at least one number
 * at least one special character - valid special characters are: !@#$%^&*_-+=`(){}:;""'<>,.?/ 

EPEX reports the following issues:
 * A user created with a password that complies with 3/4 requirements, the user is created but login results in an error message that the credentials are incorrect.
 ** After modification of user's password to comply with 4/4 requirements, the login is possible.
 * When a user tries to modify its password to one fulfilling 3/4 requirements, it results in an LDAP error.
 ** Modification of password to one fulfilling 4/4 is successful.

*Password history:*

In M7, it should be not possible to use last 6 passwords. 

EPEX reports that they are able to change user's password to a previous one but then are unable to log in with it.",,nn236,pd122,xc363,,,,,,,,,,,,,,,,,,,,,,,,,,EPEXMT-2757,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23587200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyjyn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 103 (US),Magnificent 7 Sprint 104 (PS),X-Men Sprint 105 (US),X-Men Sprint 106 (PS),Schmetterling Sprint 107 (US),Schmetterling Sprint 108,Schmetterling Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101722,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/20 17:47;pd122;How old is this feedback? I'm asking because there was new policy implemented on 9/10 ([SERVICE-8408]) and I'd like to make sure it is recent before spending more time on it.","19/Oct/20 09:21;nn236;[~pd122] It was reported on the 14/10. I asked EPEX for the confirmation of the test date.","19/Oct/20 10:21;nn236;[~pd122] EPEX confirmed that the test was after the 9th (the 14th). They also retested the issues this morning and confirmed they are currently present.
 ","29/Oct/20 11:48;pd122;[~nn236], can you provide an application data (i.e. LDAP error displayed), timestamp(s) of the event(s) as well as relevant account name(s) that would allow me to troubleshoot?","29/Oct/20 16:59;nn236;[~pd122] details provided by [~wn626]","18/Nov/20 17:18;pd122;I have modified and tested the updated policy (on ACUT). The new policy in effect now:

 
{code:java}
[pd122@m7shrdsimuldp1 ~]$ ldapmodify -h m7shrdsimuldp1 -D ""cn=Directory Manager"" -w $pw
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
changetype: modify
delete: passwordMinSpecials
-
delete: passwordMinAlphas
-
delete: passwordMin8bit
-
delete: passwordMinLowers
-
delete: passwordMinUppers
-
delete: passwordMinDigits
modifying entry ""cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test""
{code}
{code:java}
[pd122@m7shrdsimuldp1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdsimuldp1 -D ""cn=Directory Manager"" -w $pw -b ""cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test"" -s base
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
passwordMaxAge: 7776000
passwordWarning: 0
passwordResetFailureCount: 3600
passwordMinCategories: 3
passwordInHistory: 6
passwordCheckSyntax: on
passwordLockoutDuration: 900
passwordUnlock: off
passwordMaxFailure: 5
passwordLockout: on
passwordStorageScheme: ssha256
passwordMinTokenLength: 3
passwordMaxRepeats: 0
passwordMinLength: 8
passwordGraceLimit: 0
passwordExp: on
passwordMinAge: 0
passwordChange: on
passwordMustChange: off
cn: cn=nsPwPolicyEntry,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top{code}","02/Dec/20 15:53;xc363;[~pd122] the bug was reported from CTPB environment, I can see that you have made the changes in ACUT...?","02/Dec/20 16:03;pd122;Sorry if my message was not clear, I only mentioned ACUT in relation to testing of the updated policy. If you look closely at the output above you can see it is related to ELTS CTPB.","17/Dec/20 13:02;pd122;both default ans admin password policy updated in line with approved setup ([M7P-7052]):
 
{code:java}
[pd122@m7shrdsimuldp1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdsimuldp1 -D ""cn=Directory Manager"" -w $pw -b ""ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test"" ""(&(objectclass=ldapsubentry)(objectclass=passwordpolicy))""
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
passwordMaxAge: 7776000
passwordWarning: 0
passwordMinCategories: 3
passwordInHistory: 6
passwordCheckSyntax: on
passwordUnlock: off
passwordMaxFailure: 5
passwordLockout: on
passwordMinLength: 8
passwordExp: on
cn: cn=nsPwPolicyEntry,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top

dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
objectClass: top
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: extensibleObject
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
cn: cn=nsNoExpPwPolicyEntry,ou=ctpb,ou=elts-app,o=M
{code}
7,dc=energy,dc=test",,,,,,,,,,,,,,,,,,,
Add harvester to deployment job(s),M7P-7072,101616,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,HO764,HO764,15/Oct/20 08:55,23/Mar/21 17:54,16/Sep/21 14:11,16/Oct/20 13:17,,6.11.61,7tops_sprint103,,,,,,,7tops,,,,,,,Add harvester service to https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/.,,HO764,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Harvester deployment job prepared,,,,,,,,,,,,,,,,,,,,,,,,28944000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyj9z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101616,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/20 13:16;iu252;Jenkins Job prepared for harvester deployment.
Tested toghether with [~fj021] and [~HO764]: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_custom/856/console

Agreed to Close this ticket.","16/Oct/20 13:25;iu252;Also Self-Service Job prepared and tested:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/6787/console",,,,,,,,,,,,,,,,,,,,,,,,,,
For OPS: Add reporter to deployment job(s) + filebeat + telegraf,M7P-7071,101613,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,pw231,pw231,15/Oct/20 08:31,04/Nov/20 13:01,16/Sep/21 14:11,22/Oct/20 09:00,,6.11.66,7tops_sprint104,,,,,,,7tops,,,,,,,"we have a new service : M7 Reporter. Could you please add it to the deployment job (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/)
changes here : https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1165 and here https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2273/files",,iu252,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Reporter deployment jenkins job created,,,,,,,,,,,,,,,,,,,,,,,,28512000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyj9b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 103,7tops Sprint 104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101613,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"16/Oct/20 08:45;pw231;reporter deployed.

[~iu252]: please, also redeploy filebeat for reporter on syt3.
there is one file atm : {{/shrd/logs/shrd-syt3-rpr1/m7_shrd_syt3_m7treporter-1_standard_ixe.log}}

[~iu252] possibly also telegraf to poll the jolokia endpoint ? ","19/Oct/20 11:22;iu252;PR created: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2285","20/Oct/20 09:06;iu252;Reverted https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2285
Created https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2293
Deployed filebeat.
Logs are in Kibana.","20/Oct/20 16:05;iu252;Telegraf:
Created PR https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2295","20/Oct/20 17:36;iu252;Fixed typo: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2297
Deployed telegraf: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1359/console

The joloika data are in grafana: https://grafana.energy.svc.dbgcloud.io/d/QdT5584mz/java-application?orgId=2&var-host=m7shrdinterep1%20-%20tomcat%20-%20m7_shrd_syt3&var-host=m7shrdinterep2%20-%20tomcat%20-%20m7_shrd_syt3&var-client=shrd&var-environment=syt3&var-group=All&var-interval=$__auto_interval_interval&var-tomcat=All&var-core_host=&var-instance=All",,,,,,,,,,,,,,,,,,,,,,,
M7 - enable CT build with parameter withMessageGapRecovery,M7P-7065,101576,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,rehapav,rehapav,14/Oct/20 15:57,23/Mar/21 17:53,16/Sep/21 14:11,14/Oct/20 16:49,,6.11.61,7tops_sprint103,,,Customer Portal,,,,M7PRODOPS,,,,,,,"Please enable BIZOPs to deliver CT with 

parameter withMessageGapRecovery enabled from CT deployment jenkins job.

 

additionally deliver to ELTS CTPB CT version 6.10.66 with this enabled",,dp007,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"New checkbox field added to
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Customer-Portal/job/deploy-comtrader-m7/]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Customer-Portal/job/deploy-comtrader-m7-snapshot/]

When checked it deploys ComTrader with
{code:java}
 -DwithMessageGapRecovery=true {code}",,,,,,,,,,,,,,,,,,,,,,,,29030400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyj27:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 103,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101576,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/20 16:36;dp007;New checkbox field added to
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Customer-Portal/job/deploy-comtrader-m7/]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Customer-Portal/job/deploy-comtrader-m7-snapshot/]

When checked it deploys ComTrader with
{code:java}
 -DwithMessageGapRecovery=true {code}",,,,,,,,,,,,,,,,,,,,,,,,,,,
create automatic overview for all Energy VMs,M7P-7058,101470,,Bug,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,13/Oct/20 15:39,05/Jan/21 13:35,16/Sep/21 14:11,,,,,,,,,,,7tops,reducingtoil,,,,,,"As agreed on DevOps community on 13/10 it is beneficial to have 

new Jenkins based tool 
 * list all VMs that belong to Energy infrastructure (all products all environments)
 * tool runs automatically once a day
 * tool checks via facts user with read rights OS version on each VM
 ** syseng team [~cv524] agreed to provide necessary facts user
 * tool displays VMs in human readable output
 * tool allows group VM by product  / customer / environments/ shared ones
 * tool provide information about each VM such as
 ** OS kernel version
 ** ..

 

 

 PING: [~cv179]

 

 ",,cv524,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-519,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29116800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,13/Oct/20 15:39,,[],,,,,,,,None,,,M7T,,,,"2|hzz0v3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101470,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/20 13:22;cv524;Dedicated SYSENG-249 created for the task of technical account to access the content of Satellite server.


{color:#FF8B00}*Please check the ticket for details of account utilization and command examples.*{color}",,,,,,,,,,,,,,,,,,,,,,,,,,,
Self-service - Flyway AD-HOC scripts job,M7P-7055,101448,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,fj021,fj021,13/Oct/20 10:26,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"The goal is to Finish/edit this job (that is just a placeholder right now) [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Adhoc%20Flyway%20SQL%20trigger/]

 

From discussion with [~cv179], it only needs to :
 * Call this downstream job [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/Adhoc%20Flyway%20SQL%20trigger/] with reduced list of choices for environment.

 

We need it to be able to properly run/test Ad-Hoc jobs on test environments.",,fj021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29203200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0vb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101448,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Verify the correctness of Password Policy LDAP configuration (test + PROD),M7P-7052,101414,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pn508,pn508,12/Oct/20 15:07,05/Jan/21 14:01,16/Sep/21 14:11,16/Dec/20 09:14,,6.11.156,7tops_sprint107,,,uknown,,,,7tops_comm,L,,,,,,"Verify that the Password expiration policy that should be applied on PROD and test environments are in line with the underlying specification (PROD), see:
 * DFS120 chapters 7.4.0.6, 7.4.0.7
 * DFS180 chapter 6.1.8
 * DFS180a chapter 2.2.9 and 2.2.10
 * MFG110 chapters 2.3.2 and 2.4.4.2
 * MFG130 chapter 9
 * MFG140 chapter 1.2.4

*TEST environments (pls start with them):*

LDAP update. All users on ELTS PROD should have (?) the following policy: 
{code:java}
passwordChange: on
passwordCheckSyntax: on
passwordExp: on
passwordGraceLimit: 0
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordLockoutDuration: 900
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMaxRepeats: 0
passwordMin8bit: 0
passwordMinAge: 0
passwordMinAlphas: 0
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinTokenLength: 3
passwordMinUppers: 1
passwordMustChange: off
passwordResetFailureCount: 3600
passwordStorageScheme: ssha256
passwordUnlock: off
passwordWarning: 0
{code}
 
 Technical users should have (?) another policy:
{code:java}
passwordChange: on
passwordCheckSyntax: on
passwordExp: off
passwordGraceLimit: 0
passwordInHistory: 6
passwordLockout: off
passwordLockoutDuration: 900
passwordMaxFailure: 5
passwordMaxRepeats: 0
passwordMin8bit: 0
passwordMinAge: 0
passwordMinAlphas: 0
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinTokenLength: 3
passwordMinUppers: 1
passwordMustChange: off
passwordResetFailureCount: 3600
passwordStorageScheme: ssha256
passwordUnlock: off
passwordWarning: 0
{code}
List of technical users per environments are available here https://jira.deutsche-boerse.com/browse/M7P-5076, see [^list-ot-technical-users_updated-120520.txt]

receive reminders to change passwords 1 day before the password. see: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1318/files]

Idea behind is to use the same LDAP configuration for test environments under some specific ldap tree.

*PRODUCTION environments:*

LDAP update. All users on ELTS PROD should have (?) the following policy: 
{code:java}
passwordChange: on
passwordCheckSyntax: on
passwordExp: on
passwordGraceLimit: 0
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordLockoutDuration: 900
passwordMaxAge: 7776000
passwordMaxFailure: 5
passwordMaxRepeats: 0
passwordMin8bit: 0
passwordMinAge: 0
passwordMinAlphas: 0
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinTokenLength: 3
passwordMinUppers: 1
passwordMustChange: off
passwordResetFailureCount: 3600
passwordStorageScheme: ssha256
passwordUnlock: off
passwordWarning: 0
{code}
 
 Technical users should have (?) another policy:
{code:java}
passwordChange: on
passwordCheckSyntax: on
passwordExp: off
passwordGraceLimit: 0
passwordInHistory: 6
passwordLockout: off
passwordLockoutDuration: 900
passwordMaxFailure: 5
passwordMaxRepeats: 0
passwordMin8bit: 0
passwordMinAge: 0
passwordMinAlphas: 0
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinTokenLength: 3
passwordMinUppers: 1
passwordMustChange: off
passwordResetFailureCount: 3600
passwordStorageScheme: ssha256
passwordUnlock: off
passwordWarning: 0
{code}
List of technical users per environments are available here https://jira.deutsche-boerse.com/browse/M7P-5076, see [^list-ot-technical-users_updated-120520.txt]

receive reminders to change passwords 10 days before the password. see: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1318/files]
 *Note:* After change of the parameter _user_password_expiry_reminder_ M7 core needs to be re-started (core reads values of parameters only on start-up). Can be amended on the server, then failover on the active core. As well, inventory needs to be amended for next deployments (before or after the first two steps).

*Planned tasks:*
 * go thorugh suggested psw policy and evaluate it against requirements from docs
 * test points that are unclear
 * prepare detailed policies including technical one
 * list open points (none if possible)
 * get approval from [~pn508]
 * create summary of policies in Confluence for future references

*Planned effort: 8 SP*",,nn236,pd122,pn508,,,,,,,,,,,,,,,M7P-7185,M7P-5609,,,,,,,,,,,,,,,SERVICE-9052,SERVICE-4506,SERVICE-8505,,,,"12/Oct/20 15:40;nn236;list-ot-technical-users_updated-120520.txt;https://jira.deutsche-boerse.com/secure/attachment/88492/list-ot-technical-users_updated-120520.txt",,,,,,,,,,,,,,,sw455,,,,,,,,password policy fulfilling required criteria was successfully set up and tested,,,,,,,,,,,,,,,,,,,,,,,,23760000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy2rj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101414,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/Nov/20 18:14;pd122;Went through the suggested default test password policy and bellow is what would make sense to me (with 1 exception though - you really think 3 day password expiration is going to work? ):
{code:java}
passwordCheckSyntax: on
passwordExp: on
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0{code}","18/Nov/20 18:26;pd122;Your suggested password policy for technical test users does not make any sense to me. Here's my suggestion:
{code:java}
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordHistory: on
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0{code}","24/Nov/20 12:08;pd122;Waiting for approval of these suggested policies, ready to test once the environment is available.","25/Nov/20 15:33;pn508;Approved after discussing with [~nn236]","25/Nov/20 17:18;nn236;[~pd122] after alignment within our team, I propose to install the password policies for testing on ATE4 environment. The assumption is that the password policies will be 'removed' from ATE4 and user passwords will be reset to Test0101 or test01 as soon as the test is finished. ","26/Nov/20 17:30;pd122;Following ATE4 users have set non-default PP at this moment:

 
{code:java}
SADMIN01
SYSOPS01
shrd-apa-ate4-adm
M7USR006
M7USR010
AAAAAAAA
SYSMTT01
M7CODA01
M7CODA02
{code}
I will be keeping the setting for _shrd-apa-ate4-adm_ only, if you want other users included, please let me know.

 ","26/Nov/20 17:44;pd122;The above test policies have now been set for all ATE4 accounts.  Please, let me know what would you like to set the initial password expiry date to.","30/Nov/20 16:57;pd122;*M7USR006* and *M7USR007* users assigned specific (non-default) password policy for testing purposes:
{code:java}
[pd122@m7shrdtestldp1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $pw -b ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test uid=M7USR006 pwdPolicySubentry
 dn: uid=M7USR006,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
 pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test{code}","03/Dec/20 17:24;pd122;admin password policy set for 2 additional users:

 
{code:java}
[pd122@m7shrdtestldp1 ~]$ for i in M7ADM007 M7USR006 M7USR007 SYSMTT01; do ldapsearch -LLL -o ldif-wrap=no -x -h m7shrdtestldp1 -D ""cn=Directory Manager"" -w $pw -b ""ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test"" uid=$i pwdPolicySubentry passwordExpirationTime; done
dn: uid=M7ADM007,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
dn: uid=M7USR006,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
dn: uid=M7USR007,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
dn: uid=SYSMTT01,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubentry: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}
 ","09/Dec/20 18:05;pd122;Default policy updated (password history, expiration  and account lockout removed):
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordCheckSyntax: on
passwordMinCategories: 3
passwordMinLength: 8
{code}","09/Dec/20 18:22;pd122;users: M7ADM00,7 M7USR006, M7USR007 and SYSMTT01 have been assigned default policy again","09/Dec/20 19:00;pd122;* passwordExpirationTime attribute removed for all users
 * password reset for all users (except binddn) as requested","11/Dec/20 17:40;pd122;So to summarize here's the default test password policy that was successfully tested:
{code:java}
passwordCheckSyntax: on
passwordExp: on
passwordInHistory: 6
passwordHistory: on
passwordLockout: on
passwordMaxAge: 259200
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0{code}

 and here's tested test policy for technical users:
{code:java}
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordHistory: on
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0{code}

  My understanding is that production policy for technical users is to be the same as test policy and *production default policy* will *differ* from test policy in the *_passwordMaxAge_* attribute *only* (90 days).

[~nn236], [~pn508], could you specify password expiration time for test environments (I believe it should be more than current 3 days but not sure about the exact value, say 30 or 60 days?).

[~pn508], please, sign off on this complete setup.","15/Dec/20 10:47;pn508;[~pd122] signing-off for M7T","15/Dec/20 11:07;nn236;[~pd122] the above password policies look correct to me.

In my view, we should apply the following -  [~pn508] please confirm if this is ok from you, thank you.

1) *internal test environments*
 * 1a) when we are testing the password policy first time in an overall manner -> max password age should be 3 days (to allow for shorter testing)
 * 1b) after (1a) is successfully tested internally -> the environment should be returned to its previous state, i.e. without password expiry and no history of passwords checked.  passwords reset to Test0101 or test01 (to allow for normal usage of the environment). In future, the password policy as specified above can be reinstalled upon request of team members if it is required for some internal tests (but is not in place by default).

2) *customer test environments*
 * 2a) when customer is testing the password policy first time in an overall manner -> max password age should be 3 days (to allow for shorter testing)
 * 2b) after (2a) is successfully tested by a customer  -> max password age should be set to PROD value, i.e. 90 days (to allow for normal usage of the customer environment)

3) *customer Production environments*
 * after (2a) is successfully tested and upon an agreed date with the customer about password policy going live -> max password age should be set to 90 days",,,,,,,,,,,,,
ATE4 LDAP user password check,M7P-7035,101278,100264,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,ef759,ef759,08/Oct/20 10:15,21/Oct/20 11:21,16/Sep/21 14:11,08/Oct/20 14:32,,7tops_sprint103,,,,,,,,M7PRODOPS,,,,,,,I would need to check LDAP password on ATE4 for user ATE4EX02. Since right now we are not able to connect from M7 to SOB using this user. ,,ef759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29635200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyhdj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 102,Magnificent 7 Sprint 103 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101278,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
extend RAM for hosts m7shrdinterep1 and m7shrdinterep2 by additional 12GiB,M7P-7034,101277,100906,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,xt853,xt853,08/Oct/20 10:13,21/Oct/20 11:21,16/Sep/21 14:11,13/Oct/20 09:29,,7tops_sprint103,,,,,,,,M7PRODOPS,,,,,,,We need to extend RAM for hosts {{m7shrdinterep1}} and {{m7shrdinterep2}} by additional 12GiB. It is due to syt1 reporting engine epex-production-like tests which require 12GiB ram to run.,,iu252,nn236,xt853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29203200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyhdb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 103 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101277,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/20 09:18;iu252;Memory hotplug is enebled for both hosts.

Created a ticket for SysEng (https://jira.deutsche-boerse.com/browse/SYSENG-247).

Waiting for implementation.","13/Oct/20 09:29;iu252;
{noformat}
####################################################################################
[root@m7shrdinterep1 ~]# grep MemTotal /proc/meminfo
MemTotal:       20573200 kB
[root@m7shrdinterep1 ~]#
####################################################################################


####################################################################################
[root@m7shrdinterep2 ~]# grep MemTotal /proc/meminfo
MemTotal: 20573200 kB
[root@m7shrdinterep2 ~]#
####################################################################################
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD - 6.10 (rehersal) production installation test,M7P-7033,101274,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Won't Do,rehapav,rehapav,rehapav,08/Oct/20 08:45,05/Aug/21 13:25,16/Sep/21 14:11,04/Dec/20 10:41,,6.12.114,,,,cor,,,30/Oct/20 00:00,7tops_comm,M,,,,,,"*Business reason*
 - agreed mandatory test defined prior to 6.10 acceptance together by PO and  RM
 - a similar test was already executed for major release 6.9 (see linked item)
 - the test will *confirm our readiness* to execute the deployment in agreed quality/time and scope

*task description*

Together with Techops, please perform a complete installation test on the  ELTS PROD data snapshot

*Preparation*
 * *get dump from ELTS PROD* environment 
 * apply necessary *data cleansing on the dump* that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.10

*Steps*
 * agree which systemtest environment to be used
 * install on systemtest environment 6.9.150
 * load dump into system test environment
 * deploy 6.10.246 software version *confirmed*
 ** as part of the deployment  check that following steps were successfully completed
 ** migrations steps are applied
 ** DB cleanup scripts on old database successfully executed
 ** flyway scripts for 6.10 software were successfully exectued
 * measure migration timeline
 * do not start the environment

*Acceptance criteria*
 * execution times have been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions",,iu252,rehapav,,,,,,,,,,,,,,,,,,M7P-6347,,,,,,,,,,,,,,SERVICE-6738,SERVICE-6732,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"I want to formally inform you (before ELTS PROD deployment on 8/12) that we have – after sensitive risk assessment – decided to skip ELTS PROD dbcleanup/conversion test.

 

The test itself has been successfully executed for all 3 other small customers with M7 6.10 in their PROD environments – BSP, HUPX, and OPCOM – and of course, we planned it for ETLS PROD well.

While discussing execution details of this test on ELTS PROD database, we faced an issue (not present for other customers) with an extremely big ELTS PROD database size (>1 TB).

At the moment, we have no technical solution to run a full test on such a big db (we are waiting for db hosts) in our test environment (no disk space).

 

We (Roma) had some innovative ideas on how to execute this test in an alternative way with non-trivial extraordinary efforts (such as running it on read-only “dbr hosts”), yet we concluded that it’s not worth the efforts.

 

Considering that we already run dbcleanup script 3 times successfully on 6.9 ELTS PROD database directly in production (and that is a significant part of the test), we are confident this part does not need to be tested again.

Flyway scripts – another part of the deployment sequence – have been thoroughly tested on the other clients/test environments and, from its nature, has no different requirements/specifics on ETLS PROD.

The rest of the deployment, like OS upgrade, software deployment, small technical changes, has also been tested already, and we have our experienced guys doing it.

 

We agreed to have more robust review process for preparation and have 3 techops + 2 developers working on the deployment preparation and execution.

 

After constructive team negotiation, I found the risk of not running this test as acceptable.",,,,,,,,,,,,,,,,,,,,,,,,27993600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyr5r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 107,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":101274,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Oct/20 08:21;iu252;ELTS PROD DB is growing und growing:
https://grafana.energy.svc.dbgcloud.io/d/5qbhAxvmz/postgresql-overview?orgId=2&var-product=m7t&var-group=postgres&var-host=All&var-client=elts&var-client_env=prod&var-dbname=m7t-elts-prod-pdb-async1_m7teltsprodm7b&from=1601187024021&to=1603782624022&fullscreen&panelId=10


{noformat}
[root@m7prodpdb1 ~]# df -h | grep elts
/dev/mapper/datavg-lv_pgsql_m7teltsprodasync_log     5.0G  190M  4.9G   4% /var/lib/pgsql_m7teltsprodasync/log
/dev/mapper/datavg-lv_pgsql_m7teltsprodasync_data    725G  620G  106G  86% /var/lib/pgsql_m7teltsprodasync/data
/dev/mapper/datavg-lv_pgsql_m7teltsprodasync_backup  330G  4.9G  326G   2% /var/lib/pgsql_m7teltsprodasync/backup
/dev/mapper/datavg-lv_journal_m7eltsprodm7c           75G   15G   61G  20% /opt/gluster_volumes/journal/m7eltsprodm7c
[root@m7prodpdb1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize    VFree
  datavg   1  34   0 wz--n-   <1.46t <72.29g


[root@m7prodpdb1 m7teltsprodasync]# pwd
/var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync
[root@m7prodpdb1 m7teltsprodasync]# du -hs base
620G    base
[root@m7prodpdb1 m7teltsprodasync]# du -hs pg_wal/
2.1G    pg_wal/
[root@m7prodpdb1 m7teltsprodasync]#
{noformat}



Are we sure we end up not with issues during the clean up?
Like the script is copying tables of few days and then delete the old table. Are we sure we have enough space for that action?
Last time in july we had to add more times space to FS data during that operation. And during that time we had a sice of ~350G now we could have ~650G.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement full password policy on DST1 env for Penetration testing 2020 ICS,M7P-7031,101249,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,vp223,vp223,07/Oct/20 15:58,26/Nov/20 10:21,16/Sep/21 14:11,13/Oct/20 17:43,,7tops_sprint103,,,,,,,09/Oct/20 00:00,M7PRODOPS,,,,,,,"I need a full password policy on DST1 env. Right now it should be only passwordInHistory: 6 applied. However, for penetration testing, it needs to have all req. there. Especially after 5 wrong attempts lock and password requirement for the pattern (big, small, special char, number).",,pd122,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-7021,,,,,,"13/Oct/20 17:42;pd122;dst1_pp.ldif;https://jira.deutsche-boerse.com/secure/attachment/88559/dst1_pp.ldif",,,,,,,,,,,,,,,sw455,,,,,,,,new default password policy created,,,,,,,,,,,,,,,,,,,,,,,,29116800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-6888,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzym9b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":101249,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/20 12:57;pd122;[~vp223], where can I find all the details for PP you request to be set on DST1?","08/Oct/20 15:24;vp223;As far as I know and wrote in the description, there should be:
 * Lock 5 attempts
 * Expiry 10 days (for testing purpose)
 * The pattern in the password (length, big, small, special char, number).
 * History 6","08/Oct/20 15:33;vp223;The pattern is:

This password shall be at least 8 characters long and shall fulfil 3 of the 4 requirements:

i. at least one upper case letter

ii. at least one lower case letter

iii. at least one number

iv. at least one special character - valid special characters are: !, @, #, $, %, ^, &, *, , _, -, +, =, `, |, (, ), \{, }, :, ;, "", ', <, >, ,, ., ?, /","13/Oct/20 16:02;pd122;[~vp223], there is no separate LDAP tree created for this environment (was not able to find one so far, hence assuming it does not exist), it shares the data with M7T DST1 environment, so any change made to this LDAP tree applies to both DST envs (from LDAP point of view they are the same).  Fine with you? OK to proceed?","13/Oct/20 16:39;pd122;Suggested new password policy based on above requirements:
{code:java}
pwdMaxFailure: 5
passwordExp: on
pwdMaxAge: 864000
pwdCheckSyntax: on
pwdMinLength: 8
passwordMinCategories: 3
pwdMinUppers: 1
pwdMinLowers:1
passwordMinDigits: 1
passwordMinSpecials: 1
pwdHistory: on
pwdInHistory: 6{code}
Note: With above policy, after 5 unsuccessful attempts, accounts would be locked for 1h only, if you require them to be locked for longer (good), please let me know.

Question: do you require any specific password policy for technical accounts of this environment? If yes, would you prefer empty policy or would you like to set some attributes as well? 

 ","13/Oct/20 17:35;pd122;New _default_ password policy has been created for DST1 (ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test):
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Ddst1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: ldapsubentry
objectclass: passwordpolicy
passwordCheckSyntax: on
passwordExp: on
passwordHistory: on
passwordInHistory: 6
passwordMaxAge: 864000
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinUppers: 1
passwordWarning: 0{code}","13/Oct/20 17:41;pd122;Separate policy set for bind dn (dn: uid=shrd-apa-dst1-adm,ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test): 
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordWarning: 0
passwordHistory: on
passwordInHistory: 6{code}",,,,,,,,,,,,,,,,,,,,,
XRPM PROD not sending logs to EBSM,M7P-7016,101159,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,op211,dp007,dp007,06/Oct/20 15:34,21/Oct/20 11:21,16/Sep/21 14:11,07/Oct/20 12:15,,6.11.44,7tops_sprint103,,,EBSM,M7T BE,,,EBSM,M7PRODOPS,PRODUCTION_BUG,,,,,"There are no XRPM PROD logs at EBSM since 2020-09-08.

COR/ENQ/RE/.. logs are not sent to EBSM and therefore not transferred to rollover/transferred subfolders.

Please investigate why and fix the problem.",,dp007,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,file transfer added to cron.,,,,,,,,OPCOM,,,,,,,,,,,,,,,,29721600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,06/Oct/20 15:34,,[],,,,,,,,None,,,M7T,,,,"2|hzygqn:",9223372036854775807,,,,No,,,,,,,,,,Cronjob for log file transfer was missing on m7xrpmprodm7b1. Tobias added it manually.,,,,,,,,7tops Sprint 102,7tops Sprint 103,,,,,,,,,,,,,,,,,,,,,,,,,none,1.0,,,,,,,,,"{""issueId"":101159,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"07/Oct/20 10:54;op211;Cronjob for log file transfer was missing on m7xrpmprodm7b1. Added it manually.",,,,,,,,,,,,,,,,,,,,,,,,,,,
SHRD-SYT1 : Adjust logs rollover behaviour ,M7P-6998,100974,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,fj021,fj021,02/Oct/20 13:32,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"h2. Context

We reached 100% on /SHRD/LOGS on m7shrdsyt1apa1.
{code:java}
tomcat@m7shrdsyt1apa1:[/shrd/logs/shrd-syt1-harvester1]$ df -h | grep shrd/logs
 /dev/mapper/rootvg-lv_shrd_logs 55G 52G 0 100% /shrd/logs{code}
{code:java}
tomcat@m7shrdsyt1apa1:[/shrd/logs]$ du -sh *
 16K lost+found
 52K shrd-syt1-coda_1
 17G shrd-syt1-cor1
 35G shrd-syt1-enq1
 1.3G shrd-syt1-h2h4u1
 11M shrd-syt1-harvester1
 24K shrd-syt1-rmq-cardio1
 12K shrd-syt1-rmq-cardio2
 656K shrd-syt1-rmq-cardio3
 12K shrd-syt1-rmq-cardio5
 12K shrd-syt1-rmq-cardio7
 12K shrd-syt1-rmq-cardio9{code}

 The reason was that the rollover/transferred/ folders were growing bigger without any cleanup.

Usually those folders are cleaned up by the transfer job, but those jobs are don't exist on SYTs.

 
h2. What to do ?

The logs should be *excluded* from being moved to ""transferred"" folder so tomcat can delete them for *at minima SYT1*, at best for all test environments that could be similarly impacted (SYT* ATE*).

[~cv179] created the following PR for this, which is under review : [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1093/files]",,fj021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30153600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyzzr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Technical Debt/Improvements,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100974,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
merging/cleaning-up branch piotr4 to master energy.docker.hosts,M7P-6985,100886,,Epic,In Progress,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,cs687,cs687,cs687,01/Oct/20 13:18,15/Apr/21 09:52,16/Sep/21 14:11,,,,,,,,,,,M7PRODOPS,,,,,,,"Open Points:
 * M7P-7611 - S3 Bucket for Terraform State Files (S3-bucket for tf-state file for master & piotr4 (piro), proper terraform apply on master & piotr4 --> diff=0 (prio))

 * compare structure of master & piotr4 branch (/)
 * compare local branch piotr4 *rollout-automation-prod.energy.svc.dbgcloud.io:/home/ansible/piotr* with energy.docker.hosts:piotr4 (/)
 * compare tf-state file from master and piotr4 branch (/)

 * migrate energy.docker ansible-section of branch piotr4 and compare master {color:#ffab00}-> sonar topic open{color}
 * migrate open resources to master by merging the terraform code (/)

 * create/update confluence page {color:#ffab00}-> open until XP-4889 Jenkins Worker Automation{color}
 * finally sharing knowledge ops team-wide {color:#ffab00}-> recreate job in technical operations 04/15/21, second one open until XP-4889 Jenkins Worker Automation{color}",,cs687,sw455,zs244,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17539200,,,dm700,lw641,ox626,rehapav,sw455,,,,,EnergyIT - AWS Development Infra,To Do,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0vr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100886,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/21 14:57;cs687;Branch *piotr4* mostly managing the deployment of the aws-docker hosts which are used with a jenkins node behind it. 

seems like there are some local branches used in the past and not merged into master, like it should normal be the case 

[https://github.deutsche-boerse.de/dev/energy.docker.hosts]

there are also the files *terraform.tfstate* ingored with .gitignore and not uploaded in master 

in the host *ip-10-115-77-197.eu-central-1.compute.internal*
I found some dir´s were might be some useful files 
{code:java}
/home/ansible/piotr

drwxr-x---.  7 ansible ansible  131 Jul 15 11:49 .
drwx------. 20 ansible ansible 4096 Oct  1 12:55 ..
drwxr-x---.  5 ansible ansible  101 Jan  2  2020 energy.docker.hosts
drwxr-x---.  5 ansible ansible   68 May 12 16:09 energy.docker.hosts2
drwxr-x---.  5 ansible ansible  104 Aug 24 09:07 energy.sonar
drwxr-x---.  2 ansible ansible   20 Jul 15 11:49 keys
drwxr-x---.  9 ansible ansible  154 Jun 26 13:41 m7.customer.portal
{code}

the latest docker-hosts were created by myself and were also executed from the branch piotr4 as well 
* englobwkr-shared-medium0.svc.dbgcloud.io
* englobwkr-shared-medium1.svc.dbgcloud.io
* englobwkr-shared-medium2.svc.dbgcloud.io 
* englobwkr-small0.svc.dbgcloud.io 
* englobwkr-medium.svc.dbgcloud.io 
* englobwkr-large0.svc.dbgcloud.io 

/home/ansible/steffen/energy.docker.hosts

so i would recommend to clean this piotr4 branch somehow, collect all the necessary files which are still located locally and start it with a fresh new branch, which should be merged master, whatever. 

talked also to [~cv179], after vacation time we could have a look at it and try to clean it up asap. 

FYI: [~pd122]","25/Feb/21 09:51;zs244;Open from XP-4581 Maintenance:

- ""Give others rx access to jenkins_home"" access control list setting takes a lot of time
- create a playbook to properly destroy a single node (including detachment)
- update AWS provider to version 2 (then update to version 3 if possible)",,,,,,,,,,,,,,,,,,,,,,,,,,
perform VM power cycling - M7 (internal) TEST,M7P-6966,100800,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,rehapav,rehapav,rehapav,30/Sep/20 08:45,19/May/21 11:28,16/Sep/21 14:11,06/May/21 09:51,,6.12.18,7tops_sprint117,,,apache,,,,M7PRODOPS,S,,,,,,"Perform VM power off / power on (not reboot!) as redefined in SERVICE-8268

group 

(2) M7(internal) TEST

 
|xbdst1amq1|
|xbdst1app1|
|xbdtldap1|
|xbdtldap2|
|xbintebha1|
|xbintebha2|
|xbintebha3|
|xbintebha4|
|xbintectp1|
|xbintectp2|
|xbinteidm1|
|xbinteidm2|
|xbintepmi1|
|xbintepmi2|
|xbinterep1|
|xbinterep2|
|xbinterts1|
|xbinterts2|
|xbperfbha2|
|xbperfbha4|
|xbperfcbn2|
|xbperfcmi1|
|xbperfcmm1|
|xbperfctp1|
|xbperfedb1|
|xbperfidm2|
|xbperfimq2|
|xbperfimq4|
|xbperfimq6|
|xbperfrep1|
|xbperfrts2|
|xbperfrts4|
|xbperfsla1|
|xbperfsmc1|
|xbperfsmi1|
|xbperfsob1|
|xbperfxmq2|
|xbperfxmq4|
|xbperfxmq6|
|xbsyt2amq1|
|xbsyt2cmi1|
|xbsyt2cmm1|
|xbsyt2ecp1|
|xbsyt2sob1|
|xbsyt2spm1|
|xbsyt3imq3|
|xbsyt3xmq1|
|xbsyt3xmq2|
|xbsyt3xmq3|
|xbtestldp1|
|xbtestldp2|

 

todo
 * plan and execute

implementation team
 * power off can be done by 7tops, power on (and checking VM parameters) should be done by SysEng
 * restoring services by 7tops

 

 ",,rehapav,,,,,,,,,,,,,,,,,,,XP-3958,,,,,,,,,,,,,,SERVICE-8268,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,power cycling finished,,,,,,,,,,,,,,,,,,,,,,,,30326400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzym9j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100800,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
perform VM power recycling - Monitoring / Tools,M7P-6964,100798,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,rehapav,rehapav,rehapav,30/Sep/20 08:41,05/May/21 11:17,16/Sep/21 14:11,29/Apr/21 07:58,,6.12.12,7tops_sprint116,,,devops,,,,7tops,,,,,,,"Perform VM power off / power on (not reboot!) as redefined in SERVICE-8268

*Duration*:

We do not need any wait state between power off and on - its simply power off and immediately power on.

*group  (1) monitoring tools*

 

 
|Name|Host|Compatibility|EVC Mode|Note|
|jirpadw1|fresxegy1006.deutsche-boerse.de
  
 {color:#00875a}*done on 16/12*{color}|ESXi 6.5 and later (VM version 13)|Intel® ""Sandy Bridge"" Generation|JIRA|
|jirpada1|fresxegy2002.deutsche-boerse.de
  
 {color:#00875a}*done 10/1*{color}|ESXi 5.5 and later (VM version 10)|Intel® ""Sandy Bridge"" Generation|JIRA|
|englobauto1|fresxegy1002.deutsche-boerse.de
 RH 7.2
 *done SERVICE-9752*|ESXi 5.1 and later (VM version 9)|Intel® ""Broadwell"" Generation|Vault, Main Jenkins Agent
 englobauto runs Jenkins jobs (incl. production), some of them scheduled (ed|
|englobmon1|fresxegy1001.deutsche-boerse.de
   RH 7.5
*done* |ESXi 5.5 and later (VM version 10)|Intel® ""Broadwell"" Generation|AlarmTilt|
|englobmon2|fresxegy2003.deutsche-boerse.de
 RH  7.5
 *done SERVICE-9752*|ESXi 6.5 and later (VM version 13)|Intel® ""Broadwell"" Generation|CheckMK
  monitoring (incl. production)|
|entestauto1|fresxegy2007.deutsche-boerse.de
 RH 7.5
 *done SERVICE-9752*|ESXi 5.5 and later (VM version 10)
 *done SERVICE-9752*|Intel® ""Sandy Bridge"" Generation|Jump Host for TEST envs|
|englobmail2| RH 7.6
  *done SERVICE-9752*|
| | | englobmail are test servers, can be power cycled anytime, just not both at the same time|
|englobmail1|  RH 7.6
 *done SERVICE-9752*| | | |

 

*Update on 1/10*
 * no OS update during this window
 * preferably to do it during working hours
 * 

Jira [~pd122] 
 * no Jira autostart in place
 * must be started and checked explicitly after the power cycle

AlartmTilt
 * used for both external and internal alarms
 * used for customer calls
 * no autostart in place
 * service to be switched off before power off
 * service to be switched on after power on

CheckMk
 * used for internal monitoring
 * ervice to be switched off before power off
 * service to be switched on after power on

*todo*
 * techops: check impact on the services 
 * techops: propose optimal approach of implementation + estimate duration
 * announce Jira and Alarmtilt maintenance to clients - 20 WD lead time due to XBID
 * plan with 7tops and syseng
 ** *Jira* Would probably need somebody like Urban who knows Jira system set up well, in case software starts behaving different after reboot.It should not happen but just in case, as again, those VMs were up for years, literally.
 ** *AT*: 
 This would be the easiest way (for us) if we can organise it with customers.  Maybe we can even say “15 minutes”.
 The real thing will probably take 2 minutes max but at least the alarms will not negatively impact customers who should be aware.

implementation team
 * power off can be done by 7tops, power on (and checking VM parameters) should be done by SysEng
 * restoration services then again by 7tops

 

next steps
 * find an internal date/time for power cycling and OS upgrade
 ** englobmon2 - RH 7.5
 ** entestauto1 - RH 7.5
 ** englobmail2 - RH 7.6
 ** englobmail1 - RH 7.6
 ** englobauto1 - RH 7.2

 

 

 

 ",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-9307,SERVICE-8268,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,implemented,,,,,,,,,,,,,,,,,,,,,,,,15897600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzym9r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100798,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Mar/21 08:55;rehapav;Waiting for XBID 3.1 go live, all other VMs recycled already",,,,,,,,,,,,,,,,,,,,,,,,,,,
reporting engine: folders for heapdumps (all envs),M7P-6955,100747,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,pw231,pw231,29/Sep/20 11:24,05/Jan/21 13:38,16/Sep/21 14:11,,,,,,,RE,,,,7tops,M7PRODOPS,OPS,TechOps,,,,"h4. Problem
There is no heapdump flag in reporting engine. 
I added one in this pr : https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1145
Once this is merged, we can fail on creating the heapdump on missing folders.

h4. Task
create and map the heap dump folder for all reporting engine vms.
they are shared and it should always be {{/shrd/logs/heapdump}}
",,cv179,iu252,pw231,,,,,,,,,,,,,,,,,,,,,,,M7P-6980,M7P-6979,M7P-6975,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,28080000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0vj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100747,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/20 11:31;cv179;Task refinement:

PR merged. Now only the mount point needs to get attached:
 * Check, if respective glusterfs can be reached (same as backends heapdump in the same classification syt/cute/prod).
 * Create fstab entries on all 6 hosts,
 * create mountpoints on all 6 hosts,
 * mount fstab entries
 * and change ownership.

 

Ideally, this all will be integrated in the reporting-engine ansible role as 
{code:java}
- import_tasks: configure.yml
  tags: [never, configure] 
  become: true
  become_user: root{code}
block in the main.yml...","29/Sep/20 13:08;pw231;these Prs should be eventually merged as well :
- https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2237 (all but elts prod)
- https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2238 (elts prod)","30/Sep/20 10:21;iu252;Merged https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2237 and https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2238","26/Oct/20 10:37;cv179;heapdump remote servers should be used similar to the other backends:
{code:java}
production: m7shrdprodglfs1/2
all customer test (simu,lipa,cute,...): m7shrdsimuglfs1/2
all internal test (syt1,ate1,....): m7shrdtinfdat1/2{code}
perhaps, syseng can provide us with m7shrdinteglfs1/2 with heapdump storage to replace `tinfdat` host.",,,,,,,,,,,,,,,,,,,,,,,,
EPEX ASIM m7 core database dump,M7P-6954,100743,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,nn481,nn481,29/Sep/20 11:07,07/Oct/20 11:37,16/Sep/21 14:11,29/Sep/20 16:28,,6.11.26,7tops_sprint102,,,,,,,7tops,M7PRODOPS,,,,,,"We need two DB dumps of m7 core db EPEX ASIM, one before 15:00 any day and second after 15:00 same day. Preferably in psql custom format (-Fc) without additional compression.

We need only runtime tables:
{noformat}
cx_001_market_state
cx_100_order
cx_103_quote_request
cx_110_trade
cx_118_settlement
cx_120_remote_public_trade
cx_130_remote_session
cx_132_remote_account_assignment
cx_150_messages
cx_200_product
cx_201_product_configuration
cx_210_contract
cx_212_contract_name_format
cx_214_contract_closing_price
cx_216_contract_x_under_contract
cx_252_market_area
cx_254_delivery_area
cx_256_exchange
cx_257_risk_set
cx_260_member
cx_262_limit
cx_263_contract_commodity_limit
cx_268_risk_management
cx_270_balancing_group
cx_273_clearing_account
cx_275_clearing_house
cx_277_order_x_clearing_house
cx_282_user
cx_284_user_x_balancing_group
cx_295_session
cx_296_remote_user
cx_300_balancing_group_x_tso
cx_312_user_role
cx_320_product_x_balancing_gr
cx_330_product_x_delivery_area
cx_334_product_x_clearing_account
cx_340_member_volume_limit
cx_350_balancing_group_x_balancing_group
cx_354_balancing_group_x_clearing_account
cx_400_trading_schedule
cx_410_trading_phase
cx_430_market_segment_assignment
cx_440_contract_delivery_area_state
cx_450_holidays
cx_470_weekly_trading_rules
cx_600_configuration
cx_610_application_access
cx_800_subscriber
cx_820_subscriber_x_report
m7_888_failover_lock_table
m7_999_revision_index
{noformat}",,cs687,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,creating db-dumps for epex-asim,,,,,,,,EPEX,,,,,,,,,,,,,,,,30326400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyf07:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":100743,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"29/Sep/20 12:08;cs687;Starting the dump before 3
{code:java}
[root@m7simupdb1 ~]# patronictl -c /etc/patroni_m7tepexasimasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | running |  3 |           |
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | running |  3 |         0 |
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader | running |  3 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        | running |  3 |         0 |
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012  |        | running |  3 |           |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        | running |  3 |           |
+------------------+------------+----------------------+--------+---------+----+-----------+


[root@m7simupdb1 ~]# su - postgres
Last login: Tue Sep 29 12:03:22 CEST 2020
-bash-4.2$
-bash-4.2$ /usr/pgsql-11/bin/pg_dump -Fc --port=24012 -f -d m7tepexasimm7b -n m7tepexasimm7b -f /tmp/m7tepexasimm7b1.dmp{code}","29/Sep/20 12:36;cs687;location of the file: 

m7shrdebsm1:/opt/data/transfer/dbdumps/epex_asim/*m7tepexasimm7b1.dmp_before*

 ","29/Sep/20 16:28;cs687;created dump with the name: *m7tepexasimm7b1.dmp_after*

ticket can be closed!","29/Sep/20 16:28;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
expiring LDAP Certificates in M7,M7P-6951,100713,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,cs687,cs687,28/Sep/20 11:57,18/Nov/20 10:40,16/Sep/21 14:11,06/Nov/20 18:04,,6.8.146,7tops_sprint105,,,infrastructure,,,,M7PRODOPS,,,,,,,"Hey [~pd122],

ldap certs will expire and are valid until 06.11.2020
I would suggest to renew them asap. 

Got noticed in the ssl-admin channel.

 
 * m7shrdprodldp1.deutsche-boerse.de
 * m7shrdprodldp2.deutsche-boerse.de
 * m7shrdsimuldp1.deutsche-boerse.de
 * m7shrdsimuldp2.deutsche-boerse.de
 * m7shrdtestldp1.deutsche-boerse.de
 * m7shrdtestldp2.deutsche-boerse.de

example: 
{code:java}
Your SSL certificate for http://m7shrdprodldp2.deutsche-boerse.de will expire soon. Date and time of expiration: 06/11/2020 23:59 GMT. Certificate Details: Common Name : http://m7shrdprodldp2.deutsche-boerse.de Subject Alternative Names : http://m7shrdprodldp2.deutsche-boerse.de, http://m7shrdprodldp-vip1.deutsche-boerse.de Number of licenses : ${numberOfLicenses} SSL Type : Comodo Multi Domain SSL Certificate (customized for Deutsche Boerse AG) Term : 2 Year(s) Server : Apache/ModSSL Requested : 07/11/2018 12:43 GMT Approved : 07/11/2018 12:43 GMT Expires : 06/11/2020 23:59 GMT Order Number : 185347629 Self-Enrollment Certificate ID : 1125717 Comments : ITSR #Q40554 by Jürgen Schneider (Jürgen Schilp) Certificate Manager Certificate : Yes  OU: Deutsche Boerse AG{code}
https://dbg-devops.slack.com/archives/CC51TP7HP/p1601279211002900",,cs687,pd122,rehapav,,,,,,,,,,,,,,,SERVICE-7888,,,,,,,,,,,,,,,,SERVICE-8708,,,,,,"29/Sep/20 21:24;pd122;20200929-m7shrdprodldp1.csr;https://jira.deutsche-boerse.com/secure/attachment/88038/20200929-m7shrdprodldp1.csr","29/Sep/20 21:24;pd122;20200929-m7shrdprodldp2.csr;https://jira.deutsche-boerse.com/secure/attachment/88039/20200929-m7shrdprodldp2.csr","29/Sep/20 21:24;pd122;20200929-m7shrdsimuldp1.csr;https://jira.deutsche-boerse.com/secure/attachment/88040/20200929-m7shrdsimuldp1.csr","29/Sep/20 21:24;pd122;20200929-m7shrdsimuldp2.csr;https://jira.deutsche-boerse.com/secure/attachment/88041/20200929-m7shrdsimuldp2.csr","29/Sep/20 21:24;pd122;20200929-m7shrdtestldp1.csr;https://jira.deutsche-boerse.com/secure/attachment/88042/20200929-m7shrdtestldp1.csr","29/Sep/20 21:24;pd122;20200929-m7shrdtestldp2.csr;https://jira.deutsche-boerse.com/secure/attachment/88043/20200929-m7shrdtestldp2.csr","21/Oct/20 10:15;pd122;DigiCertGlobalRootCA.crt.pem;https://jira.deutsche-boerse.com/secure/attachment/88884/DigiCertGlobalRootCA.crt.pem","21/Oct/20 10:08;pd122;m7shrdprodldp1_deutsche-boerse_de_73830635.zip;https://jira.deutsche-boerse.com/secure/attachment/88875/m7shrdprodldp1_deutsche-boerse_de_73830635.zip","21/Oct/20 10:08;pd122;m7shrdprodldp2_deutsche-boerse_de_73832339.zip;https://jira.deutsche-boerse.com/secure/attachment/88876/m7shrdprodldp2_deutsche-boerse_de_73832339.zip","21/Oct/20 10:08;pd122;m7shrdsimuldp1_deutsche-boerse_de_73832047.zip;https://jira.deutsche-boerse.com/secure/attachment/88877/m7shrdsimuldp1_deutsche-boerse_de_73832047.zip","21/Oct/20 10:08;pd122;m7shrdsimuldp2_deutsche-boerse_de_73831719.zip;https://jira.deutsche-boerse.com/secure/attachment/88878/m7shrdsimuldp2_deutsche-boerse_de_73831719.zip","21/Oct/20 10:08;pd122;m7shrdtestldp1_deutsche-boerse_de_73831415.zip;https://jira.deutsche-boerse.com/secure/attachment/88879/m7shrdtestldp1_deutsche-boerse_de_73831415.zip","21/Oct/20 10:08;pd122;m7shrdtestldp2_deutsche-boerse_de_73831031.zip;https://jira.deutsche-boerse.com/secure/attachment/88880/m7shrdtestldp2_deutsche-boerse_de_73831031.zip",,,sw455,,,,,,,,"new server and intermediate CA certs installed on 6 new LDAP servers, DigiCert root CA installed on all M7 LDAP servers  ",,,,,,,,,,,,,,,,,,,,,,,,27043200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzym67:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100713,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-6951,master,true,"29/Sep/20 21:23;pd122;CSRs generated, ITSR 6B4789 created.","21/Oct/20 09:41;pd122;certificates received from ssl-admin, now need to deploy them (along with new CA chain) to all 6 above hosts and new root CA cert to 4 additional legacy LDAP servers (m7testldap1,2 and m7prodldap1,2) currently in cluster with affected hosts to keep replication running","21/Oct/20 09:48;pd122;Additionally LDAP trust stores have to be updated (new CA included) and all external test envs that already are connecting to the new set of LDAP servers need to be re-deployed (cor, enq) to still work after the certs have changed on the servers","21/Oct/20 12:26;pd122;Vault keystore at _secret/certs/root/comodo/keystore_ updated with new *DigiCert Global Root CA*:

 
{code:java}
Keystore type: jks
Keystore provider: SUN
Your keystore contains 3 entries
digicertglobalrootg2, Oct 21, 2020, trustedCertEntry,
Certificate fingerprint (SHA1): DF:3C:24:F9:BF:D6:66:76:1B:26:80:73:FE:06:D1:CC:8D:4F:82:A4
usertrust rsa certification authority, Apr 29, 2020, trustedCertEntry,
Certificate fingerprint (SHA1): 2B:8F:1B:57:33:0D:BB:A2:D0:7A:6C:51:F7:0E:E9:0D:DA:B9:AD:8E
comodo rsa certification authority, Jun 5, 2019, trustedCertEntry,
Certificate fingerprint (SHA1): AF:E5:D2:44:A8:D1:19:42:30:FF:47:9F:E2:F8:97:BB:CD:7A:8C:B4
{code}
 ","21/Oct/20 12:41;pd122;For legacy Perl based deployments, DigiCert Global Root CA has been imported into
 * non-prod : [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/733|https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/733)]
 * prod : https://github.deutsche-boerse.de/dev-confidential/energy-mkt-production/pull/50","21/Oct/20 12:56;pd122;[~rehapav] ready now to schedule COR, ENQ deployments for all external test envs. Would need to be completed by 6/11/2020 (ideally a day or 2 before that).  Also, it is possible that ELTS CUTE, PLPX LIPA, XRPM LIPA and XSOP ASIM may not require COR deployment as new (somewhat more up to date) keystore has already been uploaded during recent DST test preparations/deployments.

As all PROD envs are still using old LDAP servers, no extra rush here, they can still be gradually updated together with migration to new LDAP servers.

Update:  may make sense to create ordered environment list since those that have not yet been migrated to new LDAPs need not be rushed","26/Oct/20 09:35;rehapav;||Environment||Ticket||Done||
|ELTS ACUT|SERVICE-8564| |
|ELTS LIPA|SERVICE-8564| |
|ELTS SIMU|SERVICE-8566| |
|ELTS ASIM| | |
|ELTS CTPB| | |
|ELTS CUTE| | |
|EPEX ASIM| | |
|HUPX ASIM| | |
|HUPX CUTE| | |
|HUPX SIMU| | |
|PLPX LIPA| | |
|PLPX SIMU| | |
|XRPM LIPA| | |
|XRPM SIMU| | |
|XSOP CUTE| | |
|XSOP ASIM| | |
|XSOP SIMU| | |
|ICSC CUTE|SERVICE-8536| |
|M7A EEX CUTE| | |
|M7A EEX ASIM| | |
|M7A AMPR CUTE| | |
|M7A AMPR ASIM| | |","05/Nov/20 13:58;pd122;While installing new server certs on internal test LDAPs i have realised that CA in the trust store is not the correct one. Fixed in the Vault now:

 
{code:java}
Enter keystore password:
Keystore type: jks
Keystore provider: SUN
Your keystore contains 3 entries
digicertglobalrootca, Nov 5, 2020, trustedCertEntry,
Certificate fingerprint (SHA1): A8:98:5D:3A:65:E5:E5:C4:B2:D7:D6:6D:40:C6:DD:2F:B1:9C:54:36
usertrust rsa certification authority, Apr 29, 2020, trustedCertEntry,
Certificate fingerprint (SHA1): 2B:8F:1B:57:33:0D:BB:A2:D0:7A:6C:51:F7:0E:E9:0D:DA:B9:AD:8E
comodo rsa certification authority, Jun 5, 2019, trustedCertEntry,
Certificate fingerprint (SHA1): AF:E5:D2:44:A8:D1:19:42:30:FF:47:9F:E2:F8:97:BB:CD:7A:8C:B4
{code}
 ","05/Nov/20 14:58;pd122;Fix for legacy Perl deployments:
 * [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/738] merged
 * [https://github.deutsche-boerse.de/dev-confidential/energy-mkt-production/pull/51] merged

 ","06/Nov/20 13:36;rehapav;We're done here? I would close the ticket ","06/Nov/20 15:00;pd122;if you really want to ...  but as I haven't replaced single cert yet  it would seem a bit premature to me ....","06/Nov/20 16:21;pd122;new certs installedon internal test:

{{○ → echo | openssl s_client -connect m7shrdtestldp1.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates}}
{{subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdtestldp1.deutsche-boerse.de}}
{{issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA}}
{{notBefore=Oct 19 00:00:00 2020 GMT}}
{{notAfter=Oct 26 23:59:59 2021 GMT}}

{{○ → echo | openssl s_client -connect m7shrdtestldp2.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates}}
{{subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdtestldp2.deutsche-boerse.de}}
{{issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA}}
{{notBefore=Oct 19 00:00:00 2020 GMT}}
{{notAfter=Oct 26 23:59:59 2021 GMT}}","06/Nov/20 17:12;pd122;external test certs installed:

 
{code:java}
[pd122@m7testldap1 ~]$ echo | openssl s_client -connect m7shrdsimuldp1.deutsche-boerse.de:636 2>/dev/null |head
CONNECTED(00000003)
---
Certificate chain
 0 s:/C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdsimuldp1.deutsche-boerse.de
 i:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 1 s:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
---
[pd122@m7testldap1 ~]$ echo | openssl s_client -connect m7shrdsimuldp1.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates
subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdsimuldp1.deutsche-boerse.de
issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
notBefore=Oct 19 00:00:00 2020 GMT
notAfter=Oct 26 23:59:59 2021 GMT
 
{code}
 
{code:java}
[pd122@m7testldap1 ~]$ echo | openssl s_client -connect m7shrdsimuldp2.deutsche-boerse.de:636 2>/dev/null |head
CONNECTED(00000003)
---
Certificate chain
 0 s:/C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdsimuldp2.deutsche-boerse.de
 i:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 1 s:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
---
[pd122@m7testldap1 ~]$ echo | openssl s_client -connect m7shrdsimuldp2.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates
subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdsimuldp2.deutsche-boerse.de
issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
notBefore=Oct 19 00:00:00 2020 GMT
notAfter=Oct 26 23:59:59 2021 GMT
{code}
 ","06/Nov/20 18:01;pd122;production certs installed:

 
{code:java}
[pd122@m7prodldap1 ~]$ echo | openssl s_client -connect m7shrdprodldp1.deutsche-boerse.de:636 2>/dev/null |head
CONNECTED(00000003)
---
Certificate chain
 0 s:/C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdprodldp1.deutsche-boerse.de
 i:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 1 s:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
---
[pd122@m7prodldap1 ~]$ echo | openssl s_client -connect m7shrdprodldp1.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates
subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdprodldp1.deutsche-boerse.de
issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
notBefore=Oct 19 00:00:00 2020 GMT
notAfter=Oct 26 23:59:59 2021 GMT
{code}
 

 
{code:java}
[pd122@m7prodldap1 ~]$ echo | openssl s_client -connect m7shrdprodldp2.deutsche-boerse.de:636 2>/dev/null |head
CONNECTED(00000003)
---
Certificate chain
 0 s:/C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdprodldp2.deutsche-boerse.de
 i:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 1 s:/C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 2 s:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
 i:/C=US/O=DigiCert Inc/OU=www.digicert.com/CN=DigiCert Global Root CA
---
[pd122@m7prodldap1 ~]$ echo | openssl s_client -connect m7shrdprodldp2.deutsche-boerse.de:636 2>/dev/null | openssl x509 -noout -subject -issuer -dates
subject= /C=DE/ST=Hessen/L=Eschborn/O=Deutsche Boerse Aktiengesellschaft/CN=m7shrdprodldp2.deutsche-boerse.de
issuer= /C=US/O=DigiCert Inc/CN=DigiCert SHA2 Secure Server CA
notBefore=Oct 19 00:00:00 2020 GMT
notAfter=Oct 26 23:59:59 2021 GMT
{code}
 ",,,,,,,,,,,,,,
excessive CPU usage on GlusterFS nodes,M7P-6950,100688,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,rehapav,rehapav,27/Sep/20 16:01,07/Oct/20 11:37,16/Sep/21 14:11,30/Sep/20 09:13,,7tops_sprint102,,,,,,,,7tops,,,,,,,"During DC Hausen maintenance cluster startup [~wm282]  identified (copy pasting slack thread(

*excessive CPU usage on GlusterFS nodes in M7*

 
{code:java}
PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND
 31488 root 16 -4 58412 2436 1480 R 53.2 0.0 17895:16 audisp-remote
 13632 nscd 20 0 1020484 2376 1572 S 40.5 0.0 13495:50 nscd
 31484 root 16 -4 55448 884 484 R 34.2 0.0 11351:09 auditd{code}
 

This is state it was before, SELinux  enabled.

Recommend next steps:

understand that SELinux gets enabled when you install GlusterFS, but from what I am reading it is not a must and it is not prerequisite to have SELinux enable

[https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/selinux_users_and_administrators_guide/chap-managing_confined_services-glusterfs] 

Can we disable SELinux (i.e. reboot servers) without disrupting production?

 

[Lambert Neky|https://app.slack.com/team/U40MPJ1EH]  [15 minutes ago|https://dbg-devops.slack.com/archives/G0184KUQ17X/p1601214286447400?thread_ts=1601213090.434700&cid=G0184KUQ17X]

Stop the instances on following hosts
{code:java}
m7eltsprodm7b1.deutsche-boerse.de.
 m7eltsprodm7b2.deutsche-boerse.de.
 m7eltsprodm7c1.deutsche-boerse.de.
 m7eltsprodm7c2.deutsche-boerse.de.
 m7epexprodm7b1.deutsche-boerse.de.
 m7epexprodm7b2.deutsche-boerse.de.
 m7hupxprodm7b1.deutsche-boerse.de.
 m7plpxprodm7b1.deutsche-boerse.de.
 m7plpxprodm7b2.deutsche-boerse.de.
 m7xrpmprodm7b1.deutsche-boerse.de.
 m7xrpmprodm7b2.deutsche-boerse.de.
 m7xsopprodm7b1.deutsche-boerse.de.
 m7xsopprodm7b2.deutsche-boerse.de.{code}
umount the journal filesystems and heapdump filesystems
 run the ""os_selinux.yaml"" ansible playbook on
 both ""m7shrdprodglfs1-2"" hosts
 stop the glusterfs services on ""m7shrdprodglfs1-2"" hosts
 reboot the  ""m7shrdprodglfs1-2"" hosts
 start the glusterfs services on ""m7shrdprodglfs1-2"" hosts
 mount the journal and heapdump filesystems on client hosts
 start the instances on client hosts (edited) 
  
 # It is not so tragical. No one client uses ""nfs"" mount. It means we can process the ""GlusterFS"" related servers one by one. Clients will (I hope) seamlessly switch from one host to other. We have to have kind of approval from operations.
 # Tobias just said me, he does not wish to run any of such operation now.
 # Why multiple ""GlusterFS"" hosts? I believe it self explaining. It is native technological feature.

 
 Following ""GlusterFS"" hosts suffer with this issue
{code:java}
xbsimuglfs2 | CHANGED | rc=0 | (stdout) Enforcing
 xbsimuglfs1 | CHANGED | rc=0 | (stdout) Enforcing
 m7shrdsimuglfs1 | CHANGED | rc=0 | (stdout) Enforcing
 m7shrdprodglfs1 | CHANGED | rc=0 | (stdout) Enforcing
 m7shrdprodglfs2 | CHANGED | rc=0 | (stdout) Enforcing{code}

 (edited)",,cv524,pw231,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGEXT-208,SERVICE-8146,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Closing after the discussion with Pavel Rehak.

Agreement after with [Steffen Englert |https://jira.deutsche-boerse.com/secure/ViewProfile.jspa?name=cs687], the operation will start on Wednesday 30.09.2020 at 10:00

For more details, please refer to https://jira.deutsche-boerse.com/browse/SYSENG-208",,,,,,,,,,,,,,,,,,,,,,,,30153600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyepj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100688,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"28/Sep/20 13:15;cv524;Created dedicated ""System Engineering"" task ticket SYSENG-208.

Separated steps to process all involved hosts are described in mentioned ticket.","28/Sep/20 13:47;cv524;[~rehapav]
First initial investigation tasks are finished.
According to my opinion, the process of ""SELINUX"" effective mode fix is possible to run.

h2. {color:#403294}Please, provide me formal approval for mentioned operation.{color}
{color:#403294}*Separately, or at once for all mentioned hosts.*{color}","28/Sep/20 15:05;rehapav;Dear [~cv524], thank you for your extensive analysis. 

If I understand it correctly, the proposed way to implement this change will guarantee that all our services will run flawlessly without any impact.

Can you confirm that?

What is effort (duration) estimation for sequence 1-8 from the linked ticket?","28/Sep/20 15:06;rehapav;[~MG726] can you plese explicitly provide review of this and linked SYSENG-208

from development point of view and get their approval.","28/Sep/20 16:50;cv524;[~rehapav]
Current situation of involved hosts shows, that it uses native ""high availability"" technological model.
The seamless switching of client host from one node to another in moment of disappearing/loosing of connection of first one, is tested several times.

Upon this, {color:#00875A}*I can say very sure*{color}, described {color:#00875A}*task will not impact running instances on client hosts*{color}. Anyway, I would prefer to have presence of {color:#00875A}*additional person, providing ""four eyes"" principle during execution*{color} of mentioned operations.

My expectation of duration is 30 minutes to complete whole cycle of operations from step 1 until 8 per environment.","29/Sep/20 09:53;pw231;[~rehapav] : I reviewed the possible impact and I can approve this on behalf of m7t-dev. So it can be performed without maintenance window on m7t side. 
(thanks [~cv524] for the explanation)
","29/Sep/20 10:04;rehapav;Approved for implementaton","02/Oct/20 09:56;cv524;Ticket SYSENG-208 is successfully completed
All involved ""GlusterFS"" servers declare expected values of CPU utilization
{noformat}####################################################################################
m7shrdsimuglfs1 | SUCCESS | rc=0 >>
Linux 3.10.0-693.17.1.el7.x86_64 (m7shrdsimuglfs1)      10/02/2020      _x86_64_        (2 CPU)

09:55:00 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:55:00 AM  all    0.14    0.00    0.12    0.02    0.00    0.00    0.00    0.00    0.00   99.72

xbsimuglfs1 | SUCCESS | rc=0 >>
Linux 3.10.0-862.el7.x86_64 (xbsimuglfs1)       10/02/2020      _x86_64_        (2 CPU)

09:55:07 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:55:07 AM  all    1.59    0.01    1.35    0.06    0.00    0.05    0.00    0.00    0.00   96.94

xbsimuglfs2 | SUCCESS | rc=0 >>
Linux 3.10.0-862.el7.x86_64 (xbsimuglfs2)       10/02/2020      _x86_64_        (2 CPU)

09:55:13 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:55:13 AM  all    1.32    0.00    1.10    0.05    0.00    0.03    0.00    0.00    0.00   97.50

m7shrdprodglfs1 | SUCCESS | rc=0 >>
Linux 3.10.0-693.17.1.el7.x86_64 (m7shrdprodglfs1)      10/02/2020      _x86_64_        (2 CPU)

09:55:20 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:55:20 AM  all    0.24    0.00    0.19    0.07    0.00    0.01    0.00    0.00    0.00   99.49

m7shrdprodglfs2 | SUCCESS | rc=0 >>
Linux 3.10.0-693.17.1.el7.x86_64 (m7shrdprodglfs2)      10/02/2020      _x86_64_        (2 CPU)

09:55:26 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
09:55:26 AM  all    0.26    0.00    0.22    0.09    0.00    0.00    0.00    0.00    0.00   99.43
####################################################################################{noformat}
",,,,,,,,,,,,,,,,,,,,
M7 - Running out of swap on database hosts,M7P-6948,100676,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,26/Sep/20 10:57,25/May/21 23:40,16/Sep/21 14:11,09/Feb/21 10:06,,11.0.0,7tops_sprint110,,,Database,,,,M7PRODOPS,OS,TechOps,,,,,"[~hw120] recommend us to do this changes for our M7 Database setup as well. 

##########################################################################

xbprodpdb1 is reporting high swap usage.

Consulted with Cybertec and got a recommendation on how to set kernel parameters correctly for swappiness in /etc/sysctl.conf:
{code:java}
vm.overcommit_memory = 2
vm.overcommit_ratio = 93
vm.swappiness = 1
{code}
based on this calculation they provided

memory_limit = swap + overcommit_ratio/100 * RAM
 # only commit as much memory as we have RAM
 # overcommit_ratio = ( (RAM - swap) / RAM ) * 100

[https://engineering.pivotal.io/post/virtual_memory_settings_in_linux_-_the_problem_with_overcommit]

According to the documentation from redhat, I calculated value to be...

[https://access.redhat.com/solutions/68612]

RHEL6, 7:
 allocatable memory=(swap size + ((RAM size - huge tlb size) * overcommit ratio / 100))

where ""allocatable memory"" should be less or equal than 100

 

Discussing with Cybertec proper values, ask how it could be influenced by configured hugepages.

 
 - Implement on Test db hosts, it was already configured on pdb hosts

 * 
 ** xbtestpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 ** xbtestdbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbinteedb1: 4.8GB RAM, 4GB SWAP,  overcommit_ratio = 16

 - Implement on Simu and perf db hosts, wait for a week
 ** xbsimupdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbsimudbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbsimuedb1: 8GB RAM, 2GB SWAP,  overcommit_ratio = 75
 ** xbperfpdb1-2: 96GB RAM, 4GB SWAP,  overcommit_ratio = 95
 - Implement on Prod and perf db hosts, wait for week
 ** xbprodpdb1-4: 128GB RAM, 8GB SWAP, overcommit_ratio = 93
 ** xbproddbr1-2: 16GB RAM, 4GB SWAP,  overcommit_ratio = 75
 ** xbprodedb1: 4.8GB RAM, 2GB SWAP,  overcommit_ratio = 58

 

 
{code:java}
cat << EOF > /etc/sysctl.d/98-db.conf
## Cybertec recommendations

# don't overcommit memory
vm.overcommit_memory = 2

# only commit as much memory as we have RAM
# overcommit_ratio = ( (RAM - swap) / RAM ) * 100
vm.overcommit_ratio = 95

# Minimize swapping
vm.swappiness = 1
EOF

# to apply the settings run
sysctl -p/etc/sysctl.d/98-db.conf
# OR
sysctl --system
{code}
 

 ",,cs687,,,,,,,,,,,,,,,,,,,XP-3575,,,,,,,,,,,,,,M7P-7728,M7P-7727,M7P-7726,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"all the configuration changes are done, more info´s are in the following tickets:
* M7P-7726 (TEST)
* M7P-7727 (SIMU)
* M7P-7728 (PROD)",,,,,,,,,,,,,,,,,,,,,,,,18921600,,,dm700,lw641,ox626,rehapav,sw455,,,,XP-2234,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz0wn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 110,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,,,,,,,,,,,,,,,,,,"see Change description
",,,,,,,,,,"{""issueId"":100676,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/21 08:28;cs687;ticket will be solved in the 3 separated tickets 
* M7P-7726
* M7P-7727
* M7P-7728","09/Feb/21 10:06;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
Harvester - Logs in Kibana,M7P-6933,100550,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,23/Sep/20 13:32,04/Nov/20 13:01,16/Sep/21 14:11,23/Oct/20 09:41,,6.11.66,7tops_sprint104,,,,,,,M7PRODOPS,S,,,,,,"h2. Context

We created a new component for continuous DB cleaning. It sends some data to Influx but also generates some logs (details about the queries in Debug mode for example).
h2. What is needed

We would like to have those logs in Kibana.

The logs are generated in log folder /<client>/logs/<client>-<environement>-harvester1 ( on Syt1 /shrd/logs/shrd-syt1-harvester1 ).

Only one file m7-<client>-<env>-harvester-1_standard_<datacenter(ixe/hau)>.log

 

Thanks !",,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Harvester logs are available in Kibana.,,,,,,,,,,,,,,,,,,,,,,,,28512000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyma7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100550,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"19/Oct/20 11:38;iu252;Created PR for harvester in ATE2:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2286","19/Oct/20 12:01;iu252;Another PR: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2287","20/Oct/20 17:32;iu252;Reverted both PRs:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2286
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2287

Created and merged https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2292

Redeployed filebeat on all existing harvest-instances:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1362/console
","20/Oct/20 17:33;iu252;[~fj021] please check kibana and confirm that this ticket can be closed.","21/Oct/20 12:17;fj021;Everything is looking good !",,,,,,,,,,,,,,,,,,,,,,,
deployment job for CD pipelines (stalker to cute),M7P-6926,100490,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cv179,pw231,pw231,22/Sep/20 11:47,13/Jan/21 11:31,16/Sep/21 14:11,17/Dec/20 12:30,,7tops_sprint108,,,,Stalker,,,,7tops,,,,,,,"Create a job that can deploy m7 components (at least stalker) to cute (and later simu and prod) from continuous delivery pipelines.

this is the cd pipeline: https://englobjci1.deutsche-boerse.de/job/Energy/view/M7%20Trading/job/m7-stalker-cd/",,cv179,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/20 12:27;cv179;image-2020-12-17-12-27-10-876.png;https://jira.deutsche-boerse.com/secure/attachment/91187/image-2020-12-17-12-27-10-876.png",,,,,,,,,,,,,,,sw455,,,,,,,,"Marking it resolved for now, further improvements or polishing should be handled as dedicated tasks (reduce elephants)",,,,,,,,,,,,,,,,,,,,,,,,23587200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3073,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzym8f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100490,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/20 12:27;cv179;the used ansible job has been extended:

!image-2020-12-17-12-27-10-876.png!","17/Dec/20 12:29;cv179;Ideally, we move to the CD pipeline jobs as they allow a much more reliable version interface, especially product versions. But it's not restricted to single components so usually we would want to deploy either with the FULL job or extend and use the seamless ""UPGRADE"" job.",,,,,,,,,,,,,,,,,,,,,,,,,,
Make customer portal changelog readable on smaller devices,M7P-6925,100479,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,dp007,ax460,ax460,22/Sep/20 09:44,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,Customer Portal,,,,7tops,,,,,,,"Customer portal changelog is hardly readable on smaller monitors (14"" laptop). See screenshot.
 # Red area with valuable content covers only about 15-20% screen size
 # Blue areas might be smaller. Using relative measures (like % not px to be small on small device and bigger on big device)
 # Purple area - footer might be at the bottom of page (when you scroll) and not fix (all time visible)
 # There is no complete list of all version visible (no possibility to scroll)

 ",,ax460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/20 09:44;ax460;portal_changelog.png;https://jira.deutsche-boerse.com/secure/attachment/87789/portal_changelog.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31017600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5772,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzcyf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100479,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create Core's DB user for Harvester,M7P-6908,100407,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,nn481,nn481,21/Sep/20 13:33,05/Jan/21 13:57,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"We need to create a core's database user/role for Harvester (application for cleaning database history tables).

User has to have access to perform DELETE and EXPLAIN statements on following tables:
{noformat}
CX_151_MESSAGES_HISTORY
CX_120_REMOTE_PUBLIC_TRADE_HISTORY
CX_211_CONTRACT_HISTORY
CX_441_CONTRACT_DELIVERY_AREA_STATE_HISTORY
CX_215_CONTRACT_CLOSING_PRICE_HISTORY
CX_101_ORDER_HISTORY
CX_262_LIMIT_HISTORY
CX_119_SETTLEMENT_HISTORY
CX_111_TRADE_HISTORY
{noformat}

User should have as minimal rights as possible for security reasons.

When tested, this user should be propagated to all envs where Harvester is supposed to run. As a test env we will use SYT1 where Harvester is already running. It currently uses enq user.",,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31104000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0wv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100407,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix M7 to XBID connection field in M7 environment overview,M7P-6904,100244,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,21/Sep/20 10:12,15/Dec/20 09:05,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"As a side effect of https://jira.deutsche-boerse.com/browse/SERVICE-8167

we identified that 

XSOP SIMU is connected to XBID CUTE PX and not

to XBID SIMU as stated in table

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#sob=true]

 
{code:java}
Temporary connection to XBID CUTE according to SERVICE-5572
 sob_rabbit_addr: ""m7shrdexteprx1:55250""
 
{code}
todo:
 - please fix the overview

 

additionally as of 13/10 also 
|m7t|xrpm|lipa|6.10.156|6.10.156|6.4.67|2.0.48| |1.0.35| | | |25.10.2020, 19:18:30|

is empty but should be CUTE",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31104000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyynz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100244,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change Log - deployment,M7P-6900,100221,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,dp007,dp007,18/Sep/20 11:43,23/Mar/21 17:31,16/Sep/21 14:11,22/Sep/20 14:44,,6.11.9,7tops_sprint15,,,Customer Portal,,,,M7PRODOPS,,,,,,,The goal is to implement a deployment job for the change log (deploy-change-log).,,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Change log deployment job to the Customer Portal was introduced.,,,,,,,,,,,,,,,,,,,,,,,,31363200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5442,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyd5j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100221,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change Log - template,M7P-6899,100220,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,18/Sep/20 11:40,23/Mar/21 17:30,16/Sep/21 14:11,18/Sep/20 11:41,,6.11.9,7tops_sprint15,,,Customer Portal,,,,M7PRODOPS,,,,,,,"prepare a template for the change log:


 * change log page contains tabs per major release (6.9, 6.10...) at /change-log/index.html
 * inside each tab there will be an iframe poiting to particular change log (one file per major release) /change-log/6.9/index.html ",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Visual part of the Change log in the Customer Portal is done.,,,,,,,,,,,,,,,,,,,,,,,,31363200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5442,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyd5b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100220,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove phone-call from AMQ sessions close OpsGenie Alerting,M7P-6898,100215,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,yq577,sw455,sw455,18/Sep/20 10:25,07/Oct/20 11:37,16/Sep/21 14:11,30/Sep/20 08:43,,6.11.36,7tops_sprint102,,,,,,,7tops,,,,,,,"I received a call today from OpsGenie ~09:00 for the alert:

*elts-prod] RabbitMQ sessions closed for user CXVPDV05*

 

The alert to phone-call is not necessary for this item, it should only create a ticket and log the event in OpsGenie. Further alerting is already covered by the critical threshold breaches. 

 

Please remove voice-call esclation from the alerting heirarchy in OpsGenie for this job

 

Discussion here:

[https://dbg-devops.slack.com/archives/G011BGYFMHD/p1600413098004900]

 

 ",,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/20 13:13;yq577;selfhealing.PNG;https://jira.deutsche-boerse.com/secure/attachment/88025/selfhealing.PNG",,,,,,,,,,,,,,,sw455,,,,,,,,issue fixed as described in comment,,,,,,,,,,,,,,,,,,,,,,,,30326400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyd3z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100215,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"29/Sep/20 13:14;yq577;Hello,

The changes are completed and this will stop the notification call but the ticket will be created whenever user has too many connection.

Implemented Steps

Opsgennie - Setting- Under Integration(Configured Integration ) - Selfhealing (API) , change the priority from P3-Moderate to P5-informational, Save the change

!selfhealing.PNG!

Thanks and Regards,

Sharad","30/Sep/20 08:43;yq577;issue fixed as described in comment",,,,,,,,,,,,,,,,,,,,,,,,,,
Restart Jenkins (Un-Installation Pending - Audit Log Plugin),M7P-6886,100150,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,16/Sep/20 14:46,22/Sep/20 23:39,16/Sep/21 14:11,16/Sep/20 18:05,,6.8.142,,,,,,,,M7PRODOPS,,,,,,,"Some days ago we made the experience that the file /var/lib/jenkins/logs/html/audit.html 

will just bloom up the var-Filesystem on Jenkins Host englobjci1
and causing some alerts during oncall. 

So we find out that a Uninstalled-pending plugin called [https://englobjci1.deutsche-boerse.de/pluginManager/installed] *Audit Login Plugin* will solve the issue. 

 

For that we need to restart the Jenkins, which is planned today after 6pm.
{code:java}
[root@englobjci1 html]# ls -rthl
total 70G
-rw-r--r-- 1 jenkins jenkins 70G Sep 16 14:44 audit.html
{code}",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"ldap certs were missing in /etc/pki/java/cacerts

added them to the java keytool file 

[root@englobjci1 jenkins]# keytool -keystore /etc/pki/java/cacerts -trustcacerts -importcert -alias ldapcert2 -file /var/lib/jenkins/ldap-cert2.pem

 

and restarted jenkins again. 

 ",,,,,,,,,,,,,,,,,,,,,,,,31449600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzya2f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,refer Change description,,,,,,,,,,"{""issueId"":100150,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Sep/20 17:40;cs687;restarted Jenkins 

*systemctl restart jenkins*
{code:java}
Caused: javax.naming.CommunicationException: englobldap2.oa.pnrad.net:636 [Root exception is javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target]
{code}","16/Sep/20 17:56;cs687;added the certificate for ldap1 and ldap2 and restart the jenkins again: 
{code:java}
[root@englobjci1 jenkins]# keytool -keystore /etc/pki/java/cacerts -trustcacerts -importcert -alias ldapcert2 -file /var/lib/jenkins/ldap-cert2.pem
Enter keystore password:
Owner: CN=englobldap2.oa.pnrad.net, OU=Energy IT, O=Deutsche Boerse AG, L=Eschborn, ST=Hessen, C=DE
Issuer: CN=englobldap2.oa.pnrad.net, OU=Energy IT, O=Deutsche Boerse AG, L=Eschborn, ST=Hessen, C=DE
Serial number: b1657ff1780c8b7a
Valid from: Mon Apr 09 16:04:43 CEST 2018 until: Fri Jun 24 16:04:43 CEST 2033
Certificate fingerprints:
         MD5:  45:FB:78:21:CB:76:F9:A2:B5:71:A4:D7:4E:72:89:D1
         SHA1: 4B:77:B1:A7:D2:EE:D5:67:6A:FA:B8:73:1A:B3:E7:95:BA:F1:C9:66
         SHA256: EB:D7:DE:EA:92:EE:20:4C:71:B1:AA:D2:DC:5E:9C:1F:13:50:C6:33:65:A8:F2:8C:FC:F1:E3:B4:29:5D:1F:28
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3Extensions:#1: ObjectId: 2.5.29.35 Criticality=false
AuthorityKeyIdentifier [
KeyIdentifier [
0000: 09 39 C3 88 FC F9 01 86   92 50 FC 31 E2 8F E4 82  .9.......P.1....
0010: 47 95 CB E8                                        G...
]
]#2: ObjectId: 2.5.29.19 Criticality=false
BasicConstraints:[
  CA:true
  PathLen:2147483647
]#3: ObjectId: 2.5.29.14 Criticality=false
SubjectKeyIdentifier [
KeyIdentifier [
0000: 09 39 C3 88 FC F9 01 86   92 50 FC 31 E2 8F E4 82  .9.......P.1....
0010: 47 95 CB E8                                        G...
]
]Trust this certificate? [no]:  yes
Certificate was added to keystore{code}
Jenkins is working again (/)","16/Sep/20 18:05;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Introduce more lightweight jenkins workers,M7P-6883,100115,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,HO764,HO764,16/Sep/20 09:57,17/Dec/20 15:26,16/Sep/21 14:11,30/Sep/20 14:25,,6.11.36,7tops_sprint102,,,,,,,7tops_comm,M7PRODOPS,,,,,,"Currently, for many jobs performed on jenkins, the regular worker specification is a bit overkill. Let's introduce some workers with lower specifications. Currently, we have

englobwkr 16GB RAM, 4 cores, 50 GB disk (t2.xlarge instance)

My proposal is to introduce a few nodes with t?.small, t?.medium, and t?.large specifications (one of each kind, I don't know whether to choose t2, t3, or something else), so that we can test our builds there and find the lowest specification which suits the needs of each job type. If I understand the pricing of aws correctly, there is not much sense to over-optimize by decreasing the disk size.

Even better, it would be also nice to provide a worker node with spot instance in addition to the current on-demand instances.",,cs687,HO764,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"create 3 docker t2.medium hosts with the name
 * englobwkr-shared-medium0.svc.dbgcloud.io
 * englobwkr-shared-medium1.svc.dbgcloud.io
 * englobwkr-shared-medium2.svc.dbgcloud.io

*with 1 Jenkins node behind each docker host with 4 build executors*
 * englobwkr-shared-medium0
 * englobwkr-shared-medium1
 * englobwkr-shared-medium2",,,,,,,,,,,,,,,,,,,,,,,,30240000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzycdr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 102,,,,,,,,,,,,,,,,,,,,,,,,,,see change of description,,,,,,,,,,"{""issueId"":100115,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/20 16:48;cs687;Created 2 small worker hosts

[englobwkr-small-test0.svc.dbgcloud.io|http://englobwkr-small-test0.svc.dbgcloud.io/]
[englobwkr-small-test1.svc.dbgcloud.io
|http://englobwkr-small-test1.svc.dbgcloud.io/]

typ2 with following resources: *t2.small, 2 GiB of Memory, 1 vCPUs, EBS only, 64-bit platform*

medium and large will come with a documentation here in the ticket tomorrow morning.  ","30/Sep/20 12:44;cs687;Created a t2.medium docker host [englobwkr-medium-test0.svc.dbgcloud.io|http://englobwkr-medium-test0.svc.dbgcloud.io/]

which is connected to 4 Jenkins-Nodes 
 * englobwkr-medium1
 * englobwkr-medium2
 * englobwkr-medium3
 * englobwkr-medium4

 

*how to deploy docker host:*
{code:java}
1.) connect to entestauto1
/home/ansible/steffen/energy.docker.hosts/terraform/medium-test

edit in the main.tf file the following parameters:
* module ""medium-test""
* ec2_instance_count = 1
* ec2_instance_hostname = ""englobwkr-medium-test""
* ec2_instance_type = ""t2.medium""

run the commands:

make init 
make plan
make apply 

#########################################################################

/home/ansible/steffen/energy.docker.hosts/ansible
add the hostgroup in the inventory inventory/aws_ec2.yml

groups:
    englobwkr_medium-test: ""'englobwkr-medium-test' in tags.InventoryGroup""

run the ansible-playbook 
ansible-playbook playbooks/englobwkr-medium.yml --limit ""englobwkr-medium-test*"" -u centos{code}
*how to create nodes in jenkins:*
{code:java}
https://englobjci1.deutsche-boerse.de/computer/new

just add new jenkins nodes by ""Copy Existing Node"" 

changed the following parameter:
* node-name: ....
* Labels: englobwkr-medium
* Start script: /var/lib/jenkins/start-instance.sh englobwkr-medium-test0
* Stop script: /var/lib/jenkins/stop-instance.sh englobwkr-medium-test0 &
* Host: englobwkr-medium-test0.svc.dbgcloud.io

and Launch the new created node and check in log if everything is working!

{code}","30/Sep/20 13:29;cs687;so [~pw231] and me agreed on it, that we will create *3 docker t2.medium hosts*with the name
* englobwkr-shared-medium0.svc.dbgcloud.io 
* englobwkr-shared-medium1.svc.dbgcloud.io 
* englobwkr-shared-medium2.svc.dbgcloud.io

*with 1 Jenkins node behind each docker host with 4 build executors*
* englobwkr-shared-medium0
* englobwkr-shared-medium1
* englobwkr-shared-medium2","30/Sep/20 14:25;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: PROD - RCA - EPEX - SERVICE-7996 (Several members facing forced logout issue),M7P-6877,100080,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,lw641,lw641,lw641,15/Sep/20 14:54,02/Dec/20 12:45,16/Sep/21 14:11,24/Nov/20 15:10,,6.11.103,7tops_sprint106,,,infrastructure,,,,7tops_comm,M7PRODOPS,,,,,,"Hi Team,

I need your help to fill RCA for the Sunday's network issues, please.

I've filled in the incident timeline and looking for help with:
 * incident description
 * root cause
 * short-term measures
 * long-term measures

Report is here:

https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/09%20Teams/04%20Operations/004%20Reporting/Incident%20Reporting/002%20-%20IN%20REVIEW/2020-08-30_SERVICE-7996.docx?d=we636eba5be104acaa706ac95dfbd48f5",,lw641,pn508,,,,,,,,,,,,,,,,,,SERVICE-8041,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,IR created and shared to the customer.,,,,,,,,EPEX,,,,,,Information Request,,,,,,,,,,25488000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzycdj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100080,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"16/Sep/20 08:16;pn508;[~lw641] can you shed more light on what is expected from the development team? Since M7T was up and running, I expect DBG netops/CenturyLink team to provide more insight on the following:
 * incident description - netops/CenturyLink
 * root cause - netops/CenturyLink
 * short-term measures - netops/CenturyLink
 * long-term measures - netops/CenturyLink or potential usage of Leased Lines","16/Sep/20 14:55;lw641;[~pn508] I've aske someone from @7tops to help with getting this information from our netops.

Once we have it, I would expect product team to review and, based on netops input, decide what should we propose to change in the product (if anything).

Thanks","06/Oct/20 10:34;sw455;Copy Paste from slack:

Alex
@Serhii Botulinskyi I sent you what I wrote the EPEX management, I think you can pull from that directly the incident description and root cause.
Short term measures were what? Maybe:
*""No direction intervention, after troubleshooting with networkign teams to ensure application and DBG networks without failure, only event monitoring was done until connectivity stablized"" *
And long term measures?
Are there any?

There only concrete idea I've heard on this was something @peter.pruchnerovic said, to monitor internal access to our application end points. But I'm not sure I'd ""offer"" this to EPEX in any report.
I think here that we are pretty clear that we don't take liability for 3P ISPs, and we don't intend to do so. So...
*Long term measures: No long term measures planned to address reliability of 3rd party internet service providers*

is this enough for you to get the report wrapped up?

-----
and the description from my original mail:


{quote}
The information you received, Denis, that this was a second DDoS attack targeting DBG is incorrect. There is nothing indicating any further attacks targeting DBG. All connectivity issues yesterday are clearly the result of the global connection failures caused by the internet provider CenturyLink. You can see more in the news, but the outages were widespread, impacting major services like Netflix, Hulu, & Cloudflare – Cloudflare reported a global 3.5% drop in network traffic.

There has been official ‘reason for outage’ information published from the ISP CenturyLink, sent to DBG:

Outage Start: August 30, 2020 10:00 GMT
Outage Stop: August 30, 2020 15:50 GMTRoot Cause: An offending flowspec announcement on the IP Network prevented BGP from establishing correctly, impacting client services.
Fix Action: The NOC deployed a configuration change to block the offending flowspec announcement, restoring stability to the BGP protocols.Reason for Outage (RFO) Summary: On August 30, 2020 10:00 GMT, CenturyLink identified an issue to be affecting users across multiple markets. The CDN Network Operations Center was engaged an upon initial investigations advised the interruption to services was caused by a configuration issue on the IP Network. The IP Network Operations Center (NOC) was engaged, and initial research identified that an offending flowspec announcement prevented Border Gateway Protocol (BGP) from establishing across multiple elements throughout the CenturyLink Network. The IP NOC deployed a global configuration change to block the offending flowspec announcement, which allowed BGP to begin to correctly establish. As the change propagated through the network, the IP NOC observed all associated service affecting alarms clearing and services returning to a stable state.This service impact has concluded. Due to the nature of this outage, it may be necessary to reset your services locally at your equipment. If after that action has been performed a service issue prevails, please contact the CenturyLink Repair Center for troubleshooting assistance.

In short, an erroneous flowspec rule was pushed at the ISP which caused widespread issues with IP resolution. It is unclear what triggered the erroneous flowspec rule at the ISP. If they publish some further postmortem it may be possible to find out more, but I would not expect much there. If you are interested, a very good write up of the issue was posted by Cloudflare

@t.rakow@epexspot.com and @'Denis BESNIER' – can you please review this event with focus on whether your Market Operations personnel are connecting to M7 via Internet or via our Leased Line services? DBG leased line services were not affected by this internet provider outage. Connectivity should be possible as well for the MO teams’ market admin. but I believe they are only connecting via internet currently. I would recommend you look into changing this if that’s correct.

{quote}","23/Nov/20 16:23;lw641;Report was updated and sent to [~pn508] for review. Will ask [~sw455] to approve afterwards.","24/Nov/20 14:10;sw455;my revision here
https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/09%20Teams/04%20Operations/004%20Reporting/Incident%20Reporting/002%20-%20IN%20REVIEW/2020-08-30_SERVICE-7996_atrevision.docx?d=w2776277e74454b74b68790eeab4573c2 ","24/Nov/20 15:08;lw641;Shared with customer and closing ticket now.",,,,,,,,,,,,,,,,,,,,,,
Setup vault values,M7P-6871,100068,97852,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,ax460,ax460,15/Sep/20 13:13,23/Sep/20 11:32,16/Sep/21 14:11,15/Sep/20 15:51,,7tops_sprint15,,,,,,,,7tops,,,,,,,"Please create following record *ops_user* in vault for *plpx-lipa,hupx-cute,xsop-cute,xrpm-lipa,elts-cute*
{code:java}
username:DBGOPS01
password:{{actual password of DBGOPS01}}{code}
see template and path (SYT1) [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/shrd/syt1/m7core/ops_user]",,ax460,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31536000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzycfj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 101 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":100068,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/20 15:50;pd122; 

passwords set according to [https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=10470502:]
{code:java}
secret/m7t/plpx/lipa/m7core/ops_user:
Key Value
--- -----
refresh_interval 768h0m0s
password ***
username DBGOPS01

secret/m7t/hupx/cute/m7core/ops_user:
Key Value
--- -----
refresh_interval 768h0m0s
password ***
username DBGOPS01

secret/m7t/xsop/cute/m7core/ops_user:
Key Value
--- -----
refresh_interval 768h0m0s
password ***
username DBGOPS01

secret/m7t/xrpm/lipa/m7core/ops_user:
Key Value
--- -----
refresh_interval 768h0m0s
password ***
username DBGOPS01

secret/m7t/elts/cute/m7core/ops_user:
Key Value
--- -----
refresh_interval 768h0m0s
password ***
username DBGOPS01
{code}
 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Prepare Jenkins Pipeline Job for M7 Capacity,M7P-6870,100062,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,15/Sep/20 12:31,30/Sep/20 11:26,16/Sep/21 14:11,29/Sep/20 13:54,,6.8.143,,,,,,,,M7PRODOPS,,,,,,,"For coming ansible deployments we need to prepare the Pipeline Job for Product M7 Capacity 

jenkins/Jenkinsfile_deploy_m7c_custom

in repo energy.automation.deployments",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/20 13:53;cs687;Jenkins-CD-m7c-shrd-dst1.txt;https://jira.deutsche-boerse.com/secure/attachment/88026/Jenkins-CD-m7c-shrd-dst1.txt",,,,,,,,,,,,,,,sw455,,,,,,,,"prepared the proper files 
 * [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/Jenkinsfile_deploy_m7c_custom]
 * [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/deploy_lib_m7c.groovy]

and run a test deployment for m7c-shrd-dst1 via Pipeline Job *Pipeline M7C deploy custom*",,,,,,,,,,,,,,,,,,,,,,,,30412800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzx73r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,7tops Sprint 102,,,,,,,,,,,,,,,,,,,,,,,,,see change description ,,,,,,,,,,"{""issueId"":100062,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"28/Sep/20 08:47;cs687;prepared pull-request for m7c custom Pipeline Job 

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1144/files]
needs to be checked from 7tops, roman","29/Sep/20 13:51;cs687;just run the deployment via CD Pipeline Job 
[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/view/M7C/job/M7C%20deploy%20custom/]
and i can confirm its working. Jenkins output is attached to the ticket. 

Ticket can be closed!

 ","29/Sep/20 13:54;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
update OS to RH 7.7 on all M7T VMs,M7P-6860,99994,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,rehapav,rehapav,rehapav,14/Sep/20 09:31,04/May/21 23:24,16/Sep/21 14:11,15/Apr/21 15:58,,7tops_sprint115,,,,aot,,,,7tops,,,,,,,"The development team has requested as part of the scope for M7T release 6.10 upgrade

of OS version to RH 7.7 on all the VMs.

 
||Environment||Core/Eqn||Rabbit||Apache||HAproxy||RE||CTPS||
|ELTS CTPB| | | done|done| | |
|ELTS ACUT| | | done|done| | |
|ELTS CUTE| planned|planned| done|done| done| |
|ELTS LIPA| | | done|done| | |
|ELTS SIMU| | | done|done| done| |
|EPEX ASIM|done|done|done| done|Done | |
|ELTS PROD| | | |done| | |
|HUPX PROD| | | |done| | |
|HUPX CUTE| done| done| done|done| | |
|HUPX ASIM| done|done| done|done| | |
|HUPX SIMU| done|done| done|done| | |
|BSP PROD| planned|planned| |done| | |
|BSP CUTE| done|done| done|done| | |
|BSP ASIM| done| done| done|done| | |
|BSP SIMU| done|done| done|done| | |
|PLPX TGE PROD| planned|planned| |done| | |
|PLPX TGE LIPA| done|done| done|done| | |
|PLPX TGE SIMU| | | done|done| | |
|XRPM OPCOM PROD| planned| planned| |done| | |
|XRPM LIPA| done| done| done|done| | |
|XRPM SIMU| done|done| done|done| | |
|SHRD SHOW| | | done|done| | |
|SHRD DST| | | done|done| | |
|SYS1| | | | | | |
|SYS2| | | | | | |
|SYS3| | | | | | |
| | | | | | | |
| | | | | | | |",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13219200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0x3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99994,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/21 15:58;rehapav;No more relevant, to be upgraded to RH 7.9 until 31/8/2021",,,,,,,,,,,,,,,,,,,,,,,,,,,
Is there LDAP entry for user PORTAL01 on icsc cute?,M7P-6850,99916,99765,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cf948,cf948,10/Sep/20 14:16,23/Sep/20 11:32,16/Sep/21 14:11,10/Sep/20 14:38,,7tops_sprint15,,,,,,,,M7PRODOPS,,,,,,,,,cf948,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31968000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzybin:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 100 (PS),X-Men Sprint 101,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99916,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/20 14:38;cs687;checked in on m7testldap1 
FYI: [~cf948]


{code:java}
[root@m7testldap1 ~]#  ldapsearch -H ldap://localhost:389 -x -D ""cn=Directory Manager"" -W -b ""ou=cute,ou=epex-app,o=M7,dc=energy,dc=test"" ""uid=PORTAL01""
Enter LDAP Password:
# extended LDIF
#
# LDAPv3
# base <ou=cute,ou=epex-app,o=M7,dc=energy,dc=test> with scope subtree
# filter: uid=PORTAL01
# requesting: ALL
#
# PORTAL01, cute, epex-app, M7, energy.test
dn: uid=PORTAL01,ou=cute,ou=epex-app,o=M7,dc=energy,dc=test
uid: PORTAL01
sn: trader
cn: trader
objectClass: inetOrgPerson
objectClass: organizationalPerson
objectClass: person
objectClass: top
userPassword:: XXXX
# search result
search: 2
result: 0 Success
# numResponses: 2
# numEntries: 1
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
Job for CT snapshot version deployment,M7P-6843,99894,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,dp007,dp007,10/Sep/20 11:24,07/Oct/20 11:37,16/Sep/21 14:11,25/Sep/20 16:58,,6.11.26,7tops_sprint102,,,Customer Portal,,,,M7PRODOPS,,,,,,,"Create a job called *deploy-comtrader-m7-snapshot* at [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Customer-Portal/]

Fields:
 * ct_deploy_bucket [combo-box]
 * ct_deploy_cust [combo-box]
 * ct_deploy_env [combo-box]
 * ct_deploy_branch [combo-box with pre-filled comtrader branches]

This job will act similar to deploy-comtrader-m7 job but:
 * it will use comtrader branch instead of git tag/label
 * it will read the version from pom.xml (tag version)",,dp007,fh971,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,30672000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5442,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzya27:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99894,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/20 16:59;qo288;changes implemented in https://github.deutsche-boerse.de/dev/m7.customer.portal/blob/master/jenkins/Jenkinsfile-deploy-m7-snapshot",,,,,,,,,,,,,,,,,,,,,,,,,,,
add kernel version to M7 version overview page,M7P-6821,99695,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,rehapav,rehapav,07/Sep/20 11:28,09/Sep/20 11:20,16/Sep/21 14:11,07/Sep/20 14:28,,6.10.217,7tops_sprint14,,,,,,,7tops,,,,,,,"Please include somewhere into our Version overview page

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#os=true]

also specific version of installed Kernel

 ",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"[https://github.deutsche-boerse.de/dev/energy.automation.deployments/commit/5ec5205f06fe1edc8b120b44e907372636564c58]

 

next update will show kernel versions for all instances.",,,,,,,,,,,,,,,,,,,,,,,,32313600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzya2v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99695,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Report for August 2020,M7P-6819,99655,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,oh856,oh856,oh856,04/Sep/20 11:14,23/Sep/20 11:32,16/Sep/21 14:11,11/Sep/20 14:31,,6.11.9,7tops_sprint15,,,,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 EPEX ASIM| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 HUPX| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 XSOP| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 TGE| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 OPCOM| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| M7 AUCTION| 2020-09-04 - Volkan| 2020-09-09 - Volkan|
| ICS / Swissgrid| 2020-09-11 - Volkan| 2020-09-11 - Volkan|

[https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2020%2D08&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D]

Greenlight requesting email should be sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Martin Komberec <martin.komberec@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>; Volkan Eymir Akcora <volkan.eymir.akcora@deutsche-boerse.com>;{code}",,oh856,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,The SLA reports have been distributed to the clients,,,,,,,,,,,,,,,,,,,,,,,,32572800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzya1z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99655,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create new environment ELTS ASIM,M7P-6818,99650,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,iu252,rehapav,rehapav,04/Sep/20 10:00,28/Jan/21 08:53,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"As agreed in SERVICE-6348 we are going to *rename* EPEX ASIM to ELTS ASIM.

As we do not support the rename function, we agreed to implement this change per partes.
 # (this ticket) create new environment ETLS ASIM

From a sizing and connectivity perspective is must be copy of actual EPEX ASIM.

 ",,iu252,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,19958400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzz0xb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99650,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"04/Sep/20 11:36;iu252;Requested new VMs: https://jira.deutsche-boerse.com/browse/SYSENG-178","10/Sep/20 08:04;iu252;Created vault entries: https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/elts/asim/ ","11/Sep/20 11:22;iu252;DB Setup.

{noformat}
[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_patroni.yml --tags deploy --limit m7t-elts-asim-pdb* -b  -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [deploy patroni resources to an environment] *************************************************************************************************

TASK [Gathering Facts] ****************************************************************************************************************************
ok: [m7t-elts-asim-pdb-async4]
ok: [m7t-elts-asim-pdb-async3]
ok: [m7t-elts-asim-pdb-async2]
ok: [m7t-elts-asim-pdb-async1]

TASK [patroni : install patroni for RedHat] *******************************************************************************************************
ok: [m7t-elts-asim-pdb-async1]
ok: [m7t-elts-asim-pdb-async3]
ok: [m7t-elts-asim-pdb-async2]
ok: [m7t-elts-asim-pdb-async4]

TASK [patroni : install postgresql package] *******************************************************************************************************
ok: [m7t-elts-asim-pdb-async1] => (item=postgresql11)
ok: [m7t-elts-asim-pdb-async2] => (item=postgresql11)
ok: [m7t-elts-asim-pdb-async3] => (item=postgresql11)
ok: [m7t-elts-asim-pdb-async4] => (item=postgresql11)
ok: [m7t-elts-asim-pdb-async1] => (item=postgresql11-server)
ok: [m7t-elts-asim-pdb-async2] => (item=postgresql11-server)
ok: [m7t-elts-asim-pdb-async3] => (item=postgresql11-server)
ok: [m7t-elts-asim-pdb-async4] => (item=postgresql11-server)
ok: [m7t-elts-asim-pdb-async1] => (item=postgresql11-contrib)
ok: [m7t-elts-asim-pdb-async3] => (item=postgresql11-contrib)
ok: [m7t-elts-asim-pdb-async2] => (item=postgresql11-contrib)
ok: [m7t-elts-asim-pdb-async4] => (item=postgresql11-contrib)
ok: [m7t-elts-asim-pdb-async1] => (item=postgresql11-debuginfo)
ok: [m7t-elts-asim-pdb-async3] => (item=postgresql11-debuginfo)
ok: [m7t-elts-asim-pdb-async2] => (item=postgresql11-debuginfo)
ok: [m7t-elts-asim-pdb-async4] => (item=postgresql11-debuginfo)
ok: [m7t-elts-asim-pdb-async1] => (item=expect)
ok: [m7t-elts-asim-pdb-async3] => (item=expect)
ok: [m7t-elts-asim-pdb-async4] => (item=expect)
ok: [m7t-elts-asim-pdb-async2] => (item=expect)

TASK [patroni : LVM Volumes creation data] ********************************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item={'lv': 'data', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async2] => (item={'lv': 'data', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async3] => (item={'lv': 'data', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async4] => (item={'lv': 'data', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async1] => (item={'lv': 'log', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async2] => (item={'lv': 'log', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async3] => (item={'lv': 'log', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async4] => (item={'lv': 'log', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async1] => (item={'lv': 'backup', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async2] => (item={'lv': 'backup', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async3] => (item={'lv': 'backup', 'size': '5g'})
changed: [m7t-elts-asim-pdb-async4] => (item={'lv': 'backup', 'size': '5g'})

TASK [patroni : Filesystem creation] **************************************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item=data)
changed: [m7t-elts-asim-pdb-async2] => (item=data)
changed: [m7t-elts-asim-pdb-async3] => (item=data)
changed: [m7t-elts-asim-pdb-async4] => (item=data)
changed: [m7t-elts-asim-pdb-async1] => (item=log)
changed: [m7t-elts-asim-pdb-async2] => (item=log)
changed: [m7t-elts-asim-pdb-async3] => (item=log)
changed: [m7t-elts-asim-pdb-async4] => (item=log)
changed: [m7t-elts-asim-pdb-async1] => (item=backup)
changed: [m7t-elts-asim-pdb-async2] => (item=backup)
changed: [m7t-elts-asim-pdb-async4] => (item=backup)
changed: [m7t-elts-asim-pdb-async3] => (item=backup)

TASK [patroni : Mountpoint definition] ************************************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item=data)
changed: [m7t-elts-asim-pdb-async2] => (item=data)
changed: [m7t-elts-asim-pdb-async3] => (item=data)
changed: [m7t-elts-asim-pdb-async4] => (item=data)
changed: [m7t-elts-asim-pdb-async1] => (item=log)
changed: [m7t-elts-asim-pdb-async2] => (item=log)
changed: [m7t-elts-asim-pdb-async3] => (item=log)
changed: [m7t-elts-asim-pdb-async4] => (item=log)
changed: [m7t-elts-asim-pdb-async1] => (item=backup)
changed: [m7t-elts-asim-pdb-async2] => (item=backup)
changed: [m7t-elts-asim-pdb-async3] => (item=backup)
changed: [m7t-elts-asim-pdb-async4] => (item=backup)

TASK [patroni : Filesystem mount definition in ""/etc/fstab""] **************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item=data)
changed: [m7t-elts-asim-pdb-async2] => (item=data)
changed: [m7t-elts-asim-pdb-async3] => (item=data)
changed: [m7t-elts-asim-pdb-async4] => (item=data)
changed: [m7t-elts-asim-pdb-async1] => (item=log)
changed: [m7t-elts-asim-pdb-async2] => (item=log)
changed: [m7t-elts-asim-pdb-async3] => (item=log)
changed: [m7t-elts-asim-pdb-async1] => (item=backup)
changed: [m7t-elts-asim-pdb-async4] => (item=log)
changed: [m7t-elts-asim-pdb-async2] => (item=backup)
changed: [m7t-elts-asim-pdb-async3] => (item=backup)
changed: [m7t-elts-asim-pdb-async4] => (item=backup)

TASK [patroni : change fs permissions] ************************************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item=data)
changed: [m7t-elts-asim-pdb-async2] => (item=data)
changed: [m7t-elts-asim-pdb-async3] => (item=data)
changed: [m7t-elts-asim-pdb-async4] => (item=data)
changed: [m7t-elts-asim-pdb-async1] => (item=log)
changed: [m7t-elts-asim-pdb-async2] => (item=log)
changed: [m7t-elts-asim-pdb-async3] => (item=log)
changed: [m7t-elts-asim-pdb-async4] => (item=log)
changed: [m7t-elts-asim-pdb-async1] => (item=backup)
 [WARNING]: Consider using the file module with owner rather than running chown.  If you need to use command because file is insufficient you can
add warn=False to this command task or set command_warnings=False in ansible.cfg to get rid of this message.

changed: [m7t-elts-asim-pdb-async3] => (item=backup)
changed: [m7t-elts-asim-pdb-async4] => (item=backup)
changed: [m7t-elts-asim-pdb-async2] => (item=backup)

TASK [patroni : create patroni config folder] *****************************************************************************************************
changed: [m7t-elts-asim-pdb-async1] => (item=/etc/patroni_m7teltsasimasync)
changed: [m7t-elts-asim-pdb-async2] => (item=/etc/patroni_m7teltsasimasync)
changed: [m7t-elts-asim-pdb-async3] => (item=/etc/patroni_m7teltsasimasync)
changed: [m7t-elts-asim-pdb-async4] => (item=/etc/patroni_m7teltsasimasync)

TASK [patroni : copy patroni.yml template] ********************************************************************************************************
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async3]
changed: [m7t-elts-asim-pdb-async4]

TASK [patroni : copy patroni service file] ********************************************************************************************************
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async3]
changed: [m7t-elts-asim-pdb-async4]

TASK [patroni : enable and restart patroni service] ***********************************************************************************************
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async3]
changed: [m7t-elts-asim-pdb-async4]

TASK [patroni : giving the process time to start] *************************************************************************************************
ok: [m7t-elts-asim-pdb-async1]
ok: [m7t-elts-asim-pdb-async2]
ok: [m7t-elts-asim-pdb-async3]
ok: [m7t-elts-asim-pdb-async4]

TASK [patroni : allow postgres user to read journal] **********************************************************************************************
ok: [m7t-elts-asim-pdb-async2]
ok: [m7t-elts-asim-pdb-async1]
ok: [m7t-elts-asim-pdb-async3]
ok: [m7t-elts-asim-pdb-async4]

TASK [patroni : check which patroni-node is running as MASTER/LEADER] *****************************************************************************
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async4]
changed: [m7t-elts-asim-pdb-async3]

TASK [patroni : debug] ****************************************************************************************************************************
ok: [m7t-elts-asim-pdb-async1] => {}

MSG:

m7simupdb1 is runing as Leader: 1

ok: [m7t-elts-asim-pdb-async2] => {}

MSG:

m7simupdb2 is runing as Leader: 0

ok: [m7t-elts-asim-pdb-async3] => {}

MSG:

m7simupdb3 is runing as Leader: 0

ok: [m7t-elts-asim-pdb-async4] => {}

MSG:

m7simupdb4 is runing as Leader: 0


TASK [patroni : create ADMIN/TASK_SCRIPTS directory] **********************************************************************************************
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async3]
changed: [m7t-elts-asim-pdb-async4]

TASK [patroni : copy template RSYNC_WAL.sh] *******************************************************************************************************
changed: [m7t-elts-asim-pdb-async1]
changed: [m7t-elts-asim-pdb-async2]
changed: [m7t-elts-asim-pdb-async3]
changed: [m7t-elts-asim-pdb-async4]

TASK [patroni : create ADMIN/INSTALL directory] ***************************************************************************************************
skipping: [m7t-elts-asim-pdb-async2]
skipping: [m7t-elts-asim-pdb-async3]
skipping: [m7t-elts-asim-pdb-async4]
changed: [m7t-elts-asim-pdb-async1]

TASK [patroni : copy templates for admin scripts] *************************************************************************************************
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})

TASK [patroni : execute install scripts] **********************************************************************************************************
skipping: [m7t-elts-asim-pdb-async1] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async2] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async3] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'drop_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/001_DROP_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
skipping: [m7t-elts-asim-pdb-async4] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_database.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/010_CREATE_DATABASE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_schema.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/020_CREATE_SCHEMA.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'alter_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/030_ALTER_ROLE.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'grant_and_alter_default_privileges.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sql'})
changed: [m7t-elts-asim-pdb-async1] => (item={'src': 'create_netbackup_role.sql.j2', 'dest': '/var/lib/pgsql_m7teltsasimasync/ADMIN/INSTALL/035_CREATE_NETBACKUP_ROLE.sql'})

PLAY RECAP ****************************************************************************************************************************************
m7t-elts-asim-pdb-async1   : ok=21   changed=15   unreachable=0    failed=0
m7t-elts-asim-pdb-async2   : ok=18   changed=12   unreachable=0    failed=0
m7t-elts-asim-pdb-async3   : ok=18   changed=12   unreachable=0    failed=0
m7t-elts-asim-pdb-async4   : ok=18   changed=12   unreachable=0    failed=0

[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$
{noformat}

Patroni Cluster is up and running:

{noformat}
[root@m7simupdb2 ~]#  patronictl -c /etc/patroni_m7teltsasimasync/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsasimasync | m7simupdb1 | 10.139.58.176:24048 | Leader | running |  1 |         0 |
| m7teltsasimasync | m7simupdb2 | 10.139.58.175:24048 |        | running |  1 |         0 |
| m7teltsasimasync | m7simupdb3 | 10.139.58.174:24048 |        | running |  1 |         0 |
| m7teltsasimasync | m7simupdb4 | 10.139.58.173:24048 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
[root@m7simupdb2 ~]#
{noformat}
","11/Sep/20 14:14;iu252;Server certificates.

Created PR
https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/15

Generated csr
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/67/console

IT-Request created 
1A2762

Mail sent to ssl-admin.","22/Sep/20 08:30;iu252;LoadBalancer config for Reporting Engine requested via ISR (91018257).
https://sapffp-f5.deutsche-boerse.de/flp#ZIB_ISR_REQ_semobj-create&/ISRRequests/f9661a1a-8f01-1eda-bf93-90066ff8824d","22/Sep/20 08:50;iu252;LoadBalancer config for ELTS ASIM requested via ISR (91018261).
https://sapffp-f5.deutsche-boerse.de/flp#ZIB_ISR_REQ_semobj-create&/ISRRequests/f9661a1a-081e-1eda-bf93-f6f9e00d0244","24/Sep/20 15:53;iu252;Upgraded OS: 

{noformat}
[root@m7eltsasimm7b1 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimm7b1 ~]#
{noformat}

{noformat}
[root@m7eltsasimm7b2 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimm7b2 ~]#
{noformat}

{noformat}
[root@m7eltsasimamq1 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimamq1 ~]#
{noformat}

{noformat}
[root@m7eltsasimamq2 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimamq2 ~]#
{noformat}

{noformat}
[root@m7eltsasimamq3 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimamq3 ~]#
{noformat}

{noformat}
[root@m7eltsasimamq4 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimamq4 ~]#
{noformat}

{noformat}
[root@m7eltsasimamq5 ~]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.7 (Maipo)
[root@m7eltsasimamq5 ~]#
{noformat}","25/Sep/20 12:46;iu252;Deployed RabbitMQ:

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_custom/797/console

Cluster Status:

{noformat}
[rabbitmq@m7eltsasimamq1 elts]$ rabbitmqctl cluster_status
Cluster status of node elts-asim-amq1@m7eltsasimamq1 ...
Basics

Cluster name: elts-asim-amq1@m7eltsasimamq1.deutsche-boerse.de

Disk Nodes

elts-asim-amq1@m7eltsasimamq1
elts-asim-amq2@m7eltsasimamq2
elts-asim-amq3@m7eltsasimamq3
elts-asim-amq4@m7eltsasimamq4
elts-asim-amq5@m7eltsasimamq5

Running Nodes

elts-asim-amq1@m7eltsasimamq1
elts-asim-amq2@m7eltsasimamq2
elts-asim-amq3@m7eltsasimamq3
elts-asim-amq4@m7eltsasimamq4
elts-asim-amq5@m7eltsasimamq5

Versions

elts-asim-amq1@m7eltsasimamq1: RabbitMQ 3.8.7 on Erlang 22.1
elts-asim-amq2@m7eltsasimamq2: RabbitMQ 3.8.7 on Erlang 22.1
elts-asim-amq3@m7eltsasimamq3: RabbitMQ 3.8.7 on Erlang 22.1
elts-asim-amq4@m7eltsasimamq4: RabbitMQ 3.8.7 on Erlang 22.1
elts-asim-amq5@m7eltsasimamq5: RabbitMQ 3.8.7 on Erlang 22.1

{noformat}
","28/Sep/20 12:18;iu252;Created LDAP-three elts-asim (copy from epex-asim).","28/Sep/20 15:17;iu252;Proxy configuration done:

{noformat}
[root@m7shrdexteprx1 xinetd.d]# cp epex-asim-ixe elts-asim-ixe
[root@m7shrdexteprx1 xinetd.d]# vi elts-asim-ixe
[root@m7shrdexteprx1 xinetd.d]# grep 55260 *
elts-asim-ixe:  port = 55260
[root@m7shrdexteprx1 xinetd.d]# systemctl reload xinetd.service
[root@m7shrdexteprx1 xinetd.d]#
{noformat}


{noformat}
[root@m7shrdexteprx2 xinetd.d]# cp epex-asim-hau elts-asim-hau
[root@m7shrdexteprx2 xinetd.d]# vi elts-asim-hau
[root@m7shrdexteprx2 xinetd.d]# grep 55260 *
elts-asim-hau:        port = 55260
[root@m7shrdexteprx2 xinetd.d]# systemctl reload xinetd.service
[root@m7shrdexteprx2 xinetd.d]#
{noformat}
","18/Dec/20 10:12;iu252;Imported server certificates to vault: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/B.%20Import%20Cert%20to%20Vault%20(Ansible%20Deployment)/75/console","28/Jan/21 08:53;iu252;merged after approval https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2516",,,,,,,,,,,,,,,,
dst2.shrd.m7.deutsche-boerse.com expired - renew,M7P-6813,99606,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,03/Sep/20 12:54,09/Sep/20 11:20,16/Sep/21 14:11,08/Sep/20 13:54,,6.10.217,7tops_sprint14,,,,,,30/Sep/20 00:00,M7PRODOPS,,,,,,,"with the vmt ticket https://vmt.deutsche-boerse.de/browse/NXP-11625
we got informed that we have to renew the server-certificate for 
dst2.shrd.m7.deutsche-boerse.com

after checking the proper hosts i noticed that for the second url, dst1.shrd.m7.deutsche-boerse.com will be used which is still available until next year 2021

[root@m7shrdexteweb2 conf.d]# pwd
*/shrd/shrd-dst1-app-web2/config/conf.d/epex.conf*
{code:java}
SLCertificateFile /shrd/ssl/dst1_shrd_m7_deutsche-boerse_com_cert.crt
ServerName      dst1.shrd.m7.deutsche-boerse.com:60600
{code}

{code:java}
[root@m7shrdexteweb2 ssl]# ls -all | grep dst
-rw-r--r--   1 apache apache  8428 Feb 19  2019 dst1_shrd_m7_deutsche-boerse_com_cert.crt
-rw-r--r--   1 apache apache  1679 Feb 19  2019 dst1.shrd.m7.deutsche-boerse.com_private.key
-rw-rw-r--   1 apache apache  2788 Jul  9  2018 dst2_shrd_m7_deutsche-boerse_com_cert.crt
-rw-rw-r--   1 apache apache  1675 Jun 28  2018 dst2.shrd.m7.deutsche-boerse.com_private.key
{code}

so indeed the second cert is expired 
{code:java}
[root@m7shrdexteweb2 ssl]# openssl x509 -in dst2_shrd_m7_deutsche-boerse_com_cert.crt -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            ce:99:fa:dd:db:26:dd:e1:a2:13:56:94:d8:73:cb:a7
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jun 29 00:00:00 2018 GMT
            Not After : Jun 28 23:59:59 2020 GMT
{code}

i would recommend to request 1 new certificate which includes both issuer 
* dst1.shrd.m7.deutsche-boerse.com
* dst2.shrd.m7.deutsche-boerse.com

and replace the certs once they are available 





",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed m7t-shrd-dst1-web and m7t-shrd-dst1-rep instances with ansible 

two pull-requests were necessary: 
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2131/files
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2132/files

and the following ansible-deployment jobs: 
* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*shrd-dst1-app-haproxy*"" --tags stop,clean,deploy,start -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*shrd-dst1-app-web*"" --tags stop,clean,deploy,start -k -K -b
* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*shrd-dst1-app-haproxy*"" --tags certs -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*shrd-dst1-app-web*"" --tags certs -k -K -b

deleted the old dir´s of shrd-dst-app-web1/2 and shrd-dst-app-rep1/2 ",,,,,,,,,,,,,,,,,,,,,,,,32227200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy4h3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"certs are replaced:

https://dst1.shrd.m7.deutsche-boerse.com:60600/intraday/
https://dst2.shrd.m7.deutsche-boerse.com:60600/intraday/",,,,,,,,,,"{""issueId"":99606,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/20 09:37;cs687;added in the vars.yml of the certificate repo the following lines: 
https://github.deutsche-boerse.de/dev/energy.automation.certificate/blob/tuan/vars.yml

{code:java}
  m7t:
    shrd:
      dst1:
        - ""dst1.shrd.m7.deutsche-boerse.com""
        - ""dst2.shrd.m7.deutsche-boerse.com""
{code}

and run the jenkins job *Project A. Generate CSR (Ansible Deployment)*
afterwards we have new entries in vault 

{code:java}
secrets
/
secret
/
m7t
/
shrd
/
dst1
/
cert

Request_dst1.shrd.m7.deutsche-boerse.com
Request_dst2.shrd.m7.deutsche-boerse.com
{code}

Created IT-Service Request with the ID  *6B3230* and forwarded the email to the ssl-admin´s 
","08/Sep/20 11:07;cs687;Uploaded the new certificate with the Jenkins Job:
*Project B. Import Cert to Vault (Ansible Deployment)*

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2131/files
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2132/files

we figured out that shrd-dst1-app-web/haproxy were not deployed with ansible before.
For that we run the proper ansible-commands and replaced the certs with tag *cert*

* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*shrd-dst1-app-haproxy*"" --tags stop,clean,deploy,start -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*shrd-dst1-app-web*"" --tags stop,clean,deploy,start -k -K -b 

* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*shrd-dst1-app-haproxy*"" --tags certs -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*shrd-dst1-app-web*"" --tags certs -k -K -b

","08/Sep/20 13:54;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
Raise the look-through limit,M7P-6802,99502,98546,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,fj021,fj021,01/Sep/20 12:23,23/Sep/20 11:32,16/Sep/21 14:11,18/Sep/20 16:19,,7tops_sprint15,,,,,,,,7tops,,,,,,,Raising the look-through limit from it's default 2000 to at least 5000.,,fj021,pd122,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31017600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy97r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 98 (PS),Schmetterling Sprint 99 (PS),X-Men Sprint 100 (PS),X-Men Sprint 101,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99502,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Sep/20 12:26;pd122;instead of rising server wide setting for _nsslapd-sizelimit_ in _cn=config,cn=ldbm database,cn=plugins,cn=config_, I suggest to try to raise _nsSizeLimit_ on a _binddn_ (which should have the same desired effect but consume less overall resources as well as only affect specific environments)

I have updated the setup for ELTS CTPB:
{code:java}
dn: uid=elts-app-ctpb-adm,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
nsSizeLimit: 5000{code}
Could  you verify it, please? ","08/Sep/20 12:53;fj021;[~vp223] Are you able to test this or should we ask client to do the test ?","08/Sep/20 13:25;vp223;We can test it on our own however what are the parameters for the password expiry right now on CTPB? Just let me know how you want to test it and I agree with the customer.","08/Sep/20 14:26;fj021;So basically we concluded that we can look at the logs tomorrow morning.

If it is fixed we shouldn't see the error we've been saying every day during the execution of the job. 
 [https://kibana.energy.svc.dbgcloud.io/goto/86843ba5b9c5b7c3bce590cf381f8429]

The execution is daily at 4;20","09/Sep/20 08:16;fj021;Sadly no surprise there, like the manual test we performed yesterday with [~pd122] the job failed also : https://kibana.energy.svc.dbgcloud.io/goto/0fb637bae54af24d0a6bc0b79ef67333","11/Sep/20 15:42;pd122;was able to get successful result (empty string, no error) after setting *nsLookThroughLimit: 100000*  (not really sure why such a high setting is needed with 4571 DNs, perhaps it is related to the total number of attributes in the sub-tree) for _ELTS CTPB bind user uid=elts-app-ctpb-adm,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test_, could you test it on the app level?

 ","11/Sep/20 15:51;fj021;Like discussed on DMs, let's wait for the job to trigger and check the results on Monday.","14/Sep/20 08:22;fj021;Hey [~pd122],

Good news, no failures since 11/09.

[https://kibana.energy.svc.dbgcloud.io/goto/86843ba5b9c5b7c3bce590cf381f8429]

Test is a success (/)","18/Sep/20 16:19;pd122;I have now removed that *nsLookThroughLimit* limit set  for CTPB binddn (_uid=elts-app-ctpb-adm,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test_) set earlier as it is no longer needed  with current amount of DNs.","22/Sep/20 10:31;pd122;In light of number of users in production (nearing 3900) I have reinstated said limit on CTPB and set it on SYT1 and PROD environments as well.  Also initiated discussion with EPEX regarding their production numbers.",,,,,,,,,,,,,,,,,,
[SPF] Infrastructure Security Standard M7 OPS,M7P-6768,99236,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,sw455,cs687,cs687,25/Aug/20 13:09,30/Jun/21 12:13,16/Sep/21 14:11,23/Jun/21 10:07,,7tops_sprint120,,,,,,,,M7PRODOPS,x-product,,,,,,"The goal of this task is to provide a list of gaps in respect to Infrastructure Security Standard Compliance

The latest version of the standards is available on:

https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0823%2F400%5FPublication%2FSecurity%20Policy%20Framework%2F30%5FStandards&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6&View=%7BC85F9C0B%2D376E%2D4AE7%2D89B7%2DABE540693D5D%7D

A short overview of the standard:

 * Relevant points (and everything has to be documented):
 ** Document all processes of the whole infrastructure lifecycle incl. change management and patch management process and create operating handbooks (+evidence that you follow them)
 ** Compliance with mandatory control (SSD/security concept) requirements, e.g.
 *** secure log-on procedures/password management, event-depending access control)
 *** management of technical vulnerabilities, problem and incident management process (vulnerabilities: vmt-tickets etc., confluence) ",,cs687,PB446,sw455,,,,,,,,,,,,,,,M7P-4017,,,,,,,,,,,,,,,,XP-2990,ESO-305,,,,,"31/Aug/20 16:13;cs687;IS Infrastructure Security Standard.xlsx;https://jira.deutsche-boerse.com/secure/attachment/87065/IS+Infrastructure+Security+Standard.xlsx","31/Aug/20 16:13;cs687;Operational Manual_1.0.docx;https://jira.deutsche-boerse.com/secure/attachment/87066/Operational+Manual_1.0.docx",,,,,,,,,,,,,,sw455,,,,,,,,"Matrix to itemized all necessary ""operating processes"" created for ESO's overview",,,,,,,,,,,,,,,,,,,,,,,,7344000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzmwrj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99236,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"31/Aug/20 16:13;cs687;Feedback from [~ne232]
 [^IS Infrastructure Security Standard.xlsx]  [^Operational Manual_1.0.docx] 
{code:java}
•	Document all processes of the whole infrastructure lifecycle incl. change management and patch management process and create operating handbooks (+evidence that you follow them) – s. attached example. GIS told me, that Corporate IT has complete manuals regarding the IS requirements.
•	Compliance with mandatory control (SSD/security concept) requirements, (please see here the attached Excel file, further information can be found in the Infrastructure Standard) e.g.
•	secure log-on procedures/password management, event-depending access control)
•	management of technical vulnerabilities, problem and incident management process (vulnerabilities: vmt-tickets etc., confluence) - also covered in the attached document
{code}
","22/Mar/21 15:50;cs687;||Application||Links/Documentation||
|Rabbitmq|[Maintenance/Troubleshooting|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/RabbitMQ+Maintenance+and+troubleshooting], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/rabbitmq_instance]|
|Haproxy|[documentaiton|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Haproxy], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/haproxy_instance]|
|Apache|[documentation|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Apache], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/apache_instance]|
|Cor|[documentation|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/COR], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/m7tcor]|
|Enq|[documentation|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/ENQ], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/m7tenq]|
|MTT|[documentation|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/MTT]|
|Reporting Engine|[documentation|https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=18321228]|
|Reporter - Kafka|[documentation_kafka|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Kafka], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/playbooks/kafka/readme.md], Reporter missing!|
|Stalker|[documentation|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/STALKER], [deployment/instance|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/stalker]|
|Coda|[documentation|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/coda]|
|Cardio|missing|
|h2h4u|[architecture|https://confluence.energy.svc.dbgcloud.io/display/~xc363/H2H4U+architecture], documentation missing!|
|Patroni Postgres|[documentation/patroni|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Patroni], [troubleshooting|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/Troubleshooting+Patroni]|
|harvester|[documentation|https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/harvester]|
","17/May/21 15:41;PB446;Waiting for the clarification with ESO if the describing the patch management in high level approach is enough for this topic [~sw455]","23/Jun/21 10:06;sw455;Sorry for coming back to this ticket late.

Nothing needs to be explicitly delivered for this requirement. 
Energy Security Office tracks all related process definitions here [Energy Operational Manual - Product Development - Energy Confluence (dbgcloud.io)|https://confluence.energy.svc.dbgcloud.io/display/PD/Energy+Operational+Manual]

Energy Operations' related processes (Incident Management, Problem Management, Release Managment, etc.) are all itemized there and linked from their actual locations: [002 Process Definitions - Energy Operations - Energy Confluence (dbgcloud.io)|https://confluence.energy.svc.dbgcloud.io/display/BIZOPS/002+Process+Definitions]

This should be enough to confirm compliance with the requirements. If there is something missing or found none compliant on internal or external audit or otherwise some need to review the individual processes, those detailed requirements may come back to the teams, but the approach should remain the same: cover the _process_ _definitions_ only, not the detailed procedure to technically operate each technology or component. Keep them all organized in one place per the above link (Energy Operations confluence) ",,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Secure Energy M7 haproxy installations (external test),M7P-6762,99189,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,cs687,cs687,24/Aug/20 11:06,13/Jan/21 11:31,16/Sep/21 14:11,17/Dec/20 13:54,,6.8.148,7tops_sprint108,,,infrastructure,,,,7tops,M7PRODOPS,PenetrationTest,,,,,"||Environment||Done||Status||
|ELTS CTPB| yes|SERVICE-8376|
|ELTS ACUT| yes|SERVICE-8564|
|ELTS CUTE|yes|done by DST(SERVICE-8103)|
|ELTS LIPA|yes|SERVICE-8564|
|ELTS SIMU|yes|SERVICE-8566|
|EPEX ASIM| yes|SERVICE-8114, SERVICE-8472|
|HUPX CUTE| yes|SERVICE-8490|
|HUPX ASIM| yes|SERVICE-8126,SERVICE-8489|
|HUPX SIMU| yes|SERVICE-8488|
|BSP CUTE|yes |SERVICE-8492|
|BSP ASIM| yes|SERVICE-8026|
|BSP SIMU| yes| SERVICE-8491|
|PLPX TGE LIPA| yes|SERVICE-8181|
|PLPX TGE SIMU| | Planned(22/10) -SERVICE-8493|
|XRPM LIPA| Yes|SERVICE-8025|
|XRPM SIMU| yes|SERVICE-8491 SERVICE-8219,|
|SHRD SHOW| |done|
|SHRD DST|yes |done |
|ICSC CUTE| |SERVICE-8536|",,cs687,pd122,yq577,,,,,,,,,,,,,,,M7P-6139,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,haproxy configuration updated in line with M7P-6761,,,,,,,,,,,,,,,,,,,,,,,,31968000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzy4g7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99189,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"10/Sep/20 14:11;cs687;||Environment||Done||ticket||
|ELTS CTPB| | |
|ELTS ACUT| | |
|ELTS CUTE| 21.09.2020| |
|ELTS LIPA| | |
|ELTS SIMU| | |
|EPEX ASIM|18.09.2020|SERVICE-8114|
|ELTS PROD| | |
|HUPX PROD| | |
|HUPX CUTE| 16.09.2020| SERVICE-8022|
|HUPX ASIM| | |
|HUPX SIMU|yes 10.09.2020 | SERVICE-8005|
|BSP PROD| | |
|BSP CUTE| | |
|BSP ASIM| 17.09.2020|SERVICE-8026|
|BSP SIMU| | |
|PLPX PROD| | |
|PLPX LIPA| | |
|PLPX SIMU| | |
|XRPM PROD| | |
|XRPM LIPA| 15.09.2020|SERVICE-8025|
|XRPM SIMU| 29.09.2020|SERVICE-8219|
|SHRD SHOW| | |
|SHRD DST| | |
|SYS1|yes | |
|SYS2|yes | |
|SYS3|yes | |",,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Secure Energy M7 haproxy installations (internal test),M7P-6761,99188,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,24/Aug/20 11:05,22/Sep/20 23:39,16/Sep/21 14:11,08/Sep/20 08:48,,6.8.142,7tops_sprint14,,,,,,,M7PRODOPS,PenetrationTest,,,,,,"1.) *if possible disable *TLS < 1.2*
Disable TLS < 1.2 if possible (make sure that clients doesn't rely on it, it should be possible at least for HTTP; for AMQP, we may need TLS 1.0 for compatibility with clients, the same for mail servers). Either disable all DHE ciphersuites (preferred), or mitigate LogJam by generating custom DH specs.

2.) *M7T/C - V1 Penetration Test Finding: Outdated TLS cipher suites*
https://vmt.deutsche-boerse.de/browse/PT-1462

CAPACITY: 
{code:java}
Generally, for fixing this vulnerability you need to take into account that it depends both on the TLS protocol version and on the browser which ciphers are supported.
 In the medium term, the following ciphers should be replaced:
 TLS_DHE_RSA_WITH_AES_128_CBC_SHA
 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
 TLS_DHE_RSA_WITH_SEED_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384

From a security perspective, (EC)DHE-based algorithms (due to perfect forward secrecy) combined with strong ciphers and modes of operation (CHACHA20 and AES-GCM) as well as up-to-date integrity protection (at least SHA-256 or Poly1305) are ideal. Such cipher suites are available as of TLS 1.2.
 For Apache web server with OpenSSL, the encryption algorithms offered are configured using the SSLCipherSuite directive. Furthermore, SSLHonorCipherOrder can be used to force choosing – from a server’s perspective – the best algorithm supported by both sides (the choice is usually made based on the preference of the client).
 From today’s perspective, secure configuration is as follows:
 SSLHonorCipherOrder On
 SSLCipherSuite ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256 
{code}

TRADING: 
{code:java}
Generally, for fixing this vulnerability you need to take into account that it depends bothon the TLS protocol version and on the client which ciphers are supported. In the medium term, the following ciphers should be replaced:
TLS_DHE_RSA_WITH_AES_128_CBC_SHA
TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
TLS_DHE_RSA_WITH_AES_256_CBC_SHA
TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
TLS_DHE_RSA_WITH_SEED_CBC_SHA
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 
from a security perspective, (EC)DHE-based algorithms (due to perfect forward secrecy) combined with strong ciphers and modes of operation (CHACHA20 and AES-GCM) as well as up-to-date integrity protection (at least SHA-256 or Poly1305) are ideal. However, such cipher suites are only available as of TLS 1.2.

For Apache web server with OpenSSL, the encryption algorithms offered are configured using the SSLCipherSuite directive. Furthermore, SSLHonorCipherOrder can be used to force choosing – from a server’s perspective – the best algorithm supported by both sides (the choice is usually made based on the preference of the client).

From today’s perspective, secure configuration is as follows:
SSLHonorCipherOrder On
SSLCipherSuite ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHEECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCMSHA256:ECDHE-RSA-AES128-GCM-SHA256
{code}

3.) *Standard Diffie-Hellman parameters*
{code:java}
Generally, we recommend disabling all “export” ciphers and configuring TLS implementation in a way that it only supports at least 2048-bit Diffie-Hellman groups. Standard Diffie-Hellman groups provided with a server should be replaced with groups generated individually if the TLS implementation used allows this. Moreover, we recommend configuring servers in a way that they prefer elliptic curve Diffie-Hellman ciphers (ECDHE) to classic Diffie-Hellman and enforce this preference towards the client.
 With OpenSSL, the ECDHE ciphers in the CipherSuite directive should be specified before the DHE ciphers. Using the HonorCipherOrder directive, the server’s preference for the ciphers towards the clients can be enforced:
 SSLHonorCipherOrder On
 SSLCipherSuite ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:…<additional ciphers>…

Moreover, new Diffie-Hellman parameters with a 2048-bit length should be generated. The respective call is as follows:
 $ openssl dhparam -out dh_2048.pem 2048

 In more recent Apache and OpenSSL versions (starting with 2.4.8 and 1.0.2, respectively), the new parameters may be specified in the configuration with the following directive :
 SSLOpenSSLConfCmd DHParameters ""<path to created parameter file>"" 
{code}
",,cs687,,,,,,,,,,,,,,,,,M7P-6139,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Prepared pull-request for fixing the penetration findings: 
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2128/files
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1086/files

Pull-Request ""2128"" will be kept until the last production deployment is finished successfully. 

Standard Diffie-Hellman parameters, is already im-place in the template haproxy.cfg
*tune.ssl.default-dh-param 2048*",,,,,,,,,,,,,,,,,,,,,,,,32227200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzy4fz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 14,7tops Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,,"Tested the changes with the internal Env Systemtest2 
Post-Checks: were handled by Sharad. ",,,,,,,,,,"{""issueId"":99188,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-6761,master,true,"31/Aug/20 13:41;cs687;*1.) disable  TLS < 1.2 for HAProxy in Trading and Capactiy*

https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/haproxy_instance/templates/haproxy.cfg
energy.automation.deployments/roles/haproxy_instance/templates/haproxy.cfg

seems like its already disabled for trading and capacity as you can see
{code:java}
    ssl-default-bind-options no-sslv3 no-tlsv10 no-tlsv11 no-tls-tickets
    ssl-default-server-options no-sslv3 no-tlsv10 no-tlsv11 no-tls-tickets
{code}

for *M7C* there is no dedicated ansible Haproxy role, so at the moment they are using the common default role 
","31/Aug/20 14:48;cs687;*2.) M7T/C - V1 Penetration Test Finding: Outdated TLS cipher suites*

*figure out which cipher suites are currently activated and disabled / cleaning up if necessary*
 ciphers-list: ""openssl ciphers -V <CIPHER_LIST>""

ssl-default-bind-ciphers EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4
 ssl-default-server-ciphers EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4

*EECDH+ECDSA+AESGCM:*
{code:java}
          0xC0,0x2C - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256) Mac=AEAD
          0xC0,0x2B - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128) Mac=AEAD
{code}
*EECDH+aRSA+AESGCM:*
{code:java}
          0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(256) Mac=AEAD
          0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(128) Mac=AEAD
{code}
*EECDH+ECDSA+SHA384:*
{code:java}
          0xC0,0x24 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA384
{code}
*EECDH+ECDSA+SHA256:*
{code:java}
		  0xC0,0x23 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA256
{code}
*EECDH+aRSA+SHA384:*
{code:java}
          0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
{code}
*EECDH+aRSA+SHA256:*
{code:java}
					  ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA256
{code}
*EECDH+aRSA+RC4:*
{code:java}
          0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
{code}
*EECDH:EDH+aRSA:*
{code:java}
          0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(256) Mac=AEAD
          0xC0,0x2C - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256) Mac=AEAD
          0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
          0xC0,0x24 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA384
          0xC0,0x14 - ECDHE-RSA-AES256-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA1
          0xC0,0x0A - ECDHE-ECDSA-AES256-SHA  SSLv3 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA1
          0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(128) Mac=AEAD
          0xC0,0x2B - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128) Mac=AEAD
          0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA256
          0xC0,0x23 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA256
          0xC0,0x13 - ECDHE-RSA-AES128-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA1
          0xC0,0x09 - ECDHE-ECDSA-AES128-SHA  SSLv3 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA1
          0xC0,0x12 - ECDHE-RSA-DES-CBC3-SHA  SSLv3 Kx=ECDH     Au=RSA  Enc=3DES(168) Mac=SHA1
          0xC0,0x08 - ECDHE-ECDSA-DES-CBC3-SHA SSLv3 Kx=ECDH     Au=ECDSA Enc=3DES(168) Mac=SHA1
          0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
          0xC0,0x07 - ECDHE-ECDSA-RC4-SHA     SSLv3 Kx=ECDH     Au=ECDSA Enc=RC4(128)  Mac=SHA1
          0xC0,0x10 - ECDHE-RSA-NULL-SHA      SSLv3 Kx=ECDH     Au=RSA  Enc=None      Mac=SHA1
          0xC0,0x06 - ECDHE-ECDSA-NULL-SHA    SSLv3 Kx=ECDH     Au=ECDSA Enc=None      Mac=SHA1
          0x00,0x9F - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(256) Mac=AEAD
          0x00,0x6B - DHE-RSA-AES256-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA256
          0x00,0x39 - DHE-RSA-AES256-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA1
          0x00,0x88 - DHE-RSA-CAMELLIA256-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(256) Mac=SHA1
          0x00,0x9E - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(128) Mac=AEAD
          0x00,0x67 - DHE-RSA-AES128-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA256
          0x00,0x33 - DHE-RSA-AES128-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA1
          0x00,0x9A - DHE-RSA-SEED-SHA        SSLv3 Kx=DH       Au=RSA  Enc=SEED(128) Mac=SHA1
          0x00,0x45 - DHE-RSA-CAMELLIA128-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(128) Mac=SHA1
          0x00,0x16 - EDH-RSA-DES-CBC3-SHA    SSLv3 Kx=DH       Au=RSA  Enc=3DES(168) Mac=SHA1
{code}
*RC4:*
{code:java}
          0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
          0xC0,0x07 - ECDHE-ECDSA-RC4-SHA     SSLv3 Kx=ECDH     Au=ECDSA Enc=RC4(128)  Mac=SHA1
          0xC0,0x16 - AECDH-RC4-SHA           SSLv3 Kx=ECDH     Au=None Enc=RC4(128)  Mac=SHA1
          0x00,0x18 - ADH-RC4-MD5             SSLv3 Kx=DH       Au=None Enc=RC4(128)  Mac=MD5
          0xC0,0x0C - ECDH-RSA-RC4-SHA        SSLv3 Kx=ECDH/RSA Au=ECDH Enc=RC4(128)  Mac=SHA1
          0xC0,0x02 - ECDH-ECDSA-RC4-SHA      SSLv3 Kx=ECDH/ECDSA Au=ECDH Enc=RC4(128)  Mac=SHA1
          0x00,0x05 - RC4-SHA                 SSLv3 Kx=RSA      Au=RSA  Enc=RC4(128)  Mac=SHA1
          0x00,0x04 - RC4-MD5                 SSLv3 Kx=RSA      Au=RSA  Enc=RC4(128)  Mac=MD5
          0x00,0x8A - PSK-RC4-SHA             SSLv3 Kx=PSK      Au=PSK  Enc=RC4(128)  Mac=SHA1
          0x00,0x20 - KRB5-RC4-SHA            SSLv3 Kx=KRB5     Au=KRB5 Enc=RC4(128)  Mac=SHA1
          0x00,0x24 - KRB5-RC4-MD5            SSLv3 Kx=KRB5     Au=KRB5 Enc=RC4(128)  Mac=MD5
{code}
{color:#de350b}these groups can be deleted *dublicates*{color}
 * EECDH+ECDSA+AESGCM
 * EECDH+aRSA+AESGCM
 * EECDH+ECDSA+SHA384
 * EECDH+ECDSA+SHA256
 * EECDH+aRSA+SHA384
 * EECDH+aRSA+SHA256
 * EECDH+aRSA+RC4

these ciphers are duplicates and anyways configured with
 ssl-default-bind-ciphers EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:*EECDH:EDH+aRSA*:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4

and also RC4 can be deleted because its anyways excluded
 *so we could shrink it down like the following:*
{code:java}
ssl-default-bind-ciphers EECDH+aRSA+RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4
ssl-default-server-ciphers EECDH+aRSA+RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4
{code}","31/Aug/20 15:23;cs687;*exclude the ciphers which are mentioned in the description*

*DHE+aRSA+CAMELLIA*:
{code:java}
          0x00,0x88 - DHE-RSA-CAMELLIA256-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(256) Mac=SHA1
          0x00,0x45 - DHE-RSA-CAMELLIA128-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(128) Mac=SHA1
{code}

*DHE+aRSA+SEED*:
{code:java}
         0x00,0x9A - DHE-RSA-SEED-SHA        SSLv3 Kx=DH       Au=RSA  Enc=SEED(128) Mac=SHA1
{code}

*ECDHE+aRSA+AES+SHA256*:
{code:java}
         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
{code}

*ECDHE+aRSA+AES+SHA384*:
{code:java}
          0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
{code}

*ECDHE+aRSA+AES+SHA*:
{code:java}
          0xC0,0x14 - ECDHE-RSA-AES256-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA1
          0xC0,0x13 - ECDHE-RSA-AES128-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA1
{code}

*DHE+aRSA+AES+SHA*:
{code:java}
          0x00,0x39 - DHE-RSA-AES256-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA1
          0x00,0x33 - DHE-RSA-AES128-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA1
{code}

*DHE+aRSA+AES+SHA256*:
{code:java}
          0x00,0x6B - DHE-RSA-AES256-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA256
          0x00,0x67 - DHE-RSA-AES128-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA256
{code}

*cipher configuration should looks like:*
{code:java}
ssl-default-bind-ciphers EECDH+aRSA+RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4:!DHE+aRSA+CAMELLIA:!DHE+aRSA+SEED:!ECDHE+aRSA+AES+SHA256:!ECDHE+aRSA+AES+SHA384:!ECDHE+aRSA+AES+SHA:!DHE+aRSA+AES+SHA:!DHE+aRSA+AES+SHA256
ssl-default-server-ciphers EECDH+aRSA+RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4:!DHE+aRSA+CAMELLIA:!DHE+aRSA+SEED:!ECDHE+aRSA+AES+SHA256:!ECDHE+aRSA+AES+SHA384:!ECDHE+aRSA+AES+SHA:!DHE+aRSA+AES+SHA:!DHE+aRSA+AES+SHA256
{code}

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1071/files","01/Sep/20 14:23;cs687;Just talked to [~pd122] and we figured out that the cipher suite setting for haproxy is the same like it is for web/apache in ticket -> https://jira.deutsche-boerse.com/browse/M7P-6553

so following cipher families were deleted 
* EECDH+aRSA+RC4
* RC4

and following added: 
* !SHA1 
* !SHA256 
* !SHA384

haproxy-instance *before the change*: 
""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""
apache-instance *before the change*: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1000/files
""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""

so the plan is to set the cipher like it is managed for apache, because for haproxy the same cipher family should be replaced (refer description) 
{code:java}
TLS_DHE_RSA_WITH_AES_128_CBC_SHA
 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
 TLS_DHE_RSA_WITH_SEED_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384
{code}
*EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""*
","04/Sep/20 13:31;cs687;prepared pull-request: 
Inventory: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2128/files
Deployments: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1086/files

Standard Diffie-Hellman parameters, is already im-place in the template haproxy.cfg
{code:java}
tune.ssl.default-dh-param 2048
{code}

Going to deploy with [~pd122] on internal env SYT2


","08/Sep/20 08:48;cs687;done",,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: M7 TGE SIMU deliver 6.10.183,M7P-6746,99077,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,,dp007,dp007,20/Aug/20 10:47,26/Nov/20 14:31,16/Sep/21 14:11,21/Aug/20 13:02,,7tops_sprint13,,,,,,,,7tops,deployment,,,,,," 

Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|TGE|SIMU| | |

*Software versions:*
 M7 6.10.183
||Component||Version||Comment||
|Trading| 6.10.130| |
|MTT|-| |
|Reporting Engine| 6.4.62| |
|ComTrader |6.10.44| |
|H2H|2.0.47| |
|CTPS|1.9.264| |

*Scope:*
 * initial deployment of 6.10
 * TomCat:  *8.5.56*

 
 * after the deployment explicitly check reconnect to XBID ",,ax460,dp007,,,,,,,,,,,,,,,,,,SERVICE-7849,,,,,,,,,M7P-6756,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,wn626,,,,,,,,,,,,,,,TGE,,,,,,Internal Deployment Request,ef759,fh971,fp407,jv861,oy574,pw231,xt853,,No,33868800,,SIMU,dm700,lw641,ox626,rehapav,sw455,,17/Aug/20 16:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy6xj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 99 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99077,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Stalker 1.0.35 for all the prod-instances ,M7P-6745,99069,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,20/Aug/20 07:38,26/Aug/20 11:07,16/Sep/21 14:11,20/Aug/20 13:05,,6.10.194,7tops_sprint13,,,,,,,M7PRODOPS,,,,,,,"We need to deploy stalker instance with version 1.0.35 for all the other production env´s as well. 
Currently it is already deployed for 
* elts-prod
* plpx-prod

open envs: 
* hupx-prod
* xrpm-prod
* xsop-prod

1.) create proper pull-request for the open env´s 
2.) deploy stalker instances 
3.) deploy monitoring clients
4.) validate the status with dev´s ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed stalker instance for hupx-prod, xrpm-prod and xsop-prod",,,,,,,,,,,,,,,,,,,,,,,,33868800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy4fj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"deployed stalker instance for hupx-prod, xrpm-prod and xsop-prod",,,,,,,,,,"{""issueId"":99069,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Aug/20 07:50;cs687;1.) prepared pull-request:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2076
Vault Entries are already existing for hupx-, xrpm-, xsop-prod","20/Aug/20 08:11;cs687;2.) add the stalker user to rabbitmq db 
proofed it´s already existing. 
","20/Aug/20 11:43;cs687;3.) deployed monitoring clients and stalker instance 

{code:java}
[tomcat@m7shrdprodstk1 shrd]$ curl http://localhost:61038/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdprodstk1 shrd]$
{code}
","20/Aug/20 12:59;cs687;{code:java}
[tomcat@m7shrdprodstk1 shrd]$ curl http://localhost:61088/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdprodstk1 shrd]$
{code}


{code:java}
[tomcat@m7shrdprodstk1 shrd]$ curl http://localhost:61058/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdprodstk1 shrd]$
{code}


","20/Aug/20 13:05;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
Renew XSOP Cute Server Certificates ,M7P-6744,99068,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Aug/20 07:01,09/Sep/20 11:20,16/Sep/21 14:11,27/Aug/20 13:44,,6.10.212,7tops_sprint14,,,,,,,M7PRODOPS,,,,,,,"*Ticket to renew certificates for:*

CN=cute1.xsop.m7.deutsche-boerse.com
CN=cute2.xsop.m7.deutsche-boerse.com

*Expiration: 25th September*
{code:java}
root@m7shrdexteweb1 ssl]# openssl x509 -in cute1.xsop.m7.deutsche-boerse.com_cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            aa:30:db:ff:fc:5b:21:ee:4b:fd:98:9a:56:be:f5:12
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Sep 25 00:00:00 2018 GMT
            Not After : Sep 24 23:59:59 2020 GMT
{code}
",,cs687,,,,,,,,,,,,,,,,,SERVICE-7896,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Requested Server Certificates by ssl-admin team 
and uploaded it to vault, creating SERVICE-Request and replace them by tomorrow",,,,,,,,Southpool,,,,,,,,,,,,,,,,33264000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy4fr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,refer *change description*,,,,,,,,,,"{""issueId"":99068,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"20/Aug/20 07:04;cs687;updated the repository *energy.automation.certificate* branch ""tuan"" which is running as MASTER
https://github.deutsche-boerse.de/dev/energy.automation.certificate/blob/tuan/vars.yml

with the following lines: 

{code:java}
    xsop:
      simu:
        - ""....""
        - ""....""
     cute:
         - ""cute1.xsop.m7.deutsche-boerse.com""
        - ""cute2.xsop.m7.deutsche-boerse.com""    
{code}
","20/Aug/20 07:26;cs687;*1.) Creating CSR-Request*
Project A. Generate CSR (Ansible Deployment)
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/

Afterwards we received an email for SSL-Team and added two new entries in vault
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/xsop/cute/cert/

* Request_cute1.xsop.m7.deutsche-boerse.com
* Request_cute2.xsop.m7.deutsche-boerse.com

Created: IT-Service Request with the ID-No: *6B2379*

#######################################################
EMAIL to SSL-ADMIN Team 
{code:java}
Hello SSL-Admin Team,

Please sign the attached CSR as soon ""ITSR 6B2379"" is approved by @Alexander Thorne

Thank you in Advance!

Cheers, 
Steffen 
{code}
","27/Aug/20 13:43;cs687;saved the certificates as 
*as Certificate only, PEM encoded:* and uploaded them with the following jenkins job 

* Project B. Import Cert to Vault (Ansible Deployment)","27/Aug/20 13:44;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Upgrade sonar to the latest LTS version (infra),M7P-6742,99062,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dm700,HO764,dm700,19/Aug/20 15:52,07/Oct/20 11:37,16/Sep/21 14:11,23/Sep/20 16:06,,7tops_sprint102,,,,,,,12/Jan/20 00:00,7tops_comm,M7PRODOPS,,,,,,Implemetnation details in the linked techlog ticket. NOW *we need to create the server and get back the ID* to send it to licence provider.,,cs687,dm700,,,,,,,,,,,,,,,,,,TECHLOG-3106,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,infrastructure for the server was provided - new instance running on https://sonar.energy.svc.dbgcloud.io/sessions/new,,,,,,,,,,,,,,,,,,,,,,,,33782400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,,,,,"2|hzy2s7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 14,7tops Sprint 15,7tops Sprint 102,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":99062,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/20 15:59;dm700;Communication to provider of the licence:
I understand that we need to set up the server first, then send you ID and based on this they send us a key. Right?
*So we need to have the instance ready... *
What happens if we need to redeploy, it will probably randomize  the server ID and can we reuse the same key then? 

Answer of licence provider:
You should not need to re-apply the license as long as the database connection does not change. Once applied, the license is stored in the database.
If you change your database your license will be invalid. If for some reason your server ID changes, we will issue you with a new license key matching your new server ID.
","21/Aug/20 10:49;cs687;[~pn508] we are planning a shared session with [~qo288] and the rest of 7tops team to share the knowledge about it. 
Properly on the coming monday. 

planned monday 8:30 - 9:30",,,,,,,,,,,,,,,,,,,,,,,,,,
6.10 ELTS PROD production installation test,M7P-6732,99010,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Duplicate,,rehapav,rehapav,18/Aug/20 16:54,02/Dec/20 12:45,16/Sep/21 14:11,30/Nov/20 15:37,,7tops_sprint106,,,,uknown,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - ELTS PROD installation test in systemtest1 or ELTS SIMU
 - agreed mandatory test defined prior to 6.10 acceptance by RM 
 - agreed *TBD*
 - to be tested on software version *TBD*

*task description*

Together with Techops, please perform a complete installation test on the ELTS PROD data
 * get dump from ELTS PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * Apply DB cleanup scripts on old database 
 ** adapted cleanup script for 6.10 PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/205|https://slack-redir.net/link?url=https%3A%2F%2Fgithub.deutsche-boerse.de%2Fdev%2Fenergy.automation.inventory-sql%2Fpull%2F205]
 * run flyway migration (still on the old db)
 * measure migration timeline
 * load dump to the internal test environment or ELTS SIMU (decision pending)
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,rehapav,,,,,,,,,,,,,,,,,,,M7P-6347,,,,,,,,,,,,,,SERVICE-6732,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,M7P-7033,,,,,,,,,,,,,,,,,,,,,,,,33955200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmwnj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":99010,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add ICS PROD to Pipeline Temporary DB access (M7),M7P-6699,98807,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,wn626,wn626,11/Aug/20 09:27,25/May/21 23:40,16/Sep/21 14:11,11/Feb/21 10:56,,11.0.0,7tops_sprint111,,,Database,,,,M7PRODOPS,,,,,,,"we need to get access to ICS PROD DB, please add it into Pipeline Temporary DB access (M7).

 

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Temporary%20DB%20access%20(M7)/build?delay=0sec]",,cs687,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Already done!
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7cicscprodasync | m7proddbr1 | 10.139.135.221:20020 |        | running |  5 |           |
| m7cicscprodasync | m7proddbr2 | 10.139.135.222:20020 |        | running |  5 |         0 |
| m7cicscprodasync | m7prodpdb2 | 10.139.53.173:20020  |        | running |  5 |           |
| m7cicscprodasync | m7prodpdb3 | 10.139.53.172:20020  | Leader | running |  5 |         0 |
| m7cicscprodasync | m7prodpdb4 | 10.139.53.171:20020  |        | running |  5 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

m7proddbr1/2 nodes are deployed and running in the cluster.
Jenkins Job is prepared and tested. ",,,,,,,,,,,,,,,,,,,,,,,,18748800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzzd3j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,6.12 non RC,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":98807,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Aug/20 07:24;cs687;will be solved once ICSC is migrated with Patroni DB Setup ","01/Feb/21 15:29;wn626;[~cs687], I think it's already fixed, right?","11/Feb/21 10:56;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: ICSC PROD Deployment of 6.7 CH-AT border,M7P-6687,98724,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qz412,qz412,qz412,06/Aug/20 11:34,26/Nov/20 14:36,16/Sep/21 14:11,30/Sep/20 14:01,,7tops_sprint7,,,,cor,ICS,,,7tops,deployment,,,,,,"Placeholder for the DR preparation, see the original ticket 

 ",,qz412,,,,,,,,,,,,,,,,,,,SERVICE-6516,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,qz412,rehapav,tj898,ub113,wn626,,,,"* Border configuration done
 * V6.7.141 deployed",,,,,,,,,,,,,,Internal Deployment Request,cf948,fj021,HO764,jI663,jv861,oy574,qz412,,No,30326400,,PROD,dm700,lw641,ox626,rehapav,sw455,,25/Aug/20 10:00,,M7P-5388,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzn36v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 100 (PS),X-Men Sprint 101,X-Men Sprint 102 (US),,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,"{""issueId"":98724,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Sep/20 14:01;qz412;The Border has been successfully configured in PROD, v 6.7.141 deployed. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,
configuration error on inventory side,M7P-6678,98681,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,wn626,wn626,05/Aug/20 11:26,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"I don't fully understand what exactly needs to be fixed. maybe we can find it out on 7tops refinement meeting

 

[iaroslav kuchugurnyi|https://app.slack.com/team/UJY9F7518] 
 link for M7 to XBID connection shows that HUPX SIMU and ASIM both connected to LIPB XBID, and none of them connected to XBID SIMU. it seems a little bit strange for us, but could be true.

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#deployed=false&sob=true] (edited) 
  
 [roman|https://app.slack.com/team/U13ECCCAJ] 

that's a configuration error on inventory side.core is assigned to use {{m7hupxsimumpls1/2}} (by ip address, which i don't like):
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/hupx/asim/m7tcor/vars.yml#L2]but in the same env, the xinetd proxy instances are pointing to the shared proxy {{m7shrdexteprx1/2}}
 [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/hupx/asim/xinetd/main.yml#L2]fixing the inventory will reveal the true address.",,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,HUPX,,,,,,,,,,,,,,,,35164800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzcy7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98681,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Post-deployment checks for all components,M7P-6672,98653,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,pw231,pw231,05/Aug/20 08:46,21/Apr/21 11:28,16/Sep/21 14:11,19/Apr/21 12:24,,7tops_sprint115,,,,cor,enq,Stalker,,OPS,,,,,,,"h4. What we need
After startup of each component, we need to verify:
- system is up and it can connect to all its dependent services - implemented by /health endpoint
- the correct version is running - version contained in /info endpoint
- do basic functional shakedown - covered in M7P-1936

h4. Suggested Solution
- create a {{check.sh}} script that is invoked after start.sh
- it will call {{/health}} endpoint and verify the return code is {{200}}, and value {{UP}}
-* any other error code should make the script to fail the deployment job
- it will call {{/info}} endpoint to verify the version against the expected one.
-* typically, the output looks like:
{code:json}
{""app"":""m7-core"",""build"":{""version"":""6.10.97""},""profiles"":""default,epex,remote-sob,epex-lts-xbid-uat3-data-remote-products-only,env,non-prod""}
{code}
-* fail only if the version is different than expected",,cv179,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-1936,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Health and Info pipeline works stable since weeks.

Closing this ticket.",,,,,,,,,,,,,,,,,,,,,,,,16156800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-2305,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzcxr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98653,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"05/Aug/20 11:37;cv179;Creating `check.sh` script and check tag for stalker...","05/Aug/20 16:19;cv179;check script and pipeline created first for stalker:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/dev-trigger/job/M7T_check/]

 

running this pipeline will perform a health check on components (currently just stalker). It also shows the health and info endpoint results in the console, but the output is not yet optimal. Anyways, in case stalker is missing or does not have the endpoint, the result is still success. otherwise, it can be failure if the app is not properly running.","05/Aug/20 16:21;cv179;we might need to split implicit checking after startup and explicit checking on demand. After startup, core takes up to 2 minutes to respond with a valid health response. Do we also want to wait up to 5 minutes if we just check any instance ad-hoc although it might have crashed hours ago?","12/Mar/21 14:58;cv179;mtt2 and h2h4u info endpoints provide different structure than the others:

mtt,h2h:
{code:java}
 {\""version\"":\""1.0.124\""} {code}
 

cor,enq,stalker,...:
{code:java}
 {\""app\"":\""m7-core\"",\""build\"":{\""version\"":\""6.10.195\""},\""profiles\"":\""default,epex,remote-sob,empty-data,env\""} {code}
 

specifically ""version"" is below the ""build"" property. 

Can we have this harmonized?",,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Report for July 2020,M7P-6670,98615,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,03/Aug/20 15:48,12/Aug/20 11:02,16/Sep/21 14:11,11/Aug/20 08:19,,BO_CW33_2020,,,,,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD|2020-08-03 - Volkan|2020-08-05|
| M7 EPEX ASIM|2020-08-03 - Volkan|2020-08-05|
| M7 HUPX|2020-08-03 - Volkan|2020-08-05|
| M7 XSOP|2020-08-03 - Volkan|2020-08-05|
| M7 TGE|2020-08-03 - Volkan|2020-08-05|
| M7 OPCOM|2020-08-03 - Volkan|2020-08-05|
| M7 AUCTION|2020-08-03 - Volkan|2020-08-05|
| ICS / Swissgrid|2020-08-06 - Yarik|2020-08-07|

[https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2020%2D07&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D]

Greenlight requesting email should be sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Martin Komberec <martin.komberec@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>; Volkan Eymir Akcora <volkan.eymir.akcora@deutsche-boerse.com>;
{code}
 ",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,reports sent,,,,,,,,,,,,,,,,,,,,,,,,35251200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy4fb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98615,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unable to stop some app modules without providing the version,M7P-6663,98543,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,pd122,pd122,pd122,30/Jul/20 14:21,12/Aug/20 11:02,16/Sep/21 14:11,31/Jul/20 14:19,,BO_CW33_2020,,,,ansible,,,,7tops,ansible,,,,,,"H2H and REP modules cannot be stopped via [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/view/M7T/job/M7T_deploy_custom/] without providing the version:

 

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/view/M7T/job/M7T_deploy_custom/651/console]",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,variables only used when defined,,,,,,,,,,,,,,,,,,,,,,,,35510400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,30/Jul/20 14:21,,[],,,,,,,,None,,,M7T,,,,"2|hzy3xz:",9223372036854775807,,,,No,,,,,,,,,,deployment script fails when no versions provided (e.g. in a scenario when trying to stop the instances only),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/view/M7T/job/M7T_deploy_custom/651/console,,,,,,,,,,"{""issueId"":98543,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"30/Jul/20 15:27;pd122;PR [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1013] created to fix","31/Jul/20 14:16;pd122;Additional PRs:
 * https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1016
 * https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1017","31/Jul/20 14:17;pd122;PRs merged and successfully tested: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/view/M7T/job/M7T_deploy_custom/662/console",,,,,,,,,,,,,,,,,,,,,,,,,
XSOP_ASIM Reporting Engine to connect to M7 replica DB,M7P-6660,98537,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 12:03,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 12:22,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2.  -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/elts/simu/vars.yml:

{code:sql}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed patroni nodes
3.) deployed enq and reporting_engine",,,,,,,,Southpool,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyymn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":98537,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"31/Jul/20 08:49;cs687;Additional Firewall-Request for setting up patroni-replica-node is necessary: *ID: 505013*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2033

*Waiting until the Firewall-Requests are done to start with the implementation:*
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*xsop*asim*dbr-async*"" -k -K -b --tags replica
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+  
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
| m7txsopasimasync | m7simudbr1 | 10.139.134.221:24028 |        | running |  5 |           |  
| m7txsopasimasync | m7simudbr2 | 10.139.134.222:24028 |        | running |  5 |           |  
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028  | Leader | running |  5 |         0 |  
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028  |        | running |  5 |           |  
| m7txsopasimasync | m7simupdb3 | 10.139.58.174:24028  |        | running |  5 |           |  
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028  |        | running |  5 |         0 |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]","05/Jan/21 12:15;cs687;1.) merged pull-request
2.) deployed patroni nodes
3.) deployed enq and reporting_engine","05/Jan/21 12:22;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
XSOP_SIMU Reporting Engine to connect to M7 replica DB,M7P-6659,98536,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 12:02,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 12:20,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2.  -> *ID:504994*
 # adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
 # adjust energy.automation.inventory, specifically add the following into  inventory/m7t/xsop/simu/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed patroni nodes
3.) deployed enq and reporting_engine",,,,,,,,Southpool,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyymf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":98536,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,"31/Jul/20 08:46;cs687;Additional Firewall-Request for setting up patroni-replica-node is necessary: *ID: 505013*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2032

*Waiting until the Firewall-Requests are done to start with the implementation:*
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*xsop*simu*dbr-async*"" -k -K -b --tags replica
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+    
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |    
+------------------+------------+----------------------+--------+---------+----+-----------+    
| m7txsopsimuasync | m7simudbr1 | 10.139.134.221:24032 |        | running |  7 |           |    
| m7txsopsimuasync | m7simudbr2 | 10.139.134.222:24032 |        | running |  7 |           |    
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032  | Leader | running |  7 |         0 |    
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032  |        | running |  7 |           |    
| m7txsopsimuasync | m7simupdb3 | 10.139.58.174:24032  |        | running |  7 |           |    
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032  |        | running |  7 |           |    
+------------------+------------+----------------------+--------+---------+----+-----------+   
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]
","05/Jan/21 12:13;cs687;1.) *merged pull-request*
2.) deployed patroni nodes
3.) deployed enq and reporting_engine","05/Jan/21 12:20;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
HUPX_ASIM Reporting Engine to connect to M7 replica DB,M7P-6658,98535,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:45,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 11:12,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db.  -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/hupx/asim/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) redeployed patroni dbr-nodes
3.) redeployed enq and reporting_engine",,,,,,,,HUPX,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyym7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,like described in comments and change description,,,,,,,,,,"{""issueId"":98535,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"31/Jul/20 08:39;cs687;Additional Firewall-Request for setting up patroni-replica-nodes are not necessary
Deploying HUPX-ASIM REPLICA NODES:

ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*hupx*asim*dbr-async*"" -k -K -b --tags replica
{code:java}
[root@m7simudbr1 ~]# patronictl -c /etc/patroni_m7thupxasimasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simudbr1 | 10.136.161.121:24018 |        | running |  5 |         0 |
| m7thupxasimasync | m7simudbr2 | 10.136.33.123:24018  |        | running |  5 |         0 |
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018  |        | running |  5 |           |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018  | Leader | running |  5 |         0 |
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018  |        | running |  5 |           |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018  |        | running |  5 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]","05/Jan/21 11:08;cs687;1.) *merging pull-request:*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2446/files

2.) *deployment of replica-nodes* to update the necessary parameter ""max_standby_streaming_delay: 3600000""

3.) *re-deploy reporting engine and enquiry* 
{code:java}
enq: 6.10.179
rep: 6.4.70
{code}
","05/Jan/21 11:12;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
HUPX_SIMU Reporting Engine to connect to M7 replica DB,M7P-6657,98534,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:43,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 12:13,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db.  -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/hupx/simu/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed patroni nodes
3.) deployed enq and reporting_engine",,,,,,,,HUPX,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyylz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":98534,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,"31/Jul/20 08:24;cs687;Additional Firewall-Request for setting up patroni-replica-node is necessary: *ID: 505013*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2030

*Waiting until the Firewall-Requests are done to start with the implementation:*
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*hupx*simu*dbr-async*"" -k -K -b --tags replica
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simudbr1 | 10.139.134.221:24022 |        | running |  6 |         0 |
| m7thupxsimuasync | m7simudbr2 | 10.139.134.222:24022 |        | running |  6 |         0 |
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022  | Leader | running |  6 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022  |        | running |  6 |         0 |
| m7thupxsimuasync | m7simupdb3 | 10.139.58.174:24022  |        | running |  6 |         0 |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022  |        | running |  6 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]","05/Jan/21 12:09;cs687;1.) *merged pull-request*
2.) deployed patroni nodes
3.) deployed enq and reporting_engine","05/Jan/21 12:13;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
XRPM_SIMU Reporting Engine to connect to M7 replica DB,M7P-6656,98533,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:42,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 12:07,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/xrpm/simu/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed patroni nodes
3.) deployed enq and reporting_engine",,,,,,,,OPCOM,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyylr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see description ,,,,,,,,,,"{""issueId"":98533,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,"31/Jul/20 08:15;cs687;Additional Firewall-Request for setting up patroni-replica-node is necessary: *ID: 505013*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2029

*Waiting until the Firewall-Requests are done to start with the implementation:*
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*xrpm*simu*dbr-async*"" -k -K -b --tags replica
{code:java}
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simudbr1 | 10.139.134.221:24036 |        | running |  6 |           |
| m7txrpmsimuasync | m7simudbr2 | 10.139.134.222:24036 |        | running |  6 |         0 |
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036  | Leader | running |  6 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036  |        | running |  6 |           |
| m7txrpmsimuasync | m7simupdb3 | 10.139.58.174:24036  |        | running |  6 |           |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036  |        | running |  6 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]
","05/Jan/21 12:06;cs687;1.) *merged pull-request*
2.) deployed patroni nodes
3.) deployed enq and reporting_engine","05/Jan/21 12:07;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
PLPX_SIMU Reporting Engine to connect to M7 replica DB,M7P-6655,98532,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:40,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 12:03,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
 # adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
 # adjust energy.automation.inventory, specifically add the following into  inventory/m7t/plpx/simu/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed dbr-nodes
3.) deployed reporting engine and enquiry ",,,,,,,,TGE,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyylj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see description,,,,,,,,,,"{""issueId"":98532,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,"31/Jul/20 08:06;cs687;Additional Firewall-Request for setting up patroni-replica-node is necessary: *ID: 505013*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2028

*Waiting until the Firewall-Requests are done to start with the implementation:*
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*plpx*simu*dbr-async*"" -k -K -b --tags replica
{code:java}
[root@m7simudbr1 telegraf]# patronictl -c /etc/patroni_m7tplpxsimuasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simudbr1 | 10.139.134.221:24026 |        | running |  8 |         0 |
| m7tplpxsimuasync | m7simudbr2 | 10.139.134.222:24026 |        | running |  8 |         0 |
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026  | Leader | running |  8 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026  |        | running |  8 |         0 |
| m7tplpxsimuasync | m7simupdb3 | 10.139.58.174:24026  |        | running |  8 |         0 |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026  |        | running |  8 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]
","05/Jan/21 12:02;cs687;1.) *merged pull-request*
2.) deployed patroni nodes
3.) deployed enq and reporting_engine","05/Jan/21 12:03;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
ELTS_CTPB Reporting Engine to connect to M7 replica DB,M7P-6654,98531,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:37,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 08:54,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/elts/ctpb/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"change the max_standby_streaming_delay parameter in patroni config.yml 
* max_standby_streaming_delay: 3600000
* redeployed the dbr-nodes for this specific env. 
* redeployed reporting engine to point to the replica-nodes.
",,,,,,,,ELTS,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyylb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments,,,,,,,,,,"{""issueId"":98531,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CTPB,master,,true,"31/Jul/20 07:47;cs687;prepared pull-request: 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2027","05/Jan/21 08:54;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS_SIMU Reporting Engine to connect to M7 replica DB,M7P-6653,98529,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,30/Jul/20 11:30,13/Jan/21 11:31,16/Sep/21 14:11,05/Jan/21 11:35,,6.11.160,7tops_sprint108,,,Database,RE,,,M7PRODOPS,Patroni,Reporting_Engine,,,,,"# send a firewall request opening Reporting Engine's ports to replica hosts m7simudbr1 and m7simudbr2 from exterep1 and exterep2. -> *ID:504994*
# adjust pg_hba.conf in order to allow connection to udev and uapp users to the replica db. -> *redeploying patroni playbook with tag replica*
# adjust energy.automation.inventory, specifically add the following into  inventory/m7t/elts/simu/vars.yml:

{code:java}
db_replica_server:
  - ""m7simudbr1.deutsche-boerse.de""
  - ""m7simudbr2.deutsche-boerse.de"" {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-7384,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"1.) merged pull-request
2.) deployed replica nodes
3.) deployed enq and reporting_engine",,,,,,,,ELTS,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyyl3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,see comments and change description ,,,,,,,,,,"{""issueId"":98529,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,"31/Jul/20 07:28;cs687;Additional Firewall-Request for setting up patroni-replica-nodes are not necessary
Deploying ELTS-SIMU REPLICA NODES: 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2026/files

ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*elts*simu*dbr-async*"" -k -K -b --tags replica
{code:java}
[root@m7simudbr1 ~]# patronictl -c /etc/patroni_m7teltssimuasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simudbr1 | 10.136.161.121:24010 |        | running |  8 |         0 |
| m7teltssimuasync | m7simudbr2 | 10.136.33.123:24010  |        | running |  8 |         0 |
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010  |        | running |  8 |           |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010  | Leader | running |  8 |         0 |
| m7teltssimuasync | m7simupdb3 | 10.139.58.174:24010  |        | running |  8 |         0 |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010  |        | running |  8 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}

We have also to keep in mind to set up the monitoring, once the replica-nodes are successfully running 
FYI: [~dp007], [~hw120], [~iu252]
","05/Jan/21 11:33;cs687;1.) *merging pull request:*
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2447/files

2.) *deployment of replica-nodes* to update the necessary parameter ""max_standby_streaming_delay: 3600000""

3.) *re-deploy reporting engine and enquiry*
{code:java}
enq: 6.10.179
rep: 6.4.70
{code}
","05/Jan/21 11:35;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
all PROD: remove software component versions  and 3rd party components versions from inventory,M7P-6637,98431,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,28/Jul/20 09:54,26/Aug/20 11:07,16/Sep/21 14:11,19/Aug/20 09:07,,6.10.194,7tops_sprint13,,,,,,,7tops,M7PRODOPS,,,,,,"As agreed on DevOps community practice

software component versions, including 3rd party components versions, are no longer required to be part of the inventory.

As part of this task
 * prepare PR to remove reference to versions
 ** tomcat
 ** rabbitmq
 ** azul
 ** core
 ** enquiry
 ** mtt
 ** re
 ** h2h
 ** ... etc
 * from all 6 PROD environments
 ** HUPX PROD
 ** ELTS PROD
 ** ICSC PROD
 ** TGE PROD
 ** OPCOM PROD
 ** BSP PROD

 
 * perform thorough review
 * merge PRs",,cs687,fj021,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deleted all the software component versions 
including 3rd party components 

handled in the pull-request 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2023",,,,,,,,,,,,,,,,,,,,,,,,33955200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy2tj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"deleted all the software component versions 
including 3rd party components 

handled in the pull-request 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2023",,,,,,,,,,"{""issueId"":98431,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"30/Jul/20 09:48;cs687;Prepared a pull-request: 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2023

In the pull-request is also a cleanup for existing ""enterprisedb"" folder and some versions of simu-env´s included. 

Will let it review by 7tops, DEV and Roman","30/Jul/20 10:01;cs687;we have to figure out how deal with the internal monitoring tools like coda, cardio & stalker
[~fj021] and [~HO764] will have a look at it. ","30/Jul/20 10:21;fj021;For the internal apps (Co,Ca & S), I think it should be also done but there is no need nor urge to do it in this PR. 
 Beforehand, we should ensure that they are tracked in [Current versions|https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=9603437] , we only have Stalker there right now.  

 ","19/Aug/20 08:29;cs687;Agreed on it with [~fj021] and [~cv179] to keep the fallback versions in the inventory: 

*inventory/m7t/vars.yml*
* tomcat_version: 8.5.50

*inventory/m7t/rabbitmq.yml*
* RABBIT_MQ_VERSION: 3.8.3","19/Aug/20 09:06;cs687;Merged pull-request pull-2023
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2023

Ticket can be closed. ","19/Aug/20 09:07;cs687;Done",,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 ELTS CUTE deliver 6.9.150,M7P-6636,98430,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,HO764,rehapav,rehapav,28/Jul/20 09:44,26/Nov/20 16:23,16/Sep/21 14:11,28/Jul/20 13:58,,6.10.157,7tops_sprint12,,,,,,29/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Prepare PRs for linked deployment
  * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : *tbd*",,HO764,rehapav,,,,,,,,,,,,,,,,,,SERVICE-6799,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,wn626,,,,,,ELTS CUTE: enabled tomcat_pool_cleanup,,,,,,,,ELTS,,,,,,Internal Deployment Request,fj021,HO764,nn481,vp223,,,,,No,35856000,,CUTE,dm700,lw641,ox626,rehapav,sw455,,17/Jul/20 16:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzn42f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 97 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":98430,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,master,,true,"28/Jul/20 13:58;HO764;PR prepared: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2014]",,,,,,,,,,,,,,,,,,,,,,,,,,,
describe standard M7 PROD PROD installation,M7P-6633,98402,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,27/Jul/20 14:37,17/Dec/20 14:40,16/Sep/21 14:11,,,,,,,,,,31/Jul/21 00:00,7tops,reducingtoil,,,,,,"We have executed a pre-production installation test for 6.8/6.9 major deployments.

We have done it for all 5 customers.

todo:
 * document (on confluence page) such a test,
 * continuously enhance scope of such a test

 

f.e. see /M7P-6427

 

 
 * get PROD dump of DB
 * get RE PROD dump of DB
 * install it to ASIM/SIMU/SYS2 ?
 * perform datacleansing
 * run deployment
 * run sqls
 * start environment
 * check logs
 * perform shakedown tests
 * etc
 *",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,35856000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyymv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98402,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Website design for all m7 customers and xbid,M7P-6630,98394,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,27/Jul/20 13:02,30/Jul/20 14:19,16/Sep/21 14:11,27/Jul/20 13:04,,6.10.157,7tops_sprint12,,,Customer Portal,,,,M7PRODOPS,,,,,,,"List of webdesigns in alphabetical order
 * EPEX (2 designs: clean white + with background)
 * HUPX
 * PLPX
 * SEMO
 * SHRD (internal tests)
 * XBID
 * XRPM
 * XSOP",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"done in [https://github.deutsche-boerse.de/dev/m7.customer.portal/tree/master/html]

 ",,,,,,,,,,,,,,,,,,,,,,,,35942400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5442,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy2qn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98394,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/20 13:04;dp007;website designs ready for all customers in [https://github.deutsche-boerse.de/dev/m7.customer.portal/tree/master/html]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Stalker deployment of 1.0.35,M7P-6627,98366,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,nn481,nn481,24/Jul/20 12:42,30/Jul/20 14:19,16/Sep/21 14:11,27/Jul/20 11:12,,6.10.157,7tops_sprint12,,,,,,,M7PRODOPS,,,,,,,"Deployment of stalker 1.0.35 on:
elts-simu
elts-cute
epex-simu
plpx-lipa
plpx-simu
shrd-ate4
",,cs687,nn481,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed stalker 1.0.35 and monitoring clients
with CD Pipeline Job ",,,,,,,,,,,,,,,,,,,,,,,,35942400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy2l3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1.) deployed stalker application with 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/M7T_deploy_custom/

2.) added stalker user to vault and rabbitmq-db via management webgui

3.) deploy monitoirng clients 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/",,,,,,,,,,"{""issueId"":98366,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/20 12:56;cs687;https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2001

deploying new stalker version for 
* elts-cute
* epex-asim
* elts-simu
* plpx-lipa
* plpx-simu

elts-cute: done (/)

{code:java}
[root@m7shrdextestk1 config]# curl http://localhost:61368/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 config]#
{code}

elts-simu: done (/)
{code:java}
[root@m7shrdextestk1 config]# curl http://localhost:61168/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 config]#
{code}

plpx-lipa: done (/)
{code:java}
[root@m7shrdextestk1 config]# curl http://localhost:61728/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 config]#
{code}

plpx-simu: done (/)
{code:java}
[root@m7shrdextestk1 config]# curl http://localhost:61128/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 config]#
{code}

epex-asim: done (/)
{code:java}
epex-asim: done :heavy_check_mark:
[root@m7shrdextestk1 config]# curl http://localhost:61248/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 config]#
{code}



","24/Jul/20 12:58;cs687;for all the other simu-env´s 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2004

waiting for pavel´s go 

*we also have to think about to deploy monitoring clients*","27/Jul/20 09:55;rehapav;gogo, approved","27/Jul/20 10:08;cs687;hupx-cute: done (/) 

added the stalker user to the rabbitmq database, deployed the stalker instance and monitoring clients
{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61338/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#
{code}
","27/Jul/20 10:45;cs687;hupx-asim: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61238/stalker/health                                                        
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#
{code}
","27/Jul/20 10:49;cs687;hupx-simu: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61138/stalker/health                                                           
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#   
{code}
","27/Jul/20 10:53;cs687;xrpm-lipa: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61788/stalker/health                                                        
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#
{code}
","27/Jul/20 10:55;cs687;xrpm-simu: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61188/stalker/health                                                        
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#
{code}
","27/Jul/20 11:00;cs687;xsop-cute: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61358/stalker/health                                                          
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#  
{code}
","27/Jul/20 11:03;cs687;xsop-asim: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61258/stalker/health                                                          
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#  
{code}

","27/Jul/20 11:09;cs687;xsop-simu: done (/)

{code:java}
[root@m7shrdextestk1 ~]# curl http://localhost:61158/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdextestk1 ~]#
{code}
","27/Jul/20 11:12;cs687;done",,,,,,,,,,,,,,,,
Restore ELTS-PROD Database (Patroni) ,M7P-6620,98322,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,cs687,cs687,cs687,23/Jul/20 07:16,18/Aug/20 16:04,16/Sep/21 14:11,23/Jul/20 15:32,,7tops_sprint12,,,,,,,24/Jul/20 00:00,M7PRODOPS,,,,,,,"Developers need ""elts-prod-core"" Database with complete trade data for May 8 because of https://jira.deutsche-boerse.com/browse/M7P-6608

FYI: [~cf948] [~pd122]",,cs687,,,,,,,,,,,,,,,,,M7P-6608,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,36288000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzmx8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98322,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"23/Jul/20 09:53;cs687;*requested the backup from 8.05.2020*
{code:java}
[root@m7spg2 ~]# ps -ef | grep restore_eltsprod_new.sh
root      4440 19693  0 07:02 pts/0    00:00:00 /bin/bash /root/restore_eltsprod_new.sh /ampgsql-data-0 2020-05-08 22:25:04
{code}

*Full-Backup:*
copyId: 1 - 1588969504 - /ampgsql-data-0 - 2020-05-08 22:25:04

*Incremental-Backup:*
copyId: 1 - 1589002180 - /ampgsql-data-1 - 2020-05-09 07:29:40
","23/Jul/20 12:36;cs687;Fullbackup request finished after ~4-4:30 hours 

{code:java}
[root@m7spg2 restore]# ~/restore_eltsprod_new.sh /ampgsql-data-0 ""2020-05-08 22:25:04""
Check copyId: 1 - 1588969504 - /ampgsql-data-0 - 2020-05-08 22:25:04
Retrieving copyId: 1 - 1588969504 - /ampgsql-data-0 - 2020-05-08 22:25:04
bv[0] = /usr/bin/ampgsql
v[1] = restore
v[2] = --disk
v[3] = /var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync
v[4] = --device
v[5] = /var/lib/pgsql_m7teltsprodasync/data/11/m7teltsprodasync
v[6] = --level
v[7] = 1
v[8] = --statedir
v[9] = /var/lib/pgsql_m7teltsprodasync/backup/netbackup/ampgsql
v[10] = --db
v[11] = template1
v[12] = --user
v[13] = usernetbackup
v[14] = --host
v[15] = m7prodpdb1.deutsche-boerse.de
v[16] = --cleanupwal
v[17] = YES
v[18] = --port
v[19] = 20002
v[20] = --passfile
v[21] = /var/lib/ppas/.pgpass
v[22] = --tmpdir
v[23] = /tmp
v[24] = --psql-path
v[25] = /usr/ppas-9.3/bin/psql
v[26] = --archivedir
v[27] = /var/lib/pgsql_m7teltsprodasync/backup/11/pg_xlog_archive
v[28] = --gnutar-path
v[29] = /bin/tar
Total bytes retrieved: 1277460480
{code}

Root cause for this long time, was a full queue on netbackup side. (First in First out) 
Will raise this topic in the technical meeting. 
","23/Jul/20 12:51;cs687;1.) *stopping patroni services for the target db* in that case systemtest2 
{code:java}
[root@m7testpdb2 m7tshrdsyt2async]# patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+---------+--------+------+------+-------+----+-----------+
| Cluster | Member | Host | Role | State | TL | Lag in MB |
+---------+--------+------+------+-------+----+-----------+
+---------+--------+------+------+-------+----+-----------+
{code}

2.) *deleting files of data-dir*
{code:java}
-rw------- 1 postgres postgres   180 Apr 17 16:44 backup_label.old
drwx------ 9 postgres postgres   100 Jun 30 14:00 base
-rw------- 1 postgres postgres    62 Jul 23 00:00 current_logfiles
drwx------ 2 postgres postgres  4096 Jul  8 20:26 global
-rw------- 1 postgres postgres  1031 Jun 18 15:11 patroni.dynamic.json
drwx------ 2 postgres postgres     6 Mar 12 16:52 pg_commit_ts
drwx------ 2 postgres postgres     6 Mar 12 16:52 pg_dynshmem
-rw------- 1 postgres postgres  5103 May 19 12:05 pg_hba.conf
-rw------- 1 postgres postgres  5103 Jun 24 14:16 pg_hba.conf.backup
-rw------- 1 postgres postgres  1636 Apr 17 16:44 pg_ident.conf
-rw------- 1 postgres postgres  1636 Jun 24 14:16 pg_ident.conf.backup
drwx------ 4 postgres postgres    68 Jul 23 12:47 pg_logical
drwx------ 4 postgres postgres    36 Mar 12 16:52 pg_multixact
drwx------ 2 postgres postgres    18 Jun 24 14:16 pg_notify
drwx------ 2 postgres postgres     6 Jul 23 12:46 pg_replslot
drwx------ 2 postgres postgres     6 Mar 12 16:52 pg_serial
drwx------ 2 postgres postgres     6 Mar 12 16:52 pg_snapshots
drwx------ 2 postgres postgres   177 Jul 23 12:47 pg_stat
drwx------ 2 postgres postgres     6 Jul 23 12:47 pg_stat_tmp
drwx------ 2 postgres postgres    18 Jul 23 01:47 pg_subtrans
drwx------ 2 postgres postgres     6 Mar 12 16:53 pg_tblspc
drwx------ 2 postgres postgres     6 Mar 12 16:52 pg_twophase
-rw------- 1 postgres postgres     3 Mar 12 16:53 PG_VERSION
drwx------ 3 postgres postgres  4096 Jul 23 12:47 pg_wal
drwx------ 2 postgres postgres   174 Jul 10 04:25 pg_xact
-rw------- 1 postgres postgres    88 Apr 17 16:44 postgresql.auto.conf
-rw------- 1 postgres postgres 23893 Apr 17 16:44 postgresql.base.conf
-rw------- 1 postgres postgres 23893 Jun 24 14:16 postgresql.base.conf.backup
-rw------- 1 postgres postgres  1409 Jun 24 14:16 postgresql.conf
-rw------- 1 postgres postgres  1409 Jun 24 14:16 postgresql.conf.backup
-rw------- 1 postgres postgres   519 Jun 24 14:16 postmaster.opts
-rw------- 1 postgres postgres   233 Jun 24 14:15 recovery.done
{code}

3.) *replace the data-dir files with the restored backup-files (incl. recovery.conf) and start the db with pg_ctl*
* changing pg_hba.conf entries 
* changing postgresql.conf settings like port, schema-name, directory names
* /usr/pgsql-11/bin/pg_ctl -D /var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async  start
* /usr/pgsql-11/bin/pg_ctl -D /var/lib/pgsql_m7tshrdsyt2async/data/11/m7tshrdsyt2async promote (to deactivate replica and we can work on the database as MASTER) 

Changing DB-Name, Schema-Owner, user/roles and passwords. 
* ALTER ROLE m7teltsprodm7b RENAME TO m7tshrdsyt2m7b;
* ALTER ROLE m7tshrdsyt2m7b WITH PASSWORD 'TESTPASSWORD';
....
* ALTER DATABASE m7teltsprodm7b RENAME TO m7tshrdsyt2m7b;
... 


in case we get some error like that: 
{code:java}
Jul 24 11:00:58 m7testpdb1 patroni[5669]: 2020-07-24 11:00:58,371 INFO: No PostgreSQL configuration items changed, nothing to reload.
Jul 24 11:00:58 m7testpdb1 patroni[5669]: 2020-07-24 11:00:58,387 CRITICAL: system ID mismatch, node m7testpdb1 belongs to a different cluster: 67...834409372
{code}

we have to stop patroni service, remove the cluster and start patroni service again
",,,,,,,,,,,,,,,,,,,,,,,,,
ansible deployment for CTP WEB (inte),M7P-6604,98222,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,pd122,pd122,20/Jul/20 13:14,22/Jul/21 14:08,16/Sep/21 14:11,30/Apr/21 10:35,,6.12.12,7tops_sprint116,,,ansible,,,,7tops,,,,,,,"* populate inventory
 * create ansible playbook/role(s)
 * create separate deployment tickets for external test and production environments",,fh971,pd122,,,,,,,,,,,,,,,,M7P-7521,,,,,,,,,,,,,,,,M7P-8668,M7P-3226,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,deployed successfully ,,,,,,,,,,,,,,,,,,,,,,,,12009600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy1uv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98222,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"26/Apr/21 15:52;pd122;PRs:
- https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1520
- https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1526
- https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1530
- https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2701
- https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2702
- https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1532
- https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1533
- https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2723","30/Apr/21 10:34;pd122;Internal test environment deployed successfully ",,,,,,,,,,,,,,,,,,,,,,,,,,
Toggling Kapacitor/Calls alerts for m7t-xsop-prod-dbr-async2,M7P-6593,98127,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,cs687,cs687,16/Jul/20 13:45,08/Sep/21 15:19,16/Sep/21 14:11,,,,,,,,,,31/Jul/20 00:00,7tops,M7PRODOPS,Monitoring,,,,,"Hey [~hw120]

during our ELTS-PROD Deployment we figured out a strange behavior. 

Lots of alerts for m7prodpdb1-4 occured for several production databases.  
Refer: https://dbg-devops.slack.com/archives/C941CV942/p1594839840461500 

on top we received today 16.07.2020 around 8am toggling alarms for xsop-prod-dbr2 instance 
https://dbg-devops.slack.com/archives/C941CV942/p1594879680469300

{code:java}
kapacitorAPP  11:00 AM
m7proddbr2 - m7t - xsop - prod - dbr-async2 is not sending postgres data.

11:04
m7proddbr2 - m7t - xsop - prod - dbr-async2 is sending postgres data.
{code}

The database cluster is healthy and looking fine, all the monitoring clients are running, just and only for pgwatch we figured out the following: 
{code:java}
Jul 16 12:03:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:03:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-plpx-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:03:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:03:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-shrd-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:03:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:03:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-xrpm-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7a-ampr-prod-dbr-sync2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-elts-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-flex-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-hupx-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-plpx-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-shrd-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
Jul 16 12:04:50 m7proddbr2 pg_watch2[14281]: 2020/07/16 12:04:50 ERRO GetMonitoredDatabasesFromMonitoringConfig: Failed to resolve DBs for ""m7t-xrpm-prod-dbr-async2"": pq: no pg_hba.conf entry for host ""10.136.33.253"", user ""pgwatch2"", database ""template1"", SSL off
[root@m7proddbr2 log]#
{code}

*What did we do to avoid the calls/alerts:*
* we comment out the entry in pg_hba.conf (/var/lib/pgsql_m7txsopprodasync/data/11/m7txsopprodasync/pg_hba.conf)
{code:java}
# BEGIN ANSIBLE MANAGED BLOCK
#################################################################################################################
# monitoring
#
#################################################################################################################
# TYPE  DATABASE           USER                                                 ADDRESS                 METHOD
#host    all                pgwatch2                                           10.136.33.253/32          md5
# END ANSIBLE MANAGED BLOCK
{code}

* stopped pg_watch service on the host m7proddbr2 
{code:java}
[root@m7proddbr2 m7txsopprodasync]# systemctl stop pg_watch2.service -l
[root@m7proddbr2 m7txsopprodasync]# systemctl status pg_watch2.service -l
● pg_watch2.service - pg_watch2
   Loaded: loaded (/etc/systemd/system/pg_watch2.service; enabled; vendor preset: disabled)
   Active: inactive (dead) since Thu 2020-07-16 13:30:38 CEST; 1s ago
  Process: 45246 ExecStopPost=/bin/rm -rf /run/pg_watch2 (code=exited, status=0/SUCCESS)
  Process: 45243 ExecStop=/bin/kill -s TERM $MAINPID (code=exited, status=0/SUCCESS)
  Process: 37716 ExecStart=/opt/pg_watch2/pg_watch2 -c /etc/pg_watch2/pg_watch2.d -m /opt/pg_watch2/metrics/ --issl=true --ihost=influxdb.energy.svc.dbgcloud.io --iport=443 --iretentionname=autogen --idbname=metrics_m7_shared --conn-pooling=off (code=killed, signal=TERM)
  Process: 37713 ExecStartPre=/bin/chown -R pg_watch2:pg_watch2 /run/pg_watch2 (code=exited, status=0/SUCCESS)
  Process: 37711 ExecStartPre=/bin/mkdir /run/pg_watch2 (code=exited, status=0/SUCCESS)
 Main PID: 37716 (code=killed, signal=TERM)
{code}

I will be in vacation on 02 of August, maybe we can talk about that in week 27.7-31.7
At the moment we have no clue why this alerts are coming up. 


",,cs687,du271,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,Southpool,,,,,,,,,,,,,,,,35337600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzzcxj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98127,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"21/Jul/20 14:41;du271;Hey,

this looks like pgwatch2 tries to connect to several other database that it has been told to monitor, and those databases have no HBA rules to allow these connections.

Assuming that you desire these databases to be monitored, we need to add those hba rules on those clusters.

Maybe you can check e.g.
m7t-plpx-prod-dbr-async2
if it has an HBA rule like this:

host all pgwatch2 10.136.33.253/32 md5

due to the difficulty in checking whether something from the actual pg_hba.conf file has been loaded by the database, you can also query the pg_hba_file_rules view directly in the database...

Additionally, I'd like to know: what's the IP address of the machine running pgwatch2?","21/Jul/20 15:37;iu252;
{noformat}

P:\>nslookup
Default Server:  FRPDC806.oa.pnrad.net
Address:  10.250.0.162

> m7proddbr2
Server:  FRPDC806.oa.pnrad.net
Address:  10.250.0.162

Non-authoritative answer:
Name:    m7proddbr2.deutsche-boerse.de
Address:  10.136.33.253
{noformat}
","03/Aug/20 13:38;du271;Hey @iu252 ,

I've talked to our pgwatch2 guru, Kaarel (@ik353 ), and explained to him that you are relying upon the value of ""numbackends"" being greater than 0 to determine from influxdb whether pgwatch2 is still running right...
He confirmed my suspicion, that this is not a great metric to cover all possible cases of ""everything is alright"", unless you plan on keeping up at least one connection to each database in the cluster and monitor that.

Instead, he suggested to use grafana with the ""alert on no data"" trigger.
Or, alternatively, the health check API built into pgwatch2 could be used to determine it's healthyness.
e.g.:
{code:java}
http :9081
HTTP/1.1 200 OK
Content-Length: 383
Content-Type: text/plain; charset=utf-8
Date: Mon, 03 Aug 2020 11:12:20 GMT
{
    ""datastoreAvgSuccessfulWriteTimeMillis"": 4.6,
    ""datastoreSuccessfulWritesCounter"": 3,
    ""datastoreWriteFailuresCounter"": 0,
    ""gathererUptimeSeconds"": 12,
    ""metricPointsPerMinuteLast5MinAvg"": 320,
    ""metricsDropped"": 0,
    ""secondsFromLastSuccessfulDatastoreWrite"": 12,
    ""totalDatasetsFetchedCounter"": 25,
    ""totalMetricsFetchedCounter"": 64,
    ""totalMetricsReusedFromCacheCounter"": 0
}
{code}

Dpending upon the intervals configured in pgwatch2, one could for example monitor the ""secondsFromLastSuccessfulDatastoreWrite"" value.

 

I hope this helps!",,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD - deployed CTPS version is old,M7P-6584,98086,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,pd122,rehapav,rehapav,16/Jul/20 00:18,30/Jul/20 14:19,16/Sep/21 14:11,20/Jul/20 13:28,,7tops_sprint12,,,,,,,,7tops,,,,,,,"For whatever reason, we have now very old 

CT Profile Server software installed.

Expected version: 1.9.218

Actual version: , 1.9.90 

 

Propose what steps should be taken to correct this or if its acceptable to wait for another deployment window.

 

Update from [~pd122]
 [@Pavel Rehak|https://dbg-devops.slack.com/team/U4FV7JP6V] I think I found out what had happened: new CTPs were initially installed (on 14/4) and worked, however on 9/6 the hosts were restarted (during OS os ESX upgrade I presume) and since old CTPs were still there, they were started and occupied network ports that new CTPs failed to acquire and thus failed to start
 TO DO:
 #  stop old CTPs
 # start new CTPS (meanwhile succeeded in deploying the latest version)
 # verify
 # REMOVE old CTPs if all’s good

 

 ",,pd122,pn508,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"* DB migrated
 * old instances shut down and the new ones started
 * old instances disabled",,,,,,,,,,,,,,,,,,,,,,,,36547200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,16/Jul/20 00:18,,[],,,,,,,,None,,,M7T,,,,"2|hzy147:",9223372036854775807,,,,No,,,,,,,,,,"* old instances were not removed after new ones were deployed via Ansible on 14/4
 * old instances were then started during ESX migration (instead of new ones) on 9/6
 * no-one investigated

 ",,,,,,,,X-Men Sprint 97 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,incorrect/old instances started,1.0,,,,,,,,,"{""issueId"":98086,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jul/20 11:17;pn508;[~pd122], [~rehapav] what is the risk assessment? Can we wait for the next MW?","16/Jul/20 13:17;pd122;bad news: on top of listed steps we need to perform DB migration as well since 'old' CTP DB now contains new profiles (created since 9/6) that are missing on the 'new' CTP DB)

good new: this could be done while the app is running, hence no downtime

 

Also, old->new instance switch can be done on each host individually, limiting the perceived downtime.

in case of problem it would be possible to quickly revert to old setup just by shutting down new instances and starting back the old ones (that are running at this moment).   Thus I'd consider this to be low risk operation.","16/Jul/20 14:50;pd122;[~pn508] , [~rehapav]  inventory fixed (in M7P-5985), ready to migrate/deploy","16/Jul/20 14:54;rehapav;Approved for implementation asap - 16/7 

Risk assessment:  Low / Acceptable","20/Jul/20 13:21;pd122;db migrated, new instances started up again, old instances stopped and disabled; details in M7P-5985",,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Consider validating Host header (production),M7P-6576,98065,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pd122,pd122,15/Jul/20 13:52,08/Sep/21 13:47,16/Sep/21 14:11,07/Sep/21 16:24,,7tops_sprint125,,,,apache,infrastructure,,,7tops,7tops_comm,S,,,,,"Currently, we do not validate Host header and use it often for redirects. Consider allowing only correct Host header and reject the request otherwise.

This behavior has been reported on M7T, M7C, and profile server.

*Test M7T upgrade process in BSP PROD*",,pd122,rehapav,vp223,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-10182,SERVICE-9946,SERVICE-9962,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Required changes (default - catch-all and monitoring virtual hosts) were deployed to all production environments,,,,,,,,,,,,,,,,,,,,,,,,691200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5259,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz8an:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,7tops Sprint 125,7tops Sprint 126,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98065,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"12/Feb/21 10:55;vp223;Please consider that M7C part was moved to XBID as part of the ICS to XBID move.","16/Mar/21 16:24;pd122;XSOP PROD deployed on 15/3, resulted in monitoring failure.  Need to evaluate the options before proceeding.","12/Apr/21 15:25;pd122;After monitoring workaround has been put in place ([M7P-7996]) and all XSOP PROD web servers we re-deployed, the alerts cleared.","14/Apr/21 17:12;pd122;PR https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2683 merged and 
- HUPX
- PLPX
- XRPM
production envs deployed","15/Apr/21 11:33;pd122;ELTS PROd deployment failed because external and internal (?!) host names/ports differ (historical burden)

https://prod2.epex.m7.deutsche-boerse.com:60040/ -> https://prod2.epex-lts.m7.deutsche-boerse.com:60060/

making redirects in catch-all default virtual host fail. Proper solution would be to settle on a correct/single URL and modify the setup accordingly.
","16/Apr/21 12:16;pd122;Requested current LB setup for both EPEX (not in use any more) and ELTS production environments from CCI; the idea is to set up and use both LBs concurrently while getting the customer to switch to the correct one (the same host/port internal web instances are using) over time","19/Apr/21 10:48;rehapav;When activating new URLs please do not forget to update monitoring tools as requested in M7P-8179","29/Apr/21 15:07;pd122;https://prod2.epex-lts.m7.deutsche-boerse.com:60060/ now has the same pool as https://prod2.epex.m7.deutsche-boerse.com:60040/. Requested the same change for https://prod1.epex-lts.m7.deutsche-boerse.com:60060/.  Waiting for the confirmation as well as for the firewall check to confirm that both sets of private VIPs (https://10.136.[150,22].16:60040/ as wellas https://10.136.[150,22].18:60060/)  can be accessed via the leased line.","11/Jun/21 11:04;pd122;It has been confirmed by ICC that both sets of private VIPs can now be accessed via existing leased line setup.","05/Aug/21 13:17;pd122;PRs:
 * [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1723]
 * https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2940

 * [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1730]
 * [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2945]","06/Aug/21 10:50;pd122; [https://prod2.epex-lts.m7.deutsche-boerse.com:60060/] has been deployed successfully

- https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/11921/console

- https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/11924/console

- https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7 Ansible Jobs/job/M7-Deploy-Playbook/11925/console","31/Aug/21 15:08;pd122;[http://10.136.150.13:62060|http://10.136.150.13:62060/reporting-engine-app/] (reporting) redeployed:
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12122/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12124/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12126/console]

 

had to change file system permission for this one (not really sure why):
{code:java}
[pd122adm@m7shrdprodweb1 m7t-elts-prod-rep-web1]$ tail -f error_log 
[Tue Dec 08 21:17:38.569989 2020] [mpm_prefork:notice] [pid 13682] AH00169: caught SIGTERM, shutting down
[Tue Dec 08 21:18:14.079531 2020] [lbmethod_heartbeat:notice] [pid 30244] AH02282: No slotmem from mod_heartmonitor
[Tue Dec 08 21:18:14.081625 2020] [mpm_prefork:notice] [pid 30244] AH00163: Apache/2.4.6 (Red Hat Enterprise Linux) configured -- resuming normal operations
[Tue Dec 08 21:18:14.081654 2020] [core:notice] [pid 30244] AH00094: Command line: '/usr/sbin/httpd -f /shrd/m7t-elts-prod-rep-web1/config/httpd.conf'
[Tue Aug 31 15:04:44.159643 2021] [mpm_prefork:notice] [pid 30244] AH00169: caught SIGTERM, shutting down
[Tue Aug 31 15:04:52.495218 2021] [auth_digest:error] [pid 32154] (13)Permission denied: AH01762: Failed to create shared memory segment on file /run/httpd/authdigest_shm.32154
[Tue Aug 31 15:04:52.495344 2021] [auth_digest:error] [pid 32154] (13)Permission denied: AH01760: failed to initialize shm - all nonce-count checking and one-time noncesdisabled
[Tue Aug 31 15:04:52.495350 2021] [:emerg] [pid 32154] AH00020: Configuration Failed, exiting
^C
[pd122adm@m7shrdprodweb1 m7t-elts-prod-rep-web1]$ ls -ld /run/httpd/
drwx--x--- 3 root apache 1120 Oct 9 2020 /run/httpd/
[pd122adm@m7shrdprodweb1 m7t-elts-prod-rep-web1]$ sudo chmod g+w /run/httpd/
[pd122adm@m7shrdprodweb1 m7t-elts-prod-rep-web1]$ ls -ld /run/httpd/
drwx-wx--- 3 root apache 1120 Oct 9 2020 /run/httpd/{code}","02/Sep/21 15:29;pd122;filesystem permissions changed because of RH httpd package upgrade.  Workaround created in PR [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1769] (merged)","02/Sep/21 15:31;pd122;Additional issue discovered with mtt/as2mock  virtual hosts - their specific ports and log file names were not respected in all virtual hosts.  Fixed in PR  [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1772] (merged).","02/Sep/21 15:48;pd122;HUPX SIMU APP instance successfully re-deployed to test new changes:
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12204/console
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12205/console","06/Sep/21 11:16;pd122;HUPX PROD app instance re-deployed:
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12232/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12233/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12234/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12235/console]
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12236/console]
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12237/console","06/Sep/21 13:52;pd122;ELTS PROD (2) successfully re-deployed:
 * [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12239/console]
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12240/console
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12241/console","07/Sep/21 16:22;pd122;ELTS PROD (1) deployed:
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12262/console
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12269/console
 * https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/12271/console",,,,,,,,,,
SPIKE: Consider validating Host header (external test),M7P-6575,98063,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pd122,pd122,15/Jul/20 13:45,25/May/21 23:40,16/Sep/21 14:11,08/Mar/21 16:22,,11.0.0,7tops_sprint112,,,infrastructure,,,,7tops,7tops_comm,M,,,,,"Currently, we do not validate Host header and use it often for redirects. Consider allowing only correct Host header and reject the request otherwise.

This behavior has been reported on M7T, M7C, and profile server.",,pd122,vp223,,,,,,,,,,,,,,,,M7P-6576,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Apache web server has been re-deployed on all M7T external test environments to action the configuration changes,,,,,,,,,,,,,,,,,,,,,,,,16502400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5259,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzz89b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":98063,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"12/Feb/21 10:55;vp223;Please consider that M7C part was moved to XBID as part of the ICS to XBID move.","26/Feb/21 11:43;pd122;XRPM LIPA deployed and verified, [~rehapav] ideally, I'd like to schedule single window to deploy all external tests' web servers (one by one).","03/Mar/21 14:37;pd122;Additional environments deployed:
- PLPX LIPA
- XSOP CUTE
- HUPX CUTE
- ELTS CUTE
- ELTS ACUT
- ELTS CTPB
- ELTS LIPA","05/Mar/21 19:54;pd122;Environments deployed:
- SHOWCASE
- XRPM SIMU
- PLPX SIMU
- HUPX ASIM
- HUPX SIMU
- XSOP ASIM
- XSOP SIMU
- ELTS SIMU
- ELSs ASIM","08/Mar/21 16:21;pd122;DST1 deployed",,,,,,,,,,,,,,,,,,,,,,,
Due date 17/07/20 -SERVICE CLONE: prepare missing PRs for M7 HUPX PROD deliver 6.9.150,M7P-6558,98023,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,fj021,rehapav,rehapav,15/Jul/20 08:51,26/Nov/20 16:28,16/Sep/21 14:11,17/Jul/20 10:57,,6.10.153,7tops_sprint12,,,,,,17/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare missing PRs for*
 * software components
 * RABIITMQ 3.8.3
 * TOMCAT 8.5.50
 * AZUL 1.8.0_242
 * see similar what was done for XSOP: TOMCAT 8.5.50
 ** [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1944/files]

 ",,fj021,rehapav,,,,,,,,,,,,,,,,,,SERVICE-6634,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,PR prepared for 6.9 delivery.,,,,,,,,HUPX,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,36806400,,PROD,dm700,lw641,ox626,rehapav,sw455,,22/Jul/20 11:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzy153:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 97 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":98023,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"17/Jul/20 10:51;fj021;[~rehapav] PR prepared : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1990]",,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Secure Enegy M7 Web servers (production),M7P-6555,97967,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,13/Jul/20 14:24,27/Jan/21 11:16,16/Sep/21 14:11,25/Jan/21 15:56,,6.8.150,7tops_sprint109,,,infrastructure,,,,M7PRODOPS,PenetrationTest,,,,,,refer: https://jira.deutsche-boerse.com/browse/M7P-6554,,cs687,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,all is prepared for the coming deployment. no need to keep the ticket open ,,,,,,,,,,,,,,,,,,,,,,,,20131200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzym7z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97967,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/20 18:41;pd122;||Customer||Deployed||
|ELTS |SERVICE-7890|
|EPEX| |
|HUPX|SERVICE-7891|
|PLPX| planned (1st week of Dec)|
|XRPM|SERVICE-7888|
|XSOP|SERVICE-7887|","25/Jan/21 15:56;cs687;{code:java}
Pavel Rehak (dbg ops) added a comment - 25/Jan/21 15:23
{code}

TGE PROD planned in https://jira.deutsche-boerse.com/browse/SERVICE-7889
ticket can be closed","25/Jan/21 15:56;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Secure Enegy M7 Web servers (external test),M7P-6554,97966,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,cs687,cs687,13/Jul/20 14:23,17/Nov/20 23:40,16/Sep/21 14:11,30/Oct/20 13:39,,6.8.146,7tops_sprint104,,,infrastructure,,,,7tops_comm,ICS,M7PRODOPS,PenetrationTest,S,,,"refer: https://jira.deutsche-boerse.com/browse/M7P-6553

 

 
||Customer||Environment||Deployed||
|ELTS|ACUT| SERVICE-8564|
| |CTPB| SERVICE-8024|
| |CUTE|SERVICE-6799|
| |LIPA|SERVICE-8564|
| |SIMU|SERVICE-8566|
|EPEX|ASIM| SERVICE-8114|
|FLEX|SIMU| N/A|
|HUPX|ASIM| SERVICE-8126|
| |CUTE| SERVICE-8490|
| |SIMU|SERVICE-8005|
|PLPX|LIPA| SERVICE-8181|
| |SIMU| SERVICE-8493|
|XRPM|LIPA|SERVICE-8025|
| |SIMU| SERVICE-8219|
|XSOP|ASIM| SERVICE-8026|
| |CUTE|SERVICE-7838|
| |SIMU| SERVICE-8491|
 ",,cs687,pd122,yq577,,,,,,,,,,,,,,,M7P-6555,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,all external M7 trading and capacity environments were re-deployed to update web server setup,,,,,,,,,,,,,,,,,,,,,,,,32227200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzy4gf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97966,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jul/20 13:46;pd122;Deploying solution from M7P-6553 to external test environments.","30/Jul/20 14:32;pd122;Deployed to ELTS CUTE ([SERVICE-6799]). ","03/Sep/20 14:25;pd122;Deployed to XSOP CUTE ([SERVICE-7838]).","08/Sep/20 12:39;pd122;M7C/T
||Customer||Environment||Deployed||
|ELTS|ACUT| |
| |CTPB| SERVICE-8024|
| |CUTE|SERVICE-6799|
| |LIPA| |
| |SIMU| |
|EPEX|ASIM| |
|FLEX|SIMU| |
|HUPX|ASIM| |
| |CUTE|SERVICE-8022|
| |SIMU|SERVICE-8005|
|PLPX|LIPA| |
| |SIMU| |
|XRPM|LIPA|SERVICE-8025|
| |SIMU| SERVICE-8219|
|XSOP|ASIM|SERVICE-8026|
| |CUTE|SERVICE-7838|
| |SIMU| |",,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Secure Enegy M7 Web servers (internal test) ,M7P-6553,97965,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,cs687,cs687,13/Jul/20 14:01,27/Jan/21 09:52,16/Sep/21 14:11,31/Jul/20 14:29,,6.8.139,BO_CW33_2020,,,infrastructure,,,31/Jul/20 00:00,M7PRODOPS,PenetrationTest,,,,,," 

Pen test  discovered problems with TLS stack configuration: old tls versions supported, logjam not mitigated, insecure client-initiated renegotiation supported.

 

To do:

Decide on protocol versions and ciphersuites, either in general, or per service. Configure TLS stack properly, and make sure that LogJam is mitigated, insecure renegotiation is not allowed, and supported ciphersuites conform to up-to-date security standards.
 * *1.) if possible disable *TLS < 1.2*
 Pen test also discovered other problems with TLS stack configuration: old tls versions supported, logjam not mitigated, insecure client-initiated renegotiation supported.
 Disable TLS < 1.2 if possible (make sure that clients doesn't rely on it). Either disable all DHE ciphersuites (preferred), or mitigate LogJam by generating 
 custom DH specs.

 * *2.) M7T/C - V1 Penetration Test Finding: Outdated TLS cipher suites*
 The following cipher suites should be replaced
 CBC ciphers are prone to so-called padding oracle attacks:
{code:java}
TLS_DHE_RSA_WITH_AES_128_CBC_SHA
 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA
 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
 TLS_DHE_RSA_WITH_SEED_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384
{code}

more details: [https://vmt.deutsche-boerse.de/browse/PT-1462]
 * *3.) Standard Diffie-Hellman parameters*
{code:java}
$ testssl.sh https://cute1.ics.m7c.deutsche-boerse.com
…
Testing robust (perfect) forward secrecy, (P)FS -- omitting Null
Authentication/Encryption, 3DES, RC4
PFS is offered (OK) …
Elliptic curves offered: prime256v1 secp384r1 secp521r1
DH group offered: RFC3526/Oakley Group 14 (2048 bits) 
{code}

This flaw allows attackers with much computing power to break the key negotiation by pre-calculation.
 *Recommendations*
 Generally, we recommend disabling all “export” ciphers and configuring TLS implementation in a way that it only supports at least 2048-bit Diffie-Hellman groups. Standard Diffie-Hellman groups provided with a server should be replaced with groups generated individually if the TLS implementation used allows this.

Moreover, we recommend configuring servers in a way that they prefer elliptic curve Diffie-Hellman ciphers (ECDHE) to classic Diffie-Hellman and enforce this preference towards the client.

With OpenSSL, the ECDHE ciphers in the CipherSuite directive should be specified before the DHE ciphers. Using the HonorCipherOrder directive, the server’s preference for the ciphers towards the clients can be enforced:
{code:java}
SSLHonorCipherOrder On
SSLCipherSuite ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-
SHA384:...<additional ciphers>...{code}
Moreover, new Diffie-Hellman parameters with a 2048-bit length should be generated. The respective call is as follows:
{code:java}
$ openssl dhparam -out dh_2048.pem 2048{code}
In more recent Apache and OpenSSL versions (starting with 2.4.8 and 1.0.2, respectively), the new parameters may be specified in the configuration with the following directive:
{code:java}
SSLOpenSSLConfCmd DHParameters ""<path to created parameter file>"" {code}",,cs687,pd122,,,,,,,,,,,,,,,,M7P-6554,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"available ssl ciphers set limited (down to 4):

TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
TLS_DHE_RSA_WITH_AES_256_GCM_SHA384
TLS_DHE_RSA_WITH_AES_128_GCM_SHA256",,,,,,,,,,,,,,,,,,,,,,,,35510400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxv7b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 11,7tops Sprint 12,,,,,,,,,,,,,,,,,,,,,,,,,test available ciphers ,,,,,,,,,,"{""issueId"":97965,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"20/Jul/20 14:34;cs687;*1.)  if possible disable *TLS < 1.2*
seems like its already disabled for trading and capacity as you can see 
{code:java}
SSLProtocol all -SSLv3 -TLSv1 -TLSv1.1
SSLHonorCipherOrder on
{code}

TRADING: https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/apache_instance/templates
Just found out that for the reporting-engine ""m7_reporting.conf.j2"" ssl/tls is missing at all. Will investigate
CAPACITY: https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/m7c_apache/templates/m7c.conf.j2
","21/Jul/20 10:07;cs687;*2.)  M7T/C - V1 Penetration Test Finding: Outdated TLS cipher suites*

*(1) figure out which cipher suites are currently activated and disabled / cleaning up if necessary* 


*ciphers-list:* ""openssl ciphers -V <CIPHER_LIST>""
{code:java}
SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""


EECDH+ECDSA+AESGCM
	0xC0,0x2C - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256) Mac=AEAD
    0xC0,0x2B - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128) Mac=AEAD
		  
EECDH+aRSA+AESGCM
	0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(256) Mac=AEAD
    0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(128) Mac=AEAD

EECDH+ECDSA+SHA384
    0xC0,0x24 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA384
	 
EECDH+ECDSA+SHA256
	0xC0,0x23 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA256

EECDH+aRSA+SHA384
	0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
		  
EECDH+aRSA+SHA256
	0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA256
		  
EECDH+aRSA+RC4
	0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
		  
EECDH
	0xC0,0x30 - ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(256) Mac=AEAD
    0xC0,0x2C - ECDHE-ECDSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256) Mac=AEAD
    0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
    0xC0,0x24 - ECDHE-ECDSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA384
    0xC0,0x14 - ECDHE-RSA-AES256-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA1
    0xC0,0x0A - ECDHE-ECDSA-AES256-SHA  SSLv3 Kx=ECDH     Au=ECDSA Enc=AES(256)  Mac=SHA1
    0xC0,0x2F - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AESGCM(128) Mac=AEAD
    0xC0,0x2B - ECDHE-ECDSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128) Mac=AEAD
    0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA256
    0xC0,0x23 - ECDHE-ECDSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA256
    0xC0,0x13 - ECDHE-RSA-AES128-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA1
    0xC0,0x09 - ECDHE-ECDSA-AES128-SHA  SSLv3 Kx=ECDH     Au=ECDSA Enc=AES(128)  Mac=SHA1
    0xC0,0x12 - ECDHE-RSA-DES-CBC3-SHA  SSLv3 Kx=ECDH     Au=RSA  Enc=3DES(168) Mac=SHA1
    0xC0,0x08 - ECDHE-ECDSA-DES-CBC3-SHA SSLv3 Kx=ECDH     Au=ECDSA Enc=3DES(168) Mac=SHA1
    0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
    0xC0,0x07 - ECDHE-ECDSA-RC4-SHA     SSLv3 Kx=ECDH     Au=ECDSA Enc=RC4(128)  Mac=SHA1
    0xC0,0x10 - ECDHE-RSA-NULL-SHA      SSLv3 Kx=ECDH     Au=RSA  Enc=None      Mac=SHA1
    0xC0,0x06 - ECDHE-ECDSA-NULL-SHA    SSLv3 Kx=ECDH     Au=ECDSA Enc=None      Mac=SHA1
		  
EDH+aRSA
    0x00,0x9F - DHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(256) Mac=AEAD
    0x00,0x6B - DHE-RSA-AES256-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA256
    0x00,0x39 - DHE-RSA-AES256-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA1
    0x00,0x88 - DHE-RSA-CAMELLIA256-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(256) Mac=SHA1
    0x00,0x9E - DHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=DH       Au=RSA  Enc=AESGCM(128) Mac=AEAD
    0x00,0x67 - DHE-RSA-AES128-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA256
    0x00,0x33 - DHE-RSA-AES128-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA1
    0x00,0x9A - DHE-RSA-SEED-SHA        SSLv3 Kx=DH       Au=RSA  Enc=SEED(128) Mac=SHA1
    0x00,0x45 - DHE-RSA-CAMELLIA128-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(128) Mac=SHA1
    0x00,0x16 - EDH-RSA-DES-CBC3-SHA    SSLv3 Kx=DH       Au=RSA  Enc=3DES(168) Mac=SHA1

RC4
    0xC0,0x11 - ECDHE-RSA-RC4-SHA       SSLv3 Kx=ECDH     Au=RSA  Enc=RC4(128)  Mac=SHA1
    0xC0,0x07 - ECDHE-ECDSA-RC4-SHA     SSLv3 Kx=ECDH     Au=ECDSA Enc=RC4(128)  Mac=SHA1
    0xC0,0x16 - AECDH-RC4-SHA           SSLv3 Kx=ECDH     Au=None Enc=RC4(128)  Mac=SHA1
    0x00,0x18 - ADH-RC4-MD5             SSLv3 Kx=DH       Au=None Enc=RC4(128)  Mac=MD5
    0xC0,0x0C - ECDH-RSA-RC4-SHA        SSLv3 Kx=ECDH/RSA Au=ECDH Enc=RC4(128)  Mac=SHA1
    0xC0,0x02 - ECDH-ECDSA-RC4-SHA      SSLv3 Kx=ECDH/ECDSA Au=ECDH Enc=RC4(128)  Mac=SHA1
    0x00,0x05 - RC4-SHA                 SSLv3 Kx=RSA      Au=RSA  Enc=RC4(128)  Mac=SHA1
    0x00,0x04 - RC4-MD5                 SSLv3 Kx=RSA      Au=RSA  Enc=RC4(128)  Mac=MD5
    0x00,0x8A - PSK-RC4-SHA             SSLv3 Kx=PSK      Au=PSK  Enc=RC4(128)  Mac=SHA1
    0x00,0x20 - KRB5-RC4-SHA            SSLv3 Kx=KRB5     Au=KRB5 Enc=RC4(128)  Mac=SHA1
    0x00,0x24 - KRB5-RC4-MD5            SSLv3 Kx=KRB5     Au=KRB5 Enc=RC4(128)  Mac=MD5
{code}


{color:#DE350B}these groups can be deleted{color}
* EECDH+aRSA+AESGCM
* EECDH+ECDSA+AESGCM
* EECDH+ECDSA+SHA384
* EECDH+ECDSA+SHA256
* EECDH+aRSA+SHA384
* EECDH+aRSA+SHA256
* EECDH+aRSA+RC4

these ciphers are duplicates and anyways configured with
SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 *EECDH* EDH+aRSA RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""

and also RC4 can be deleted because its anyways excluded?

*so i would rather configure it like that:*
{code:java}
SSLCipherSuite ""EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""
{code}
","21/Jul/20 12:51;cs687;*(2) exclude the ciphers which are mentioned in the description*
*!DHE+aRSA+AES+SHA*
{code:java}
TLS_DHE_RSA_WITH_AES_256_CBC_SHA
0x00,0x39 - DHE-RSA-AES256-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA1

TLS_DHE_RSA_WITH_AES_128_CBC_SHA
0x00,0x33 - DHE-RSA-AES128-SHA      SSLv3 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA1
{code}

*!DHE+aRSA+AES+SHA256*
{code:java}
TLS_DHE_RSA_WITH_AES_128_CBC_SHA256
0x00,0x67 - DHE-RSA-AES128-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(128)  Mac=SHA256

TLS_DHE_RSA_WITH_AES_256_CBC_SHA256
0x00,0x6B - DHE-RSA-AES256-SHA256   TLSv1.2 Kx=DH       Au=RSA  Enc=AES(256)  Mac=SHA256
{code}
 
*!DHE+aRSA+CAMELLIA*
{code:java}
TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA
0x00,0x45 - DHE-RSA-CAMELLIA128-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(128) Mac=SHA1

TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA
0x00,0x88 - DHE-RSA-CAMELLIA256-SHA SSLv3 Kx=DH       Au=RSA  Enc=Camellia(256) Mac=SHA1
{code}

*!ECDHE+aRSA+AES+SHA*
{code:java}
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
0xC0,0x14 - ECDHE-RSA-AES256-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA1

TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
0xC0,0x13 - ECDHE-RSA-AES128-SHA    SSLv3 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA1
{code}

*!ECDHE+aRSA+AES+SHA256*
{code:java}
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
0xC0,0x27 - ECDHE-RSA-AES128-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(128)  Mac=SHA256
{code}

*!ECDHE+aRSA+AES+SHA384*
{code:java}
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384
0xC0,0x28 - ECDHE-RSA-AES256-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  Enc=AES(256)  Mac=SHA384
{code}

*cipher configuration should looks like:*
{code:java}
SSLCipherSuite ""EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !DHE+aRSA+AES+SHA !DHE+aRSA+AES+SHA256 !DHE+aRSA+CAMELLIA !ECDHE+aRSA+AES+SHA !ECDHE+aRSA+AES+SHA256 !ECDHE+aRSA+AES+SHA384""
{code}

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1000/files","22/Jul/20 09:45;cs687;*Next step:*
We have to verify the current set (cipher suite) before deploying the new one. 
[~pd122] will try to test it with the tool ""nmap""

For testing the new cipher set we can use the internal test-env´s *ate1* or *ate5*","22/Jul/20 14:19;pd122;something to be aware of regarding point 3 (Logjam vulnerability):

Based on  [https://httpd.apache.org/docs/current/ssl/ssl_faq.html:]
{quote}Java 7 and earlier limit their support for DH prime sizes to a maximum of 1024 bits.

If your Java-based client aborts with exceptions such as java.lang.RuntimeException: Could not generate DH keypair and java.security.InvalidAlgorithmParameterException: Prime size must be multiple of 64, and can only range from 512 to 1024 (inclusive), and httpd logs tlsv1 alert internal error (SSL alert number 80) (at LogLevel info or higher), you can either rearrange mod_ssl's cipher list with SSLCipherSuite (possibly in conjunction with SSLHonorCipherOrder), or you can use custom DH parameters with a 1024-bit prime, which will always have precedence over any of the built-in DH parameters.
{quote}","27/Jul/20 10:26;pd122;*m7t* web deployed to *ate5* and cipher check (using openssl) peformed:

 
{code:java}
ciphers=$(openssl ciphers 'ALL:eNULL' | sed -e 's/:/ /g')
for cipher in ${ciphers[@]}
do
  echo -n | openssl s_client -cipher ""$cipher"" -connect localhost:60500 -servername ate5.shrd.m7.deutsche-boerse.com
done
{code}
 

Result:
{code:java}
Testing ECDHE-RSA-AES256-GCM-SHA384
Testing ECDHE-RSA-AES256-SHA384
Testing ECDHE-RSA-AES256-SHA
Testing DHE-RSA-AES256-GCM-SHA384
Testing DHE-RSA-AES256-SHA256
Testing DHE-RSA-AES256-SHA
Testing DHE-RSA-CAMELLIA256-SHA
Testing ECDHE-RSA-AES128-GCM-SHA256
Testing ECDHE-RSA-AES128-SHA256
Testing ECDHE-RSA-AES128-SHA...YES
Testing DHE-RSA-AES128-GCM-SHA256
Testing DHE-RSA-AES128-SHA256
Testing DHE-RSA-AES128-SHA
Testing DHE-RSA-SEED-SHA
Testing DHE-RSA-CAMELLIA128-SHA{code}","27/Jul/20 11:25;pd122;installed and ran *nmap* on the web host to verify the set:

 
{code:java}
[pd122@m7shrdinteweb1 ~]$ nmap -sV --script ssl-enum-ciphers -p 60500 localhost
Starting Nmap 6.40 ( http://nmap.org ) at 2020-07-27 11:21 CEST
Nmap scan report for localhost (127.0.0.1)
Host is up (0.000038s latency).
Other addresses for localhost (not scanned): 127.0.0.1
PORT STATE SERVICE VERSION
60500/tcp open ssl/http Apache httpd
| ssl-enum-ciphers: 
| SSLv3: No supported ciphers found
| TLSv1.2: 
| ciphers: 
| TLS_DHE_RSA_WITH_AES_128_CBC_SHA - strong
| TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_CBC_SHA - strong
| TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA - strong
| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA - strong
| TLS_DHE_RSA_WITH_SEED_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong
| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| compressors: 
| NULL
|_ least strength: strong
 
{code}","27/Jul/20 13:38;pd122;tested several cipher list:

- ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4"": (result is the same as with original setup)
{code:java}
| TLSv1.2: 
| ciphers: 
| TLS_DHE_RSA_WITH_AES_128_CBC_SHA - strong
| TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_CBC_SHA - strong
| TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA - strong
| TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA - strong
| TLS_DHE_RSA_WITH_SEED_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong
| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| compressors: 
| NULL
|_ least strength: strong{code}
 

- ""EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !DHE+aRSA+AES+SHA !DHE+aRSA+AES+SHA256 !DHE+aRSA+CAMELLIA !ECDHE+aRSA+AES+SHA !ECDHE+aRSA+AES+SHA256 !ECDHE+aRSA+AES+SHA384"": (offered cipher set is rather limited)
{code:java}
| TLSv1.2: 
| ciphers: 
| TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| TLS_DHE_RSA_WITH_SEED_CBC_SHA - strong
| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| compressors: 
| NULL
|_ least strength: strong{code}","28/Jul/20 16:04;pd122;All CBC ciphers eliminated with:

 
{code:java}
SSLProtocol all -SSLv3 -TLSv1 -TLSv1.1
SSLHonorCipherOrder on
SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
{code}
{code:java}
PORT STATE SERVICE VERSION
60500/tcp open ssl/http Apache httpd
| ssl-enum-ciphers: 
| SSLv3: No supported ciphers found
| TLSv1.2: 
| ciphers: 
| TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
| compressors: 
| NULL
|_ least strength: strong{code}
 ","29/Jul/20 13:36;pd122;Deployed to ATE5 ICS env.","31/Jul/20 14:26;pd122;[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1000] merged into the master",,,,,,,,,,,,,,,,,
HUPX CUTE Server Certificates expires soon,M7P-6546,97913,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,10/Jul/20 10:21,30/Jul/20 14:19,16/Sep/21 14:11,27/Jul/20 09:37,,6.10.157,7tops_sprint12,,,,,,,M7PRODOPS,,,,,,,"For hupx-cute the server (WEB/SSL) certificates will expire soon. 

WEB-CERTS:
{code:java}
apache@m7shrdexteweb1:[/shrd/ssl]$ openssl x509 -in /shrd/ssl/cute1_hupx_m7_deutsche-boerse_com_cert.crt -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            1f:e5:5a:71:be:f0:e3:a4:c6:ed:1e:93:ef:0a:b2:08
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jul 31 00:00:00 2018 GMT
            Not After : Jul 30 23:59:59 2020 GMT
{code}
{color:#DE350B}*Not After : Jul 30 23:59:59 2020 GMT*{color}

HA-CERTS:
{code:java}
sslsrv@m7shrdextessl1:[/shrd/vault/hupx-cute-app-haproxy1]$  openssl x509 -in server-cert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            1f:e5:5a:71:be:f0:e3:a4:c6:ed:1e:93:ef:0a:b2:08
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jul 31 00:00:00 2018 GMT
            Not After : Jul 30 23:59:59 2020 GMT
{code}

{color:#DE350B}*Not After : Jul 30 23:59:59 2020 GMT*{color}",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/20 09:16;cs687;hupx-cute.PNG;https://jira.deutsche-boerse.com/secure/attachment/86018/hupx-cute.PNG",,,,,,,,,,,,,,,sw455,,,,,,,,"renewed the certificates new experation date: 
Not After : Jul 14 23:59:59 2022",,,,,,,,HUPX,,,,,,,,,,,,,,,,35942400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzwrs7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"* requested new certificates by ssl-admin team
* uploaded the new certs to vault 
* renewed the certificates to the m7shrdexteweb1|2 and m7shrdextessl1|2|3|4 hosts 
* restarted the instances on the mentioned hosts above 

* post checks ",,,,,,,,,,"{""issueId"":97913,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"10/Jul/20 10:50;cs687;added hupx-cute to energy.automation.certificate in vars.yml 
https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/13/files
*1.) Run the Job ""Project A. Generate CSR (Ansible Deployment)""*
{code:java}
Started by user Steffen Englert
Running as SYSTEM
[EnvInject] - Loading node environment variables.
Building remotely on englobauto1 (englobauto) in workspace /home/jenkins/workspace/Energy-Operations/Certificate Deploy/A. Generate CSR (Ansible Deployment)
using credential ff4c895e-1043-458e-be44-195fb4d1b1b2
 > git rev-parse --is-inside-work-tree # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url git@github.deutsche-boerse.de:dev/energy.automation.certificate.git # timeout=10
Fetching upstream changes from git@github.deutsche-boerse.de:dev/energy.automation.certificate.git
 > git --version # timeout=10
using GIT_SSH to set credentials 
 > git fetch --tags --progress -- git@github.deutsche-boerse.de:dev/energy.automation.certificate.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git rev-parse refs/remotes/origin/tuan^{commit} # timeout=10
 > git rev-parse refs/remotes/origin/origin/tuan^{commit} # timeout=10
Checking out Revision f3ef59e8d87f15061bf5167c3eefde4fde00c05c (refs/remotes/origin/tuan)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f f3ef59e8d87f15061bf5167c3eefde4fde00c05c # timeout=10
Commit message: ""Merge pull request #13 from dev/M7P-6546""
 > git rev-list --no-walk 7abe57a6f50ce9160a796888c5afc95559e7315b # timeout=10
New run name is '#generate_csr_m7t_hupx_cute'
[A. Generate CSR (Ansible Deployment)] $ /bin/sh -xe /tmp/jenkins4936224262101349103.sh
+ ansible-playbook gencsr.yml --extra-vars '{ '\''PROD'\'': '\''m7t'\'', '\''CUS'\'': '\''hupx'\'', '\''ENV'\'':'\''cute'\'', '\''EMAIL'\'':'\''steffen.englert@deutsche-boerse.com'\''}'
 [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source
 [WARNING]: No inventory was parsed, only implicit localhost is available
 [WARNING]: provided hosts list is empty, only localhost is available. Note
that the implicit localhost does not match 'all'
PLAY [127.0.0.1] ***************************************************************

TASK [Gathering Facts] *********************************************************
ok: [127.0.0.1]

TASK [Generate Private Key] ****************************************************
changed: [127.0.0.1]

TASK [Generate Certificate Signing Request (CSR)] ******************************
changed: [127.0.0.1]

TASK [Generate Certificate Signing Request (CSR)] ******************************

TASK [Import private key and chain to vault] ***********************************
changed: [127.0.0.1]

TASK [Import private key and chain to vault second key] ************************
changed: [127.0.0.1]

TASK [Send email with the CSR as attachment] ***********************************
ok: [127.0.0.1 -> localhost]

PLAY RECAP *********************************************************************
127.0.0.1                  : ok=6    changed=4    unreachable=0    failed=0   

New run name is '#generate_csr_m7t_hupx_cute'
Finished: SUCCESS
{code}

added in vault two entries via executing the jenkins job above: 
* Request_cute1.hupx.m7.deutsche-boerse.com
* Request_cute2.hupx.m7.deutsche-boerse.com
","10/Jul/20 11:02;cs687;Created the SERVICE-REQUEST 6B0104 
and send the Email out to SSL-ADMIN´s

{code:java}
Hello,
Please sign the attached CSR(s) with maximum possible validity.
Alternative Names:
[cute1.hupx.m7.deutsche-boerse.com, cute2.hupx.m7.deutsche-boerse.com]


Thanks. 
Regards

{code}
","27/Jul/20 08:51;cs687;*2.) Downloaded the renewed certificates and uploaded it with the following Jenkins Job*

* Project B. Import Cert to Vault (Ansible Deployment)
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/B.%20Import%20Cert%20to%20Vault%20(Ansible%20Deployment)/","27/Jul/20 08:53;cs687;*3.) Rollout the certificates with the following ansible-commands*

* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*hupx-cute-app-haproxy*"" --tags certs -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*hupx-cute-app-web*"" --tags certs -k -K -b

Checking if the cert´s were successfully renewed: 
{code:java}
sslsrv@m7shrdextessl1:[/shrd/vault/hupx-cute-app-haproxy1]$  openssl x509 -in server.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            0e:45:28:82:27:74:29:66:8c:e3:1b:73:df:ab:93:75
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=Sectigo Limited, CN=Sectigo RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jul 14 00:00:00 2020 GMT
            Not After : Jul 14 23:59:59 2022 GMT
{code}


","27/Jul/20 09:16;cs687;*4.) Restarted WEB and HA instances*

* ansible-playbook playbooks/deploy_haproxy.yml --limit ""m7t*hupx-cute-app-haproxy*"" --tags stop,start -k -K -b
* ansible-playbook playbooks/deploy_apache.yml --limit ""m7t*hupx-cute-app-web*"" --tags stop,start -k -K -b

 !hupx-cute.PNG! ","27/Jul/20 09:37;cs687;done",,,,,,,,,,,,,,,,,,,,,,
set not expiring LDAP password policy for admin accounts,M7P-6545,97911,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pd122,pd122,10/Jul/20 10:10,05/Jan/21 14:06,16/Sep/21 14:11,14/Jul/20 16:23,,7tops_sprint10,,,,,,,,7tops,M7PRODOPS,,,,,,"Set bellow policy for admin accounts defined in -M7P-5076:-
{code:java}
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
passwordMinAge: 0
passwordLockout: off
passwordMaxAge: 259200
passwordUnlock: off
passwordMaxFailure: 3
passwordChange: on
passwordLockoutDuration: 900
passwordStorageScheme: ssha
passwordExp: off
passwordWarning: 432000
objectClass: top
objectClass: passwordpolicy
objectClass: ldapsubentry
passwordResetFailureCount: 60
cn: cn=nsNoExpPwPolicyEntry,o=M7,dc=energy,dc=test
passwordMustChange: off
passwordInHistory: 0
passwordGraceLimit: 0{code}",,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,pwdPolicySubentry attribute modified for provided technical accounts to reference the new policy,,,,,,,,,,,,,,,,,,,,,,,,36979200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxz1r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97911,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Jul/20 10:16;pd122;list of admin accounts that need to have non expiring password policy set provided in M7P-5076

unfortunately *mtt* users are listed as vault entry  _/secret/m7t/elts/lipa/mtt2/m7_user_password:value_ (the secret contains the user's password not its name)","10/Jul/20 15:27;pd122;It appears that at this time only ELTS ACUT and CTPB environments have specific password policy (with password expiration) configured. Admin accounts of those 2 environments have been already assigned non password expiring policy.","14/Jul/20 14:20;pd122;these are remaining 20 external test technical accounts (I was able to identify) that will have password policy updated:
{code:java}
uid=DBGCARD1,ou=lipa,ou=elts-app,o=M7,dc=energy,dc=test
uid=DBGCARD2,ou=lipa,ou=elts-app,o=M7,dc=energy,dc=test
uid=elts-app-lipa-adm,ou=lipa,ou=elts-app,o=M7,dc=energy,dc=test
uid=DBGCARD1,ou=simu,ou=elts-app,o=M7,dc=energy,dc=test
uid=DBGCARD2,ou=simu,ou=elts-app,o=M7,dc=energy,dc=test
uid=elts-app-simu-adm,ou=simu,ou=elts-app,o=M7,dc=energy,dc=test
uid=CARDIO01,ou=asim,ou=epex-app,o=M7,dc=energy,dc=test
uid=CARDIO02,ou=asim,ou=epex-app,o=M7,dc=energy,dc=test
uid=epex-app-asim-adm,ou=asim,ou=epex-app,o=M7,dc=energy,dc=test
uid=flex-app-simu-adm,ou=simu,ou=flex-app,o=M7,dc=energy,dc=test
uid=hupx-app-asim-adm,ou=asim,ou=hupx-app,o=M7,dc=energy,dc=test
uid=hupx-app-cute-adm,ou=cute,ou=hupx-app,o=M7,dc=energy,dc=test
uid=hupx-app-simu-adm,ou=simu,ou=hupx-app,o=M7,dc=energy,dc=test
uid=plpx-app-lipa-adm,ou=lipa,ou=plpx-app,o=M7,dc=energy,dc=test
uid=plpx-app-simu-adm,ou=simu,ou=plpx-app,o=M7,dc=energy,dc=test
uid=xrpm-app-lipa-adm,ou=lipa,ou=xrpm-app,o=M7,dc=energy,dc=test
uid=xrpm-app-simu-adm,ou=simu,ou=xrpm-app,o=M7,dc=energy,dc=test
uid=xsop-app-asim-adm,ou=asim,ou=xsop-app,o=M7,dc=energy,dc=test
uid=xsop-app-cute-adm,ou=cute,ou=xsop-app,o=M7,dc=energy,dc=test
uid=xsop-app-simu-adm,ou=simu,ou=xsop-app,o=M7,dc=energy,dc=test{code}","14/Jul/20 16:21;pd122;At the same time 2 changes were applied to newly assigned password policy:

- passwordMaxAge removed

- passwordMaxFailure: 3 -> 5

 ",,,,,,,,,,,,,,,,,,,,,,,,
fix EBSM_Maintenance-Outage_Times job,M7P-6539,97849,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,wn626,wn626,08/Jul/20 13:54,17/Dec/20 15:26,16/Sep/21 14:11,13/Jul/20 11:29,,6.10.146,7tops_sprint10,,,EBSM,,,,EBSM,M7PRODOPS,,,,,,"EBSM_Maintenance-Outage_Times job is not working, logs can be found in:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/EBSM_Maintenance-Outage_Times/210/console

Possibly it's related to migration to PostgreSQL EBSM database.
We need to fix it",,dp007,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"[https://github.deutsche-boerse.de/dev/energy.ebsm/pull/25]

[https://github.deutsche-boerse.de/dev/energy.ebsm/pull/26]

 ",,,,,,,,,,,,,,,,,,,,,,,,37065600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxpcn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97849,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jul/20 11:29;dp007;job fixed: [https://github.deutsche-boerse.de/dev/energy.ebsm/pull/25]

 ","13/Jul/20 14:21;wn626;It's still not working:

[https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/EBSM_Maintenance-Outage_Times/211/console]","13/Jul/20 15:28;dp007;all three actions do work now:
insert -  [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/EBSM_Maintenance-Outage_Times/214/console]

delete - [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/EBSM_Maintenance-Outage_Times/213/console]

display - [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/RestrictedAccess/job/EBSM_Maintenance-Outage_Times/212/console]

 ",,,,,,,,,,,,,,,,,,,,,,,,,
missing clean-up cronjob for tomcat hosts,M7P-6531,97770,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,06/Jul/20 15:32,16/Jul/20 13:22,16/Sep/21 14:11,07/Jul/20 07:38,,6.10.149,7tops_sprint10,,,,,,,M7PRODOPS,,,,,,,"We figured out that we have some missing clean-up job for tomcat hosts m7b1/2 
for production and simulation 

ansible 'm7t*cor*' -m shell -b -a ""ls -all /etc/cron.d/clean_tomcat_logfiles"" -k -K
{code:java}
m7t-flex-prod-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-flex-prod-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-flex-simu-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-flex-simu-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-hupx-asim-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xsop-cute-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xsop-cute-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xsop-asim-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xsop-asim-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-elts-simu-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-elts-simu-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-plpx-lipa-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-plpx-lipa-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-plpx-simu-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-plpx-simu-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-lipa-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-lipa-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-simu-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-simu-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-prod-cor2 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code

m7t-xrpm-prod-cor1 | FAILED | rc=2 >>
ls: cannot access /etc/cron.d/clean_tomcat_logfiles: No such file or directorynon-zero return code
{code}

we need to create the proper file in /etc/cron.d/clean_tomcat_logfiles
and add the proper cronjob settings. 

I am not sure if there is already an ansible role existing for that. 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,37670400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxzgv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97770,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/20 07:12;cs687;*Created the missing cronjob file:*
ansible 'm7t*xrpm-simu-cor1' -m shell -b -a ""touch /etc/cron.d/clean_tomcat_logfiles"" -k -K

*Copy the proper command into the file:*
ansible 'm7t*xrpm-simu-cor1' -m shell -b -a 'echo 30 5 * * * root /usr/bin/find /*/logs/*{{customer}}*/ -name ""*.log*"" -type f -mtime +4 -exec rm {} \; >> /etc/cron.d/clean_tomcat_logfiles' -k -K
","07/Jul/20 07:38;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Report for June,M7P-6528,97749,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,oh856,oh856,03/Jul/20 15:53,21/Jul/20 23:21,16/Sep/21 14:11,17/Jul/20 10:05,,6.10.153,7tops_sprint7,,,,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD|  2020-07-13|  2020-07-15(Volkan)|
| M7 EPEX FLEX|  2020-07-13|  2020-07-15(Volkan) |
| M7 EPEX ASIM|  2020-07-13|  2020-07-15(Volkan) |
| M7 HUPX|  2020-07-13|  2020-07-15(Volkan) |
| M7 XSOP|  2020-07-13|  2020-07-15(Volkan) |
| M7 TGE|  2020-07-13|  2020-07-15(Volkan) |
| M7 OPCOM|  2020-07-13|  2020-07-15(Volkan) |
| M7 AUCTION|  2020-07-02| 2020-07-08(Volkan)|
| ICS / Swissgrid|  2020-07-13| 2020-07-15(Iaroslav)|

Link to teams: [https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2020%2D06&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D]

Greenlight requesting email should be sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>; Volkan Eymir Akcora <volkan.eymir.akcora@deutsche-boerse.com>; 
{code}
 ",,oh856,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,All reports have been distributed to the clients.,,,,,,,,,,,,,,,,,,,,,,,,37929600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxz13:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97749,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make component field required,M7P-6502,97673,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,ax460,ax460,ax460,02/Jul/20 14:39,19/May/21 14:32,16/Sep/21 14:11,04/Dec/20 11:15,,6.11.132,7tops_sprint107,,,JIRA,,,,7tops_comm,M7PRODOPS,S,,,,,"Make component field required in transition screen (→ Resolved) in Jira

 

see motivation [M7 Development CoP|https://confluence.energy.svc.dbgcloud.io/display/EIT/M7T+Development+CoP]",,ax460,dp007,sJ194,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"component field required in transition screen for Task, bugs and story type fir M7P Project",,,,,,,,,,,,,,,,,,,,,,,,24710400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzygr3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97673,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Oct/20 15:15;sJ194;M7T product related issue","28/Oct/20 10:13;yq577;Hi [~ax460] ,

 

I updated component field required in transition screen for Task, bugs and story type fir M7P Project.

 

Thanks and Regards,

Sharad","04/Dec/20 10:37;dp007;issue resolved, closing the ticket",,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 TGE PROD deliver 6.9.150,M7P-6497,97653,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,ax460,rehapav,rehapav,02/Jul/20 11:35,26/Nov/20 17:00,16/Sep/21 14:11,02/Jul/20 14:20,,7tops_sprint10,,,,,,,09/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Prepare PRs for linked deplyment
 * initial delivery of 6.9 to this environment
 * upgrade of various 3rd party tools like defined in M7P-5812
 ** Software version
 *** PR:  [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1950]
 ** AZUL 1.8.0_242
 *** PR [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1950]
 ** RABIITMQ 3.8.3
 *** PR;   *[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1950]*
 ** TOMCAT 8.5.50
 *** PR no PR for tomcat is required 8.5.50 is default version.
 *** please check
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1950]

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6676,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,pr created,,,,,,,,TGE,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,xt853,,,No,38102400,,PROD,dm700,lw641,ox626,rehapav,sw455,,14/Jul/20 10:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxyvr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 96 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97653,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ungraceful disconnection test 6.8 M7TOPS,M7P-6494,97642,97635,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cs687,th409,th409,02/Jul/20 09:38,15/Jul/20 11:03,16/Sep/21 14:11,03/Jul/20 14:07,,7tops_sprint10,,,,,,,,M7PRODOPS,,,,,,,"TIME: 3/7/2020 13.00-14.00
Actions needed:
peform the ungraceful diesconnection (5 minutes of disconnection), simmilar as f.e M7P-6418",,cs687,th409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38016000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxytz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 96 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97642,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 14:07;cs687;stopped xbid-connectivity with version 6.8 and 6.9, we figured out now differences with these tests. 

Blocking: 
{code:java}
ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-shrd-syt3-cor* -b -K -k --tag block
{code}

Re-connecting:
{code:java}
ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-shrd-syt3-cor* -b -K -k --tag flush
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
"SERVICE CLONE: ""stand by modus"" for ENERA test and prod environment ",M7P-6492,97627,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,tj898,tj898,01/Jul/20 16:00,16/Jul/20 13:22,16/Sep/21 14:11,01/Jul/20 16:31,,6.10.149,7tops_sprint10,,,,,,29/May/20 00:00,M7PRODOPS,,,,,,,"Dear all

EPEX would like to have the ENERA Environments de-comissioned as of 1st of July 2020. 

 

The environments in question are:

M7 ENERA - FLEX-M7 PROD Environment

M7 ENERA - FLEX-M7 TEST Environment

 

EPEX plans to launch a similar ENERA like environment in the near future. 

internally (DBAG) we decided that it´s cheaper to keep the environments alive in a stand-by mode until (approximately September/October 2020 ) EPEX needs again such an environment. We would reuse the FLEX one.

(EPEX is aware that the name of the environment can not be changed)

that means the environments should be{color:#de350b} *not decommissioned*{color} completely, 

*Please stop services for both environments by 1st of July (no access for users from the internet) and hibernate the environment so that it could be reactivated later on.*

 

If EPEX wants to reuse the environment how much lead time would we need to reactivate it again?

 

 Denise 

 ",,cs687,tj898,,,,,,,,,,,,,,,,,,SERVICE-6343,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,EPEX,,,,,,,,,,,,,,,,38102400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxyqv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97627,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,FPROD,,,,"01/Jul/20 16:00;lu515;[~lw641] i am wondering why this ticket is not assigned to anybody.  please make sure that all relevant tasks will be done by end of the month.","01/Jul/20 16:00;lu515;Dear all EPEX just contact me about the following request. 

I told her to create a separate Service ticket by her own. However due to the time pressure i will copy her message here as well:

 

Dear Denise, DBAG colleagues,

 

In the context of the upcoming decommissioning of the M7 flex market environments, EPEX would like to discuss a couple of topics with you.

 

First of all, we see a need to align on the timing for the decommissioning: we plan to close the market for the members tomorrow afternoon (30/06) but will need to perform a last post trading run on 01/07 to treat the orders from 30/06. Can you confirm that we can still access the M7 flex environment with our DTT/LISEco user on July 1^st^? We plan to give you a go to cut our access to the M7 flex environments after having verified that all reporting was correctly generated on July 1^st^ by close of business.

 

On the long term, we would like to check if the environments can be mothballed for up to 12 months as we do not expect a new flex market to be implemented before mid 2021.

 

Would you be available to discuss these topics in a short call tomorrow morning between 9 and 11.30? Thank you in advance for your flexibility

 

Kind Regards,

Maxime","01/Jul/20 16:00;lu515;EPEX informed us yesterday that the do NOT expect to have a new customer using the flex prod and flex test environment again earlier thatn Q2 2021. Please let me know what would be cheaper for us:
 # keep the environments up and running in a standby mode
 # or to completely decommission and set up from scratch in Q2  (not sure yet as the customer has not done a final decision) ","01/Jul/20 16:30;cs687;FLEX-SIMU and FLEX-PROD were stopped","01/Jul/20 16:31;cs687;.",,,,,,,,,,,,,,,,,,,,,,,
decomissioning of outstanding VMs,M7P-6491,97625,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,rehapav,rehapav,01/Jul/20 15:42,15/Dec/20 09:05,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"AuditD configuration will not rolled out on the following machines:

M7PPG1,M7PPG2, M7SPG1,M7SPG2, M7PRODLDAP1, M7PRODLDAP2, M7CICSCASIMAMQ1, M7CICSCASIMAMQ2, M7CICSCASIMAPP1, M7CICSCASIMAPP2.

These are completely deprecated and should be replaced/decommissioned

 

todo
 * check if these are used by any of our environment
 * provide timeline when these can be decomissioned

input from [~rehapav] (to be confirmed)
 * M7PPG1,M7PPG2, M7SPG1,M7SPG2, -> these should be old DBs - currently used by last M7 App ICSC - decommissioning foreseen 11-12/2020
 * M7PRODLDAP1, M7PRODLDAP2 -> old LDAP, migration in progress ->- decommissioning foreseen 11-12/202
 * M7CICSCASIMAMQ1, M7CICSCASIMAMQ2, M7CICSCASIMAPP1, M7CICSCASIMAPP2. no idea what are these machines about

 ",,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38102400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzyynj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97625,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 ELTS LIPA deliver product increment 6.9.150 ,M7P-6484,97606,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,ax460,rehapav,rehapav,01/Jul/20 12:43,26/Nov/20 17:01,16/Sep/21 14:11,01/Jul/20 14:04,,7tops_sprint10,,,,,,,02/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Prepare PR for 
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1947] 

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6667,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,PR created,,,,,,,,ELTS,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,38188800,,LIPA,dm700,lw641,ox626,rehapav,sw455,,03/Jul/20 12:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxynb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 96 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97606,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,LIPA,master,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"SPIKE: Disabling ""directory listings"" in application server configuration (production staging)",M7P-6476,97550,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:47,22/Sep/20 23:39,16/Sep/21 14:11,10/Sep/20 13:34,,6.8.142,,,,,,,,M,M7PRODOPS,,,,,,"*related ticket:*
https://vmt.deutsche-boerse.de/browse/PT-1512

Recommendation: If directory listings are not explicitly requested, we recommend disabling them in the application server configuration.

once it is proofed it is working in ticket
https://jira.deutsche-boerse.com/browse/M7P-6474
https://jira.deutsche-boerse.com/browse/M7P-6475",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"deployed new ctp version 1.9.304 which was already tested on internal and external profile-server 

deployed it on ctp2 and afterwards ctp1 

checked the following url´s
* https://prod1.profiles.m7.deutsche-boerse.com:60000/plpx-app-prod/
* https://prod1.profiles.m7.deutsche-boerse.com:60000/plpx-app-prod/info
* https://prod1.profiles.m7.deutsche-boerse.com:60000/plpx-app-prod/health 

and also the second URL, can confirm that listing directories are disabled. 

",,,,,,,,,,,,,,,,,,,,,,,,32054400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxxon:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,,,"running the Ansible Deployment with the Job: *Project M7-Deploy-Playbook*
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/

and parameters: -e artifact_version=1.9.304 -e consul_enabled=false -e app_version=1.9.304

old application directories are stored in /tmp
and can be used to roll-back ",,,,,,,,,,"{""issueId"":97550,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/20 13:31;cs687;Deployed m7t-shrd-prod-ctp2
and m7t-shrd-prod-ctp1

{code:java}
{""status"":""UP"",""components"":{""dataSource"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""validationQuery"":""isValid()""}},""ping"":{""status"":""UP""}}}
{code}

and the listing directories are disabled 
* https://prod1.profiles.m7.deutsche-boerse.com:60000/plpx-app-prod/
* https://prod2.profiles.m7.deutsche-boerse.com:60000/plpx-app-prod/","10/Sep/20 13:34;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,
"SPIKE: Disabling ""directory listings"" in application server configuration (external staging)",M7P-6475,97548,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:46,22/Sep/20 23:39,16/Sep/21 14:11,09/Sep/20 16:49,,6.8.142,,,,,,,,ICS,M,M7PRODOPS,,,,,"*related ticket:*
https://vmt.deutsche-boerse.de/browse/PT-1512

Recommendation: If directory listings are not explicitly requested, we recommend disabling them in the application server configuration.

once it is proofed it is working in ticket 
https://jira.deutsche-boerse.com/browse/M7P-6474",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"new version is fixing the issue. 
more information's are described in the tickets: 
* https://jira.deutsche-boerse.com/browse/M7P-6474
* https://jira.deutsche-boerse.com/browse/M7P-5063",,,,,,,,,,,,,,,,,,,,,,,,32054400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzn6c7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 15,,,,,,,,,,,,,,,,,,,,,,,,,,refer Change description,,,,,,,,,,"{""issueId"":97548,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Jul/20 09:58;cs687;will be solved with that PR: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1963#pullrequestreview-223998
and re-deployment of CTP External Profileserver","09/Sep/20 16:47;cs687;no need for the mentioned pull-request above. the CTP Version comes with the M7P Version and for the external Profile-Server we have deployed the version 1.9.304 
findings in ticket PT-1512 are fixed!
","09/Sep/20 16:49;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
"SPIKE: Disabling ""directory listings"" in application server configuration (internal test staging)",M7P-6474,97547,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:45,15/Jul/20 11:03,16/Sep/21 14:11,14/Jul/20 09:55,,7tops_sprint10,,,,,,,,7tops_comm,M,M7PRODOPS,,,,,"*related ticket:*
https://vmt.deutsche-boerse.de/browse/PT-1512

Recommendation: If directory listings are not explicitly requested, we recommend disabling them in the application server configuration.

properly changing ansible-role and redeploy tomcat",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,37065600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxv6f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97547,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/20 09:47;cs687;for the apache http instances its already disabled via ansible deployment: 
{code:java}
#
# Deny access to the entirety of your server's filesystem. You must
# explicitly permit access to web content directories in other
# <Directory> blocks below.
#
<Directory />
    Options FollowSymLinks
    AllowOverride None
</Directory>

#
# Relax access to content within /var/www.
#
<Directory ""/var/www"">
    AllowOverride None
    # Allow open access:
    Require all granted
</Directory>
{code}

Just the profile-server TRADING which is running with apache tomcat instances we have to change it and re-deploy it 
can be changed with the lines *<param-name>listings</param-name>* and *<param-value>false</param-value>*
{code:java}
<servlet>
          <servlet-name>default</servlet-name>
          <servlet-class>org.apache.catalina.servlets.DefaultServlet</servlet-class>
           ......
          <init-param>
                         <param-name>listings</param-name>
                         <param-value>false</param-value>
          </init-param>
          <load-on-startup>1</load-on-startup>
</servlet>
{code}

Solution find here: https://www.lostsaloon.com/technology/how-to-enable-and-disable-web-directory-listing-on-your-web-server/


tested URL´s 
* https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/
* https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/services
","06/Jul/20 10:07;cs687;{code:java}
    <servlet>
        <display-name>CXF Servlet</display-name>
        <servlet-name>CXFServlet</servlet-name>
        <servlet-class>org.apache.cxf.transport.servlet.CXFServlet</servlet-class>
        <load-on-startup>1</load-on-startup>
    </servlet>

    <servlet-mapping>
        <servlet-name>CXFServlet</servlet-name>
        <url-pattern>/services/*</url-pattern>
    </servlet-mapping>

    <servlet>
        <servlet-name>diagnostics</servlet-name>
        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
    </servlet>
    <servlet-mapping>
        <servlet-name>diagnostics</servlet-name>
        <url-pattern>/diagnostics/*</url-pattern>
    </servlet-mapping>

{code}
","07/Jul/20 10:51;cs687;[~ax460] has a similar ticket open and is working on it 
https://jira.deutsche-boerse.com/browse/M7P-5063

{code:java}
Task is to:

remove web pages from profile server:
index.html
/diagnostics/
/services/
And provide health check (replacing diagnostics page).
Following text is left just for evidence:
Multiple directories were found where directory listing was possible. A directory listing shows the complete content of a directory. To be specific, we were able to provoke a directory listing in the following directories:
{code}

Seems like the ticket from [~ax460] will solve the issue as well. 
Please give me a feedback, in case we can close the ticket M7P-6474 as a duplicate. 
Thanks","13/Jul/20 10:20;cs687;Problem seems like solved: 

{code:java}
remove web pages from profile server:
index.html
/diagnostics/
/services/
{code}

Page ""Profile storage server"" was removed with its services and diagnostics directory listing. Page was replaced by page ""Available SOAP services"" (see http://10.136.20.16:61400/shin-apa-syt3/)

more Information´s see: https://jira.deutsche-boerse.com/browse/M7P-5063
So next steps would be deploying external/production profile-server","14/Jul/20 09:55;cs687;Fixed in M7P-5684
http://10.136.20.16:61400/shin-apa-syt3/
http://10.136.20.16:61400/shin-apa-syt3/services

service directory listing was disabled
diagnostics page removed/disabled. 

Agreed with team and testers to keep the services-page (SOAP services).
 ",,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Replacing standard error pages of Tomcat server with neutral error pages (production staging),M7P-6473,97545,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,cs687,cs687,cs687,30/Jun/20 13:37,30/Jul/20 14:19,16/Sep/21 14:11,15/Jul/20 17:51,,7tops_sprint12,,,,,,,,M,M7PRODOPS,,,,,,"*related tickets:*
https://vmt.deutsche-boerse.de/browse/PT-1490 ICSC
https://vmt.deutsche-boerse.de/browse/PT-1510 Trading

The standard error pages of the Tomcat server should be replaced with neutral error pages not disclosing any details on the environment.
For Tomcat application server, individual error pages can be configured by setting the <error-page> directive.
Error pages for HTTP layer errors are set via <error-code>. Using this directive, the most common HTTP error codes should be covered, an error page for code 501 can be configured as follows:
<error-page>
<error-code>501</error-code>
<location>/error.html</location>
</error-page>
…

Since servlet specification 3.0 (for Tomcat since version 7.0.29), the <error-code> and <exception-type> settings are optional, so one common error page may be defined for any kind of error with the following directive:
<error-page>
<location>/error.html</location>
</error-page>",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,36892800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxxof:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97545,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/20 17:51;cs687;no further actions (deactivating the default error-pages and create our own one) needed, pls close vmt ticket

refer: https://jira.deutsche-boerse.com/browse/M7P-6470",,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Replacing standard error pages of Tomcat server with neutral error pages (external staging),M7P-6471,97543,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,cs687,cs687,cs687,30/Jun/20 13:33,30/Jul/20 14:19,16/Sep/21 14:11,15/Jul/20 17:51,,7tops_sprint12,,,,,,,,M,M7PRODOPS,,,,,,"*related tickets:*
https://vmt.deutsche-boerse.de/browse/PT-1490 ICSC
https://vmt.deutsche-boerse.de/browse/PT-1510 Trading

The standard error pages of the Tomcat server should be replaced with neutral error pages not disclosing any details on the environment.
For Tomcat application server, individual error pages can be configured by setting the <error-page> directive.
Error pages for HTTP layer errors are set via <error-code>. Using this directive, the most common HTTP error codes should be covered, an error page for code 501 can be configured as follows:
<error-page>
<error-code>501</error-code>
<location>/error.html</location>
</error-page>
…

Since servlet specification 3.0 (for Tomcat since version 7.0.29), the <error-code> and <exception-type> settings are optional, so one common error page may be defined for any kind of error with the following directive:
<error-page>
<location>/error.html</location>
</error-page>",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,36892800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzmx8v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97543,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jul/20 17:51;cs687;no further actions (deactivating the default error-pages and create our own one) needed, pls close vmt ticket

refer: https://jira.deutsche-boerse.com/browse/M7P-6470",,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Replacing standard error pages of Tomcat server with neutral error pages (internal test staging) ,M7P-6470,97542,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,cs687,cs687,cs687,30/Jun/20 13:32,30/Jul/20 14:19,16/Sep/21 14:11,15/Jul/20 17:44,,7tops_sprint12,,,,,,,,7tops_comm,M,M7PRODOPS,,,,,"*related tickets:*
https://vmt.deutsche-boerse.de/browse/PT-1490 ICSC
https://vmt.deutsche-boerse.de/browse/PT-1510 Trading

The standard error pages of the Tomcat server should be replaced with neutral error pages not disclosing any details on the environment.
For Tomcat application server, individual error pages can be configured by setting the <error-page> directive.
Error pages for HTTP layer errors are set via <error-code>. Using this directive, the most common HTTP error codes should be covered, an error page for code 501 can be configured as follows:
<error-page>
<error-code>501</error-code>
<location>/error.html</location>
</error-page>
…

Since servlet specification 3.0 (for Tomcat since version 7.0.29), the <error-code> and <exception-type> settings are optional, so one common error page may be defined for any kind of error with the following directive:
<error-page>
<location>/error.html</location>
</error-page>",,cs687,pn508,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,36979200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxv67:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,7tops Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97542,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jul/20 08:21;cs687;ansible tomcat-role (cmi/cmm and profileserver) need to be updated to change the following files for the default erorr-pages
/shrd/shrd-ate5-cmm1/tomcat/webapps/cmm/WEB-INF/web.xml
/shrd/shrd-ate5-cmm1/tomcat/webapps/cmm/WEB-INF/web.xml

{code:java}
    <error-page>
        <error-code>500</error-code>
        <location>/public/error/serverError.faces</location>
    </error-page>

    <error-page>
        <error-code>420</error-code>
        <location>/logout</location>
    </error-page>

    <error-page>
        <error-code>404</error-code>
        <location>/public/error/notFound.faces</location>
    </error-page>

    <error-page>
        <error-code>403</error-code>
        <location>/public/error/accessDenied.faces</location>
    </error-page>

    <error-page>
        <error-code>401</error-code>
        <location>/public/error/notAuthenticated.faces</location>
    </error-page>

    <error-page>
        <error-code>400</error-code>
        <location>/public/error/badRequest.faces</location>
    </error-page>

    <error-page>
        <exception-type>java.lang.Throwable</exception-type>
        <location>/public/error/serverError.faces</location>
    </error-page>
{code}
","06/Jul/20 08:53;cs687;From the first point of view i see no security issue, at least i tried Google-Chrome, IE and Firefox. 
i could see no tomcat version in the footer etc. 
Have to check that again, if we really have to investigate something on it. 
","09/Jul/20 12:29;cs687;Just talked to [~op211] about the finding which is mentioned above in the description. 
At the moment we have nothing to worry because there is no footer with discloses Information available 
https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/ssss

all what is visible is: 
{code:java}
Not found
The page you have requested cannot be found
{code}

so with the next penetration findings we have with that current tomcat version nothing to worry, but we don´t know how it will looks like after upgrading the tomcat version to a newer one. 
So its up to [~pn508] if we should do something like deactivating the default error-pages and create our own one. 

https://stackoverflow.com/questions/1520162/reducing-information-disclosure-in-tomcat-error-pages","15/Jul/20 14:04;pn508;no further actions (deactivating the default error-pages and create our own one) needed, pls close vmt ticket",,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Tomcat Application server´s default applications and the examples (production staging),M7P-6468,97540,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,op211,cs687,cs687,30/Jun/20 13:29,24/Feb/21 11:26,16/Sep/21 14:11,15/Feb/21 14:22,,7tops_sprint111,,,,uknown,,,,M,M7PRODOPS,,,,,,"*related Ticket:* https://vmt.deutsche-boerse.de/browse/PT-1493

We recommend removing the Tomcat application server’s default applications and the examples.

Example:
The Tomcat default web page has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/

Likewise, the application server’s examples have not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/examples/

deployment of tomcat is necessary once it is proofed that it is working in ticket
https://jira.deutsche-boerse.com/browse/M7P-6466 &
https://jira.deutsche-boerse.com/browse/M7P-6467
",,cs687,op211,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,See below.,,,,,,,,,,,,,,,,,,,,,,,,18316800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzmwwn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97540,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 11:18;cs687;More information are described here: https://jira.deutsche-boerse.com/browse/M7P-6466
No Changes needed, ansible will solve it, we just have to check the ICSC-PROD Url´s once we deployed it via ansible.

ticket from now on in Waiting!","15/Feb/21 14:22;op211;Done with last ICSC PROD Ansible deployment.",,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Tomcat Application server´s default applications and the examples (external staging),M7P-6467,97539,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:27,18/Nov/20 10:40,16/Sep/21 14:11,12/Nov/20 10:51,,7tops_sprint105,,,,ICS,,,,ICS,M,M7PRODOPS,,,,,"*related Ticket:* https://vmt.deutsche-boerse.de/browse/PT-1493

We recommend removing the Tomcat application server’s default applications and the examples.

Example:
The Tomcat default web page has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/

Likewise, the application server’s examples have not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/examples/

deployment of tomcat is necessary once it is proofed that it is working in ticket 
https://jira.deutsche-boerse.com/browse/M7P-6466",,cs687,,,,,,,,,,,,,,,,,M7P-6468,M7P-5684,,,,,,,,,,,,,,,,,,,,,"12/Nov/20 10:48;cs687;default-page-after-ansibledeployment.png;https://jira.deutsche-boerse.com/secure/attachment/89871/default-page-after-ansibledeployment.png","12/Nov/20 10:46;cs687;default-page.PNG;https://jira.deutsche-boerse.com/secure/attachment/89870/default-page.PNG","12/Nov/20 10:49;cs687;example-page-after-ansibledeployment.png;https://jira.deutsche-boerse.com/secure/attachment/89872/example-page-after-ansibledeployment.png","12/Nov/20 10:46;cs687;examples.PNG;https://jira.deutsche-boerse.com/secure/attachment/89869/examples.PNG",,,,,,,,,,,,sw455,,,,,,,,"with the ansible deployment for ICSC-CUTE the following pages mentioned in the description were removed. 

attached the proof with the pictures 
* default-page-after-ansibledeployment.png
* example-page-after-ansibledeployment.png


",,,,,,,,,,,,,,,,,,,,,,,,26611200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzymaf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97539,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 11:17;cs687;More information are described here: https://jira.deutsche-boerse.com/browse/M7P-6466
No Changes needed, ansible will solve it, we just have to check the ICSC-CUTE Url´s once we deployed it via ansible. 

ticket from now on in Waiting!  ","12/Nov/20 10:49;cs687;solved with the ansible deployment in icsc-cute
default page and example page successfully removed!
","12/Nov/20 10:51;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Tomcat Application server´s default applications and the examples (internal test staging),M7P-6466,97538,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:24,01/Mar/21 17:31,16/Sep/21 14:11,03/Jul/20 11:14,,6.8.134,7tops_sprint10,,,,,,,7tops_comm,M,M7PRODOPS,,,,,"*related Ticket:* https://vmt.deutsche-boerse.de/browse/PT-1493

We recommend removing the Tomcat application server’s default applications and the examples.

*Example:*
The Tomcat default web page has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/

Likewise, the application server’s examples have not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/examples/



For profile server (requires auth):

Standard error pages, e.g.: https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/ssss (already done in M7P-5060)

https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/examples/

https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/docs/


properly changes in ansible-role tomcat is necessary. ",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 07:25;cs687;default-page.PNG;https://jira.deutsche-boerse.com/secure/attachment/85389/default-page.PNG","03/Jul/20 07:25;cs687;examples.PNG;https://jira.deutsche-boerse.com/secure/attachment/85390/examples.PNG",,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38016000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxv5z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97538,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/20 09:50;cs687;https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/examples/
examples page seems to be just existing on environments which were deployed via perl-deployment!

/icsc/icsc-cute-cmm1/tomcat/webapps/examples
{code:java}
-rw-r--r--  1 tomcat tomcat 1126 May 10  2017 index.html
drwxr-xr-x 21 tomcat tomcat 4096 Dec 18  2018 jsp
drwxr-xr-x  5 tomcat tomcat 4096 Dec 18  2018 servlets
drwxr-xr-x  7 tomcat tomcat 4096 Dec 18  2018 WEB-INF
drwxr-xr-x  2 tomcat tomcat 4096 Dec 18  2018 websocket
{code}


*/icsc/icsc-cute-cmm1/tomcat/webapps/examples*
{code:java}
drwxr-xr-x  6 tomcat tomcat 4096 Dec 18  2018 .
drwxr-xr-x  8 tomcat tomcat 4096 May 13 08:46 ..
-rw-r--r--  1 tomcat tomcat 1126 May 10  2017 index.html
drwxr-xr-x 21 tomcat tomcat 4096 Dec 18  2018 jsp
drwxr-xr-x  5 tomcat tomcat 4096 Dec 18  2018 servlets
drwxr-xr-x  7 tomcat tomcat 4096 Dec 18  2018 WEB-INF
drwxr-xr-x  2 tomcat tomcat 4096 Dec 18  2018 websocket
{code}


*ate5* which was deployed via ansible the folders are not existing anymore!
*/shrd/shrd-ate5-cmm1/tomcat/webapps*
{code:java}
drwxr-x--- 12 tomcat tomcat      4096 Jun 25 09:48 cmm
-rw-r--r--  1 tomcat tomcat 108239701 Jun 25 09:48 cmm.war
{code}


","03/Jul/20 10:46;cs687;https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/
https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/index.jsp

same result like pasted above. It will be solved with the ansible-deployment, no need to change it now for deployments which are deployed via perl 
*In case yes:*
we can solve it like that https://www.ibm.com/support/pages/disabling-apache-tomcat-default-home-page-openpages-reporting-server

*/icsc/icsc-cute-cmm1/tomcat/conf/web.xml*
{code:java}
    <welcome-file-list>
        <welcome-file>index.html</welcome-file>
        <welcome-file>index.htm</welcome-file>
        <welcome-file>index.jsp</welcome-file>
    </welcome-file-list>
{code}

*path to tomcat default page and doc pages*
/icsc/icsc-cute-cmm1/tomcat/webapps/ROOT/index.jsp
/icsc/icsc-cute-cmm1/tomcat/webapps/docs


","03/Jul/20 11:09;cs687;For *TRADING* i checked the *profilserver* URL´s

https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/examples/
https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/docs/

all of them gives a HTTP-404 error back 
Same situation as above, ansible deployment fixed already the penetration findings. 

*/shrd/shrd-exte-ctp1/tomcat/webapps*
{code:java}
drwxr-x--- 6 tomcat tomcat     4096 Feb 13 15:35 profile-storage
-rw-r--r-- 1 tomcat tomcat 41153445 Feb 13 15:35 profile-storage.war
{code}

","03/Jul/20 11:13;cs687;Ticket can be closed. Confirmed with [~pn508].
Tickets external/production staging updated: 
* https://jira.deutsche-boerse.com/browse/M7P-6467
* https://jira.deutsche-boerse.com/browse/M7P-6468

will link them to the ICSC-CUTE/PROD Deployment to be aware of this and checking the URL´s once the deployment is done handled by ansible!
FYI: [~rehapav]","03/Jul/20 11:14;cs687;.",,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Apache content of web-server standard icons / error pages (production staging),M7P-6465,97537,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,op211,cs687,cs687,30/Jun/20 13:21,24/Feb/21 11:26,16/Sep/21 14:11,15/Feb/21 14:37,,7tops_sprint111,,,,uknown,,,,M,M7PRODOPS,,,,,,"related Ticket: https://vmt.deutsche-boerse.de/browse/PT-1492

Removing the content of web-servers standard icons and web-servers standard error pages.

Examples:
The folder containing the web server’s standard icons has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/icons/

Likewise, the web server’s standard error pages have not been removed and can be accessed with the following exemplary URL:
https://cute1.ics.m7c.deutsche-boerse.com/error/HTTP_NOT_FOUND.html.var

Re-deployment of apache instance is necessary once we proofed it is working in ticket
https://jira.deutsche-boerse.com/browse/M7P-6463 & 
https://jira.deutsche-boerse.com/browse/M7P-6464",,cs687,op211,pn508,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,See below.,,,,,,,,,,,,,,,,,,,,,,,,18316800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzym7r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97537,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 15:29;cs687;Solution was found in ticket https://jira.deutsche-boerse.com/browse/M7P-6463
pull-request was prepared for apache ansible-role, apache needs to be deployed as well once it is confirmed that it is working for external env´s 
refer: https://jira.deutsche-boerse.com/browse/M7P-6464

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981","02/Jul/20 16:18;cs687;Martin Matejka and me agreed to it not to merge the prepared pull-request because in the next few weeks we having production deployments to 6.9
so we are skipping this part not to mix things up!

Once we tested it succesfully in non-prod env´s https://jira.deutsche-boerse.com/browse/M7P-6464 we can go for prod as well. 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981

Specially checking it for ICSC-PROD where the penetration-findings were found. (refer URL above!)
Pavel Rehak (dbg ops) can you please link the pull-request and ticket itself to the soon incoming SERVICE-Ticket for ICSC-PROD Deployment, please

In that case we are remembering us in the future about the changes","18/Dec/20 10:58;pn508;[~rehapav] ^^ pls take the pull request into account","15/Feb/21 14:37;op211;Done with last ICSC PROD deployment.",,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Apache content of web-server standard icons / error pages (external staging),M7P-6464,97535,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:17,05/Jan/21 23:39,16/Sep/21 14:11,01/Dec/20 09:04,,6.8.148,7tops_sprint106,,,uknown,,,,ICS,M,M7PRODOPS,,,,,"related Ticket: https://vmt.deutsche-boerse.de/browse/PT-1492

Removing the content of web-servers standard icons and web-servers standard error pages.

Examples:
The folder containing the web server’s standard icons has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/icons/

Likewise, the web server’s standard error pages have not been removed and can be accessed with the following exemplary URL:
https://cute1.ics.m7c.deutsche-boerse.com/error/HTTP_NOT_FOUND.html.var

Re-deployment of apache instance is necessary once we proofed it is working in ticket
https://jira.deutsche-boerse.com/browse/M7P-6463",,cs687,rehapav,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Deployed on 12.11.2020 to ICSC CUTE.,,,,,,,,,,,,,,,,,,,,,,,,26265600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzym6n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97535,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 15:29;cs687;Solution was found in ticket https://jira.deutsche-boerse.com/browse/M7P-6463
pull-request was prepared for apache ansible-role, needs to be merged and tested in external env´s as well
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981

","02/Jul/20 16:04;cs687;[~pn508] and me agreed to it not to merge the prepared pull-request because in the next few weeks we having production deployments to 6.9 
so we are skipping this part not to mix things up!

After this wave we can test it in the next incoming non-prod/external environments the changes which are listed in (Deployment of apache_instance) 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981

Specially checking it for ICSC-CUTE where the penetration-findings were found. (refer URL above!)
[~rehapav] can you please link the pull-request and ticket itself to the soon incoming SERVICE-Ticket for ICSC-Cute Deployment, please? 

In that case we are remembering us in the future about the changes ","02/Jul/20 16:17;cs687;coming: ICSC-CUTE
https://jira.deutsche-boerse.com/browse/SERVICE-2483","16/Nov/20 09:04;rehapav;[~cs687]can we simply merge

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981] 

and forget about the topic? 

We missed this one in lengthy 6.8 ICSC CUTE preparation and now we are in the middle of the UAT.

 ",,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Removing Apache content of web-server standard icons / error pages (internal test staging),M7P-6463,97534,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,30/Jun/20 13:15,25/Jan/21 13:04,16/Sep/21 14:11,02/Jul/20 15:26,,6.8.134,7tops_sprint10,,,,,,,7tops_comm,M,M7PRODOPS,,,,,"*related Ticket:* https://vmt.deutsche-boerse.de/browse/PT-1492

Removing the content of web-servers standard icons and web-servers standard error pages.

*Examples:*
The folder containing the web server’s standard icons has not been removed and can be accessed with the following URL:
https://cute1.ics.m7c.deutsche-boerse.com/icons/

Likewise, the web server’s standard error pages have not been removed and can be accessed with the following exemplary URL:
https://cute1.ics.m7c.deutsche-boerse.com/error/HTTP_NOT_FOUND.html.var

For that we need to test it in internal environments and make the proper ansible-role ""apache"" changes and re-deploy apache. ",,cs687,,,,,,,,,,,,,,,,,M7P-5684,,,,,,,,,,,,,,,,,,,,,,"02/Jul/20 10:58;cs687;with_indexes.png;https://jira.deutsche-boerse.com/secure/attachment/85354/with_indexes.png","02/Jul/20 10:59;cs687;without_indexes.png;https://jira.deutsche-boerse.com/secure/attachment/85355/without_indexes.png",,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38016000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5007,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzxv5r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97534,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"01/Jul/20 12:46;cs687;The Web-Servers Standard Icons are already removed 
after opening the link, i can see the following. 

https://cute1.ics.m7c.deutsche-boerse.com/icons/

{code:java}
Forbidden
You don't have permission to access /icons/ on this server.
{code}

{code:java}
       Alias /icons/ ""/var/www/icons/""

Directory ""/var/www/icons"">
   Options {color:#DE350B}Indexes {color}MultiViews FollowSymLinks
   AllowOverride None
   Order allow,deny
   Allow from all
/Directory>
{code}

We just need to change it in the ansible-role to fix that behavior.
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981
After creating the folder *""icons"" in /var/www/""* the icons are still visible with ate5 (ansible-deployment) 
https://10.136.148.37:60501/icons/

{code:java}
-bash-4.2$ ls -all /var/www/icons/
-rw-r--r-- 1 root root  332 Jul  2 10:28 world1.png
{code}

After merging the pull-request and re-deploying it we get a HTTP-403 error (/)

*Solution* found here: 
https://www.virtualmin.com/node/37306
or
https://cloudblue.freshdesk.com/support/solutions/articles/44001883958-disabling-apache-http-server-indexing-of-icons-directory

[~HO764] also confirmed this findings were just related to M7-ICSC Setup. ","01/Jul/20 13:15;cs687;Proper Solution for second part *Removing web server´s standard error page"" 

https://books.google.de/books?id=dTYKAAAAQBAJ&pg=PA302&lpg=PA302&dq=/error/HTTP_NOT_FOUND.html.var+apache+disable+standard+error+page&source=bl&ots=12hrXrLN-r&sig=ACfU3U2hXSmC5GfSdTrm3n6YoeFPzR6COw&hl=en&sa=X&ved=2ahUKEwih0fWh9KvqAhXFy6QKHcVdAl8Q6AEwAHoECAoQAQ#v=onepage&q=%2Ferror%2FHTTP_NOT_FOUND.html.var%20apache%20disable%20standard%20error%20page&f=false

1.) open httpd.conf
2.) Search for ""HTTP_NOT_FOUND"" The resulting line should be ""Error Document 404 /error/HTTP_NOT_FOUND.html.var"" Insert a # at the beginning of the line to make a comment out of it, thereby disabling the line. 
3.) Create a blank line, and then type ErrorDocument 404 ""The page was not found"". 
4.) Save the changes and restart the web-instance. ","02/Jul/20 14:21;cs687;Solution for the *web server’s standard error pages* was: 

we had differences on the internal/external and production Hosts. 
On *m7shrdexteweb1/2* and *m7shrdprodweb1/2* we have the HTTP_NOT_FOUND.html.var page also in */var/www/error*

{code:java}
/usr/share/httpd/error/HTTP_NOT_FOUND.html.var
/var/www/error/HTTP_NOT_FOUND.html.var
{code}


so after calling the url: https://cute1.ics.m7c.deutsche-boerse.com/error/HTTP_NOT_FOUND.html.var
we still saw the Object not Found page because of the proper *alias* in the httpd.conf file 

{code:java}
Alias /error/ ""/var/www/error/""
<IfModule mod_negotiation.c>
<IfModule mod_include.c>
    <Directory ""/var/www/error"">
        AllowOverride None
        Options IncludesNoExec
        AddOutputFilter Includes html
        AddHandler type-map var
        Order allow,deny
        Allow from all
        LanguagePriority en es de fr
        ForceLanguagePriority Prefer Fallback
    </Directory>
{code}

*Plan:*
#Alias /error/ ""/var/www/error/""
commenting out the alias line above, problem will be fixed with the ansible deployment in cute and prod as well. ","02/Jul/20 15:04;cs687;Ticket can be closed! 
Ansible-Role apache was prepared for *M7T/C*
After re-deploying apache its fixed!

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/981","02/Jul/20 15:10;cs687;Tickets for external and production staging can be also waiting/closed. (i) once we deployed it during end of year, will update [~rehapav] for that. 

https://jira.deutsche-boerse.com/browse/M7P-6464
https://jira.deutsche-boerse.com/browse/M7P-6465

Maybe just linking them to the proper SERVICE-Ticket would be not a bad idea",,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 ELTS PROD deliver 6.9 release,M7P-6458,97513,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,rehapav,rehapav,30/Jun/20 09:37,30/Mar/21 18:25,16/Sep/21 14:11,15/Dec/20 09:10,,6.11.145,7tops Sprint8,,,cor,,,08/Jul/20 00:00,M7PRODOPS,,,,,,,"Prepare PRs and perform deployment ticket review for following deployment:

 
||Customer||Environment||Date & Time||Comment||
|ELTS|PROD| | |

*Software versions:*
 M7 6.9.150 - 
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|1.0.100| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 
 *PRs to be prepared:*
 * 
 * upgrade of various 3rd party tools like defined in M7P-5812
 ** Software version
 *** PR: *tbd*
 ** AZUL 1.8.0_242
 *** PR tbd
 ** RABIITMQ 3.8.3
 *** PR tbd
 ** TOMCAT 8.5.50
 *** PR tbd
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : *tbd*

*",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6495,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,,,,Obsolete,,,,,,,,ELTS,,,,,,Internal Deployment Request,ax460,cf948,fj021,jv861,nn481,oy574,pw231,rehapav,No,38275200,,PROD,dm700,lw641,ox626,rehapav,sw455,,15/Jul/20 21:15,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxz1b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97513,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE prepare for : M7 OPCOM PROD deliver 6.9 release,M7P-6457,97504,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,xt853,rehapav,rehapav,30/Jun/20 09:02,26/Nov/20 17:03,16/Sep/21 14:11,30/Jun/20 11:31,,6.10.123,7tops Sprint8,,,,,,02/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Prepare PRs and perform deployment ticket review for linked deployment:

 

*PRs to be prepared:*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : tbd
 * also prepare PRs for software version change
 * *Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |
|RabbitMQ|3.8.3| |

 

todo:
 * prepare PR
 * review linked deployment ticket
 * approve linked deployment ticket",,rehapav,xt853,,,,,,,,,,,,,,,,,,SERVICE-6517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,,,,Pull request with all necessary modifications prepared,,,,,,,,OPCOM,,,,,,Internal Deployment Request,ax460,cf948,fj021,jv861,nn481,oy574,pw231,rehapav,No,38275200,,PROD,dm700,lw641,ox626,rehapav,sw455,,09/Jul/20 10:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxy0f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 95 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,,,,,,,,,"{""issueId"":97504,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"30/Jun/20 11:11;xt853;PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1943]",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: preparation for M7 HUPX PROD deliver 6.9.150,M7P-6456,97503,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,ax460,rehapav,rehapav,30/Jun/20 08:48,06/May/21 10:11,16/Sep/21 14:11,01/Jul/20 10:42,,7tops_sprint9_,,,,,,,15/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Prepare PRs and perform deployment ticket review for linked deployment:

 

*PRs to be prepared:*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1946]

todo:
 * prepare PR
 * review linked deployment ticket
 * approve linked deployment ticket",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6634,,,,,,,,,,,,,,SERVICE-8029,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,PR prepared,,,,,,,,HUPX,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,38275200,,PROD,dm700,lw641,ox626,rehapav,sw455,,22/Jul/20 11:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxp33:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 95 (PS),Schmetterling Sprint 96 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97503,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,ax460-patch-1,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New M7C LDAP password policy for CUTE and PROD,M7P-6451,97467,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,pd122,ef759,ef759,26/Jun/20 16:16,08/Sep/21 13:47,16/Sep/21 14:11,02/Sep/21 09:58,,7tops_sprint125,,,,,,,,7tops,M7PRODOPS,,,,,,"Set new password policies on ICS CUTE and PROD LDAPs. 
Use following rules  (Same as for ATE1, ATE5 environments):

*Acceptance criteria:*
* At least 8 characters (GIS requirement, same rules as in M7T)
* Password must fulfil at least 3 of the 4 requirements: at least one upper case letter, one lower case letter, one number, one special character.
* 5 attempts account lock (5 times used wrong password for log in)
* 6 passwords in history and password expiration are needed

Follow up JIRA for: https://jira.deutsche-boerse.com/browse/M7P-4989",,ef759,nn236,pd122,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Working policy proposed and configured on DST1 in December 2020.  No response or any further developments since.  Also, this product is now another team's responsibility.",,,,,,,,,,,,,,,,,,,,,,,,23155200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzmwuv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97467,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/20 12:17;pd122;Current default LDAP password policies:

ATE1:

 
{code:java}
passwordMaxFailure: 32000
passwordLockout: on
passwordMinCategories: 3
passwordStorageScheme: SSHA
passwordCheckSyntax: on
passwordMinLength: 8{code}
ATE5:
{code:java}
passwordMaxFailure: 5
passwordStorageScheme: SSHA
passwordLockout: on
passwordMinCategories: 3
passwordCheckSyntax: on
passwordMinLength: 8{code}
 

Notes:
 * can't think of anyone who would really want to use SSHA for their password storage scheme these days (server's default is SHA512), assuming it is a mistake
 * ATE1 - 32000 failed attempts needed for an account to be locked does not make any sense, assuming this one is a mistake

 ","19/Nov/20 12:19;pd122;[~ef759] before I move further on with this ticket, one question - what would the length of requested account lockout (after 5 unsuccessful attempts) be?  Indefinite (requiring manual intervention) or would you like it to expire after a given amount of time?","18/Dec/20 18:57;pd122;Based on this request and agreed and verified policy ([M7P-7052]), here's my suggestion for both default and admin password policy for ICSC CUTE/PROD:

Default policy:
{code:java}
passwordCheckSyntax: on
passwordLockout: on
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
passwordUnlock: off
passwordWarning: 0
{code}

Admin policy:
{code:java}
passwordCheckSyntax: on
passwordExp: off
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
{code}


[~ef759], [~pn508], please approve.","21/Dec/20 09:59;pn508;[~pd122], [~nn236], [~ef759], [~vp223]

As per Access control GIS security standard:
 * Password Expiry needs to be enabled: as per Access Control standard. Password rotated per policy: Passwords of privileged accounts (e.g. Admin user, but it can be applicable for all (non-technical) users) must be changed according to the policy
 * Password history needs to be enabled: New passwords must be different from at least the last 6 passwords.","21/Dec/20 11:50;pd122;Based on discussion with [~vp223] and [~nn236] going to set up DST1 environment 1st.

Current default DST1 PP (there is no DST1 specific admin PP set up):
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Ddst1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordWarning: 0
passwordInHistory: 6
passwordCheckSyntax: on
passwordExp: on
passwordMaxAge: 864000
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinDigits: 1
passwordMinLength: 8
passwordMinLowers: 1
passwordMinSpecials: 1
passwordMinUppers: 1
{code}

New default policy:

{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Ddst1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordUnlock: on
passwordLockout: on
passwordMaxAge: 7776000
passwordWarning: 0
passwordInHistory: 6
passwordCheckSyntax: on
passwordExp: on
passwordMaxFailure: 5
passwordMinCategories: 3
passwordMinLength: 8
{code}
","21/Dec/20 12:43;nn236;Changing from blocking to related, as this task is about LDAP configuration. The issue M7P-6601 is probably on ICS side.","21/Dec/20 13:41;pd122;New DST1 admin PP created

{code:java}
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Cou\3Ddst1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordCheckSyntax: on
passwordExp: off
passwordInHistory: 6
passwordLockout: off
passwordMinCategories: 3
passwordMinLength: 8
passwordWarning: 0
{code}

and assigned to _shrd-apa-dst1-adm_ user.",,,,,,,,,,,,,,,,,,,,,
ATE5 VM reinstall,M7P-6450,97461,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,ef759,ef759,26/Jun/20 14:44,30/Jul/20 14:19,16/Sep/21 14:11,22/Jul/20 09:28,,6.8.137,7tops_sprint12,,,,,,,7tops,M7PRODOPS,,,,,,"Since on ATE5 is actually installed old version of java, which fixed previous problems of m7 core on ATE5, please reinstall VM with latest java version.",,cs687,ef759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"upgraded the azul/java version to 
*XBID-zulu-8-8.44.0.11-1.x86_64*
",,,,,,,,,,,,,,,,,,,,,,,,36374400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzxxnj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"* stopped the tomcat instances on host m7shrdate5apa1 
* upgraded the azul version with proper ansible command 
* started the instances again. ",,,,,,,,,,"{""issueId"":97461,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jul/20 09:25;cs687;1.) stopped the tomcat instances on the host m7shrdate5apa1

2.) upgraded zulu version via ansible:
{code:java}
ansible-playbook playbooks/azul_java_install_8.44.yml --limit ""m7t*shrd*ate5*cor1"" -k -K -b

[root@m7shrdate5apa1 ~]# rpm -qa | grep -e java- -e zulu
XBID-zulu-8-8.44.0.11-1.x86_64
{code}

3.) and started the instances again:
{code:java}
tomcat@m7shrdate5apa1 ~]$ /shrd/shrd-ate5-cmi1/tomcat/bin/start.sh
{""status"":""UP"",""details"":{""application"":{""status"":""UP""},""dataSource"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""hello"":1}},""coreRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}}}}[tomcat@m7shrdate5apa1 ~]$
{code}

{code:java}
[tomcat@m7shrdate5apa1 ~]$ /shrd/shrd-ate5-cmm1/tomcat/bin/start.sh
{""status"":""UP"",""details"":{""application"":{""status"":""UP""},""dataSource"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""hello"":1}},""coreRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}},""cmiRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}}}}[tomcat@m7shrdate5apa1 ~]$
{code}

{code:java}
[tomcat@m7shrdate5apa1 ~]$ /shrd/shrd-ate5-enq1/tomcat/bin/start.sh
{""status"":""UP"",""details"":{""application"":{""status"":""UP""},""dataSource"":{""status"":""UP"",""details"":{""database"":""PostgreSQL"",""hello"":1}},""coreRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}},""cunsumerRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}},""adminRabbit"":{""status"":""UP"",""details"":{""version"":""3.8.0""}}}}[tomcat@m7shrdate5apa1 ~]$
{code}

{code:java}
[tomcat@m7shrdate5apa1 ~]$ /shrd/shrd-ate5-cor1/tomcat/bin/start.sh
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""CONNECTED""}}}}[tomcat@m7shrdate5apa1 ~]$
{code}




","22/Jul/20 09:28;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,,,
Apache server caches LDAP user data,M7P-6449,97460,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,cs687,ef759,ef759,26/Jun/20 13:51,05/Jan/21 16:40,16/Sep/21 14:11,26/Jun/20 15:05,,7tops_sprint9_,,,,,,,,7tops,M7PRODOPS,PenetrationTest,,,,,"On ATE environments (ATE1, ATE5) was tested, apache server caches after successful log in user data from ldap. But it causes this problem:

# User log into inquiry (cmm) using valid password
# User logout
# User use 5 times wrong password to log into the app, what is the limit for account lock on ATE1 and ATE5
# User try for 6th attempt to use valid password and log in process finishes successfully

6th attempt to log in should fail, but because of cached data from first successful login, is user able to access the app. This behavior should be fixed. In case there is no successful login before providing 5 wrong passwords for login (no cached data), user is not able for 6th attempt to access the app. 

Acceptance criteria:
* Fix the problem for ATE environments
* Check also other environments: SYT, CUTE, PROD if problem occurs also there and prepare fix possibly
",,cs687,ef759,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,-,,,,,,,,,,,,,,,,,,,,,,,,38534400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,26/Jun/20 13:51,,[],,,,,,,,None,,,M7T,,,,"2|hzxxnb:",9223372036854775807,,,,No,,,,,,,,,,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,,,,,,,,,,"{""issueId"":97460,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/20 14:41;cs687;https://10.136.148.37:60501/cmm/ <- ATE5

I did the following test:
* logged in to the cmm-portal (ate5) above
* with user CXTEST01 and typed in 3 times wrong password

Afterwards i noticed that the login is working for more 10 minutes, which is causing the *apache LDAPCacheTTL*

This parameter is set by default to 600 seconds (10 minutes) 

{code:java}
Description:	Time that cached items remain valid
Syntax:	LDAPCacheTTL seconds
Default:	LDAPCacheTTL 600
Context:	server config
Status:	Extension
Module:	mod_ldap
{code}

https://httpd.apache.org/docs/2.4/mod/mod_ldap.html#ldapcachettl


The caching behavior should not be disabled because of protecting for Authentication-flooding.
We could think about to make the LDAPCacheTTL smaller, if necessary.

FYI: [~pn508]","26/Jun/20 15:05;cs687;We agreed to it that we keep it with the default value of 10 minutes. Ticket can be closed. 

*Not a bug*",,,,,,,,,,,,,,,,,,,,,,,,,,
Monitoring: keep production data for 10 years,M7P-6448,97457,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,pw231,pw231,26/Jun/20 13:17,16/Jul/21 13:46,16/Sep/21 14:11,,,,,,,,,,,OPS,,,,,,,"h4. Problem
We are constantly enhancing monitoring and nowadays we have very valuable data in influxdb.
Problem is that it has rather low retention policy and the data get deleted after 1 year.

h4. Requirements
- Keep the production data for 10 years 
- data from tests can be deleted after 3 months
- it is ok to have it in a different db (we can create dedicated dashboards for long term views)
- it is ok to have it down sampled (e.g. to 5 minutes, currently the period is 30 secs), as long as the statistical functions still make some sense. i.e. maximum, minimums should not be lost, means can be estimated as mean of means, etc.
",,hw120,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21945600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-176,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|i00acs:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97457,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jan/21 15:54;hw120;Retention policy is set to 2 years, but right now I don't have capacity to work on this one, at least not in Q1/2021. Alex can pick it up.",,,,,,,,,,,,,,,,,,,,,,,,,,,
HUPX SIMU Server Certificates expires soon,M7P-6445,97448,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,26/Jun/20 10:03,16/Jul/20 13:22,16/Sep/21 14:11,09/Jul/20 10:55,,6.10.149,7tops_sprint10,,,,,,,7tops_comm,M7PRODOPS,XS,,,,,"For hupx-simu the server (WEB/SSL) certificates will expire soon.

*Opsgenie Alert: This cert will expire soon: CN=simu2.hupx.m7.deutsche-boerse.com*

{code:java}
Description:	
Responders:	
Details:	CUS	:	hupx 
ENV	:	simu 
EXPDATE	:	Jul 25 23:59:59 2020 GMT 
PRODUCT	:	m7t 

Source:	193.29.81.232
Integration:	Certificate Monitoring API (API)
Created At:	26.6.2020 8:31:45
Tags:	
Id:	9d69868a-9071-4e99-acdd-9aa3e926e8d9-1593153105446
TinyId:	8959
{code}

*Certificate will expire* {color:#DE350B}Jul 25 23:59:59 2020 GMT{color}
simu1.hupx.m7.deutsche-boerse.com will expire around September, maybe its a good idea to renew it as well. 

*hupx-simu1: Not After : Sep 24 23:59:59 2020 GMT*

{code:java}
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            b9:3d:98:9e:2e:69:ff:59:0d:53:d7:dd:e6:ca:97:09
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jul 26 00:00:00 2017 GMT
            Not After : Jul 25 23:59:59 2020 GMT
{code}
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,HUPX,,,,,,,,,,,,,,,,37497600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxv6v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,7tops Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97448,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"01/Jul/20 10:53;cs687;*1.) Run the Job ""Project A. Generate CSR (Ansible Deployment)""*
{code:java}
Started by user Steffen Englert
Rebuilds build #53
Running as SYSTEM
[EnvInject] - Loading node environment variables.
Building remotely on englobauto1 (englobauto) in workspace /home/jenkins/workspace/Energy-Operations/Certificate Deploy/A. Generate CSR (Ansible Deployment)
using credential ff4c895e-1043-458e-be44-195fb4d1b1b2
 > git rev-parse --is-inside-work-tree # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url git@github.deutsche-boerse.de:dev/energy.automation.certificate.git # timeout=10
Fetching upstream changes from git@github.deutsche-boerse.de:dev/energy.automation.certificate.git
 > git --version # timeout=10
using GIT_SSH to set credentials 
 > git fetch --tags --progress -- git@github.deutsche-boerse.de:dev/energy.automation.certificate.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git rev-parse refs/remotes/origin/tuan^{commit} # timeout=10
 > git rev-parse refs/remotes/origin/origin/tuan^{commit} # timeout=10
Checking out Revision 7abe57a6f50ce9160a796888c5afc95559e7315b (refs/remotes/origin/tuan)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f 7abe57a6f50ce9160a796888c5afc95559e7315b # timeout=10
Commit message: ""added hupx-simu related to M7P-6445""
 > git rev-list --no-walk 760ba8cc8ff25b652132ccde722e77a3de8ee4a1 # timeout=10
New run name is '#generate_csr_m7t_hupx_simu'
[A. Generate CSR (Ansible Deployment)] $ /bin/sh -xe /tmp/jenkins7492830489768231699.sh
+ ansible-playbook gencsr.yml --extra-vars '{ '\''PROD'\'': '\''m7t'\'', '\''CUS'\'': '\''hupx'\'', '\''ENV'\'':'\''simu'\'', '\''EMAIL'\'':'\''steffen.englert@deutsche-boerse.com'\''}'
 [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source
 [WARNING]: No inventory was parsed, only implicit localhost is available
 [WARNING]: provided hosts list is empty, only localhost is available. Note
that the implicit localhost does not match 'all'
PLAY [127.0.0.1] ***************************************************************

TASK [Gathering Facts] *********************************************************
ok: [127.0.0.1]

TASK [Generate Private Key] ****************************************************
changed: [127.0.0.1]

TASK [Generate Certificate Signing Request (CSR)] ******************************
changed: [127.0.0.1]

TASK [Generate Certificate Signing Request (CSR)] ******************************

TASK [Import private key and chain to vault] ***********************************
changed: [127.0.0.1]

TASK [Import private key and chain to vault second key] ************************
changed: [127.0.0.1]

TASK [Send email with the CSR as attachment] ***********************************
ok: [127.0.0.1 -> localhost]

PLAY RECAP *********************************************************************
127.0.0.1                  : ok=6    changed=4    unreachable=0    failed=0   

New run name is '#generate_csr_m7t_hupx_simu'
Finished: SUCCESS
{code}


*2.) check Vault settings*
 /secrets/secret/m7t/hupx/simu/cert
two secrets should be added (includes chain and key):
Request_simu1.hupx.m7.deutsche-boerse.com
Request_simu2.hupx.m7.deutsche-boerse.com


3.) Create Service Approval ""ITSR: *5B9519*"" in Notes and write Email to SSL-ADMINS

The below email is classified: Internal

Hello, 
Please sign the attached CSR(s) with maximum possible validity.
Alternative Names:
[simu1.hupx.m7.deutsche-boerse.com, simu2.hupx.m7.deutsche-boerse.com]


Thanks. 
Regards

*Waiting until the certs are available*","09/Jul/20 07:25;cs687;Certificates are finally provided:
{code:java}
Hello,

You have successfully enrolled for a SSL certificate.

You now need to complete the following steps:

    * Click the following link to download your SSL certificate
    Available formats:
       as Certificate (w/ chain), PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=x509
       as Certificate only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=x509CO
       as PKCS#7, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=base64
       as PKCS#7: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=bin

    Issuing CA certificates only:
       as Root/Intermediate(s) only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=x509IO
       as Intermediate(s)/Root only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=x509IOR

    * Import your new certificate into your server (Please contact your administrator for help with this).
    * Your renew id: 4klssYTfuY5eYJsmcF6B

Certificate Details:
    Common Name :  simu1.hupx.m7.deutsche-boerse.com
    Subject Alternative Names : simu1.hupx.m7.deutsche-boerse.com, simu2.hupx.m7.deutsche-boerse.com
    SSL Certificate Profile :     Comodo Multi Domain SSL Certificate (customized for Deutsche Boerse AG)
    Term :         2 Year(s)
    Server :       OTHER
    Requested :    08/07/2020 15:19 GMT
    Approved :     08/07/2020 15:19 GMT
    Expires :      08/07/2022 23:59 GMT
    Order Number : 368266915
    Self-Enrollment Certificate ID : 1880220
    Comments :     ITSR 5B9519 - Steffen Englert (Thorne, Alexander)

{code}
","09/Jul/20 07:32;cs687;*saved the cert by opening this link* ->  as Certificate only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1880220&format=x509CO
and uploaded to vault with the following Jenkins Job *Project B. Import Cert to Vault (Ansible Deployment)*
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/B.%20Import%20Cert%20to%20Vault%20(Ansible%20Deployment)/","09/Jul/20 10:38;cs687;will create a SERVICE Ticket for that
and close the ticket. ","09/Jul/20 10:55;cs687;certificate is in the vault",,,,,,,,,,,,,,,,,,,,,,,
XSOP SIMU Server Certificates expires soon ,M7P-6444,97447,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,26/Jun/20 10:00,30/Jul/20 14:19,16/Sep/21 14:11,16/Jul/20 11:46,,6.10.149,7tops_sprint12,,,,,,,7tops_comm,M7PRODOPS,XS,,,,,"For xsop-simu the server (WEB/SSL) certificates will expire soon. 

*Opsgenie Alert: This cert will expire soon: CN=simu2.xsop.m7.deutsche-boerse.com*

{code:java}
Description:	
Responders:	
Details:	CUS	:	xsop 
ENV	:	simu 
EXPDATE	:	Jul 25 23:59:59 2020 GMT 
PRODUCT	:	m7t 

Source:	193.29.81.232
Integration:	Certificate Monitoring API (API)
Created At:	26.6.2020 8:31:45
Tags:	
Id:	14056aac-d160-45e5-a7d0-1ed38b062691-1593153105548
TinyId:	8960
{code}

*Certificate will expire* at {color:#DE350B}Not After : Jul 25 23:59:59 2020 GMT{color}
simu1.xsop.m7.deutsche-boerse.com will expire arround December.

*xsop-simu1: Not After : Dec 11 23:59:59 2020 GMT*

{code:java}
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            9b:b6:a7:a6:ca:76:aa:93:5c:ca:7c:76:07:65:41:2f
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=GB, ST=Greater Manchester, L=Salford, O=COMODO CA Limited, CN=COMODO RSA Organization Validation Secure Server CA
        Validity
            Not Before: Jul 26 00:00:00 2017 GMT
            Not After : Jul 25 23:59:59 2020 GMT
{code}


",,cs687,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-6709,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,Southpool,,,,,,,,,,,,,,,,36892800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxv6n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 10,7tops Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97447,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"29/Jun/20 11:33;pd122;PR [https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/10] created to enter XSOP SIMU servers into cert inventory","29/Jun/20 11:59;pd122;PR approved -> change merged -> CSR generated -> ITSR #5B9344 created ","09/Jul/20 10:39;pd122;certificate received and imported into the vault using https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/B.%20Import%20Cert%20to%20Vault%20(Ansible%20Deployment)/","09/Jul/20 11:08;pd122;deployment requested","16/Jul/20 11:45;cs687;ticket can be closed, deployment will be handled with the ticket
https://jira.deutsche-boerse.com/browse/SERVICE-6709

today around 3pm ","16/Jul/20 11:46;cs687;.",,,,,,,,,,,,,,,,,,,,,,
Maintenance of m7shrdexterepX instances to add memory,M7P-6442,97435,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,hw120,hw120,hw120,25/Jun/20 16:29,30/Jul/20 14:19,16/Sep/21 14:11,07/Jul/20 12:03,,7tops_sprint12,,,,,,,,7tops,,,,,,,"m7shrdexterep1 is running out of memory, number of instances and especially Xmx configured is much higher than servers memory.

We need to stop both reporting servers, add memory and enable cpu/mem hotplug, start the server.
Then start all reporting instances.
Martin Komberec will check if all instances are running fine.",,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SYSENGINT-106,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Memory added, instances started.",,,,,,,,,,,,,,,,,,,,,,,,37670400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxxnr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97435,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jul/20 12:04;hw120;For some reason, stopping instances using ansible-playbook didn't worked.

I had to stop and start them manually

{code:bash}
cd /shrd/elts-acut-rep1/tomcat/bin/ && ./start.sh
cd /shrd/elts-ctpb-rep1/tomcat/bin/ && ./start.sh
cd /shrd/elts-cute-rep1/tomcat/bin/ && ./start.sh
cd /shrd/elts-lipa-rep1/tomcat/bin/ && ./start.sh
cd /shrd/elts-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/epex-asim-rep1/tomcat/bin/ && ./start.sh
cd /shrd/epex-cute-rep1/tomcat/bin/ && ./start.sh
cd /shrd/flex-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/hupx-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/hupx-asim-rep1/tomcat/bin/ && ./start.sh
cd /shrd/hupx-cute-rep1/tomcat/bin/ && ./start.sh
cd /shrd/nore-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/plpx-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/plpx-lipa-rep1/tomcat/bin/ && ./start.sh
cd /shrd/xsop-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/xrpm-simu-rep1/tomcat/bin/ && ./start.sh
cd /shrd/xsop-asim-rep1/tomcat/bin/ && ./start.sh
cd /shrd/xrpm-lipa-rep1/tomcat/bin/ && ./start.sh
cd /shrd/xsop-cute-rep1/tomcat/bin/ && ./start.sh
cd /shrd/shrd-show-rep1/tomcat/bin/ && ./start.sh

cd /shrd/shrd-show-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-acut-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-ctpb-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-ute-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-cute-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-lipa-rep2/tomcat/bin/ && ./start.sh
cd /shrd/elts-simu-rep2/tomcat/bin/ && ./start.sh
cd /shrd/epex-asim-rep2/tomcat/bin/ && ./start.sh
cd /shrd/epex-cute-rep2/tomcat/bin/ && ./start.sh
cd /shrd/hupx-simu-rep2/tomcat/bin/ && ./start.sh
cd /shrd/xsop-cute-rep2/tomcat/bin/ && ./start.sh
cd /shrd/plpx-simu-rep2/tomcat/bin/ && ./start.sh
cd /shrd/xsop-simu-rep2/tomcat/bin/ && ./start.sh
cd /shrd/xrpm-simu-rep2/tomcat/bin/ && ./start.sh
cd /shrd/xsop-asim-rep2/tomcat/bin/ && ./start.sh
cd /shrd/hupx-asim-rep2/tomcat/bin/ && ./start.sh
cd /shrd/xrpm-lipa-rep2/tomcat/bin/ && ./start.sh
cd /shrd/plpx-lipa-rep2/tomcat/bin/ && ./start.sh
cd /shrd/hupx-cute-rep2/tomcat/bin/ && ./start.sh
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
Create selective Jenkins deployment pipeline for Customer Portal,M7P-6438,97429,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,qo288,qo288,qo288,25/Jun/20 15:05,30/Jul/20 14:19,16/Sep/21 14:11,27/Jul/20 12:58,,7tops_sprint12,,,,Customer Portal,,,,M7PRODOPS,,,,,,,,,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Jenkins pipeline in operation,,,,,,,,,,,,,,,,,,,,,,,,35942400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5442,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwqv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97429,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jul/20 12:57;qo288;https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/customer-portal/job/m7-customer-portal-test/",,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Consider validating Host header (Internal test staging),M7P-6434,97424,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pn508,pn508,25/Jun/20 13:44,25/May/21 23:40,16/Sep/21 14:11,19/Feb/21 16:31,,11.0.0,7tops_sprint111,,,apache,,,,7tops_comm,L,,,,,,"See M7P-5686

 

Currently, we do not validate Host header and use it often for redirects. Consider allowing only correct Host header and reject the request otherwise.

This behavior has been reported on M7T, M7C, and profile server.

 

Pen test report references:

Security assessment report of M7 EPEX V8 (6.2) [https://vmt.deutsche-boerse.de/browse/PT-1459] - *Priority* None
Security assessment report of M7C V18+V19 (6.2, 6.3) [https://vmt.deutsche-boerse.de/browse/PT-1471] + [https://vmt.deutsche-boerse.de/browse/PT-1472] - *Priority* Low
Security assessment report of ComTrader, the profile server and the Trading Module PMI V12 (7.2) [https://vmt.deutsche-boerse.de/browse/PT-1514] *Priority* Medium",,pd122,pn508,vp223,,,,,,,,,,,,,,,M7P-6575,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,default catch-all virtual host implemented,,,,,,,,,,,,,,,,,,,,,,,,17971200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5259,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzy2rb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,7tops Sprint 15,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,7tops Sprint 109,7tops Sprint 110,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,7tops Sprint 114,7tops Sprint 115,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,,,,,,,,,,,,,,,,"{""issueId"":97424,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"30/Jul/20 16:57;pd122;* create default virtual host that does nothing
 * verify/set Host header for remaining virtual hosts","12/Feb/21 10:55;vp223;Please consider that M7C part was moved to XBID as part of the ICS to XBID move.","19/Feb/21 16:30;pd122;default catch-all virtual host created
all internal tests as well as reporting web servers on external environments are accessible via IPs only => no header check implemented",,,,,,,,,,,,,,,,,,,,,,,,,
6.9 production like installation test HUPX PROD,M7P-6427,97368,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,24/Jun/20 15:31,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 13:57,,6.10.123,7tops_sprint9_,,,,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - agreed mandatory test defined prior to 6.9 acceptance by RM - see M7 6.9 Acceptance readiness M7P-5739
 - agreed 30/3/2020
 - a similar test was already executed for major release 6.8 -> M7P-5201 with exactly same scope

*task description*

Together with Techops, please perform a complete installation test on the PROD data from the HUPX customer:
 * get dump from HUPX PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * It was agreed by DEV/TECHOPS that for non-ELTS environments we will not execute dbeaclunp script
 * -Apply DB cleanup scripts on old database- 
 * run 6.9 flyway migration (still on the old db)
 * measure migration timeline
 * load dump to internal test environment
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** -execution time of dbcleanup-
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,cs687,jv861,rehapav,,,,,,,,,,,,,,,,,M7P-6426,,,,,,,,,,,,,,SERVICE-5963,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38275200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwqf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97368,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/20 11:26;cs687;Stopped Systemtest2 Environment and dropped the database, to run a fresh restore of HUPX-PROD
{code:java}
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2m7b;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2mtt;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2rep;
DROP DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2rep WITH OWNER   m7tshrdsyt2rep;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2m7b WITH OWNER   m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2mtt WITH OWNER   m7tshrdsyt2mtt;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;
ALTER DATABASE
postgres=# CREATE ROLE ro_users;
{code}
","30/Jun/20 11:34;cs687;1.) *dump xrpm-prod (m7prodpdb1) and restore in systemtest2 (m7testpdb1)*
{code:java}
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7thupxprodm7b | m7thupxprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7thupxprodm7b                   +
                |                |          |             |             | m7thupxprodm7b=CTc/m7thupxprodm7b    +
                |                |          |             |             | uapp01m7thupxprodm7b=c/m7thupxprodm7b+
                |                |          |             |             | uapp01m7thupxprodrep=c/m7thupxprodm7b+
                |                |          |             |             | udev01m7thupxprodm7b=c/m7thupxprodm7b+
                |                |          |             |             | ro_users=c/m7thupxprodm7b            +
                |                |          |             |             | pgwatch2=c/m7thupxprodm7b
 m7thupxprodmtt | m7thupxprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7thupxprodmtt                   +
                |                |          |             |             | m7thupxprodmtt=CTc/m7thupxprodmtt    +
                |                |          |             |             | uapp01m7thupxprodmtt=c/m7thupxprodmtt+
                |                |          |             |             | udev01m7thupxprodmtt=c/m7thupxprodmtt+
                |                |          |             |             | pgwatch2=c/m7thupxprodmtt
 m7thupxprodrep | m7thupxprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7thupxprodrep                   +
                |                |          |             |             | m7thupxprodrep=CTc/m7thupxprodrep    +
                |                |          |             |             | uapp01m7thupxprodrep=c/m7thupxprodrep+
                |                |          |             |             | udev01m7thupxprodrep=c/m7thupxprodrep+
                |                |          |             |             | pgwatch2=c/m7thupxprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
{code}

dumping the db´s
{code:java}
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20008 -d m7thupxprodm7b -n m7thupxprodm7b | sed 's/m7thupxprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20008 -d m7thupxprodmtt -n m7thupxprodmtt | sed 's/m7thupxprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20008 -d m7thupxprodrep -n m7thupxprodrep | sed 's/m7thupxprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz
{code}
{code:java}
-rw-r--r--   1 postgres postgres 454276719 Jun 30 11:29 m7tshrdsyt2m7b.sql.gz
-rw-r--r--   1 postgres postgres  24428988 Jun 30 11:32 m7tshrdsyt2mtt.sql.gz
-rw-r--r--   1 postgres postgres      3484 Jun 30 11:33 m7tshrdsyt2rep.sql.gz
{code}

","30/Jun/20 11:35;cs687;2.) *copy dump´s to m7testpdb1 machine*
{code:java}
-bash-4.2$ scp /tmp/m7tshrdsyt2* cs687@m7testpdb2:/tmp
cs687@m7testpdb2's password:
m7tshrdsyt2m7b.sql.gz                                                                                                                                                                                                                                                                        0%    0     0.0KB/s   --:-- ETA
m7tshrdsyt2m7b.sql.gz                                                                                                                                                                                                                                                                      100%  433MB 165.8MB/s   00:02
m7tshrdsyt2mtt.sql.gz                                                                                                                                                                                                                                                                      100%   23MB  95.4MB/s   00:00
m7tshrdsyt2rep.sql.gz                                                                                                                                                                                                                                                                      100% 3484   186.4KB/s   00:00
{code}
","30/Jun/20 11:37;cs687;3.) *restore the dumps to syt2*
before the restoration: 
{code:java}
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 |        | running | 15 |         0 |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 | Leader | running | 15 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+

postgres=# \l+
                                                                         List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |   Access privileges   |  Size   | Tablespace |                Description
----------------+----------------+----------+-------------+-------------+-----------------------+---------+------------+--------------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +| 8061 kB | pg_default | default administrative connection database
                |                |          |             |             | postgres=CTc/postgres+|         |            |
                |                |          |             |             | pgwatch2=c/postgres   |         |            |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7817 kB | pg_default | unmodifiable empty database
                |                |          |             |             | postgres=CTc/postgres |         |            |
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7957 kB | pg_default | default template for new databases
                |                |          |             |             | postgres=CTc/postgres |         |            |
(6 rows)
{code}

after restoration: 
* starting the restore of the dump with schema owner user 
{code:java}
for comp in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${comp}.sql.gz | psql -p 26004 -U m7tshrdsyt2${comp} -d m7tshrdsyt2${comp}; done
{code}

After restoring i executed the following commands:
{code:java}
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1= '',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 61
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number  = '';
UPDATE 212
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 2
{code}

{color:#DE350B}In the current running hupx-prod database we have a total size of 5281 MB for m7thupxprodm7b database{color}

*In the database what we restored we have now a total size of 4913 MB!*
We expect that the data is just structured differently.

","30/Jun/20 11:42;cs687;4.) *running clean_up scripts*

will be skipped!","30/Jun/20 11:42;cs687;As last step i just deployed systemtest2 again

and made some manually changes for the test: 
In files /shrd/shrd-syt2-enq1/tomcat/lib/comxerv_env.properties and /shrd/shrd-syt2-cor1/tomcat/lib/application_env.properties, the value of comxerv.exchangeId=HUPX has to be filled (instead of default EPEX) and both cor and enq have to be restarted after the change.

[~jv861] made the changes for running CT in systemtest2 ","30/Jun/20 13:20;jv861;Tested - created trades without problems","30/Jun/20 13:57;cs687;.",,,,,,,,,,,,,,,,,,,,
6.9 production like installation test BSP PROD,M7P-6426,97367,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,24/Jun/20 15:31,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 14:35,,6.10.123,7tops_sprint9_,,,,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - agreed mandatory test defined prior to 6.9 acceptance by RM - see M7 6.9 Acceptance readiness M7P-5739
 - agreed 30/3/2020
 - a similar test was already executed for major release 6.8 -> M7P-5201 with exactly same scope

*task description*

Together with Techops, please perform a complete installation test on the PROD data from the BSP customer:
 * get dump from BSP PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * It was agreed by DEV/TECHOPS that for non-ELTS environments we will not execute dbeaclunp script
 * -Apply DB cleanup scripts on old database- 
 * run 6.9 flyway migration (still on the old db)
 * measure migration timeline
 * load dump to internal test environment
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** -execution time of dbcleanup-
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,cs687,jv861,rehapav,,,,,,,,,,,,,,,,,M7P-6425,,,,,,,,,,,,,,SERVICE-5966,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38188800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwq7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97367,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/20 14:01;cs687;Stopped Systemtest2 Environment and dropped the database, to run a fresh restore of HUPX-PROD
{code:java}
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2m7b;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2mtt;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2rep;
DROP DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2rep WITH OWNER   m7tshrdsyt2rep;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2m7b WITH OWNER   m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2mtt WITH OWNER   m7tshrdsyt2mtt;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;
ALTER DATABASE
postgres=# CREATE ROLE ro_users;
{code}
","30/Jun/20 14:08;cs687;1.) *dump xrpm-prod (m7prodpdb1) and restore in systemtest2 (m7testpdb1)*
{code:java}
                                              List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7txsopprodm7b | m7txsopprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodm7b                   +
                |                |          |             |             | m7txsopprodm7b=CTc/m7txsopprodm7b    +
                |                |          |             |             | uapp01m7txsopprodm7b=c/m7txsopprodm7b+
                |                |          |             |             | uapp01m7txsopprodrep=c/m7txsopprodm7b+
                |                |          |             |             | udev01m7txsopprodm7b=c/m7txsopprodm7b+
                |                |          |             |             | ro_users=c/m7txsopprodm7b            +
                |                |          |             |             | pgwatch2=c/m7txsopprodm7b
 m7txsopprodmtt | m7txsopprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodmtt                   +
                |                |          |             |             | m7txsopprodmtt=CTc/m7txsopprodmtt    +
                |                |          |             |             | uapp01m7txsopprodmtt=c/m7txsopprodmtt+
                |                |          |             |             | udev01m7txsopprodmtt=c/m7txsopprodmtt+
                |                |          |             |             | pgwatch2=c/m7txsopprodmtt
 m7txsopprodrep | m7txsopprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txsopprodrep                   +
                |                |          |             |             | m7txsopprodrep=CTc/m7txsopprodrep    +
                |                |          |             |             | uapp01m7txsopprodrep=c/m7txsopprodrep+
                |                |          |             |             | udev01m7txsopprodrep=c/m7txsopprodrep+
                |                |          |             |             | pgwatch2=c/m7txsopprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
{code}
dumping the db´s 
{code:java}
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20012 -d m7txsopprodm7b -n m7txsopprodm7b | sed 's/m7txsopprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20012 -d m7txsopprodmtt -n m7txsopprodmtt | sed 's/m7txsopprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz
-bash-4.2$ /usr/pgsql-11/bin/pg_dump --port=20012 -d m7txsopprodrep -n m7txsopprodrep | sed 's/m7txsopprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz
-bash-4.2$
{code}
{code:java}
-rw-r--r--   1 postgres postgres 713285257 Jun 30 14:07 m7tshrdsyt2m7b.sql.gz
-rw-r--r--   1 postgres postgres       589 Jun 30 14:08 m7tshrdsyt2mtt.sql.gz
-rw-r--r--   1 postgres postgres      3470 Jun 30 14:08 m7tshrdsyt2rep.sql.gz
{code}


","30/Jun/20 14:09;cs687;2.) *copy dump´s to m7testpdb1 machine*
{code:java}
-bash-4.2$ scp /tmp/m7tshrdsyt2* cs687@m7testpdb2:/tmp
cs687@m7testpdb2's password:
m7tshrdsyt2m7b.sql.gz                                                                                                                                                                                                                                                                      100%  680MB  85.0MB/s   00:08
m7tshrdsyt2mtt.sql.gz                                                                                                                                                                                                                                                                      100%  589    90.9KB/s   00:00
m7tshrdsyt2rep.sql.gz                                                                                                                                                                                                                                                                      100% 3470     1.7MB/s   00:00
{code}
","30/Jun/20 14:16;cs687;3.) *restore the dumps to syt2*
* starting the restore of the dump´s with schema owner user 
{code:java}
for comp in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${comp}.sql.gz | psql -p 26004 -U m7tshrdsyt2${comp} -d m7tshrdsyt2${comp}; done
{code}
After restoring i executed the following commands:
{code:java}
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1= '',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 47
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number  = '';
UPDATE 219
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 1
{code}
","30/Jun/20 14:16;cs687;4.) *running clean_up scripts*

will be skipped!","30/Jun/20 14:16;cs687;As last step i just deployed systemtest2 again

and made some manually changes for the test:
In files /shrd/shrd-syt2-enq1/tomcat/lib/comxerv_env.properties and /shrd/shrd-syt2-cor1/tomcat/lib/application_env.properties, the value of comxerv.exchangeId=XSOP has to be filled (instead of default EPEX) and both cor and enq have to be restarted after the change.

Kamil Ondrak made the changes for running CT in systemtest2","30/Jun/20 14:34;jv861;ComTrader tested, everything runs smoothly","30/Jun/20 14:35;cs687;.",,,,,,,,,,,,,,,,,,,,
6.9 production like installation test TGE PROD,M7P-6425,97366,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,24/Jun/20 15:30,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 11:16,,6.10.123,7tops_sprint9_,,,,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - agreed mandatory test defined prior to 6.9 acceptance by RM - see M7 6.9 Acceptance readiness M7P-5739
 - agreed 30/3/2020
 - a similar test was already executed for major release 6.8 -> M7P-5201 with exactly same scope

*task description*

Together with Techops, please perform a complete installation test on the PROD data from the TGE customer:
 * get dump from TGE PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * It was agreed by DEV/TECHOPS that for non-ELTS environments we will not execute dbeaclunp script
 * -Apply DB cleanup scripts on old database- 
 * run 6.9 flyway migration (still on the old db)
 * measure migration timeline
 * load dump to internal test environment
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** -execution time of dbcleanup-
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,cs687,jv861,rehapav,,,,,,,,,,,,,,,,,M7P-6424,,,,,,,,,,,,,,SERVICE-5964,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38275200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwpz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97366,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jun/20 08:27;cs687;Stopped Systemtest2 Environment and dropped the database, to run a fresh restore of PLPX-PROD
{code:java}
postgres=# DROP DATABASE IF EXISTS m7tshrdsyt2m7b;                                                             
DROP DATABASE                                                                                                  
postgres=# DROP DATABASE IF EXISTS m7tshrdsyt2mtt;                                                             
DROP DATABASE                                                                                                  
postgres=# DROP DATABASE IF EXISTS m7tshrdsyt2rep;                                                             
DROP DATABASE                                                                                                  
postgres=#                                                                                                     
postgres=# CREATE DATABASE   m7tshrdsyt2rep WITH OWNER   m7tshrdsyt2rep;                                       
CREATE DATABASE                                                                                                
postgres=# ALTER  DATABASE   m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;                                 
ALTER DATABASE                                                                                                 
postgres=# CREATE DATABASE   m7tshrdsyt2m7b WITH OWNER   m7tshrdsyt2m7b;                                       
CREATE DATABASE                                                                                                
postgres=# ALTER  DATABASE   m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;                                 
ALTER DATABASE                                                                                                 
postgres=# CREATE DATABASE   m7tshrdsyt2mtt WITH OWNER   m7tshrdsyt2mtt;                                       
CREATE DATABASE                                                                                                
postgres=# ALTER  DATABASE   m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;                                 
ALTER DATABASE                                                                                                 
postgres=# CREATE ROLE ro_users;                                                                               
{code}
","30/Jun/20 08:27;cs687;1.) *dump plpx-prod (m7prodpdb1) and restore in systemtest2 (m7testpdb1)*
{code:java}
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7tplpxprodm7b | m7tplpxprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tplpxprodm7b                   +
                |                |          |             |             | m7tplpxprodm7b=CTc/m7tplpxprodm7b    +
                |                |          |             |             | uapp01m7tplpxprodm7b=c/m7tplpxprodm7b+
                |                |          |             |             | uapp01m7tplpxprodrep=c/m7tplpxprodm7b+
                |                |          |             |             | udev01m7tplpxprodm7b=c/m7tplpxprodm7b+
                |                |          |             |             | ro_users=c/m7tplpxprodm7b            +
                |                |          |             |             | pgwatch2=c/m7tplpxprodm7b
 m7tplpxprodmtt | m7tplpxprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tplpxprodmtt                   +
                |                |          |             |             | m7tplpxprodmtt=CTc/m7tplpxprodmtt    +
                |                |          |             |             | uapp01m7tplpxprodmtt=c/m7tplpxprodmtt+
                |                |          |             |             | udev01m7tplpxprodmtt=c/m7tplpxprodmtt+
                |                |          |             |             | pgwatch2=c/m7tplpxprodmtt
 m7tplpxprodrep | m7tplpxprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tplpxprodrep                   +
                |                |          |             |             | m7tplpxprodrep=CTc/m7tplpxprodrep    +
                |                |          |             |             | uapp01m7tplpxprodrep=c/m7tplpxprodrep+
                |                |          |             |             | udev01m7tplpxprodrep=c/m7tplpxprodrep+
                |                |          |             |             | pgwatch2=c/m7tplpxprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
{code}

dumping the db´s 
{code:java}
/usr/pgsql-11/bin/pg_dump --port=20010 -d m7tplpxprodm7b -n m7tplpxprodm7b | sed 's/m7tplpxprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20010 -d m7tplpxprodmtt -n m7tplpxprodmtt | sed 's/m7tplpxprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20010 -d m7tplpxprodrep -n m7tplpxprodrep | sed 's/m7tplpxprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz
{code}

{code:java}
-rw-r--r-- 1 postgres postgres 1055080908 Jun 30 08:32 m7tshrdsyt2m7b.sql.gz
-rw-r--r-- 1 postgres postgres        589 Jun 30 08:33 m7tshrdsyt2mtt.sql.gz
-rw-r--r-- 1 postgres postgres       3477 Jun 30 08:34 m7tshrdsyt2rep.sql.gz
{code}

","30/Jun/20 08:35;cs687;2.) *copy dump´s to m7testpdb2 machine*
{code:java}
-bash-4.2$ scp /tmp/m7tshrdsyt2* cs687@m7testpdb2:/tmp
cs687@m7testpdb2's password:
m7tshrdsyt2m7b.sql.gz                                                                                                                                                                                                                                                                      100% 1006MB 143.7MB/s   00:07
m7tshrdsyt2mtt.sql.gz                                                                                                                                                                                                                                                                      100%  589   606.3KB/s   00:00
m7tshrdsyt2rep.sql.gz                                                                                                                                                                                                                                                                      100% 3477     3.7MB/s   00:00
{code}
","30/Jun/20 08:39;cs687;3.) *restore the dumps to syt2*
before the restoration: 
{code:java}
[root@m7testpdb2 ~]# patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 |        | running | 15 |         0 |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 | Leader | running | 15 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+

-bash-4.2$ psql -p 26004
psql (11.5)
Type ""help"" for help.

postgres=# \l+
                                                                         List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |   Access privileges   |  Size   | Tablespace |                Description
----------------+----------------+----------+-------------+-------------+-----------------------+---------+------------+--------------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +| 8061 kB | pg_default | default administrative connection database
                |                |          |             |             | postgres=CTc/postgres+|         |            |
                |                |          |             |             | pgwatch2=c/postgres   |         |            |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7817 kB | pg_default | unmodifiable empty database
                |                |          |             |             | postgres=CTc/postgres |         |            |
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7957 kB | pg_default | default template for new databases
                |                |          |             |             | postgres=CTc/postgres |         |            |
(6 rows)
{code}

after the restoration: 
* starting the restore of the dump with schema-owner user
{code:java}
for comp in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${comp}.sql.gz | psql -p 26004 -U m7tshrdsyt2${comp} -d m7tshrdsyt2${comp}; done
{code}

After restoring i executed the following commands:
{code:java}
postgres=# \c m7tshrdsyt2m7b
You are now connected to database ""m7tshrdsyt2m7b"" as user ""postgres"".
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 0
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number  = '';
UPDATE 404
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1= '',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 57
{code}

{color:#DE350B}In the current running plpx-prod database we have a total size of 12 GB for m7tplpxprodm7b database{color}

*In the database what we restored we have now a total size of 11 GB!*
We expect that the data is just structured differently.

","30/Jun/20 08:43;cs687;4.) *running clean_up scripts*

will be skipped!","30/Jun/20 08:47;cs687;As last step i just deployed systemtest2 again
","30/Jun/20 08:54;cs687;There is on more change needed for runing non-EPEX configuration on SYT2:

In files */shrd/shrd-syt2-enq1/tomcat/lib/comxerv_env.properties* and */shrd/shrd-syt2-cor1/tomcat/lib/application_env.properties*, 
the value of *comxerv.exchangeId=PLPX* has to be filled (instead of default EPEX) and both cor and enq have to be restarted after the change.

[~jv861] will handle the CT changes. ","30/Jun/20 10:47;jv861;Tested with the comtrader - created a trade without problems

TGE doesn't use local products, so I had to craete one, but it worked without problems too","30/Jun/20 11:16;cs687;.",,,,,,,,,,,,,,,,,,,
6.9 production like installation test OPCOM PROD,M7P-6424,97365,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,24/Jun/20 15:29,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 07:26,,6.10.123,7tops_sprint9_,,,,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - agreed mandatory test defined prior to 6.9 acceptance by RM - see M7 6.9 Acceptance readiness M7P-5739
 - agreed 30/3/2020
 - a similar test was already executed for major release 6.8 -> M7P-5201 with exactly same scope

*task description*

Together with Techops, please perform a complete installation test on the PROD data from the OPCOM customer:
 * get dump from OPCOM PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * It was agreed by DEV/TECHOPS that for non-ELTS environments we will not execute dbeaclunp script
 * -Apply DB cleanup scripts on old database- 
 * run 6.9 flyway migration (still on the old db)
 * measure migration timeline
 * load dump to internal test environment
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** -execution time of dbcleanup-
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,cs687,jv861,rehapav,,,,,,,,,,,,,,,,,M7P-6347,,,,,,,,,,,,,,SERVICE-5965,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38275200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwpr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97365,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/20 11:27;cs687;Stopped Systemtest2 Environment and dropped the database, to run a fresh restore of OPCOM-PROD 

{code:java}
postgres=# DROP DATABASE IF EXIS

postgres=# DROP DATABASE IF EXIS

postgres=# DROP DATABASE IF EXIS

postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2m7b;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2mtt;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2rep;
DROP DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2rep WITH OWNER   m7tshrdsyt2rep;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2m7b WITH OWNER   m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;
ALTER DATABASE
postgres=# CREATE DATABASE   m7tshrdsyt2mtt WITH OWNER   m7tshrdsyt2mtt;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;
ALTER DATABASE
postgres=# CREATE ROLE ro_users;
{code}
","29/Jun/20 11:38;cs687;1.) *dump xrpm-prod (m7prodpdb1) and restore in systemtest2 (m7testpdb1)*

{code:java}
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7txrpmprodm7b | m7txrpmprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodm7b                   +
                |                |          |             |             | m7txrpmprodm7b=CTc/m7txrpmprodm7b    +
                |                |          |             |             | uapp01m7txrpmprodm7b=c/m7txrpmprodm7b+
                |                |          |             |             | uapp01m7txrpmprodrep=c/m7txrpmprodm7b+
                |                |          |             |             | udev01m7txrpmprodm7b=c/m7txrpmprodm7b+
                |                |          |             |             | ro_users=c/m7txrpmprodm7b            +
                |                |          |             |             | pgwatch2=c/m7txrpmprodm7b
 m7txrpmprodmtt | m7txrpmprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodmtt                   +
                |                |          |             |             | m7txrpmprodmtt=CTc/m7txrpmprodmtt    +
                |                |          |             |             | uapp01m7txrpmprodmtt=c/m7txrpmprodmtt+
                |                |          |             |             | udev01m7txrpmprodmtt=c/m7txrpmprodmtt+
                |                |          |             |             | pgwatch2=c/m7txrpmprodmtt
 m7txrpmprodrep | m7txrpmprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7txrpmprodrep                   +
                |                |          |             |             | m7txrpmprodrep=CTc/m7txrpmprodrep    +
                |                |          |             |             | uapp01m7txrpmprodrep=c/m7txrpmprodrep+
                |                |          |             |             | udev01m7txrpmprodrep=c/m7txrpmprodrep+
                |                |          |             |             | pgwatch2=c/m7txrpmprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
              |                |          |             |             | postgres=CTc/postgres
{code}
dumping the db´s
{code:java}
/usr/pgsql-11/bin/pg_dump --port=20014 -d m7txrpmprodm7b -n m7txrpmprodm7b | sed 's/m7txrpmprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20014 -d m7txrpmprodmtt -n m7txrpmprodmtt | sed 's/m7txrpmprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20014 -d m7txrpmprodrep -n m7txrpmprodrep | sed 's/m7txrpmprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz
{code}
{code:java}
-rw-r--r--   1 postgres postgres 649527626 Jun 29 11:35 m7tshrdsyt2m7b.sql.gz
-rw-r--r--   1 postgres postgres       589 Jun 29 11:37 m7tshrdsyt2mtt.sql.gz
-rw-r--r--   1 postgres postgres      3478 Jun 29 11:37 m7tshrdsyt2rep.sql.gz
{code}
","29/Jun/20 11:42;cs687;2.) *copy dump´s to m7testpdb1 machine*
{code:java}
-bash-4.2$ scp /tmp/m7tshrdsyt2* cs687@m7testpdb2:/tmp                                                                                                                                                                                      
cs687@m7testpdb2's password:                                                                                                                                                                                                                
m7tshrdsyt2m7b.sql.gz                                                                                                                                                                                       100%  619MB 103.2MB/s   00:06   
m7tshrdsyt2mtt.sql.gz                                                                                                                                                                                       100%  589   591.4KB/s   00:00   
m7tshrdsyt2rep.sql.gz                                                                                                                                                                                       100% 3478     3.7MB/s   00:00   
{code}
","29/Jun/20 11:56;cs687;3.) *restore the dumps to syt2*
before the restoration: 
{code:java}
[root@m7testpdb2 tmp]# patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 |        | running | 15 |         0 |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 | Leader | running | 15 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+

-bash-4.2$ psql -p 26004
psql (11.5)
Type ""help"" for help.

postgres=# \l+
                                                                         List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |   Access privileges   |  Size   | Tablespace |                Description
----------------+----------------+----------+-------------+-------------+-----------------------+---------+------------+--------------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 |                       | 7957 kB | pg_default |
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres         +| 8061 kB | pg_default | default administrative connection database
                |                |          |             |             | postgres=CTc/postgres+|         |            |
                |                |          |             |             | pgwatch2=c/postgres   |         |            |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7817 kB | pg_default | unmodifiable empty database
                |                |          |             |             | postgres=CTc/postgres |         |            |
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +| 7957 kB | pg_default | default template for new databases
                |                |          |             |             | postgres=CTc/postgres |         |            |
(6 rows)
{code}

after the restoration:
* starting the restore of the dump with schema-owner user
{code:java}
for comp in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${comp}.sql.gz | psql -p 26004 -U m7tshrdsyt2${comp} -d m7tshrdsyt2${comp}; done
{code}

After restoring i executed the following commands: 
{code:java}
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1= '',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 180
m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number  = '';
UPDATE 414
m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 0
{code}

{color:#DE350B}In the current running xrpm-prod database we have a total size of 7179 MB for m7txrpmprodm7b database{color}

*In the database what we restored we have now a total size of 6816 MB!*
We expect that the data is just structured differently.
","29/Jun/20 11:58;cs687;4.) *running clean_up scripts*

will be skipped!","29/Jun/20 12:11;cs687;As last step i just deployed systemtest2 again
Developers should also have a look at it and give green light to it. ","29/Jun/20 17:59;jv861;There is on more change neede for runin non-EPEX configuration on SYT2:
In files {{/shrd/shrd-syt2-enq1/tomcat/lib/comxerv_env.properties}} and {{/shrd/shrd-syt2-cor1/tomcat/lib/application_env.properties}}, the value of {{comxerv.exchangeId=XRPM}} has to be filles (instead of default EPEX) and both cor and enq have to be restarted after the change. 

This time, I did it manually, maybe we can (temporarily) changed it in automation inventory, depending on how many tests are needed to be run.

Also modified ComTrader is needed, the deployed one for SYT2 is for EPEX only.

To do that, it's neede to copy the folder {{comtrader-config/src/main/config/custom/EPEX/envs/sys2}} to {{comtrader-config/src/main/config/custom/XRPM/envs/sys2}} and replace EPEX with XRPM in {{comtrader-config/src/main/config/custom/XRPM/envs/sys2/connection-parameters.properties}} and create a new profile CT's {{pom.xml}} with this new configuration. I did it only locally this time, it's questionable if it would be worth to have it for the future - it could make sense when we have fully working deployment of ComTrader using Ansible.

I created the trade using ComTrader and all works fine now","30/Jun/20 07:26;cs687;Thank you [~jv861] 
we have hupx-prod, plpx-prod and xsop-prod will be follow as well. ",,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 ELTS SIMU deliver product increment 6.9.150 - rehersal installation test with EPEX,M7P-6409,97278,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,fp407,rehapav,rehapav,23/Jun/20 09:20,01/Jul/20 11:27,16/Sep/21 14:11,23/Jun/20 19:11,,6.10.105,7tops_sprint9_,,,,,,25/Jun/20 00:00,M7PRODOPS,,,,,,,"Please prepare PR, deadline - deployment planned for 30/06/2020

Initial delivery of 6.9
||Customer||Environment||Date & Time||Comment||
|ELTS |SIMU| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 *Prepare PR for* 
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1931

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6572,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,added PR for activation of connection pool cleanup (inquiry): https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1931,,,,,,,,ELTS,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,38880000,,SIMU,dm700,lw641,ox626,rehapav,sw455,,30/Jun/20 15:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwrz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97278,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 ELTS (EPEX) ASIM deliver product increment 6.9.150,M7P-6408,97276,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,fp407,rehapav,rehapav,23/Jun/20 09:12,01/Jul/20 11:27,16/Sep/21 14:11,23/Jun/20 17:28,,6.10.105,7tops_sprint9_,,,,,,23/Jun/20 00:00,M7PRODOPS,,,,,,,"Please prepare PR - deadline 23.6 EOB. Deployment planned for for 25/06/2020

Initial deployment of 6.9

Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|ELTS (EPEX)|ASIM| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 *Prepare PR*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : N/A - change already present: https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/dcfb21d88a0127b41571c7576ff5bd34253daa31/inventory/m7t/epex/asim/vars.yml#L22

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6571,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,"PR: N/A, as change already present: https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/dcfb21d88a0127b41571c7576ff5bd34253daa31/inventory/m7t/epex/asim/vars.yml#L22",,,,,,,,EPEX,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,38880000,,ASIM,dm700,lw641,ox626,rehapav,sw455,,25/Jun/20 15:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxwrj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97276,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ATE5 VM reinstall,M7P-6399,97171,89589,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,qo288,ef759,ef759,22/Jun/20 10:43,01/Jul/20 11:27,16/Sep/21 14:11,26/Jun/20 12:45,,7tops_sprint9_,,,,,,,,M7PRODOPS,,,,,,,"Since ATE5 env is not running because of JAVA error, please reinstall VM to fix the problem.",,ef759,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6450,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38620800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxw2f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),Schmetterling Sprint 93 (PS),Schmetterling Sprint 94,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97171,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/20 12:45;qo288;Separate ticket will be created for this instead of subtask as this is not directly related to password policy ticket",,,,,,,,,,,,,,,,,,,,,,,,,,,
Rollout of auditd configuration on m7shrdldap1/2 - Production,M7P-6390,97116,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,19/Jun/20 11:53,07/Jul/20 23:40,16/Sep/21 14:11,23/Jun/20 07:48,,6.8.134,7tops_sprint9_,,,,,,,M7PRODOPS,,,,,,,"In the previous ticket 
https://jira.deutsche-boerse.com/browse/M7P-6131

we figured out that the hosts m7shrdprodldap1/2 are still running with old RH Version 6.7 
For that [~pd122] is active working on moving whole LDAP in to new RHEL7.6.

For that we are waiting for until its done and gonna deploy auditd again. 

FYI: [~iO924]
",,cs687,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38880000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxu6v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97116,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jun/20 12:44;pd122;there are no such hosts - _m7shrdldap1/2_

hosts _m7shrdprodldp1/2_ are running 7.6:
{code:java}
[pd122@m7shrdprodldp1 ~]$ cat /etc/redhat-release
Red Hat Enterprise Linux Server release 7.6 (Maipo){code}","19/Jun/20 12:54;cs687;deployed it on m7*shrd*prodldap2 
lets wait for the report on monday :) 

thanks [~pd122]","23/Jun/20 07:48;cs687;deployed *m7shrdprodldap1* as well. 
Ticket can be closed. ","23/Jun/20 07:48;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: preparation for M7 BSP XSOP PROD deliver 6.9.150,M7P-6380,97069,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,xt853,rehapav,rehapav,18/Jun/20 10:18,26/Nov/20 17:07,16/Sep/21 14:11,30/Jun/20 11:32,,6.10.123,7tops_sprint9_,,,,,,02/Jul/20 00:00,deployment,M7PRODOPS,minor,,,,,"Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|BSP XSOP|PROD| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |
|RabbitMQ|3.8.3| |

 

*Prepare PR for*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : tbd

*This is FIRST 6.9 PROD deployment*

*carefully review linked deployment ticket and check if we do not miss anything*",,rehapav,xt853,,,,,,,,,,,,,,,,,,SERVICE-6541,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,Pull request with all necesary modifivations prepared,,,,,,,,Southpool,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,38275200,,PROD,dm700,lw641,ox626,rehapav,sw455,,08/Jul/20 15:05,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxvkv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 95 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,,,,,,,,,"{""issueId"":97069,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"30/Jun/20 11:32;xt853;PR: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1944]",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 BSP XSOP SIMU deliver 6.9.150,M7P-6379,97067,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,fp407,rehapav,rehapav,18/Jun/20 10:15,01/Jul/20 14:51,16/Sep/21 14:11,29/Jun/20 09:22,,6.10.123,7tops_sprint9_,,,,,,25/Jun/20 00:00,M7PRODOPS,,,,,,,"Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|BSP XSOP|SIMU| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare PR for*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1941

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6540,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,PR for enabling stale connection cleanup (enquiry): https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1941,,,,,,,,Southpool,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,39312000,,SIMU,dm700,lw641,ox626,rehapav,sw455,,30/Jun/20 12:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxvkf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97067,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,master,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 BSP XSOP ASIM deliver 6.9.150,M7P-6378,97065,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,fp407,rehapav,rehapav,18/Jun/20 10:12,01/Jul/20 11:27,16/Sep/21 14:11,23/Jun/20 17:23,,6.10.105,7tops_sprint9_,,,,,,23/Jun/20 00:00,M7PRODOPS,,,,,,,"Please prepare PR, deployment planned 25/06/2020

Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|BSP XSOP|ASIM| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare PR for* 
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1930

 ",,rehapav,,,,,,,,,,,,,,,,,,,SERVICE-6539,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,yq577,,,,,,added PR for cleanup of stale connections: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1930,,,,,,,,Southpool,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,39312000,,ASIM,dm700,lw641,ox626,rehapav,sw455,,25/Jun/20 12:00,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxvjz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":97065,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
upgrade zulu-version on docker hosts ,M7P-6367,97043,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,18/Jun/20 07:57,01/Jul/20 11:27,16/Sep/21 14:11,18/Jun/20 14:43,,6.10.105,7tops_sprint9_,,,,,,,M7PRODOPS,,,,,,,"the file is at: zulu-jdk/zulu11.39.15-ca-jdk11.0.7-linux_x64.tar.gz

full link  https://artifactory.dbgcloud.io:443/artifactory/energy-prod-local/zulu-jdk/zulu11.39.15-ca-jdk11.0.7-linux_x64.tar.gz

should prepare pull-request for repository 
https://github.deutsche-boerse.de/dev/energy.docker.hosts/blob/master/ansible/roles/energy.java/defaults/main.yml
by adding the new docker version 
and start with the upgrade via ansible
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,39225600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxu7b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97043,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/20 08:02;cs687;Prepared necessary pull-request for the zulu-upgrade: 
https://github.deutsche-boerse.de/dev/energy.docker.hosts/pull/89","18/Jun/20 13:21;cs687;connect to entestauto1
ssh ec2-user@rollout-automation-prod.energy.svc.dbgcloud.io -i /home/cs687/ansible01_docker_rsa

switch to ""ansible"" user and directory -> /home/ansible/piotr/energy.docker.hosts/ansible
and run the ansible-playbook on first few hosts englobwkr0-9
{code:java}
ansible-playbook playbooks/docker-wkr-java.yml --limit englobwkr-auto1:englobwkr-auto2:englobwkr-auto3:englobwkr-auto4:englobwkr-auto5:englobwkr-auto6:englobwkr-auto7:englobwkr-auto8:englobwkr-auto9
{code}

waiting for dev feedback to do the rest of the workers. 


Also opened the Jenkins URL 
https://englobjci1.deutsche-boerse.de/configureTools/

and added JDK Installations with 
{code:java}
Name: Zulu-JDK-11.0.7 (/sw/cmqa/tools/JDK)
JAVA-HOME: /sw/cmqa/tools/JDK/zulu11.39.15-ca-jdk11.0.7-linux_x64
{code}
","18/Jun/20 14:43;cs687;docker deployment done: 

{code:java}
englobwkr-auto0            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto1            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto10           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto11           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto12           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto13           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto14           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto15           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto16           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto17           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto18           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto19           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto2            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto20           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto21           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto22           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto23           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto24           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto25           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto26           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto27           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto28           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto29           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto3            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto30           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto31           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto32           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto33           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto34           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto35           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto36           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto37           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto38           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto39           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto4            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto40           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto41           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto42           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto43           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto44           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto45           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto46           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto47           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto48           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto49           : ok=13   changed=7    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto5            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto6            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto7            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto8            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
englobwkr-auto9            : ok=13   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
{code}
","18/Jun/20 14:43;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,
disable php banner and server easter eggs in icsc-cute,M7P-6363,97033,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,17/Jun/20 13:29,07/Jul/20 23:40,16/Sep/21 14:11,19/Jun/20 08:41,,6.8.134,7tops_sprint9_,,,,,,,M7PRODOPS,,,,,,,"solution is described in ticket. 
https://jira.deutsche-boerse.com/browse/M7P-6354
once it is deployed successful in ate1/3 

we need to re-deploy icsc-cute apache as well and validate if the php-banner / server easter eggs are disabled. ",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,39225600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5268,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzxv5j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97033,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"18/Jun/20 07:36;cs687;created proper pull-request for fixing the issue with the perl-deployment as well. 
https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/689

When we could handle a re-deployment now, then we can just approve and merge the pull-request above. If not we should link this Ticket to the next coming ICSC-CUTE Deployment with pull-689 included there.

FYI: [~rehapav], [~qz412]","18/Jun/20 10:04;rehapav;Implement in ICSC CUTE 19/6 prior to 9:00 ","19/Jun/20 07:13;cs687;Re-deployed ICSC GROUP (WEB) 
PHP-Credits are not published anymore by opening this link 
https://cute1.ics.m7c.deutsche-boerse.com/php/main.php/?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000

Just noticed that the php-page is not proper formatted once i am opening the link above. 
It´s just publishing the proper style once i am opening the url https://cute1.ics.m7c.deutsche-boerse.com/php/main.php

Anyways the security lag seems for me fixed. 
also tried it with the url 
https://cute2.ics.m7c.deutsche-boerse.com/php/main.php/?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000","19/Jun/20 08:40;cs687;Dev. just confirmed:

{code:java}
it is a bug in the application, because it uses relative references to css stylesheets and other resources, 
but when you put there trailing slash, it takes main.php as a directory, not a file
{code}

its not related the httpd.conf changes and the security lack is fixed. will close the ticket.","19/Jun/20 08:41;cs687;.",,,,,,,,,,,,,,,,,,,,,,,
extend query timeout on plpx prod db,M7P-6360,97016,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,17/Jun/20 10:22,01/Jul/20 11:27,16/Sep/21 14:11,18/Jun/20 07:26,,6.10.105,7tops_sprint9_,,,Database,,,,M7PRODOPS,,,,,,,"SLA calculation job crashes on 
canceling statement due to conflict with recovery
Please extend the param from 300 (ms) to 60000 (=1minute)",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,TGE,,,,,,,,,,,,,,,,39312000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzxv1r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":97016,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"17/Jun/20 13:17;cs687;changed the parameter to *max_standby_streaming_delay: 30000* and reload the cluster-change 

{code:java}
[root@m7proddbr1 ~]# patronictl -c /etc/patroni_m7tplpxprodasync/config.yml reload m7tplpxprodasync m7proddbr1
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tplpxprodasync | m7proddbr1 | 10.136.161.253:20010 |        | running |  5 |           |
| m7tplpxprodasync | m7proddbr2 | 10.136.33.253:20010  |        | running |  5 |           |
| m7tplpxprodasync | m7prodpdb1 | 10.139.53.176:20010  | Leader | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb2 | 10.139.53.173:20010  |        | running |  5 |           |
| m7tplpxprodasync | m7prodpdb3 | 10.139.53.172:20010  |        | running |  5 |           |
| m7tplpxprodasync | m7prodpdb4 | 10.139.53.171:20010  |        | running |  5 |           |
+------------------+------------+----------------------+--------+---------+----+-----------+
Are you sure you want to reload members m7proddbr1? [y/N]: y
Reload request received for member m7proddbr1 and will be processed within 10 seconds
[root@m7proddbr1 ~]#
[root@m7proddbr1 ~]#
[root@m7proddbr1 ~]#
[root@m7proddbr1 ~]#
[root@m7proddbr1 ~]# patronictl -c /etc/patroni_m7tplpxprodasync/config.yml reload m7tplpxprodasync m7proddbr2
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tplpxprodasync | m7proddbr1 | 10.136.161.253:20010 |        | running |  5 |           |
| m7tplpxprodasync | m7proddbr2 | 10.136.33.253:20010  |        | running |  5 |           |
| m7tplpxprodasync | m7prodpdb1 | 10.139.53.176:20010  | Leader | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb2 | 10.139.53.173:20010  |        | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb3 | 10.139.53.172:20010  |        | running |  5 |         0 |
| m7tplpxprodasync | m7prodpdb4 | 10.139.53.171:20010  |        | running |  5 |           |
+------------------+------------+----------------------+--------+---------+----+-----------+
Are you sure you want to reload members m7proddbr2? [y/N]: y
Reload request received for member m7proddbr2 and will be processed within 10 seconds
{code}
","18/Jun/20 07:26;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,,,
disable php banner and server easter eggs in ate1/5,M7P-6354,96968,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,16/Jun/20 15:29,07/Jul/20 23:40,16/Sep/21 14:11,18/Jun/20 07:21,,6.8.134,7tops_sprint9_,,,,,,,7tops_comm,M7PRODOPS,,,,,,"The proper solution must be the following 
{code:java}
Disable expose_php via php.ini
If you have access to (and can edit) your server’s php.ini file, the recommended solution is to set expose_php = Off and be done with it. In addition to preventing access to the PHP easter eggs and credit information, disabling expose_php has the added benefit of preventing PHP from sending version information in X-Powered-By HTTP Headers. So instead of sending the following response for PHP-generated pages (e.g., WordPress):
{code}

change the parameter expose_php to off in the php.ini file. 
*expose_php = Off*

For that i will test it in Test-Env 
Ate1 and/or Ate5

url for ate1:
https://10.136.148.29:60101/php/main.php?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000

First try change /etc/php.ini file 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"changed the ansible apache-role with the proper changes in httpd.conf template
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/947/files

Afterwards deployed apache on ate1 Test-Environment

Testing the url *before* and *after* the changes 
https://10.136.148.29:60101/php/main.php?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000",,,,,,,,,,,,,,,,,,,,,,,,39312000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5268,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,,,,"2|hzxmy7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":96968,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"17/Jun/20 07:43;cs687;After changing the parameter expose_php = Off and restarted 
/shrd/m7c-shrd-ate1-cmm-web1 on m7shrdinteweb1 it´s working and the php-credits page is hidden and not published anymore. 

Also tried it with editing httpd.conf and .htaccess file with the following lines.
This was not working out for me. 
{code:java}
RewriteEngine On
RewriteCond %{QUERY_STRING} PHP[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12} [NC]
RewriteRule .* - [F,L]
{code}
","17/Jun/20 08:47;cs687;Would not propose to change the expose_php parameter in global /etc/php.ini file to close the security lag for all the php-applications because after php upgrade it will be overwritten, so the change would be useless afterwards:

{code:java}
[root@m7shrdinteweb1 php.d]# rpm -ql php-common-5.4.16-46.el7.x86_64
/etc/php.d
/etc/php.d/curl.ini
/etc/php.d/fileinfo.ini
/etc/php.d/json.ini
/etc/php.d/phar.ini
/etc/php.d/zip.ini
/etc/php.ini
/usr/lib64/php
/usr/lib64/php/modules
/usr/lib64/php/modules/curl.so
/usr/lib64/php/modules/fileinfo.so
/usr/lib64/php/modules/json.so
/usr/lib64/php/modules/phar.so
/usr/lib64/php/modules/zip.so
/usr/share/doc/php-common-5.4.16
/usr/share/doc/php-common-5.4.16/CODING_STANDARDS
/usr/share/doc/php-common-5.4.16/CREDITS
/usr/share/doc/php-common-5.4.16/EXTENSIONS
/usr/share/doc/php-common-5.4.16/LICENSE
/usr/share/doc/php-common-5.4.16/NEWS
/usr/share/doc/php-common-5.4.16/README.EXTENSIONS
/usr/share/doc/php-common-5.4.16/README.EXT_SKEL
/usr/share/doc/php-common-5.4.16/README.GIT-RULES
/usr/share/doc/php-common-5.4.16/README.MAILINGLIST_RULES
/usr/share/doc/php-common-5.4.16/README.NEW-OUTPUT-API
/usr/share/doc/php-common-5.4.16/README.PARAMETER_PARSING_API
/usr/share/doc/php-common-5.4.16/README.PHP4-TO-PHP5-THIN-CHANGES
/usr/share/doc/php-common-5.4.16/README.REDIST.BINS
/usr/share/doc/php-common-5.4.16/README.RELEASE_PROCESS
/usr/share/doc/php-common-5.4.16/README.SELF-CONTAINED-EXTENSIONS
/usr/share/doc/php-common-5.4.16/README.STREAMS
/usr/share/doc/php-common-5.4.16/README.SUBMITTING_PATCH
/usr/share/doc/php-common-5.4.16/README.TESTING
/usr/share/doc/php-common-5.4.16/README.TESTING2
/usr/share/doc/php-common-5.4.16/README.UNIX-BUILD-SYSTEM
/usr/share/doc/php-common-5.4.16/README.WIN32-BUILD-SYSTEM
/usr/share/doc/php-common-5.4.16/README.input_filter
/usr/share/doc/php-common-5.4.16/README.namespaces
/usr/share/doc/php-common-5.4.16/TSRM_LICENSE
/usr/share/doc/php-common-5.4.16/ZEND_CHANGES
/usr/share/doc/php-common-5.4.16/ZEND_LICENSE
/usr/share/doc/php-common-5.4.16/libmagic_LICENSE
/usr/share/doc/php-common-5.4.16/phar_LICENSE
/usr/share/doc/php-common-5.4.16/php.ini-development
/usr/share/doc/php-common-5.4.16/php.ini-production
/usr/share/doc/php-common-5.4.16/regex_COPYRIGHT
/usr/share/php
/var/lib/php
{code}

in that case i recommend to create a file ""expose_php.ini and overwrite the parameter from global /etc/php.ini and set the parameter expose_php to Off
/etc/php.d/expose_php.ini

In our case just only M7C is using php instances: 
{code:java}
[root@m7shrdinteweb1 php]# ps -ef | grep php
apache    1778  1775  0 Jun04 ?        00:00:00 /usr/bin/php /shrd/m7c-shrd-ate1-cmm-web1/www/php/src/CLI.php
apache   25273 25271  0 08:40 ?        00:00:00 /usr/bin/php /shrd/m7c-shrd-ate5-cmm-web1/www/php/src/CLI.php
apache   25488 25482  0 08:41 ?        00:00:00 /usr/bin/php /shrd/m7c-shrd-ate5-cmm-web1/www/php/src/CLI.php
{code}

After changing the config file we have to restart the cmm-application.
Confirmed by by [~HO764] and [~op211] as well. 



","17/Jun/20 11:43;cs687;Problem seems to be solved also by changing the httpd.conf file for the proper instance with the following tags

{code:java}
<IfModule mod_php5.c>
  php_admin_flag expose_php off
</IfModule>
{code}

need to change the ansible-role and deploy it on ate1 and ate3
afterwards when cute and prod will be deployed via ansible the security lag is also resolved. 
","17/Jun/20 11:56;cs687;pull-request: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/947/files
for fixing the issue. Apache needs to be re-deployed for that. 

Perl needs also to be changed because ansible will not come sooner then 11/2020 into PROD","18/Jun/20 07:19;cs687;Deployed the new apache version to ate1 environment 

_/shrd/m7c-shrd-ate1-cmm-web1/config/httpd.conf_
{code:java}
##
## Disable php banner and server easter eggs
##

# PHP contains a flaw that may lead to an unauthorized information disclosure.
# The issue is triggered when a remote attacker makes certain HTTP requests with
# crafted arguments, which will disclose PHP version and another sensitive information
# resulting in a loss of confidentiality.
# For that expose_php has to be disabled
<IfModule mod_php5.c>
  php_admin_flag expose_php off
</IfModule>
{code}

After opening the link ""https://10.136.148.29:60101/php/main.php?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000""
the php credits are not visible anymore and the redirection to the main.php page is working. 

Ticket closed.
","18/Jun/20 07:21;cs687;.",,,,,,,,,,,,,,,,,,,,,,
Consul TEST Cert Renewal for M7,M7P-6349,96938,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,16/Jun/20 09:18,07/Jul/20 23:40,16/Sep/21 14:11,18/Jun/20 15:15,,6.8.134,7tops_sprint9_,,,,,,01/Jul/20 00:00,7tops_comm,,,,,,,"Just received an Email that the consul-test certificate is expiring soon.

*CN=server.m7-shrd-test.consul;Jul 15 12:42:29 2020 GMT;secret/global/consul/m7-shrd-test/server_cert*

have to renew it asap that we dont end up with an downtime on test-databases. ",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3111,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,39225600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5890,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7C,M7T,,,"2|hzxmxj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":96938,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/20 12:28;hw120;As for m7 test, it is still not connected to consul cluster.
It has consul running on pdb1 and 2 as two node cluster.
 * we will have to pause all patroni instances
 * generate new certs
 * copy them over to those 2 nodes
 * restart consul services
 * resume patroni clusters","18/Jun/20 08:53;cs687;Created backup of the old consul certificates on both hosts
{code:java}
[root@m7testpdb1 tmp]# ll consul-cert-backup/
total 12
-rw-r--r-- 1 root root 1245 Jun 18 08:52 ca.crt
-rw-r--r-- 1 root root 1164 Jun 18 08:52 server.crt
-rw------- 1 root root  227 Jun 18 08:52 server.key
{code}

*1.)* Pause all patroni services
{code:java}
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
{code}

*2.)* renew the certificates (saved in vault) - https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/consul_instance
{code:java}
export CONSUL_DC=m7-shrd-test && \
export CONSUL_BINARY=/usr/local/bin/consul && \
roles/consul_instance/create-consul-cluster.sh
{code}

*3.)* copy the certificates from vault to m7testpdb1 and m7testpdb2

*4.)* restart consul services
{code:java}
systemctl restart consul.service
{code}

*5.)* resume patroni clusters
{code:java}
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume; done
{code}
","18/Jun/20 15:13;cs687;run the commands to copy the certs to the target hosts: 

{code:java}
ansible all -m copy -a 'src=m7-shrd-test-server-consul-0-key.pem dest=/etc/consul/ssl/server.key owner=consul group=bin mode=0600 backup=yes' -b --limit 'm7t*-shrd-syt1*pdb*:&postgres' -k -K

ansible all -m copy -a 'src=m7-shrd-test-server-consul-0.pem dest=/etc/consul/ssl/server.crt owner=consul group=bin mode=0644 backup=yes' -b --limit 'm7t*-shrd-syt1*pdb*:&postgres' -k -K

ansible all -m copy -a 'src=consul-agent-ca.pem dest=/etc/consul/ssl/ca.crt owner=consul group=bin mode=0644 backup=yes' -b --limit 'm7t*-shrd-syt1*pdb*:&postgres' -k -K
{code}

{code:java}
-rw-r--r-- 1 consul bin 1078 Jun 18 15:04 ca.crt
-rw-r--r-- 1 consul bin 1245 Jul 16  2019 ca.crt.21655.2020-06-18@15:04:10~
-rw-r--r-- 1 consul bin  993 Jun 18 15:04 server.crt
-rw-r--r-- 1 consul bin 1164 Jul 16  2019 server.crt.22326.2020-06-18@15:04:48~
-rw------- 1 consul bin  227 Jun 18 15:05 server.key
-rw------- 1 consul bin  227 Jul 16  2019 server.key.22533.2020-06-18@15:05:12~
[root@m7testpdb1 ssl]# openssl x509 -in server.crt -text -noout
{code}

{code:java}
        Validity
            Not Before: Jun 18 12:58:37 2020 GMT
            Not After : Jun 16 12:58:37 2030 GMT
{code}


","18/Jun/20 15:15;cs687;.",,,,,,,,,,,,,,,,,,,,,,,,
include XSD version into m7 software version overview page,M7P-6348,96917,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,ax460,rehapav,rehapav,15/Jun/20 14:01,12/Aug/20 11:02,16/Sep/21 14:11,04/Aug/20 14:41,,6.10.173,BO_CW33_2020,,,,,,,7tops,,,,,,,"It would be great if we could include XSD version used by core

into our m7 software overview table

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/]

 

In the future once we will have same overview from XBID we can easily then see

not only to which XBID env its connected but also XSD deployed on the XBID end

to ensure that we have connected compatible versions.

The solution is to publish XBID API version to an info endpoint.
Then adjust the file https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/inventory-report/tasks/main.yml
After a day, adjust the files https://github.deutsche-boerse.de/dev/energy.deployment.versions/blob/gh-pages/js/data.js#L77 and https://github.deutsche-boerse.de/dev/energy.deployment.versions/blob/gh-pages/yml/specs.yml#L54

 ",,ax460,pn508,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"API version reference added to changelog, and will be published in customer portal.",,,,,,,,,,,,,,,,,,,,,,,,35164800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-2441,,,,,,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzn3yn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 98,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":96917,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 14:46;pn508;[~rehapav] & [~dp007] shouldn't we use the docu portal instead?","23/Jun/20 12:26;rehapav;The documentation portal is right place also to show this information.

 

Nevertheless for internal environment overview - to know what exactly we have where - it is important to have this in [https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/]

overview.","16/Jul/20 12:20;ax460;Note this information is already being published to changelog to customer portal [https://github.deutsche-boerse.de/dev/m7.customer.portal/blob/master/release-notes/6.10/6.10.146/CHANGELOG_6.10.146.html#L3] Once portal is live you and customers can see XSD used in M7P version

[~rehapav] is above mentioned enough?","04/Aug/20 14:16;rehapav;I think having a documentation portal + updated changelog is a good enough solution.

Feel free to close the ticket.",,,,,,,,,,,,,,,,,,,,,,,,
6.9 production like installation test,M7P-6347,96906,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,15/Jun/20 12:51,08/Oct/20 08:45,16/Sep/21 14:11,29/Jun/20 11:03,,6.10.123,7tops_sprint9_,,,,,,30/Jun/20 00:00,7tops_comm,M7PRODOPS,,,,,,"*business reason*
 - agreed mandatory test defined prior to 6.9 acceptance by RM - see M7 6.9 Acceptance readiness M7P-5739
 - agreed 30/3/2020
 - a similar test was already executed for major release 6.8 -> M7P-5201 with exactly same scope

*task description*

Together with Techops, please perform a complete installation test on the PROD data from the ELTS customer:
 * get dump from ELTS PROD environment 
 * apply necessary data cleansing on the dump that it does not interfere with real production
 ** https://jira.deutsche-boerse.com/browse/M7P-5203?focusedCommentId=262493&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-262493
 ** review if these cleansing steps are still valid with 6.9
 * apply migration steps : if any
 * Apply DB cleanup scripts on old database 
 * run 6.9 flyway migration (still on the old db)
 * measure migration timeline
 * load dump to internal test environment
 * start environment without connection to XBID
 * perform basic shakedown test

*acceptance criteria*
 * execution times has been noted
 ** execution time of dbcleanup
 ** execution time of flyway
 ** execution time of SQL conversions
 * shakedown test of 6.9 application is successful

 ",,cs687,PB446,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5962,M7P-5739,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38361600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,None,,,M7T,,,,"2|hzpr8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":96906,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jun/20 13:12;PB446;[~rehapav] Could you, please, answer if the abovementioned tests are One Time test set? 
 Or if you want to have it as new kit of automated tests triggered after some occasion /if yes, which one?/","16/Jun/20 13:24;rehapav;These kinds of tests will be performed for every major release on ELTS PROD data.

If test is successful I consider it valid also for other PROD environments (HUPX BSP OPCOM TGE)

It's up to the development team if they want to invest in automation.

I personally think full automation is not needed, because every major release deployment have its own specifics and will be handled individually.

 

So answer is this is one time test per major version, do not automate.","23/Jun/20 10:35;cs687;1.) *dump elts-prod (m7prodpdb1) and restore it in systemtest2 (m7testpdb1)*
{code:java}
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7teltsprodm7b | m7teltsprodm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7teltsprodm7b                   +
                |                |          |             |             | m7teltsprodm7b=CTc/m7teltsprodm7b    +
                |                |          |             |             | uapp01m7teltsprodm7b=c/m7teltsprodm7b+
                |                |          |             |             | uapp01m7teltsprodrep=c/m7teltsprodm7b+
                |                |          |             |             | udev01m7teltsprodm7b=c/m7teltsprodm7b+
                |                |          |             |             | ro_users=c/m7teltsprodm7b            +
                |                |          |             |             | pgwatch2=c/m7teltsprodm7b
 m7teltsprodmtt | m7teltsprodmtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7teltsprodmtt                   +
                |                |          |             |             | m7teltsprodmtt=CTc/m7teltsprodmtt    +
                |                |          |             |             | uapp01m7teltsprodmtt=c/m7teltsprodmtt+
                |                |          |             |             | udev01m7teltsprodmtt=c/m7teltsprodmtt+
                |                |          |             |             | pgwatch2=c/m7teltsprodmtt
 m7teltsprodrep | m7teltsprodrep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7teltsprodrep                   +
                |                |          |             |             | m7teltsprodrep=CTc/m7teltsprodrep    +
                |                |          |             |             | uapp01m7teltsprodrep=c/m7teltsprodrep+
                |                |          |             |             | udev01m7teltsprodrep=c/m7teltsprodrep+
                |                |          |             |             | ro_users=c/m7teltsprodrep            +
                |                |          |             |             | pgwatch2=c/m7teltsprodrep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/postgres                         +
                |                |          |             |             | postgres=CTc/postgres                +
                |                |          |             |             | pgwatch2=c/postgres
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
{code}
dumping the db´s:
{code:java}
/usr/pgsql-11/bin/pg_dump --port=20002 -d m7teltsprodm7b -n m7teltsprodm7b | sed 's/m7teltsprodm7b/m7tshrdsyt2m7b/g' | gzip > /tmp/m7tshrdsyt2m7b.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20002 -d m7teltsprodmtt -n m7teltsprodmtt | sed 's/m7teltsprodmtt/m7tshrdsyt2mtt/g' | gzip > /tmp/m7tshrdsyt2mtt.sql.gz

/usr/pgsql-11/bin/pg_dump --port=20002 -d m7teltsprodrep -n m7teltsprodrep | sed 's/m7teltsprodrep/m7tshrdsyt2rep/g' | gzip > /tmp/m7tshrdsyt2rep.sql.gz
{code}

{code:java}
-rw-r--r-- 1 postgres postgres  589 Jun 23 13:49 m7tshrdsyt2mtt.sql.gz
-rw-r--r-- 1 postgres postgres 3.6K Jun 23 13:50 m7tshrdsyt2rep.sql.gz
-rw-r--r-- 1 postgres postgres  27G Jun 23 15:16 m7tshrdsyt2m7b.sql.gz
{code}
","23/Jun/20 15:19;cs687;2.) *copy dump´s to m7testpdb1 machine*

{code:java}
[root@m7prodpdb1 ~]# scp /tmp/m7tshrdsyt2* cs687@m7testpdb1:/tmp/
The authenticity of host 'm7testpdb1 (10.139.58.178)' can't be established.
ECDSA key fingerprint is SHA256:91hvoGJ56EjjAGH9DJ4ANm9pNlwcM63dv77JF2AxPOc.
ECDSA key fingerprint is MD5:ec:ac:ac:15:68:56:40:b3:95:ba:cc:94:86:cc:2a:e8.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'm7testpdb1,10.139.58.178' (ECDSA) to the list of known hosts.
cs687@m7testpdb1's password:
{code}
","23/Jun/20 15:32;cs687;3.) *restore the dumps to syt2*

before the restoration:
{code:java}
-bash-4.2$ patronictl -c /etc/patroni_m7tshrdsyt2async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt2async | m7testpdb1 | 10.139.58.178:26004 | Leader | running | 13 |         0 |
| m7tshrdsyt2async | m7testpdb2 | 10.139.58.177:26004 |        | running | 13 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
-bash-4.2$ psql -p 26004
psql (11.5)
Type ""help"" for help.

postgres=# \l+
                                                                                 List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges           |  Size   | Tablespace |                Description
----------------+----------------+----------+-------------+-------------+---------------------------------------+---------+------------+--------------------------------------------
 m7tshrdsyt2m7b | m7tshrdsyt2m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2m7b                   +| 62 MB   | pg_default |
                |                |          |             |             | m7tshrdsyt2m7b=CTc/m7tshrdsyt2m7b    +|         |            |
                |                |          |             |             | uapp01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b+|         |            |
                |                |          |             |             | uapp01m7tshrdsyt2rep=c/m7tshrdsyt2m7b+|         |            |
                |                |          |             |             | udev01m7tshrdsyt2m7b=c/m7tshrdsyt2m7b+|         |            |
                |                |          |             |             | pgwatch2=c/m7tshrdsyt2m7b             |         |            |
 m7tshrdsyt2mtt | m7tshrdsyt2mtt | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2mtt                   +| 7981 kB | pg_default |
                |                |          |             |             | m7tshrdsyt2mtt=CTc/m7tshrdsyt2mtt    +|         |            |
                |                |          |             |             | uapp01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt+|         |            |
                |                |          |             |             | udev01m7tshrdsyt2mtt=c/m7tshrdsyt2mtt+|         |            |
                |                |          |             |             | pgwatch2=c/m7tshrdsyt2mtt             |         |            |
 m7tshrdsyt2rep | m7tshrdsyt2rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7tshrdsyt2rep                   +| 7981 kB | pg_default |
{code}

after the restoration:

* stopping the env systemtest2 and dropping/re-creating the old db
{code:java}
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2m7b;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2mtt;
DROP DATABASE
postgres=# DROP DATABASE IF EXISTS   m7tshrdsyt2rep;
DROP DATABASE

postgres=# CREATE DATABASE   m7tshrdsyt2rep WITH OWNER   m7tshrdsyt2rep;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2rep SET SEARCH_PATH TO m7tshrdsyt2rep;

postgres=# CREATE DATABASE   m7tshrdsyt2m7b WITH OWNER   m7tshrdsyt2m7b;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2m7b SET SEARCH_PATH TO m7tshrdsyt2m7b;

postgres=# CREATE DATABASE   m7tshrdsyt2mtt WITH OWNER   m7tshrdsyt2mtt;
CREATE DATABASE
postgres=# ALTER  DATABASE   m7tshrdsyt2mtt SET SEARCH_PATH TO m7tshrdsyt2mtt;

CREATE ROLE ro_users
{code}

* starting the restore of the dump
{code:java}
-bash-4.2$ for comp in m7b rep mtt; do zcat /tmp/m7tshrdsyt2${comp}.sql.gz | psql -p 26004 -d m7tshrdsyt2${comp}; done
SET
SET
SET
SET
SET
 set_config
------------

(1 row)

SET
SET
SET
{code}

After restoring i executed the following commands:

{code:java}
m7tshrdsyt2m7b=# UPDATE cx_260_member SET address_city= '',clearing_contact_fax= '',clearing_contact_name1= '',clearing_contact_name2= '',clearing_contact_phone1= '',clearing_contact_phone2= '',trading_contact_fax= '',trading_contact_name1= '',trading_contact_name2= '',trading_contact_phone1= '',trading_contact_phone2= '';
UPDATE 510

m7tshrdsyt2m7b=# UPDATE cx_282_user SET email_address = 'test@deutsche-boerse.com',phone_number  = '';
UPDATE 5984

m7tshrdsyt2m7b=# UPDATE cx_600_configuration SET value = 'test@deutsche-boerse.com' WHERE id IN ('smsAddressee','mailAddressee','quoteRequestSMSMailExtension');
UPDATE 3
{code}


{color:#DE350B}In the current running elts-prod database we have a total size of 277GB for m7teltsprodm7b database{color}

*In the database what we restored we have now a total size of 249GB!*
We expect that the data is just structured differently.

PID:
*postgres 46610 27201 98 14:43 ?        01:08:17 postgres: m7tshrdsyt2async: postgres m7tshrdsyt2m7b [local] COPY*","25/Jun/20 08:10;cs687;4.) *running clean_up scripts*

VERY IMPORTANT -> Scripts has to be run with schema-owner user: *m7tshrdsyt2m7b* 

*R__002_cleanup_messages_history.sql*
*{color:#DE350B}=> 0,74 seconds{color}*
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__002_cleanup_messages_history.sql
ALTER TABLE
Time: 1.433 ms
CREATE TABLE
Time: 4.139 ms
ALTER TABLE
Time: 0.508 ms
INSERT 0 191010
Time: 486.147 ms
TRUNCATE TABLE
Time: 127.672 ms
DROP TABLE
Time: 29.870 ms
SET
Time: 0.117 ms
ALTER TABLE
Time: 91.854 ms
{code}

*R__003_cleanup_remote_public_trade_history.sql*
*{color:#DE350B}=> 23 seconds{color}*
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__003_cleanup_remote_public_trade_history.sql
ALTER TABLE
Time: 1.016 ms
CREATE TABLE
Time: 0.927 ms
ALTER TABLE
Time: 0.349 ms
INSERT 0 7113353
Time: 15791.033 ms (00:15.791)
TRUNCATE TABLE
Time: 202.725 ms
DROP TABLE
Time: 22.450 ms
SET
Time: 0.093 ms
ALTER TABLE
Time: 6951.523 ms (00:06.952)
{code}

*R__004_cleanup_contract_delivery_area_state_history.sql*
*{color:#DE350B}=> 2,8 seocnds{color}*
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__004_cleanup_contract_delivery_area_state_history.sql
ALTER TABLE
Time: 0.645 ms
CREATE TABLE
Time: 0.821 ms
ALTER TABLE
Time: 0.373 ms
INSERT 0 1017643
Time: 2277.784 ms (00:02.278)
TRUNCATE TABLE
Time: 41.052 ms
DROP TABLE
Time: 23.979 ms
SET
Time: 0.155 ms
ALTER TABLE
Time: 474.149 ms
{code}

*R__005_cleanup_contract_history.sql*
{color:#DE350B}*=> 1,7 seconds*{color}
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__005_cleanup_contract_history.sql
ALTER TABLE
Time: 0.628 ms
CREATE TABLE
Time: 1.784 ms
ALTER TABLE
Time: 0.350 ms
INSERT 0 567399
Time: 1302.287 ms (00:01.302)
TRUNCATE TABLE
Time: 50.160 ms
DROP TABLE
Time: 30.311 ms
SET
Time: 0.092 ms
ALTER TABLE
Time: 315.770 ms
{code}

*R__006_cleanup_contract_closing_price_history.sql*
*{color:#DE350B}=> 0,45 seconds{color}*
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__006_cleanup_contract_closing_price_history.sql  
ALTER TABLE                                                                 
Time: 0.699 ms                                                              
CREATE TABLE                                                                
Time: 1.008 ms                                                              
ALTER TABLE                                                                 
Time: 0.334 ms                                                              
INSERT 0 177883                                                             
Time: 305.851 ms                                                            
TRUNCATE TABLE                                                              
Time: 28.658 ms                                                             
DROP TABLE                                                                  
Time: 21.796 ms                                                             
SET                                                                         
Time: 0.079 ms                                                              
ALTER TABLE                                                                 
Time: 93.940 ms                                                             
{code}


*R__007_cleanup_session_history.sql*
Finished immediately 
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__007_cleanup_session_history.sql 
m7tshrdsyt2m7b=#                                            
{code}

*R__008_cleanup_revision_index.sql*
=> 0.42 seconds
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__008_cleanup_revision_index.sql
ALTER TABLE
Time: 0.768 ms
CREATE TABLE
Time: 0.782 ms
INSERT 0 1
Time: 1.516 ms
TRUNCATE TABLE
Time: 398.867 ms
DROP TABLE
Time: 25.930 ms
SET
Time: 0.072 ms
ALTER TABLE
Time: 1.422 ms
{code}

*R__009_cleanup_order_history.sql*
{color:#DE350B}=> 1185.2 seconds{color}
{code:java}
m7tshrdsyt2m7b=# \i /tmp/R__009_cleanup_order_history.sql                
ALTER TABLE                                                              
Time: 0.842 ms                                                           
CREATE TABLE                                                             
Time: 1.910 ms                                                           
ALTER TABLE                                                              
Time: 0.339 ms                                                           
INSERT 0 172034439                                                       
Time: 646981.612 ms (10:46.982)                                          
TRUNCATE TABLE                                                           
Time: 6241.533 ms (00:06.242)                                            
DROP TABLE                                                               
Time: 44.543 ms                                                          
SET                                                                      
Time: 0.098 ms                                                           
ALTER TABLE                                                              
Time: 271854.775 ms (04:31.855)                                          
CREATE INDEX                                                             
Time: 180029.914 ms (03:00.030)                                          
CREATE INDEX                                                             
Time: 80087.792 ms (01:20.088)                                          
{code}

By executing the clean-scripts i was using the this command to clean up constantly the backup-Filesystem if necessary 

*watch 'df -h | grep m7tshrdsyt2async; rm /var/lib/pgsql_m7tshrdsyt2async/backup/11/pg_xlog_archive/*; df -h'*
{code:java}
Every 2.0s: df -h | grep m7tshrdsyt2async; rm /var/lib/pgsql_m7tshrdsyt2async/backup/11/pg_xlog_archive/*; df -
{code}

The database size changed from *249GB* to *136GB*
for the clean-up script we need totally: *22.8236663 minutes*
","26/Jun/20 11:32;cs687;Just run the deployment and job was finished after 3 minutes.

{code:java}
jenkinsAPP  11:24 AM
Steffen Englert triggered custom deployment to shrd-syt2 (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/deploy_custom/548/)

jenkinsAPP  11:27 AM
Custom deployment to shrd-syt2 finished with result SUCCESS (https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/deploy_custom/548/)
{code}


{code:java}
Flyway Community Edition 6.0.4 by Redgate
WARNING: Skipping filesystem location:/home/jenkins/workspace/Energy-Operations/CD-Pipeline/deploy_custom/playbooks/envsql/repo/m7coredb/shrd/syt2 (not found)
Database: jdbc:postgresql://m7testpdb1.deutsche-boerse.de:26004,m7testpdb2.deutsche-boerse.de:26004/m7tshrdsyt2m7b (PostgreSQL 11.5)
Successfully validated 1 migration (execution time 00:00.016s)
Current version of schema ""m7tshrdsyt2m7b"": 1
Schema ""m7tshrdsyt2m7b"" is up to date. No migration necessary.

TASK [m7tcor : Cleanup Flyway basedir] *****************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Check for existing Flyway installation] *************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Ensure Flyway basedir exists] ***********************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Download Flyway] ************************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Unarchive Flyway] ***********************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Download db cfg] ************************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : make flyway executable] *****************************************
changed: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Ensure db cfg temp dir exists] **********************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : Unarchive db cfg] ***********************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : DBG - flyway directories] ***************************************
skipping: [m7t-shrd-syt2-cor1]

TASK [m7tcor : Clean db] *******************************************************
skipping: [m7t-shrd-syt2-cor1]

TASK [m7tcor : repair flyway metadata table] ***********************************
skipping: [m7t-shrd-syt2-cor1]

TASK [m7tcor : Migrate db] *****************************************************
changed: [m7t-shrd-syt2-cor1 -> localhost]

TASK [m7tcor : DBG - flyway stdout] ********************************************
skipping: [m7t-shrd-syt2-cor1]

TASK [m7tcor : Cleanup Flyway basedir] *****************************************
ok: [m7t-shrd-syt2-cor1 -> localhost]

PLAY RECAP *********************************************************************
m7t-shrd-syt2-cor1         : ok=73   changed=17   unreachable=0    failed=0   
{code}
","29/Jun/20 11:03;cs687; [~jv861] also confirmed that everything looks fine. Ticket can be closed. ",,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 TGE SIMU deliver product increment 6.9.150,M7P-6342,96885,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,jv861,rehapav,rehapav,15/Jun/20 09:08,17/Jun/20 08:12,16/Sep/21 14:11,15/Jun/20 13:42,,6.10.94,7tops Sprint8,,,,,,16/Jun/20 00:00,M7PRODOPS,UAT6.9,,,,,,"INITIAL 6.9 DEPLOYMENT

Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|TGE|SIMU| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare PR for*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : *tbd*

 ",,nn236,rehapav,,,,,,,,,,,,,,,,,,SERVICE-6487,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,,,,,,,,,,,,TGE,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,39571200,,SIMU,dm700,lw641,ox626,rehapav,sw455,,19/Jun/20 15:00,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxuc7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 94 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":96885,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 13:42;nn236;PR in Service ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 OPCOM SIMU deliver product increment 6.9.150,M7P-6341,96884,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,jv861,rehapav,rehapav,15/Jun/20 09:07,17/Jun/20 08:12,16/Sep/21 14:11,15/Jun/20 13:41,,6.10.94,7tops Sprint8,,,,,,16/Jun/20 00:00,M7PRODOPS,UAT6.9,,,,,,"INTITAL 6.9 deployment 

Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|OPCOM|SIMU| | |

*Software versions:*
 M7 6.9.150
||Component||Version||Comment||
|Trading|6.9.100| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare PR for*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : *tbd*

 
 * perform shakedown test",,nn236,rehapav,,,,,,,,,,,,,,,,,,SERVICE-6513,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,,,,,,,,,,,,OPCOM,,,,,,Internal Deployment Request,ax460,jv861,oy574,pw231,rehapav,,,,No,39571200,,SIMU,dm700,lw641,ox626,rehapav,sw455,,17/Jun/20 15:00,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxubz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 94 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":96884,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 13:41;nn236;PR in Service ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,
"Check ELTS PROD start up procedure, H2H should start on 1 node only",M7P-6336,96869,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,qo288,wn626,wn626,12/Jun/20 12:44,17/Jun/20 11:18,16/Sep/21 14:11,16/Jun/20 11:58,,6.10.94,7tops_sprint8,,,,,,,M7PRODOPS,,,,,,,"Check ELTS PROD start-up procedure, H2H should start on 1 node only

 

During last 2 restarts of ELTS PROD, H2H was started on both nodes and caused the issues",,qo288,wn626,,,,,,,,,,,,,,,,,,SERVICE-6477,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"done, see comment",,,,,,,,EPEX,,,,,,Report a Non-Critical Incident,,,,,,,,,,39484800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,Communication -> Customer,,,[],,,,,,,,,,,M7T,,,,"2|hzxu6f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96869,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"16/Jun/20 11:38;qo288;Research indicated that shortly after the maintenance on Jun 9 the h2h instances in the inventory were swapped due to an emergency event.
https://github.deutsche-boerse.de/dev/energy.automation.inventory/commits/master/inventory/m7t/elts/prod/h2h4u/main.yml

H2H4U instance on m7b1 server was disabled in inventory but was most probably still running.
During deployment, 2nd instance on m7b2 VM was started and this is why we ended up with 2 running at the same time.

Also, 2nd instance is now commented out in the inventory. Removing it now so that it does not confuse anyone:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1915

Now host list in the deployment job only shows 1st instance https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/deploy_custom/510/console so there is no possibility for the 2nd instance will be affected.
","16/Jun/20 11:58;qo288;done, see comment",,,,,,,,,,,,,,,,,,,,,,,,,,
[Energy@Mainframe] Decommissioning of Mainframe DB2 databases (except GridLoss & EBSM),M7P-6335,96863,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,pn508,pn508,12/Jun/20 10:35,01/Jul/20 11:27,16/Sep/21 14:11,17/Jun/20 13:32,,6.10.105,7tops_sprint9_,,,,,,,M7PRODOPS,,,,,,,"*Market data has to be stored at least for 10 years in line with the contract. Do we have the backups somewhere else (netbackup, etc) and therefore we can delete DB2/Mainframe databases?*

 

Hi POs,

 

we are on the last mile towards the decommissioning of the old DB2/Mainframe databases. Our database colleagues have send us the output of the unload jobs, which writes the data from databases into CSV files (the attachments are not the actual data).

 

This output is for us to be able to verify, if all the tables have been exported properly into CSV files. The files will be put on tape and stored for 10 years. I leave it up to you, if you want to verify the output logs. Based on my experience with Mainframe, the tools and procedures are pretty save and we can trust them. In case of questions about the format of the logfiles, please contact Tanja Kammel.

 

If you want to check it, please give me feedback *until 17.06. eob*. If I don’t get any feedback from you, I consider it as a *GO* for the deletion of the databases on 20.06.2020.

 

Thanks a lot,

Tobias",,cs687,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jun/20 10:37;pn508;JR97XAUN.JOB01997.2020-06-10.15001026.zip;https://jira.deutsche-boerse.com/secure/attachment/84812/JR97XAUN.JOB01997.2020-06-10.15001026.zip","12/Jun/20 10:37;pn508;JR97XCUN.JOB02032.2020-06-10.15114446.zip;https://jira.deutsche-boerse.com/secure/attachment/84813/JR97XCUN.JOB02032.2020-06-10.15114446.zip","12/Jun/20 10:37;pn508;JR97XEUN.JOB01751.2020-06-10.12153803.zip;https://jira.deutsche-boerse.com/secure/attachment/84814/JR97XEUN.JOB01751.2020-06-10.12153803.zip","12/Jun/20 10:37;pn508;JR97XGUN.JOB01752.2020-06-10.12154837.zip;https://jira.deutsche-boerse.com/secure/attachment/84815/JR97XGUN.JOB01752.2020-06-10.12154837.zip","12/Jun/20 10:38;pn508;JR97XPUN.JOB01753.2020-06-10.12155788.zip;https://jira.deutsche-boerse.com/secure/attachment/84816/JR97XPUN.JOB01753.2020-06-10.12155788.zip","12/Jun/20 10:38;pn508;JR97XRUN.JOB01754.2020-06-10.12160634.zip;https://jira.deutsche-boerse.com/secure/attachment/84817/JR97XRUN.JOB01754.2020-06-10.12160634.zip","12/Jun/20 10:38;pn508;JR97XSUN.JOB01755.2020-06-10.12161595.zip;https://jira.deutsche-boerse.com/secure/attachment/84818/JR97XSUN.JOB01755.2020-06-10.12161595.zip","12/Jun/20 10:38;pn508;JR97XTUN.JOB01756.2020-06-10.12162487.zip;https://jira.deutsche-boerse.com/secure/attachment/84819/JR97XTUN.JOB01756.2020-06-10.12162487.zip",,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,39398400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmxb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 8,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":96863,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/20 10:27;cs687;I checked all the mentioned zip files above. 

checked specially this lines in the files 
{code:java}
UTILITY EXECUTION STARTING
...
UTILITY EXECUTION COMPLETE, RETURN CODE = 0
{code}

{code:java}
BMC51675I UNLOAD STATISTICS:  0 RECORDS DISCARDED DUE TO ERRORS
{code}

All looks good for me! 
I would give green light to it
(/)
","17/Jun/20 13:32;cs687;checked the attached files all looks good. 
",,,,,,,,,,,,,,,,,,,,,,,,,,
"Create components ""Stalker"", ""Cardio"" a ""Coda"" in M7P jira project",M7P-6321,96811,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,yq577,wn626,wn626,10/Jun/20 17:01,17/Jun/20 11:18,16/Sep/21 14:11,11/Jun/20 10:29,,7tops_sprint8,,,,,,,,M7PRODOPS,,,,,,,"Create components ""Stalker"", ""Cardio"" a ""Coda"" in M7P jira project
 
Dev COP would like to filter based on them our fix version etc. see [https://confluence.energy.svc.dbgcloud.io/display/EIT/M7T+Development+CoP]",,ax460,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,new components added,,,,,,,,,,,,,,,,,,,,,,,,39916800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxtwv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96811,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 10:29;ax460;Already done by Pavel Popelka",,,,,,,,,,,,,,,,,,,,,,,,,,,
Stalker Host restructuring & checking netbackup behavior,M7P-6286,96604,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,04/Jun/20 14:58,17/Jun/20 11:18,16/Sep/21 14:11,15/Jun/20 09:50,,6.10.94,7tops_sprint8,,,,,,,M7PRODOPS,,,,,,,"Currently we have for stalker-application the following shrd hosts 
* m7shrdintestk1 ( for internal test env´s) 
* m7shrdcutestk1 ( for cute, lipa env´s) 
* m7shrdsimustk1 ( for simu env´s) 
* m7shrdprodstk1 ( for prod env´s) 

We will shrink down the amount of hosts and keep our structure. 
For that we are going to decommission ""m7shrdcutestk1"" and merge it with the resources of DISK, CPU & RAM to ""m7shrdsimustk1""

We also gonna rename the host ""m7shrdsimustk1"" to ""m7shrdextestk1""
and gonna deploy plpx-lipa & elts-cute on m7shrdextestk1 after changing the inventory with a proper pull-reuqest.

As second topic we have to check with netbackup Team that the backups are running fine, i checked https://opscenter/opscenter/sfr.wizard.include.do?OWASP_CSRFTOKEN=ZUA6-A9ER-5G07-8FOV-4HWU-7ZPF-7PGS-AJBU#
and can find the mentioned host above. ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 09:06;cs687;backup-of-filesytems.png;https://jira.deutsche-boerse.com/secure/attachment/84844/backup-of-filesytems.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39571200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxstj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96604,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 09:08;cs687;Just talked to netbackup admins and they confirmed that for these 3 machines the FS-backup is scheduled
* m7shrdintestk1 
* m7shrdextestk1
* m7shrdprodstk1

backup is configured with ALL_LOCAL_DRIVES so this means when you add a new FS it is automatically included in the backup. 
refer attached file. ","15/Jun/20 09:32;cs687;deployed stalker version 1.0.25 for plpx-lipa, elts-cute, plpx-simu and elts-simu on the host m7shrdextestk1 
Also deployed the monitoring clients on this machine. 

*elts-cute*
{code:java}
[tomcat@m7shrdextestk1 config]$ curl http://localhost:61368/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdextestk1 config]$
{code}

*plpx-lipa*
{code:java}
[tomcat@m7shrdextestk1 config]$ curl http://localhost:61728/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdextestk1 config]$
{code}

*elts-simu*
{code:java}
[tomcat@m7shrdextestk1 config]$ curl http://localhost:61168/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdextestk1 config]$
{code}

*plpx-simu*
{code:java}
[tomcat@m7shrdextestk1 elts-simu-stk1]$ curl http://localhost:61128/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdextestk1 elts-simu-stk1]$
{code}

Old previous hosts m7shrdcutestk1 and m7shrdsimustk1 can be decommissioned.",,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 OPCOM SIMU deliver 6.9.140,M7P-6283,96583,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,xt853,rehapav,rehapav,04/Jun/20 09:33,17/Jun/20 11:18,16/Sep/21 14:11,05/Jun/20 16:10,,6.10.78,7tops_sprint8,,,,,,05/Jun/20 00:00,M7PRODOPS,UAT6.9,,,,,,"Deploy M7  into respective environments according to the following *timeline:
||Customer||Environment||Date & Time||Comment||
|OPCOM|SIMU| | |

*Software versions:*
 M7 6.9.140
||Component||Version||Comment||
|Trading|6.9.96| |
|MTT|n/a| |
|Reporting Engine|6.4.41| |
|ComTrader|6.9.57| |
|H2H|2.0.43| |

 

*Prepare PR (see below) for initial SIMU deployment*
 * enable the feature ""enable database thread pool cleanup for enquiry module"" from ticket  M7P-5300
 ** PR : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1895]

 ",,rehapav,xt853,,,,,,,,,,,,,,,,,,SERVICE-6451,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,,,,,,,,,,,,OPCOM,,,,,,Internal Deployment Request,ax460,cf948,fj021,jv861,nn481,oy574,pw231,,No,40348800,,SIMU,dm700,lw641,ox626,rehapav,sw455,,30/Apr/20 12:00,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxso7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 94 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96583,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"05/Jun/20 09:55;rehapav;look at the similar PR prepared for ELTS ASIM

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1857/files]","05/Jun/20 16:10;xt853;PR [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1895]",,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a full DB backup of ELTS PROD as of 21/4/2020 EoD,M7P-6282,96578,94747,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fp407,fp407,04/Jun/20 08:58,25/Jun/20 13:41,16/Sep/21 14:11,09/Jun/20 16:34,,7tops_sprint8,,,,,,,,7tops,M7PRODOPS,,,,,,"DB backup

Env: ELTS PROD

Date: 21/4/2020 End of Day

 

Thanks :)",,cs687,fp407,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,40003200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxsn3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 91 (PS),Schmetterling Sprint 93 (PS),Schmetterling Sprint 94,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96578,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/20 09:20;cs687;Taking that as a full-backup 
*copyId: 1 - 1587499856 - /ampgsql-data-0 - 2020-04-21 22:10:56*

and incremental-backup 
*copyId: 1 - 1587503566 - /ampgsql-data-1 - 2020-04-21 23:12:46*","04/Jun/20 10:12;cs687;restoring Fullbackup: 
{code:java}
[root@m7spg2 restore]# ~/restore_eltsprod.sh /ampgsql-data-0 ""2020-04-21 22:10:56""
Check copyId: 1 - 1587499856 - /ampgsql-data-0 - 2020-04-21 22:10:56
Retrieving copyId: 1 - 1587499856 - /ampgsql-data-0 - 2020-04-21 22:10:56
.....
{code}
","04/Jun/20 10:52;cs687;restoring Incremental:
{code:java}
[root@m7spg2 restore]# ~/restore_eltsprod.sh /ampgsql-data-1 ""2020-04-21 23:12:46""
Check copyId: 1 - 1587503566 - /ampgsql-data-1 - 2020-04-21 23:12:46
Retrieving copyId: 1 - 1587503566 - /ampgsql-data-1 - 2020-04-21 23:12:46
{code}
","04/Jun/20 11:59;cs687;
{code:java}
                                                   List of databases
       Name       |      Owner       | Encoding |   Collate   |    Ctype    |             Access privileges
------------------+------------------+----------+-------------+-------------+-------------------------------------------
 edb              | enterprisedb     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/enterprisedb                         +
                  |                  |          |             |             | enterprisedb=CTc/enterprisedb            +
                  |                  |          |             |             | pg_watch2=c/enterprisedb
 m7eltsprodm7b    | m7eltsprodm7b    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7eltsprodm7b=CTc/m7eltsprodm7b          +
                  |                  |          |             |             | uapp01m7eltsprodm7b=c/m7eltsprodm7b      +
                  |                  |          |             |             | uapp01m7eltsprodrepm7b=c/m7eltsprodm7b   +
                  |                  |          |             |             | udev01m7eltsprodm7b=c/m7eltsprodm7b      +
                  |                  |          |             |             | umon01m7eltsprodm7b=c/m7eltsprodm7b      +
                  |                  |          |             |             | umgrcopy=c/m7eltsprodm7b                 +
                  |                  |          |             |             | m7epexprodm7b=Cc/m7eltsprodm7b           +
                  |                  |          |             |             | pg_watch2=c/m7eltsprodm7b
 m7eltsprodmtt    | m7eltsprodmtt    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7eltsprodmtt=CTc/m7eltsprodmtt          +
                  |                  |          |             |             | uapp01m7eltsprodmtt=c/m7eltsprodmtt      +
                  |                  |          |             |             | udev01m7eltsprodmtt=c/m7eltsprodmtt      +
                  |                  |          |             |             | umon01m7eltsprodmtt=c/m7eltsprodmtt      +
                  |                  |          |             |             | umgrcopy=c/m7eltsprodmtt                 +
                  |                  |          |             |             | pg_watch2=c/m7eltsprodmtt
 m7eltsprodrepm7b | m7eltsprodrepm7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7eltsprodrepm7b=CTc/m7eltsprodrepm7b    +
                  |                  |          |             |             | uapp01m7eltsprodrepm7b=c/m7eltsprodrepm7b+
                  |                  |          |             |             | udev01m7eltsprodrepm7b=c/m7eltsprodrepm7b+
                  |                  |          |             |             | umon01m7eltsprodrepm7b=c/m7eltsprodrepm7b+
                  |                  |          |             |             | umgrcopy=c/m7eltsprodrepm7b              +
                  |                  |          |             |             | pg_watch2=c/m7eltsprodrepm7b
 postgres         | enterprisedb     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/enterprisedb                         +
                  |                  |          |             |             | enterprisedb=CTc/enterprisedb            +
                  |                  |          |             |             | pg_watch2=c/enterprisedb
 template0        | enterprisedb     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                          +
                  |                  |          |             |             | enterprisedb=CTc/enterprisedb
 template1        | enterprisedb     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                          +
                  |                  |          |             |             | enterprisedb=CTc/enterprisedb            +
                  |                  |          |             |             | pg_watch2=c/enterprisedb
(7 rows)

edb=# \c m7eltsprodm7b
You are now connected to database ""m7eltsprodm7b"" as user ""enterprisedb"".
{code}

Database is available waiting for [~fp407]","04/Jun/20 16:27;cs687;Going to restore the backup from 22/04/20

full-backup: *2020-04-22 22:11:09*
incremental-backup: *2020-04-22 00:13:03*","09/Jun/20 16:33;cs687;my plan was to restore netbackup files from 21.4 to m7spg2 and running the db with postgres version 9.3 on host m7spg2 with enterprisedb standalone database. 
The backup was taken from a patroni setup, somehow its not working to restore the backup. 

https://confluence.energy.svc.dbgcloud.io/display/ET/9.4+Weekly+Meeting+-+Agenda

At the moment the history table for production databases like elts-prod will not be cleaned up, so far dev´s can request access to m7proddbr1/2 and can check the current database setup with read-only permissions.
Once we are constantly cleaning the history table for our env´s, it can happen that dev´s are asking for netbackup-restoration of a previous history-table state.
So properly we need to find a way/solution/jenkins Job to restore netbackup files to an empty/default patroni setup, which dev´s can use.. sounds for me like an copyshrd-job alias Hotfix Job 2.0

Will start discussion with ops-guys and create a ticket afterwards. ",,,,,,,,,,,,,,,,,,,,,,
Repeating load alert for m7shrdshowm7b2,M7P-6270,96481,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,hw120,hw120,02/Jun/20 10:31,17/Jun/20 11:18,16/Sep/21 14:11,08/Jun/20 13:33,,7tops_sprint8,,,,,,,,M7PRODOPS,,,,,,,"I am trying to eliminate repeating alerts as much as possible, either by solving the problem, updating alert conditions, or adding resources.


This one has been repeating almost 1000 times
 WARNING on m7shrdshowm7b2 | System Load: XXXX

 

We can start by adding 2 more cpu to both m7shrdshowm7bX instances.

 

I tried to investigate system resources usage and there might be also some other problem.

[https://grafana.energy.svc.dbgcloud.io/d/PhgXqCNik/system?orgId=2&var-product=m7t&var-host=All&var-client=shrd&var-client_env=show&var-group=tomcat&var-interval=$__auto_interval_interval&from=now-30m&to=now]

 ",,cs687,cv524,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,40089600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxstr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96481,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SHOW,,,,"08/Jun/20 12:06;cv524;Currently no one of involved hosts have enabled the ""CPU Hot Add"" function.
It means, such type of hardware parameter modification will require the power down/up loop.","08/Jun/20 13:15;cv524;Related SYSENG-69 ticket was created and CPU number was increased.
""CPU Hot Add"" and ""Memory Hot Plug"" options were activated on both processed hosts.","08/Jun/20 13:33;cs687;Lambert added more CPU to the mentioned hosts above. 
Stopped application on show-case hosts m7shrdshowm7b1 & m7shrdshowm7b2

and started the application afterwards again. 
we went in with 2 core´s started as SLAVE needed to remove the journalefiles and restart it afterwards. 

[~vp619] confirmed that everything is working fine. 

","08/Jun/20 14:12;hw120;Looks fine now.

[https://grafana.energy.svc.dbgcloud.io/d/PhgXqCNik/system?orgId=2&var-product=m7t&var-host=All&var-client=shrd&var-client_env=show&var-group=tomcat&var-interval=$__auto_interval_interval&from=now-6h&to=now]",,,,,,,,,,,,,,,,,,,,,,,,
M7 SLA Report for May 2020,M7P-6264,96449,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,oh856,oh856,01/Jun/20 11:06,23/Jun/20 23:21,16/Sep/21 14:11,18/Jun/20 10:39,,6.10.105,7tops_sprint7,,,,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
| M7 EPEX PROD| 2020-06-08| 2020-06-08(Volkan)|
| M7 EPEX FLEX| 2020-06-02| 2020-06-05(Volkan)|
| M7 EPEX ASIM| 2020-06-02| 2020-06-05(Volkan)|
| M7 HUPX| 2020-06-02| 2020-06-05(Volkan)|
| M7 XSOP| 2020-06-02| 2020-06-05(Volkan)|
| M7 TGE| 2020-06-02| 2020-06-05(Volkan)|
| M7 OPCOM| 2020-06-02| 2020-06-05(Volkan)|
| M7 AUCTION| 2020-06-02| 2020-06-05(Volkan)|
| ICS / Swissgrid| 2020-06-05| 2020-06-05(Volkan)|

Link to teams: [https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2020%2D05&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D]

 

Greenlight requesting email should be sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>; Volkan Eymir Akcora <volkan.eymir.akcora@deutsche-boerse.com>; 
{code}
 ",,dp007,oh856,wn626,,,,,,";05/Jun/20 09:16;wn626;11760",,0,11760,,,0,11760,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Reports have been generated and sent,,,,,,,,,,,,,,,,,,,,,,,,40780800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmx3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 8,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96449,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Missing SIEM Connection,M7P-6243,96354,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,iO924,iO924,28/May/20 08:08,03/Jun/20 10:36,16/Sep/21 14:11,28/May/20 09:25,,6.10.69,7tops Sprint8,,,,,,29/May/20 00:00,M7PRODOPS,Security,SIEM,,,,,"The servers M7XSOPASIMAMQ1,2,3 und M7XSOPASIMM7B1,2 are apparently not properly connected to SIEM. 

Starting next week, we will receive incident tickets every day (!) in SAP for each server that is not properly connected. 

Would you also be so kind and check if the server englobtdb1 is in your responsibility as well or if this server belongs to the shop of SysEng. If the server is in your responsibility, please also troubleshoot that particular one. 

 

Thank you!

 

Michael",,cs687,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41126400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxpcv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96354,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"28/May/20 09:25;cs687;Restarted for the mentioned M7 Hosts the Service rsyslog.service
Afterwards Renaud Perozzo confirmed that the Hosts are shown as on-boarded again. 

It´s hard to check why this is happening, since we don´t know when they stopped sending logs, its not easy to investigate. 
Renaud will check on their side, if they got something from these hosts in the last months.

",,,,,,,,,,,,,,,,,,,,,,,,,,,
XRPM SIMU - CT down. Network Error: Connection Refused: connect,M7P-6235,96273,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,wn626,27/May/20 09:56,26/Nov/20 17:13,16/Sep/21 14:11,28/May/20 10:26,,6.10.69,7tops Sprint8,,,,,,,connectionIssue,M7PRODOPS,minor,,,,,"XRPM SIMU cannot login to CT. Error:

Network Error: Connection Refused: connect",,wn626,,,,,,,,,,,,,,,,,,,M7P-6144,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,OPCOM,,,,,,,,,,,,,,,,41126400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxran:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 93 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96273,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"27/May/20 09:58;wn626;I found similar issue - [https://jira.deutsche-boerse.com/browse/XBID-1822|https://slack-redir.net/link?url=https%3A%2F%2Fjira.deutsche-boerse.com%2Fbrowse%2FXBID-1822&v=3]
[|https://dbg-devops.slack.com/archives/GSUTH60F8/p1590561130424100?thread_ts=1590560939.423600&cid=GSUTH60F8]

it said that some certificate needs to be extended","28/May/20 10:15;fh971;I can connect with ComTrader:
https://m7trading-test.deutsche-boerse.com/xrpm-simu/
Is it still an issue [~wn626]?","28/May/20 10:26;wn626;confirmed, it works fine now",,,,,,,,,,,,,,,,,,,,,,,,,
M7T Core health checks enhancements,M7P-6230,96195,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,cv179,cv179,26/May/20 14:38,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,,,,,7tops,M,M7PRODOPS,,,,,"Originally from DevOps CoP:
{quote}Assuming, after a startup, a component usually reaches the SLAVE status in ideal case. Currently, in such an event, only after a failover, a configuration mistake can be determined.

Can we perform some ""passive"" checks during a SLAVE startup?
 * connection to the database (i think this is done anyways)
 * verify write access to journal
 * verify journal files are in sync with the revinfo state
 * check connection to LDAP
 * check connection to RABBITMQ
 * check connection to XBID (for m7core / h2h / ...)
 * check connection to sftp, sob, cmi ... (for xbid components)

So what else can we check in advance? A ""healthy"" startup result should not be possible if any of above checks fail.

Can it be done from within the app? Alternatively, we could perform a check from deployment roles, but it might be difficult to find the correct logic... At least the app can easily read all parameters during startup.
{quote}
 

-So we agreed on following split:-

-1. adjustments to health endpoint:-

-Easy connectivity checks should go to the health check:-
 * -basic ldap connection-
 * -Rabbitmq connection-
 * -basic sob connection (without login request)-

-So we can determine if a TCP handshake is successful according to the configuration (host, port, client certificate, user, password) even while in SLAVE state.-

 -- 

-2. adjustments to the seamless blue-green pipeline-

-Trigger the failover/stop endpoint as dedicated task but don't stop tomcat of the previous master until the previous slave ends up in MASTER state. If this does not happen, abort the deployment. (to be done by Roman)-

3. adjustments of the core startup

Check if the journal filesystem is writable. If not, return a failed state.

Also check the contents of the health check - if ldap or rabbitmq connections are impossible, return a failed state

 ",,cs687,cv179,sJ194,,,,,,,,,,,,,,,,,,,,,,,M7P-6312,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,40003200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzym9z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96195,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"28/May/20 14:27;sJ194;[~cs687]to discuss with DEV side and Roman, whether this task is really for 7tops. It seems, that the first and the third part is for DEV and the second part just for Roman","09/Jun/20 18:10;cs687;Talked to Roman, to sum it up 
* point1 is for dev´s 
* point2 will take over Roman as continuous integration topic
* point3 will be taken over from 7tops 

so our task is to check if journal file-system is write-able, in that case cor is started as MASTER. 
to check contents of health-check requires the changes in point1, it can be done with dev together later on as well. 

FYI: [~sJ194] ",,,,,,,,,,,,,,,,,,,,,,,,,,
update pg_hba.conf for m7prodpdb1 Host,M7P-6225,96178,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,cs687,cs687,26/May/20 12:24,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"During the migration we updated the pg_hba.conf for all the production-databases
on Host m7prodpdb1. The Rest of the nodes (m7prodpdb2, m7prodpdb3, m7prodpdb4)
are deployed with the default pg_hba.conf from the *patroni-repository*

https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/82c48d4cb76413aae395532eb91f6119322ce919/roles/patroni/templates/patroni.yml.j2#L72

*default-setting for now looks like that:*
{code:java}
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# ""local"" is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust

host replication replicator 0.0.0.0/0 md5
host all all 0.0.0.0/0 md5
{code}

on m7prodpdb1 machine the pg_hba.conf are copied&paste from the former hosts m7ppg1 and m7ppg2

that´s why we have inconstant state and have to clean it up for the databases:
/var/lib/pgsql_m7tflexprodasync/data
/var/lib/pgsql_m7txrpmprodasync/data
/var/lib/pgsql_m7tplpxprodasync/data
/var/lib/pgsql_m7thupxprodasync/data
/var/lib/pgsql_m7teltsprodasync/data
/var/lib/pgsql_m7tshrdprodasync/data
/var/lib/pgsql_m7txsopprodasync/data
/var/lib/pgsql_m7aamprprodsync/data

For that we should change the pg_hba.conf´s on the host m7prodpdb1 with the version of the m7prodpdb2,3,4 and reload the config with the database command 
*SELECT pg_reload_conf();*

A proper Plan would be maybe to start with FLEX-PROD (because of planned Decommissioning of this Environment), afterwards we can continue with PROD-Profile-server, but further Plan´s i will discuss with [~rehapav].

In Simulation and Test Database-Clusters we are already running the same pg_hba.conf version, so that´s already the proof that it is working with it. 
 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41299200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzymcn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96178,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update certificate for MTT on HUPX ASIM,M7P-6220,96092,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,oy574,oy574,25/May/20 10:52,03/Jun/20 10:36,16/Sep/21 14:11,29/May/20 12:11,,6.10.69,7tops Sprint8,,,MTT,,,,7tops,M7PRODOPS,,,,,,The certificate used for AS2 communication has expired in february: *CertificateExpiredException: NotAfter: Mon Feb 17 14:56:29 CET 2020*. Please update the certificate in vault and restart the instance.,,cs687,fh971,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41040000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxpcf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":96092,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"27/May/20 08:14;cs687;Seems like the certificate in the keystore-File expired: 
*until: Mon Feb 17 14:56:29 CET 2020*

{code:java}
[cs687@m7shrdebsm1 ~]$ keytool -list -v -keystore keystore.p12
Enter keystore password:
Keystore type: jks
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: May 27, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
Certificate fingerprints:
         MD5:  04:00:43:1E:6C:5A:91:93:B8:EA:5F:D6:F1:31:AC:02
         SHA1: F5:1B:C7:6C:A4:3F:52:CB:FA:0B:51:71:FB:98:AA:26:BD:E2:11:37
         SHA256: 43:89:09:BC:0F:80:33:EE:83:63:85:2E:99:BA:7D:7C:F9:A8:C0:C3:86:48:3B:DB:B9:0A:C6:C5:82:3C:F8:00
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3
{code}

","28/May/20 11:01;cs687;Got the information from [~tj898]
that [~lw641] already asked via Email for Certificate Renewal 


{code:java}
HUPX ASIM:
[root@m7hupxasimm7b1 hupx-asim-mtt1]# keytool -list -v -keystore keystore.p12 | more
Enter keystore password:  Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: Feb 14, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
{code}

just checked the received file *as20002.p12*


{code:java}
[root@m7shrdebsm1 cs687]# keytool -list -v keystore as20002.p12

Alias name: 1
Creation date: May 28, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=as20002, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 6e50aadcc2c82a6ce71a696884761382df649828
Valid from: Tue Feb 18 16:04:28 CET 2020 until: Sat Feb 18 16:04:28 CET 2023
Certificate fingerprints:
         MD5:  AC:9C:26:28:F8:F4:49:6A:A6:0A:ED:8A:36:E1:70:E6
         SHA1: 4F:F7:E7:54:1A:80:24:82:ED:05:62:8C:C2:12:DB:C4:34:21:8C:F1
         SHA256: 7B:DC:7A:3D:B5:A8:A9:B4:DD:72:F9:2D:C4:1E:38:9A:08:60:E6:48:D4:26:18:1B:96:5F:B1:DB:A2:F7:A6:DE
Signature algorithm name: SHA256withRSA
Subject Public Key Algorithm: 2048-bit RSA key
Version: 3
{code}

Seems like that it is!
Updating vault, re-deploying and checking.","28/May/20 11:12;cs687;in the previous one we had alias: *Alias name: as20001 - ds, ke*
new generated one is now *Alias name: 1*

i guess we have to change it also back to *Alias name: as20002 - ds, ke*","28/May/20 12:05;cs687;Seems like in Vault for 
* hupx-simu
* hupx-cute
* hupx-asim 

we are using the same keystore/included certificates, when i am checking it for the host m7hupxsimum7b1 and m7hupxcutem7b1 its updated and running, just for m7hupxasimm7b1 is missing. 
Going to re-deploy mtt2 for hupx-asim 

before the re-deployment - logfiles looked like that: 
{code:java}
2020-05-27T22:00:00.126Z [lt-dispatcher-8] ERROR c.h.a.c.AS2Client - Error sending AS2 message
com.helger.as2lib.exception.WrappedOpenAS2Exception: java.security.cert.CertificateExpiredException: NotAfter: Mon Feb 17 14:56:29 CET 2020
{code}
","28/May/20 12:17;cs687;{code:java}
[root@m7hupxasimm7b1 hupx-asim-mtt1]# ls -all /hupx/hupx-asim-mtt1/
total 61752
-rw-r--r--  1 tomcat tomcat     6028 Jan 16 10:09 keystore.p12
{code}

{code:java}
[root@m7hupxasimm7b1 hupx-asim-mtt1]# ls -all /hupx/hupx-asim-mtt1/
total 61752
-rw-r--r--  1 tomcat tomcat     6137 May 28 12:14 keystore.p12
{code}

log files includes: 
{code:java}
Caused by: java.security.KeyStoreException: Unsupported Key type

Caused by: java.security.KeyStoreException: Key protection  algorithm not found: java.security.KeyStoreException: Unsupported Key type


Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mttClientConfigurationCreator': Invocation of init method failed; nested exception is com.deutscheboerse.energy.mtt.MttException: Key protection  algorithm not found: java.security.KeyStoreException: Unsupported Key type
{code}

","29/May/20 09:36;fh971;[~cs687] was Alias name changed to *as20002 - ds, ke*?","29/May/20 12:06;cs687;After checking twice! i have to admit nope 
Hupx-ASIM and Hupx-CUTE are using the alias -> *as20001 - ds, ke* in the inventory. 
Hupx-SIMU just *as20001*

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1886/files

after-redeployment it worked
{code:java}
[root@m7hupxasimm7b1 hupx-asim-mtt1]# curl http://localhost:63234/mtt/health
{""status"":""UP""}[root@m7hupxasimm7b1 hupx-asim-mtt1]#
{code}

will do the same changes for cute
 
","29/May/20 12:11;cs687;hupx-cute after re-deployment:
{code:java}
[root@m7hupxcutem7b1 ~]# curl http://localhost:63334/mtt/health      
{""status"":""UP""}[root@m7hupxcutem7b1 ~]#                              
{code}

",,,,,,,,,,,,,,,,,,,,
missing backups for m7tshrdsyt1 database. ,M7P-6176,95933,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/May/20 12:33,03/Jun/20 10:36,16/Sep/21 14:11,26/May/20 08:00,,6.10.64,7tops Sprint8,,,,,,,M7PRODOPS,,,,,,,"We found out with [~pw231] that we have some missing full/incremental backups for m7tshrdsyt1 

Starting the investigation and also asking netbackup for help 

{code:java}
Hi NBU-Admins, 

Like already discussed with @Michael Lievens EXT, 
We found out some missing Full-Backups for the database with the backup-policy “PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1”.
With the query-command it will shown up, that the last backup was running at 11th of May. (some of them are also triggered manually – like today) 

[root@m7testpdb2 bphdb]# /usr/bin/query-ampgsql#m7tshrdsyt1.sh -p PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 | grep /ampgsql-data-0
copyId: 1 - 1589960806 - /ampgsql-data-0 - 2020-05-20 09:46:46
copyId: 1 - 1589227972 - /ampgsql-data-0 - 2020-05-11 22:12:52
copyId: 1 - 1589141773 - /ampgsql-data-0 - 2020-05-10 22:16:13
copyId: 1 - 1589054715 - /ampgsql-data-0 - 2020-05-09 22:05:15
copyId: 1 - 1588969592 - /ampgsql-data-0 - 2020-05-08 22:26:32
copyId: 1 - 1588945042 - /ampgsql-data-0 - 2020-05-08 15:37:22
copyId: 1 - 1588883151 - /ampgsql-data-0 - 2020-05-07 22:25:51
copyId: 1 - 1588795974 - /ampgsql-data-0 - 2020-05-06 22:12:54
copyId: 1 - 1588750415 - /ampgsql-data-0 - 2020-05-06 09:33:35
copyId: 1 - 1588710367 - /ampgsql-data-0 - 2020-05-05 22:26:07
copyId: 1 - 1588683330 - /ampgsql-data-0 - 2020-05-05 14:55:30
copyId: 1 - 1588591158 - /ampgsql-data-0 - 2020-05-04 13:19:18
copyId: 1 - 1588163635 - /ampgsql-data-0 - 2020-04-29 14:33:55
copyId: 1 - 1587710781 - /ampgsql-data-0 - 2020-04-24 08:46:21

Michael told me that on your side you can see the following error: 
ERR - bphdb exit status = 29: failed trying to exec a command 

Can somebody please investigate in a deeper way on your side. 
I already checked the client logs like 
/usr/openv/netbackup/logs/bphdb and I find nothing related for the mentioned policy above. 

The same means also for the Incremental backup as well. Here an output seems like its also not running constantly every hour. 
[root@m7testpdb2 bphdb]# /usr/bin/query-ampgsql#m7tshrdsyt1.sh -p PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 | grep /ampgsql-data-1
copyId: 1 - 1589963027 - /ampgsql-data-1 - 2020-05-20 10:23:47
copyId: 1 - 1589742677 - /ampgsql-data-1 - 2020-05-17 21:11:17
copyId: 1 - 1589739034 - /ampgsql-data-1 - 2020-05-17 20:10:34
copyId: 1 - 1589570910 - /ampgsql-data-1 - 2020-05-15 21:28:30
copyId: 1 - 1589567279 - /ampgsql-data-1 - 2020-05-15 20:27:59
copyId: 1 - 1589563657 - /ampgsql-data-1 - 2020-05-15 19:27:37
copyId: 1 - 1589560027 - /ampgsql-data-1 - 2020-05-15 18:27:07
copyId: 1 - 1589556410 - /ampgsql-data-1 - 2020-05-15 17:26:50
copyId: 1 - 1589552800 - /ampgsql-data-1 - 2020-05-15 16:26:40
copyId: 1 - 1589549182 - /ampgsql-data-1 - 2020-05-15 15:26:22
copyId: 1 - 1589545575 - /ampgsql-data-1 - 2020-05-15 14:26:15
copyId: 1 - 1589541965 - /ampgsql-data-1 - 2020-05-15 13:26:05
copyId: 1 - 1589538364 - /ampgsql-data-1 - 2020-05-15 12:26:04
copyId: 1 - 1589534735 - /ampgsql-data-1 - 2020-05-15 11:25:35
copyId: 1 - 1589531115 - /ampgsql-data-1 - 2020-05-15 10:25:15
copyId: 1 - 1589527509 - /ampgsql-data-1 - 2020-05-15 09:25:09
copyId: 1 - 1589523872 - /ampgsql-data-1 - 2020-05-15 08:24:32
copyId: 1 - 1589520260 - /ampgsql-data-1 - 2020-05-15 07:24:20
copyId: 1 - 1589516611 - /ampgsql-data-1 - 2020-05-15 06:23:31
copyId: 1 - 1589513002 - /ampgsql-data-1 - 2020-05-15 05:23:22
copyId: 1 - 1589509396 - /ampgsql-data-1 - 2020-05-15 04:23:16
copyId: 1 - 1589310720 - /ampgsql-data-1 - 2020-05-12 21:12:00
copyId: 1 - 1589307067 - /ampgsql-data-1 - 2020-05-12 20:11:07
copyId: 1 - 1589303480 - /ampgsql-data-1 - 2020-05-12 19:11:20
copyId: 1 - 1589299840 - /ampgsql-data-1 - 2020-05-12 18:10:40
copyId: 1 - 1589296195 - /ampgsql-data-1 - 2020-05-12 17:09:55
copyId: 1 - 1589292590 - /ampgsql-data-1 - 2020-05-12 16:09:50
copyId: 1 - 1589288986 - /ampgsql-data-1 - 2020-05-12 15:09:46
copyId: 1 - 1589285354 - /ampgsql-data-1 - 2020-05-12 14:09:14
copyId: 1 - 1589281714 - /ampgsql-data-1 - 2020-05-12 13:08:34
copyId: 1 - 1589278115 - /ampgsql-data-1 - 2020-05-12 12:08:35
copyId: 1 - 1589274477 - /ampgsql-data-1 - 2020-05-12 11:07:57
copyId: 1 - 1589270866 - /ampgsql-data-1 - 2020-05-12 10:07:46
copyId: 1 - 1589267242 - /ampgsql-data-1 - 2020-05-12 09:07:22
copyId: 1 - 1589263640 - /ampgsql-data-1 - 2020-05-12 08:07:20
copyId: 1 - 1589260038 - /ampgsql-data-1 - 2020-05-12 07:07:18
copyId: 1 - 1589256398 - /ampgsql-data-1 - 2020-05-12 06:06:38
copyId: 1 - 1589252775 - /ampgsql-data-1 - 2020-05-12 05:06:15
copyId: 1 - 1589249139 - /ampgsql-data-1 - 2020-05-12 04:05:39
copyId: 1 - 1589245497 - /ampgsql-data-1 - 2020-05-12 03:04:57
copyId: 1 - 1589225900 - /ampgsql-data-1 - 2020-05-11 21:38:20
copyId: 1 - 1589222278 - /ampgsql-data-1 - 2020-05-11 20:37:58
copyId: 1 - 1589218645 - /ampgsql-data-1 - 2020-05-11 19:37:25
copyId: 1 - 1589215021 - /ampgsql-data-1 - 2020-05-11 18:37:01

I tried to get an overview with ops-center URL but its not usable for me regarding the usability performance.

Thanks in Advance! 
Cheers, 
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main
{code}
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41299200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxpc7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95933,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/May/20 12:40;cs687;activated workaround to avoid full DATA/BACKUP Filesystem for m7tshrdsyt1

created cronjob for postgres user to clean up the archived folder every 10 minutes. 
Once we solved the issue with netbackup we can get rid of it again. 
{code:java}
-bash-4.2$ crontab -l
# temporary to avoid full data/backup Filesystem for m7tshrdsyt1
*/10 * * * * rm -rf /var/lib/pgsql_m7tshrdsyt1async/backup/11/pg_xlog_archive/*
{code}
","26/May/20 08:00;cs687;Jenkins job seems like to work in a stable mode:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/job/Start%20Full%20Backup%20All/42/console

{code:java}
[root@m7testpdb2 ~]# /usr/bin/query-ampgsql#m7tshrdsyt1.sh -p PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 -c m7testpdb2.deutsche-boerse.de | grep /ampgsql-data-0
copyId: 1 - 1590437510 - /ampgsql-data-0 - 2020-05-25 22:11:50
{code}

{code:java}
TASK [netbackup : start fullbackup on patroni leader node] *********************
changed: [m7t-shrd-syt1-pdb-async2]
{code}




",,,,,,,,,,,,,,,,,,,,,,,,,,
Open firewall for all patroni postgres dbr instances to monitoring,M7P-6174,95902,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,hw120,hw120,20/May/20 10:03,05/Aug/20 14:32,16/Sep/21 14:11,04/Jun/20 07:52,,6.8.133,7tops_sprint8,,,,,,,M7PRODOPS,MONITORING,,,,,,"Monitoring client can't reach influxdb database from dbr database hosts and therefore those hosts are not being monitored.
{code:java}
[root@m7simudbr1 ~]# telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.72.59...
^C
[hw120@m7simudbr2 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@m7proddbr1 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@m7proddbr2 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C

[hw120@xbtestdbr1 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@xbtestdbr2 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@xbsimudbr1 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@xbsimudbr2 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.72.59...
^C
[hw120@xbproddbr1 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
[hw120@xbproddbr2 ~]$ telnet influxdb.energy.svc.dbgcloud.io 443
Trying 10.115.84.51...
^C
{code}
we must open port tcp 443 from dbr instances to monitoring networks in aws

[https://github.deutsche-boerse.de/dev/energy.infra.vlans/blob/master/yml/networks.yml#L229-L231]

 

 ",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,XP-3383,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,35078400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxpbz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95902,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/May/20 11:37;cs687;Created the necessary firewall-request.

Waiting until ID 504198 is successful implemented to continue on the ticket. ","04/Jun/20 07:52;cs687;Firewall´s are done and successful implemented 
FYI: [~hw120]","03/Aug/20 12:33;hw120;Tested access to all aws subnets from dbr hosts, accessing elasticsearch and influxdb.

Enabling monitoring by starting pg_watch2 service to start collecting instance metrics.","05/Aug/20 14:31;hw120;We still need to update patroni deployment to add pg_hba rule for pg_watch2 so we can connect metrics data from instances.",,,,,,,,,,,,,,,,,,,,,,,,
clean_reports.ksh script not running on PROD RE,M7P-6172,95892,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,pd122,dp007,dp007,20/May/20 09:17,03/Jun/20 10:36,16/Sep/21 14:11,29/May/20 13:38,,6.10.69,7tops Sprint8,,,RE,,,,M7PRODOPS,Reporting_Engine,,,,,,"The reports are piling up on production reporting engines indicating the clean_reports.ksh script is either:
 * not triggered by cron
 * or the script itself is not working

Please compare the situation with exterep where the reports are correctly removed after 5 days.",,cs687,dp007,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,sshd configuration fixed - tomcat user allowed to use public key authentication,,,,,,,,,,,,,,,,,,,,,,,,41644800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,20/May/20 09:17,,[],,,,,,,,,,,M7T,,,,"2|hzxomf:",9223372036854775807,,,,No,,,,,,,,,,sshd configuration broken during recent host reinstall,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ssh to itselffails,,,,,,,,,,"{""issueId"":95892,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"20/May/20 11:09;cs687;restarted elts-prod-rep1 and elts-prod-rep2 
on host m7shrdprodrep1/2 confirmed by [~dp007]

The scripts are looking the same. ","20/May/20 11:10;cs687;cron.d is running on both hosts:

{code:java}
tomcat@m7shrdprodrep1:[/shrd/elts-prod-rep1/tomcat/bin]$ systemctl status crond.service
● crond.service - Command Scheduler
   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)
   Active: active (running) since Wed 2020-04-08 16:24:09 CEST; 1 months 11 days ago
 Main PID: 6450 (crond)
   CGroup: /system.slice/crond.service
           └─6450 /usr/sbin/crond -n
{code}
","20/May/20 13:23;cs687;just checked the log files 
/var/log/cron

and can confirm that the script was running on both hosts: 
{code:java}
May 20 06:00:01 m7shrdprodrep1 CROND[22671]: (tomcat) CMD (/shrd/prodscripts/clean_reports.ksh)
{code}

{code:java}
May 20 06:00:01 m7shrdprodrep2 CROND[16333]: (tomcat) CMD (/shrd/prodscripts/clean_reports.ksh)
{code}

","20/May/20 14:34;dp007;In order to find out  the root cause, please:
 * store this code as clean_reports_test.ksh,
 * create an entry for it in crontab
 * check what appears in the log file /shrd/prodscripts/clean_reports.log

{code:java}
#!/bin/bash
. ~/.bash_profile
################################
#
# Purpose : Removing journal files older than 30 days
#
# Author  : CM / SMD
#
# Creation Date : Feb 2016
#
################################
# Shared machines are 'exte' in non-prod, 'prod' in prod
if [ ""$env"" = ""prod"" ]; then suffix=""prod""; else suffix=""exte""; fi;
echo ""env:$env; suffix:$suffix; "" >> /shrd/prodscripts/clean_reports.log 
{code}","20/May/20 14:48;cs687;done: 
provided log-file includes 

{code:java}
env:prod; suffix:prod;
{code}
","21/May/20 14:24;pd122;Script expects to be able to connect to tomcat@m7shrd${suffix}rep${inst} hosts using rsa keys, this was not possible in case of host m7shrdprodrep1 since 7/4/2020 when sshd configuration was updated (user tomcat was forced to use password authentication) which caused the script to fail.  This has been fixed now:

 ","21/May/20 14:31;pd122;Additionally, the script produces list of files removed as well as hosts accessed to standard output which goes against the concept of crontab scripts (error output only) since the data will eventually fill up local mailbox of user tomcat.  If the data is really required it should be sent out to a specific email address or stored in a (log) file instead.","21/May/20 14:43;pd122;[~cs687], any idea where */shrd/prodscripts/clean_reports.ksh* is deployed from (noticed that the crontab entry is created by ansible)?",,,,,,,,,,,,,,,,,,,,
"Deploy Stalker to TGE Cutes, Simus and Prod",M7P-6158,95798,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pw231,pw231,18/May/20 13:22,17/Jun/20 11:18,16/Sep/21 14:11,04/Jun/20 07:53,,6.10.78,7tops_sprint8,,,,,,,7tops_comm,M7PRODOPS,,,,,,"h4. The Need
We need the enhanced monitoring in elts prod ASAP to see what peaks and delays we are facing.
So we need to deploy stalker to elts cute, simu and prod.
To verify that all works, we should deploy to smaller client first - let's choose TGE( it has a reasonable load)
Other clients can be handled in different jira later on.

h4. What is Stalker?
Our new external logging and monitoring component. 
See https://github.deutsche-boerse.de/dev/m7.stalker

h4. Requirements
Stalker can run on a shared vm but still we would like to have separeted VMs for simu, prod and cute.
- new VM : stalker prod (shared for all clients) - 6 CPU, 8GB, 40GB partition.
- new VM : stalker simu (shared for all clients) - 6 CPU, 8GB, 40GB partition.
- new VM : stalker cute (shared for all cute/lipa/ctpX envs) - 6 CPU, 8 GB, 40GB partition.
- enhance m7shrdintestk1 (shared for all test envs) - 4 CPU, 6GB, (40GB partition already there).
- clock on the stalker vms should be synchronized with their respective environments (the time diff is used to calculate delays).

h4. Tasks
- create VMs as described above
- enhance stalker inventory - see https://github.deutsche-boerse.de/dev/energy.automation.inventory/tree/master/inventory/m7t/shrd/syt1/stalker.
Note : max heap (Xmx) is set to 1GB. This might be too much for cutes and internal test environments since the VMs will host many stalker processes.
- deploy to  
-# TGE - -lipa-, -simu-, -prod-, then
-# ELTS - -cute-,-simu-, prod
- verify in grafana (e.g. here  https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1589798925567&to=1589800725567&var-host=All&var-client=shrd&var-client_env=syt1&var-group=All&var-interval=30s&var-exchangeId=EPEX&fullscreen&panelId=40 
or in chronograf - metric name {{m7_stk_msg_delay}} )
- verify health status monitoring and alerting is in place",,cs687,pw231,,,,,,,,,,,,,,,,M7P-6236,,,,,,,,,,,,,,,,M7P-6226,SYSENGEXT-47,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,40608000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1469,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmw7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 7,7tops Sprint 8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95798,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"25/May/20 13:53;cs687;As first step i created a SYENG-Ticket for creating the necessary VM´s 
Ticket in waiting until the ticket is done!


{code:java}
Hi NBU-Team, 

can you please schedule the backup-procedure for the following newly created machines:

M7SHRDCUTESTK1
M7SHRDSIMUSTK1
M7SHRDPRODSTK1

And please add those jobs to our FFM_Energy in opscenter.
Once it is done, please let us know that we can test it.

Thank you in Advance!

Cheers,
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43

E-Mail  steffen.englert@deutsche-boerse.com
http://www.deutsche-boerse.com
{code}
","26/May/20 12:37;cs687;1.) Deployment for plpx-lipa on host: *m7shrdcutestk1*
* prepared pull-request https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1869
* vault-secret are already prepared /secret/m7t/plpx/lipa/amqp/stalker

Run the Deployment with *Energy-Operations M7 Ansible Jobs*

{code:java}
Started by user Steffen Englert
Rebuilds build #8823
Running as SYSTEM
[EnvInject] - Loading node environment variables.
Building remotely on englobauto1 (englobauto) in workspace /home/jenkins/workspace/Energy-Operations/M7 Ansible Jobs/M7-Deploy-Playbook
using credential ff4c895e-1043-458e-be44-195fb4d1b1b2
 > git rev-parse --is-inside-work-tree # timeout=10
Fetching changes from the remote Git repository
 > git config remote.origin.url git@github.deutsche-boerse.de:dev/energy.automation.deployments.git # timeout=10
Fetching upstream changes from git@github.deutsche-boerse.de:dev/energy.automation.deployments.git
 > git --version # timeout=10
using GIT_SSH to set credentials 
 > git fetch --tags --progress -- git@github.deutsche-boerse.de:dev/energy.automation.deployments.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git rev-parse refs/remotes/origin/master^{commit} # timeout=10
 > git rev-parse refs/remotes/origin/refs/heads/master^{commit} # timeout=10
Checking out Revision ebd81223cfce51952802d70e4c719fdbf98f65d9 (refs/remotes/origin/master)
 > git config core.sparsecheckout # timeout=10
 > git checkout -f ebd81223cfce51952802d70e4c719fdbf98f65d9 # timeout=10
Commit message: ""Merge pull request #905 from dev/revert-904-set-stalkers-base-dir""
 > git rev-list --no-walk ebd81223cfce51952802d70e4c719fdbf98f65d9 # timeout=10
[M7-Deploy-Playbook] $ /bin/sh -xe /tmp/jenkins6501707582004381389.sh
++ [[ false == \f\a\l\s\e ]]
++ echo ''
++ [[ false == \f\a\l\s\e ]]
++ echo ''
++ [[ -z stop,clean,deploy,start ]]
++ echo '--tags stop,clean,deploy,start'
++ [[ false == \f\a\l\s\e ]]
++ echo ''
++ [[ -z '' ]]
++ echo ''
+ ansible-playbook playbooks/deploy_stalker.yml --limit 'm7t-plpx-lipa-*' --tags stop,clean,deploy,start
 [WARNING]: While constructing a mapping from /usr/local/share/energy.automatio
n.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1,
found a duplicate dict key (additional_params). Using last defined value only.
PLAY [Deploy stalker instance] *************************************************

TASK [Gathering Facts] *********************************************************
ok: [m7t-plpx-lipa-stk1]

TASK [stalker : set location equinix] ******************************************
ok: [m7t-plpx-lipa-stk1]
TASK [stalker : set location hausen] *******************************************
skipping: [m7t-plpx-lipa-stk1]

TASK [stalker : compute artifact path] *****************************************
ok: [m7t-plpx-lipa-stk1]

TASK [stalker : compute zip file name] *****************************************
ok: [m7t-plpx-lipa-stk1]

TASK [stalker : Stop running application] **************************************
fatal: [m7t-plpx-lipa-stk1]: FAILED! => {
    ""changed"": true,
    ""cmd"": ""/shrd/plpx-lipa-stk1/stalker-1.0.11/stop.sh"",
    ""delta"": ""0:00:00.002767"",
    ""end"": ""2020-05-26 15:02:58.893432"",
    ""rc"": 127,
    ""start"": ""2020-05-26 15:02:58.890665""
}

STDERR:

/bin/bash: /shrd/plpx-lipa-stk1/stalker-1.0.11/stop.sh: No such file or directory


MSG:

non-zero return code
...ignoring

TASK [stalker : Delete deployment folder] **************************************
ok: [m7t-plpx-lipa-stk1]

TASK [stalker : Create deployment folder] **************************************
changed: [m7t-plpx-lipa-stk1]

TASK [stalker : Create logs folder] ********************************************
changed: [m7t-plpx-lipa-stk1]

TASK [stalker : Create messages logs folder] ***********************************
changed: [m7t-plpx-lipa-stk1]

TASK [stalker : Get app from artifactory] **************************************
ok: [m7t-plpx-lipa-stk1 -> localhost]

TASK [stalker : Unzip artifact to remote server] *******************************
changed: [m7t-plpx-lipa-stk1]

TASK [include_role : roles/vault_base64_decode] ********************************
skipping: [m7t-plpx-lipa-stk1]

TASK [stalker : Create application config file or script] **********************
changed: [m7t-plpx-lipa-stk1] => (item={'mode': '0754', 'src': 'stop.sh.j2', 'dest': 'stop.sh'})
changed: [m7t-plpx-lipa-stk1] => (item={'mode': '0754', 'src': 'start.sh.j2', 'dest': 'start.sh'})
changed: [m7t-plpx-lipa-stk1] => (item={'src': 'logback.xml.j2', 'dest': 'config/logback.xml'})
Replacing double-slashes (""//"") in path with single slash (""/"") to avoid Vault redirect response.
Replacing double-slashes (""//"") in path with single slash (""/"") to avoid Vault redirect response.
changed: [m7t-plpx-lipa-stk1] => (item={'src': 'application.yml.j2', 'dest': 'config/application.yml'})

TASK [stalker : Start the application] *****************************************
changed: [m7t-plpx-lipa-stk1]

PLAY RECAP *********************************************************************
m7t-plpx-lipa-stk1         : ok=13   changed=7    unreachable=0    failed=0   

+ rc=0
+ exit 0
Finished: SUCCESS
{code}

Also deployed telegraf and filebeat for this instance with the jenkins job 
*Deploy Monitoring Clients*

{code:java}
[root@m7shrdcutestk1 plpx-lipa-stk1]# systemctl status filebeat.service
● filebeat.service - filebeat
   Loaded: loaded (/usr/lib/systemd/system/filebeat.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2020-05-26 15:12:09 CEST; 1min 35s ago
     Docs: https://www.elastic.co/guide/en/beats/filebeat/current/index.html
 Main PID: 117510 (filebeat)
   CGroup: /system.slice/filebeat.service
           └─117510 /usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat -strict.perms=false

May 26 15:12:09 m7shrdcutestk1 systemd[1]: Started filebeat.
[root@m7shrdcutestk1 plpx-lipa-stk1]#
[root@m7shrdcutestk1 plpx-lipa-stk1]#
[root@m7shrdcutestk1 plpx-lipa-stk1]# systemctl status telegraf.service
● telegraf.service - The plugin-driven server agent for reporting metrics into InfluxDB
   Loaded: loaded (/usr/lib/systemd/system/telegraf.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2020-05-26 15:12:30 CEST; 1min 22s ago
     Docs: https://github.com/influxdata/telegraf
 Main PID: 118170 (telegraf)
   CGroup: /system.slice/telegraf.service
           └─118170 /usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d

May 26 15:12:30 m7shrdcutestk1 systemd[1]: Started The plugin-driven server agent for reporting metrics into InfluxDB.
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Starting Telegraf 1.13.2
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Loaded inputs: diskio swap statsd ping system processes kernel dns_query cpu mem disk net jolokia2_agent http_response exec
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Loaded aggregators:
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Loaded processors:
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Loaded outputs: influxdb
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! Tags enabled: client=plpx client_environment=lipa datacenter=equinix group=tomcat host=m7shrdcutestk1 host_group_module=m7shrdcutestk1 - tomcat - m7_plpx_lipa machine=tomcat module=m7_plpx_lipa product=m7t
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! [agent] Config: Interval:30s, Quiet:false, Hostname:""m7shrdcutestk1"", Flush Interval:30s
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! [inputs.statsd] UDP listening on ""0.0.0.0:8125""
May 26 15:12:30 m7shrdcutestk1 telegraf[118170]: 2020-05-26T13:12:30Z I! [inputs.statsd] Started the statsd service on "":8125""
{code}

","26/May/20 15:24;cs687;{code:java}
Caused by: com.rabbitmq.client.AuthenticationFailureException: ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.
{code}

we need either to add the user manually via web to RMQ or redeploy RMQ, afterwards we can confirm that everything is working. WAITING.","27/May/20 09:21;cs687;[~dp007] created the proper user in the rabbitmq cluster which is configured in vault. 
Afterwards i am re-deploying/restarting Stalker application

*{color:#DE350B}Important:{color}*
Re-deployment is necessary all the users will be pop up automatically 
After a restart of rabbitmq´s the manually added user will disappear!!!

Stalker application is running: 
{code:java}
[tomcat@m7shrdcutestk1 stalker-1.0.11]$ curl  http://localhost:61728/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdcutestk1 stalker-1.0.11]$
{code}
","27/May/20 11:57;cs687;1.) Deployment for plpx-simu on host: m7shrdsimustk1

prepared pull-request https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1875
vault-secret are already prepared /secret/m7t/plpx/simu/amqp/stalker

* *Run the deployment with CD Pipeline Custom-Job*
* Deployed Monitoring Clients on host m7shrdsimustk1
* added the proper stalker user to rabbitmq 

DONE: 
{code:java}
[tomcat@m7shrdsimustk1 ~]$ curl  http://localhost:61128/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdsimustk1 ~]$
{code}

","27/May/20 13:25;cs687;2.) Deployment for elts-cute on host: m7shrdcutestk1

prepared pull-request https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1878
vault-secret are already prepared /secret/m7t/elts/cute/amqp/stalker

* Run the deployment with CD Pipeline Custom-Job
* Deployed Monitoring Clients on host m7shrdcutestk1
* added the proper stalker user to rabbitmq

DONE: 
{code:java}
[tomcat@m7shrdcutestk1 elts-cute-stk1]$ curl  http://localhost:61368/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdcutestk1 elts-cute-stk1]$
{code}
","27/May/20 13:45;cs687;3.) Deployment for elts-simu on host: m7shrdsimustk1

prepared pull-request https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1879
vault-secret are already prepared /secret/m7t/elts/simu/amqp/stalker

* Run the deployment with CD Pipeline Custom-Job
* Deployed Monitoring Clients on host m7shrdsimustk1
* added the proper stalker user to rabbitmq

DONE:
{code:java}
[tomcat@m7shrdsimustk1 ~]$ curl http://localhost:61168/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[tomcat@m7shrdsimustk1 ~]$
{code}
","02/Jun/20 09:28;cs687;deployed for all mentioned instances above stalker version 1.1.0.12
there was a bug in the previous older version. 

We also made the exp. that during a re-deployment the previous running instances were not killed/stopped during the deployment. 
For that [~nn481] will prepare a fix and come back to us. 
Afterwards we going to deploy it again and continue with production ones ""plpx-prod"" and followed by ""elts-prod""

https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/914
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/916
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/917
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1889
also defining xmx set that the process is not getting the default (portion of the RAM) 
","02/Jun/20 11:29;cs687;Preparation for Prod-Deployment https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1890/files
Starting with plpx-prod and continuing with elts-prod: 

*plpx-prod*

* added user ""Stalker"" to rabbitmq plpx-prod
* deploying stalker application
* deploying monitoring 

{code:java}
tomcat   24134     1 34 13:54 ?        00:00:06 java -Xms256m -Xmx1g -classpath /shrd/plpx-prod-stk1/stalker-1.0.12/lib/stalker-1.0.12.jar:
{code}

{code:java}
2020-06-02T11:54:31.136Z [main] INFO  o.s.s.c.ThreadPoolExecutorFactoryBean - Initializing ExecutorService 'healthExecutorService'
2020-06-02T11:54:31.683Z [main] INFO  io.undertow.servlet - jolokia-agent: No access restrictor found, access to any MBean is allowed
2020-06-02T11:54:31.763Z [main] INFO  io.undertow - starting server: Undertow - 2.0.29.Final
2020-06-02T11:54:31.768Z [main] INFO  org.xnio - XNIO version 3.3.8.Final
2020-06-02T11:54:31.778Z [main] INFO  org.xnio.nio - XNIO NIO Implementation Version 3.3.8.Final
2020-06-02T11:54:31.867Z [DecodingService] INFO  c.d.e.m.s.c.DecodingService - DecodingService thread 'Thread[DecodingService,5,main]' started
2020-06-02T11:54:31.867Z [LoggingService] INFO  c.d.e.m.s.c.LoggingService - LoggingService thread 'Thread[LoggingService,5,main]' started
2020-06-02T11:54:31.867Z [ElasticService] INFO  c.d.e.m.s.c.ElasticService - ElasticService thread 'Thread[ElasticService,5,main]' started
2020-06-02T11:54:31.867Z [MonitorService] INFO  c.d.e.m.s.c.MonitorService - MonitorService thread 'Thread[MonitorService,5,main]' started
2020-06-02T11:54:31.868Z [main] INFO  c.d.e.m.s.l.RetryingLtsConsumer - Trying to start 'RetryingLtsConsumer(ltsConsumer=LtsConsumer(clientName='stalker-1', amqpConfiguration=AmqpConfiguration(addresses=m7shrdprodbha1:50020,m7shrdprodbha3:50020, virtualHost=app, encodingStr=utf-8, retryInterval=5000, maxRetries=2147483647, amqpCredentials=Credentials(username='stalker', password='*****'), consumerConfiguration=ConsumerConfiguration(autoAck=false, exclusive=true, defaultBroadcastExchange=m7.broadcastExchange, defaultRequestExchange=m7.requestExchange, defaultRequestExchangeBindings=[m7.request.management, m7.request.inquiry], defaultRoutingKey=#, broadcastQueueConfiguration=BroadcastQueueConfiguration(queueName=m7.stalker.broadcastQueue, durability=true, exclusive=false, autoDelete=false, messageTTL=300000)))), retryStrategy=RetryStrategy(intervalInMs=5000, maxRetries=2147483647))'
2020-06-02T11:54:31.869Z [AckService] INFO  c.d.e.m.s.c.AckService - AckService thread 'Thread[AckService,5,main]' started
2020-06-02T11:54:31.974Z [main] INFO  c.d.e.m.s.l.RetryingLtsConsumer - Started 'RetryingLtsConsumer(ltsConsumer=LtsConsumer(clientName='stalker-1', amqpConfiguration=AmqpConfiguration(addresses=m7shrdprodbha1:50020,m7shrdprodbha3:50020, virtualHost=app, encodingStr=utf-8, retryInterval=5000, maxRetries=2147483647, amqpCredentials=Credentials(username='stalker', password='*****'), consumerConfiguration=ConsumerConfiguration(autoAck=false, exclusive=true, defaultBroadcastExchange=m7.broadcastExchange, defaultRequestExchange=m7.requestExchange, defaultRequestExchangeBindings=[m7.request.management, m7.request.inquiry], defaultRoutingKey=#, broadcastQueueConfiguration=BroadcastQueueConfiguration(queueName=m7.stalker.broadcastQueue, durability=true, exclusive=false, autoDelete=false, messageTTL=300000)))), retryStrategy=RetryStrategy(intervalInMs=5000, maxRetries=2147483647))'
2020-06-02T11:54:31.974Z [pool-2-thread-3] INFO  c.d.e.m.s.a.AmqpConsumer - Started listening for consumerTag 'stalker-1'
2020-06-02T11:54:31.976Z [health-thread-1] WARN  c.d.e.m.s.h.HealthService - HealthStatus changed from 'HealthState(status=DOWN, rabbitMqConnectionStatus=DOWN, elasticConnectionStatus=UP, diskStatus=UP)' to 'HealthState(status=UP, rabbitMqConnectionStatus=UP, elasticConnectionStatus=UP, diskStatus=UP)'
{code}

Health-Check:
{code:java}
[root@m7shrdprodstk1 plpx-prod-stk1]# curl http://localhost:61028/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdprodstk1 plpx-prod-stk1]#
{code}
","02/Jun/20 14:11;cs687;||Channel||Node||Virtual Host||User Name||Mode ?||State||Unconfirmed||Prefetch ?||unacked||publish||confirm||unroutable (drop)||deliver /get||ack||
|10.139.53.244:39152 (1)|plpx-prod-amq5@m7plpxprodamq5|app|stalker| |running|0|| |0| | | |1.0/s|1.0/s|","02/Jun/20 15:32;cs687;Did the same steps for *elts-prod*

{code:java}
[root@m7shrdprodstk1 elts-prod-stk1]# curl http://localhost:61068/stalker/health
{""status"":""UP"", ""rabbitMqConnectionStatus"":""UP"", ""elasticConnectionStatus"":""UP"", ""diskStatus"":""UP""}[root@m7shrdprodstk1 elts-prod-stk1]#
{code}
",,,,,,,,,,,,,,,,,
rename EPEX ASIM to ELTS ASIM - analysis,M7P-6156,95792,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,rehapav,rehapav,rehapav,18/May/20 11:35,05/Nov/20 13:23,16/Sep/21 14:11,04/Sep/20 10:03,,6.10.217,7tops_sprint14,,,,,,26/Aug/20 00:00,7tops,,,,,,,"all ELTS environments has customer set as ELTS

ELTS CTPB

ELTS SIMU

ELTS PROD

ELTS CUTE

ELTS ACUT

ELTS LIPA

for whatever reasons ASIM is

EPEX ASIM

please rename it to ELTS ASIM

 

update on 29/7

Rename approved - we will use create new one/remove old one approach.

Environments will live in parael for some time.
 * 1/11/2020 request creation of new environment - cca 8 weeks
 ** create task *tbd*
 * 1/1/2021 deploy new environment ELTS ASIM
 ** create task *tbd*
 ** *do not forget to import data from EPEX ASIM* 
 * 1/2/2022 decomission old one EPEX ASIM
 ** create task *tbd*

 

 ",,lu515,PB446,pn508,rehapav,,,,,,,,,,,,,,,,ICS-52,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,tbd,,,Analysis completed,,,,,,,,,,,,,,,pw231,,,,,,,,,33782400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmuhb:",9223372036854775807,,,,No,,,,,,tbd,,,,,,,,,,,,6.12 non RC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95792,""testStatuses"":[]}",,,,tbd,,,,,,,,,,,,,,,,,,PROD,,,,"19/May/20 12:53;PB446;[~pn508] Please, find out if we may afford a downtime for couple of hours on EPEX ASIM environment.
So we know if it is worth to do this task.","19/May/20 12:54;fh971;ComTrader is deployed to special site: http://comtrader-advsimu.epexspot.com/
It would be sweet to move it to https://m7trading-test.deutsche-boerse.com/epex-lts-asim/
","19/May/20 14:26;rehapav;Requesting info from EPEX in SERVICE-6348","25/May/20 13:48;pn508;[~lu515] can we afford some large maintenance window for ELTS ASIM 4-8 hours? if it's announced does it deplete up time SLAs of this environment?","26/May/20 08:16;lu515;it would be better to name it as a ""service update"". If it doesn´t have a functional impact to EPEX we can introduce an unlimited number of the services updates. If it´s just the renaming then there is no functional impact.  Please find the corresponding part of the contract below:

(1) DBAG shall use the process described in Annex 4 to introduce Service Updates. DBAG shall classify each Service Update as mandatory or voluntary.

(2) In case of mandatory Service Updates, Customer shall be obliged to participate in and execute the Service Update process as described in Annex 4. DBAG is allowed to introduce an unlimited number of mandatory Service Updates per year which does not impact changes to the Trading Services for the Customer or the members of the Customer. Where the mandatory Service Update has a functional impact for Customer or client of the Customer, including but not limited to changes in the API, DBAG limits the maximum number of Service Updates per year to two (2) and shall mutually agree the timing of the Service Update introduction with the Customer beforehand. If the timing cannot be agreed, it will be arbitrate by the Steering Committee representatives.","26/May/20 08:38;pn508;EPEX is asking for a different CT url","02/Jun/20 09:01;rehapav;[~pn508] what is expected from me here?

Agree with EPEX on the change, prioritize and implement.","15/Jul/20 08:41;rehapav;2 questions from EPEX:
 # Will there be change of the values in the TC reports for the attribute 'envText' and 'exchNam'? Compared with the values used currently today for the TC reports in ASIMU.

2. Would it be possible to redirect the old URL at least for a while on the new one with this change?

 

[~matemar] can you please answer these directly?","17/Jul/20 11:43;pn508;[~rehapav] 
1) 'envText' and 'exchNam' is configurable, no change is needed.
2) yes","19/Aug/20 15:43;rehapav;[Steffen Englert|https://app.slack.com/team/U7BU3EE12]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F10.2%2Fgoogle-small%2F1f3e2.png!   
 hey [@Pavel Rehak|https://dbg-devops.slack.com/team/U4FV7JP6V] to sum it up
 need to change the following: * dynamic inventory changes from epex-asim to elts-asim (proper pull-request)
 * re-deployment with the proper application names afterwards.
 * changing DNS Settings by SYSENG (will consult [@Andrei Nazarenko|https://dbg-devops.slack.com/team/U28CM2AEL] for that) they need 15 minutes for that.
 * renaming VM machines.
 * changing DB Schemas Usernames from epex-asim to elts-asim
 * checking if loadbalancers are somehow pointing to real hostnames? (need to contact CCI Team)

quite hard to say how long we need because of the mentioned dependencies. But i would say def. more then a day.
 I would take that topic to the meeting tomorrow and talk about it.
  
 ----New
  
 [<1m|https://dbg-devops.slack.com/archives/G011BGYFMHD/p1597844587075100?thread_ts=1597843886.074800&cid=G011BGYFMHD]
 [Steffen Englert|https://app.slack.com/team/U7BU3EE12]!https://slack-imgs.com/?c=1&o1=gu&url=https%3A%2F%2Fa.slack-edge.com%2Fproduction-standard-emoji-assets%2F10.2%2Fgoogle-small%2F1f3e2.png!   
 maybe i also missed some points, not 100% sure that this is all

 

 
 * setup in parallel a new dedicated env with new VM´s, Firewall-Requests etc..
 * estimation around 4-5 weeks (because the firewall-requests have an SLA of 30days) - in the past we setup a new env in one week with 2 people but as you know we have lots of dependencies with network team, netbackup etc. 
 * and we plan to do it after power maintenance HAU, ebsm decommissioning etc. so more end of the year.","21/Aug/20 10:32;rehapav;Final plan
 # 1/11/2020 request creation of new environment on networks - 8 weeks
 # 1/1/2021 deploy new environment ELTS ASIM
 # 1/2/2022 decomission old one EPEX ASIM",,,,,,,,,,,,,,,,,
M7C Password Policy ATE1 and ATE5,M7P-6154,95788,89589,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,ef759,ef759,18/May/20 10:58,01/Jul/20 11:27,16/Sep/21 14:11,26/Jun/20 12:44,,7tops_sprint9_,,,,,,,,7tops,M7PRODOPS,,,,,,"Set please in LDAP new password policy rules for M7C.
environments: ATE1 and ATE5
Password Rules: 
1. minimum 8 characters (GIS requirement, same rules as in M7T)
2. must fulfil at least 3 of the 4 requirements: 
  - at least one upper case letter
  -  one lower case letter
  -  one number
  -  one special character

3. 5 attempts account lock
4. no password history and no password expiration needed",,ef759,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38620800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxo27:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),Schmetterling Sprint 93 (PS),Schmetterling Sprint 94,Schmetterling Sprint 95 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95788,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/20 12:44;qo288;password policy applied and tested",,,,,,,,,,,,,,,,,,,,,,,,,,,
Check connection between ELTS CTPB and XBID CTPB,M7P-6149,95781,95733,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,jv861,jv861,18/May/20 10:36,21/May/20 10:23,16/Sep/21 14:11,18/May/20 12:25,,7tops_sprint7,,,,,,,,7tops,M7PRODOPS,,,,,,"When ELTS CTPB tries to connect to XBID CTPB, we are getting a connection reset error. Can you please verify if all the proxies between environemtns work as expected?",,cs687,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41990400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxo13:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 92 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95781,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/May/20 12:02;cs687;Ticket will be handled here -> https://jira.deutsche-boerse.com/browse/M7P-6140",,,,,,,,,,,,,,,,,,,,,,,,,,,
h2h4u1 down for m7xrpmsimum7b1 ,M7P-6144,95754,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,15/May/20 11:17,26/Nov/20 17:15,16/Sep/21 14:11,27/May/20 07:48,,6.10.69,7tops Sprint8,,,,,,,M7PRODOPS,minor,,,,,,"Since 13.05.2020 h2h4u is down for m7xrpmsimum7b1
need to investigate and solve the issue. 

CRITICAL on m7xrpmsimum7b1 - h2h4u1 | Application health check status: DOWN",,ax460,cs687,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,OPCOM,,,,,,,,,,,,,,,,41212800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxozr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 93 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95754,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"26/May/20 14:26;ax460;Kibana logs, it was down from 13-15.5. But now it seems to be OK since 15.5.. [~cs687] can you verify?","27/May/20 07:17;cs687;From Health-Check point of view i can confirm it looks like it´s up and running again.  [~ax460] (/)

{code:java}
[tomcat@m7xrpmsimum7b1 ~]$ curl http://localhost:8123/h2h4u/health
{""status"":""UP""}[tomcat@m7xrpmsimum7b1 ~]$
{code}

Will let it confirm from a BO by checking the ComTrader. 
Thanks for reminding!","27/May/20 09:56;wn626;In WebGUI I can see it's connected to XBID, but I cannot login to CT. Error: Network Error: Connection Refused: connect

will create separate ticket for it",,,,,,,,,,,,,,,,,,,,,,,,,
postgreSQL baseline implementation,M7P-6141,95742,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,iO924,iO924,15/May/20 09:28,22/Sep/20 23:40,16/Sep/21 14:11,15/Sep/20 09:48,,6.8.142,,,,Database,,,26/Jun/20 00:00,M7PRODOPS,,,,,,,"Please check if we have implemented our Databases according to the Baseline below.

 
 [https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20baselines/PostgreSQL_Security_Baseline.pdf]
  

Please keep in mind that we have Cybertec as a support company that can as well take care of that and identify our gaps. 

Servers are shared with M7A",,cs687,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"go through the list and answered the open topics. 
Operating part will be double checked by SYSENG.",,,,,,,,,,,,,,,,,,,,,,,,31622400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzn6cv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,see change description,,,,,,,,,,"{""issueId"":95742,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"15/Sep/20 09:00;cs687;Regarding the mentioned pdf-file we come to the following result on production DB-Hosts: 

*3.1 Operating System:*
 * OS01 (/)
 * OS02
 * OS03
 * OS04
 * OS05 (/)
 * OS06 (verified it is not used!) (/)
 * OS07
 * OS08
 * OS09
 * OS10 (/)
 * OS11 (/)
 * OS12 (/)
 * OS13 (/)

 

*3.2 PostgreSQL settings:*
 * PS01 (The default is {{none}}. Only superusers can change this setting.) (/)

 

*3.3 PostgreSQL Versions/Patches*
 * VP01 (/) (version PostgreSQL 11) 

 

*3.4 PostgreSQL Privileges*
 * PP01 (/)
 * PP02 (/) (all of them are written directly in PL/SQL language) 
 * PPO3 (/) (have no security definer functions) 

 

*4 Other PostgreSQL settings*
 * OP01 (/)

 

 ","15/Sep/20 09:42;cs687;Will clone the ticket for SYSENG Team, to go through the Operating System points. 

our part is done","15/Sep/20 09:48;cs687;done

[~iO924] our part is done, 

SYSENG is taking the operating part. ",,,,,,,,,,,,,,,,,,,,,,,,,
EPEXMT CLONE: CTPB and Acute are not connected to XBID,M7P-6140,95733,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Fixed,cs687,nn236,nn236,14/May/20 16:51,21/May/20 10:23,16/Sep/21 14:11,18/May/20 13:53,6.9.111,6.10.51,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"Hello,

Currently M7 is not connected to XBID on CTPB and Acute, this happened after the XBID maintenace on 13/05. We received some feedback from XBID DBAG:

On xbid side the rootCA has been changed.

We received the next information:

Hi Gertjan Brouwer,This is the link:[https://support.sectigo.com/Com_KnowledgeDetailPage?Id=kA01N000000rfBOPlease] be aware that you have to replace the exchanged rootCA with the latest one that can be downloaded on the link, and import it in the LTS truststore.",,cs687,jv861,nn236,,,,,,,,,,,,,,,,,EPEXMT-2637,,,,,,,,,,,,,,,,,,,,"18/May/20 11:56;cs687;seamless_deploy_elts-ctpb.txt;https://jira.deutsche-boerse.com/secure/attachment/83918/seamless_deploy_elts-ctpb.txt",,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,EPEX,,,,,,,,,,,,,,,,41990400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,14/May/20 16:44,M7ADM140/Test0101,[],,,,,,,,,,,M7T,,,,"2|hzxnnz:",9223372036854775807,,,,No,,,,,,,,,,"there were two issues for *elts-ctpb*
First *haproxy xbid ctpb* were not running. Was started by XBID Team. 

Afterwards we received we received an error 
*caused by: java.net.SocketException: Connection reset*

this was fixed with SERVICE-6327
##################################################
for elts-acut we informed epex about it to create a dedicated xbid ticket and check the environment ctpa 

seems like to do endless re-connections https://kibana.energy.svc.dbgcloud.io/goto/fe6b2aa42caa9d647c6734fa788596e7
 ",,,,,,,,Magnificent 7 Sprint 92 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":95733,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/May/20 10:02;nn236;Putting issue into TODO (was put into PROGRESS by mistake, instead of EPEXMT).","18/May/20 10:29;jv861;Two separate issues:
1) ACUT connects to XBID CTPA - We don't get any response from XBID to our LoginReq - seems like XBID is down or not working correctly
2) CTPB connects to XBID CTPB - looks like some network problems, work in progress","18/May/20 11:04;cs687;First impression after checking the environment: 

sob is disconnected - health check: 
{code:java}
[root@m7eltsctpbm7b1 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[root@m7eltsctpbm7b1 ~]#
{code}

after reconnecting it manually in the webgui with deployed username/password: 
{code:java}
.""/><EventMessage timestamp=""2020-05-18T08:45:26.287Z"" value=""Unable to connect: Can not connect to response queue; responseQueueStatus: DISCONNECTED, broadcastQueueStatus: DISCONNECTED""/></EventMessages></SobConnectionStateRprt>
2020-05-18T08:46:17.566Z [Sender] INFO  perf-raw-sender - 2020-05-18 10:46:17.560,SADMIN01,SobConnectionStateReq,6,1589791577560,1589791577560,1589791577563,1589791577563,1589791577563,1589791577563,1589791577563,null,null,1589791577563,1589791577563,1589791577563,1589791577563,null,null,1589791577563,1589791577565,1589791577565,1589791577565,1589791577565,1589791577566,null,null,Y,N,S
{code}

checking the proxy connections: 
from m7eltsctpbm7b1 -> m7shrdexteprx1 (/) its working 
from proxy-host -> target XBID IP (x)

{code:java}
service elts-ctpb-ixe
{
        disable = no
        type = UNLISTED
        socket_type = stream
        protocol = tcp
        wait = no
        redirect = 193.29.80.67 50330
        bind = 0.0.0.0
        port = 55460
        user = nobody
}
[root@m7shrdexteprx1 xinetd.d]# telnet 193.29.80.67 50330
Trying 193.29.80.67...
telnet: connect to address 193.29.80.67: Connection refused
{code}


same for related environments which are also connecting there, in that case epex-fsim 
{code:java}
[root@m7shrdexteprx1 xinetd.d]# grep ""193.29.80.67"" *
elts-ctpb-ixe:        redirect = 193.29.80.67 50330
epex-fsim-ixe:  redirect = 193.29.80.67 50330
[root@m7shrdexteprx1 xinetd.d]# telnet 193.29.80.67 50330
Trying 193.29.80.67...
telnet: connect to address 193.29.80.67: Connection refused
{code}

Checking that with XBID Team. 
Will come back to you [~nn236]


","18/May/20 11:09;cs687;also see that HAPROXY 
https://alerta.energy.svc.dbgcloud.io/#/alert/6abf8606-ad43-4351-b057-b197d6a1a2af

*xbcutsssl1 - xbid - ctpb - sob-haproxy1 is not sending HAProxy data.*

Would recommend that epex should create a xbid-ticket. On our side it seems like well configured. 
[~nn236] please let them know, that xbid-team can work on it. thanks","18/May/20 11:17;cs687;can confirm that elts-acute is working and anyways not connecting to the same env like [~jv861] was writing above as well. 

{code:java}
[root@m7eltsacutm7b1 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[root@m7eltsacutm7b1 ~]#
11:15
{code}
","18/May/20 11:25;cs687;like described above xbid haproxy instance was not running: https://alerta.energy.svc.dbgcloud.io/#/alert/6abf8606-ad43-4351-b057-b197d6a1a2af
[~iv732] started it again and its working now. Trying to re-connect and checking logfiles. 

{code:java}
[root@m7shrdexteprx1 ~]# telnet 193.29.80.67 50330
Trying 193.29.80.67...
Connected to 193.29.80.67.
Escape character is '^]'.
{code}
","18/May/20 11:33;jv861;[~nn236] Regarding CTPB: After Steffen's findings above and fixing Xbid side, now we encountered the certifiacte issue that will be solved by https://jira.deutsche-boerse.com/browse/SERVICE-6327","18/May/20 11:34;cs687;logfiles having entries: *certificate issue: Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: No trusted certificate found* -> thanks for providing [~jv861]
issue will be solved with that deployment: https://jira.deutsche-boerse.com/browse/SERVICE-6327

running a prepared jenkins job with core-version *6.9.87*: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/m7t%20seamless%20backend/

","18/May/20 11:56;cs687;After the deployment its working and connecting to xbid 

Running Master on second host m7eltsctpbm7b2
{code:java}
[root@m7eltsctpbm7b2 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[root@m7eltsctpbm7b2 ~]#
{code}

 [^seamless_deploy_elts-ctpb.txt] ","18/May/20 12:09;cs687;Also deployed it for open environment elts-acut
Running Master on second host m7eltsacutm7b2

{code:java}
[root@m7eltsacutm7b2 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[root@m7eltsacutm7b2 ~]#
{code}
","18/May/20 13:33;cs687;h2h4u is not working, seems like xbid connection is not working properly even its shown up as sob:connected. 
[~jv861] found out endless reconnects:: https://kibana.energy.svc.dbgcloud.io/goto/17bd8599942fb105f362052d1ff1fa59

",,,,,,,,,,,,,,,,,
Secure Energy M7 haproxy installations,M7P-6139,95727,,Task,Resolved,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,rehapav,pd122,pd122,14/May/20 13:29,02/Jun/21 10:44,16/Sep/21 14:11,26/May/21 14:51,,7tops_sprint118,,,,infrastructure,,,,7tops,7tops_comm,DEVOPS,M7PRODOPS,PenetrationTest,S,TLS,Update Energy M7 HAProxy SSL/TLs setup based on 2019 Penetration Test findings,,cs687,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-6732,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,already implemented,,,,,,,,,,,,,,,,,,,,,,,,9676800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5244,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzym87:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,"{""issueId"":95727,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/20 14:20;cs687;||Environment||Done||ticket||
|ELTS CTPB| | |
|ELTS ACUT| | |
|ELTS CUTE| | |
|ELTS LIPA| | |
|ELTS SIMU| | |
|ELTS PROD| | |
|HUPX PROD| | |
|HUPX CUTE| | |
|HUPX ASIM| | |
|HUPX SIMU| | |
|BSP PROD| | |
|BSP CUTE| | |
|BSP ASIM| | |
|BSP SIMU| | |
|PLPX PROD| | |
|PLPX LIPA| | |
|PLPX SIMU| | |
|XRPM PROD| | |
|XRPM LIPA| | |
|XRPM SIMU| | |
|SHRD SHOW| | |
|SHRD DST| | |
|SYS1| | |
|SYS2| done | |
|SYS3| | |","26/May/21 14:51;rehapav;all M7 environments are completed

only waiting for ICSC PROD

ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,,,,
"Full-Pipeline Job add ""def ansibleRun""",M7P-6136,95712,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,,cs687,cs687,14/May/20 09:18,24/Feb/21 11:26,16/Sep/21 14:11,15/Feb/21 14:13,,7tops_sprint111,,,,uknown,,,,M7PRODOPS,,,,,,,"After some changes in our pipeline Job 
* custom_deploy 
* full_deploy 

we end up with such of that error 
{code:java}
java.lang.RuntimeException: Method code too large!
	at groovyjarjarasm.asm.MethodWriter.a(Unknown Source)
	at groovyjarjarasm.asm.ClassWriter.toByteArray(Unknown Source)
	at org.codehaus.groovy.control.CompilationUnit$17.call(CompilationUnit.java:827)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1065)
	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:603)
	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:581)
	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:558)
	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:298)
	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:268)
	at groovy.lang.GroovyShell.parseClass(GroovyShell.java:688)
	at groovy.lang.GroovyShell.parse(GroovyShell.java:700)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.doParse(CpsGroovyShell.java:142)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.reparse(CpsGroovyShell.java:127)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.parseScript(CpsFlowExecution.java:561)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.start(CpsFlowExecution.java:522)
	at org.jenkinsci.plugins.workflow.job.WorkflowRun.run(WorkflowRun.java:331)
	at hudson.model.ResourceController.execute(ResourceController.java:97)
	at hudson.model.Executor.run(Executor.java:428)
1 error
	at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:310)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1085)
	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:603)
	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:581)
	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:558)
	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:298)
	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:268)
	at groovy.lang.GroovyShell.parseClass(GroovyShell.java:688)
	at groovy.lang.GroovyShell.parse(GroovyShell.java:700)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.doParse(CpsGroovyShell.java:142)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.reparse(CpsGroovyShell.java:127)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.parseScript(CpsFlowExecution.java:561)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.start(CpsFlowExecution.java:522)
	at org.jenkinsci.plugins.workflow.job.WorkflowRun.run(WorkflowRun.java:331)
	at hudson.model.ResourceController.execute(ResourceController.java:97)
	at hudson.model.Executor.run(Executor.java:428)
Finished: FAILURE
{code}

the root cause for that is, that we have to many code-lines in the pipeline. 
Thats why we have to shrink it and propose to do it like we did it already for custom_deploy (refer pull-request: 875)
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/875/files

Need to create the *""def ansibleRun""*  and call it in the necessary stages. ",,cs687,cv179,op211,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,See comments.,,,,,,,,,,,,,,,,,,,,,,,,18316800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzymbz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95712,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 09:57;cv179;we should consider to use shared library files (already done somewhere else for the comtrader deployments!)

Also we could abstract the functions a bit more or use a class to carry the different variables instead of passing them over and over again!","15/Feb/21 14:13;op211;Generic issue in Jenkins with existing and known workarounds. Can be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,
Secure Enegy M7 Web servers,M7P-6134,95707,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pd122,pd122,13/May/20 17:19,01/Jun/21 17:15,16/Sep/21 14:11,25/Jan/21 15:57,,6.8.150,7tops_sprint109,,,infrastructure,,,,7tops,7tops_comm,DEVOPS,M7PRODOPS,PenetrationTest,TLS,,Update security setup across all Apache installations to reflect 2019 Penetration Test findings.,,cs687,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,M7P-6555,M7P-6554,M7P-6553,,,,,,SERVICE-6732,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"no need to keep the ticket open. last deployment with PLPX is already planned! 
ticket can be closed",,,,,,,,,,,,,,,,,,,,,,,,20131200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5244,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzy2rz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 14,7tops Sprint 15,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,7tops Sprint 109,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95707,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/20 14:18;cs687;||Environment||Done||ticket||
|ELTS CTPB| | |
|ELTS ACUT| | |
|ELTS CUTE| | |
|ELTS LIPA| | |
|ELTS SIMU| | |
|ELTS PROD| | |
|HUPX PROD| | |
|HUPX CUTE| | |
|HUPX ASIM| | |
|HUPX SIMU| | |
|BSP PROD| | |
|BSP CUTE| YES 03.09.2020 | |
|BSP ASIM| | |
|BSP SIMU| | |
|PLPX PROD| | |
|PLPX LIPA| | |
|PLPX SIMU| | |
|XRPM PROD| | |
|XRPM LIPA| | |
|XRPM SIMU| | |
|SHRD SHOW| | |
|SHRD DST| | |
","25/Jan/21 15:21;cs687;Waiting for M7P-6555
production staging!
{code:java}
/shrd/m7t-elts-prod-app-web1/config/conf.d/m7_intraday.conf:    SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
/shrd/m7t-hupx-prod-app-web1/config/conf.d/m7_intraday.conf:    SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
/shrd/m7t-plpx-prod-app-web1/config/conf.d/m7_intraday.conf:    SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH+aRSA+RC4 EECDH EDH+aRSA RC4 !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4""
/shrd/m7t-xrpm-prod-app-web1/config/conf.d/m7_intraday.conf:    SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
/shrd/m7t-xsop-prod-app-web1/config/conf.d/m7_intraday.conf:    SSLCipherSuite ""EECDH+ECDSA+AESGCM EECDH+aRSA+AESGCM EECDH+ECDSA+SHA384 EECDH+ECDSA+SHA256 EECDH+aRSA+SHA384 EECDH+aRSA+SHA256 EECDH EDH+aRSA !aNULL !eNULL !LOW !3DES !MD5 !EXP !PSK !SRP !DSS !RC4 !SHA1 !SHA256 !SHA384""
{code}

currently we are waiting for plpx-prod and also shrd-prod apache are not done as well 
tomorrow we will finish it with m7c-icsc-prod 

@Pavel Rehak for the next plpx-prod deployment lets think about deploying apache and lets close the ticket. 
","25/Jan/21 15:23;rehapav;TGE PROD planned in https://jira.deutsche-boerse.com/browse/SERVICE-7889

ticket can be closed","25/Jan/21 15:57;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,
Secure Energy mail GW servers,M7P-6133,95706,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,pd122,pd122,13/May/20 17:04,01/Jun/21 17:15,16/Sep/21 14:11,01/Apr/21 10:34,,11.0.0,7tops_sprint114,,,infrastructure,,,,7tops,DEVOPS,M7PRODOPS,PenetrationTest,TLS,,,Update External Energy mail GW servers' SMTP security setup based on 2019 Penetraton Test findings. Forked from M7P-4464.,,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,TLS protocols 1.0/1.1 were disabled on external DB gate and cipher set reduced significantly,,,,,,,,,,,,,,,,,,,,,,,,14688000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5244,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzmww7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95706,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/20 14:27;pd122;need to

1) remove at least these cypers:

TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA
 TLS_RSA_WITH_3DES_EDE_CBC_SHA
 TLS_RSA_WITH_IDEA_CBC_SHA

2) disable TLS1.1 (1.0 if enabled)

3) disable client initiated TLS negotiotion

 

All the above changes to be made on external internet facing mail gate, subject to negotiation with CCI team as they are the system's admins.","27/Oct/20 14:55;pd122;IT change requests 44024233 (protocol change, scheduled for 23/11/2020) and 44024241 (cipher change, scheduled for 1/12/2020) created.","13/Nov/20 12:14;pd122;ITCR cancelled on request by (XBID) product team","20/Jan/21 19:44;pd122;ITCRs 44025633 (limit available TLS protocol versions) scheduled for 23/3/2021 11:00 and 44025635 (limit available ciphers) scheduled for 30/3/2021 11:00 have been created.","30/Mar/21 12:31;pd122;Both changes have been implemented now.",,,,,,,,,,,,,,,,,,,,,,,
Rollout of auditd configuration on linux devices - Production,M7P-6131,95671,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,iO924,iO924,13/May/20 13:56,07/Jul/20 23:40,16/Sep/21 14:11,23/Jun/20 09:01,,6.8.134,7tops_sprint9_,,,,,,05/Jun/20 00:00,7tops_comm,M7PRODOPS,S,,,,,"We will have to roll out the [auditd Configuration|https://github.deutsche-boerse.de/dev/sec.auditd-recommendation] on the following servers in production:

 
-|M7CICSCPRODAMQ1|-
-|M7CICSCPRODAMQ2|-
-|M7CICSCPRODAPP1|-
-|M7CICSCPRODAPP2|-
-|M7ELTSPRODAMQ1|-
-|M7ELTSPRODAMQ2|-
-|M7ELTSPRODM7B1|-
-|M7ELTSPRODM7B2|-
-|M7ELTSPRODM7C1|-
-|M7ELTSPRODM7C2|-
-|M7EPEXPRODAMQ1|-
-|M7EPEXPRODAMQ2|-
-|M7EPEXPRODAMQ3|-
-|M7EPEXPRODM7B1|-
-|M7EPEXPRODM7B2|-
|M7EPEXPRODNET1|
|M7EPEXPRODNET2| 
-|M7FLEXPRODAMQ1|-
-|M7FLEXPRODAMQ2|-
-|M7FLEXPRODM7B1|-
-|M7FLEXPRODM7B2|-
-|M7HUPXPRODAMQ1|-
-|M7HUPXPRODAMQ2|-
-|M7HUPXPRODAMQ3|-
-|M7HUPXPRODM7B1|-
-|M7HUPXPRODM7B2|-
{color:#DE350B}-|M7PPG1|- (?){color}
{color:#DE350B}-|M7PPG2|- (?){color}
{color:#DE350B}-|M7PRODLDAP1|- (?){color}
{color:#DE350B}-|M7PRODLDAP2|- (?){color}
-|M7PRODMAIL1|-
-|M7PRODMAIL2|-
-|M7PRODPDB1|-
-|M7PRODPDB2|-
-|M7PRODPDB3|-
-|M7PRODPDB4|-
-|M7SHRDPRODCTP1|-
-|M7SHRDPRODCTP2|-
-|M7SHRDPRODGLFS1|-
-|M7SHRDPRODGLFS2|-
-|M7SHRDPRODLDP1|-
-|M7SHRDPRODLDP2|-
-|M7SHRDPRODPRX1|-
-|M7SHRDPRODPRX2|-
-|M7SHRDPRODREP1|-
-|M7SHRDPRODREP2|-
-|M7SHRDPRODSSL0|-
-|M7SHRDPRODSSL1|-
-|M7SHRDPRODSSL2|-
-|M7SHRDPRODSSL3|-
-|M7SHRDPRODSSL4|-
-|M7SHRDPRODSSL5|-
-|M7SHRDPRODSSL6|-
-|M7SHRDPRODSSL7|-
-|M7SHRDPRODSSL8|-
-|M7SHRDPRODSSL9|-
-|M7SHRDPRODWEB1|-
-|M7SHRDPRODWEB2|-
-|M7SHRDPRODWEB3|-
-|M7SHRDPRODWEB4|-
-|M7SHRDPRODWEB5|-
-|M7SHRDPRODWEB6|-
-|M7XSOPPRODAMQ1|-
-|M7XSOPPRODAMQ2|-
-|M7XSOPPRODAMQ3|-
-|M7XSOPPRODM7B1|-
-|M7XSOPPRODM7B2|-

 

[https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0823%2F400%5FPublication%2FSecurity%20Policy%20Framework%2F70%5FConcepts&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6&View=%7BC85F9C0B%2D376E%2D4AE7%2D89B7%2DABE540693D5D%7D]

 

Data from github is also attached

Please try to carry this task out during the time window of 28.05.2020-10.06.2020 if possible

 

Best Regards

Michael",,cs687,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 09:03;iO924;sec.auditd-recommendation-master.zip;https://jira.deutsche-boerse.com/secure/attachment/83832/sec.auditd-recommendation-master.zip",,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38880000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxmxz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,7tops Sprint 10,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":95671,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"17/Jun/20 14:12;cs687;Deployed auditd on several hosts: 
* M7XSOPPRODM7B2
* M7SHRDPRODWEB6
* M7SHRDPRODWEB5
* M7SHRDPRODSSL9
* M7SHRDPRODSSL8
* M7SHRDPRODREP2
* M7PRODPDB4
* M7PRODMAIL2
* M7HUPXPRODM7B2
* M7FLEXPRODM7B2
* M7CICSCPRODAPP2
* M7CICSCPRODAMQ2

checking it on monday if the hosts are on-boarded successful. ","19/Jun/20 10:52;cs687;Like discussed with you [~iO924] 
host: M7PRODLDAP2 and M7PRODLDAP1 will not work, they are running with OS-6.7 
for that the parameter write_logs in /etc/audit/auditd.conf is missing and first come with version RH7-family. 

I will skip the installation for this hosts. 
Please share that in the iscp meeting. 

thanks. 


UPDATE:
same for m7ppg1, m7ppg2","19/Jun/20 11:33;cs687;{code:java}
1. According some weird ""git like"" webpage, this ""write_logs"" parameter was not available until ""audit-2.5-7"" version (without guarantee, it is really correct information)
2. ""m7axeerprod*"" hosts are using ""audit-2.4-1"" version as part of ""RHEL7.2"" release, so it could be reason of issue.
3. Mentioned ""m7xsopprodm7b2"" is already upgraded system to ""RHEL7.6"", where ""audit-2.8-4"" is running
4. All ""m7axeerprod*"" hosts (all 4 of them) are planed to be upgraded to ""RHEL7.6"" on June 24th 2020 by Boris. Everything is arranged already.
5. For that reason in point 4. I would propose to wait until the upgrade will be completed and you can run ""audit"" related playbooks afterwords
6. ""m7prodldap*"" host are really running old ""RHEL6.7"" version. I have just spoken with Urban, who is in active process of moving whole ""LDAP"" datas into new ""RHEL7.6"" hosts and then all troublemaking hosts will be decommissioned. So my proposal? Leave it, because in two weeks, it will be out of scope.
{code}

will finish the hosts which are listed above and once m7shrdprodldap1/2 is fully migrated to RH7.6 i will install them as will in separated ticket.
M7PPG1/2 will be skipped and ignored, its the old db-hosts where icsc-prod/epex-prod and xeer-prod is running, for that we will not touch the RH Version and upgrade it. 
The Hosts will be anyways decommissioned soon and the instances above will run on the new database setup m7prodpdb1-4
","19/Jun/20 11:41;iO924;Perfect plan - this ticket can be closed then, if all servers- except m7ppg1/2 and shrdprodldap1/2 - are onboarded. Thank you for the detailled work. ","23/Jun/20 07:35;cs687;Just checked the Report from 22.06.2020 all the on-boarded hosts are included. 
The rest of the host-list will follow. 
","23/Jun/20 07:50;cs687;Deployed auditd to the rest of the hosts: 
* M7XSOPPRODAMQ1
* M7XSOPPRODAMQ2
* M7XSOPPRODAMQ3
* M7XSOPPRODM7B1
* M7SHRDPRODWEB1
* M7SHRDPRODWEB2
* M7SHRDPRODWEB3
* M7SHRDPRODWEB4
* M7SHRDPRODSSL0
* M7SHRDPRODSSL1
* M7SHRDPRODSSL2
* M7SHRDPRODSSL3
* M7SHRDPRODSSL4
* M7SHRDPRODSSL5
* M7SHRDPRODSSL6
* M7SHRDPRODSSL7
* M7SHRDPRODREP1
* M7PRODPDB1
* M7PRODPDB2
* M7PRODPDB3
* M7PRODMAIL1
* M7HUPXPRODAMQ1
* M7HUPXPRODAMQ2
* M7HUPXPRODAMQ3
* M7HUPXPRODM7B1
* M7FLEXPRODM7B1
* M7FLEXPRODAMQ1
* M7CICSCPRODAPP1
* M7CICSCPRODAMQ1
* M7ELTSPRODAMQ1
* M7ELTSPRODAMQ2
* M7ELTSPRODM7B1
* M7ELTSPRODM7B2
* M7ELTSPRODM7C1
* M7ELTSPRODM7C2
* M7EPEXPRODAMQ1
* M7EPEXPRODAMQ2
* M7EPEXPRODAMQ3
* M7EPEXPRODM7B1
* M7EPEXPRODM7B2
* M7SHRDPRODGLFS1
* M7SHRDPRODGLFS2
* M7SHRDPRODLDAP1
* M7SHRDPRODLDAP2
* M7SHRDPRODPRX1
* M7SHRDPRODPRX2
* M7SHRDPRODCTP1
* M7SHRDPRODCTP2
","23/Jun/20 09:01;cs687;M7EPEXPRODNET1 & M7EPEXPRODNET2 
need to be upgraded to the OS Version 7.5/7.6 

afterwards we have to install audidt as well on these machines. 
https://jira.deutsche-boerse.com/browse/M7P-6407","23/Jun/20 09:01;cs687;.",,,,,,,,,,,,,,,,,,,,
Rollout of auditd configuration on linux devices - Simulation,M7P-6130,95670,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,iO924,iO924,13/May/20 13:54,17/Jun/20 11:18,16/Sep/21 14:11,15/Jun/20 16:44,,6.8.133,7tops_sprint8,,,,,,05/Jun/20 00:00,M7PRODOPS,,,,,,,"We will have to roll out the [auditd Configuration|https://github.deutsche-boerse.de/dev/sec.auditd-recommendation] on the following servers in simulation:

-|M7ELTSSIMUAMQ1|-
-|M7ELTSSIMUAMQ2|-
-|M7ELTSSIMUM7B1|-
-|M7ELTSSIMUM7B2|- (/)
-|M7ELTSSIMUM7C1|-
-|M7ELTSSIMUM7C2|- (/)
-|M7EPEXASIMAMQ1|-
-|M7EPEXASIMAMQ2|-
-|M7EPEXASIMM7B1|-
-|M7EPEXASIMM7B2|- (/)
-|M7FLEXSIMUAMQ1|-
-|M7FLEXSIMUAMQ2|-
-|M7FLEXSIMUM7B1|-
-|M7FLEXSIMUM7B2|- (/)
-|M7HUPXASIMAMQ1|-
-|M7HUPXASIMAMQ2|-
-|M7HUPXASIMM7B1|-
-|M7HUPXASIMM7B2|- (/)
-|M7HUPXSIMUAMQ1|-
-|M7HUPXSIMUAMQ2|-
-|M7HUPXSIMUAMQ3|-
-|M7HUPXSIMUM7B1|-
-|M7HUPXSIMUM7B2|- (/)
-|M7PLPXLIPAAMQ1|-
-|M7PLPXLIPAAMQ2|-
-|M7PLPXLIPAM7B1|-
-|M7PLPXLIPAM7B2|-
-|M7PLPXSIMUAMQ1|-
-|M7PLPXSIMUAMQ2|-
-|M7PLPXSIMUM7B1|-
-|M7PLPXSIMUM7B2|- (/)
-|M7SHRDEXTEBHA1|-
-|M7SHRDEXTEBHA2|-
-|M7SHRDEXTEBHA3|-
-|M7SHRDEXTEBHA4|-
-|M7SHRDEXTECTP1|-
-|M7SHRDEXTECTP2|-
-|M7SHRDEXTEPRX1|-
-|M7SHRDEXTEPRX2|-
-|M7SHRDEXTEREP1|-
-|M7SHRDEXTEREP2|-
-|M7SHRDEXTESSL1|-
-|M7SHRDEXTESSL2|-
-|M7SHRDEXTESSL3|-
-|M7SHRDEXTESSL4|-
-|M7SHRDEXTEWEB1|-
-|M7SHRDEXTEWEB2|-
-|M7SHRDSIMUGLFS1|-
-|M7SHRDSIMUGLFS2|-
-|M7SHRDSIMULDP1|-
-|M7SIMUPDB1|-
-|M7SIMUPDB2|-
-|M7SIMUPDB3|-
-|M7SIMUPDB4|-
-|M7XRPMLIPAAMQ1|-
-|M7XRPMLIPAAMQ2|- (/)
-|M7XRPMLIPAAMQ3|-
-|M7XRPMLIPAAMQ4|- (/)
-|M7XRPMLIPAAMQ5|-
-|M7XRPMLIPAAMQ6|- (/)
-|M7XRPMLIPAM7B1|-
-|M7XRPMLIPAM7B2|- (/)
-|M7XRPMSIMUAMQ1|-
-|M7XRPMSIMUAMQ2|- (/)
-|M7XRPMSIMUAMQ3|-
-|M7XRPMSIMUAMQ4|- (/)
-|M7XRPMSIMUAMQ5|-
-|M7XRPMSIMUAMQ6|- (/)
-|M7XRPMSIMUM7B1|-
-|M7XRPMSIMUM7B2|- (/)
-|M7XSOPASIMAMQ1|-
-|M7XSOPASIMAMQ2|-
-|M7XSOPASIMAMQ3|-
-|M7XSOPASIMM7B1|-
-|M7XSOPASIMM7B2|- (/)
-|M7XSOPSIMUAMQ1|-
-|M7XSOPSIMUAMQ2|-
-|M7XSOPSIMUAMQ3|-
-|M7XSOPSIMUM7B1|-
-|M7XSOPSIMUM7B2|- (/)

Please try to carry this task out during the time window of 21.05.2020-03.06.2020 if possible

 [https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0823%2F400%5FPublication%2FSecurity%20Policy%20Framework%2F70%5FConcepts&FolderCTID=0x012000BBD2A4ED70FFBD44AF97DAC0AD2268D6&View=%7BC85F9C0B%2D376E%2D4AE7%2D89B7%2DABE540693D5D%7D]

Best Regards

Michael",,cs687,cv524,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 09:03;iO924;sec.auditd-recommendation-master.zip;https://jira.deutsche-boerse.com/secure/attachment/83833/sec.auditd-recommendation-master.zip",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39571200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxmwn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95670,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"14/May/20 08:23;cs687;Just checked the link - in my opinion we have to do the following steps: (via ansible-playbook) 

*1.)* *copy* the the audit.rules file to /etc/audit/rules.d (https://github.deutsche-boerse.de/dev/sec.auditd-recommendation) 
*2.)* restart service -> service auditd restart
*3.)* changing the file /etc/audisp/*audisp-remote.conf* with the following parameter
* remote_server = siempfralbos.nw.lan
* port = 44514
* transport = tcp
* format = ascii
* network_failure_action = syslog

*4.)* changing the file /etc/audisp/plugins.d/*syslog.conf* with the following parameter
* active = no

*5.)* changing the file /etc/audisp/plugins.d/*au-remote.conf* with the following parameter
* active = yes

*6.)* changing the file /etc/audit/*auditd.conf* with the following parameter
* write_logs = no

*7.)* execute command: semanage port -a -t audit_port_t -p tcp 44514

chapter has to be done: Changes to system files (/etc/pam.d)

Will check that next week with [~cv524]
documentation: https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/Security%20Policy%20Framework/70_Concepts/auditd_implementation_concept.pdf
","18/May/20 16:20;cv524;Some notes already performed earlier
A2AP-87","09/Jun/20 17:07;cs687;Prepared Playbook is already existing in branch auditd
https://github.deutsche-boerse.de/dev/energy.automation.os.install/blob/auditd/roles/os_agents/tasks/auditagent.yml

Will deploy it as test *M7XRPMLIPAAMQ6*

File needed no change so, agent was not restarted. 
Waiting for feedback from Thorsten Gessner to give green light for that host. 
{code:java}
[cs687@enprodauto1 {auditd L | ✔} ~/ansible/energy.automation.os.install]$ ansible-playbook playbooks/os_agents.yml --limit ""m7t*xrpm-simu
-amq6"" --tags audit -k -K -b -C
SSH password:
SUDO password[defaults to SSH password]:
 [WARNING]: While constructing a mapping from
/usr/local/share/energy.automation.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict
key (additional_params). Using last defined value only.


PLAY [all] *******************************************************************************************************************************

TASK [Gathering Facts] *******************************************************************************************************************
ok: [m7t-xrpm-simu-amq6]

TASK [os_agents : Ensure auditd is installed] ********************************************************************************************
ok: [m7t-xrpm-simu-amq6] => (item=['audit', 'audit-libs', 'audispd-plugins'])

TASK [os_agents : Deactivates writing audit logs to syslog] ******************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure commands of the root user are logged] ************************************************************************
changed: [m7t-xrpm-simu-amq6] => (item=/etc/pam.d/system-auth)
changed: [m7t-xrpm-simu-amq6] => (item=/etc/pam.d/password-auth)
changed: [m7t-xrpm-simu-amq6] => (item=/etc/pam.d/sudo)
changed: [m7t-xrpm-simu-amq6] => (item=/etc/pam.d/sudo-i)

TASK [os_agents : copy audit rules to target host] ***************************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure remote server is configured] *********************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure remote server is configured] *********************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure remote server is configured] *********************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure remote server is configured] *********************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Activates the forwarding to a remote destination] **********************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Make sure that auditd logfiles are not stored locally] *****************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set number of files] ***************************************************************************************************
ok: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set size of files] *****************************************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set max log action] ****************************************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set space left action] *************************************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set admin space left action] *******************************************************************************************
changed: [m7t-xrpm-simu-amq6]

TASK [os_agents : Set action mail acct] **************************************************************************************************
ok: [m7t-xrpm-simu-amq6]

TASK [os_agents : Audit service restart in case of modifications] ************************************************************************
skipping: [m7t-xrpm-simu-amq6]

PLAY RECAP *******************************************************************************************************************************
m7t-xrpm-simu-amq6         : ok=17   changed=13   unreachable=0    failed=0
{code}


Thorsten Gessner confirmed its on-boarded successfully!","10/Jun/20 12:22;cs687;Deployed auditd on following hosts *on 10.06.2020*
* m7xrpmlipaamq6
* m7xrpmlipaamq4
* m7xrpmlipaamq2
* m7xrpmsimuamq6
* m7xrpmsimuamq4
* m7xrpmsimuamq2
* m7xsopsimum7b2
* m7xsopasimm7b2
* m7xrpmsimum7b2
* m7xrpmlipam7b2
* m7plpxlipam7b2
* m7plpxsimum7b2
* m7hupxsimum7b2
* m7hupxasimm7b2
* m7flexsimum7b2
* m7epexasimm7b2
* m7eltssimum7c2
* m7eltssimum7b2

Have to check every monday in the excel sheet if the hosts were successfully on-boarded. Will check that with [~iO924] together. 

FYI: 
these hosts are not existing anymore, were renamed to M7PLPX...
{code:java}
|M7TGEXSIMUAMQ1|
|M7TGEXSIMUAMQ2|
|M7TGEXSIMUM7B1|
|M7TGEXSIMUM7B2|
{code}

these hosts are not existing anymore and m7spg1/2 will be decommissioned in few weeks, when icsc is deployed via ansible. 
{code:java}
|M7EPEXSIMUAMQ3|
M7CICSCASIMAMQ1
|M7SPG1|
|M7SPG2|
{code}





","15/Jun/20 10:08;cs687;just checked in the report from today the on-boarded hosts from last week and i can confirm that all the mentioned hosts in the description has auditd successfully on-boarded. 
Will continue with the rest and on-boarded for all the missing hosts and finish the ticket. ",,,,,,,,,,,,,,,,,,,,,,,
Create User Vault entries for ICSC Portal CUTE and PROD,M7P-6126,95622,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ef759,ef759,13/May/20 10:19,21/May/20 10:23,16/Sep/21 14:11,14/May/20 08:53,,7tops_sprint7,,,,,,,,7tops,M7PRODOPS,,,,,,"Create please vault entries for ICSC Portal (CUTE and PROD)
CUTE:
*  Usernames and passwords are already available on m7shrdexteweb1 and m7shrdexteweb2 under /shrd/icsc-cute-cmm-web1/www/php/config.ini (resp /shrd/icsc-cute-cmm-web2/www/php/config.ini) under *rabbitmq_username* and *rabbitmq_password*.
*  Copy them into vault under m7c/icsc/cute/amqp/portal/user1 and m7c/icsc/cute/amqp/portal/user2 
(Same as https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/portal/user1)

PROD: follow the same rules as for CUTE for this hosts:
*  m7shrdprodweb1 - m7shrdprodweb6 (6 hosts)
*  /shrd/icsc-prod-cmm-web(1-6)/www/php/config.ini",,ef759,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxn6n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95622,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 08:36;iu252;CUTE done:
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/cute/amqp/portal/


{noformat}
[iu252@enprodauto1 ~/M7C/prod]$ vault list secret/m7c/icsc/cute/amqp/portal/
Keys
----
user1
user2
[iu252@enprodauto1 ~/M7C/prod]$
{noformat}
","14/May/20 08:52;iu252;PROD done:
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/prod/amqp/portal/


{noformat}
[iu252@enprodauto1 ~/M7C/prod]$ vault list secret/m7c/icsc/prod/amqp/portal/
Keys
----
user1
user2
user3
user4
user5
user6
[iu252@enprodauto1 ~/M7C/prod]$
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,
TESTMAV1 user having too many queues,M7P-6125,95606,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,13/May/20 09:09,21/May/20 10:23,16/Sep/21 14:11,13/May/20 10:36,,6.10.51,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"*HUPX SIMU* RabbitMQ is not in a good shape. All 3 nodes are getting memory alerts one after each other. We also have warnings for too many queues:
{code:java}
User TESTMAV1 has 7570 queues open (out of 8543 in total). Can you please check with HUPX, if this can be changed? {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,HUPX,,,,,,,,,,,,,,,,42422400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxn33:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95606,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"13/May/20 09:13;cs687;Connected to m7testldap1 and increased the passwordRetryCount to ""9""
{code:java}
#RESULT OK
#CONNECTION:ldap://m7testldap1:389
#DATE:2020-05-13T07:00:52:034
dn:uid=TESTMAV1,ou=simu,ou=hupx-app,o=M7,dc=energy,dc=test
changetype:modify
replace:passwordRetryCount
passwordRetryCount:9
{code}

since 13.05.2020 - 09:00:29 he never logged in again. 
Guess its working. ","13/May/20 09:14;dp007;Several emails exchanged:
{code:java}
Hi HUPX market operations,

I hope you are all good and safe.
Please note there is a TESTMAV1 user making troubles to your Simulation environment, specifically to RabbitMQ because it has over 7500 open queues and our alerting system is ringing due to high memory consumption.
Could you please take a look?

Best regards,
Martin
{code}
{code:java}
Hi Martin!
Thanks a lot for the info! 
I will let them now and if they cannot fix it I will suspend the user. 
Best regards,
N.Tomi
{code}
{code:java}
Hi Martin!

I have forwarded them the issue, they will investigate it.
As they don’t need the user currently, I have suspended it and then reactivated again, I hope it closed all queues. 

In case it happens again please let us know. Thank you!

Best regards,
N.Tomi
{code}
{code:java}
Hi Tomi,
Actually this didn’t help, there are still 7577 queues. Could you please stop/restart that API client?
BR,
Martin
{code}
{code:java}
Hi Martin,
I deactivated their Application ID in WebGUI, I assume it should be good now. 
They have forwarded the details to their service provider, it will take a couple of days until they get a feedback. 
Best regards,
N.Tomi
{code}","13/May/20 10:26;cs687;USER in LDAP is blocked: like described in the first comment. 
As *second step* we deleted the current existing queues of the user TESTMAV1 with the following guidline 

https://confluence.energy.svc.dbgcloud.io/display/IO/RabbitMQ+Maintenance+and+troubleshooting#RabbitMQMaintenanceandtroubleshooting-Cleanbandits!

*Please be aware to execute the steps chapter 3.1 & 3.2*

before you can start with -> *3.3.2. Delete all Queues of a user*
connecting to m7hupxsimuamq1 and execute the following command:
{code:java}
grep TESTMAV1 /tmp/amqp-stats/amqp-queues_hupx-simu-amq1 | awk '{print $1}' | while read queue
do
 echo $queue
 /bin/curl -i -XDELETE http://$AMQP_ADMIN_USER:$AMQP_ADMIN_PASS@localhost:52${ERL_EPMD_PORT:2}/api/queues/$AMQP_ADMIN_INST/$queue
done
{code}
","13/May/20 10:35;cs687;User-queues are deleted 
15 pages left. 

ticket will be closed. ",,,,,,,,,,,,,,,,,,,,,,,,
set tomcat_pool_cleanup to true for 6.9 and higher,M7P-6120,95574,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,12/May/20 14:19,14/Jan/21 14:21,16/Sep/21 14:11,26/Aug/20 15:29,,6.10.212,7tops_sprint14,,,ansible,,,,ansible,M7PRODOPS,,,,,,"JDBC parameters of Enquiry module heavily depend on a parameter called _tomcat_pool_cleanup_ which was introduced by ticket M7P-5354 with fix version M7P 6.9.71.

[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/m7tenq/templates/context.xml.j2]

By default it's set to false but some environments set it to true (enabling the jdbc params fix):

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/search?q=tomcat_pool_cleanup&unscoped_q=tomcat_pool_cleanup]

The current approach is wrong and it needs to be rewritten in the following way:
 * all occurrences of _tomcat_pool_cleanup_ must disappear from all env configs (plpx_lipa, xrpm_lipa, xsop_cute, huxp_cute, elts_ctpb, all shrds)
 * the only place it will remain in energy.automation.inventory will be the default [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/vars.yml] - please double check with [~cv179]
 * the variable _tomcat_pool_cleanup_ in energy.automation.deployments will be set to true or false based on the m7p major version (6.9+ => higher; otherwise false) - please ask Roman for guidance if needed.",,ax460,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,troublesome variable tomcat_pool_cleanup removed,,,,,,,,,,,,,,,,,,,,,,,,33264000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmvz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,7tops Sprint 10,7tops Sprint 11,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95574,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"04/Aug/20 11:48;ax460;[~dp007] [~cv179] do we need dynamic value true/false based on version? 

Note we have 6.9 in each prod environment at the moment together with tomcat_pool_cleanup: true

So IMHO we can set default to *true* and remove all overridings of tomcat_pool_cleanup (as suggested above), what do you think?","04/Aug/20 12:17;dp007;In this case I think we don't need that param at all and also the else condition in [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/m7tenq/templates/context.xml.j2] ","26/Aug/20 15:28;dp007;Configuration amended. closing the ticket",,,,,,,,,,,,,,,,,,,,,,,,,
Monitor system resources per process,M7P-6112,95526,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,oy574,oy574,11/May/20 14:35,01/Jul/20 11:27,16/Sep/21 14:11,29/Jun/20 08:50,,6.10.123,7tops_sprint9_,,,,,,,7tops,7tops_comm,M7PRODOPS,MONITORING,,,,"*Motivation*

Occasionally it happens that an application crashes with OOM/cannot create native thread, caused by some other application running on the same host. This is usually caused by a memory leak or different bug in the apps, and we need to get notified about such issues in advance. Also, without this monitoring, it's impossible to create RCA retroactively.

*Acceptance criteria*

For a start, we would want to monitor system resource usage *per (application) process* - that is, we want to know how many threads does MTT use, how many file descriptors does enquiry process have open etc. List of resources (please add more if you think it's useful):
 * -Threads- - [already monitored|https://grafana.energy.svc.dbgcloud.io/d/QdT5584mz/java-application?orgId=2&var-host=All&var-client=elts&var-environment=prod&var-group=All&var-interval=$__auto_interval_interval&var-tomcat=All&var-core_host=&var-instance=coda1&var-instance=enq1&var-instance=enq2&var-instance=h2h4u1&var-instance=h2h4u2&from=1587938400000&to=1588197599000]
 * File Descriptors - including telegraf, filebeat, ...

Also, we would want to collect the host limits - that means both *user* (tomcat) and *system* limits (hard and soft). Based on the ratio of these, we will create alerts (we need to first observe what's the usage right now, but let's start with alert with 90% threshold).",,iu252,oy574,xt853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,Introduced FD-metrics and alerting for tomcat processes.,,,,,,,,,,,,,,,,,,,,,,,,38361600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmwf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95526,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"12/May/20 08:51;xt853;There is solution usable directly from java on Unix/Linux ([ https://stackoverflow.com/questions/16360720/how-to-find-out-number-of-files-currently-open-by-java-application|https://stackoverflow.com/questions/16360720/how-to-find-out-number-of-files-currently-open-by-java-application] ):

using the [{{ManagementFactory}}|http://docs.oracle.com/javase/1.5.0/docs/api/java/lang/management/ManagementFactory.html] to get the [{{OperatingSystemMxBean}}|http://docs.oracle.com/javase/6/docs/api/java/lang/management/OperatingSystemMXBean.html] and if it is a [{{UnixOperatingSystemMXBean}}|http://docs.oracle.com/javase/1.5.0/docs/guide/management/extension/com/sun/management/UnixOperatingSystemMXBean.html], you can use the {{getOpenFileDescriptorCount()}} method","28/May/20 09:33;iu252;The Procstat input plugin provides metrics for FD, but there are few problems with it, it requires root permissions to access necessary system metrics to get relevant data.
We are running telegraf with telegraf user for security reasons.


Looking for other solution.","05/Jun/20 09:35;iu252;With help from [~wm282] und [~pd122] created a shell script which collects FD-metrics:

{noformat}
[root@m7shrdsyt2apa1 sudoers.d]# cat /etc/telegraf/scripts/tele-test.sh
#!/bin/bash
CLIENT=""$1"" ; ENVIRONMENT=""$2"" ; INSTANCE=""$3""
ID=""$CLIENT-$ENVIRONMENT-$INSTANCE""
PIDNUM=$(sudo cat ""/$CLIENT/$ID/tomcat/pid"" 2>/dev/null) || exit 1
printf ""filedescriptors,instance=%s fd=%s\n"" $ID ""$(sudo ls /proc/$PIDNUM/fd | wc -l)""
[root@m7shrdsyt2apa1 sudoers.d]#
{noformat}

Configured telegraf corresponding:

{noformat}
#############################################################################
#   Tomcat Application filedescriptor script                                  #
#############################################################################
[[inputs.exec]]
  commands = [""/etc/telegraf/scripts/tele-test.sh shrd syt2 cor1"",]

  timeout = ""15s""
  data_format = ""influx""
  name_prefix = ""filedescriptor_""

[inputs.exec.tags]
    tomcat = ""m7shrdsyt2apa1_m7core""
    module = ""m7_shrd_syt2""
    product = ""m7t""
    client = ""shrd""
    client_environment = ""syt2""
    host_group_module=""m7shrdsyt2apa1 - tomcat - m7_shrd_syt2""
    instance = ""cor1""
    datacenter = ""hausen""
#############################################################################
#   End of Tomcat Application filedescriptor script                           #
#############################################################################
{noformat}
","05/Jun/20 09:37;iu252;Restarted telegraf and checked the logs:

{noformat}
Jun 05 09:11:15 m7shrdsyt2apa1 telegraf[30536]: 2020-06-05T07:11:15Z I! [inputs.statsd] Started the statsd service on "":8125""
Jun 05 09:11:30 m7shrdsyt2apa1 sudo[30570]: pam_unix(sudo:auth): conversation failed
Jun 05 09:11:30 m7shrdsyt2apa1 sudo[30570]: pam_unix(sudo:auth): auth could not identify password for [telegraf]
Jun 05 09:11:30 m7shrdsyt2apa1 sudo[30570]: pam_succeed_if(sudo:auth): requirement ""uid >= 1000"" not met by user ""telegraf""
Jun 05 09:11:31 m7shrdsyt2apa1 sudo[30570]: telegraf : command not allowed ; TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/bin/cat /shrd/shrd-syt2-cor1/tomcat/pid
Jun 05 09:11:31 m7shrdsyt2apa1 telegraf[30536]: 2020-06-05T07:11:31Z E! [inputs.exec] Error in plugin: exec: exit status 1 for command '/etc/telegraf/scripts/tele-test.sh
{noformat}
","05/Jun/20 09:40;iu252;The issue is that ""telegraf"" account is not allowed to run shell commands, because ""/bin/false"" in shell definition:

{noformat}
[root@m7shrdsyt2apa1 ~]# getent passwd telegraf
telegraf:x:497:497::/etc/telegraf:/bin/false
[root@m7shrdsyt2apa1 ~]#
{noformat}

And ""telegraf"" account does not have identified password, nor ""SSH"" key

{noformat}
[root@m7shrdsyt2apa1 ~]# getent shadow telegraf
telegraf:!!:18205::::::
[root@m7shrdsyt2apa1 ~]# ls -al /etc/telegraf/.ssh
ls: cannot access /etc/telegraf/.ssh: No such file or directory
[root@m7shrdsyt2apa1 ~]#
{noformat}
","05/Jun/20 09:42;iu252;We need to discuss with System Engeneers team if it possible to allow another technical account to execute shell commands with high privileges.
Already contacted [~cv524].","05/Jun/20 11:42;wm282;There is some confusion here.
The above error messages from Telegraf were not interpreted correctly and ""investigation"" went slightly wrong way.
The issue has nothing to do with any passwords or SSH or keys.
Telegraf does not access any remote hosts and no local host is accessed remotely using system 'telegraf' account.
It also has nothing to do with the Shell setting of Telegraf account, because Telegraf can execute child process ( _{{/etc/telegraf/scripts/tele-test.sh}}_ ) without Shell setting in /etc/passwd.
So please forget all of those things, they are irrelevant.

 

The actual problem is that we overlooked the fact that the script has 2 different sudo commands, not just 1 'sudo ls'.
There is also 'sudo cat ...' command, which is failing now and those are the errors you're seeing (sudo asking telegraf for password, because there is no sudo rule for 'cat' command).
The situation is not so good, because the path for the 'cat' command is variable on every server, so 1 sudo rule will not cover it.
Alternative could be to try and see if 'telegraf' account can be made a member of 'tomcat' group, or something like that to allow 'cat' on a file inside '/client/client-env-instance/....'  directory.
Then we won't be needing any sudo rule here and everything would work.

 ","08/Jun/20 11:04;iu252;[~oy574] FDs of tomcat processes are setup on SYT1 and SYT2:
https://chronograf.energy.svc.dbgcloud.io/sources/3/chronograf/data-explorer?query=SELECT%20mean%28%22fd%22%29%20AS%20%22mean_fd%22%20FROM%20%22metrics_m7%22.%22autogen%22.%22filedescriptors%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A%20AND%20%22client%22%3D%27shrd%27%20AND%20%22host%22%3D%27m7shrdsyt1apa1%27%20AND%20%22instance%22%3D%27shrd-syt1-cor1%27%20GROUP%20BY%20time%28%3Ainterval%3A%29%20FILL%28null%29","08/Jun/20 11:26;oy574;Looking fine, thanks! Now what's left is the alerting - that probably requires also collecting the user and system limits, summing the FDs of running processes and comparing it with the limit value. If we exceed some threshold, we should get an alert. Or any other approach that you find suitable - the only requirement is that we want to be alerted before the process crashes because of using too many FDs.","08/Jun/20 11:37;iu252;What exactly do you mean by""user and system Limits""?

To setup alerting we have to know thresholds for warnings/alerts.","08/Jun/20 12:24;oy574;User limit = limit of FDs per process (output of ulimit -a).
 System limit = hard limit of all FDs of all processes of all users (content of /proc/sys/fs/file-max)

Maybe we'll be fine with just checking user limit (as it's unlikely that we cross the system limit, on my computer it's 3.2Mio, so we'll almost certainly hit user limit sooner). And I wrote in the description that I suggest to start with 90% threshold (we can very easily adjust it later on) - so something like 90% warning, 95% error.","08/Jun/20 13:48;iu252;created https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/928and merged after approval.","08/Jun/20 15:23;iu252;Preparation steps before deployment of telegraf:

* add user telegraf to tomcat-group:  usermod -a -G tomcat telegraf
* create telegraf-file in /etc/sudoers.d with following content:
 {noformat}
Defaults:telegraf       !requiretty
telegraf ALL= NOPASSWD: /bin/ls /proc/*
{noformat}
","16/Jun/20 11:35;iu252;Now we also collecting softlimits metrics.","16/Jun/20 12:39;oy574;Great, I can verify that it works! Thanks [~iu252]","16/Jun/20 15:40;iu252;Created PR: https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1192","17/Jun/20 10:50;iu252;Merged https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1192","18/Jun/20 12:05;iu252;We decreased soft- and hardlimit for cor1 on ATE4

{noformat}
[root@m7shrdate4apa1 scripts]# grep tomcat  /etc/security/limits.conf
tomcat  soft    nofile  122
tomcat  hard    nofile  500
[root@m7shrdate4apa1 scripts]#
{noformat}

Restarted cor and we see the warning in slack channel ""m7_alerts"":



{noformat}
11:56

WARNING on m7shrdate4apa1 - m7t - shrd - ate4 - shrd-ate4-cor1 - file descriptors used: 92% -   276/  300 Used/Total
{noformat}
","23/Jun/20 09:52;iu252;Rolled out filedescriptors monitoring on all ATE-environments for cor,enq,mtt2 and h2h4u.

","23/Jun/20 09:53;iu252;[~oy574] from my point of view ticket is solved.","23/Jun/20 09:57;oy574;The data as well as alerts are great, but why to have it only on ATE? The main motivation is obviously prod and customer facing envs","23/Jun/20 10:18;iu252;Of course we can deploy fd-alerting on all environemts.
My suggestion is to start today with customer facing envs and tomorrow with prod. What do you think?
","23/Jun/20 10:47;oy574;Fine by me, I don't think there should be any impact, right?","23/Jun/20 11:11;iu252;I don't expect any impact.","23/Jun/20 11:55;iu252;Introduced file desriptor alerting on all non-prod envs:
* mtt2: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1164/console
* h2h4u: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1163/console
* enq: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1166/console
* cor: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1169/console

Tomorrow we will continue with production.","29/Jun/20 08:41;iu252;Introduced file desriptor alerting on all prod envs:
mtt2: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1177/console
h2h4u: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1179/console
enq: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1181/console
cor: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/1183/console","29/Jun/20 08:42;iu252;I'll close this ticket.","29/Jun/20 08:47;iu252;Checked fd-metrics in Chrohograf for ELTS PROD Cor. Looks good, data is there."
"EPEX TEST ""ungraceful disconnection from XBID""",M7P-6102,95422,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,06/May/20 15:08,18/Nov/20 13:09,16/Sep/21 14:11,19/May/20 11:52,,6.10.51,7tops_sprint7,,,,,,15/May/20 00:00,M7PRODOPS,,,,,,,"{code:java}
Hello DBAG,
As you know we have a new functional improvement in 6.9 which is UNKN state. I discussed internally with the team and we require the help of DBAG in some scenarios:
1.) Ungraceful disconnection between M7 and XBID: DBAG to perform an ungraceful disconnection and EPEX to check the OrdrExeRprt and FullOrdrCaptResp. We will physically stop the proxy.
2.) Reconnection after Ungraceful disconnection: DBAG to restore the connection and EPEX to check the OrdrExeRprt and FullOrdrCaptResp
3.) M7 Failover: Switching from Core 1 to Core 2:  The connection to XBID will be lost for a while.
4.) Another Failover to switch back to Core 1.
When will be a suitable date to perform this test ?
Proposed date: 07/05 11 AM - 12 PM
{code}

Specially for 1 and 2 point we need to test the behavior first in a different environment like elts-cute or something else. need to be arrange with [~wn626]/[~th409]

The current plan is to use iptables on the core machine and deploying it with ansible
something similar like this 
https://github.deutsche-boerse.de/dev/m7.development-scripts/blob/master/stability-tests/block_sob.yml
{code:java}
---
- name: block SOB connection
  hosts: m7tcor
  become: true
  tasks:
    - name: block sob
      shell: ""/sbin/iptables -A INPUT -s {{ item.split(':')[0] }} -j DROP""
      tags: [block]
      loop: ""{{ sob_rabbit_addr.split(',') }}""
    - name: flush iptables
      shell: ""/sbin/iptables -F""
      tags: [flush]
{code}

Will create an ansible-playbook in energy.automation.deployments to have it prepared for future maintenances.",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6201,EPEXMT-2646,,,,M7P-6105,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,41904000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxlxj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95422,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"07/May/20 08:21;cs687;Prepared a pull-request with proper playbook 
{code:java}
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/855/files
{code}

First test without tags:
{code:java}
[cs687@enprodauto1 {M7P-6102 L | ?1} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-elts-cute-* -b -K -k -C --diff
SSH password:
SUDO password[defaults to SSH password]:
PLAY [block SOB connection] *************************************************************************************************************************************************************************************************************************************************************************************************
TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-elts-cute-cor2]
ok: [m7t-elts-cute-cor1]
TASK [block sob] ************************************************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-elts-cute-cor2] => (item=m7shrdexteprx1:55360)
skipping: [m7t-elts-cute-cor1] => (item=m7shrdexteprx1:55360)
TASK [flush iptables] *******************************************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-elts-cute-cor1]
skipping: [m7t-elts-cute-cor2]
PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
m7t-elts-cute-cor1         : ok=1    changed=0    unreachable=0    failed=0
m7t-elts-cute-cor2         : ok=1    changed=0    unreachable=0    failed=0
{code}

","07/May/20 11:24;cs687;Made some Dry-Run test with *elts-cute* before we start with *epex-asim*

*1.) blocking sob-connectivity by executing the playbook*
{code:java}
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-elts-cute-* -b -K -k --tag block
SSH password:
SUDO password[defaults to SSH password]:

PLAY [block SOB connection] ************************************************************************************************************************************************************************************************************************************************************************************************$

TASK [Gathering Facts] *****************************************************************************************************************************************************************************************************************************************************************************************************$
ok: [m7t-elts-cute-cor2]
ok: [m7t-elts-cute-cor1]

TASK [debug] ***************************************************************************************************************************************************************************************************************************************************************************************************************$
ok: [m7t-elts-cute-cor1] => (item=m7shrdexteprx1:55360) => {}

MSG:

/sbin/iptables -A INPUT -s m7shrdexteprx1 -j DROP

ok: [m7t-elts-cute-cor2] => (item=m7shrdexteprx1:55360) => {}

MSG:

/sbin/iptables -A INPUT -s m7shrdexteprx1 -j DROP


TASK [block sob] ***********************************************************************************************************************************************************************************************************************************************************************************************************$
changed: [m7t-elts-cute-cor2] => (item=m7shrdexteprx1:55360)
changed: [m7t-elts-cute-cor1] => (item=m7shrdexteprx1:55360)

PLAY RECAP *****************************************************************************************************************************************************************************************************************************************************************************************************************$
m7t-elts-cute-cor1         : ok=3    changed=1    unreachable=0    failed=0
m7t-elts-cute-cor2         : ok=3    changed=1    unreachable=0    failed=0
{code}

After few seconds we saw a disconnect on the MASTER cor1
{code:java}
tomcat@m7eltscutem7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""
:""UP"",""details"":{""sob"":""DISCONNECTED""}}}}tomcat@m7eltscutem7b1:[/elts]
{code}
[~wn626] confirmed the DISCONNECT on Webgui!

*2.) allowing the connectivity to XBID again by running the ansible-playbook*
{code:java}
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-elts-cute-* -b -K -k --tag flush
SSH password:
SUDO password[defaults to SSH password]:

PLAY [block SOB connection] *************************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-elts-cute-cor2]
ok: [m7t-elts-cute-cor1]

TASK [debug] ****************************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-elts-cute-cor1] => {}

MSG:

/sbin/iptables -F

ok: [m7t-elts-cute-cor2] => {}

MSG:

/sbin/iptables -F


TASK [flush iptables] *******************************************************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-elts-cute-cor2]
changed: [m7t-elts-cute-cor1]

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
m7t-elts-cute-cor1         : ok=3    changed=1    unreachable=0    failed=0
m7t-elts-cute-cor2         : ok=3    changed=1    unreachable=0    failed=0
{code}

After some seconds cor1 connected back to XBID -> [~wn626] also confirmed that by checking it in the WEBGUI

*3.) ungraceful stop of MASTER cor1*
killing cor1 process
{code:java}
tomcat@m7eltscutem7b1:[/elts]$ ps -ef | grep cor1
tomcat   11759     1  3 May04 ?        02:10:03 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/elts/elts-cute-cor1/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webre
sources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Xms1740m -Xmx2320m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+PerfDisableSharedMem -XX:+CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+UnlockDiagnosticVMOptions -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly -
XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:MaxTenuringThreshold=2 -XX:SurvivorRatio=8 -XX:ParGCCardsPerStrideChunk=1024 -XX:+AlwaysPreTouch -Dfile.encoding=UTF-8 -Duser.timezone=CET -Dm7.nodeId=cor1 -Dspring.profiles.active=default,epex,remote-sob,empty-data,env -XX:MaxHeapFreeRatio=85 -XX:+HeapDumpOn
OutOfMemoryError -XX:HeapDumpPath=/elts/logs/heapdump/ -Xloggc:/elts/logs/elts-cute-cor1/m7_elts_cute_cor-1_gc-%p_ixe.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCApplicationStoppedTime -XX:+UseGCLogFileRotation
 -XX:NumberOfGCLogFiles=9 -XX:GCLogFileSize=20M -Dignore.endorsed.dirs= -classpath /elts/elts-cute-cor1/tomcat/bin/bootstrap.jar:/elts/elts-cute-cor1/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/elts/elts-cute-cor1/tomcat -Dcatalina.home=/elts/elts-cute-cor1/tomcat -Djava.io.tmpdir=/elts/temp/elts-cute-cor1 org.apach
e.catalina.startup.Bootstrap start

tomcat@m7eltscutem7b1:[/elts]$ kill -9 11759
-bash: kill: (11759) - No such process
{code}

Short Disconnection and failover to cor2
Afterwards started cor1 as SLAVE again

*4.) ungraceful stop of new MASTER cor2*
{code:java}
atomcat@m7eltscutem7b2:[/elts]$ ps -ef | grep cor2
tomcat   37506     1  0 May04 ?        00:09:02 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/elts/elts-cute-cor2/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Xms1738m -Xmx2318m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+PerfDisableSharedMem -XX:+CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+UnlockDiagnosticVMOptions -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:MaxTenuringThreshold=2 -XX:SurvivorRatio=8 -XX:ParGCCardsPerStrideChunk=1024 -XX:+AlwaysPreTouch -Dfile.encoding=UTF-8 -Duser.timezone=CET -Dm7.nodeId=cor2 -Dspring.profiles.active=default,epex,remote-sob,empty-data,env -XX:MaxHeapFreeRatio=85 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/elts/logs/heapdump/ -Xloggc:/elts/logs/elts-cute-cor2/m7_elts_cute_cor-1_gc-%p_ixe.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationConcurrentTime -XX:+PrintGCApplicationStoppedTime -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=9 -XX:GCLogFileSize=20M -Dignore.endorsed.dirs= -classpath /elts/elts-cute-cor2/tomcat/bin/bootstrap.jar:/elts/elts-cute-cor2/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/elts/elts-cute-cor2/tomcat -Dcatalina.home=/elts/elts-cute-cor2/tomcat -Djava.io.tmpdir=/elts/temp/elts-cute-cor2 org.apache.catalina.startup.Bootstrap start

tomcat@m7eltscutem7b2:[/elts]$ kill -9 37506
{code}

Short Disconnection and failover to cor1 again. 
Starting Cor2 again

TEST finished. 



","07/May/20 13:08;cs687;jan.repcin:  1:02 PM
*EPEX suggested - 13/05 from 2-3 PM

Ticket will be in waiting until wednesday. 

","19/May/20 11:31;cs687;*Test with EPEX on elts-ctpb env*

*1.)* ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-elts-ctpb-* -b -K -k --tag block

*2.)* confirming m7 is not connected to xbid anymore
{code:java}
[root@m7eltsctpbm7b2 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[root@m7eltsctpbm7b2 ~]#
{code}

*3.)* ansible-playbook playbooks/m7_maintenance/block_sob.yml --limit m7t-elts-ctpb-* -b -K -k --tag flush

*4.)* confirming m7 is connected to xbid again - autoconnect was not working ([~wn626] had to connect manually, like in the test elts-cute before) 
{code:java}
[root@m7eltsctpbm7b2 elts-ctpb-cor2]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[root@m7eltsctpbm7b2 elts-ctpb-cor2]#
{code}

*5.)* failover from *cor2* as *MASTER* to *cor1* which is currently running as *SLAVE* by killing the core instance 

before:
{code:java}
[root@m7eltsctpbm7b1 ~]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[root@m7eltsctpbm7b1 ~]#
{code}

afterwards:
{code:java}
tomcat@m7eltsctpbm7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7eltsctpbm7b1:[/elts]$
{code}
starting the core2 again: 
*/elts/elts-ctpb-cor2/tomcat/bin/start.sh*

*6.)* failover from *cor1* as *MASTER* to *cor2* which is running as *SLAVE* after failover
{code:java}
tomcat@m7eltsctpbm7b2:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7eltsctpbm7b2:[/elts]$
{code}
","19/May/20 11:51;cs687;Ticket will be created by EPEX 
some orders were not in a proper state. 

This ticket can be closed. ",,,,,,,,,,,,,,,,,,,,,,,
Sentinel One onboarding,M7P-6098,95377,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,iO924,iO924,06/May/20 08:26,22/Sep/20 23:40,16/Sep/21 14:11,24/Aug/20 12:34,,6.8.142,7tops_sprint13,,,,,,29/May/20 00:00,7tops_comm,M7PRODOPS,,,,,,"Dear Colleagues,

We will need to install the security tool Sentinel one on each Jump Host, Internet facing server and end point.

In case of any questions regarding sentinel one, please contact Alexander Hasenbiller!

Documentation can be found here:

https://mysites.deutsche-boerse.de/personal/np476/Documents/Cyber%20Security%20Defense/Endpoint%20Detection%20and%20Response/SentinelOne/Software/Agents

https://vmcolorado:8443/index.php/SentinelOne#Onboarding_Sentinel_One_Red_Hat_Agent_on_TEST_infrastructure

https://teams.deutsche-boerse.de/sites/sp0823/400_Publication/IS%20IT%20Services/IS%20Tool%20onboarding%20process/SentinelOne%20Onboarding%20Process.pdf

Internet facing server on energy side:

#Done
M7SHRDPRODSSL1
M7SHRDPRODSSL4
M7SHRDPRODSSL9
M7SHRDPRODSSL8
M7SHRDPRODSSL0
M7SHRDPRODSSL7
M7SHRDPRODSSL6
M7SHRDPRODSSL5
M7SHRDPRODSSL3
M7SHRDPRODSSL2
M7SHRDPRODWEB2
M7SHRDPRODWEB3
M7SHRDPRODWEB4
M7SHRDPRODWEB5
M7SHRDPRODWEB6
m7shrdprodprx1
m7shrdprodprx2

M7SHRDEXTEWEB1
M7SHRDEXTEWEB2
M7SHRDEXTESSL1
M7SHRDEXTESSL2
M7SHRDEXTESSL3
M7SHRDEXTESSL4
M7SHRDEXTEPRX1
M7SHRDEXTEPRX2

for testing we will use
m7shrdinteweb1
m7shrdinteweb2",,cs687,iO924,zv517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"installed sentinel_one on the mentioned hosts in the description. 
with ansible playbook 
https://github.deutsche-boerse.de/dev/energy.automation.os.install/blob/master/roles/os_agents/tasks/sentinelone.yml",,,,,,,,,,,,,,,,,,,,,,,,33523200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxi13:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,7tops Sprint 10,7tops Sprint 11,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,7tops Sprint 15,,,,,,,,,,,,,,,,,see change description ,,,,,,,,,,"{""issueId"":95377,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"08/May/20 12:07;cs687;On-board Plan: 

*1.)* preparing playbook and add it to os_install repository os_agents
*2.)* functionality test of the playbook on a low-priority host
*3.)* test SentinelOne Tool on an internet-facing test-hosts and validate the on-boarding process with Alexander Hasenbiller
*4.)* afterwards coordinating the deployments for the Hosts which are mentioned in the description together with [~rehapav]

Which steps are necessary for the on-boarding Process: 
#########################################################
{code:java}
*1.)* creating necessary Firewall-Request (not part of playbook) 
ENERGY-HOST -> sentinel1.deutsche-boerse.de with PORT 443
{code}

{code:java}
*2.)* uploading package to Redhat Satellite (not part of playbook)
{code}

{code:java}
*3.)* import the Root and Intermediate (vault) certificate of our DBAG CA to the operating System *(part of playbook)*
copy root.crt intermediate.crt /usr/local/share/ca-certificates/
update certificates
{code}

{code:java}
*4.)* installing the package from Redhat Satellite *(part of playbook) *
rpm -i package_pathname
yum install package_pathname
{code}

{code:java}
*5.)* Every Agent belongs to a Site of a specific Management Console. If an installed Agent package is not bound to
a specific Site, your Management Console cannot manage the Agent *(part of playbook)*
sudo /opt/sentinelone/bin/sentinelctl management token set site_token <-- site_token from vault 
{code}

{code:java}
*6.)* Activating the agent *(part of playbook)*
sudo /opt/sentinelone/bin/sentinelctl control start
{code}","11/May/20 10:49;cs687;Got the information back from Alexander
{code:java}
Hello Steffen,

We have a test server as well, so you can onboard your clients there to perform some tests. See below for more information. 

Name:    sentinel1-test.deutsche-boerse.de
Address:  172.31.220.239

The packages you can find here: W:\IT-Security\Softs_Repo\SentinelOne\Agents\Linux\4.0.3.11

Best Regards / Mit freundlichen Grüßen / С уважением
Alexander Hazenbiller, CISSP

IT Security Engineer
Group Information Security 
{code}
","11/May/20 12:26;cs687;Waiting until [~cv524] comes back from his vacation to add the rpm-package to RHS. 
In the meanwhile i will prepare the ansible-playbook and also raise for a test-shrd host the firewall-request to test it next week. 

prepared vault setting: 
*secret/global/security_tools/Sentinel_One*
* prod_rootCA
* prod_subCA
* prod_site_token

UPDATE: 
* playbook is prepared
* create FW-Request for m7shrdinteweb1/2 to test the playbook  
*FW504098*

Request: approved by GIS
https://vmt.deutsche-boerse.de/browse/FRM-411
Firewall-Request Status ""Rules implementation"" still waiting. 

Package is available in RHS:
{code:java}
[root@m7shrdinteweb1 ~]# yum info XBID-SentinelAgent.x86_64
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Available Packages
Name        : XBID-SentinelAgent
Arch        : x86_64
Version     : 4.0.3.11
Release     : 1
Size        : 11 M
Repo        : xbid-genoa-rh7.6
Summary     : SentinelOne | Next-Generation Endpoint Protection Software
License     : Proprietary
Description : SentinelOne | Leverage powerful behavior-based threat detection to protect data from the types of advanced malware, exploits and script-based attacks that evade AV and sandboxing solutions.
            :
            :
            :
            :
            :
            :
            :
            : %doc
{code}


*Dry-Run:*
{code:java}
[cs687@enprodauto1 {SentinelOne L | +2 ?1} ~/ansible/energy.automation.os.install]$ ansible-playbook playbooks/os_agents.yml --limit ""m7t*shrd*syt1*app-web2"" --tags sentinelone -k -K -b -C
SSH password:
SUDO password[defaults to SSH password]:
 [WARNING]: While constructing a mapping from /usr/local/share/energy.automation.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict key (additional_params). Using last defined value only.


PLAY [all] ******************************************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-app-web2]

TASK [os_agents : create directory '/usr/local/share/ca-certificates'] ******************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-app-web2]

TASK [os_agents : copy the Root certificate of DBAG CA] *********************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : copy the Intermediate certificate of DBAG CA] *************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : import the certificates] **********************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-syt1-app-web2]

TASK [os_agents : clear yum-cache] ******************************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-syt1-app-web2]

TASK [os_agents : install the sentinel_one from redhat satellite] ***********************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : bound the installed agent to a specific Site] *************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-syt1-app-web2]

TASK [os_agents : activate the installed agent] *****************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-syt1-app-web2]

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
m7t-shrd-syt1-app-web2     : ok=5    changed=3    unreachable=0    failed=0
{code}

","25/May/20 14:51;cs687;Firewall is successful implemented.
Will install it on m7shrdinteweb1&2 tomorrow morning. 

Installed sentinel_one for a dry run on *m7shrdinteweb2*
{code:java}
[cs687@enprodauto1 {SentinelOne L | +2 ?1} ~/ansible/energy.automation.os.install]$ ansible-playbook playbooks/os_agents.yml --limit ""m7t*shrd*syt1*app-web2"" --tags sentinelone -k -K -b
SSH password:
SUDO password[defaults to SSH password]:
 [WARNING]: While constructing a mapping from /usr/local/share/energy.automation.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict key (additional_params). Using last defined value only.
PLAY [all] ******************************************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-app-web2]

TASK [os_agents : create directory '/usr/local/share/ca-certificates'] ******************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-syt1-app-web2]

TASK [os_agents : copy the Root certificate of DBAG CA] *********************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : copy the Intermediate certificate of DBAG CA] *************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : import the certificates] **********************************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : clear yum-cache] ******************************************************************************************************************************************************************************************************************************************************************************************
 [WARNING]: Consider using the yum module rather than running yum.  If you need to use command because yum is insufficient you can add warn=False to this command task or set command_warnings=False in ansible.cfg to get rid of this message.

changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : install the sentinel_one from redhat satellite] ***********************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : bound the installed agent to a specific Site] *************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

TASK [os_agents : activate the installed agent] *****************************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-syt1-app-web2]

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
m7t-shrd-syt1-app-web2     : ok=9    changed=7    unreachable=0    failed=0
{code}

seems like sentinel_one was successful deployed 
{code:java}
[root@m7shrdinteweb2 ~]# systemctl status sentinelone.service
● sentinelone.service - Monitor SentinelOne Agent
   Loaded: loaded (/usr/lib/systemd/system/sentinelone.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2020-05-26 09:38:00 CEST; 3min 55s ago
  Process: 3397 ExecStart=/opt/sentinelone/bin/sentinelctl control run (code=exited, status=0/SUCCESS)
 Main PID: 3405 (s1-agent)
   Status: ""Starting agent...""
   CGroup: /system.slice/sentinelone.service
           ├─3401 s1-orchestrator
           ├─3402 s1-network
           ├─3403 s1-scanner
           ├─3405 s1-agent
           ├─3406 s1-firewall
           ├─3407 s1-fanotify
           └─3408 s1-perf

May 26 09:37:59 m7shrdinteweb2 systemd[1]: Starting Monitor SentinelOne Agent...
May 26 09:38:00 m7shrdinteweb2 systemd[1]: PID file /opt/sentinelone/configuration/agent.pid not readable (yet?) after start.
May 26 09:38:00 m7shrdinteweb2 systemd[1]: sentinelone.service: Supervising process 3405 which is not our child. We'll most likely not notice when it exits.
May 26 09:38:00 m7shrdinteweb2 systemd[1]: Started Monitor SentinelOne Agent.
{code}

Waiting for feedback of the responsible team. 

","26/May/20 10:16;cs687;waiting for final GO to approve it and merge it to MASTER: 
FYI: [~cv524]
https://github.deutsche-boerse.de/dev/energy.automation.os.install/pull/68
","27/May/20 10:19;cs687;M7shrdinteweb1 & M7shrdinteweb2 are successfully on-boarded. 
After on-boarding a full disk scan will be running once, so CPU usage can be a little bit higher then usual!

{code:java}
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
21505 root      20   0  254784  68064  19400 S   6.3  2.3   0:03.60 s1-scanner
{code}

In that case i would trigger that deployment for production in the evening out of business hours. 
Will coordinate it with [~rehapav]

Scan should run roundabout 1-2 hours max. 


UPDATE: 
Created a slack-channel to coordinate the on-boarding process. 

","27/May/20 11:13;cs687;[‎5/‎27/‎2020 11:04 AM]  Alexander Hazenbiller:  
Agent m7shrdinteweb2 completed full disk scan at Wed, 27 May 2020, 08:19:18 UTC. 
Agent m7shrdinteweb1 completed full disk scan at Wed, 27 May 2020, 08:26:15 UTC. 
 
","28/May/20 08:30;cs687;Creating Firewall-Request for the mentioned hosts above: 
ID:  *504323*","02/Jun/20 11:06;cs687;need to upgrade the version from *4.0.3.11* to *4.2.1* before installing it we need to import the pub-key rpm --import /home/cs687/sentinel_one.gpg <-- which is stored in vault as well 
*global/security_tools/Sentinel_One/pub_key*

Waiting until its uploaded to RHS and then i am going to test it again on these two hosts. 

m7shrdintweb2 on-boarded with new version 4.2.1 
Agent m7shrdinteweb2 completed full disk scan at Tue, 02 Jun 2020, 11:49:09 UTC. 

Installed sentinel_one on m7shrdinteweb1 with the ansible-playbook:

{code:java}
[cs687@enprodauto1 {SentinelOne L | +2 ?1} ~/ansible/energy.automation.os.install]$ ansible-playbook playbooks/os_agents.yml --limit ""m7t*shrd*syt1*app-web1"" --tags sentinelone -k -K -b
SSH password:
SUDO password[defaults to SSH password]:

PLAY [all] *************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : create directory '/etc/pki/ca-trust/source/anchors'] *************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : copy the Root certificate of DBAG CA] ****************************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : copy the Intermediate certificate of DBAG CA] ********************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : import the certificates] *****************************************************************************
changed: [m7t-shrd-syt1-app-web1]

TASK [os_agents : copy pub-key to remote-host] *************************************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : import pub-key for Sentinel_One Installation] ********************************************************
ok: [m7t-shrd-syt1-app-web1]

TASK [os_agents : clear yum-cache] *************************************************************************************
 [WARNING]: Consider using the yum module rather than running yum.  If you need to use command because yum is
insufficient you can add warn=False to this command task or set command_warnings=False in ansible.cfg to get rid of
this message.

changed: [m7t-shrd-syt1-app-web1]

TASK [os_agents : install the sentinel_one from redhat satellite] ******************************************************
changed: [m7t-shrd-syt1-app-web1]

TASK [os_agents : delete keyfile] **************************************************************************************
changed: [m7t-shrd-syt1-app-web1]

TASK [os_agents : bound the installed agent to a specific Site] ********************************************************
changed: [m7t-shrd-syt1-app-web1]

TASK [os_agents : activate the installed agent] ************************************************************************
changed: [m7t-shrd-syt1-app-web1]

PLAY RECAP *************************************************************************************************************
m7t-shrd-syt1-app-web1     : ok=12   changed=6    unreachable=0    failed=0
{code}


","04/Jun/20 08:14;cs687;Firewall-Request is successfully implemented - will start with the installation step by step. 
Starting with these servers 
* M7SHRDEXTESSL3
* M7SHRDEXTESSL4

working! confirmed by Security-Team.","08/Jun/20 08:08;cs687;Installing sentinel_one on hosts 
* M7SHRDEXTEPRX1
* M7SHRDEXTESSL2
* M7SHRDEXTESSL1
* M7SHRDEXTEWEB1

also done successfully!","21/Aug/20 10:17;cs687;Installed on 21.8.2020 
* m7shrdprodssl4
* m7shrdprodweb6
* m7shrdprodweb4","24/Aug/20 08:09;cs687;Installed on 24.08.2020
* m7shrdprodweb5
* m7shrdprodssl0
* m7shrdprodssl9
* m7shrdprodssl8
* m7shrdprodssl7
* m7shrdprodssl6
* m7shrdprodssl5
* m7shrdprodssl3
* m7shrdprodssl2
","24/Aug/20 10:39;zv517;installed on 24.08.2020
m7shrdprodssl1 
m7shrdprodweb2
m7shrdprodweb3
m7shrdprodprx1
m7shrdprodprx2","24/Aug/20 12:34;cs687;done",,,,,,,,,,,,,
Configure telegraf on m7shrdsyt1ldr1,M7P-6096,95364,94219,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,xt853,xt853,05/May/20 16:43,21/May/20 10:23,16/Sep/21 14:11,06/May/20 13:17,,7tops_sprint7,,,,,,,,M7PRODOPS,,,,,,,"On the host {{[m7shrdsyt1ldr1.deutsche-boerse.de |http://m7shrdsyt1ldr1.deutsche-boerse.de/]}}there is telegraf installed and running. However its  {{[[inputs.statsd]]}} is not configured, therefore it does not listen on udp port 8125. Please configure this section in similar way as on  _m7shrdsyt1apa1_  and restart telegraf.",,iu252,xt853,,,,,,,,,,,,,,,,M7P-6024,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42940800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxlnb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 90,Magnificent 7 Sprint 91 (US),Magnificent 7 Sprint 92 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95364,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,true,"06/May/20 10:13;iu252;[~xt853] there are some open questions:
* is it java+tomcat app?
* do you need only statsd daemon?
* or also monitoring of application?
* do you want to collect JVM metrics? is application providing health endpoint?
* do you need to collect logs from it?","06/May/20 10:39;xt853;* They are several standalone java apps. They are all manageded by python based scheduler, restarted quite often (some daily, some hourly, some even evety 15 minutes).
 * Yes, we need stastd daemon only. All apps we are interted in are able to report themselves.
 * No monitoring of any app is required.
 * No jvm metrics can be collected now, none of java apps provides jolokia endpoind.
 * Most apps are providing health endpoint, but the port number is random (can be fixed by modifing its config).
 * Log collection is not needed.

In the end we are interested only statsd daemon and that it sends data to influx (similar way as on  _m7shrdsyt1apa1_ )

 ","06/May/20 11:39;iu252;created and merged https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/850.","06/May/20 11:50;iu252;redeployed telegraf:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/975/console","06/May/20 11:53;iu252;statsd is in telegraf config now:


{noformat}
.....
###############################################################################
#                              SERVICE PLUGINS                                #
###############################################################################
# Statsd Server
[[inputs.statsd]]
  ## Protocol, must be ""tcp"", ""udp4"", ""udp6"" or ""udp"" (default=udp)
  protocol = ""udp""
  ## Address and port to host UDP listener on
  service_address = "":8125""
  ## Delete gauges every interval (default=false)
  delete_gauges = false
  ## Delete counters every interval (default=false)
  delete_counters = false
  ## Delete sets every interval (default=false)
  delete_sets = false
  ## Delete timings & histograms every interval (default=true)
  delete_timings = true
  ## Number of timing/histogram values to track per-measurement in the
  ## calculation of percentiles. Raising this limit increases the accuracy
......
{noformat}

telegraf is listening on udp port 8125:

{noformat}
[root@m7shrdsyt1ldr1 telegraf]# netstat -tulpn | grep 8125
udp        0      0 0.0.0.0:8125            0.0.0.0:*                           103782/telegraf
[root@m7shrdsyt1ldr1 telegraf]#
{noformat}

","06/May/20 14:29;xt853;Works nice and smooth, data are in influx/chronograph.",,,,,,,,,,,,,,,,,,,,,,
M7 SLA Report for April 2020,M7P-6087,95322,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,oh856,dp007,dp007,05/May/20 08:21,21/May/20 10:23,16/Sep/21 14:11,13/May/20 09:38,,7tops_sprint7,,,,,,,,M7PRODOPS,SLR,,,,,,"||Environment||Created||Sent||
|M7 EPEX PROD| 2020-05-05| 2020-05-06(Volkan)|
|M7 EPEX FLEX| 2020-05-04| 2020-05-06(Volkan)|
|M7 EPEX ASIM| 2020-05-04| 2020-05-06(Volkan)|
|M7 HUPX| 2020-05-04| 2020-05-06(Volkan)|
|M7 XSOP| 2020-05-04| 2020-05-06(Volkan)|
|M7 TGE| 2020-05-04| 2020-05-06(Volkan)|
|M7 OPCOM| 2020-05-04| 2020-05-06(Volkan)|
|M7 AUCTION| 2020-05-04| 2020-05-06(Volkan)|
|ICS / Swissgrid| 2020-05-04| 2020-05-11(Volkan)|

Link to teams: [https://teams.deutsche-boerse.de/sites/sp0232/SitePages/Home.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F10%20KPI%20%26%20SLA%20Reporting%2F02%29%20Service%20Level%20Reporting%2F2020%2D04&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7B834D681E%2D356F%2D44C7%2D8F3E%2DD393CD59B8F6%7D]

Greenlight requesting email should be sent to:
{code:java}
Denise Schuchter Kratz <denise.schuchter.kratz@deutsche-boerse.com>; Stefanie Naeder <Stefanie.Naeder@deutsche-boerse.com>; Simona Hristova <simona.hristova@deutsche-boerse.com>; Martin Matejka <martin.matejka@deutsche-boerse.com>; Vitalija Kairyte <vitalija.kairyte@deutsche-boerse.com>; Alexander Thorne <alexander.thorne@deutsche-boerse.com>; Iaroslav Kuchugurnyi <iaroslav.kuchugurnyi@deutsche-boerse.com>; Volkan Eymir Akcora <volkan.eymir.akcora@deutsche-boerse.com>; {code}
 

This time don't use the official email template for EPEX PROD but use the following instead:
{code:java}
Dear EPEX,
please find the ELTS PROD SLA report for April. You may note the slight processing time degradation in the system performance slides. I wanted to address the topic here first. You'll notice the change in the metric is correlated to the PatroniDB migration (14.04). To confirm, we are monitoring very closely and we track significant improvement in our persistor performance: M7T's ability to write to database has been drastically improved with our Patroni implementation.  As system bottlenecks have shifted around with the database change however, we are seeing now some changes to processing time related to contract maintenance house keeping tasks. The exact trigger of the event and the correlation with the database change is still under close evaluation.  
We plan to address this change in 6.9 with improvements to these housekeeping tasks. Until then, we are tracking the performance metric change closely, and we see the current performance levels are still within acceptable tolerance and do not expect any further trend of loss of performance, and therefore see no need to address the issue before our next planned release time. {code}",,dp007,oh856,wn626,,,,,,";05/May/20 14:07;wn626;3180",,0,3180,,,0,3180,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43027200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgpj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95322,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/20 11:26;oh856;XSOP report has been generated.

OPCOM report has been generated.

HUPX report has been generated.

EPEX report has been generated(Iaroslav)

FLEX report has been generated.

TGE report has been generated.

M7 AUCTION report has been generated.

ICS / Swissgrid report has been generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide SSL certificates for Portal PROD,M7P-6085,95310,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ef759,ef759,04/May/20 15:16,21/May/20 10:23,16/Sep/21 14:11,14/May/20 11:48,,7tops_sprint7,,,,,,,,7tops,M7PRODOPS,,,,,,"Provide please certificates for ICSC Portal on PROD. Certificates needed for AMQPS communication with HA Proxies.

*IXE*
# M7SHRDPRODWEB1, M7SHRDPRODWEB3, M7SHRDPRODWEB5 apache hosts -> M7SHRDPRODSSL5, M7SHRDPRODSSL7, M7SHRDPRODSSL9 (HA proxies)
*HAU*
# M7SHRDPRODWEB2, M7SHRDPRODWEB4, M7SHRDPRODWEB6 apache hosts -> M7SHRDPRODSSL6, M7SHRDPRODSSL8, M7SHRDPRODSSL0 (HA proxies)",,ef759,iu252,,,,,,,,,,,,,,,,M7P-6137,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxlcf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95310,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/May/20 10:45;iu252;[~cv179] created  csr-file for PROD and requested new Server certificates.
 https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/A.%20Generate%20CSR%20(Ansible%20Deployment)/45/","13/May/20 11:31;iu252;There is another ticket for Server certs: https://jira.deutsche-boerse.com/browse/M7P-5946","14/May/20 08:23;iu252;Created Portal certs from CT-certificate:

{noformat}
[iu252@enprodauto1 ~/M7C/prod]$ openssl pkcs12 -in certificate.p12 -cacerts -nokeys -out ca.pem
Enter Import Password:
MAC verified OK
[iu252@enprodauto1 ~/M7C/prod]$ openssl pkcs12 -in certificate.p12 -nodes -nocerts -out priv.pem
Enter Import Password:
MAC verified OK
[iu252@enprodauto1 ~/M7C/prod]$ openssl pkcs12 -in certificate.p12 -out pub.pem -nodes
Enter Import Password:
MAC verified OK
[iu252@enprodauto1 ~/M7C/prod]$ ll *.pem
-rw-r--r-- 1 iu252 users 4742 May 14 08:21 ca.pem
-rw-r--r-- 1 iu252 users 1828 May 14 08:21 priv.pem
-rw-r--r-- 1 iu252 users 8189 May 14 08:22 pub.pem
[iu252@enprodauto1 ~/M7C/prod]$
{noformat}
","14/May/20 08:27;iu252;Imported certificates into vault:

{noformat}
[iu252@enprodauto1 ~/M7C/prod]$ cat priv.pem | base64 |  vault write /secret/m7c/icsc/prod/portal/cert/priv.pem value=-
Success! Data written to: secret/m7c/icsc/prod/portal/cert/priv.pem
[iu252@enprodauto1 ~/M7C/prod]$ cat pub.pem | base64 |  vault write /secret/m7c/icsc/prod/portal/cert/pub.pem value=-
Success! Data written to: secret/m7c/icsc/prod/portal/cert/pub.pem
[iu252@enprodauto1 ~/M7C/prod]$ cat ca.pem | base64 |  vault write /secret/m7c/icsc/prod/portal/cert/ca.pem value=-
Success! Data written to: secret/m7c/icsc/prod/portal/cert/ca.pem
[iu252@enprodauto1 ~/M7C/prod]$
{noformat}

https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/prod/portal/cert/","14/May/20 08:28;iu252;[~ef759] before installing portal in production we need to check the portal certificates.",,,,,,,,,,,,,,,,,,,,,,,
Provide SSL certificates for Portal CUTE,M7P-6084,95308,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ef759,ef759,04/May/20 15:11,21/May/20 10:23,16/Sep/21 14:11,14/May/20 11:48,,7tops_sprint7,,,,,,,,7tops,M7PRODOPS,,,,,,"Provide please certificates for ICSC Portal on CUTE. Certificates needed for AMQPS communication with HA Proxies.

# M7SHRDEXTEWEB1 apache host -> M7SHRDEXTESSL1, M7SHRDEXTESSL3 (HA proxies)
# M7SHRDEXTEWEB2 apache host -> M7SHRDEXTESSL2, M7SHRDEXTESSL4 (HA proxies)",,ef759,iu252,,,,,,,,,,,,,,,,M7P-6137,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxlbz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95308,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/May/20 13:48;iu252;Server certificates:

{noformat}
sslsrv@m7shrdextessl1:[/shrd/vault/icsc-cute-app-haproxy1]$ openssl x509 -in server.pem -noout -subject -issuer -enddate
subject= /C=DE/postalCode=65760/ST=Hessen/L=Eschborn/street=Mergenthalerallee 61/O=Deutsche Boerse AG/OU=Cash & Derivatives IT Operations/OU=Hosted by Deutsche Borse Aktiengesellschaft/OU=Enterprise SSL Pro/CN=cute1.ics.m7c.deutsche-boerse.com
issuer= /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
notAfter=Jul  9 23:59:59 2020 GMT
sslsrv@m7shrdextessl1:[/shrd/vault/icsc-cute-app-haproxy1]$
{noformat}


{noformat}
sslsrv@m7shrdextessl2:[/shrd/vault/icsc-cute-app-haproxy2]$ openssl x509 -in server.pem -noout -subject -issuer -enddate
subject= /C=DE/postalCode=65760/ST=Hessen/L=Eschborn/street=Mergenthalerallee 61/O=Deutsche Boerse AG/OU=Cash & Derivatives IT Operations/OU=Hosted by Deutsche Borse Aktiengesellschaft/OU=Enterprise SSL Pro/CN=cute2.ics.m7c.deutsche-boerse.com
issuer= /C=GB/ST=Greater Manchester/L=Salford/O=Sectigo Limited/CN=Sectigo RSA Organization Validation Secure Server CA
notAfter=Jun 10 23:59:59 2021 GMT
sslsrv@m7shrdextessl2:[/shrd/vault/icsc-cute-app-haproxy2]$
{noformat}
","11/May/20 10:46;iu252;We will request new Server certificates.

PR created:
https://github.deutsche-boerse.de/dev/energy.automation.certificate/pull/8
Merged.","12/May/20 07:46;iu252;IT-Service Request 5B5856.
Sent mail to ssl-admins.
Waiting for signed certificates.","13/May/20 11:46;iu252;Downloaded signed certificate and imported it into vault:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Certificate%20Deploy/job/B.%20Import%20Cert%20to%20Vault%20(Ansible%20Deployment)/41/console","13/May/20 14:43;iu252;  openssl pkcs12 -in certificate.p12 -out pub.pem -nodes
 
  openssl pkcs12 -in certificate.p12 -nodes -nocerts -out priv.pem
 
 openssl pkcs12 -in certificate.p12 -cacerts -nokeys -out ca.pem

","13/May/20 14:45;iu252;Server certificates are in vault:

{noformat}
[iu252@enprodauto1 ~/M7C/cute]$ vault list secret/m7c/icsc/cute/cert/
Keys
----
....
cute1.ics.m7c.deutsche-boerse.com
cute2.ics.m7c.deutsche-boerse.com
....
sectigo_chain.pem
[iu252@enprodauto1 ~/M7C/cute]$ 
{noformat}



","13/May/20 14:55;iu252;Portal certificates are also in vault:

https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/cute/portal/cert/

{noformat}
[iu252@enprodauto1 ~/M7C/cute]$ cat priv.pem | base64 |  vault write /secret/m7c/icsc/cute/portal/cert/priv.pem value=-
Success! Data written to: secret/m7c/icsc/cute/portal/cert/priv.pem
[iu252@enprodauto1 ~/M7C/cute]$ cat pub.pem | base64 |  vault write /secret/m7c/icsc/cute/portal/cert/pub.pem value=-
Success! Data written to: secret/m7c/icsc/cute/portal/cert/pub.pem
[iu252@enprodauto1 ~/M7C/cute]$ cat ca.pem | base64 |  vault write /secret/m7c/icsc/cute/portal/cert/ca.pem value=-
Success! Data written to: secret/m7c/icsc/cute/portal/cert/ca.pem
{noformat}
","13/May/20 15:00;iu252;[~ef759] we need to test portal certificates.",,,,,,,,,,,,,,,,,,,,
ATE1 ICS Portal CA certificate,M7P-6079,95252,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ef759,ef759,30/Apr/20 14:55,26/May/20 23:39,16/Sep/21 14:11,14/May/20 14:06,,6.8.129,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"Log for ATE1 ICS portal contains this message:
PHP Fatal error:  Call to a member function isConnected() on a non-object in /shrd/shrd-ate1-portal1/www/php/src/Amqp.php on line 11
2020-04-30 14:48:01 ERROR: Disconnecting due to following reason: stream_socket_client(): SSL operation failed with code 1. OpenSSL:
error:14094418:SSL routines:ssl3_read_bytes:tlsv1 *alert unknown ca*

Please check the ca certificate.",,ef759,iu252,,,,,,,,,,,,,,,,M7P-6137,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxgp3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95252,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/20 13:27;iu252;[~ef759] as discussed in slack, it looks like, that configuration of haproxy is not comlete:

{noformat}
[sslsrv@m7shrdintessl1 vault]$ ll shrd-ate5-app-ssl1
total 20
-rw-r----- 1 sslsrv sslsrv 10108 Mar 19 14:59 server.pem
-rw-r----- 1 sslsrv sslsrv  5640 Mar 19 15:00 trustedCAs.pem
[sslsrv@m7shrdintessl1 vault]$ ll shrd-ate1-app-ssl1
ls: cannot access shrd-ate1-app-ssl1: No such file or directory
[sslsrv@m7shrdintessl1 vault]$ ps -ef | grep ate1
sslsrv    8955     1  0  2019 ?        02:07:24 /usr/sbin/haproxy -D -f /shrd/m7-shrd-ate1-apa-ssl1/haproxy.cfg -p /shrd/m7-shrd-ate1-apa-ssl1/haproxy.pid
sslsrv   18450 17977  0 15:27 pts/0    00:00:00 grep --color=auto ate1
[sslsrv@m7shrdintessl1 vault]$ ps -ef | grep ate5
sslsrv   14023     1  0 Apr08 ?        00:08:27 /usr/sbin/haproxy -D -f /shrd/shrd-ate5-app-ssl1/haproxy.cfg -p /shrd/shrd-ate5-app-ssl1/haproxy.pid
sslsrv   19120 17977  0 15:34 pts/0    00:00:00 grep --color=auto ate5
[sslsrv@m7shrdintessl1 vault]$
{noformat}
","06/May/20 13:27;iu252;Created https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate1/cert/trustedCAs.pem","06/May/20 13:28;iu252;Haproxy should be redeployed with ansible.","14/May/20 13:14;ef759;Created new JIRA to solve ICS Portal HA proxy configuration for ansible. Testing of provided certificate for ATE1 will be part of newly created JIRA.
https://jira.deutsche-boerse.com/browse/M7P-6137",,,,,,,,,,,,,,,,,,,,,,,,
Monitoring/Overview of Netbackup´s (Database related) ,M7P-6078,95250,,Task,Refined,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,cs687,cs687,30/Apr/20 14:39,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"today in the morning I received an Alert that our backup-FS is getting bigger and bigger.
After I checked the current backup-situation with the query command, I found out that a FULLBACKUP 
for 29.04 and 25.04 is missing. Also for 26th of April I run somehow twice. 

I checked already some /usr/openenv/netbackup/logs, but I found nothing critical so far.

[root@m7prodpdb1 ~]# /usr/bin/query-ampgsql#eltsprod.sh -p PROD-M7-PGSQL-M7PRODPDB-ELTSPROD | grep ampgsql-data-0
copyId: 1 - 1588104692 - /ampgsql-data-0 - 2020-04-28 22:11:32
copyId: 1 - 1588018376 - /ampgsql-data-0 - 2020-04-27 22:12:56
copyId: 1 - 1587932100 - /ampgsql-data-0 - 2020-04-26 22:15:00
copyId: 1 - 1587852818 - /ampgsql-data-0 - 2020-04-26 00:13:38
copyId: 1 - 1587759482 - /ampgsql-data-0 - 2020-04-24 22:18:02
copyId: 1 - 1587672960 - /ampgsql-data-0 - 2020-04-23 22:16:00
copyId: 1 - 1587586299 - /ampgsql-data-0 - 2020-04-22 22:11:39
copyId: 1 - 1587499855 - /ampgsql-data-0 - 2020-04-21 22:10:55
copyId: 1 - 1587413471 - /ampgsql-data-0 - 2020-04-20 22:11:11
copyId: 1 - 1587327163 - /ampgsql-data-0 - 2020-04-19 22:12:43
copyId: 1 - 1587241015 - /ampgsql-data-0 - 2020-04-18 22:16:55
copyId: 1 - 1587154225 - /ampgsql-data-0 - 2020-04-17 22:10:25
copyId: 1 - 1587067906 - /ampgsql-data-0 - 2020-04-16 22:11:46

For the near Future we need for all our SHRD product environments (M7A/T/C/XBID)
monitoring of our netbackup situation, to avoid such of this behavior. 

This Ticket will be treated as a SHRD-ticket and its not 100% only M7T realted. 
So every Product-Supporter who is interested in it, can also work on it.
",,cs687,sJ194,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39225600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzymdb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95250,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/20 16:01;sJ194;[~cs687] pls discuss this topic with [~yo218] ","16/Jun/20 15:20;cs687;Just got the feedback back from [~yo218]
Niklas just configured the proper Jenkins Job to trigger the fully/incremental backups on our side (client-side) 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/DB-Jobs/

and no monitoring is planned with these job, we have to do it maybe in a different way, maybe [~hw120] can help us out there. 
At least once the Jobs above are failing we will be noticed via email but that should not be the proper solution for the future. 

","18/Jun/20 15:20;cs687;Like we discussed in the weekly meeting 18.09.2020
we agreed as a ""first step"" to monitor the backup behavior like with OPSGenie how it is similar solved with rabbitmq-instances: 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/rabbitmq_instance/templates/prodscripts/rabbitmq/rabbitmq_include#L88

Have to check if we gonna use the m7-proxy or the usal webproxy.
Ticket can be taken as refined. ",,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Automated solution from temporary fix,M7P-6076,95236,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Not a Bug,cs687,wn626,wn626,30/Apr/20 11:55,19/May/20 08:24,16/Sep/21 14:11,05/May/20 08:32,,7tops Sprint6,,,,,,,,M7PRODOPS,,,,,,,"we need to create some automated solution to run following query on ELTS PROD everyday:

select o.order_id, o.external_id, o.mod_type_code, o.action, o.parent_id, o.last_update_time, c.contract_id, c.inactive from CX_210_CONTRACT c join CX_100_ORDER o on c.contract_id = o.contract_id where c.inactive = true and o.mod_type_code <> 'IACT';

and alarm in case of any result. any idea how to do it?",,cs687,cv179,wn626,,,,,,,,,,,,,,,,,M7P-6058,,,,,,,,,,,,,,M7P-6090,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,4.93412156234E11,,,ELTS,,,,,,Report a Critical Incident,,,,,,,,,,43113600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,Communication -> Customer,29/Apr/20 00:16,,[],,,,,,,,,,,M7T,,,,"2|hzxirz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95236,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Apr/20 12:04;cs687;We could trigger that via Jenkins on the Replica-Hosts (m7proddbr1/2) 
{code:java}
m7teltsprodm7b=# select o.order_id, o.external_id, o.mod_type_code, o.action, o.parent_id, o.last_update_time, c.contract_id, c.inactive from CX_210_CONTRACT c join CX_100_ORDER o on c.contract_id = o.contract_id where c.inactive = true and o.mod_type_code <> 'IACT';
 order_id | external_id | mod_type_code | action | parent_id | last_update_time | contract_id | inactive
----------+-------------+---------------+--------+-----------+------------------+-------------+----------
(0 rows)
{code}

As far i know from [~wn626] the query output should be empty, if not we would have an error. 

It would be enough to create afterwards an ticket or send via Jenkins an email when the query would not end up with an empty result. 
Call is not necessary, in case of an not empty result, we would have 5 days to investigate. 

[~cv179] would do you think about ? ","30/Apr/20 12:08;cv179;fully agree! sounds good. jenkins host should even have psql and direct db access. a slack message could be sent to m7_prod_alerts using the token from vault","05/May/20 07:35;cs687;Created the Jenkins Job -> *M7-ELTS-hanging_orders_in_pools_check*
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Scheduled-tasks/job/M7-ELTS-hanging_orders_in_pools_check/

which is executing the sql-command and in case of trouble will send out an email to ""7tops@deutsche-boerse.com""

{code:java}
COUNTER=$(ssh ansible@m7proddbr1 << END_OF_SCRIPT
sudo -u postgres psql -qtA -p 20002 -d m7teltsprodm7b -c ""select o.order_id, o.external_id, o.mod_type_code, o.action, o.parent_id, o.last_update_time, c.contract_id, c.inactive from CX_210_CONTRACT c join CX_100_ORDER o on c.contract_id = o.contract_id where c.inactive = true and o.mod_type_code <> 'IACT'"" | wc -l
END_OF_SCRIPT)
echo ROWS: $COUNTER
[[ ""$COUNTER"" == ""0"" ]] && exit 0 || exit 1
{code}



Output of the executed Job today:
{code:java}
Started by timer
Running as SYSTEM
[EnvInject] - Loading node environment variables.
Building remotely on englobauto1 (englobauto) in workspace /home/jenkins/workspace/Energy-Operations/Scheduled-tasks/M7-ELTS-hanging_orders_in_pools_check
[M7-ELTS-hanging_orders_in_pools_check] $ /bin/sh -xe /tmp/jenkins2045926088218861182.sh
/tmp/jenkins2045926088218861182.sh: line 7: warning: here-document at line 5 delimited by end-of-file (wanted `END_OF_SCRIPT')
++ ssh ansible@m7proddbr1
Pseudo-terminal will not be allocated because stdin is not a terminal.
could not change directory to ""/home/ansible""
+ COUNTER=0
+ echo ROWS: 0
ROWS: 0
+ [[ 0 == \0 ]]
+ exit 0
Finished: SUCCESS
{code}
","05/May/20 08:32;cs687;Slack notification is enabled: 
Alert will be send to channel ""*m7_prod_alerts*"" but only the failed ones 

SUCCESS:
{code:java}
jenkinsAPP  8:08 AM
Energy-Operations » Scheduled-tasks » M7-ELTS-hanging_orders_in_pools_check - #5 Success after 1.4 sec (Open)
{code}

FAILURE:
{code:java}
Energy-Operations » Scheduled-tasks » M7-ELTS-hanging_orders_in_pools_check - #6 Failure after 0.46 sec (Open)
ELTS-PROD Hanging orders in pool!
{code}
","05/May/20 08:32;cs687;done",,,,,,,,,,,,,,,,,,,,,,,
shrink LDAP replication DB on m7prodldap1/2,M7P-6074,95226,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Not a Bug,pd122,pd122,pd122,30/Apr/20 09:56,17/Jun/20 11:18,16/Sep/21 14:11,11/Jun/20 10:24,,7tops_sprint8,,,,infrastructure,,,,7tops,M7PRODOPS,,,,,,"Replication DBs need to be shrank on m7 prodldap1/2 servers.

m7prodldap1:
{code:java}
-rw------- 1 ldap ldap 35G Apr 30 09:53 /var/lib/dirsrv/slapd-m7prodldap1/changelogdb/3a35bc02-15db11e6-a75ceef5-7a20a081_54817f04000000070000.db4{code}
 

 m7prodldap2:
{code:java}
-rw------- 1 ldap ldap 34G Apr 30 09:53 /var/lib/dirsrv/slapd-m7prodldap2/changelogdb/4c175f02-15db11e6-8217e33d-2c4b9a53_54817f04000000070000.db4{code}
 ",,localadmin,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39916800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgpb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95226,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jun/20 10:23;pd122;servers stopped (one by one), changelog db4 file removed and servers started up:
{code:java}
-rw------- 1 ldap ldap 167M Jun 11 10:21 /var/lib/dirsrv/slapd-m7prodldap1/changelogdb/3a35bc02-15db11e6-a75ceef5-7a20a081_54817f04000000070000.db4

-rw------- 1 ldap ldap 836M Jun 11 10:22 /var/lib/dirsrv/slapd-m7prodldap2/changelogdb/4c175f02-15db11e6-8217e33d-2c4b9a53_54817f04000000070000.db4
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Create LoadRunner host for SYT2 SYT3,M7P-6073,95216,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,29/Apr/20 16:11,19/May/21 14:32,16/Sep/21 14:11,18/May/20 08:44,,6.10.27,6.10.64,7tops Sprint6,,,,,,M7PRODOPS,,,,,,,"h2. What ?

Create dedicated Load Runner hosts for SYT2 and SYT3.

We want a duplicate of what was done for SYT1's host ( *m7shrdsyt1ldr1* ), and create m7shrdsyt2ldr1 and m7shrdsyt3ldr1.
h2. Why ?

We want to have the same Load Runner setup for SYT1/SYT2/SYT3. And the same load capabilities.

We want to have Load Runner running on the three of them for :
 * SYT1 : Long running stability tests
 * SYT2 : Testing of issues that would need specific loads
 * SYT3 : Chaos monkey stability tests",,cv524,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,41990400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4645,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgpr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95216,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/20 09:29;cv524;NSR tickets were initiated with request to assign IP addresses and write DNS records
Ticket numbers: 7032300, 7032301

Requested data:
10.139.59.115   m7shrdsyt2ldr1 m7shrdsyt2ldr1.deutsche-boerse.de
10.139.59.114   m7shrdsyt3ldr1 m7shrdsyt3ldr1.deutsche-boerse.de
","30/Apr/20 09:56;iu252;VMs are up and running, but DNS records will be available later.
The VMs have been cloned from SYT1-LDR1","30/Apr/20 10:36;cv524;Both hosts were registered into ""new"" satellite to relevant standard repositories

{noformat}
########################################################################################################
[root@m7shrdsyt2ldr1 tmp]# yum repolist
Loaded plugins: enabled_repos_upload, langpacks, package_upload, product-id, rhnplugin, search-disabled-repos, subscription-manager
This system is not registered with RHN Classic or Red Hat Satellite.
You can use rhn_register to register.
Red Hat Satellite or RHN Classic support will be disabled.
repo id                                                         repo name                                                                                status
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64                  EPEL-7-x86_64                                                                            13,229
!DBG_Energy_Global_XBID-7_XBID-7                                XBID-7                                                                                       43
!rhel-7-server-extras-rpms/x86_64                               Red Hat Enterprise Linux 7 Server - Extras (RPMs)                                         1,275
!rhel-7-server-optional-rpms/x86_64                             Red Hat Enterprise Linux 7 Server - Optional (RPMs)                                      17,914
!rhel-7-server-rpms/x86_64                                      Red Hat Enterprise Linux 7 Server (RPMs)                                                 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64                  Red Hat Satellite Tools 6.6 (for RHEL 7 Server) (RPMs)                                       65
!rhel-server-rhscl-7-rpms/x86_64                                Red Hat Software Collections RPMs for Red Hat Enterprise Linux 7 Server                  11,287
repolist: 68,352
Uploading Enabled Repositories Report
Loaded plugins: langpacks, product-id, rhnplugin, subscription-manager
This system is not registered with RHN Classic or Red Hat Satellite.
You can use rhn_register to register.
Red Hat Satellite or RHN Classic support will be disabled.
[root@m7shrdsyt2ldr1 tmp]#
########################################################################################################
{noformat}
{noformat}
########################################################################################################
[root@m7shrdsyt3ldr1 tmp]# yum repolist
Loaded plugins: enabled_repos_upload, langpacks, package_upload, product-id, rhnplugin, search-disabled-repos, subscription-manager
This system is not registered with RHN Classic or Red Hat Satellite.
You can use rhn_register to register.
Red Hat Satellite or RHN Classic support will be disabled.
repo id                                                         repo name                                                                                status
!DBG_Energy_Global_EPEL-7-x86_64_EPEL-7-x86_64                  EPEL-7-x86_64                                                                            13,229
!DBG_Energy_Global_XBID-7_XBID-7                                XBID-7                                                                                       43
!rhel-7-server-extras-rpms/x86_64                               Red Hat Enterprise Linux 7 Server - Extras (RPMs)                                         1,275
!rhel-7-server-optional-rpms/x86_64                             Red Hat Enterprise Linux 7 Server - Optional (RPMs)                                      17,914
!rhel-7-server-rpms/x86_64                                      Red Hat Enterprise Linux 7 Server (RPMs)                                                 24,539
!rhel-7-server-satellite-tools-6.6-rpms/x86_64                  Red Hat Satellite Tools 6.6 (for RHEL 7 Server) (RPMs)                                       65
!rhel-server-rhscl-7-rpms/x86_64                                Red Hat Software Collections RPMs for Red Hat Enterprise Linux 7 Server                  11,287
repolist: 68,352
Uploading Enabled Repositories Report
Loaded plugins: langpacks, product-id, rhnplugin, subscription-manager
This system is not registered with RHN Classic or Red Hat Satellite.
You can use rhn_register to register.
Red Hat Satellite or RHN Classic support will be disabled.
[root@m7shrdsyt3ldr1 tmp]#
########################################################################################################
{noformat}","04/May/20 10:37;iu252;DNS entries are done:


{noformat}
P:\>nslookup
Default Server:  FRPDC806.oa.pnrad.net
Address:  10.250.0.162

> m7shrdsyt2ldr1
Server:  FRPDC806.oa.pnrad.net
Address:  10.250.0.162

Non-authoritative answer:
Name:    m7shrdsyt2ldr1.deutsche-boerse.de
Address:  10.139.59.115

> m7shrdsyt3ldr1
Server:  FRPDC806.oa.pnrad.net
Address:  10.250.0.162

Non-authoritative answer:
Name:    m7shrdsyt3ldr1.deutsche-boerse.de
Address:  10.139.59.114

> 
{noformat}
","04/May/20 10:40;fj021;Thanks guys, looks good to me.

If we have any issues with them, we can create tickets later on when we start setting them up.

As far as I'm concerned, this ticket can be resolved !","04/May/20 10:51;iu252;[~fj021] to deploy LoadRunner inventory entries are missing. Please create a PR for deployment.
I'll close this ticket.","04/May/20 10:55;fj021;[~iu252] I didn't want to block this ticket with the creation of deployment PR because I know I won't have the free time to do it until next sprint (Wednesday is the end of my ProductionShift). 
But if you don't mind waiting, I don't mind either ! ^^","13/May/20 09:36;iu252;Alex P. has created FW request #504115 (open access for LDRs to SYSTEST environments).","18/May/20 08:44;iu252;Firewall is implementes.
Both connections are working now.


{noformat}
[tomcat@m7shrdsyt2ldr1 ~]$ telnet 10.136.20.12 50800
Trying 10.136.20.12...
Connected to 10.136.20.12.
Escape character is '^]'.
{noformat}

{noformat}
[tomcat@m7shrdsyt3ldr1 ~]$ telnet 10.136.148.25 50900
Trying 10.136.148.25...
Connected to 10.136.148.25.
Escape character is '^]'.
{noformat}
",,,,,,,,,,,,,,,,,,,
CCS onboarding failed,M7P-6061,95155,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,iO924,iO924,29/Apr/20 10:39,21/May/20 10:23,16/Sep/21 14:11,07/May/20 07:58,,6.8.128,7tops_sprint7,,,,,,08/May/20 00:00,7tops_comm,M7PRODOPS,,,,,,"Dear Colleague, 

The CCS onboarding for the following servers have failed:
|M7FLEXSIMUM7B2|
|M7FLEXSIMUM7B1|
|M7FLEXSIMUAMQ2|
|M7FLEXSIMUAMQ1|",,cs687,iO924,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42940800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxi2f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95155,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Apr/20 11:20;cs687;*M7FLEXSIMUM7B1*
{code:java}
[root@m7flexsimum7b1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-
              : disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control
            : Compliance Suite Agent for Linux. FSH
            : modifications on the system are: /opt/esm:
            : distribution tree /etc/rc.d: installation of
            : the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec:
            : software Idtag /esm: symlink
{code}

*M7FLEXSIMUM7B2*
{code:java}
[root@m7flexsimum7b2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-
              : disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control
            : Compliance Suite Agent for Linux. FSH
            : modifications on the system are: /opt/esm:
            : distribution tree /etc/rc.d: installation of
            : the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec:
            : software Idtag /esm: symlink
{code}

*M7FLEXSIMUAMQ1*
{code:java}
[root@m7flexsimuamq1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-
              : disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control
            : Compliance Suite Agent for Linux. FSH
            : modifications on the system are: /opt/esm:
            : distribution tree /etc/rc.d: installation of
            : the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec:
            : software Idtag /esm: symlink
{code}

*M7FLEXSIMUAMQ2*
{code:java}
[root@m7flexsimumamq2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-
              : disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control
            : Compliance Suite Agent for Linux. FSH
            : modifications on the system are: /opt/esm:
            : distribution tree /etc/rc.d: installation of
            : the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec:
            : software Idtag /esm: symlink
{code}

Agent is installed ","30/Apr/20 11:30;cs687;Validation of the registration happened but still with the wrong host-name *m7epexfsim...*

*M7FLEXSIMUAMQ1*
{code:java}
[root@m7flexsimuamq1 ~]# ls -all /opt/esm/system/m7epexfsimamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimamq1/db/agtcert.dat
{code}

*M7FLEXSIMUAMQ2*
{code:java}
[root@m7flexsimuamq2 ~]# ls -all /opt/esm/system/m7epexfsimamq2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimamq2/db/agtcert.dat
{code}

*M7FLEXSIMUM7B1*
{code:java}
[root@m7flexsimum7b1 ~]# ls -all /opt/esm/system/m7epexfsimm7b1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimm7b1/db/agtcert.dat
{code}

*M7FLEXSIMUM7b2*
{code:java}
[root@m7flexsimum7b2 ~]# ls -all /opt/esm/system/m7epexfsimm7b2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimm7b2/db/agtcert.da
{code}

","30/Apr/20 12:27;cs687;would rather re-register the agents for these machines:

{code:java}
[root@host~]# cp /opt/esm/system/host/db/agtcert.dat /tmp
[root@host~]# rm -rf /opt/esm/system/host/db/agtcert.dat
[root@host~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

will contact the @Symantec CCS Contacts Team for that. ","06/May/20 11:19;cs687;Informed the necessary Team about it - will wait for Response 
{code:java}
Hi Symantec CCS-Team, 

in our reports we saw that the following Hosts are not onboarded with CCS
•	M7FLEXSIMUAMQ1
•	M7FLEXSIMUAMQ2
•	M7FLEXSIMUM7B1
•	M7FLEXSIMUM7B2

At least the package is installed and last activation was in Jul 2018, maybe it got somehow expired.

M7FLEXSIMUAMQ1
[root@m7flexsimuamq1 ~]# ls -all /opt/esm/system/m7epexfsimamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimamq1/db/agtcert.dat
M7FLEXSIMUAMQ2
[root@m7flexsimuamq2 ~]# ls -all /opt/esm/system/m7epexfsimamq2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimamq2/db/agtcert.dat
M7FLEXSIMUM7B1
[root@m7flexsimum7b1 ~]# ls -all /opt/esm/system/m7epexfsimm7b1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimm7b1/db/agtcert.dat
M7FLEXSIMUM7b2
[root@m7flexsimum7b2 ~]# ls -all /opt/esm/system/m7epexfsimm7b2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jul 31  2018 /opt/esm/system/m7epexfsimm7b2/db/agtcert.da

I would suggest to re-register CCS. Should I re-register it with a special Collector-Node, or just run blindly the re-register.sh script? 

Please let me know. 

Thanks in Advance!
Cheers,
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43

E-Mail  steffen.englert@deutsche-boerse.com
http://www.deutsche-boerse.com
{code}
","06/May/20 13:16;cs687;saved old registration file:
{code:java}
[cs687@enprodauto1 {introduce-stalker-deployment-scripts L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-amq1:m7t-flex-simu-amq2:m7t-flex-simu-cor1:m7t-flex-simu-cor2' -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-amq1 | SUCCESS | rc=0 >>
m7t-flex-simu-amq2 | SUCCESS | rc=0 >>
m7t-flex-simu-cor2 | SUCCESS | rc=0 >>
m7t-flex-simu-cor1 | SUCCESS | rc=0 >>
{code}

deleted the current one:
{code:java}
[cs687@enprodauto1 {introduce-stalker-deployment-scripts L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-amq1:m7t-flex-simu-amq2:m7t-flex-simu-cor1:m7t-flex-simu-cor2' -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-cor2 | SUCCESS | rc=0 >>
m7t-flex-simu-cor1 | SUCCESS | rc=0 >>
m7t-flex-simu-amq2 | SUCCESS | rc=0 >>
m7t-flex-simu-amq1 | SUCCESS | rc=0 >>
{code}

and re-register ccs agent: 
{code:java}
[cs687@enprodauto1 {introduce-stalker-deployment-scripts L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-amq1:m7t-flex-simu-amq2:m7t-flex-simu-cor1:m7t-flex-simu-cor2' -m shell -b -a ""/opt/esm/re-register.sh"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... failed.
Registering to 10.250.132.149... failed.
Registering to 10.254.232.113... failed.
Registering to 10.90.28.123... failed.
Registering to 10.139.65.121... failed.
Registering to 172.31.120.253... failed.

m7t-flex-simu-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... failed.
Registering to 10.250.132.149... failed.
Registering to 10.254.232.113... failed.
Registering to 10.90.28.123... failed.
Registering to 10.139.65.121... failed.
Registering to 172.31.120.253... failed.

m7t-flex-simu-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... failed.
Registering to 10.250.132.149... failed.
Registering to 10.254.232.113... failed.
Registering to 10.90.28.123... failed.
Registering to 10.139.65.121... failed.
Registering to 172.31.120.253... failed.

m7t-flex-simu-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... failed.
Registering to 10.250.132.149... failed.
Registering to 10.254.232.113... failed.
Registering to 10.90.28.123... failed.
Registering to 10.139.65.121... failed.
Registering to 172.31.120.253... failed.
{code}

seems like it is an firewall-issue.
need to open an firewall-request! 
","06/May/20 15:24;cs687;#############################################################################
[root@m7flexsimum7b1 ~]# */opt/esm/bin/lnx-x64/register -m 10.129.119.254 -p 5600 -E -v -u*
[58244] register: Args List: -m 10.129.119.254 -p 5600 -E -v -u
[58244] register: Agent registration starting ......
[58244] register: Registering to Manager:       10.129.119.254
      registering agent information
[58244] register: Registering agent information
[58244] [2020/05/06 15:16:40:330] register: Error connecting to local ESM service. Check if the agent service is up and running.
    loading agent information
[58244] register: Passing the IP address [10.139.59.40] to the assetinfo for the OS asset.
[58244] register: manager successfully validated agent XML
{color:red}[58244] register: Successfully created asset xml for agent m7flexsimum7b1{color}

[root@m7flexsimum7b1 ~]# ls -all /opt/esm/system/*m7epexfsimm7b1*/
total 40
drwxrwx--- 5 root root 4096 Jul  5  2019 .
drwxrwx--- 4 root root 4096 Jul 31  2018 ..
-rw------- 1 root root  361 Jul 31  2018 assetinfo.log
-r--r----- 1 root root 6239 Nov 23  2016 ccsmod_Install.log
drwxrwx--- 2 root root 4096 May  6 13:08 db
-rw-rw---- 1 root root    0 Jul  5  2019 esmd.err
-rw-rw---- 1 root root  340 Jul  5  2019 esmd.log
-rw------- 1 root root  187 Jul 31  2018 EsmSybaseConfig.log
drwxrwx--- 2 root root 4096 Nov 23  2016 reports
drwxrwx--- 2 root root 4096 Jul 31  2018 tmp
[root@m7flexsimum7b1 ~]#

*Seems like it was deployed with an different hostname in the past!*

[root@m7flexsimum7b1 ~]# /opt/esm/bin/lnx-x64/register -m 10.129.119.254 -p 5600 -E -v -u
*The agent registration cannot continue as the hostname of the agent computer is different than the name that appears in the ESM installation directory at #esm/system/. For a successful agent registration and policy runs, update the hostname or the #esm/system/ directory name.*

Just changed it and run it for all 4 hosts, could be please check it on your side as well. 

Waiting for confirmation from the Symantec Team. ","07/May/20 07:58;cs687;Dedicated Team confirmed that everything is onboarded.

{code:java}
Hello,

The hosts are now in CCS.


Kind regards,
Matic Lukas
Security Linux & PKI (INH)
Phone: +420 29 64-2 80 25
Email: matic.lukas@deutsche-boerse.com
Deutsche Boerse Group
{code}
",,,,,,,,,,,,,,,,,,,,,
Rapid 7 Onboarding failed,M7P-6060,95154,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,iO924,iO924,29/Apr/20 10:38,21/May/20 10:23,16/Sep/21 14:11,07/May/20 11:42,,6.8.128,7tops_sprint7,,,,,,08/May/20 00:00,7tops_comm,M7A,M7PRODOPS,RiskAssessment,,,,"The onboarding of Rapid7 has failed for the following servers:
-|M7EPEXSIMUAMQ3|-
-|M7TGEXSIMUAMQ1|-
-|M7TGEXSIMUAMQ2|-
-|M7TGEXSIMUM7B1|-
-|M7TGEXSIMUM7B2|-
|M7SIMUPDB1|
|M7SIMUPDB2|
|M7SIMUPDB3|
|M7SIMUPDB4|
",,cs687,iO924,rl336,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42940800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxi27:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95154,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"29/Apr/20 12:58;cs687;M7TGEXSIMUAMQ1
M7TGEXSIMUAMQ2
M7TGEXSIMUM7B1
M7TGEXSIMUM7B2

These Hosts should be renamed 
{code:java}
hey @here
just checking the current status of onboarded hosts and found out that these hosts are still listed.
We agree on it that these hosts can be decommissioned or?
M7TGEXSIMUAMQ1
M7TGEXSIMUAMQ2
M7TGEXSIMUM7B1
M7TGEXSIMUM7B2

tobias.jordan  11:11 AM
Yes, old customer name TGEX . Has been changed to PLPX later
{code}

M7EPEXSIMUAMQ3

this host is also not available anymore, EPEXSIMU is also decommissioned. 
In that case we have to check the decommissioning process, not that we have some gaps there and it was not fully finalized. 
","29/Apr/20 13:17;rl336;also valid for M7A","06/May/20 12:34;cs687;seems like we need an NSR-Deletion Request: 
IPs and DNS record is still available - VMS are not in ESX Cluster anymore. 

{code:java}
[cs687@enprodauto1 ~]$ nslookup m7tgexsimuamq1
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   m7tgexsimuamq1.deutsche-boerse.de
Address: 10.139.59.97

[cs687@enprodauto1 ~]$ nslookup m7tgexsimuamq2
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   m7tgexsimuamq2.deutsche-boerse.de
Address: 10.139.59.96

[cs687@enprodauto1 ~]$ nslookup m7tgexsimum7b1
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   m7tgexsimum7b1.deutsche-boerse.de
Address: 10.139.59.95

[cs687@enprodauto1 ~]$ nslookup m7tgexsimum7b2
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   m7tgexsimum7b2.deutsche-boerse.de
Address: 10.139.59.94

[cs687@enprodauto1 ~]$ nslookup m7epexsimuamq3
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
Name:   m7epexsimuamq3.deutsche-boerse.de
Address: 10.139.59.63
{code}

*Created an NSR-Request with the Number#:* 
Request 7032360 successfully created!

TO: In CMS the hosts are also tagged as *installed* have to be changed as well. 
Contacted  Artur Tkaczyk EXT, he will set the hosts in cms to ""be decommissioned""","06/May/20 14:00;cs687;For the Rapid7 deployment we need to run the playbook os_agent with the proper tag:
https://github.deutsche-boerse.de/dev/energy.automation.os.install/blob/master/roles/os_agents/tasks/rapid7agent.yml

This part seems already be done in the past, just checked all the mentioned hosts and user is existing on all hosts. 

{code:java}
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-pdb-async*' -m shell -b -a ""cat /etc/passwd | grep scanmgr"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-pdb-async2 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async4 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async3 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async1 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash
{code}

Afterwards we need also to run the playbook os_authentication so that it picks up that new user and adds it to sshd_conf and the key to ""authorized_keys"" 
https://github.deutsche-boerse.de/dev/energy.automation.os.install/tree/master/roles/os_authentication

Also these steps are already done:
{code:java}
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-pdb-async*' -m shell -b -a ""cat /etc/ssh/sshd_config | grep scanmgr"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-pdb-async3 | SUCCESS | rc=0 >>
Match User ansible,bbrother,globmon,postgres,scanmgr

m7t-flex-simu-pdb-async2 | SUCCESS | rc=0 >>
Match User ansible,bbrother,globmon,postgres,scanmgr

m7t-flex-simu-pdb-async4 | SUCCESS | rc=0 >>
Match User ansible,bbrother,globmon,postgres,scanmgr

m7t-flex-simu-pdb-async1 | SUCCESS | rc=0 >>
Match User ansible,bbrother,globmon,postgres,scanmgr
{code}

checked it on all 4 hosts:
{code:java}
cat /home/scanmgr/.ssh/authorized_keys | grep KEY 
{code}


Informed the Team about it to check the server-side. 

{code:java}
Hi Jeremy,

.....

Back to my question, we have 4 Hosts which are tagged as not on-boarded for “rapid7”.
•	M7SIMUPDB1
•	M7SIMIUPDB2
•	M7SIMUPDB3
•	M7SIMUPDB4

Actually I checked all the necessary stuff and find no issues on our side.
1.) User scanmgr is available on the hosts: 
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-flex-simu-pdb-async*' -m shell -b -a ""cat /etc/passwd | grep scanmgr"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-flex-simu-pdb-async2 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async4 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async3 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

m7t-flex-simu-pdb-async1 | SUCCESS | rc=0 >>
scanmgr:x:20399:532:Nexpose Rapid7 automatic scan user:/home/scanmgr:/bin/bash

2.) the necessary key is also in authorized_keys 
cat /home/scanmgr/.ssh/authorized_keys | grep KEY 

when I am checking the log /var/log/secure I find nothing related to the user “scanmgr”. (for all 4 hosts) 

[root@m7simupdb4 ~]# cat /var/log/secure | grep scanmgr
[root@m7simupdb4 ~]#


Can you maybe have a look on the server side, or at least give me some tip where else I can have a look. 

Thanks in Advance!
Cheers, 
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43
{code}
","07/May/20 11:42;cs687;Issue was more on server-side. Ticket can be closed should be visible in the report by next week. 

{code:java}
Hi Steffen,

Yes I’m the right contact for Rapid7 onboarding verification.

In fact, after checking those servers were not part of the scanning schedule so I just added them. They should be scanned this week-end so we can have a look on early next week.

Regards,

Molinaro Jérémy
IS Engineering

Group Information Security	
{code}
",,,,,,,,,,,,,,,,,,,,,,,
SIEM onboarding failed,M7P-6059,95152,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,iO924,iO924,29/Apr/20 10:36,21/May/20 10:23,16/Sep/21 14:11,11/May/20 07:29,,6.8.128,7tops_sprint7,,,,,,08/May/20 00:00,7tops_comm,M7A,M7PRODOPS,RiskAssessment,,,,"Dear Colleagues,

 

The onboarding for SIEM failed for the following hosts:
|M7SHRDPRODREP2|
|M7SHRDPRODREP1|
-|M7SHRDEXTEREP1|-
-|M7SHRDEXTEREP2|-
-|M7EPEXSIMUAMQ3|-
-|M7TGEXSIMUAMQ1|-
-|M7TGEXSIMUAMQ2|-
-|M7TGEXSIMUM7B1|-
-|M7TGEXSIMUM7B2|-",,cs687,iO924,rehapav,rl336,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/May/20 06:42;cs687;Deploy_m7shrdexterep2.txt;https://jira.deutsche-boerse.com/secure/attachment/83634/Deploy_m7shrdexterep2.txt",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42595200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxi1z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95152,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"29/Apr/20 12:54;cs687;M7TGEXSIMUAMQ1
M7TGEXSIMUAMQ2
M7TGEXSIMUM7B1
M7TGEXSIMUM7B2

These Hosts should be renamed 
{code:java}
hey @here
just checking the current status of onboarded hosts and found out that these hosts are still listed.
We agree on it that these hosts can be decommissioned or?
M7TGEXSIMUAMQ1
M7TGEXSIMUAMQ2
M7TGEXSIMUM7B1
M7TGEXSIMUM7B2

tobias.jordan  11:11 AM
Yes, old customer name TGEX . Has been changed to PLPX later
{code}

M7EPEXSIMUAMQ3

this host is also not available anymore, EPEXSIMU is also decommissioned. 
In that case we have to check the decommissioning process, not that we have some gaps there and it was not fully finalized. 

solved in ticket: -> https://jira.deutsche-boerse.com/browse/M7P-6060","29/Apr/20 13:15;rl336;Servers are also valid for M7A","07/May/20 13:35;cs687;Unfortunately SIEM is not on-boarded on the mentioned reporting-hosts above. 

{code:java}
[cs687@enprodauto1 {M7P-6102 L | ✔} ~/ansible/energy.automation.deployments]$ ansible 'm7t-elts-prod-rep1:m7t-elts-prod-rep2:m7t-elts-simu-rep1:m7t-elts-simu-rep2' -m shell -b -a ""ls -all /etc/rsyslog.d/siem.conf"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-elts-simu-rep2 | FAILED | rc=2 >>
ls: cannot access /etc/rsyslog.d/siem.conf: No such file or directorynon-zero return code

m7t-elts-simu-rep1 | FAILED | rc=2 >>
ls: cannot access /etc/rsyslog.d/siem.conf: No such file or directorynon-zero return code

m7t-elts-prod-rep1 | FAILED | rc=2 >>
ls: cannot access /etc/rsyslog.d/siem.conf: No such file or directorynon-zero return code

m7t-elts-prod-rep2 | FAILED | rc=2 >>
ls: cannot access /etc/rsyslog.d/siem.conf: No such file or directorynon-zero return code
{code}

Will handle an appointment with [~rehapav]
{code:java}
Hi Pavel may i disturb you?
we need to install SIEM security tool on our Reporting hosts (simu/prod)
https://jira.deutsche-boerse.com/browse/M7P-6059
https://csansp01.deutsche-boerse.de/dev/my342/sectools/#
m7shrdexterep1
m7shrdexterep2
m7shrdprodrep1
m7shrdprodrep2
its nothing special about it, it will be deployed via ansible, just copying a ""conf-file"" to the proper directory and restart ""Rsyslog"" agent.
Rsyslog is a powerful, secure and high-performance log processing system which accepts data from different types of source (systems/applications) and outputs it into multiple formats.
Can i handle that somehow, at least for simulation? On monday we would see if the tool is successful onboarded and we could continue with prod?
{code}

","07/May/20 13:51;rehapav;Approved for SIMU 7/5

to be continued with PROD on 11/5 in case of no issues","08/May/20 06:46;cs687;Deployment: *m7shrdexterep2*:
 [^Deploy_m7shrdexterep2.txt] 

{color:red}Before the deployment: {color}
*1.) no conf file was existing*
{code:java}
[root@m7shrdexterep2 ~]# ls -all /etc/rsyslog.d/siem.conf
ls: cannot access /etc/rsyslog.d/siem.conf: No such file or directory
{code}

*2.) service was not restarted since over one month ago*
{code:java}
[root@m7shrdexterep2 ~]# systemctl status rsyslog
● rsyslog.service - System Logging Service
   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)
   Active: active (running) since Mon 2020-04-06 03:23:21 CEST; 1 months 1 days ago
     Docs: man:rsyslogd(8)
           http://www.rsyslog.com/doc/
 Main PID: 6559 (rsyslogd)
   CGroup: /system.slice/rsyslog.service
           └─6559 /usr/sbin/rsyslogd -n

May 02 04:43:59 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
May 03 03:47:01 m7shrdexterep2 rsyslogd[6559]:  [origin software=""rsyslogd"" swVersion=""8.24.0-34.el7"" x-pid=""6559"" x-info=""http://www.rsyslog.com""] rsyslogd was HUPed
May 03 19:05:05 m7shrdexterep2 rsyslogd[6559]: sd_journal_get_cursor() failed: 'Cannot assign requested address'  [v8.24.0-34.el7]
May 03 19:05:05 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
May 03 19:05:05 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
May 05 09:05:13 m7shrdexterep2 rsyslogd[6559]: sd_journal_get_cursor() failed: 'Cannot assign requested address'  [v8.24.0-34.el7]
May 05 09:05:13 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
May 07 00:12:44 m7shrdexterep2 rsyslogd[6559]: sd_journal_get_cursor() failed: 'Cannot assign requested address'  [v8.24.0-34.el7]
May 07 00:12:44 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
May 07 00:12:44 m7shrdexterep2 rsyslogd[6559]: imjournal: journal reloaded... [v8.24.0-34.el7 try http://www.rsyslog.com/e/0 ]
[root@m7shrdexterep2 ~]#
{code}

{color:#00875A}After the deployment:{color}

*1.) deployed necessary conf.file*
{code:java}
[root@m7shrdexterep2 ~]# ls -all /etc/rsyslog.d/siem.conf
-rw-r--r-- 1 root root 40 May  8 06:41 /etc/rsyslog.d/siem.conf
{code}

*2.) service was restarted as well*
{code:java}
[root@m7shrdexterep2 ~]# systemctl status rsyslog
● rsyslog.service - System Logging Service
   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-05-08 06:41:25 CEST; 4min 51s ago
     Docs: man:rsyslogd(8)
           http://www.rsyslog.com/doc/
 Main PID: 5117 (rsyslogd)
   CGroup: /system.slice/rsyslog.service
           └─5117 /usr/sbin/rsyslogd -n

May 08 06:41:25 m7shrdexterep2 systemd[1]: Starting System Logging Service...
May 08 06:41:25 m7shrdexterep2 rsyslogd[5117]:  [origin software=""rsyslogd"" swVersion=""8.24.0-34.el7"" x-pid=""5117"" x-info=""http://www.rsyslog.com""] start
May 08 06:41:25 m7shrdexterep2 systemd[1]: Started System Logging Service.
[root@m7shrdexterep2 ~]#
{code}

Will let validate it with *Renaud Perozzo* 
from &SIEM_admin <&SIEM_admin@deutsche-boerse.com>
output in /var/log/secure file 
{code:java}
[root@m7shrdexterep2 ~]# cat /var/log/secure | grep scanmgr
May  3 18:41:17 m7shrdexterep2 sshd[13734]: Invalid user scanmgr from 172.31.220.251 port 57492
May  3 18:41:17 m7shrdexterep2 sshd[13734]: input_userauth_request: invalid user scanmgr [preauth]
{code}
","08/May/20 06:51;cs687;The same steps are done for *m7shrdexterep1* as well!","08/May/20 07:06;cs687;Waiting for feedback

{code:java}
Good Morning Renaud, 

we from Team „Energy“ have to on-board security-tool SIEM to 4 Hosts:
•	M7SHRDEXTEREP1
•	M7SHRDEXTEREP2
•	M7SHRDPRODREP1
•	M7SHRDPRODREP2

The first two hosts are already on-boarded today in the morning. 
So, what did it actually do:

1.)	Deployed the siem.conf file to the proper path 

[root@m7shrdexterep2 ~]# ls -all /etc/rsyslog.d/siem.conf
-rw-r--r-- 1 root root 40 May  8 06:41 /etc/rsyslog.d/siem.conf

2.)	Afterwards I restarted the service rsyslog

[root@m7shrdexterep2 ~]# systemctl status rsyslog
● rsyslog.service - System Logging Service
   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2020-05-08 06:41:25 CEST; 4min 51s ago
     Docs: man:rsyslogd(8)
           http://www.rsyslog.com/doc/
 Main PID: 5117 (rsyslogd)
   CGroup: /system.slice/rsyslog.service
           └─5117 /usr/sbin/rsyslogd -n

May 08 06:41:25 m7shrdexterep2 systemd[1]: Starting System Logging Service...
May 08 06:41:25 m7shrdexterep2 rsyslogd[5117]:  [origin software=""rsyslogd"" swVersion=""8.24.0-34.el7"" x-pid=""5117"" x-info=""http://www.rsyslog.com""] start
May 08 06:41:25 m7shrdexterep2 systemd[1]: Started System Logging Service.


In /var/log/secure I can see the following log-entries: 

[root@m7shrdexterep2 ~]# cat /var/log/secure | grep scanmgr
May  3 18:41:17 m7shrdexterep2 sshd[13734]: Invalid user scanmgr from 172.31.220.251 port 57492
May  3 18:41:17 m7shrdexterep2 sshd[13734]: input_userauth_request: invalid user scanmgr [preauth]

Can you maybe verify if everything went fine from client-side perspective? 
At least our playbook is just deploying the mentioned steps above. 

#################################################
[root@m7shrdexterep1 ~]# telnet 172.31.220.251 57492
Trying 172.31.220.251...

[root@m7shrdexterep1 ~]# nslookup 172.31.220.251
Server:         193.29.68.61
Address:        193.29.68.61#53

Non-authoritative answer:
251.220.31.172.in-addr.arpa     name = vmscanmgrfra.nw.lan.
#################################################


Once it is working with out any issues on these hosts I will continue with m7shrdprodrep1 & m7shrdprodrep2 on Monday the 11th of May. 

Wish you already a nice weekend. 
Thank you in Advance!

Cheers,
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43

E-Mail  steffen.englert@deutsche-boerse.com
http://www.deutsche-boerse.com
{code}
","08/May/20 08:38;cs687;Done: (/) m7shrdexterep1 & m7shrdexterep2
{code:java}
Good morning Steffen,

The onboarding to SIEM is working.
{code}
","11/May/20 07:29;cs687;Done (/) m7shrdprodrep1 & m7shrdprodrep2",,,,,,,,,,,,,,,,,,,
Migration of VM m7proddbr1,M7P-6057,95068,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,28/Apr/20 16:53,21/May/20 10:23,16/Sep/21 14:11,14/May/20 16:17,,6.10.51,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"During the migration of m7proddbr2 (Replica-Host), [~wm282] and me made some experience, which we need to do for the first host ""*m7proddbr1*"" as well.

1.) shutdown ""m7proddbr1"" Host
2.) change in patroni-config file for each cluster on ""*m7proddbr2*"" the tag ""clonefrom: True"" and reload the patroni-cluster(s)
3) after the migration, starting m7proddbr1 without network connectivity 
4.) connecting to m7proddbr1 (via vsphere) and shutting down all patroni-services which are running
5.) changing the patroni-config file for each cluster on ""*m7proddbr1*"" by adding tag
""*replicatefrom: m7proddbr2*""
6.) starting all patroni services again
7.) running reinit of all patroni-clusters for host m7proddbr1 
8.) afterwards rollback the patroni config changes on m7proddbr1/2 and update it with reloading the cluster. 

[~wm282] once you are ready for it, please consult me and we can work on it how we did it for m7proddbr2 as well. 

*important*
when all the nodes have a ""clonefrom"" set to false, that means *only leader* will be chosen to resync after patroni-services on host m7proddbr1 will be up again. 
To avoid performance issues on leader side we activate the clonefrom on m7proddbr2.

Additional to the upper part, we should add ""replicationfrom-tag"". 
This will make replication connections from m7proddbr1 go to m7proddbr2. What would be called cascading replication. 
Reinit may still be needed in the end, so the clonefrom that should still be set too.
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42249600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzn6bz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95068,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"11/May/20 07:47;cs687;Planned for the 14 of May - starting at 2 o´clock","14/May/20 14:02;cs687;*1.)* shutdown m7proddbr1 Host 
[root@m7proddbr1 ~]# shutdown now  

{code:java}
[root@m7proddbr2 ~]# patronictl -c /etc/patroni_m7teltsprodasync/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsprodasync | m7proddbr2 | 10.136.33.253:20002 |        | running |  1 |           |
| m7teltsprodasync | m7prodpdb1 | 10.139.53.176:20002 | Leader | running |  1 |         0 |
| m7teltsprodasync | m7prodpdb2 | 10.139.53.173:20002 |        | running |  1 |           |
| m7teltsprodasync | m7prodpdb3 | 10.139.53.172:20002 |        | running |  1 |           |
| m7teltsprodasync | m7prodpdb4 | 10.139.53.171:20002 |        | running |  1 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
{code}

","14/May/20 14:06;cs687;*2*) cahnged the patroni config on host m7proddbr2 with the tag ""clonefrom: True""
for each patroni cluster configuration file. 

and reload all the changes:
{code:java}
[root@m7proddbr2 ~]# patronictl -c /etc/patroni_m7txsopprodasync/config.yml reload m7txsopprodasync m7proddbr2
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopprodasync | m7proddbr2 | 10.136.33.253:20012 |        | running |  3 |           |
| m7txsopprodasync | m7prodpdb1 | 10.139.53.176:20012 | Leader | running |  3 |         0 |
| m7txsopprodasync | m7prodpdb2 | 10.139.53.173:20012 |        | running |  3 |         0 |
| m7txsopprodasync | m7prodpdb3 | 10.139.53.172:20012 |        | running |  3 |         0 |
| m7txsopprodasync | m7prodpdb4 | 10.139.53.171:20012 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
Are you sure you want to reload members m7proddbr2? [y/N]: y
Reload request received for member m7proddbr2 and will be processed within 10 seconds

{code}
","14/May/20 14:08;cs687;*3)* after the migration, starting m7proddbr1 without network connectivity
handled by Andrei","14/May/20 14:27;cs687;*4.)* connecting to m7proddbr1 (via vsphere) and shutting down all patroni-services which are running

step *5.)* was already prepared before i shutdown the machine ","14/May/20 15:52;cs687;*6.)* started patroni services again and check with list command that m7proddbr1 is part of the cluster. ","14/May/20 15:54;cs687;*7.)* reinit for elts-prod db that m7proddbr1 has the same level of infromation

{code:java}
[root@m7proddbr2 ~]# patronictl -c /etc/patroni_m7teltsprodasync/config.yml list
+------------------+------------+----------------------+--------+------------------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |      State       | TL | Lag in MB |
+------------------+------------+----------------------+--------+------------------+----+-----------+
| m7teltsprodasync | m7proddbr1 | 10.136.161.253:20002 |        | creating replica |    |   unknown |
| m7teltsprodasync | m7proddbr2 | 10.136.33.253:20002  |        |     running      |  1 |           |
| m7teltsprodasync | m7prodpdb1 | 10.139.53.176:20002  | Leader |     running      |  1 |         0 |
| m7teltsprodasync | m7prodpdb2 | 10.139.53.173:20002  |        |     running      |  1 |           |
| m7teltsprodasync | m7prodpdb3 | 10.139.53.172:20002  |        |     running      |  1 |           |
| m7teltsprodasync | m7prodpdb4 | 10.139.53.171:20002  |        |     running      |  1 |           |
+------------------+------------+----------------------+--------+------------------+----+-----------+
{code}
","14/May/20 15:54;cs687;*8.)* rollback the configuration settings",,,,,,,,,,,,,,,,,,,,
Provide PROD property files,M7P-6056,95056,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ax460,ax460,28/Apr/20 13:56,06/May/20 11:08,16/Sep/21 14:11,05/May/20 14:26,,7tops Sprint6,,,,,,,,7tops,M7PRODOPS,,,,,,"Please provide following property files from EPEX PROD environment 
 # existing (generated via perl)
 # and ansible generated (check mode)

We need to compare them to verify identity.

List of files
 * CORE
 ** ""\{{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/logback.xml""
 ** ""\{{ tomcat_directory }}/lib/EnergyCommonsChangePasswd_en.properties""
 ** ""\{{ tomcat_directory }}/lib/application-env.properties""
 * ENQ
 ** ""\{{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/comxerv.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/comxerv_env.properties""
 ** ""\{{ tomcat_directory }}/bin/restart.sh""
 * CMI
 ** ""\{{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/cmi.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/id_dbs_AMP_prod_dbs""
 ** ""\{{ tomcat_directory }}/lib/cmi_env.properties""
 ** ""\{{ tomcat_directory }}/lib/known_hosts""
 ** ""\{{ tomcat_directory }}/lib/jsch.properties""
 * CMM
 ** ""\{{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/cmm.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/cmm_env.properties""",,ax460,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43113600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxjsv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95056,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/May/20 09:56;iu252;CMI:

{noformat}
@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_cmi.yml --limit 'm7c-icsc-prod-cmi1' --check --diff --tags deploy -k -K | tee m7c_cmi_diff.txt cat m7c_cmi_diff.txt | mailx -s 'm7c diffs' -r 'iu252@enprodauto1.deutsche-boerse.de' alexander.orlov@deutsche-boerse.com,tomas.zdara@deutsche-boerse.com
{noformat}
","05/May/20 10:48;iu252;CMM:

{noformat}
iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_cmm.yml --limit 'm7c-icsc-prod-cmm1' --check --diff --tags deploy -k -K | tee m7c_cmm_diff.txt cat m7c_cmm_diff.txt | mailx -s 'm7c diffs' -r 'iu252@enprodauto1.deutsche-boerse.de' alexander.orlov@deutsche-boerse.com
{noformat}
","05/May/20 10:56;iu252;COR:

{noformat}
[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_core.yml --limit 'm7c-icsc-prod-cor1' --tags deploy --skip-tags slack -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy M7C core] *************************************************************************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : set_fact] *********************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : set_fact] *********************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : set_fact] *********************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : set_fact] *********************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : debug] ************************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1] => {}

MSG:

do_flyway_migrate: True, flyway_clean_migration: False


TASK [m7c_core : Set location equinix] *********************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : Set location hausen] **********************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Set other computed variables] *************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : Get app from artifactory] *****************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : Create instance log directory] ************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [include_role : roles/tag_artifact] *******************************************************************************************************************************************************

TASK [tag_artifact : Tag the artifact] *********************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : create prodscripts folder] ****************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : Copy journal cleanup script] **************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : create journal cleanup cronjob] ***********************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Create instance directory] ****************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Get Tomcat from artifactory] **************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : Extract tomcat] ***************************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Tomcat webapps directory must exist] ******************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Create tomcat log symlink] ****************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Copy app WAR into tomcat directory] *******************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [m7c_core : Copy application config files] ************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1] => (item={'source': 'start.sh.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/bin/start.sh', 'mode': '0754'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'stop.sh.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/bin/stop.sh', 'mode': '0754'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'context.xml.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/conf/context.xml'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'server.xml.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/conf/server.xml'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'logback.xml.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/lib/logback.xml'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'EnergyCommonsChangePasswd_en.properties.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/lib/EnergyCommonsChangePasswd_en.properties'})
changed: [m7c-icsc-prod-cor1] => (item={'source': 'application-env.properties.j2', 'target': '/icsc/icsc-prod-cor1/tomcat/lib/application-env.properties', 'mode': '0640'})

TASK [include_role : roles/vault_base64_decode] ************************************************************************************************************************************************

TASK [vault_base64_decode : Print role info] ***************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1] => {}

MSG:

Base64 decode from vault secret/certs/root/comodo/keystore:value to /icsc/icsc-prod-cor1/tomcat/lib/ldapkeystore.jks


TASK [vault_base64_decode : Fetch to base64 file] **********************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : Decode base64 file] ************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : Get checksum of the old file] **************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : Get checksum of the new file] **************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : show differences] **************************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1] => {}

MSG:

Checksum old file: no-file - checksum new file: 9ef6d7ffaebcb11f1a293212a38e6a308882e854


TASK [vault_base64_decode : Replace the target file] *******************************************************************************************************************************************
changed: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : Clean base64 file] *************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [vault_base64_decode : Clean temporary file] **********************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1]

TASK [m7c_core : Check for existing Flyway installation] ***************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : Ensure Flyway basedir exists] *************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Download Flyway] **************************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Unarchive Flyway] *************************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Download db cfg] **************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : make flyway executable] *******************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : Ensure db cfg temp dir exists] ************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : Unarchive db cfg] *************************************************************************************************************************************************************
ok: [m7c-icsc-prod-cor1 -> localhost]

TASK [m7c_core : DBG - flyway directories] *****************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Clean db] *********************************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : repair flyway metadata table] *************************************************************************************************************************************************
skipping: [m7c-icsc-prod-cor1]

TASK [m7c_core : Migrate db] *******************************************************************************************************************************************************************
fatal: [m7c-icsc-prod-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-6.0.4/flyway"",
        ""-user=m7cicscprodm7b"",
        ""-url=jdbc:postgresql://m7ppg12-prodicsc:20020/m7cicscprodm7b?targetServerType=master"",
        ""-schemas=m7cicscprodm7b"",
        ""-password=pw3DBAm7cicscprodm7b"",
        ""-locations=filesystem:/home/iu252/git/energy.automation.deployments/playbooks/flyway_role/m7-core-6.8.96-db-cfg"",
        ""-group=true"",
        ""migrate""
    ],
    ""delta"": ""0:00:10.139347"",
    ""end"": ""2020-05-05 10:55:18.922559"",
    ""rc"": 1,
    ""start"": ""2020-05-05 10:55:08.783212""
}

STDOUT:

Flyway Community Edition 6.0.4 by Redgate


STDERR:

ERROR:
Unable to obtain connection from database (jdbc:postgresql://m7ppg12-prodicsc:20020/m7cicscprodm7b?targetServerType=master) for user 'm7cicscprodm7b': The connection attempt failed.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL State  : 08001
Error Code : 0
Message    : The connection attempt failed.


MSG:

non-zero return code


NO MORE HOSTS LEFT *****************************************************************************************************************************************************************************

NO MORE HOSTS LEFT *****************************************************************************************************************************************************************************
        to retry, use: --limit @/home/iu252/git/energy.automation.deployments/playbooks/deploy_m7c_core.retry

PLAY RECAP *************************************************************************************************************************************************************************************
m7c-icsc-prod-cor1         : ok=35   changed=12   unreachable=0    failed=1

[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$
{noformat}
","05/May/20 11:17;iu252;ENQ:

{noformat}
[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_enq.yml --limit 'm7c-icsc-prod-enq1' --tags deploy --skip-tags slack -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy M7C enquiry] **********************************************************************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Create instance log directory] *************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Create instance directory] *****************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Get Tomcat from artifactory] ***************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1 -> localhost]

TASK [m7c_enq : Extract tomcat] ****************************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Tomcat webapps directory must exist] *******************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Tomcat directory for static conent must exist] *********************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Create tomcat log symlink] *****************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : debug] *************************************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1] => {}

MSG:

Deploying artifact: intraday


TASK [m7c_enq : Get app from artifactory] ******************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1 -> localhost]

TASK [include_role : roles/tag_artifact] *******************************************************************************************************************************************************

TASK [tag_artifact : Tag the artifact] *********************************************************************************************************************************************************
changed: [m7c-icsc-prod-enq1 -> localhost]

TASK [m7c_enq : Copy WAR into tomcat directory] ************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Set location equinix] **********************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Set location hausen] ***********************************************************************************************************************************************************
skipping: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Set other computed variables] **************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Copy application config files] *************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1] => (item={'source': 'start.sh.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/bin/start.sh', 'mode': '0754'})
ok: [m7c-icsc-prod-enq1] => (item={'source': 'stop.sh.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/bin/stop.sh', 'mode': '0754'})
ok: [m7c-icsc-prod-enq1] => (item={'source': 'context.xml.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/conf/context.xml'})
ok: [m7c-icsc-prod-enq1] => (item={'source': 'server.xml.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/conf/server.xml'})
ok: [m7c-icsc-prod-enq1] => (item={'source': 'logback.xml.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/comxerv.logback.xml'})
changed: [m7c-icsc-prod-enq1] => (item={'source': 'comxerv_env.properties.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/comxerv_env.properties', 'mode': '0640'})
ok: [m7c-icsc-prod-enq1] => (item={'source': 'restart.sh.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/bin/restart.sh', 'mode': '0754'})

TASK [m7c_enq : Copy universal war config files] ***********************************************************************************************************************************************
changed: [m7c-icsc-prod-enq1] => (item={'source': 'exchange.properties.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/exchange.properties'})
changed: [m7c-icsc-prod-enq1] => (item={'source': 'spring-beans.xml.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/spring-beans-epex.xml'})
changed: [m7c-icsc-prod-enq1] => (item={'source': 'defaultConfiguration.xml.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/defaultConfiguration_epex.xml'})
changed: [m7c-icsc-prod-enq1] => (item={'source': 'ChangePasswdEmailMessageResources.properties.j2', 'target': '/icsc/icsc-prod-enq1/tomcat/lib/ChangePasswdEmailMessageResources_epex.properties'})

TASK [include_role : roles/vault_base64_decode] ************************************************************************************************************************************************

TASK [vault_base64_decode : Print role info] ***************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1] => {}

MSG:

Base64 decode from vault secret/certs/root/comodo/keystore:value to /icsc/icsc-prod-enq1/tomcat/lib/ldapkeystore.jks


TASK [vault_base64_decode : Fetch to base64 file] **********************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : Decode base64 file] ************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : Get checksum of the old file] **************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : Get checksum of the new file] **************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : show differences] **************************************************************************************************************************************************
changed: [m7c-icsc-prod-enq1] => {}

MSG:

Checksum old file: no-file - checksum new file: 9ef6d7ffaebcb11f1a293212a38e6a308882e854


TASK [vault_base64_decode : Replace the target file] *******************************************************************************************************************************************
changed: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : Clean base64 file] *************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [vault_base64_decode : Clean temporary file] **********************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1]

TASK [m7c_enq : Get Tomcat from artifactory] ***************************************************************************************************************************************************
ok: [m7c-icsc-prod-enq1 -> localhost]

TASK [m7c_enq : Copy customer logo] ************************************************************************************************************************************************************
changed: [m7c-icsc-prod-enq1]

PLAY RECAP *************************************************************************************************************************************************************************************
m7c-icsc-prod-enq1         : ok=27   changed=6    unreachable=0    failed=0

[iu252@enprodauto1 {master L | ?5} ~/git/energy.automation.deployments]$
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,
Provide CUTE property files,M7P-6054,95048,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ax460,ax460,28/Apr/20 10:49,06/May/20 11:08,16/Sep/21 14:11,04/May/20 09:50,,7tops Sprint6,,,,,,,,7tops,M7PRODOPS,,,,,,"Please provide following property files from EPEX CUTE environment 
 # existing (generated via perl)
 # and ansible generated (check mode)

We need to compare them to verify identity.

List of files
 * CORE (/)
 ** ""{\{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/logback.xml""
 ** ""\{{ tomcat_directory }}/lib/EnergyCommonsChangePasswd_en.properties""
 ** ""\{{ tomcat_directory }}/lib/application-env.properties""
 * ENQ (/)
 ** ""{\{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/comxerv.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/comxerv_env.properties""
 ** ""\{{ tomcat_directory }}/bin/restart.sh""
 * CMI (/)
 ** ""{\{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/cmi.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/id_dbs_AMP_prod_dbs""
 ** ""\{{ tomcat_directory }}/lib/cmi_env.properties""
 ** ""\{{ tomcat_directory }}/lib/known_hosts""
 ** ""\{{ tomcat_directory }}/lib/jsch.properties""
 * CMM (/)
 ** ""{\{ tomcat_directory }}/bin/start.sh""
 ** ""\{{ tomcat_directory }}/bin/stop.sh""
 ** ""\{{ tomcat_directory }}/conf/context.xml""
 ** ""\{{ tomcat_directory }}/conf/server.xml""
 ** ""\{{ tomcat_directory }}/lib/cmm.logback.xml""
 ** ""\{{ tomcat_directory }}/lib/cmm_env.properties""",,ax460,cs687,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43459200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxjrb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95048,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"29/Apr/20 10:44;cs687;[~ax460] providing you that kind of files via email ","29/Apr/20 11:17;cs687;[~ax460] going to close the ticket. 
As with [~cv179] discussed, you have already the output of the ansible-check command. 

When the output has not the proper style than we can not change it right now. 
Check-Mechanism is im-place and you can use it. 
When better style of the check-output has a higher priority we should handle that with Martin M. 
","29/Apr/20 11:25;cs687;Providing you the check output for cmm1/enq/cor as well. 

CMI:
{code:java}
ansible-playbook playbooks/deploy_m7c_cmi.yml --limit 'm7c-icsc-cute-cmi1' --check --diff --tags deploy -k -K | tee m7c_cmi_diff.txt cat m7c_cmi_diff.txt | mailx -s 'm7c diffs' -r 'cs687@enprodauto1.deutsche-boerse.de' steffen.englert@deutsche-boerse.com,tomas.zdara@deutsche-boerse.com
{code}

CMM:
{code:java}
 ansible-playbook playbooks/deploy_m7c_cmm.yml --limit 'm7c-icsc-cute-cmm1' --check --diff --tags deploy -k -K | tee m7c_cmm_diff.txt cat m7c_cmm_diff.txt | mailx -s 'm7c diffs' -r 'cs687@enprodauto1.deutsche-boerse.de' steffen.englert@deutsche-boerse.com,tomas.zdara@deutsche-boerse.com
{code}

CORE:
{code:java}
ansible-playbook playbooks/deploy_m7c_core.yml --limit 'm7c-icsc-cute-cor1' --check --diff --tags deploy -k -K | tee m7c_cor_diff.txt cat m7c_cor_diff.txt | mailx -s 'm7c diffs' -r 'cs687@enprodauto1.deutsche-boerse.de' steffen.englert@deutsche-boerse.com,tomas.zdara@deutsche-boerse.com
{code}

ENQ:
{code:java}
ansible-playbook playbooks/deploy_m7c_enq.yml --limit 'm7c-icsc-cute-enq1' --check --diff --tags deploy -k -K | tee m7c_enq_diff.txt cat m7c_enq_diff.txt | mailx -s 'm7c diffs' -r 'cs687@enprodauto1.deutsche-boerse.de' steffen.englert@deutsche-boerse.com,tomas.zdara@deutsche-boerse.com
{code}


","30/Apr/20 13:22;iu252;Tried to deploy cor which failed:


{noformat}
[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_core.yml --limit 'm7c-icsc-cute-cor1' --tags deploy --skip-tags slack -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy M7C core] *****************************************************************************************************************************************************

TASK [Gathering Facts] *****************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : debug] ****************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1] => {}

MSG:

do_flyway_migrate: True, flyway_clean_migration: False


TASK [m7c_core : Set location equinix] *************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Set location hausen] **************************************************************************************************************************************
skipping: [m7c-icsc-cute-cor1]

TASK [m7c_core : Set other computed variables] *****************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Get app from artifactory] *********************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Create instance log directory] ****************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [include_role : roles/tag_artifact] ***********************************************************************************************************************************

TASK [tag_artifact : Tag the artifact] *************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : create prodscripts folder] ********************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy journal cleanup script] ******************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : create journal cleanup cronjob] ***************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Create instance directory] ********************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Get Tomcat from artifactory] ******************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Extract tomcat] *******************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Tomcat webapps directory must exist] **********************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Create tomcat log symlink] ********************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy app WAR into tomcat directory] ***********************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy application config files] ****************************************************************************************************************************
changed: [m7c-icsc-cute-cor1] => (item={'source': 'start.sh.j2', 'target': '/epex/epex-cute-cor1/tomcat/bin/start.sh', 'mode': '0754'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'stop.sh.j2', 'target': '/epex/epex-cute-cor1/tomcat/bin/stop.sh', 'mode': '0754'})
failed: [m7c-icsc-cute-cor1] (item={'source': 'context.xml.j2', 'target': '/epex/epex-cute-cor1/tomcat/conf/context.xml'}) => {
    ""changed"": false,
    ""item"": {
        ""source"": ""context.xml.j2"",
        ""target"": ""/epex/epex-cute-cor1/tomcat/conf/context.xml""
    }
}

MSG:

AnsibleError: An unhandled exception occurred while templating '{{ db_server | join([':', db_port, ','] | join('')) }}:{{ db_port }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ db_port_pg | default('') }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('get_port','service=db env=test instance={{ postgres_port_lookup }} ') }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while running the lookup plugin 'get_port'. Error was a <class 'ansible.errors.AnsibleError'>, original message: instance m7c-epex-cute-pdb-async of service db and environment test not found

changed: [m7c-icsc-cute-cor1] => (item={'source': 'server.xml.j2', 'target': '/epex/epex-cute-cor1/tomcat/conf/server.xml'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'logback.xml.j2', 'target': '/epex/epex-cute-cor1/tomcat/lib/logback.xml'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'EnergyCommonsChangePasswd_en.properties.j2', 'target': '/epex/epex-cute-cor1/tomcat/lib/EnergyCommonsChangePasswd_en.properties'})
failed: [m7c-icsc-cute-cor1] (item={'source': 'application-env.properties.j2', 'target': '/epex/epex-cute-cor1/tomcat/lib/application-env.properties', 'mode': '0640'}) => {
    ""changed"": false,
    ""item"": {
        ""mode"": ""0640"",
        ""source"": ""application-env.properties.j2"",
        ""target"": ""/epex/epex-cute-cor1/tomcat/lib/application-env.properties""
    }
}

MSG:

AnsibleError: An unhandled exception occurred while templating '{{ db_cluster | join([':', db_port, ','] | join('')) }}:{{ db_port }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ db_port_pg | default('') }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('get_port','service=db env=test instance={{ postgres_port_lookup }} ') }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while running the lookup plugin 'get_port'. Error was a <class 'ansible.errors.AnsibleError'>, original message: instance m7c-epex-cute-pdb-async of service db and environment test not found


NO MORE HOSTS LEFT *********************************************************************************************************************************************************

NO MORE HOSTS LEFT *********************************************************************************************************************************************************
        to retry, use: --limit @/home/iu252/git/energy.automation.deployments/playbooks/deploy_m7c_core.retry

PLAY RECAP *****************************************************************************************************************************************************************
m7c-icsc-cute-cor1         : ok=20   changed=10   unreachable=0    failed=1

[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$
{noformat}
","30/Apr/20 14:02;iu252;approved https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1815
and rerun cor-deployment:

{noformat}
[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_core.yml --limit 'm7c-icsc-cute-cor1' --tags deploy --skip-tags slack -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy M7C core] ***********************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *******************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *******************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *******************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : set_fact] *******************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : debug] **********************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1] => {}

MSG:

do_flyway_migrate: True, flyway_clean_migration: False


TASK [m7c_core : Set location equinix] *******************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Set location hausen] ********************************************************************************************************************************************************
skipping: [m7c-icsc-cute-cor1]

TASK [m7c_core : Set other computed variables] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Get app from artifactory] ***************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Create instance log directory] **********************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [include_role : roles/tag_artifact] *****************************************************************************************************************************************************

TASK [tag_artifact : Tag the artifact] *******************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : create prodscripts folder] **************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy journal cleanup script] ************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : create journal cleanup cronjob] *********************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Create instance directory] **************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Get Tomcat from artifactory] ************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Extract tomcat] *************************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Tomcat webapps directory must exist] ****************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Create tomcat log symlink] **************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy app WAR into tomcat directory] *****************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [m7c_core : Copy application config files] **********************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1] => (item={'source': 'start.sh.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/bin/start.sh', 'mode': '0754'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'stop.sh.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/bin/stop.sh', 'mode': '0754'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'context.xml.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/conf/context.xml'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'server.xml.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/conf/server.xml'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'logback.xml.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/lib/logback.xml'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'EnergyCommonsChangePasswd_en.properties.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/lib/EnergyCommonsChangePasswd_en.properties'})
changed: [m7c-icsc-cute-cor1] => (item={'source': 'application-env.properties.j2', 'target': '/icsc/icsc-cute-cor1/tomcat/lib/application-env.properties', 'mode': '0640'})

TASK [include_role : roles/vault_base64_decode] **********************************************************************************************************************************************

TASK [vault_base64_decode : Print role info] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1] => {}

MSG:

Base64 decode from vault secret/certs/root/comodo/keystore:value to /icsc/icsc-cute-cor1/tomcat/lib/ldapkeystore.jks


TASK [vault_base64_decode : Fetch to base64 file] ********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : Decode base64 file] **********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : Get checksum of the old file] ************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : Get checksum of the new file] ************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : show differences] ************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1] => {}

MSG:

Checksum old file: no-file - checksum new file: 9ef6d7ffaebcb11f1a293212a38e6a308882e854


TASK [vault_base64_decode : Replace the target file] *****************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : Clean base64 file] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [vault_base64_decode : Clean temporary file] ********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1]

TASK [m7c_core : Check for existing Flyway installation] *************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Ensure Flyway basedir exists] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Download Flyway] ************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Unarchive Flyway] ***********************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Download db cfg] ************************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : make flyway executable] *****************************************************************************************************************************************************
changed: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Ensure db cfg temp dir exists] **********************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : Unarchive db cfg] ***********************************************************************************************************************************************************
ok: [m7c-icsc-cute-cor1 -> localhost]

TASK [m7c_core : DBG - flyway directories] ***************************************************************************************************************************************************
skipping: [m7c-icsc-cute-cor1]

TASK [m7c_core : Clean db] *******************************************************************************************************************************************************************
skipping: [m7c-icsc-cute-cor1]

TASK [m7c_core : repair flyway metadata table] ***********************************************************************************************************************************************
skipping: [m7c-icsc-cute-cor1]

TASK [m7c_core : Migrate db] *****************************************************************************************************************************************************************
fatal: [m7c-icsc-cute-cor1 -> localhost]: FAILED! => {
    ""changed"": true,
    ""cmd"": [
        ""flyway_role/flyway-6.0.4/flyway"",
        ""-user=m7cicsccutem7b"",
        ""-url=jdbc:postgresql://m7simupdb1.deutsche-boerse.de:24050,m7simupdb2.deutsche-boerse.de:24050/m7cicsccutem7b?targetServerType=master"",
        ""-schemas=m7cicsccutem7b"",
        ""-password=pw3DBAm7cicsccutem7b"",
        ""-locations=filesystem:/home/iu252/git/energy.automation.deployments/playbooks/flyway_role/m7-core-6.8.96-db-cfg"",
        ""-group=true"",
        ""migrate""
    ],
    ""delta"": ""0:00:20.179004"",
    ""end"": ""2020-04-30 13:41:18.837163"",
    ""rc"": 1,
    ""start"": ""2020-04-30 13:40:58.658159""
}

STDOUT:

Flyway Community Edition 6.0.4 by Redgate


STDERR:

ERROR:
Unable to obtain connection from database (jdbc:postgresql://m7simupdb1.deutsche-boerse.de:24050,m7simupdb2.deutsche-boerse.de:24050/m7cicsccutem7b?targetServerType=master) for user 'm7cicsccutem7b': The connection attempt failed.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL State  : 08001
Error Code : 0
Message    : The connection attempt failed.


MSG:

non-zero return code


NO MORE HOSTS LEFT ***************************************************************************************************************************************************************************

NO MORE HOSTS LEFT ***************************************************************************************************************************************************************************
        to retry, use: --limit @/home/iu252/git/energy.automation.deployments/playbooks/deploy_m7c_core.retry

PLAY RECAP ***********************************************************************************************************************************************************************************
m7c-icsc-cute-cor1         : ok=38   changed=13   unreachable=0    failed=1

[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$ 
{noformat}


checked the files on icsc-host:

{noformat}
tomcat@m7cicsccuteapp1:[/icsc]$ ls -l icsc-cute-cor1/
total 4
drwxr-xr-x 8 tomcat tomcat 4096 Apr 30 13:40 tomcat
tomcat@m7cicsccuteapp1:[/icsc]$ ls -l icsc-cute-cor1/tomcat/
total 140
drwxr-x--- 2 tomcat tomcat  4096 Apr 30 13:40 bin
-rw-r----- 1 tomcat tomcat 19318 Dec  7 20:23 BUILDING.txt
drwx------ 2 tomcat tomcat  4096 Apr 30 13:40 conf
-rw-r----- 1 tomcat tomcat  5408 Dec  7 20:23 CONTRIBUTING.md
drwxr-x--- 2 tomcat tomcat  4096 Apr 30 13:40 lib
-rw-r----- 1 tomcat tomcat 57011 Dec  7 20:23 LICENSE
lrwxrwxrwx 1 tomcat tomcat    25 Apr 30 13:40 logs -> /icsc/logs/icsc-cute-cor1
-rw-r----- 1 tomcat tomcat  1726 Dec  7 20:23 NOTICE
-rw-r----- 1 tomcat tomcat  3255 Dec  7 20:23 README.md
-rw-r----- 1 tomcat tomcat  7136 Dec  7 20:23 RELEASE-NOTES
-rw-r----- 1 tomcat tomcat 16262 Dec  7 20:23 RUNNING.txt
drwxr-x--- 2 tomcat tomcat  4096 Apr 30 13:40 temp
drwxr-xr-x 2 tomcat tomcat  4096 Apr 30 13:40 webapps
drwxr-x--- 2 tomcat tomcat  4096 Dec  7 20:19 work
tomcat@m7cicsccuteapp1:[/icsc]$ du -hs icsc-cute-cor1/
126M    icsc-cute-cor1/
{noformat}
","30/Apr/20 14:04;iu252;merged https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1816 for enq-deployment.","30/Apr/20 14:26;iu252;merged next one: https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/837","30/Apr/20 14:42;iu252;deployed enq:

{noformat}
[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$ ansible-playbook playbooks/deploy_m7c_enq.yml --limit 'm7c-icsc-cute-enq1' --tags deploy --skip-tags slack -k -K
SSH password:
SUDO password[defaults to SSH password]:

PLAY [Deploy M7C enquiry] ********************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Create instance log directory] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Create instance directory] ***************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Get Tomcat from artifactory] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1 -> localhost]

TASK [m7c_enq : Extract tomcat] **************************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Tomcat webapps directory must exist] *****************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Tomcat directory for static conent must exist] *******************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Create tomcat log symlink] ***************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : debug] ***********************************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1] => {}

MSG:

Deploying artifact: intraday


TASK [m7c_enq : Get app from artifactory] ****************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1 -> localhost]

TASK [include_role : roles/tag_artifact] *****************************************************************************************************************************************************

TASK [tag_artifact : Tag the artifact] *******************************************************************************************************************************************************
changed: [m7c-icsc-cute-enq1 -> localhost]

TASK [m7c_enq : Copy WAR into tomcat directory] **********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Set location equinix] ********************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Set location hausen] *********************************************************************************************************************************************************
skipping: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Set other computed variables] ************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Copy application config files] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1] => (item={'source': 'start.sh.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/bin/start.sh', 'mode': '0754'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'stop.sh.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/bin/stop.sh', 'mode': '0754'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'context.xml.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/conf/context.xml'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'server.xml.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/conf/server.xml'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'logback.xml.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/comxerv.logback.xml'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'comxerv_env.properties.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/comxerv_env.properties', 'mode': '0640'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'restart.sh.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/bin/restart.sh', 'mode': '0754'})

TASK [m7c_enq : Copy universal war config files] *********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1] => (item={'source': 'exchange.properties.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/exchange.properties'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'spring-beans.xml.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/spring-beans-epex.xml'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'defaultConfiguration.xml.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/defaultConfiguration_epex.xml'})
ok: [m7c-icsc-cute-enq1] => (item={'source': 'ChangePasswdEmailMessageResources.properties.j2', 'target': '/icsc/icsc-cute-enq1/tomcat/lib/ChangePasswdEmailMessageResources_epex.properties'})

TASK [include_role : roles/vault_base64_decode] **********************************************************************************************************************************************

TASK [vault_base64_decode : Print role info] *************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1] => {}

MSG:

Base64 decode from vault secret/certs/root/comodo/keystore:value to /icsc/icsc-cute-enq1/tomcat/lib/ldapkeystore.jks


TASK [vault_base64_decode : Fetch to base64 file] ********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : Decode base64 file] **********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : Get checksum of the old file] ************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : Get checksum of the new file] ************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : show differences] ************************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1] => {}

MSG:

Checksum old file: 9ef6d7ffaebcb11f1a293212a38e6a308882e854 - checksum new file: 9ef6d7ffaebcb11f1a293212a38e6a308882e854


TASK [vault_base64_decode : Replace the target file] *****************************************************************************************************************************************
skipping: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : Clean base64 file] ***********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [vault_base64_decode : Clean temporary file] ********************************************************************************************************************************************
ok: [m7c-icsc-cute-enq1]

TASK [m7c_enq : Get Tomcat from artifactory] *************************************************************************************************************************************************
changed: [m7c-icsc-cute-enq1 -> localhost]

TASK [m7c_enq : Copy customer logo] **********************************************************************************************************************************************************
changed: [m7c-icsc-cute-enq1]

PLAY RECAP ***********************************************************************************************************************************************************************************
m7c-icsc-cute-enq1         : ok=26   changed=3    unreachable=0    failed=0

[iu252@enprodauto1 {master L | ?4} ~/git/energy.automation.deployments]$
{noformat}
",,,,,,,,,,,,,,,,,,,,
Create replica for shrd prod profile server DB,M7P-6052,95032,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fh971,fh971,27/Apr/20 17:13,06/May/20 11:08,16/Sep/21 14:11,28/Apr/20 10:00,,7tops Sprint6,,,,PS,,,,M7PRODOPS,,,,,,,"We would like to have production profile server db (m7tshrdprodctp schema on m7prodpdbX:20000) accessible via CyberArk tool.

",,cs687,,,,,,,,,,,,,,,,,M7P-5858,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43718400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgqn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":95032,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"28/Apr/20 08:45;cs687;1.) prepared necessary pull-request
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1808/files
","28/Apr/20 09:37;cs687;2.) run the playbook 
ansible-playbook playbooks/deploy_patroni.yml --tags replica --limit m7t-shrd-prod-dbr* -b -K -k

cluster-nodes is available
{code:java}
[root@m7proddbr2 ~]# patronictl -c /etc/patroni_m7tshrdprodasync/config.yml list
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tshrdprodasync | m7proddbr1 | 10.136.161.253:20000 |        | running |  2 |         0 |
| m7tshrdprodasync | m7proddbr2 | 10.136.33.253:20000  |        | running |  2 |         0 |
| m7tshrdprodasync | m7prodpdb1 | 10.139.53.176:20000  | Leader | running |  2 |         0 |
| m7tshrdprodasync | m7prodpdb2 | 10.139.53.173:20000  |        | running |  2 |         0 |
| m7tshrdprodasync | m7prodpdb3 | 10.139.53.172:20000  |        | running |  2 |         0 |
| m7tshrdprodasync | m7prodpdb4 | 10.139.53.171:20000  |        | running |  2 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
{code}


","28/Apr/20 09:37;cs687;3.) run also the jenkins job to get temporary permissions. 
can connect to m7proddbr1 host. 

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Temporary%20DB%20access%20(M7)/ ","28/Apr/20 10:00;cs687;working [~fh971] confirmed the connectivity ",,,,,,,,,,,,,,,,,,,,,,,,
SYT1 SLA reporting - switch to patroni,M7P-6041,94934,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,dp007,dp007,24/Apr/20 09:44,06/May/20 11:08,16/Sep/21 14:11,24/Apr/20 10:36,,7tops Sprint6,,,,EBSM,,,,EBSM,M7PRODOPS,Patroni,SLA,,,,switch the db connection to patroni and run all calculation jobs for 2020,,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"db source switched, 2020 recalculated",,,,,,,,,,,,,,,,,,,,,,,,44064000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,24/Apr/20 09:44,,[],,,,,,,,,,,M7T,,,,"2|hzxj47:",9223372036854775807,,,,No,,,,,,,,,,n/a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":94934,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create Vault entries - PROD,M7P-6039,94929,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ax460,ax460,24/Apr/20 08:19,06/May/20 11:08,16/Sep/21 14:11,24/Apr/20 14:40,,7tops Sprint6,,,,,,,,7tops,M7PRODOPS,,,,,,"Please in [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/prod]

follow existing structre [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/shrd/ate5/] and create additional amqp users eg
 * [amqp/enquiry|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/enquiry]
 * [amqp/core|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/core]
 * [amqp/cmm|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/cmm]
 * [amqp/cmi|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/cmi]

 ",,ax460,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43977600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxj3b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94929,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Apr/20 14:40;iu252;done:

{noformat}
[iu252@enprodauto1 ~]$ vault list secret/m7c/icsc/prod/amqp
Keys
----
admin
cmi
cmm
core
enquiry
monitor
user_enq1
user_enq2
[iu252@enprodauto1 ~]$
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
Create Vault entries - CUTE,M7P-6038,94928,92489,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,ax460,ax460,24/Apr/20 08:18,06/May/20 11:08,16/Sep/21 14:11,24/Apr/20 10:14,,7tops Sprint6,,,,,,,,7tops,M7PRODOPS,,,,,,"Please in [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/icsc/cute]

follow existing structre [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7c/shrd/ate5/]

and create additional amqp users eg
 * [amqp/enquiry|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/enquiry]
 * [amqp/core|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/core]
 * [amqp/cmm|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/cmm]
 * [amqp/cmi|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate5/amqp/cmi]",,ax460,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44064000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxj33:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 91,Schmetterling Sprint 92 (US),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94928,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Apr/20 10:04;iu252;[~ax460] amqp/cmi already exists in vault but with different user:


{noformat}
[iu252@enprodauto1 ~]$ vault read secret/m7c/shrd/ate5/amqp/cmi
Key                 Value
---                 -----
refresh_interval    768h
password            cmm-integ
user                cmm-integ


[iu252@enprodauto1 ~]$ vault read secret/m7c/icsc/cute/amqp/cmi
Key                 Value
---                 -----
refresh_interval    768h
password            ***************
user                cmm-inquiry
[iu252@enprodauto1 ~]$
{noformat}

Which one is correct?","24/Apr/20 10:13;iu252;ICSC CUTE done:

{noformat}
[iu252@enprodauto1 ~]$ vault list secret/m7c/icsc/cute/amqp
Keys
----
admin
cmi
cmm
core
enquiry
monitor
user_enq1
user_enq2
[iu252@enprodauto1 ~]$
{noformat}
","24/Apr/20 10:33;ax460;[~iu252] user for amq/cmi should be cmm-integ 

 

see ate5
 * cmi - cmm-integ
 * cmm - cmm-inquiry
 * core - core
 * enquiry - enquiry

user will be created in rabbit by ansible role based on this values

so name is important only for us to be able distinguish applications (functionally it cant be and was one user)

 ",,,,,,,,,,,,,,,,,,,,,,,,,
SLA report sql query crashing due to short timeout on patroni,M7P-6028,94871,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,cs687,dp007,dp007,23/Apr/20 11:20,06/May/20 11:08,16/Sep/21 14:11,29/Apr/20 14:17,,6.10.27,7tops Sprint6,,,Database,,,,M7PRODOPS,,,,,,,"{code:java}
org.postgresql.util.PSQLException: ERROR: canceling statement due to conflict with recovery
  Detail: User query might have needed to see row versions that must be removed.
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2102)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:1835)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:257)
        at org.postgresql.jdbc2.AbstractJdbc2Statement.execute(AbstractJdbc2Statement.java:500)
        at org.postgresql.jdbc2.AbstractJdbc2Statement.executeWithFlags(AbstractJdbc2Statement.java:374)
        at org.postgresql.jdbc2.AbstractJdbc2Statement.executeQuery(AbstractJdbc2Statement.java:254)
        at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_acs_kpivalues.processETL(Gnrl_acs_kpivalues.java:115)
        at com.deutscheboerse.energy.ebsm.cxxp.Cxxp_kpi_valuesday.processETL(Cxxp_kpi_valuesday.java:46)
        at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_acs_DBS.prepareETL(Gnrl_acs_DBS.java:44)
        at com.deutscheboerse.energy.ebsm.gnrl.Gnrl_acs_ETL.initETL(Gnrl_acs_ETL.java:75)
        at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at com.deutscheboerse.energy.ebsm.gnrl.JobSequencerThread.run(JobSequencerThread.java:64)
 {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6041,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,changed max_standby_streaming_delay on slave host,,,,,,,,,,,,,,,,,,,,,,,,43545600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,23/Apr/20 11:20,,[],,,,,,,,,,,M7T,,,,"2|hzxirr:",9223372036854775807,,,,No,,,,,,,,,,no root-cause details was just a test,,,,,,,,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,none,,,,,,,,,,"{""issueId"":94871,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Apr/20 08:29;cs687;For testing i activated temporarily the *max_standby_streaming_delay* on the slave host m7testpdb1

{code:java}
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt1async | m7testpdb1 | 10.139.58.178:26002 |        | running |  6 |         1 |
| m7tshrdsyt1async | m7testpdb2 | 10.139.58.177:26002 | Leader | running |  6 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
Are you sure you want to reload members m7testpdb1? [y/N]: y
Reload request received for member m7testpdb1 and will be processed within 10 seconds
{code}

will revert it afterwards again.","24/Apr/20 09:45;cs687;[~dp007] job finished after 35 mintues. ","24/Apr/20 10:24;cs687;revoked the settings. ","24/Apr/20 14:18;dp007;agreed with developers the max_standby_streaming_delay will be set to 20 minutes (1200000ms) on SYT1. If there'll be any subsequent disruption (problems after failover or so) we will revert the value back to default.","29/Apr/20 12:34;cs687;Changed it for both cluster-nodes m7testpdb1/2 for env m7tshrdsyt1

afterwards i reloaded config changes 
{code:java}
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml reload m7tshrdsyt1async m7testpdb1
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml reload m7tshrdsyt1async m7testpdb2
{code}

changes:
{code:java}
  parameters:
    max_standby_streaming_delay: 1200000
{code}


","29/Apr/20 14:17;cs687;done! [~dp007] confirmed we end up with a value of 180000",,,,,,,,,,,,,,,,,,,,,,
ICS User Set Up (New BG & User for Catrina user),M7P-6019,94814,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,tj898,qm925,qm925,22/Apr/20 12:36,01/Feb/21 09:52,16/Sep/21 14:11,06/May/20 11:12,,6.8.128,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"Request for a set-up of one (1) Production user for CATRINA
 * Participant Name/Company: Axpo Solutios AG

 * Balancing Group EIC/EAN/GLN Code: 12XEGL-H-------0

 * Email address to be added to account: [support.stt-ps.ch@axpo.com|mailto:support.stt-ps.ch@axpo.com]

 * Assignment of Borders: CH-DE; CH-FR

Additional Note: This client has already two existing accounts (CXEGLA03 and CXEGLA04 )Please provide the details to the clients (user, certificate, etc.) only after confirmation from Account Management (Simona). *The foreseen go-live in Prod is in the upcoming 2-3 weeks*",,qm925,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-1074,,,,,,"06/May/20 11:07;tj898;M7P-6019.txt;https://jira.deutsche-boerse.com/secure/attachment/83569/M7P-6019.txt","06/May/20 11:09;tj898;TestClient_Connection.PNG;https://jira.deutsche-boerse.com/secure/attachment/83570/TestClient_Connection.PNG",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43027200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxgof:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94814,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/20 11:10;tj898;Account created and tested.

Details on the text file attached: [^M7P-6019.txt]

Test using TestClient also added here. 

Created SERVICE ticket for delivery: SERVICE-6278 (to be processed only when instructed by ACM - Simona added as Watcher)

Ticket to be set on Resolved.

 

 ","06/May/20 11:10;tj898;!TestClient_Connection.PNG!",,,,,,,,,,,,,,,,,,,,,,,,,,
EPEX_ASIM: Reporting Engine DB - preferred node,M7P-6018,94795,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,22/Apr/20 10:16,05/Aug/20 08:46,16/Sep/21 14:11,29/Jul/20 15:09,,6.10.173,7tops_sprint12,,,RE,,,,L,M7PRODOPS,Reporting_Engine,,,,,"Goal of this ticket is to find best practice of connecting reporting engine to patroni database.

So far all production REs are connected master node which is affecting performance of the system as such.

The definition is managed by line db_server_type: ""master"" in energy.automation.inventory

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/search?q=db_server_type&unscoped_q=db_server_type]

We need to connect RE to replica host and configure the replica properly because the very same change will be applied on all production REs.

The final solution has to be able to cope with long running queries (30 minutes) analysing data of the whole month which are used for SLA reporting.",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"make it possible that the reporting_engine connects to the replica-DBR Hosts

tested with epex-asim and supported by Martin K.",,,,,,,,EPEX,,,,,,,,,,,,,,,,35683200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgon:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"merged the following pull-requests: 
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2020/files
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1010/files
* https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1009
* https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2018

Deployed reporting_engine and dbr-hosts to refresh the config.xml file 
ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*epex*asim*dbr-async1"" -k -K -b --tags replica",,,,,,,,,,"{""issueId"":94795,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,master,,true,"22/Jul/20 14:02;cs687;For epex-asim database we changed the parameter *max_standby_streaming_delay* for the replica hosts *m7simudbr1* & *m7simudbr2*

afterwards we are changing in the inventory the parameter *db_server* https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/65cea19a06b39505e359378b6a87be9c04455eb4/inventory/m7t/epex/asim/vars.yml
in the section reporting-engine -> https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/epex/asim/reporting_engine/vars.yml
","22/Jul/20 14:36;dp007;[https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/reporting_engine/defaults/main.yml]
db_server_type: ""master""
flyway_user: ""\{{ db_owner }}""
flyway_url: ""jdbc:postgresql://\{{ db_cluster_string }}/\{{ db_owner }}?targetServerType=master""","22/Jul/20 14:40;cs687;*Issue: Missing Firewall-Request* 
-> will create Firewallrequest 

m7shrdexterep1 -> m7simudbr1/2 
m7shrdexterep2 -> m7simudbr1/2

{code:java}
[root@m7shrdexterep1 ~]# telnet m7simudbr1 24012
Trying 10.136.161.121...

[root@m7shrdexterep1 ~]# telnet m7simupdb1 24012
Trying 10.139.58.176...
Connected to m7simupdb1.
Escape character is '^]'.
^CConnection closed by foreign host.
{code}

Once the firewall-Request is implemented, we will test it again, once we are successful we will report it to the devops-meeting. 

*#504909 | EGY Reporting-Engine to Replica-DB Hosts*

","22/Jul/20 14:43;dp007;once FW req is ready => [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1999] => just remove the commenting hash signs ","28/Jul/20 14:39;cs687;We agreed on it in the devops meeting 28.07.2020
to create a separate parameter and replace the value of ""{{ db_server_string }}"" to make it possible to connect to m7simudbr1/2 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/reporting_engine/templates/context.xml.j2

[~dp007] will prepare the pull-request ","29/Jul/20 09:58;cs687;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1009
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2018

after merging the pull-requests and deploying reporting engine for epex-asim 
we can see the connection is working fine. 

{code:java}
                                            | client backend
 16386 | m7tepexasimm7b | 12821 |    16395 | uapp01m7tepexasimrep | PostgreSQL JDBC Driver | 10.139.59.240 |                 |       50062 | 2020-07-29 11:24:
41.875752+02 |                               | 2020-07-29 11:24:42.612277+02 | 2020-07-29 11:24:42.612319+02 | Client          | ClientRead       | idle   |
           |              | SELECT configuration.VALUE as value from m7tepexasimm7b.cx_600_configuration as configuration where configuration.id=$1
                                            | client backend
 13881 | postgres       | 12840 |       10 | postgres             | psql                   |               |                 |          -1 | 2020-07-29 11:25:
03.449548+02 | 2020-07-29 11:25:10.539296+02 | 2020-07-29 11:25:10.539296+02 | 2020-07-29 11:25:10.539298+02 |                 |                  | active |
           |     58602395 | select * from pg_stat_activity;
{code}

we just added the following to the pg_hba.conf on the replica hosts m7simudbr1
* - host m7tepexasimm7b uapp01m7tepexasimrep 10.139.59.240/22 md5
* - host m7tepexasimm7b uapp01m7tepexasimrep 10.139.59.184/22 md5
* max_standby_streaming_delay: 600000

once this is working we have to add that to the playbook as well, to automate that process for the replica-hosts. 



","29/Jul/20 14:32;cs687;changed the patroni playbook for deploying replica-host in a generic way 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2020/files
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1010/files

","29/Jul/20 15:09;cs687;Done",,,,,,,,,,,,,,,,,,,,
Investigate ELTS CTPB Kernel randomly killing CORE instance,M7P-6015,94761,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,21/Apr/20 16:35,01/Feb/21 09:52,16/Sep/21 14:11,22/Apr/20 15:30,,6.10.21,7tops Sprint6,,,,,,,7tops_comm,M7PRODOPS,,,,,,"h1. What ?

On the 17th around 11:26 ELTS CTPB had COR2 go down (this instance was Slave), without any specific logs. 
 After investigation we found out that it was *killed by Kernel after detecting an OOM issue.*

 

BUT, when we look at our metrics, this server was looking just fine memory wise.

 

*We would like to know why the kernel detected an OOM situation, and what needs to be done on the server to avoid future similar situation.*

 
h1. Additional information :

Metrics :

[https://chronograf.energy.svc.dbgcloud.io/sources/3/chronograf/data-explorer?query=SELECT%20mean%28%22total%22%29%20AS%20%22mean_total%22%2C%20mean%28%22used%22%29%20AS%20%22mean_used%22%20FROM%20%22metrics_m7%22.%22autogen%22.%22mem%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A%20AND%20%22host%22%3D%27m7eltsctpbm7b2%27%20GROUP%20BY%20time%28%3Ainterval%3A%29%20FILL%28null%29]

 

[https://grafana.energy.svc.dbgcloud.io/d/QdT5584mz/java-application?orgId=2&from=1587074400000&to=1587160799000&var-host=All&var-client=elts&var-environment=ctpb&var-group=All&var-interval=$__auto_interval_interval&var-tomcat=m7eltsctpbm7b1_m7core&var-tomcat=m7eltsctpbm7b2_m7core&var-core_host=&var-instance=cor1&var-instance=cor2]

 

Kernel logs :
{code:java}
[root@m7eltsctpbm7b2 ~]# dmesg -T| grep -E -i -B100 'killed process'
[Fri Apr 17 11:26:38 2020] quartzScheduler cpuset=/ mems_allowed=0
[Fri Apr 17 11:26:38 2020] CPU: 3 PID: 8504 Comm: quartzScheduler Kdump: loaded Not tainted 3.10.0-957.el7.x86_64 #1
[Fri Apr 17 11:26:38 2020] Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 12/12/2018
[Fri Apr 17 11:26:38 2020] Call Trace:
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d61dc1>] dump_stack+0x19/0x1b
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d5c7ea>] dump_header+0x90/0x229
[Fri Apr 17 11:26:38 2020]  [<ffffffffb090095b>] ? cred_has_capability+0x6b/0x120
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07ba274>] oom_kill_process+0x254/0x3d0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0900a2c>] ? selinux_capable+0x1c/0x40
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07baab6>] out_of_memory+0x4b6/0x4f0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d5d2ee>] __alloc_pages_slowpath+0x5d6/0x724
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07c0e95>] __alloc_pages_nodemask+0x405/0x420
[Fri Apr 17 11:26:38 2020]  [<ffffffffb080dcf8>] alloc_pages_current+0x98/0x110
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07b60d7>] __page_cache_alloc+0x97/0xb0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07b8d38>] filemap_fault+0x298/0x490
[Fri Apr 17 11:26:38 2020]  [<ffffffffc0564186>] ext4_filemap_fault+0x36/0x50 [ext4]
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07e41da>] __do_fault.isra.59+0x8a/0x100
[Fri Apr 17 11:26:38 2020]  [<ffffffffb070c72c>] ? __unqueue_futex+0x2c/0x60
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07e478c>] do_read_fault.isra.61+0x4c/0x1b0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07e9134>] handle_pte_fault+0x2f4/0xd10
[Fri Apr 17 11:26:38 2020]  [<ffffffffb070cb18>] ? get_futex_key+0x1c8/0x2c0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb07ebc6d>] handle_mm_fault+0x39d/0x9b0
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d6f5e3>] __do_page_fault+0x203/0x500
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d6f915>] do_page_fault+0x35/0x90
[Fri Apr 17 11:26:38 2020]  [<ffffffffb0d6b758>] page_fault+0x28/0x30
[Fri Apr 17 11:26:38 2020] Mem-Info:
[Fri Apr 17 11:26:38 2020] active_anon:1461524 inactive_anon:283307 isolated_anon:0
 active_file:118 inactive_file:650 isolated_file:0
 unevictable:0 dirty:17 writeback:0 unstable:0
 slab_reclaimable:7854 slab_unreclaimable:9115
 mapped:16852 shmem:16795 pagetables:6395 bounce:0
 free:37849 free_pcp:30 free_cma:0
[Fri Apr 17 11:26:38 2020] Node 0 DMA free:15860kB min:52kB low:64kB high:76kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:15992kB managed:15908kB mlocked:0kB dirty:0kB writeback:0kB mapped:0kB shmem:0kB slab_reclaimable:0kB slab_unreclaimable:16kB kernel_stack:0kB pagetables:0kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:0 all_unreclaimable? yes
[Fri Apr 17 11:26:38 2020] lowmem_reserve[]: 0 2811 19889 19889
[Fri Apr 17 11:26:38 2020] Node 0 DMA32 free:77712kB min:9544kB low:11928kB high:14316kB active_anon:1128220kB inactive_anon:436556kB active_file:180kB inactive_file:760kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:3129152kB managed:2881904kB mlocked:0kB dirty:20kB writeback:0kB mapped:8732kB shmem:8656kB slab_reclaimable:2932kB slab_unreclaimable:3564kB kernel_stack:1296kB pagetables:4408kB unstable:0kB bounce:0kB free_pcp:280kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:506 all_unreclaimable? no
[Fri Apr 17 11:26:38 2020] lowmem_reserve[]: 0 0 17077 17077
[Fri Apr 17 11:26:38 2020] Node 0 Normal free:57788kB min:57984kB low:72480kB high:86976kB active_anon:4717876kB inactive_anon:696672kB active_file:292kB inactive_file:712kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:17825792kB managed:17487472kB mlocked:0kB dirty:48kB writeback:0kB mapped:58676kB shmem:58524kB slab_reclaimable:28484kB slab_unreclaimable:32880kB kernel_stack:6800kB pagetables:21172kB unstable:0kB bounce:0kB free_pcp:120kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:26 all_unreclaimable? no
[Fri Apr 17 11:26:38 2020] lowmem_reserve[]: 0 0 0 0
[Fri Apr 17 11:26:38 2020] Node 0 DMA: 1*4kB (U) 0*8kB 1*16kB (U) 1*32kB (U) 1*64kB (U) 1*128kB (U) 1*256kB (U) 0*512kB 1*1024kB (U) 1*2048kB (M) 3*4096kB (M) = 15860kB
[Fri Apr 17 11:26:38 2020] Node 0 DMA32: 667*4kB (UEM) 904*8kB (UEM) 647*16kB (UEM) 467*32kB (UEM) 279*64kB (UEM) 128*128kB (UEM) 31*256kB (UEM) 1*512kB (M) 0*1024kB 0*2048kB 0*4096kB = 77884kB
[Fri Apr 17 11:26:38 2020] Node 0 Normal: 11293*4kB (UEM) 1114*8kB (UEM) 69*16kB (UEM) 76*32kB (UEM) 9*64kB (EM) 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 58196kB
[Fri Apr 17 11:26:38 2020] Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=1048576kB
[Fri Apr 17 11:26:38 2020] Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=2048kB
[Fri Apr 17 11:26:38 2020] 147918 total pagecache pages
[Fri Apr 17 11:26:38 2020] 130219 pages in swap cache
[Fri Apr 17 11:26:38 2020] Swap cache stats: add 512232, delete 382035, find 0/0
[Fri Apr 17 11:26:38 2020] Free swap  = 0kB
[Fri Apr 17 11:26:38 2020] Total swap = 2047996kB
[Fri Apr 17 11:26:38 2020] 5242734 pages RAM
[Fri Apr 17 11:26:38 2020] 0 pages HighMem/MovableOnly
[Fri Apr 17 11:26:38 2020] 146413 pages reserved
[Fri Apr 17 11:26:38 2020] [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
[Fri Apr 17 11:26:38 2020] [ 4419]     0  4419    44892    27876      92       64             0 systemd-journal
[Fri Apr 17 11:26:38 2020] [ 4448]     0  4448    49639       57      29      119             0 lvmetad
[Fri Apr 17 11:26:38 2020] [ 4455]     0  4455    11159        2      24      170         -1000 systemd-udevd
[Fri Apr 17 11:26:38 2020] [ 8672]     0  8672    15511       27      29      130         -1000 auditd
[Fri Apr 17 11:26:38 2020] [ 8674]     0  8674    21138        8      11       30             0 audispd
[Fri Apr 17 11:26:38 2020] [ 8695]     0  8695    24892        0      40      402             0 VGAuthService
[Fri Apr 17 11:26:38 2020] [ 8696]     0  8696    57056        1      65      482             0 abrtd
[Fri Apr 17 11:26:38 2020] [ 8697]   997  8697   156119       59      66     1806             0 polkitd
[Fri Apr 17 11:26:38 2020] [ 8699]     0  8699    93612      107      59      265             0 vmtoolsd
[Fri Apr 17 11:26:38 2020] [ 8702]     0  8702     5419       35      16       46             0 irqbalance
[Fri Apr 17 11:26:38 2020] [ 8708]    81  8708    19674       79      36       79          -900 dbus-daemon
[Fri Apr 17 11:26:38 2020] [ 8720]    38  8720     9492       43      21      111             0 ntpd
[Fri Apr 17 11:26:38 2020] [ 8748]     0  8748     6123        7      17      139             0 smartd
[Fri Apr 17 11:26:38 2020] [ 8749]     0  8749    22598        1      46      229             0 rngd
[Fri Apr 17 11:26:38 2020] [ 8750]     0  8750    56432       10      60      361             0 abrt-watch-log
[Fri Apr 17 11:26:38 2020] [ 8753]   996  8753     2144        8      10       30             0 lsmd
[Fri Apr 17 11:26:38 2020] [ 8754]     0  8754    64415       12      75      322             0 sssd
[Fri Apr 17 11:26:38 2020] [ 8777]     0  8777    51957        1      40      167             0 gssproxy
[Fri Apr 17 11:26:38 2020] [ 8881]     0  8881    78369      344     103      466             0 sssd_be
[Fri Apr 17 11:26:38 2020] [ 8924]     0  8924    68892       82      86      165             0 sssd_nss
[Fri Apr 17 11:26:38 2020] [ 8925]     0  8925    61236       66      75      181             0 sssd_pam
[Fri Apr 17 11:26:38 2020] [ 8927]     0  8927    61546       85      74      181             0 sssd_ssh
[Fri Apr 17 11:26:38 2020] [ 8928]     0  8928    59628       54      71      182             0 sssd_sudo
[Fri Apr 17 11:26:38 2020] [ 8933]     0  8933     9168       49      19       42             0 systemd-logind
[Fri Apr 17 11:26:38 2020] [ 9041]   499  9041   206128     7803      76     1185             0 telegraf
[Fri Apr 17 11:26:38 2020] [ 9043]     0  9043    28189       27      58      231         -1000 sshd
[Fri Apr 17 11:26:38 2020] [ 9046]   495  9046   168480     4223      73     1187             0 filebeat
[Fri Apr 17 11:26:38 2020] [ 9049]     0  9049     6260        0      17       58             0 xinetd
[Fri Apr 17 11:26:38 2020] [ 9053]     0  9053   143457      114      97     2657             0 tuned
[Fri Apr 17 11:26:38 2020] [ 9056]     0  9056    96703    14598     114      329             0 rsyslogd
[Fri Apr 17 11:26:38 2020] [ 9124]     0  9124   209271      322      35      817             0 discagnt
[Fri Apr 17 11:26:38 2020] [ 9166]    32  9166    18412       12      39      166             0 rpcbind
[Fri Apr 17 11:26:38 2020] [ 9199]    29  9199    12239        1      27      251             0 rpc.statd
[Fri Apr 17 11:26:38 2020] [ 9266]     0  9266     6476        4      18       46             0 atd
[Fri Apr 17 11:26:38 2020] [ 9270]     0  9270    31572       30      19      128             0 crond
[Fri Apr 17 11:26:38 2020] [ 9271]     0  9271    26992        7       9       31             0 rhnsd
[Fri Apr 17 11:26:38 2020] [ 9286]     0  9286    27523        1      10       32             0 agetty
[Fri Apr 17 11:26:38 2020] [ 9404]  1984  9404     1107       13       9       20             0 xymonlaunch
[Fri Apr 17 11:26:38 2020] [ 9529]     0  9529    22385       18      42      241             0 master
[Fri Apr 17 11:26:38 2020] [ 9539]    89  9539    25490       14      47      240             0 qmgr
[Fri Apr 17 11:26:38 2020] [43834]     0 43834    42744       51      81      285             0 sshd
[Fri Apr 17 11:26:38 2020] [43839]   496 43839    42779       74      78      298             0 sshd
[Fri Apr 17 11:26:38 2020] [ 8244]   500  8244  3016302  1194928    3370   472712             0 java
[Fri Apr 17 11:26:38 2020] [21534]   500 21534  2296567   384111     899        0             0 java
[Fri Apr 17 11:26:38 2020] [16191]    89 16191    25473      251      48        0             0 pickup
[Fri Apr 17 11:26:38 2020] [17453]  1984 17453     2389       48      10        0             0 sh
[Fri Apr 17 11:26:38 2020] [17455]  1984 17455    12255       80      28        0             0 vmstat
[Fri Apr 17 11:26:38 2020] Out of memory: Kill process 8244 (java) score 297 or sacrifice child
[Fri Apr 17 11:26:38 2020] Killed process 8244 (java) total-vm:12065208kB, anon-rss:4779712kB, file-rss:0kB, shmem-rss:0kB
[root@m7eltsctpbm7b2 ~]#
{code}
 ",,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5984,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44150400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxi0f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94761,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/20 15:07;iu252;Unfortunately, kernel crash dump was not created.
Maybe ESX vSphere event logs will show us something usable.","22/Apr/20 15:23;iu252;From ESX vSphere logs we can see that on 17th of April at 11:06 m7eltsctpbm7b2 VM was migrated to Energy ESX Cluster.
The migration was done without stopping the applications and without reboot.

We assume that this migration  was the root cause of kernel crash.
It happend only on this VM!


To avoid similar issues during the migration of production VMs we suggest following:
1. stopp all applications on the VM
2. migrate VM
3. reboot VM
4. start all applications on the VM

PS. Thank you for your support, [~cv524]!","22/Apr/20 15:29;fj021;[~rehapav] [~pn508] : 

Root cause analysis completed, we know why the kernel behaved the way it did. (And how to avoid it next time).

Thanks [~iu252] ! The ticket can be resolved.",,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Restore DB dump for ELTS PROD Profile DB,M7P-6008,94738,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,wn626,wn626,21/Apr/20 13:02,06/May/20 11:08,16/Sep/21 14:11,22/Apr/20 15:33,,6.10.21,7tops Sprint6,,,,,,,M7PRODOPS,,,,,,,"Restore DB dump for ELTS PROD Profile DB for 11.03.2020

 

Run SQL command to check if CXVITL20's profile has grouping separator disabled or enabled on 11.03.2020.

Run SQL command to check it:

SELECT content FROM TBXC101_PROFILE WHERE exchangeId='EPEXv6' AND userName='CXVITL20' AND environmentId='production';",,cs687,wn626,,,,,,,,,,,,,,,,,,SERVICE-6104,,,,,,,,,,,,,,,,,,,,"22/Apr/20 12:07;cs687;output_M7P-6008;https://jira.deutsche-boerse.com/secure/attachment/82919/output_M7P-6008",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,Other Service Request,,,,,,,,,,44236800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxhzr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94738,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"22/Apr/20 08:19;cs687;i will take the following fully/incremental backups from netbackup:
{code:java}
copyId: 1 - 1583965199 - /ampgsql-data-1 - 2020-03-11 23:19:59
copyId: 1 - 1583961996 - /ampgsql-data-0 - 2020-03-11 22:26:36
{code}
","22/Apr/20 08:42;cs687;Created in the root-home Dir on host m7spg2 the script ""/root/restore_shrdprod.sh"" 
which will request the archived netbackup files.

archived files will be stored in 
m7spg2:/copyshrd/data/restore

*1.) request the full-backup*
{code:java}
[root@m7spg2 restore]# ~/restore_shrdprod.sh /ampgsql-data-0 ""2020-03-11 22:26:36""
Check copyId: 1 - 1583961996 - /ampgsql-data-0 - 2020-03-11 22:26:36
Retrieving copyId: 1 - 1583961996 - /ampgsql-data-0 - 2020-03-11 22:26:36
......
{code}

*2.) request incremental-backup*
{code:java}
[root@m7spg2 restore]# ~/restore_shrdprod.sh /ampgsql-data-1 ""2020-03-11 23:19:59""
Check copyId: 1 - 1583965199 - /ampgsql-data-1 - 2020-03-11 23:19:59
Retrieving copyId: 1 - 1583965199 - /ampgsql-data-1 - 2020-03-11 23:19:59
{code}

*3.) modify the postgresql.conf in a proper state*
/copyshrd/data/restore/archive/data/postgresql.conf

*4.) preparing the recovery.conf file*
cp -p /usr/ppas-9.3/share/recovery.conf.sample /copyshrd/data/restore/archive/data
mv /copyshrd/data/restore/archive/data/recovery.conf.sample /copyshrd/data/restore/archive/data/recovery.conf

changes the parameter *restore_command* and *recovery_target_time* in the file recovery.conf

*5.) starting the database*
pg_ctl -D  /copyshrd/data/restore/archive/data start

{code:java}
<user= db= host= time=2020-04-22 11:47:06.994 CEST pid=46839 > LOG:

        ** EnterpriseDB Dynamic Tuning Agent ********************************************
        *       System Utilization: 66 %                                                *
        *         Database Version: 9.3.6.19                                            *
        * Operating System Version:                                                     *
        *     Number of Processors: 0                                                   *
        *           Processor Type:                                                     *
        *   Processor Architecture:                                                     *
        *            Database Size: 7.5    GB                                           *
        *                      RAM: 94.5   GB                                           *
        *            Shared Memory: 96705  MB                                           *
        *       Max DB Connections: 254                                                 *
        *               Autovacuum: on                                                  *
        *       Autovacuum Naptime: 60   Seconds                                        *
        *            InfiniteCache: off                                                 *
        *    InfiniteCache Servers: 0                                                   *
        *       InfiniteCache Size: 0.000  GB                                           *
        *********************************************************************************

<user= db= host= time=2020-04-22 11:47:06.997 CEST pid=46845 > LOG:  restored log file ""00000001000000B800000098"" from archive
<user= db= host= time=2020-04-22 11:47:07.054 CEST pid=46845 > LOG:  redo starts at B8/98000090
<user= db= host= time=2020-04-22 11:47:07.056 CEST pid=46845 > LOG:  consistent recovery state reached at B8/98004C58
<user= db= host= time=2020-04-22 11:47:07.068 CEST pid=46845 > LOG:  restored log file ""00000001000000B800000099"" from archive
<user= db= host= time=2020-04-22 11:47:07.121 CEST pid=46845 > LOG:  recovery stopping before commit of transaction 5519495, time 2020-03-11 23:19:59.482043+01
<user= db= host= time=2020-04-22 11:47:07.121 CEST pid=46845 > LOG:  redo done at B8/99132730
<user= db= host= time=2020-04-22 11:47:07.121 CEST pid=46845 > LOG:  last completed transaction was at log time 2020-03-11 23:19:39.958408+01
cp: cannot stat `/copyshrd/data/restore/archive/00000002.history': No such file or directory
<user= db= host= time=2020-04-22 11:47:07.128 CEST pid=46845 > LOG:  selected new timeline ID: 2
cp: cannot stat `/copyshrd/data/restore/archive/00000001.history': No such file or directory
<user= db= host= time=2020-04-22 11:47:07.195 CEST pid=46845 > LOG:  archive recovery complete
<user= db= host= time=2020-04-22 11:47:07.197 CEST pid=46847 > LOG:  checkpoint starting: end-of-recovery immediate wait
<user= db= host= time=2020-04-22 11:47:07.236 CEST pid=46847 > LOG:  checkpoint complete: wrote 192 buffers (0.1%); 0 transaction log file(s) added, 0 removed, 0 recycled; write=0.006 s, sync=0.027 s, total=0.040 s; sync files=9, longest=0.005 s, average=0.003 s
<user= db= host= time=2020-04-22 11:47:07.299 CEST pid=46839 > LOG:  database system is ready to accept connections
<user= db= host= time=2020-04-22 11:47:07.299 CEST pid=46853 > LOG:  autovacuum launcher started
{code}
","22/Apr/20 11:49;cs687;Executing the prepared SQL-Command:

{code:java}
enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 edb
psql.bin (9.3.6.19)
Type ""help"" for help.

edb=# \l
                                             List of databases
     Name      |     Owner     | Encoding |   Collate   |    Ctype    |          Access privileges
---------------+---------------+----------+-------------+-------------+-------------------------------------
 edb           | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 m7shrdprodctp | m7shrdprodctp | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7shrdprodctp=CTc/m7shrdprodctp    +
               |               |          |             |             | uapp01m7shrdprodctp=c/m7shrdprodctp+
               |               |          |             |             | umgrcopy=c/m7shrdprodctp           +
               |               |          |             |             | umon01m7shrdprodctp=c/m7shrdprodctp
 postgres      | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0     | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                    +
               |               |          |             |             | enterprisedb=CTc/enterprisedb
 template1     | enterprisedb  | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/enterprisedb                    +
               |               |          |             |             | enterprisedb=CTc/enterprisedb
(5 rows)

edb=# \c m7shrdprodctp
You are now connected to database ""m7shrdprodctp"" as user ""enterprisedb"".
{code}




{code:java}
m7shrdprodctp=# SELECT content FROM TBXC101_PROFILE WHERE exchangeId='EPEXv6' AND userName='CXVITL20' AND environmentId='production';

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 <?xml version='1.0' encoding='UTF-8'?><ProfileContentWithFormatVersion><settings><entry><string>com.deutscheboerse.comxerv.comtrader.jfx.service.sound.SoundService$EPEXv6$TRADE$XBID_Hour_Power</string><string>&lt;?xml version='1.0' encoding='UTF-8'?>&lt;com.deutscheboerse.comxerv.comtrader.jfx.service.sound.SoundTy
 &amp;lt;SplitPanel orientation=""HORIZONTAL"" dividerPositions=""0.249609375,0.499609375,0.749609375"" >
 &amp;lt;SplitPanel orientation=""VERTICAL"" dividerPositions=""0.3890086206896552"" >
 &amp;lt;PanelWrapper persistentId=""486901d0-6ae4-4225-bd1c-e627891790ba"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""c44b701b-be89-46b4-8771-a3d389a17082"" >
 &amp;lt;MagnifiedOrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;PanelWrapper persistentId=""b61afdb5-ecf3-4719-ad40-1024b58e93b9"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;SplitPanel orientation=""VERTICAL"" dividerPositions=""0.665948275862069"" >
 &amp;lt;PanelWrapper persistentId=""cfbb7645-cb04-4dcd-b578-cb0f18378319"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""cafd6c0f-43dc-47f1-a636-6364f6c2e82f"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;PanelWrapper persistentId=""093e2725-475d-4166-b6bf-18f823172d35"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;SplitPanel orientation=""HORIZONTAL"" dividerPositions=""0.301171875,0.66484375"" >
 &amp;lt;PanelWrapper persistentId=""7fefbf26-7f4a-4d53-a402-7d54c0266b40"" >
 &amp;lt;TradesChartPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""c189d14a-0a52-4e1d-8380-c96e3e9fd195"" >
 &amp;lt;OwnOrderPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""856f8378-0715-4b7e-aa95-cda5c75e9ae4"" >
 &amp;lt;BasketPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;SplitPanel orientation=""HORIZONTAL"" dividerPositions=""0.499609375"" >
 &amp;lt;PanelWrapper persistentId=""6d96e1c8-4788-4de5-88cf-7b06d0beb196"" >
 &amp;lt;OwnTradePanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""ebeb17ca-17ac-4193-93f7-979cceea9c13"" >
 &amp;lt;MessagePanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;/SplitPanel>
 &lt;/content>&lt;/com.deutscheboerse.comxerv.comtrader.service.profile.TabState>&lt;com.deutscheboerse.comxerv.comtrader.service.profile.TabState>&lt;title>Own Overview&lt;/title>&lt;content>&amp;lt;SplitPanel orientation=""VERTICAL"" dividerPositions=""0.5735593220338983"" >
 &amp;lt;SplitPanel orientation=""HORIZONTAL"" dividerPositions=""0.333203125,0.664453125"" >
 &amp;lt;PanelWrapper persistentId=""f71f55d4-4b3a-4161-baf0-84f871239145"" >
 &amp;lt;OrderbookBlockPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""6ff1c179-40dc-4e9e-9788-6778a6806dc2"" >
 &amp;lt;TradesChartPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""ae7b1b5f-2da3-4fc7-93b7-559f200df544"" >
 &amp;lt;OrderbookPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;SplitPanel orientation=""HORIZONTAL"" dividerPositions=""0.5"" >
 &amp;lt;PanelWrapper persistentId=""24e00130-4af8-423e-a003-1d791ae79aed"" >
 &amp;lt;OwnTradePanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;PanelWrapper persistentId=""87037249-3f8f-4e34-8490-a7766f9fab5c"" >
 &amp;lt;OwnOrderPanel/>
 &amp;lt;/PanelWrapper>
 &amp;lt;/SplitPanel>
 &amp;lt;/SplitPanel>
 &lt;/content>&lt;/com.deutscheboerse.comxerv.comtrader.service.profile.TabState>&lt;/tabs>&lt;selectedTab>0&lt;/selectedTab>&lt;visibleTabs>true&lt;/visibleTabs>&lt;/com.deutscheboerse.comxerv.comtrader.service.profile.StageState></string></entry></stages></ProfileContentWithFormatVersion>
(1 row)
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,
Reducing RabbitMQ footprint with stretched ESX clusters - external test environments,M7P-6006,94733,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,21/Apr/20 11:50,04/Nov/20 13:01,16/Sep/21 14:11,27/Aug/20 09:47,,6.11.66,7tops_sprint104,,,,,,,7tops,,,,,,,"Previously we had 2 ESX clusters per environment (1 in each DC) so we had to provide critical components in each DC separately.

This resulted in things like two independent RabbitMQ clusters (3 nodes in each) and four back-end and front-end proxies.

 

Now that we are migrating every M7 VM to new ESX cluster we are ending up with all of these VMs from both independent clusters in the same single stretched cluster.

This  makes many VMs completely redundant and unneeded.

For this reason, we want to consolidate at least the most heavy components such as RabbitMQ (and related back-end proxies) and remove many of those unneeded VMs.

 

For instance, currently the VMs with Rabbit MQ nodes are named with a number 1,2,3,4,5,6 at the end.

The VMs are assigned to clusters as follows:

 
 * Node 1,3,5 – RabbitMQ cluster in Equinix
 * Node 2,4,6, - RabbitMQ cluster in Hausen1.

 

But we need to come to a set up where we have single RabbitMQ clusters with this config:

 
 * Node 1,2,3

 

As you can see, this does not fit with the above config, so it requires redeployment of Rabbit nodes themselves, as well as all other components that refer to them by host names (such as back-end proxies, front-end proxies), etc.

 

Also we can reduce back-end proxies amount from 4 to 2, which also will require a redeployment of Core’s configuration.

 

 

*todo with this ticket*
 * use input from M7P-6005 Reducing RabbitMQ footprint with stretched ESX clusters - internal test environments *finished successfully*
 * prepare and immediately merge configuration change for all non-prod environments
 * the change will become effective with the next 6.10 deployment including RabbitMQ and HAProxy restart

 

Next steps todo with next deploymtns:
 * stop environment
 * redeploy rabbitmq
 * redeploy haproxy
 * start environemnt
 * redeploy core
 * redeploy coda
 * redeploy stalker
 * redeploy cardio
 * when

 

Actual state overview

 
||Environment||Done||ticket||
|ELTS CTPB|yes|SERVICE-8024|
|ELTS ACUT| yes|SERVICE-8564|
|ELTS CUTE| yes|SERVICE-8103|
|ELTS LIPA| yes|SERVICE-8564|
|ELTS SIMU| yes|SERVICE-8566|
|EPEX ASIM| yes|SERVICE-8114|
|HUPX CUTE| yes| SERVICE-8022|
|HUPX ASIM| yes|SERVICE-8126|
|HUPX SIMU|yes|SERVICE-8005 |
|BSP CUTE| yes| SERVICE-7838|
|BSP ASIM| yes| SERVICE-8026|
|BSP SIMU| yes|SERVICE-8491|
|PLPX LIPA| yes| solved|
|PLPX SIMU| yes|Planned SERVICE-8493|
|XRPM LIPA| yes| SERVICE-8025|
|XRPM SIMU| yes|SERVICE-8219|
|SHRD SHOW| yes| solved |
|SHRD DST| yes| done with ticket M7P-6869|
|SYS1|yes | |
|SYS2|yes | |
|SYS3|yes | |
|ICSC CUTE| will be handled in the week 26.10 - 30.10 |automatically with ansible|

 

*{color:#de350b}after alll deployments are done we need to stop the bha3,4 and not running amq´s, maybe monitoring as well.{color}*",,cs687,rehapav,xc363,,,,,,,,,,,,,,,,,M7P-6005,,,,,,,,,,,,,,SERVICE-7952,SERVICE-5386,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2091/files 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1056/files

after merging the pulls above, re-deployment of the whole environment is necessary 
tested the changes for non-prod/prod env´s in a checkmode and run it finally on *elts-ctpb* successfully 

all the envs are re-deployed and amq´s are cleaned up (running: amq1,2,3, expecting epex-asim) and just bha1,2 are available. 

",,,,,,,,,,,,,,,,,,,,,,,,27993600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxv73:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 11,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,7tops Sprint 15,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,,,,,,,,,,,,,,,,,,,refer change description. ,3.0,,,,,,,,,"{""issueId"":94733,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"05/May/20 13:30;xc363;Estimation by Roman:
 # change of inventory configuration: 10 minutes (removal and reassignment of instances) per env
 # redeployment of rabbitmq, frontend haproxy, backend haproxy and backend application (requires maintenance of about 15-30 minutes per env)
 # shutdown and removal of additional VMs - decom of IPs, DNS, etc. - about 15 minutes per env","21/Aug/20 08:23;rehapav;[~cv179]

How preparing and merging config from (1) during course of next 3 weeks for all-non prod environments and I would take care for redeployment (2)
while we start with 6.10 acceptance? (foreseen for 15/9+)
Once all environments would be deployed I would trigger step (3)","26/Aug/20 09:13;rehapav;Agreed with [~cv179] (techops) that this ticket should be implemented asap.
 * prepare and merge PRs for all non-prod environments
 * 

[~rehapav] will then plan redeployment of all environments in course of deployment of 6.10.","26/Aug/20 11:16;cs687;prepared a pull-request for the non-prod env´s https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/2091/files and 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/1056/files
[~cv179] & 7tops will review it","27/Aug/20 08:49;cs687;pull request(s) reviewed by [~cv179]
merged and will be tested with elts-ctpb in couple of minutes -> https://jira.deutsche-boerse.com/browse/SERVICE-7952

need to remember to stop the instances after each non-prod deployment
* bha3
* bha4
* amq´s ","27/Aug/20 09:36;rehapav;instructions for any other deployment
 * stop environment
 * redeploy rabbitmq
 * redeploy haproxy
 * start environemnt
 * redeploy core
 * redeploy coda
 * redeploy stalker
 * redeploy cardio
 * when
 * alll deployments are done we need to stop the bha3,4 and not running amq´s, maybe monitoring as well.","27/Aug/20 09:47;cs687;[~rehapav] will take this sleeping ticket and will close it once we are done with non-prod env´s","26/Oct/20 14:18;cs687;done",,,,,,,,,,,,,,,,,,,,
review current Consul TEST setup,M7P-6004,94731,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,rehapav,rehapav,21/Apr/20 11:30,02/Mar/21 13:58,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"As part of the analysis of M7P-5993 we identified that:
Consul TEST cluster (on which Patroni depends) does not currently match PROD and SIMU Consul set up. We use Consul Enterprise in PROD/SIMU, but TEST consul is still running open source version.
 
 
1. Consul TEST cluster needs to be set up using Consul Enterprise (basically we currently don't have Consul cluster for TEST environment that is set up like our PROD and SIMU Consul) (edited) 
 
2. M7 Test DB / Patroni needs to start using the Consul Enterprise Test cluster (edited) 
 
3. XBID TEST needs to use Consul SIMU cluster (because XBID TEST environment is classified as ""SIMU"" in network security matrix)
 
4. M7 TEST environment needs to be moved into new dedicated network that was created for it over a year ago and we did not follow this up (meaning splitting up network for M7 SIMU and M7 TEST hosts)",,cs687,hw120,rehapav,sw455,xx256,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42163200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzzcxb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94731,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/20 13:41;cs687;Consulting [~hw120] for more detailed information´s ","30/Apr/20 16:41;hw120;The main reason for delays of having a test environment the same as simu and prod are network security/firewall restrictions.

I discussed the problem with Andrei and we came up with the following plan.
 * Get new spanned vLANs (TEST, SIMU, PROD) for 'shared services' and for 'data lake' (request already raised for that)
 * Deploy new Consul Enterprise TEST into new spanned 'shared services' TEST vLAN - new dns names, VMs, deployment of consul cluster
 * In parallel with the above, move M7 TEST hosts into new M7 TEST vLAN (that would include M7TESTPDB1 servers) 
 * Move DB replica hosts from single sided 'data lake' TEST vLAN to new spanned 'data lake' TEST vLAN
 * Connect M7 TEST Patroni Cluster to the new Consul Enteprise TEST cluster
 * XBID TEST Patroni Cluster would have to wait till we prepare SIMU spanned vLAN and the new Consul Enterprise SIMU cluster

Steps 3, 4, 5 must be done in one maintenance window as it would be very difficult to separate them","07/May/20 08:57;wm282;[~xx256] is in contact with CCI team about getting new spanned vLANs.","14/May/20 15:18;cs687;*This ticket can taken as a freezer at the moment.*
Like [~hw120] already mentioned there are several things to do. 

Unfortunately its like a big epic-ticket. few steps has to be done until it comes back to us as a M7T/C/A shrd-product task.
SysENg will request new VLAN´s handled by [~xx256]. Please update us about any related status, thanks :) 
Once this is available the proper machines has to move to new M7 TEST Vlan and consul enterprise has to be deployed, properly handled by [~hw120]
mostly the step ""connect m7 TEST Patroni Cluster to the new consul Enterprise TEST cluster"" can be handled by us Product-Support Team (shrd-task m7t/c or m7a), but to do that several weeks will pass. ","15/May/20 15:16;xx256;creation of spanned TEST DMZ is tracked in SYSENG-6",,,,,,,,,,,,,,,,,,,,,,,
Activate netbackup on m7testpdb1/2 ,M7P-5998,94696,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Apr/20 14:28,06/May/20 11:08,16/Sep/21 14:11,23/Apr/20 16:46,,6.8.126,7tops Sprint6,,,,,,24/Apr/20 00:00,M7PRODOPS,,,,,,,"On the hosts *m7testpdb1* and *m7testpdb2* no backup is currently configured. 

At the moment the new agent version is deployed.
{code:java}
[root@m7testpdb1 ~]# cat /usr/openv/netbackup/bin/version
NetBackup-RedHat2.6.32 8.1.2
{code}

as far i understood from nbu-admins we can keep the higher version and just have to deploy the netbackup-role for all the env´s on these hosts and request the new policies via email. 

for these clusters we need to request new polices (amount 15) 
* m7tshrdate5async (/)
* m7tshrdinteasync (/)
* m7tshrdate1async (/)
* m7cshrdate1async (/)
* m7tshrdsyt4async (/) 
* m7ashrdsyt2sync (/)
* m7tshrdshowasync (/)
* m7tshrdate3async (/) 
* m7tshrdate2async (/)
* m7tshrdsyt2async (/)
* m7ashrdsyt1sync (/)
* m7cshrdate5async (/)
* m7tshrdsyt3async (/)
* m7tshrdsyt1async (/)
* m7tshrdate4async (/)
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/20 13:33;cs687;new_policies_m7testpdb12.txt;https://jira.deutsche-boerse.com/secure/attachment/82921/new_policies_m7testpdb12.txt",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44064000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxgqf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94696,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,true,"21/Apr/20 12:32;cs687;https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/824
Had some collisions with the backup script names for shrd environments, therefore this pull-request 

*1.) execute the netbackup scripts with the following command for all the necessary env´s*
*ansible-playbook playbooks/deploy_netbackup.yml --limit ""m7t*shrd*ate5*pdb-async*"" --*tags deploy -k -K -b*


{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/deploy_netbackup.yml --limit ""m7t*shrd*ate5*pdb-async*"" -k -K -b
SSH password:
SUDO password[defaults to SSH password]:

PLAY [deploy patroni resources to an environment] ***************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate5-pdb-async2]
ok: [m7t-shrd-ate5-pdb-async1]

TASK [netbackup : check which patroni-node is running as MASTER/LEADER] *****************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-ate5-pdb-async1]
changed: [m7t-shrd-ate5-pdb-async2]

TASK [netbackup : debug] ****************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate5-pdb-async1] => {}

MSG:

m7testpdb1 is runing as Leader: 0

ok: [m7t-shrd-ate5-pdb-async2] => {}

MSG:

m7testpdb2 is runing as Leader: 1


TASK [netbackup : start fullbackup] *****************************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate5-pdb-async1]
fatal: [m7t-shrd-ate5-pdb-async2]: FAILED! => {
    ""changed"": true,
    ""cmd"": ""/usr/bin/backup-ampgsql#shrdate5#Full.sh"",
    ""delta"": ""0:00:00.004404"",
    ""end"": ""2020-04-21 12:30:58.241705"",
    ""rc"": 127,
    ""start"": ""2020-04-21 12:30:58.237301""
}

STDERR:

/bin/bash: /usr/bin/backup-ampgsql#shrdate5#Full.sh: No such file or directory


MSG:

non-zero return code


TASK [netbackup : check which patroni-node is running as MASTER/LEADER] *****************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-ate5-pdb-async1]

TASK [netbackup : debug] ****************************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate5-pdb-async1] => {}

MSG:

m7testpdb1 is runing as Leader: 0


TASK [netbackup : start incremental backup] *********************************************************************************************************************************************************************************************************************************************************************************
skipping: [m7t-shrd-ate5-pdb-async1]

TASK [netbackup : create state dir] *****************************************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-ate5-pdb-async1]

TASK [netbackup : copy netbackup.ampgsql#env to /etc] ***********************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'netbackup.ampgsql#env.j2', 'dest': '/etc/netbackup.ampgsql#shrdate5'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'netbackup.ampgsql#env.j2', 'dest': '/etc/netbackup.ampgsql#shrdate5#Full', 'netbackup_schedule': 'Full'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'netbackup.ampgsql#env.j2', 'dest': '/etc/netbackup.ampgsql#shrdate5#INCREMENTAL', 'netbackup_schedule': 'INCREMENTAL'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'backup-ampgsql#env.sh.j2', 'dest': '/usr/bin/backup-ampgsql#shrdate5.sh', 'netbackup_filename': '/etc/netbackup.ampgsql#shrdate5'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'backup-ampgsql#env#Full.sh.j2', 'dest': '/usr/bin/backup-ampgsql#shrdate5#Full.sh', 'netbackup_filename': '/etc/netbackup.ampgsql#shrdate5'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'backup-ampgsql#env#INCREMENTAL.sh.j2', 'dest': '/usr/bin/backup-ampgsql#shrdate5#INCREMENTAL.sh', 'netbackup_filename': '/etc/netbackup.ampgsql#shrdate5'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'query-ampgsql#env.sh.j2', 'dest': '/usr/bin/query-ampgsql#shrdate5.sh', 'netbackup_filename': '/etc/netbackup.ampgsql#shrdate5'})
changed: [m7t-shrd-ate5-pdb-async1] => (item={'src': 'restore-ampgsql#env.sh.j2', 'dest': '/usr/bin/restore-ampgsql#shrdate5.sh', 'netbackup_filename': '/etc/netbackup.ampgsql#shrdate5'})

TASK [netbackup : created files] ********************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate5-pdb-async1]

TASK [netbackup : show email] ***********************************************************************************************************************************************************************************************************************************************************************************************
ok: [m7t-shrd-ate5-pdb-async1] => {}

MSG:

Hi Netbackup-Team,

Could you, please, implement additional NetBackup schedules for new Enterprisedb servers in the M7-cluster “m7testpdb1”.
Priorities of NetBackup schedules:
please, set priority in the same way as for existing PLPX schedules on m7testpdb1 (e.g. m7testpdb1.deutsche-boerse.de).

Enterprisedb instances are already active on m7testpdb1.

New scripts and configs are prepared in /usr/bin/ and /etc/ in the same way as done in the past for existing schedules.

-rwxr-xr-x 1 root root 1081 Apr 21 12:31 /etc/netbackup.ampgsql#shrdate5
-rwxr-xr-x 1 root root 1104 Apr 21 12:31 /etc/netbackup.ampgsql#shrdate5#Full
-rwxr-xr-x 1 root root 1111 Apr 21 12:31 /etc/netbackup.ampgsql#shrdate5#INCREMENTAL
-rwxr-xr-x 1 root root 2203 Apr 21 12:31 /usr/bin/backup-ampgsql#shrdate5#Full.sh
-rwxr-xr-x 1 root root 2210 Apr 21 12:31 /usr/bin/backup-ampgsql#shrdate5#INCREMENTAL.sh
-rwxr-xr-x 1 root root 2198 Apr 21 12:31 /usr/bin/backup-ampgsql#shrdate5.sh
-rwxr-xr-x 1 root root 2100 Apr 21 12:31 /usr/bin/query-ampgsql#shrdate5.sh
-rwxr-xr-x 1 root root 3070 Apr 21 12:31 /usr/bin/restore-ampgsql#shrdate5.sh

DNS Names:      M7TESTPDB1.
DNS Domain:     DEUTSCHE-BOERSE.DE
PORT:
Policy Name:    PROD-M7-PGSQL-M7TESTPDB-SHRDATE5

Can you please also check whether the backups for the newly created VMs are already scheduled:

M7SHRDATE5M7B1
M7SHRDATE5M7B2
M7SHRDATE5AMQ1
M7SHRDATE5AMQ2
M7SHRDATE5AMQ3
M7SHRDATE5AMQ4
M7SHRDATE5AMQ5
M7SHRDATE5AMQ6

And please add those jobs to our FFM_Energy in opscenter.
Once it is done, please let us know that we can test it.

Thank you in Advance!



TASK [netbackup : add password to pass file] ********************************************************************************************************************************************************************************************************************************************************************************
changed: [m7t-shrd-ate5-pdb-async1]
        to retry, use: --limit @/home/cs687/ansible/energy.automation.deployments/playbooks/deploy_netbackup.retry

PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************************************************************************
m7t-shrd-ate5-pdb-async1   : ok=10   changed=5    unreachable=0    failed=0
m7t-shrd-ate5-pdb-async2   : ok=3    changed=1    unreachable=0    failed=1

{code}
","21/Apr/20 14:25;cs687;*2.) request new Policies from netbackup-Team*
new schedule procedure for internal test-env´s could be once a month. 

new policies printed in the uploaded file


email sent out:
{code:java}
Hi Michael, 

As we have already spoken about it, here the email with all the new polices. 

Could you, please, implement additional NetBackup schedules for new Postgres servers in the M7-cluster “m7testpdb1 & m7testpdb2”.
Please be also aware that a successful backup can only run on the MASTER node in the patroni-cluster

Priorities of NetBackup schedules:

Postgres instances are already active on m7testpdb1 and m7testpdb2.

And please add those jobs to our FFM_Energy in opscenter.
Once it is done, please let us know that we can test it.

In case of open questions, please reach me out.

Thank you in Advance!

Cheers, 
Steffen 
{code}
","23/Apr/20 10:27;cs687;NBU-ADMIN´s confirmed that the policies were created will check that and close the ticket afterwards.","23/Apr/20 11:34;cs687;still receving some erros will check that with nbu-admins:

{code:java}
[root@m7testpdb1 ~]# /usr/bin/query-ampgsql#m7tshrdsyt1.sh -p PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 | head
Query Started - Thu Apr 23 11:23:03 CEST 2020
/usr/bin/postgres-query --hostname nbuonline2.deutsche-boerse.de --policy PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 --client m7testpdb1.deutsche-boerse.de --app pgsql --property statedir= --property db=template1 --property user=usernetbackup --property max-wal-wait= --property host=m7testpdb1.deutsche-boerse.de --property cleanupwal=YES --property port= --property passfile=/var/lib/pgsql/.pgpass --property tmpdir=/tmp --property psql-path=/usr/pgsql-11/bin/psql --property archivedir=/var/lib/pgsql_m7tshrdsyt1async/backup/11/pg_xlog_archive --property gnutar-path=/bin/tar
Finished Thu Apr 23 11:23:04 CEST 2020
exit 17

[root@m7testpdb1 ~]# /usr/bin/backup-ampgsql#m7tshrdsyt1#Full.sh
Backup Started - Thu Apr 23 11:24:07 CEST 2020
DATASTORE_SERVER =
DATASTORE_POLICY =
DATASTORE_SCHED  =
/usr/bin/postgres-backup --hostname nbuonline2.deutsche-boerse.de --policy PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 --schedule Full --client m7testpdb1.deutsche-boerse.de --app pgsql --application ampgsql --disk /var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async --device /var/lib/pgsql_m7tshrdsyt1async/data/11/m7tshrdsyt1async --property statedir=/var/lib/pgsql_m7tshrdsyt1async/backup/netbackup/ampgsql --property db=template1 --property user=usernetbackup --property max-wal-wait= --property host=m7testpdb1.deutsche-boerse.de --property cleanupwal=YES --property port= --property passfile=/var/lib/pgsql/.pgpass --property tmpdir=/tmp --property psql-path=/usr/pgsql-11/bin/psql --property archivedir=/var/lib/pgsql_m7tshrdsyt1async/backup/11/pg_xlog_archive --property gnutar-path=/bin/tar --property verbose=on
Finished Thu Apr 23 11:26:27 CEST 2020
exit 3


11:24:07.698 [33829] <4> sendRequest: sending BACKUP request to bprd
11:24:07.698 [33829] <4> sendRequest:    request = root root m7testpdb1.deutsche-boerse.de m7testpdb1.deutsche-boerse.de m7testpdb1.deutsche-boerse.de /usr/openv/netbackup/logs/user_ops/dbext/logs/33829.0.1587633847 PROD-M7-PGSQL-M7TESTPDB-M7TSHRDSYT1 Default-Application-Backup 0  0 24 0 C C C C C 0 0 0 0 5
11:24:07.698 [33829] <2> bprd_connect: Ignoring local_name m7testpdb1.deutsche-boerse.de.
11:24:07.698 [33829] <2> bprd_connect: Ignoring owner_name root.
11:24:07.698 [33829] <2> vnet_async_connect: ../../libvlibs/vnet_vnetd.c.4052: connect in progress: 0 0x00000000
11:24:07.700 [33829] <2> version_connect: ../../libvlibs/vnet_vnetd.c.1834: *actual_version: 5 0x00000005
11:24:07.700 [33829] <2> vnet_vnetd_service_socket: ../../libvlibs/vnet_vnetd.c.2054: VN_REQUEST_SERVICE_SOCKET: 6 0x00000006
11:24:07.700 [33829] <2> vnet_vnetd_service_socket: ../../libvlibs/vnet_vnetd.c.2068: service: bprd
11:24:07.743 [33829] <2> vnet_async_connect: ../../libvlibs/vnet_vnetd.c.4238: in progress connect: 0 0x00000000
11:24:07.743 [33829] <2> vnet_async_connect: ../../libvlibs/vnet_vnetd.c.4241: connect: async CONNECT FROM 10.139.58.178.35890 TO 193.29.68.90.13724 fd = 5
11:24:07.743 [33829] <2> logconnections: BPRD CONNECT FROM 10.139.58.178.35890 TO 193.29.68.90.13724
11:24:07.744 [33829] <2> vnet_check_vxss_client_magic_with_info: ../../libvlibs/vnet_vxss_helper.c.840: VxSS not supported: 0 0x00000000
11:24:07.744 [33829] <4> serverResponse: entering serverResponse.
11:24:07.744 [33829] <4> serverResponse: initial client_read_timeout = <900>
11:24:07.744 [33829] <4> readCommMessages: Entering readCommMessages
11:24:17.744 [33829] <4> serverResponse: read comm file:<11:24:08 Initiating backup>
11:24:17.744 [33829] <4> readCommMessages: Entering readCommMessages
11:24:22.744 [33829] <4> serverResponse: read comm file:<11:24:16 INF - Starting bpbrm>
11:24:22.744 [33829] <4> readCommMessages: Entering readCommMessages
11:26:27.749 [33829] <4> serverResponse: read comm file:<11:26:19 INF - Server status = 21>
11:26:27.749 [33829] <16> serverResponse: ERR - server exited with status 21: socket open failed
11:26:27.749 [33829] <16> CreateNewImage: ERR - serverResponse() failed
11:26:27.749 [33829] <4> closeApi: entering closeApi.
11:26:27.749 [33829] <4> closeApi: INF - EXIT STATUS 6: the backup failed to back up the requested files

11:26:27.749 [33829] <16> VxBSACreateObject: ERR - Could not create new image with file /ampgsql-data-0.
11:26:27.749 [33829] <16> Backup: ERROR: BSACreateObject() failed with error: System detected error, operation aborted.
11:26:27.749 [33829] <4> VxBSAEndTxn: INF - entering VxBSAEndTxn.
11:26:27.749 [33829] <4> VxBSAEndTxn: INF - Transaction being ABORTED.
11:26:27.749 [33829] <4> VxBSAGetEnv: INF - entering GetEnv - NBBSA_LOG_DIRECTORY
11:26:27.749 [33829] <4> VxBSAGetEnv: INF - returning -
11:26:27.749 [33829] <4> VxBSAEndTxn: INF - Cleaning directory: </usr/openv/netbackup/logs/exten_client>
11:26:27.749 [33829] <4> delete_old_files: entering delete_old_files.
11:26:27.749 [33829] <8> close_image: Session being terminated abnormally, cleaning up
11:26:27.749 [33829] <4> closeApi: entering closeApi.
11:26:27.749 [33829] <4> closeApi: INF - EXIT STATUS 6: the backup failed to back up the requested files

11:26:27.749 [33829] <4> close_image: INF - backup FAILED
11:26:27.749 [33829] <4> close_image: INF ---- end of Backup ---

11:26:27.749 [33829] <4> VxBSATerminate: INF - entering VxBSATerminate.
11:26:27.749 [33829] <4> VxBSAGetEnv: INF - entering GetEnv - NBBSA_DEBUGFD
11:26:27.749 [33829] <4> VxBSAGetEnv: INF - returning -
""log.042320"" 231L, 20099C      
{code}
","23/Apr/20 16:46;cs687;issue fixed",,,,,,,,,,,,,,,,,,,,,,,
failed restart of M7TESTPDB1/2 (consul),M7P-5993,94682,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Apr/20 12:14,28/Apr/20 23:39,16/Sep/21 14:11,21/Apr/20 12:18,,6.8.126,7tops_Sprint5,,,,,,20/Apr/20 00:00,M7PRODOPS,,,,,,,"seems like when we reboot one test db-host (m7testpdb1 or m7testpdb2)
the last host standing loses the consul members, so consul is not reachable anymore and the patroni cluster is not up and running.
In that case the failovering is not happening and the clusters are not in a healthy mode.

We checked that with [~hw120] and we came to that conclusion that the root cause belongs to the amount of database-machines.  

{code:java}
[root@m7testpdb1 ~]# cat /etc/consul/config.json
    ""retry_join"": [
        ""10.139.58.178"",
        ""10.139.58.177""
    ],
{code}

In the consul configuration file there are listed in *""retry_join""* two IPs which belongs to the database-hosts *m7testpdb1 & m7testpdb2*
This is exactly the list of servers, where consul is trying to connect to them. 

So that consul is working properly both hosts has to be running, to prevent a split-brain scenario. 

We could possible add a 3rd node somewhere to prevent this behavior, in case we are just talking about our internal test-env´s i would skip that. 

The most important question: 
[~hw120] could you please agree the root cause what i was describing above and besides that can you please confirm that with the same maintenance on simu- and prod-hosts we will *not* end up in the same situation, because of higher number of db-hosts and different consul-configuration.

*Simu*
* m7simupdb1
* m7simupdb2
* m7simupdb3
* m7simupdb4

*Prod*
* m7prodpdb1
* m7prodpdb2
* m7prodpdb3
* m7prodpdb4
",,cs687,hw120,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6004,SERVICE-6111,SERVICE-6110,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44323200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxgq7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94682,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/20 14:46;hw120;Problem is that m7testpdbX nodes are not connected to separate consul cluster yet, but rather to 2-node cluster which is running on the same servers are database is.

As consul server cluster needs quorum, with only two server nodes it can't tolerate outage of one server. You need both to be running, to prevent split-brain scenario.","20/Apr/20 14:56;hw120;M7 simu and prod db servers are connected to separate 5 node consul clusters so restart of the pdb node shouldn't influence patroni cluster availability.","21/Apr/20 10:28;rehapav;1) I find strange that we have Patroni set up in Prod and Simu that does not match it's set up in TEST environment

Please [~wm282]  / [~ox626]  / [~cs687] decide if this is acceptable - if not, set test environments same way as it is for SIMU and PRODI

I would personally expect even test with 2 servers behave as SIMU PROD

 ","21/Apr/20 12:18;cs687;can be closed confirmed by [~rehapav]",,,,,,,,,,,,,,,,,,,,,,,,
energy version lookup shows wrong SOB connection,M7P-5990,94677,,Bug,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,cv179,rehapav,rehapav,20/Apr/20 11:23,27/Oct/20 13:24,16/Sep/21 14:11,,,,,,,,,,,7tops,,,,,,,"chec 

[https://github.deutsche-boerse.de/pages/dev/energy.deployment.versions/#sob=true]

 
|m7t|xsop|asim|6.8.90|6.8.90|6.4.19|2.0.38| |*SIMU*|MPLS|28.10.2020, 17:13:25|

 

It says XSOP ASIM is connected to XBID SIMU, however we know its connected to XBID CUTE",,rehapav,ub113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44409600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,20/Apr/20 11:23,,[],,,,,,,,,,,M7T,,,,"2|hzymbr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94677,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Decommission RE for CLTX and NORE,M7P-5989,94674,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,iu252,dp007,dp007,20/Apr/20 11:01,22/Apr/20 15:06,16/Sep/21 14:11,22/Apr/20 12:27,,7tops_Sprint5,,,,RE,,,,Cleartrade,Decommission,M7PRODOPS,,,,,"* stop ctlx and nore tomcats (if running)
 * delete their report dirs
 * delete their tomcat dirs
 * check if they have apache on web server and decommission it there too",,dp007,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,all related files were removed,,,,,,,,Norexeco,,,,,,,,,,,,,,,,44236800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,20/Apr/20 11:01,,[],,,,,,,,,,,M7T,,,,"2|hzxhnb:",9223372036854775807,,,,No,,,,,,,,,,the nore and cltx dir zombie files were left behind,,,,,,,,7tops Sprint 4,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,n/a,,,,,,,,,,"{""issueId"":94674,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"22/Apr/20 11:30;iu252;Nore RE:

Tomcat is not running:

{noformat}
tomcat@m7shrdprodrep2:[/shrd/nore-prod-rep2/tomcat/bin]$ ps -ef | grep tomcat | grep nore-prod
tomcat   12567 12104  0 11:23 pts/0    00:00:00 grep --color=auto nore-prod
tomcat@m7shrdprodrep2:[/shrd/nore-prod-rep2/tomcat/bin]$
{noformat}


{noformat}
tomcat@m7shrdprodrep1:[/shrd]$ ps -ef | grep tomcat | grep nore-prod
tomcat    8587  7740  0 11:24 pts/0    00:00:00 grep --color=auto nore-prod
tomcat@m7shrdprodrep1:[/shrd]$
{noformat}

Deleted tomcats-dirs:


{noformat}
tomcat@m7shrdprodrep1:[/shrd]$ rm -rf nore-prod-rep1*
tomcat@m7shrdprodrep1:[/shrd]$ ls -l nore*
ls: cannot access nore*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd]$

tomcat@m7shrdprodrep1:[/shrd/logs]$ rm -rf nore-prod*
tomcat@m7shrdprodrep1:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd/logs]$
{noformat}


{noformat}
tomcat@m7shrdprodrep2:[/shrd]$ rm -rf  nore-prod-rep2*
tomcat@m7shrdprodrep2:[/shrd]$ ls -l nore-prod-rep2*
ls: cannot access nore-prod-rep2*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd]$

tomcat@m7shrdprodrep2:[/shrd/logs]$ rm -rf nore-prod*
tomcat@m7shrdprodrep2:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd/logs]$
{noformat}


Deleted report-dirs:

{noformat}
tomcat@m7shrdprodrep1:[/shrd/data]$ rm -rf nore-prod*
tomcat@m7shrdprodrep1:[/shrd/data]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd/data]$
{noformat}

{noformat}
tomcat@m7shrdprodrep2:[/shrd/data]$ rm -rf nore-prod*
tomcat@m7shrdprodrep2:[/shrd/data]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd/data]$
{noformat}
","22/Apr/20 11:41;iu252;NORE Web
Apache is not running:
{noformat}
apache@m7shrdprodweb1:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache   32572 31330  0 11:37 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb1:[/shrd]$
{noformat}

{noformat}
apache@m7shrdprodweb2:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache   16837 15865  0 11:34 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb2:[/shrd]$
{noformat}
{noformat}
apache@m7shrdprodweb3:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache   27081 26475  0 11:34 pts/1    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb3:[/shrd]$
{noformat}
{noformat}
apache@m7shrdprodweb4:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache   16132 15719  0 11:34 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb4:[/shrd]$
{noformat}
{noformat}
apache@m7shrdprodweb5:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache    6604  6295  0 11:34 pts/1    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb5:[/shrd]$
{noformat}
{noformat}
apache@m7shrdprodweb6:[/shrd]$ ps -ef | grep apache | grep nore-prod
apache    1727  1233  0 11:34 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb6:[/shrd]$
{noformat}

Deleted nore dirs:
{noformat}
apache@m7shrdprodweb1:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb1:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb1:[/shrd]$

apache@m7shrdprodweb1:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb1:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb1:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb2:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb2:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb2:[/shrd]$

apache@m7shrdprodweb2:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb2:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb2:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb3:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb3:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb3:[/shrd]$

apache@m7shrdprodweb3:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb3:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb3:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb4:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb4:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb4:[/shrd]$

apache@m7shrdprodweb4:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb4:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb4:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb5:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb5:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb5:[/shrd]$

apache@m7shrdprodweb5:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb5:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb5:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb6:[/shrd]$ rm -rf nore-prod*
apache@m7shrdprodweb6:[/shrd]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb6:[/shrd]$

apache@m7shrdprodweb6:[/shrd/logs]$ rm -rf nore-prod*
apache@m7shrdprodweb6:[/shrd/logs]$ ls -l nore-prod*
ls: cannot access nore-prod*: No such file or directory
apache@m7shrdprodweb6:[/shrd/logs]$
{noformat}

","22/Apr/20 11:54;iu252;CLTX RE
Checked if tomcat is running, deleted tomcat-dirs:


{noformat}
tomcat@m7shrdprodrep1:[/shrd]$ ps -ef | grep tomcat | grep cltx-prod
tomcat   11744  7740  0 11:51 pts/0    00:00:00 grep --color=auto cltx-prod
tomcat@m7shrdprodrep1:[/shrd]$ rm -rf cltx-prod*
tomcat@m7shrdprodrep1:[/shrd]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd]$

tomcat@m7shrdprodrep1:[/shrd/logs]$ rm -rf cltx-prod*
tomcat@m7shrdprodrep1:[/shrd/logs]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd/logs]$

tomcat@m7shrdprodrep1:[/shrd/data]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep1:[/shrd/data]$
{noformat}


{noformat}
tomcat@m7shrdprodrep2:[/shrd]$ rm -rf cltx-prod*
tomcat@m7shrdprodrep2:[/shrd]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd]$

tomcat@m7shrdprodrep2:[/shrd/logs]$ rm -rf cltx-prod*
tomcat@m7shrdprodrep2:[/shrd/logs]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd/logs]$

tomcat@m7shrdprodrep2:[/shrd/data]$ ll cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
tomcat@m7shrdprodrep2:[/shrd/data]$
{noformat}
","22/Apr/20 12:12;iu252;CLTX WEB
Checked if apache is running, deleted apache-dirs:

{noformat}
apache@m7shrdprodweb1:[/shrd/logs]$ ps -ef | grep apache | grep cltx-prod
apache    6761 31330  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb1:[/shrd/logs]$ cd ..
apache@m7shrdprodweb1:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache    6789 31330  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb1:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb1:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb1:[/shrd]$ cd logs
apache@m7shrdprodweb1:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb1:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb1:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb2:[/shrd/logs]$ ps -ef | grep apache | grep cltx-prod
apache   23884 15865  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb2:[/shrd/logs]$ cd ..
apache@m7shrdprodweb2:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache   23910 15865  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb2:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb2:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb2:[/shrd]$ cd logs
apache@m7shrdprodweb2:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb2:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb2:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb3:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache    1208 26475  0 12:09 pts/1    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb3:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb3:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb3:[/shrd]$ cd logs
apache@m7shrdprodweb3:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb3:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb3:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb4:[/shrd/logs]$ ps -ef | grep apache | grep cltx-prod
apache   22677 15719  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb4:[/shrd/logs]$ cd ..
apache@m7shrdprodweb4:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache   22822 15719  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb4:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb4:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb4:[/shrd]$ cd logs
apache@m7shrdprodweb4:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb4:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb4:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb5:[/shrd/logs]$ ps -ef | grep apache | grep cltx-prod
apache   13400  6295  0 12:09 pts/1    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb5:[/shrd/logs]$ cd ..
apache@m7shrdprodweb5:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache   13422  6295  0 12:09 pts/1    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb5:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb5:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb5:[/shrd]$ cd logs
apache@m7shrdprodweb5:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb5:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb5:[/shrd/logs]$
{noformat}
{noformat}
apache@m7shrdprodweb6:[/shrd/logs]$ ps -ef | grep apache | grep cltx-prod
apache    8595  1233  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb6:[/shrd/logs]$ cd ..
apache@m7shrdprodweb6:[/shrd]$ ps -ef | grep apache | grep cltx-prod
apache    8632  1233  0 12:09 pts/0    00:00:00 grep --color=auto cltx-prod
apache@m7shrdprodweb6:[/shrd]$ rm -rf cltx-prod*
apache@m7shrdprodweb6:[/shrd]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb6:[/shrd]$ cd logs
apache@m7shrdprodweb6:[/shrd/logs]$ rm -rf cltx-prod*
apache@m7shrdprodweb6:[/shrd/logs]$ ls -l cltx-prod*
ls: cannot access cltx-prod*: No such file or directory
apache@m7shrdprodweb6:[/shrd/logs]$
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,
Migrate EBSM to Patroni Postgres,M7P-5988,94668,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,20/Apr/20 10:01,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 07:42,,6.10.123,7tops_sprint9_,,,EBSM,,,,EBSM,M7PRODOPS,,,,,,"M7P-5526 established empty database for EBSM.

TODO
 * move data (DB2 -> Patroni)
 * migrate ebsm to new data source",,dp007,jw756,op211,,,,,,,,,,,,,,,INIT-530,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,[https://github.deutsche-boerse.de/dev/energy.ebsm/pull/24/commits/0d2085c57cf4550b946826a9dbb0ea51b7fe2be6],,,,,,,,,,,,,,,,,,,,,,,,38275200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxhm7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94668,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/May/20 11:05;dp007;'X' = done
'-' = won't do
|TYPE|SCHEMA| |STRUCTURE|DATA|
|TABLE|DB2S0XM|TBXM010_GNRL_SYS_JOBS|X|TODO|
|TABLE|DB2S0XM|TBXM020_GNRL_DIM_DATE|X|TODO|
|TABLE|DB2S0XM|TBXM030_GNRL_DIM_SCHEMAS|X|TODO|
|TABLE|DB2S0XM|TBXM031_GNRL_DIM_INSTANCES|X|X|
|TABLE|DB2S0XM|TBXM032_GNRL_DIM_DBMS|X|TODO|
|TABLE|DB2S0XM|TBXM033_GNRL_DIM_LOGPANEL|-|-|
|TABLE|DB2S0XM|TBXM100_CPCY_DIM_METHODS|X|TODO|
|TABLE|DB2S0XM|TBXM101_CPCY_DIM_TSO|X|TODO|
|TABLE|DB2S0XM|TBXM102_CPCY_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXM103_CPCY_DIM_METHODGROUPS|X|TODO|
|TABLE|DB2S0XM|TBXM104_CPCY_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM150_CPCY_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM151_CPCY_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXM152_CPCY_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM153_CPCY_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM156_CPCY_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM157_CPCY_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM158_CPCY_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXM170_CPCY_KPI_SLAS|X|TODO|
|TABLE|DB2S0XM|TBXM171_CPCY_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM172_CPCY_KPI_MEASURES|X|TODO|
|TABLE|DB2S0XM|TBXM173_CPCY_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM174_CPCY_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM300_CXXP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM302_CXXP_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXM303_CXXP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM304_CXXP_DIM_LOGEVENTS|X|TODO|
|TABLE|DB2S0XM|TBXM350_CXXP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM351_CXXP_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXM352_CXXP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM353_CXXP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM356_CXXP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM357_CXXP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM358_CXXP_AGG_PERCENTILEN_D|X|TODO|
|TABLE|DB2S0XM|TBXM359_CXXP_AGG_PERCENTILEN_D2|X|TODO|
|TABLE|DB2S0XM|TBXM360_CXXP_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM361_CXXP_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXM370_CXXP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM371_CXXP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM372_CXXP_KPI_MEASURES|X|TODO|
|TABLE|DB2S0XM|TBXM373_CXXP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM374_CXXP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM375_CXXP_KPI_CALENDAR|X|TODO|
|TABLE|DB2S0XM|TBXM376_CXXP_KPI_FEPERCENTILEN|X|TODO|
|TABLE|DB2S0XM|TBXM377_CXXP_KPI_CALENDAR_HA|X|TODO|
|TABLE|DB2S0XM|TBXM400_CXSP_DIM_METHODS|X|TODO|
|TABLE|DB2S0XM|TBXM402_CXSP_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXM403_CXSP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM404_CXSP_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM450_CXSP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM451_CXSP_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXM452_CXSP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM453_CXSP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM456_CXSP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM457_CXSP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM460_CXSP_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM461_CXSP_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXM470_CXSP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM471_CXSP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM472_CXSP_KPI_MEASURES|X|TODO|
|TABLE|DB2S0XM|TBXM473_CXSP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM474_CXSP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM475_CXSP_KPI_CALENDAR|X|TODO|
|TABLE|DB2S0XM|TBXM476_CXSP_KPI_FEPERCENTILEN|X|TODO|
|TABLE|DB2S0XM|TBXM500_CXHU_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM502_CXHU_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXM503_CXHU_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM504_CXHU_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM550_CXHU_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM552_CXHU_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM553_CXHU_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM556_CXHU_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM557_CXHU_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM560_CXHU_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM561_CXHU_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXM570_CXHU_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM571_CXHU_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM572_CXHU_KPI_MEASURES|X|TODO|
|TABLE|DB2S0XM|TBXM573_CXHU_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM574_CXHU_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM575_CXHU_KPI_CALENDAR|X|TODO|
|TABLE|DB2S0XM|TBXM576_CXHU_KPI_FEPERCENTILEN|X|TODO|
|TABLE|DB2S0XM|TBXM600_EUAP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM602_EUAP_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXM603_EUAP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM650_EUAP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM652_EUAP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM653_EUAP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM656_EUAP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM657_EUAP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM670_EUAP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM671_EUAP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM672_EUAP_KPI_MEASURES|X|TODO|
|TABLE|DB2S0XM|TBXM673_EUAP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM674_EUAP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM675_EUAP_KPI_CALENDAR|X|TODO|
|TABLE|DB2S0XM|TBXM700_GRLO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXM702_GRLO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXM703_GRLO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXM750_GRLO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXM752_GRLO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXM753_GRLO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXM756_GRLO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXM757_GRLO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXM800_TIGW_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXM802_TIGW_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXM803_TIGW_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXM804_TIGW_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXM852_TIGW_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXM856_TIGW_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXM861_TIGW_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXM870_TIGW_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXM871_TIGW_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXM872_TIGW_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXM873_TIGW_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXM874_TIGW_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXM875_TIGW_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXM950_GVPO_LOG_CPU_UTILIZATION|-|-|
|TABLE|DB2S0XM|TBXM951_GVPO_LOG_FREE_MEMORY|-|-|
|TABLE|DB2S0XM|TBXM970_GVPO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXM971_GVPO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXM972_GVPO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXM973_GVPO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXM974_GVPO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXM975_GVPO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMA00_CXNO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMA02_CXNO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMA03_CXNO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMA04_CXNO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMA50_CXNO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMA52_CXNO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMA53_CXNO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMA56_CXNO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMA57_CXNO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMA61_CXNO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMA70_CXNO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMA71_CXNO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMA72_CXNO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMA73_CXNO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMA74_CXNO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMA75_CXNO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMAAA_CXXP_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMB00_CTCO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMB02_CTCO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMB03_CTCO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMB04_CTCO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMB50_CTCO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMB52_CTCO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMB53_CTCO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMB56_CTCO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMB57_CTCO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMB61_CTCO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMB70_CTCO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMB71_CTCO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMB72_CTCO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMB73_CTCO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMB74_CTCO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMB75_CTCO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMBBB_CXXP_LOG_FE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMC00_CTTS_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMC02_CTTS_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMC03_CTTS_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMC04_CTTS_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMC50_CTTS_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMC52_CTTS_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMC53_CTTS_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMC56_CTTS_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMC57_CTTS_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMC61_CTTS_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMC70_CTTS_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMC71_CTTS_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMC72_CTTS_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMC73_CTTS_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMC74_CTTS_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMC75_CTTS_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMD00_CTFI_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMD02_CTFI_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMD03_CTFI_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMD04_CTFI_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMD50_CTFI_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMD52_CTFI_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMD53_CTFI_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMD56_CTFI_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMD57_CTFI_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMD61_CTFI_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMD70_CTFI_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMD71_CTFI_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMD72_CTFI_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMD73_CTFI_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMD74_CTFI_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMD75_CTFI_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXME04_MTHU_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXME61_MTHU_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMF04_MTNO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMF61_MTNO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMG04_XBID_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMG61_XBID_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMH00_CXPL_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXMH02_CXPL_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXMH03_CXPL_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXMH04_CXPL_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXMH50_CXPL_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXMH51_CXPL_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXMH52_CXPL_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXMH53_CXPL_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXMH56_CXPL_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXMH57_CXPL_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXMH58_CXPL_AGG_PERCENTILEN_D|X|TODO|
|TABLE|DB2S0XM|TBXMH59_CXPL_AGG_PERCENTILEN_D2|X|TODO|
|TABLE|DB2S0XM|TBXMH60_CXPL_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXMH61_CXPL_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXMH70_CXPL_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXMH71_CXPL_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXMH72_CXPL_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXMH73_CXPL_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXMH74_CXPL_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXMH75_CXPL_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXMH76_CXPL_KPI_FEPERCENTILEN|X|TODO|
|TABLE|DB2S0XM|TBXMI00_CXRP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXMI02_CXRP_DIM_USERS|X|TODO|
|TABLE|DB2S0XM|TBXMI03_CXRP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXMI04_CXRP_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXMI50_CXRP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXMI51_CXRP_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXMI52_CXRP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXMI53_CXRP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXMI56_CXRP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXMI57_CXRP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXMI58_CXRP_AGG_PERCENTILEN_D|X|TODO|
|TABLE|DB2S0XM|TBXMI59_CXRP_AGG_PERCENTILEN_D2|X|TODO|
|TABLE|DB2S0XM|TBXMI60_CXRP_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXMI61_CXRP_LOG_SCANRESULTS|X|TODO|
|TABLE|DB2S0XM|TBXMI70_CXRP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXMI71_CXRP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXMI72_CXRP_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXMI73_CXRP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXMI74_CXRP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXMI75_CXRP_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXMI76_CXRP_KPI_FEPERCENTILEN|X|TODO|
| | | | | |
|TABLE|DB2S0XM|CPCY_KPI_AVAILABILITY_V1|X|-|
|TABLE|DB2S0XM|CPCY_KPI_AVAILABILITY_V2|X|-|
|TABLE|DB2S0XM|CTCO_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTCO_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CTFI_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTFI_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CTTS_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTTS_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXHU_KPI_AVAILABILITY_V1|X|-|
|TABLE|DB2S0XM|CXHU_KPI_AVAILABILITY_V2|X|-|
|TABLE|DB2S0XM|CXNO_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXNO_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXSP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXSP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXXP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXXP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|EUAP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|EUAP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|TIGW_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|TIGW_KPI_AVAILABILITY_V2|-|-|
| | | | | |
|VIEW|DB2ZXMS3|CXHU_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXHU_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXPL_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXPL_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXRP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXRP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1291_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1291_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1503_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1503_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1520_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1520_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1525_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1525_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1540_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1540_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|EUAP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|EUAP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|GVPO_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|GVPO_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|TIGW_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|TIGW_KPI_AVAILABILITY_V2|-|-|","15/Jun/20 15:21;dp007;'X' = done
 '-' = won't do
|TYPE|SCHEMA| |STRUCTURE|DATA|
|TABLE|DB2S0XM|TBXM010_GNRL_SYS_JOBS|X|TODO|
|TABLE|DB2S0XM|TBXM020_GNRL_DIM_DATE|X|TODO|
|TABLE|DB2S0XM|TBXM030_GNRL_DIM_SCHEMAS|X|TODO|
|TABLE|DB2S0XM|TBXM031_GNRL_DIM_INSTANCES|X|X|
|TABLE|DB2S0XM|TBXM032_GNRL_DIM_DBMS|X|X|
|TABLE|DB2S0XM|TBXM033_GNRL_DIM_LOGPANEL|-|-|
|TABLE|DB2S0XM|TBXM100_CPCY_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM101_CPCY_DIM_TSO|X|X|
|TABLE|DB2S0XM|TBXM102_CPCY_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXM103_CPCY_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM104_CPCY_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM150_CPCY_AGG_RESPONSETIMES_H1|X|X|
|TABLE|DB2S0XM|TBXM151_CPCY_AGG_RESPONSETIMES_D2|X|X|
|TABLE|DB2S0XM|TBXM152_CPCY_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM153_CPCY_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM156_CPCY_AGG_RESPONSETIMES_D1|X|X|
|TABLE|DB2S0XM|TBXM157_CPCY_AGG_RESPONSETIMES_M1|X|X|
|TABLE|DB2S0XM|TBXM158_CPCY_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXM170_CPCY_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM171_CPCY_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM172_CPCY_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXM173_CPCY_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM174_CPCY_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM300_CXXP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM302_CXXP_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXM303_CXXP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM304_CXXP_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM350_CXXP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM351_CXXP_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXM352_CXXP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM353_CXXP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM356_CXXP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM357_CXXP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM358_CXXP_AGG_PERCENTILEN_D|X|TODO|
|TABLE|DB2S0XM|TBXM359_CXXP_AGG_PERCENTILEN_D2|X|TODO|
|TABLE|DB2S0XM|TBXM360_CXXP_LOG_FE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM361_CXXP_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXM370_CXXP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM371_CXXP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM372_CXXP_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXM373_CXXP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM374_CXXP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM375_CXXP_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXM376_CXXP_KPI_FEPERCENTILEN|X|X|
|TABLE|DB2S0XM|TBXM377_CXXP_KPI_CALENDAR_HA|X|X|
|TABLE|DB2S0XM|TBXM400_CXSP_DIM_METHODS|X|TODO|
|TABLE|DB2S0XM|TBXM402_CXSP_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXM403_CXSP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM404_CXSP_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM450_CXSP_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM451_CXSP_AGG_RESPONSETIMES_D2|X|TODO|
|TABLE|DB2S0XM|TBXM452_CXSP_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM453_CXSP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM456_CXSP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM457_CXSP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM460_CXSP_LOG_FE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXM461_CXSP_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXM470_CXSP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM471_CXSP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM472_CXSP_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXM473_CXSP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM474_CXSP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM475_CXSP_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXM476_CXSP_KPI_FEPERCENTILEN|X|X|
|TABLE|DB2S0XM|TBXM500_CXHU_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM502_CXHU_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXM503_CXHU_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM504_CXHU_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXM550_CXHU_AGG_RESPONSETIMES_H1|X|TODO|
|TABLE|DB2S0XM|TBXM552_CXHU_LOG_BE_RESPONSETIMES|X|TODO|
|TABLE|DB2S0XM|TBXM553_CXHU_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXM556_CXHU_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM557_CXHU_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM560_CXHU_LOG_FE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXM561_CXHU_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXM570_CXHU_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM571_CXHU_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXM572_CXHU_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXM573_CXHU_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM574_CXHU_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM575_CXHU_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXM576_CXHU_KPI_FEPERCENTILEN|X|X|
|TABLE|DB2S0XM|TBXM600_EUAP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXM602_EUAP_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXM603_EUAP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXM650_EUAP_AGG_RESPONSETIMES_H1|X|X|
|TABLE|DB2S0XM|TBXM652_EUAP_LOG_BE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXM653_EUAP_LOG_CONCURRENTUSERS|X|X|
|TABLE|DB2S0XM|TBXM656_EUAP_AGG_RESPONSETIMES_D1|X|TODO|
|TABLE|DB2S0XM|TBXM657_EUAP_AGG_RESPONSETIMES_M1|X|TODO|
|TABLE|DB2S0XM|TBXM670_EUAP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXM671_EUAP_KPI_AVAILABILITY|X|X|
|TABLE|DB2S0XM|TBXM672_EUAP_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXM673_EUAP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXM674_EUAP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXM675_EUAP_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXM700_GRLO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXM702_GRLO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXM703_GRLO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXM750_GRLO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXM752_GRLO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXM753_GRLO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXM756_GRLO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXM757_GRLO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXM800_TIGW_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXM802_TIGW_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXM803_TIGW_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXM804_TIGW_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXM852_TIGW_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXM856_TIGW_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXM861_TIGW_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXM870_TIGW_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXM871_TIGW_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXM872_TIGW_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXM873_TIGW_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXM874_TIGW_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXM875_TIGW_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXM950_GVPO_LOG_CPU_UTILIZATION|-|-|
|TABLE|DB2S0XM|TBXM951_GVPO_LOG_FREE_MEMORY|-|-|
|TABLE|DB2S0XM|TBXM970_GVPO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXM971_GVPO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXM972_GVPO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXM973_GVPO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXM974_GVPO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXM975_GVPO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMA00_CXNO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMA02_CXNO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMA03_CXNO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMA04_CXNO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMA50_CXNO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMA52_CXNO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMA53_CXNO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMA56_CXNO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMA57_CXNO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMA61_CXNO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMA70_CXNO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMA71_CXNO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMA72_CXNO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMA73_CXNO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMA74_CXNO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMA75_CXNO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMAAA_CXXP_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMB00_CTCO_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMB02_CTCO_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMB03_CTCO_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMB04_CTCO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMB50_CTCO_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMB52_CTCO_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMB53_CTCO_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMB56_CTCO_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMB57_CTCO_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMB61_CTCO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMB70_CTCO_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMB71_CTCO_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMB72_CTCO_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMB73_CTCO_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMB74_CTCO_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMB75_CTCO_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMBBB_CXXP_LOG_FE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMC00_CTTS_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMC02_CTTS_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMC03_CTTS_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMC04_CTTS_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMC50_CTTS_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMC52_CTTS_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMC53_CTTS_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMC56_CTTS_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMC57_CTTS_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMC61_CTTS_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMC70_CTTS_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMC71_CTTS_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMC72_CTTS_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMC73_CTTS_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMC74_CTTS_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMC75_CTTS_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXMD00_CTFI_DIM_METHODS|-|-|
|TABLE|DB2S0XM|TBXMD02_CTFI_DIM_USERS|-|-|
|TABLE|DB2S0XM|TBXMD03_CTFI_DIM_METHODGROUPS|-|-|
|TABLE|DB2S0XM|TBXMD04_CTFI_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMD50_CTFI_AGG_RESPONSETIMES_H1|-|-|
|TABLE|DB2S0XM|TBXMD52_CTFI_LOG_BE_RESPONSETIMES|-|-|
|TABLE|DB2S0XM|TBXMD53_CTFI_LOG_CONCURRENTUSERS|-|-|
|TABLE|DB2S0XM|TBXMD56_CTFI_AGG_RESPONSETIMES_D1|-|-|
|TABLE|DB2S0XM|TBXMD57_CTFI_AGG_RESPONSETIMES_M1|-|-|
|TABLE|DB2S0XM|TBXMD61_CTFI_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMD70_CTFI_KPI_SLAS|-|-|
|TABLE|DB2S0XM|TBXMD71_CTFI_KPI_AVAILABILITY|-|-|
|TABLE|DB2S0XM|TBXMD72_CTFI_KPI_MEASURES|-|-|
|TABLE|DB2S0XM|TBXMD73_CTFI_KPI_VALUESDAY|-|-|
|TABLE|DB2S0XM|TBXMD74_CTFI_KPI_VALUESMONTH|-|-|
|TABLE|DB2S0XM|TBXMD75_CTFI_KPI_CALENDAR|-|-|
|TABLE|DB2S0XM|TBXME04_MTHU_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXME61_MTHU_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMF04_MTNO_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMF61_MTNO_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMG04_XBID_DIM_LOGEVENTS|-|-|
|TABLE|DB2S0XM|TBXMG61_XBID_LOG_SCANRESULTS|-|-|
|TABLE|DB2S0XM|TBXMH00_CXPL_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXMH02_CXPL_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXMH03_CXPL_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXMH04_CXPL_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXMH50_CXPL_AGG_RESPONSETIMES_H1|X|X|
|TABLE|DB2S0XM|TBXMH51_CXPL_AGG_RESPONSETIMES_D2|X|X|
|TABLE|DB2S0XM|TBXMH52_CXPL_LOG_BE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXMH53_CXPL_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXMH56_CXPL_AGG_RESPONSETIMES_D1|X|X|
|TABLE|DB2S0XM|TBXMH57_CXPL_AGG_RESPONSETIMES_M1|X|X|
|TABLE|DB2S0XM|TBXMH58_CXPL_AGG_PERCENTILEN_D|X|X|
|TABLE|DB2S0XM|TBXMH59_CXPL_AGG_PERCENTILEN_D2|X|X|
|TABLE|DB2S0XM|TBXMH60_CXPL_LOG_FE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXMH61_CXPL_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXMH70_CXPL_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXMH71_CXPL_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXMH72_CXPL_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXMH73_CXPL_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXMH74_CXPL_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXMH75_CXPL_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXMH76_CXPL_KPI_FEPERCENTILEN|X|X|
|TABLE|DB2S0XM|TBXMI00_CXRP_DIM_METHODS|X|X|
|TABLE|DB2S0XM|TBXMI02_CXRP_DIM_USERS|X|X|
|TABLE|DB2S0XM|TBXMI03_CXRP_DIM_METHODGROUPS|X|X|
|TABLE|DB2S0XM|TBXMI04_CXRP_DIM_LOGEVENTS|X|X|
|TABLE|DB2S0XM|TBXMI50_CXRP_AGG_RESPONSETIMES_H1|X|X|
|TABLE|DB2S0XM|TBXMI51_CXRP_AGG_RESPONSETIMES_D2|X|X|
|TABLE|DB2S0XM|TBXMI52_CXRP_LOG_BE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXMI53_CXRP_LOG_CONCURRENTUSERS|X|TODO|
|TABLE|DB2S0XM|TBXMI56_CXRP_AGG_RESPONSETIMES_D1|X|X|
|TABLE|DB2S0XM|TBXMI57_CXRP_AGG_RESPONSETIMES_M1|X|X|
|TABLE|DB2S0XM|TBXMI58_CXRP_AGG_PERCENTILEN_D|X|X|
|TABLE|DB2S0XM|TBXMI59_CXRP_AGG_PERCENTILEN_D2|X|X|
|TABLE|DB2S0XM|TBXMI60_CXRP_LOG_FE_RESPONSETIMES|X|X|
|TABLE|DB2S0XM|TBXMI61_CXRP_LOG_SCANRESULTS|X|X|
|TABLE|DB2S0XM|TBXMI70_CXRP_KPI_SLAS|X|X|
|TABLE|DB2S0XM|TBXMI71_CXRP_KPI_AVAILABILITY|X|TODO|
|TABLE|DB2S0XM|TBXMI72_CXRP_KPI_MEASURES|X|X|
|TABLE|DB2S0XM|TBXMI73_CXRP_KPI_VALUESDAY|X|TODO|
|TABLE|DB2S0XM|TBXMI74_CXRP_KPI_VALUESMONTH|X|TODO|
|TABLE|DB2S0XM|TBXMI75_CXRP_KPI_CALENDAR|X|X|
|TABLE|DB2S0XM|TBXMI76_CXRP_KPI_FEPERCENTILEN|X|X|
| | | | | |
|TABLE|DB2S0XM|CPCY_KPI_AVAILABILITY_V1|X|-|
|TABLE|DB2S0XM|CPCY_KPI_AVAILABILITY_V2|X|-|
|TABLE|DB2S0XM|CTCO_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTCO_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CTFI_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTFI_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CTTS_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CTTS_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXHU_KPI_AVAILABILITY_V1|X|-|
|TABLE|DB2S0XM|CXHU_KPI_AVAILABILITY_V2|X|-|
|TABLE|DB2S0XM|CXNO_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXNO_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXSP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXSP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|CXXP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|CXXP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|EUAP_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|EUAP_KPI_AVAILABILITY_V2|-|-|
|TABLE|DB2S0XM|TIGW_KPI_AVAILABILITY_V1|-|-|
|TABLE|DB2S0XM|TIGW_KPI_AVAILABILITY_V2|-|-|
| | | | | |
|VIEW|DB2ZXMS3|CXHU_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXHU_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXNO_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXPL_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXPL_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXRP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXRP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|CXSP_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXSP_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1291_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1291_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1503_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1503_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1520_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1520_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1525_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1525_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1540_V1|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_1540_V2|X|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|CXXP_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|EUAP_KPI_AVAILABILITY_V1|X|-|
|VIEW|DB2ZXMS3|EUAP_KPI_AVAILABILITY_V2|X|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ACTIVEUSER_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_FEPERCENTILEN_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_FEPERCENTILEN_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_OMT_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_OMT_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ORDERS_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_ORDERS_V2|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_TRADES_V1|-|-|
|VIEW|DB2ZXMS3|GNRL_KPI_TRADES_V2|-|-|
|VIEW|DB2ZXMS3|GVPO_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|GVPO_KPI_AVAILABILITY_V2|-|-|
|VIEW|DB2ZXMS3|TIGW_KPI_AVAILABILITY_V1|-|-|
|VIEW|DB2ZXMS3|TIGW_KPI_AVAILABILITY_V2|-|-|","30/Jun/20 07:41;dp007;EBSM fully migrated to PostgreSQL database at m7simupdb4.

[https://github.deutsche-boerse.de/dev/energy.ebsm/pull/24/commits/0d2085c57cf4550b946826a9dbb0ea51b7fe2be6]",,,,,,,,,,,,,,,,,,,,,,,,,
Fix CT profile server configuration,M7P-5985,94646,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,pd122,yo218,yo218,17/Apr/20 14:49,05/Nov/20 13:23,16/Sep/21 14:11,20/Jul/20 13:20,,7tops_sprint12,,,,PS,,,30/Apr/20 00:00,7tops,,,,,,,"During the production deployment of the CT profile server deployment I figured out that the listening port was incorrect. It was listening to port 63100 while the webserver was trying to connect to port 63000. I fixed it manually on the host as I was running out of time. Please find the proper entry and fix it in inventory

AC:
 * Prepare Ansible role for the Apache web server (copy paste it from old configuration we already have)
 * Prepare entries in inventories for all the environments
 * Prepare JIRA tickets for the deployment on customer facing environments so we can keep the track of them
",,fh971,pd122,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6604,,,,,M7P-6584,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"inventory updated to reflect different settings for different environments, production instances re-deployed",,,,,,,,,,,,,,,,,,,,,,,,36547200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,,,,,"2|hzmufz:",9223372036854775807,,,,No,,,,,,,,,,default setting (from deployment repo) effective in all environments as environment specific settings are missing in the inventory,,,,,,,,6.12 non RC,,,,,,,,,,,,,,,,,,,,,,,,,,Ansible deployment of an instance,4.0,,,,,,,,,"{""issueId"":94646,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"16/Jul/20 11:54;pd122;as the port value is not specified in the inventory, default value (from _m7ctp_ role in _energy.automation.deployments_ repo) is currently used for deployment to *ALL* (inte, exte, prod) environments:
{code:java}
defaults/main.yml:server_conn_port_ajp: 63100{code}","16/Jul/20 12:59;pd122;temporary inventory hosts removed to allow successful CTP deployment via a Jenkins job:

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1980","16/Jul/20 14:29;pd122;port numbers entered into the inventory for each of 3 environments in [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1988] 

merged","17/Jul/20 13:44;pd122;* existing target DB dropped and recreated based on template for mtt DB present in the INSTALL directory at the root of this instance on host m7prodpdb2
 * source db dumped
 * db, users renamed in the dump
 * dump copied over to targed db host and imported
 * db migration (deployment) attempted","17/Jul/20 14:05;pd122;migration ([https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/9260/console) |https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/9260/console(]failed with 
{code:java}
ERROR: Found non-empty schema(s) ""m7tshrdprodctp"" without schema history table! Use baseline() or set baselineOnMigrate to true to initialize the schema history table.{code}","17/Jul/20 14:11;pd122;after consulting with [~HO764] and [~fj021] , fix from M7P-6580 was tried:
{code:java}
m7tshrdprodctp=# ALTER TABLE schema_version RENAME TO flyway_schema_history;
ALTER TABLE
m7tshrdprodctp=# ALTER TABLE flyway_schema_history DROP CONSTRAINT schema_version_pk;
ALTER TABLE
m7tshrdprodctp=# ALTER TABLE flyway_schema_history ADD CONSTRAINT flyway_schema_history_pk PRIMARY KEY (installed_rank);
ALTER TABLE{code}
then deployment re-ran with _""flyway_repair_migration=true""_ :  [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/9262/console]

that seemed to work","17/Jul/20 14:12;pd122;ready now to shut down old CTP instance and start newly deployed one instead","20/Jul/20 13:09;pd122;old instances were shut down and new instances started instead

old instances disabled:

 
{code:java}
[pd122@m7shrdprodctp1 ~]$ ls -ld /shrd/m7*
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp1.bkp
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp1.disabled
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp3.bkp
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp3.disabled 
{code}
 
{code:java}
[pd122@m7shrdprodctp2 ~]$ ls -ld /shrd/m7*
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp2.bkp
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp2.disabled
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp4.bkp
drwxrwxr-x 3 tomcat tomcat 4096 Dec 14 2018 /shrd/m7-prod-ctp4.disabled{code}","20/Jul/20 13:15;pd122;M7P-6604 created to migrate the web deployment to Ansible to finally complete this thing",,,,,,,,,,,,,,,,,,,
Remove m7gtigcsimuamq1/2 from monitoring,M7P-5980,94627,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,iu252,iu252,17/Apr/20 09:21,23/Sep/20 11:32,16/Sep/21 14:11,15/Sep/20 08:42,,6.11.9,7tops_sprint15,,,Monitoring,,,,M7PRODOPS,,,,,,,"We have alerts for these server:
m7gtigcsimuamq1 is not sending metrics data.
m7gtigcsimuamq2 is not sending metrics data.


They are not in use imho. Have been created for TIG RabbitMQ, but TIG was never migrated from Mainframe to us. In the meantime, TIG is dead.",,cs687,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"changed nothing:
 * mentioned machines are already decommissioned (entries in cms are also removed)

in the influx db can be some data of this env but it will be also removed after one year. So we will not touch the db, in case there are some data left, it will not harm us. ",,,,,,,,,,,,,,,,,,,,,,,,31622400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzn6cf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,described in the change description. ,,,,,,,,,,"{""issueId"":94627,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Sep/20 08:42;cs687;done",,,,,,,,,,,,,,,,,,,,,,,,,,,
ICS CuTE - Apply configs to the newly created AT-CH IC,M7P-5975,94586,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,qz412,qz412,16/Apr/20 10:55,28/Apr/20 23:39,16/Sep/21 14:11,16/Apr/20 12:01,,6.8.126,7tops_Sprint5,,,ICS,,,,M7PRODOPS,,,,,,,"Please

1) merge following PR:

[https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/160|https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/160/files]

2) Redeploy CMI in ICS CuTE.

Coordinated with the customers, the CuTE is currently available for our testing activities for AT-CH border setup. This change is needed for testing of the AT-CH border configuration.

 ",,cs687,qz412,,,,,,,,,,,,,,,,,,M7P-5923,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44755200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxgo7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94586,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"16/Apr/20 11:56;cs687;will be solved with the service ticket https://jira.deutsche-boerse.com/browse/SERVICE-6102",,,,,,,,,,,,,,,,,,,,,,,,,,,
review ESXMIG: migration plan & remove deprecated machines & logically group plan,M7P-5974,94585,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,rehapav,rehapav,rehapav,16/Apr/20 10:51,21/May/20 10:23,16/Sep/21 14:11,23/Apr/20 10:35,,6.10.54,7tops_sprint7,,,,,,21/Apr/20 00:00,7tops,7tops_comm,,,,,,"in linked ticket you can find actual version of complete ESX cluster migration plan:

SERVICE-5385 ESXMIG: migration of VMs and Hosts to Energy owned ESX cluster

 

ad 1)  I need a thorough *review* of the actual plan  for migration all our M7T and M7A PROD VMs.

It includes a timeline and chosen per-partes approach.

(date/time for phase 4 can change by management decision)

 

ad 2) review yellow machines
 * List: [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F05%20M7%20Trading%2FInfrastructure&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7BB91642FD%2D7D32%2D4F21%2D8FBB%2DF503B3712788%7D]
 * list has already pre-marked with yellow some strange VMs
 * that according to host name or according to CMS information should not even be hosted on M7 PROD cluster
 * so first point: those yellow rows need to be clarified if they belong to M7 PROD
 * 

ad 3) group VMs logically
 * List: [https://teams.deutsche-boerse.de/sites/sp0232/SP%20-%20Energy/Forms/AllItems.aspx?RootFolder=%2Fsites%2Fsp0232%2FSP%20%2D%20Energy%2F05%20M7%20Trading%2FInfrastructure&FolderCTID=0x012000D79254D6A3CC144F85EB351C5826C344&View=%7BB91642FD%2D7D32%2D4F21%2D8FBB%2DF503B3712788%7D]
 * *group VMs in logical units that should be migrated together based on the timeline*
 * 

Deadline 22/4

 

{color:#de350b} *Development review is mandatory*{color}

 ",,pd122,rehapav,wm282,,,,,,,,,,,,,,,M7P-5981,,SERVICE-5385,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,rehapav,sw455,,,,tbd,,,,,,,,,,,,,,,,,,ax460,pw231,,,,,,,,41817600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxi07:",9223372036854775807,,,,No,,,,,,tbd,,,,,,,,,,,,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94585,""testStatuses"":[]}",,,,tbd,,,,,,,,,,,,,,,,,,PROD,,,,"17/Apr/20 10:06;pd122;3) VMs were split into 9 groups based on product and client (new *Group* column has been added), VMs shared across clients were put into separate group 9.","17/Apr/20 11:05;pd122;2) 

m7gtigcprodamq[12],  xbdpladap[12]_old : to be removed

m7shrdprodrep[12]-new                               : update to be provided next week (VMs likely to be deleted)

m7inteldap[12]                                                : removed from inventory (PR #1777), to be removed","17/Apr/20 18:04;wm282;Please give me a go next week (after confirming about _shrdprodrep__ VMs) and I will decommission / destroy all of the VMs mentioned in Urban's comment. 
It would be best to clean them before migration, so we don't need to explain extra stuff to CloudAdmins and concentrate on migration.","22/Apr/20 12:50;pd122;all marked VMs are to go","22/Apr/20 12:53;pd122;marked hosts removed from the document","22/Apr/20 12:57;pd122;[~rehapav] you may now assign the task to a developer for review.","23/Apr/20 10:00;rehapav;Sheet reviewed

[~wm282] based on the comment from Urban above - you are free to go to get rid of unused machines","20/May/20 11:19;wm282;VMs have been removed.",,,,,,,,,,,,,,,,,,,,
ICS PROD : Get result of SELECT Query,M7P-5972,94580,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fj021,fj021,16/Apr/20 09:10,28/Apr/20 23:39,16/Sep/21 14:11,16/Apr/20 09:43,,6.8.126,7tops_Sprint5,,,,,,,M7PRODOPS,,,,,,,"Hello,

 

We would like to have the result of the following query on the Core DB of ICS PROD : 
{code:java}
select *
from cmm_230_inter_connector
where
((area_1_eic = '10YAT-APG------L' and area_2_eic = '10YCH-SWISSGRIDZ' ) 
or 
(area_1_eic = '10YCH-SWISSGRIDZ' and area_2_eic = '10YAT-APG------L'));
{code}
The DB should be : *m7ppg12-prodepex*

 

Thanks !",,cs687,fj021,qz412,,,,,,,,,,,,,,,M7P-5810,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44755200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxh6v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94580,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"16/Apr/20 09:42;cs687;output of the sql-execution:
{code:java}
m7epexprodm7b=# select * from cmm_230_inter_connector where ((area_1_eic = '10YAT-APG------L' and area_2_eic = '10YCH-SWISSGRIDZ' ) or (area_1_eic = '10YCH-SWISSGRIDZ' and area_2_eic = '10YAT-APG------L'));
 connector_id | version | cost_factor | area_1_eic | area_2_eic | border_id | status_id
--------------+---------+-------------+------------+------------+-----------+-----------
(0 rows)

{code}
","16/Apr/20 09:48;qz412;Yeah, this script needs to run once the IC is created in Prod. This step will be done as part of the new bordrer introduction. I will link this ticket to ICS Prod deployment so it does not get forgotten.",,,,,,,,,,,,,,,,,,,,,,,,,,
Update sob_trustStore.jks file for XBID Connectivity ,M7P-5968,94562,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,15/Apr/20 15:05,29/Jun/20 12:44,16/Sep/21 14:11,24/Apr/20 09:16,,6.8.126,7tops Sprint6,,,,,,,7tops_comm,M7PRODOPS,,,,,,"During a deployment (https://jira.deutsche-boerse.com/browse/SERVICE-6078) we figured out that the sob_trustStore.jks will expire for most of the M7 Environment until end of May

The sob_trustStore is used for the authentication of the xbid-connectivity with the related XBID certificate.

*We have different CA´s in-place.*
* AddTrust External CA Root, which will expire 30 of May
{code:java}
Common Name: AddTrust External CA Root
Organization: AddTrust AB
Organization Unit: AddTrust External TTP Network
Country: SE
Valid From: May 30, 2000
Valid To: May 30, 2020
Issuer: AddTrust External CA Root, AddTrust AB
Serial Number: 1 (0x1)
{code}

* USERTrust RSA Certification Authority which will also expire 30 of May 
{code:java}
Common Name: USERTrust RSA Certification Authority
Organization: The USERTRUST Network
Locality: Jersey City
State: New Jersey
Country: US
Valid From: May 30, 2000
Valid To: May 30, 2020
Issuer: AddTrust External CA Root, AddTrust AB Write review of Sectigo
Serial Number: 13ea28705bf4eced0c36630980614336
{code}

* and Sectigo RSA Organization Validation Secure Server CA, which expire end of 2030
{code:java}
Common Name: Sectigo RSA Organization Validation Secure Server CA
Organization: Sectigo Limited
Locality: Salford
State: Greater Manchester
Country: GB
Valid From: November 1, 2018
Valid To: December 31, 2030
Issuer: USERTrust RSA Certification Authority, The USERTRUST Network Write review of Sectigo
Serial Number: 137d539caa7c31a9a433701968847a8d
{code}

So the plan is to us the truststore with *CN: ""Sectigo RSA Organization Validation Secure Server CA""* which is already in use for *elts-prod* and *xsop-asim*

the following steps are necessary:
* 1.) figure out the env´s which are using *NOT* Sectigo Truststore 
* 2.) updating vault secret m7core and update the sob_truststore with the proper password
* 3.) re-deploy cor 
* 4.) checking with health-check if xbid is properly connected. 

With that command it can be checked if the truststore was updated and has the proper expiration date:  (example with xsop-asim) 
tomcat@m7xsopasimm7b1:[/home/tomcat]$ cd /xsop/xsop-asim-cor1/tomcat/lib/
tomcat@m7xsopasimm7b1:[/xsop/xsop-asim-cor1/tomcat/lib]$ keytool -list -v -keystore trustStore.jks
{code:java}
Owner: CN=USERTrust RSA Certification Authority, O=The USERTRUST Network, L=Jersey City, ST=New Jersey, C=US
Issuer: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Serial number: 13ea28705bf4eced0c36630980614336
Valid from: Tue May 30 12:48:38 CEST 2000 until: Sat May 30 12:48:38 CEST 2020
{code}


##############################################################################################
*List of M7 Environment which need to update sob-trustStore:*
* elts-cute *(planned to update with SERVICE-6098)*
* xsop-cute 
* xsop-simu 
* xrpm-lipa
* xrpm-simu
* plpx-lipa
* plpx-simu
* hupx-cute
* hupx-asim
* hupx-simu
* elts-acut
* elts-lipa
* elts-simu


Just checked it with Roman, we need the following owner:
{code:java}
Owner: CN=COMODO RSA Certification Authority, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Issuer: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Valid from: Tue May 30 12:48:38 CEST 2000 until: Sat May 30 12:48:38 CEST 2020

Owner: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Issuer: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Valid from: Tue May 30 12:48:38 CEST 2000 until: Sat May 30 12:48:38 CEST 2020

Owner: CN=COMODO RSA Organization Validation Secure Server CA, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Issuer: CN=COMODO RSA Certification Authority, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Valid from: Wed Feb 12 01:00:00 CET 2014 until: Mon Feb 12 00:59:59 CET 2029
   accessMethod: caIssuers

Owner: CN=Sectigo RSA Organization Validation Secure Server CA, O=Sectigo Limited, L=Salford, ST=Greater Manchester, C=GB
Issuer: CN=USERTrust RSA Certification Authority, O=The USERTRUST Network, L=Jersey City, ST=New Jersey, C=US
Valid from: Fri Nov 02 01:00:00 CET 2018 until: Wed Jan 01 00:59:59 CET 2031
   accessMethod: caIssuers

Owner: CN=USERTrust RSA Certification Authority, O=The USERTRUST Network, L=Jersey City, ST=New Jersey, C=US
Issuer: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Valid from: Tue May 30 12:48:38 CEST 2000 until: Sat May 30 12:48:38 CEST 2020
{code}

",,cs687,iv732,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/20 12:01;iv732;image-2020-04-16-12-01-47-595.png;https://jira.deutsche-boerse.com/secure/attachment/82671/image-2020-04-16-12-01-47-595.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44064000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxhzz:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94562,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/20 12:03;iv732;Added two new CAs , and removed two expired CAs  from the truststore.

Now it looks like this:

 

!image-2020-04-16-12-01-47-595.png!

Truststore is base64 encoded and store under: [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/xsop/asim/m7core/sob_truststore?redirect_to=%2Fvault%2Fsecrets]

 ","16/Apr/20 14:00;rehapav;* xsop-cute
 ** execute 22/4 between 10:00 - 11:00
 * xsop-simu
 ** execute 22/4 between 11:00 - 12:00
 * xrpm-lipa
 ** execute 22/4 between 13:00 - 14:00
 * xrpm-simu
 ** execute 22/4 between 14:00 - 15:00
 * plpx-lipa
 ** execute 23/4 between 9:00 - 11:00
 * plpx-simu
 ** execute 23/4 between 9:00 - 11:00
 * hupx-cute
 ** execute 23/4 between 12:00 - 15:00
 * hupx-asim
 ** execute 23/4 between 12:00 - 15:00
 * hupx-simu
 ** execute 23/4 between 12:00 - 15:00
 * elts-acut
 ** xecute 24/4 between 9:00 - 12:00
 * elts-lipa
 ** xecute 24/4 between 9:00 - 12:00
 * elts-simu
 ** xecute 24/4 between 9:00 - 12:00","22/Apr/20 10:48;cs687;*Starting with xsop-cute*
1.) updated vault-settings -> m7t/xsop/cute/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7xsopcutem7b1:[/xsop]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7xsopcutem7b1:[/xsop]$
{code}

status after the deployment:
{code:java}
tomcat@m7xsopcutem7b1:[/xsop/xsop-cute-cor1/tomcat/lib]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7xsopcutem7b1:[/xsop/xsop-cute-cor1/tomcat/lib]$

{code}

","22/Apr/20 11:15;cs687;*Starting with xsop-simu*
1.) updated vault-settings -> m7t/xsop/simu/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7xsopsimum7b1:[/xsop]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7xsopsimum7b1:[/xsop]$
{code}

status after the deployment:
{code:java}
tomcat@m7xsopsimum7b1:[/xsop/xsop-simu-cor1/tomcat/lib]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7xsopsimum7b1:[/xsop/xsop-simu-cor1/tomcat/lib]$
{code}
","22/Apr/20 13:02;cs687;*Starting with xrpm-lipa*
1.) updated vault-settings -> m7t/xrpm/lipa/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
[tomcat@m7xrpmlipam7b1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[tomcat@m7xrpmlipam7b1 ~]$
{code}

status after the deployment:
{code:java}

[tomcat@m7xrpmlipam7b1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[tomcat@m7xrpmlipam7b1 ~]$
{code}

","23/Apr/20 09:20;cs687;*Starting with xrpm-simu*
1.) updated vault-settings -> m7t/xrpm/simu/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
[tomcat@m7xrpmsimum7b1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""[tomcat@m7xrpmsimum7b1 ~]$
{code}
status after the deployment:
{code:java}
[tomcat@m7xrpmsimum7b1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[tomcat@m7xrpmsimum7b1 ~]$
{code}

","23/Apr/20 09:27;cs687;*Starting with plpx-lipa*
1.) updated vault-settings -> m7t/plpx/lipa/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7plpxlipam7b1:[/plpx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7plpxlipam7b1:[/plpx]$
{code}
status after the deployment:
{code:java}
tomcat@m7plpxlipam7b1:[/plpx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7plpxlipam7b1:[/plpx]$
{code}","23/Apr/20 09:35;cs687;*Starting with plpx-simu*
1.) updated vault-settings -> m7t/plpx/simu/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7plpxsimum7b1:[/plpx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7plpxsimum7b1:[/plpx]$
{code}
status after the deployment:
{code:java}
tomcat@m7plpxsimum7b1:[/plpx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7plpxsimum7b1:[/plpx]$
{code}

","23/Apr/20 12:15;cs687;*Starting with hupx-cute*
1.) updated vault-settings -> m7t/hupx/cute/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7hupxcutem7b1:[/hupx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7hupxcutem7b1:[/hupx]$
{code}
status after the deployment:
{code:java}
tomcat@m7hupxcutem7b1:[/hupx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""status"":""UP""},""m7"":{""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}You have new mail in /var/spool/mail/tomcat
tomcat@m7hupxcutem7b1:[/hupx]$
{code}
","23/Apr/20 12:20;cs687;*Starting with hupx-asim*
1.) updated vault-settings -> m7t/hupx/asim/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment:
{code:java}
tomcat@m7hupxasimm7b1:[/hupx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7hupxasimm7b1:[/hupx]$
{code}
status after the deployment:
{code:java}
tomcat@m7hupxasimm7b1:[/hupx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7hupxasimm7b1:[/hupx]$
{code}","23/Apr/20 12:26;cs687;*Starting with hupx-simu*
1.) updated vault-settings -> m7t/hupx/simu/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status after the deployment:
{code:java}
tomcat@m7hupxsimum7b1:[/hupx]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7hupxsimum7b1:[/hupx]$
{code}","24/Apr/20 08:03;cs687;*Starting with elts-acut*
1.) updated vault-settings -> m7t/elts/acut/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment: (both are running as slave) 
{code:java}
tomcat@m7eltsacutm7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""DOWN"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""DOWN"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}

tomcat@m7eltsacutm7b2:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""DOWN"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""DOWN"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}tomcat@m7eltsacutm7b2:[/elts]$
{code}
status after the deployment:
{code:java}
tomcat@m7eltsacutm7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""tomcat@m7eltsacutm7b1:[/elts]$
{code}","24/Apr/20 08:10;cs687;*Starting with elts-lipa*
1.) updated vault-settings -> m7t/elts/lipa/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment: (both are running as slave) 
{code:java}
tomcat@m7eltslipam7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""tomcat@m7eltslipam7b1:[/elts]$
{code}
status after the deployment:
{code:java}
tomcat@m7eltslipam7b1:[/elts]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}tomcat@m7eltslipam7b1:[/elts]$
{code}","24/Apr/20 08:12;cs687;*Starting with elts-simu*
1.) updated vault-settings -> m7t/elts/simu/m7core/sob_truststore and backuped the old sob_truststore value
2.) redeployment of cor
status before the deployment: (both are running as slave) 
{code:java}
[tomcat@m7eltssimum7c1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}[tomcat@m7eltssimum7c1 ~]$
{code}
status after the deployment:
{code:java}
[tomcat@m7eltssimum7c1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""[tomcat@m7eltssimum7c1 ~]$
{code}",,,,,,,,,,,,,,
CODA alerting - found cross orderbook,M7P-5962,94553,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Won't Do,,ax460,ax460,15/Apr/20 14:13,11/Mar/21 13:48,16/Sep/21 14:11,16/Apr/20 08:53,,7tops_Sprint5,,,,M7 BE,,,,7tops,M7PRODOPS,,,,,,"CODA writtes data to elastic search (in kibana index = m7-code-*), usually there is crossed:false.

We need to introduce alert in slack in case CODA write crossed:true to start investigation of crossed order book for any prod env.",,ax460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5960,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44755200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmu1j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,6.12 non RC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94553,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/20 08:52;ax460;There are already alerts in place in m7_alerts slack channel.",,,,,,,,,,,,,,,,,,,,,,,,,,,
CODA and Cardio alerting - availability on ELTS PROD,M7P-5960,94551,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,jv861,jv861,15/Apr/20 13:56,06/May/20 11:08,16/Sep/21 14:11,04/May/20 09:13,,6.10.27,7tops Sprint6,,,,,,,7tops,7tops_comm,M7PRODOPS,,,,,"We need to keep CODA up and running on ELTS PROD. We usually find out too late, that the CODA is not running and because of that we miss data, that could really help the investigation of problems. Similar for Cardio

So we need a standard (slack) notification when CODA or Cardio is down, or maybe even automatic restart, if possible.

Both CODA and Cardio have an endpoint {{/health}}, so whenever it says DOWN (or when it doesn't respond), we should get an alert and attempt to restart it.",,iu252,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43200000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1469,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxi0n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94551,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"28/Apr/20 09:10;iu252;[~jv861]Kamil, I have some questions regarding CODA and Cardio monitoring:
* do we have dedicated ports for both?
* cardio is running on 2 hosts, do we need to monitor both instances?","28/Apr/20 09:12;iu252;CODA was not running on englobmon2, started it and check on which port CODA is running:

{noformat}
[tomcat@englobmon2 elts-prod-coda1]$ ./start.sh
nohup: redirecting stderr to stdout
[tomcat@englobmon2 elts-prod-coda1]$ ps -ef | grep coda
tomcat   105661      1 99 08:59 pts/0    00:00:16 /opt/java/default/bin/java -Xms256M -Xmx256M -jar /elts/elts-prod-coda1/crossed-orderbook-detector-app.jar --spring.config.additional-location=file:/elts/elts-prod-coda1/application.yml --logging.config=file:/elts/elts-prod-coda1/logback.xml --spring.profiles.active=epex
tomcat   105795  23163  0 08:59 pts/0    00:00:00 grep --color=auto coda

[tomcat@englobmon2 elts-prod-coda1]$ netstat -tlpn | grep 105661
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:61047           0.0.0.0:*               LISTEN      105661/java

[tomcat@englobmon2 elts-prod-coda1]$ curl localhost:61047/coda/health
{""status"":""UP""}[tomcat@englobmon2 elts-prod-coda1]$
{noformat}


Checked status of Cardio on englobmon2:

{noformat}
[tomcat@englobmon2 elts-prod-lb-cardio1]$ ps -ef | grep cardio
tomcat    96342      1  4 08:51 pts/0    00:01:06 /opt/java/default/bin/java -Xms64M -Xmx128M -jar /elts/elts-prod-lb-cardio1/cardio.jar --spring.config.additional-location=file:/elts/elts-prod-lb-cardio1/application.yml --logging.config=file:/elts/elts-prod-lb-cardio1/logback.xml --spring.profiles.active=epex
tomcat   127588  23163  0 09:18 pts/0    00:00:00 grep --color=auto cardio
(reverse-i-search)`cardio': cd /elts/elts-lipa-lb-^Crdio1/
[tomcat@englobmon2 elts-prod-lb-cardio1]$ netstat -tlpn | grep 96342
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:61046           0.0.0.0:*               LISTEN      96342/java
[tomcat@englobmon2 elts-prod-lb-cardio1]$ curl localhost:61046/cardio/health
{""status"":""UP""}[tomcat@englobmon2 elts-prod-lb-cardio1]$
{noformat}


Checked status of Cardio on m7eltsprodm7b1:


{noformat}
tomcat@m7eltsprodm7b1:[/elts]$ ps -ef | grep cardio
tomcat   20600     1  6 Feb26 ?        3-20:42:03 /opt/java/default/bin/java -Xms64M -Xmx128M -jar /elts/elts-prod-rmq-cardio1/cardio.jar --spring.confi                         g.additional-location=file:/elts/elts-prod-rmq-cardio1/application.yml --logging.config=file:/elts/elts-prod-rmq-cardio1/logback.xml --spring.profiles.a                         ctive=epex
tomcat   20740     1  6 Feb26 ?        3-19:28:23 /opt/java/default/bin/java -Xms64M -Xmx128M -jar /elts/elts-prod-rmq-cardio2/cardio.jar --spring.confi                         g.additional-location=file:/elts/elts-prod-rmq-cardio2/application.yml --logging.config=file:/elts/elts-prod-rmq-cardio2/logback.xml --spring.profiles.a                         ctive=epex
tomcat   20822     1  6 Feb26 ?        3-19:22:30 /opt/java/default/bin/java -Xms64M -Xmx128M -jar /elts/elts-prod-rmq-cardio3/cardio.jar --spring.confi                         g.additional-location=file:/elts/elts-prod-rmq-cardio3/application.yml --logging.config=file:/elts/elts-prod-rmq-cardio3/logback.xml --spring.profiles.a                         ctive=epex
tomcat   21498 19705  0 09:37 pts/0    00:00:00 grep --color=auto cardio

tomcat@m7eltsprodm7b1:[/elts]$ netstat -tlpn | grep 20600
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:61066           0.0.0.0:*               LISTEN      20600/java
tomcat@m7eltsprodm7b1:[/elts]$ curl http://localhost:61066/cardio/health
{""status"":""UP""}

tomcat@m7eltspronetstat -tlpn | grep 20740
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:61067           0.0.0.0:*               LISTEN      20740/java
tomcat@m7eltsprodm7b1:[/elts]$ curl http://localhost:61067/cardio/health
{""status"":""UP""}

tomcat@m7eltspronetstat -tlpn | grep 20822
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:61068           0.0.0.0:*               LISTEN      20822/java
tomcat@m7eltsprodm7b1:[/elts]$ curl http://localhost:61068/cardio/health
{""status"":""UP""}tomcat@m7eltsprodm7b1:[/elts]$
{noformat}
","28/Apr/20 09:17;iu252;Created PR 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1809","28/Apr/20 11:08;jv861;Ports are defined in energy automation deployments, for coda, its
{code}
PORT_APP_DIGIT: 7
server_port: ""61{{ PORT_ENV_DIGIT }}{{ PORT_CUST_DIGIT }}{{ PORT_APP_DIGIT }}""
{code}

For Cario, it's more complicated, the default template for the port is similar:
{code}
PORT_APP_DIGIT: 6
server_port: ""61{{ PORT_ENV_DIGIT }}{{ PORT_CUST_DIGIT }}{{ PORT_APP_DIGIT }}""
{code}

But for particulal instances, there are these overrides:
{code}
- lb-cardio1:
    ansible_host: englobmon2
    PORT_CUST_DIGIT: 4  # ELTS PROD acts as EPEX prod from outside/customer point of view

- rmq-cardio1:
    ansible_host: m7eltsprodm7b1

- rmq-cardio2:
    ansible_host: m7eltsprodm7b1
    PORT_APP_DIGIT: 7

- rmq-cardio3:
    ansible_host: m7eltsprodm7b1
    PORT_APP_DIGIT: 8
{code}

I don't know how exactly to transfer it to the PR above, since there are more Cardio instances with different ports","30/Apr/20 11:42;iu252;modified https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1809","04/May/20 09:12;iu252;CODA and Cardio alerting implemented on ELTS PROD.
Thank you [~hw120].",,,,,,,,,,,,,,,,,,,,,,
coda and cardio tools should be deployable via deployment pipeline,M7P-5957,94547,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,15/Apr/20 13:33,21/May/20 10:23,16/Sep/21 14:11,14/May/20 11:43,,6.10.51,7tops_sprint7,,,,,,,7tops_comm,M7PRODOPS,,,,,,coda and cardio tools should be deployable via deployment pipeline,,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1469,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxi1r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94547,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"30/Apr/20 13:43;cs687;Asking [~cv179] for assistance.","30/Apr/20 13:57;cs687;Talked to Roman:

We need to update the Deployment Pipeline Job.
When the ansible-playbook for coda and cardio is available it´s just an easy copy/paste job.

Coda:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/coda

Cardio:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/tree/master/roles/cardio","12/May/20 09:17;cs687;Pipeline-Job: *deploy_custom* approved by [~cv179] and merged 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/866/files

https://stackoverflow.com/questions/40049917/jenkins-pipeline-script-fails-with-general-error-during-class-generation-metho


{code:java}
java.lang.RuntimeException: Method code too large!
	at groovyjarjarasm.asm.MethodWriter.a(Unknown Source)
	at groovyjarjarasm.asm.ClassWriter.toByteArray(Unknown Source)
	at org.codehaus.groovy.control.CompilationUnit$17.call(CompilationUnit.java:827)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1065)
	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:603)
	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:581)
	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:558)
	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:298)
	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:268)
	at groovy.lang.GroovyShell.parseClass(GroovyShell.java:688)
	at groovy.lang.GroovyShell.parse(GroovyShell.java:700)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.doParse(CpsGroovyShell.java:142)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.reparse(CpsGroovyShell.java:127)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.parseScript(CpsFlowExecution.java:561)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.start(CpsFlowExecution.java:522)
	at org.jenkinsci.plugins.workflow.job.WorkflowRun.run(WorkflowRun.java:331)
	at hudson.model.ResourceController.execute(ResourceController.java:97)
	at hudson.model.Executor.run(Executor.java:428)
1 error
	at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:310)
	at org.codehaus.groovy.control.CompilationUnit.applyToPrimaryClassNodes(CompilationUnit.java:1085)
	at org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:603)
	at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:581)
	at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:558)
	at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:298)
	at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:268)
	at groovy.lang.GroovyShell.parseClass(GroovyShell.java:688)
	at groovy.lang.GroovyShell.parse(GroovyShell.java:700)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.doParse(CpsGroovyShell.java:142)
	at org.jenkinsci.plugins.workflow.cps.CpsGroovyShell.reparse(CpsGroovyShell.java:127)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.parseScript(CpsFlowExecution.java:561)
	at org.jenkinsci.plugins.workflow.cps.CpsFlowExecution.start(CpsFlowExecution.java:522)
	at org.jenkinsci.plugins.workflow.job.WorkflowRun.run(WorkflowRun.java:331)
	at hudson.model.ResourceController.execute(ResourceController.java:97)
	at hudson.model.Executor.run(Executor.java:428)
Finished: FAILURE
{code}

[~cv179] adviced me to create a separated function *def prepare_parameters()*
to get rid of the big stage 
*stage('get prepare parameters') *
","12/May/20 12:07;cs687;coda/cardio via pipeline deployment - list hosts: 

{code:java}
[deploy_custom] $ ansible-playbook playbooks/deploy_coda.yml -l m7t-shrd-syt1-* -t stop --skip-tags=slack --list-hosts -e artifact_version=1.0.95
 [WARNING]: While constructing a mapping from /home/jenkins/workspace/Energy-
Operations/CD-Pipeline/deploy_custom/energy.automation.inventory/inventory/m7t/
shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict key
(additional_params). Using last defined value only.
playbook: playbooks/deploy_coda.yml

  play #1 (coda): Deploy coda instance	TAGS: []
    pattern: ['coda']
    hosts (1):
      m7t-shrd-syt1-coda_1
{code}


{code:java}
[WARNING]: While constructing a mapping from /home/jenkins/workspace/Energy-
Operations/CD-Pipeline/deploy_custom/energy.automation.inventory/inventory/m7t/
shrd/syt3/m7_load_runner/vars.yml, line 1, column 1, found a duplicate dict key
(additional_params). Using last defined value only.
playbook: playbooks/deploy_coda.yml

  play #1 (coda): Deploy coda instance	TAGS: []
    pattern: ['coda']
    hosts (1):
      m7t-shrd-syt1-coda_1
{code}

","13/May/20 08:13;cs687;Coda/Cardio is not part of M7P Bundle at the moment. We should think about it to include these modules also to the bundle? [~rehapav]

TO-DO: 
add Textboxs
* cod_version
* car_version 
for deploying coda/cardio ","14/May/20 09:01;cs687;[~cv179] prepared a pull-request to kill some code-lines 
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/875/files

currently running in a duplicated jenkins job 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/workspace/job/deploy_newdef/
","14/May/20 11:38;rehapav;_Coda/Cardio is not part of M7P Bundle at the moment. We should think about it to include these modules also to the bundle?_ 



No, we decided in Development community that these shouldn't be part of product bundle. These are our internal monitoring tools that get deployed separatelly on as-needed basis",,,,,,,,,,,,,,,,,,,,,
PROD ICSC Certificate will expire Jun2020,M7P-5951,94502,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,cs687,cs687,15/Apr/20 07:54,22/Apr/20 15:06,16/Sep/21 14:11,15/Apr/20 07:55,,7tops_Sprint5,,,,,,,,M7PRODOPS,,,,,,,certificate m7/icsc/prod/prod2_ics_m7c_deutsche-boerse_com_cert.cer will expire at Jun 13 23:59:59 2020 GMT,,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44841600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxguv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94502,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"15/Apr/20 07:55;cs687;already duplicate existing can be closed. ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Disable password expiration on SYT1 and SYT3,M7P-5948,94481,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,oy574,oy574,14/Apr/20 13:13,05/Jan/21 14:08,16/Sep/21 14:11,15/Apr/20 12:34,,6.10.14,6.10.15,7tops_Sprint5,,,,,,M7PRODOPS,,,,,,,Please disable the password expiration policy on LDAP for SYT1 and SYT3.,,oy574,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Removed password policy from Syt1 and Syt3.

By default, the m7 policy on all test environments only implement locking after 5 bad retries but no expiration.",,,,,,,,,,,,,,,,,,,,,,,,44841600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgnz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94481,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"15/Apr/20 12:02;pd122;Already existing password policies for *SYT1*:

 
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordLockout: off
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
cn: cn=nsPwPolicyEntry,ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test
 
{code}
 

and *SYT3*:
{code:java}
dn: cn=cn\3DnsNoPwPolicyEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordLockoutDuration: 900
passwordUnlock: off
passwordResetFailureCount: 900
passwordMaxFailure: 3
passwordLockout: on
passwordStorageScheme: ssha256
passwordMinTokenLength: 3
passwordMinCategories: 0
passwordMaxRepeats: 0
passwordMin8bit: 0
passwordMinSpecials: 0
passwordMinLowers: 0
passwordMinUppers: 0
passwordMinAlphas: 0
passwordMinDigits: 0
passwordMinLength: 8
passwordCheckSyntax: off
passwordGraceLimit: 0
passwordWarning: 0
passwordMaxAge: 7776000
passwordExp: off
passwordInHistory: 10
passwordMinAge: 0
passwordChange: on
passwordMustChange: on
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
cn: cn=nsNoPwPolicyEntry,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test{code}","15/Apr/20 12:07;pd122;*SYT1*: existing policy is default policy for the subtree

*SYT3*: existing policy is not the default policy for the subtree","15/Apr/20 12:27;pd122;new default policy (with *passwordExp: off)* created on *SYT3*:

 
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: top
objectClass: extensibleObject
objectClass: ldapsubentry
objectClass: passwordpolicy
passwordExp: off
cn: cn=nsPwPolicyEntry,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=cn\3DnsPwTemplateEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: top
objectClass: extensibleObject
objectClass: costemplate
objectClass: ldapsubentry
cosPriority: 1
cn: cn=nsPwTemplateEntry,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test

dn: cn=nsPwPolicy_CoS,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: top
objectClass: LDAPsubentry
objectClass: cosSuperDefinition
objectClass: cosPointerDefinition
costemplatedn: cn=cn\3DnsPwTemplateEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
cosAttribute: pwdpolicysubentry default operational
cn: nsPwPolicy_CoS
{code}
existing policy left in place, unchanged

 ","15/Apr/20 12:32;pd122;*passwordExp: off* attribute has been added to already existing default *SYT1* policy:
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordExp: off
passwordLockout: off
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
cn: cn=nsPwPolicyEntry,ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test{code}",,,,,,,,,,,,,,,,,,,,,,,,
Renew Server Certificates M7 ELTS PROD,M7P-5947,94465,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cs687,cs687,cs687,14/Apr/20 08:34,22/Apr/20 15:06,16/Sep/21 14:11,14/Apr/20 13:31,,6.10.14,7tops_Sprint5,,,,,,30/Apr/20 00:00,M7PRODOPS,,,,,,,"We have to renew our server-certificates for ELTS-PROD

CN=prod1.epex-lts.m7.deutsche-boerse.com;May  8 23:59:59 2020 GMT;secret/m7t/elts/prod/cert/prod1.epex-lts.m7.deutsche-boerse.com
CN=prod2.epex-lts.m7.deutsche-boerse.com;May  8 23:59:59 2020 GMT;secret/m7t/elts/prod/cert/prod2.epex-lts.m7.deutsche-boerse.com

the following above will expire beginning of May and should be replaced asap. 
For that we need to request them from CCI, upload it to vault and coordinate a re-deployment with [~rehapav]",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5476,,,,,,"14/Apr/20 10:53;cs687;generate_csr_m7t-elt-prod2.txt;https://jira.deutsche-boerse.com/secure/attachment/82523/generate_csr_m7t-elt-prod2.txt","14/Apr/20 10:53;cs687;gnerate_csr_m7t-elt-prod1.txt;https://jira.deutsche-boerse.com/secure/attachment/82524/gnerate_csr_m7t-elt-prod1.txt","14/Apr/20 13:30;cs687;upload_elts-prod1.txt;https://jira.deutsche-boerse.com/secure/attachment/82529/upload_elts-prod1.txt","14/Apr/20 13:30;cs687;upload_elts-prod2.txt;https://jira.deutsche-boerse.com/secure/attachment/82528/upload_elts-prod2.txt",,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,44841600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgkv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94465,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"14/Apr/20 10:03;cs687;Will Request the certificates with that introduction: 
https://confluence.energy.svc.dbgcloud.io/display/ET/Server+Certificates

","14/Apr/20 10:53;cs687;Generated the CSR´s and saved the temporary the old private key in vault with the naming key_14042020
 [^generate_csr_m7t-elt-prod2.txt]  [^gnerate_csr_m7t-elt-prod1.txt] ","14/Apr/20 10:54;cs687;Created the IT-Service Request *5B4268* already approved by [~ox626]

Forwarded the email to ssl-admin´s
{code:java}
-----Original Message-----
From: englobauto1@englobauto1.deutsche-boerse.de <englobauto1@englobauto1.deutsche-boerse.de> 
Sent: Tuesday, April 14, 2020 10:41 AM
To: Steffen Englert <steffen.englert@deutsche-boerse.com>
Subject: New SSL Certificate(s) request. ITSR:

Hello, 
Please sign the attached CSR(s) with maximum possible validity. 
Thanks. 
Regards

{code}
","14/Apr/20 11:32;cs687;Just called the user-help-desk 11010  and they told me that we have currently 10 ITSR tickets in the queue. 
So our ticket will be forwarded in the next hours to the ssl-admin team, to get further infos i can call 11030 hotline. ","14/Apr/20 11:54;cs687;it needs an approval from [~ox626] again, afterwards Wolfgang Allendörfer will ping the Admins in Luxenbourg which will forward the ticket directly to the ssl-admin team:

Here we have the feedback from SSL-Admin´s:
{code:java}
Should be possible. I just checked and we still do not have the ticket on our queue. Most likely my colleague on late shift will take care of the request once the ticket arrives, but in case you do not receive the certificate before your deployment, you can give us a call to -14000 so we can check. I will give him the heads up for your tkt.

Also, lately most of the requests we receive have been expedited/urgent (this is not your fault :)) but just please for next time try to plan ahead of time, as usually we have 3-5 working days to process the requests. :)
{code}
","14/Apr/20 13:30;cs687;uploaded the certs in vault:
 [^upload_elts-prod2.txt]  [^upload_elts-prod1.txt] ","15/Apr/20 08:54;rehapav;apache@m7shrdprodweb1:[/tmp]$ openssl x509 -in /tmp/test.cert -noout -subject -issuer -dates
subject= /C=DE/postalCode=65760/ST=Hessen/L=Eschborn/street=Mergenthalerallee 61/O=Deutsche Boerse AG/OU=Cash & Derivatives IT Operations/CN=
[prod1.epex-lts.m7.deutsche-boerse.com|https://slack-redir.net/link?url=http%3A%2F%2Fprod1.epex-lts.m7.deutsche-boerse.com]

issuer= /C=GB/ST=Greater Manchester/L=Salford/O=Sectigo Limited/CN=Sectigo RSA Organization Validation Secure Server CA
notBefore=Apr 14 00:00:00 2020 GMT
notAfter=Apr 14 23:59:59 2022 GMTapache@m7shrdprodweb1:[/tmp]$ openssl x509 -in /tmp/test1.cert -noout -subject -issuer -dates
subject= /C=DE/postalCode=65760/ST=Hessen/L=Eschborn/street=Mergenthalerallee 61/O=Deutsche Boerse AG/OU=Cash & Derivatives IT Operations/OU=Hosted by Deutsche Borse Aktiengesellschaft/OU=Multi-Domain SSL/CN=
[prod1.epex-lts.m7.deutsche-boerse.com|https://slack-redir.net/link?url=http%3A%2F%2Fprod1.epex-lts.m7.deutsche-boerse.com]

issuer= /C=GB/ST=Greater Manchester/L=Salford/O=COMODO CA Limited/CN=COMODO RSA Organization Validation Secure Server CA
notBefore=May  9 00:00:00 2018 GMT
notAfter=May  8 23:59:59 2020 GMT",,,,,,,,,,,,,,,,,,,,,
Provide ICSC cert in Production,M7P-5946,94463,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,14/Apr/20 07:10,26/May/20 23:39,16/Sep/21 14:11,14/May/20 12:23,,6.8.129,7tops_sprint7,,,,,,30/Apr/20 00:00,M7PRODOPS,,,,,,,"The server-certificate for 

*certificate m7/icsc/prod/prod2_ics_m7c_deutsche-boerse_com_cert.cer will expire at Jun 13 23:59:59 2020 GMT*

will expire soon. We have to renew it and update it in vault + deployment 
",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/20 12:11;cs687;upload_cert.txt;https://jira.deutsche-boerse.com/secure/attachment/83848/upload_cert.txt",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42336000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxi0v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94463,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"08/May/20 09:41;cs687;*1.) Run the Job ""Project A. Generate CSR (Ansible Deployment)""*
*2.) check Vault settings*

secrets/secret/m7c/icsc/prod/cert
two secrets should be added (includes chain and key): 
* Request_prod1.ics.m7c.deutsche-boerse.com
* Request_prod2.ics.m7c.deutsche-boerse.com

*3.) Create Service Approval ""ITSR: 5B5702"" in Notes and write Email to SSL-ADMINS*
{code:java}
The below email is classified: Internal

Hello, 
Please sign the attached CSR(s) with maximum possible validity.
Alternative Names:
[prod1.ics.m7c.deutsche-boerse.com, prod2.ics.m7c.deutsche-boerse.com, www.intraday-capacity.com, intraday-capacity.com]

Thanks. 
Regards
{code}

Waiting until the cert´s are available: 
*4.) properly run: Project ""3. Deploy Certificate (Perl Deployment)""*
backup the current certificates on hosts and run the job or copy the certs manually there. 

Afterwards stop/start of the modules are required. ","13/May/20 10:39;cs687;Got the information that the certificates are available!
Lets manage a proper window-time and update it. 
[~rehapav] please come back to us with a service-ticket. 

Thanks.","13/May/20 11:39;cs687;{code:java}
Hello,

You have successfully enrolled for a SSL certificate.

You now need to complete the following steps:

    * Click the following link to download your SSL certificate
    Format(s) most suitable for your server software:
       as Certificate only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=x509CO
       as Root/Intermediate(s) only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=x509IO
       as Intermediate(s)/Root only, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=x509IOR

    Other available formats:
       as Certificate (w/ chain), PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=x509
       as PKCS#7, PEM encoded: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=base64
       as PKCS#7: https://cert-manager.com/customer/DeutscheBorseAG/ssl?action=download&sslId=1777673&format=bin

    * Import your new certificate into your server (Please contact your administrator for help with this).
    * Your renew id: FmUWEUQsroHMbDsyHDRE

Certificate Details:
    Common Name :  prod1.ics.m7c.deutsche-boerse.com
    Subject Alternative Names : prod1.ics.m7c.deutsche-boerse.com, prod2.ics.m7c.deutsche-boerse.com, www.intraday-capacity.com, intraday-capacity.com
    SSL Type :     Comodo Multi Domain SSL Certificate
    Term :         2 Year(s)
    Server :       Apache/ModSSL
    Requested :    13/05/2020 05:35 GMT
    Approved :     13/05/2020 05:35 GMT
    Expires :      13/05/2022 23:59 GMT
    Order Number : 348281999
    Self-Enrollment Certificate ID : 1777673
    Comments :     ITSR#5B5702 R.Krewer (A.Thorne)
{code}
","14/May/20 12:12;cs687;added these two vault entries *with the private key* from the Request_prod1.ics.m7c.deutsche-boerse.com & Request_prod2.ics.m7c.deutsche-boerse.com
* prod1_ics_m7c_deutsche-boerse_com_cert.cer
* prod2_ics_m7c_deutsche-boerse_com_cert.cer

and also the *sectigo_chain.pem*

Afterwards i run the jenkins job -> *Project 2. Import Cert to Vault (Perl Deployment)*
to upload the certificate to vault 
 [^upload_cert.txt] 

and created in vault manually the same for the second certificate -> *prod2_ics_m7c_deutsche-boerse_com_cert.cer*

The Deployment will be handled in ticket SERVICE-6315 with the proper description
",,,,,,,,,,,,,,,,,,,,,,,,
plpx-prod-rep1 not working,M7P-5942,94400,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,cv524,dp007,dp007,08/Apr/20 17:35,22/Apr/20 15:06,16/Sep/21 14:11,09/Apr/20 16:41,,7tops_Sprint5,,,,RE,,,,M7PRODOPS,,,,,,,"[http://10.136.22.13:62020/reporting-engine-app/]

 ",,cs687,cv524,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Apr/20 15:55;cv524;M7_PLPX_PROD_REP2_20200409_SUCCESS_01.txt;https://jira.deutsche-boerse.com/secure/attachment/82472/M7_PLPX_PROD_REP2_20200409_SUCCESS_01.txt","09/Apr/20 15:10;cv524;M7_PLPX_PROD_REP_WEB_20200409_FAILURE_01.txt;https://jira.deutsche-boerse.com/secure/attachment/82468/M7_PLPX_PROD_REP_WEB_20200409_FAILURE_01.txt","09/Apr/20 15:26;cv524;M7_PLPX_PROD_REP_WEB_20200409_SUCCESS_01.txt;https://jira.deutsche-boerse.com/secure/attachment/82469/M7_PLPX_PROD_REP_WEB_20200409_SUCCESS_01.txt",,,,,,,,,,,,,sw455,,,,,,,,in comments,,,,,,,,TGE,,,,,,,,,,,,,,,,45273600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,08/Apr/20 17:35,,[],,,,,,,,,,,M7T,,,,"2|hzxga7:",9223372036854775807,,,,No,,,,,,,,,,missing config + already used port,,,,,,,,7tops Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,,,none,,,,,,,,,,"{""issueId"":94400,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"09/Apr/20 08:11;cs687;receiving an ERROR:
{code:java}
HTTP Status 404 - /reporting-engine-app/
{code}

reporting-engine for plpx-prod is running on m7shrdprodrep1 without any error
{code:java}

tomcat@m7shrdprodrep1:[/shrd/logs/plpx-prod-rep1]$ ps -ef | grep plpx-prod
tomcat   18978     1  0 Apr08 ?        00:01:43 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/shrd/plpx-prod-rep1/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Xms256m -Xmx2048m -XX:MaxPermSize=768m -Dfile.encoding=UTF-8 -Duser.timezone=UTC -Dignore.endorsed.dirs= -classpath /shrd/plpx-prod-rep1/tomcat/bin/bootstrap.jar:/shrd/plpx-prod-rep1/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/shrd/plpx-prod-rep1/tomcat -Dcatalina.home=/shrd/plpx-prod-rep1/tomcat -Djava.io.tmpdir=/shrd/temp/plpx-prod-rep1 org.apache.catalina.startup.Bootstrap start
{code}

on the other hand the second reporting engine is running: 
http://10.136.150.13:62040/reporting-engine-app/

Reporting web1 is also running on m7shrdprodweb1:
{code:java}
apache   22540     1  0 Apr08 ?        00:00:01 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   22541 22540  0 Apr08 ?        00:00:00 /usr/sbin/rotatelogs /shrd/logs/m7t-plpx-prod-rep-web1/m7_plpx_prod_web-rep-1_error_ixe_%Y-%m-%d_%H.log 86400 100M
apache   22542 22540  0 Apr08 ?        00:00:00 /usr/sbin/rotatelogs /shrd/logs/m7t-plpx-prod-rep-web1/m7_plpx_prod_web-rep-1_access_ixe_%Y-%m-%d_%H.log 86400 100M
apache   22543 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   22544 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   22545 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   22546 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   22547 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   23373 22540  0 Apr08 ?        00:00:00 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-rep-web1/config/httpd.conf -k start
apache   31028 13895  0  2019 ?        00:07:46 /usr/sbin/httpd -f /shrd/m7t-plpx-prod-app-web1/config/httpd.conf -k start
{code}



","09/Apr/20 08:34;cs687;Update: from Lambert

{code:java}
Hello,
your report is just exactly correct.
BO yesterday had suspicion, there is no valid ""Reporting user"" for ""M7 PLPX PROD REP1"" instance. He had plan to ask for creation one.... or, to change the password for ""M7DMRPT"" account in LDAP.
I refused to touch the LDAP during the OnCall period, let it is run with more people effectivaly available in case of troubles.
{code}
","09/Apr/20 13:57;cs687;To have a same setup like it is for the other environments with apache - reporting-engine. 
I added also the hosts m7shrdprodweb3-6 to the inventory 

--> https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1750","09/Apr/20 15:05;cv524;Thursday 09.04.2020 14:48
Pull request #1750 was succesfully merged into master branch
nekylam merged commit bb90af5 into master now","09/Apr/20 15:10;cv524;Thursday 09.04.2020 15:05
Run Jenkins job with deployment of ""M7 PLPX PROD REP WEB"" instance.
Jenkins job completed with result: FAILURE
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/8383/console
 [^M7_PLPX_PROD_REP_WEB_20200409_FAILURE_01.txt] 
 ","09/Apr/20 15:24;cv524;Identified ""M7 NORE PROD REP WEB"" instances running on demanded ""62020"" network port on ""m7shrdprodweb4"" and ""m7shrdprodweb6"" hosts.
Instances were shut down.

{noformat}
#####################################################################################################
[root@m7shrdprodweb4 ~]# netstat -tanp | grep 62020
tcp        0      0 0.0.0.0:62020           0.0.0.0:*               LISTEN      10644/httpd
tcp        1      0 10.136.23.251:47702     10.139.53.250:62020     CLOSE_WAIT  18810/httpd
[root@m7shrdprodweb4 ~]# ps -ef | grep 10644
apache   10644 18799  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web4/config/httpd.conf -k start
root     17545 17342  0 15:14 pts/0    00:00:00 grep --color=auto 10644
[root@m7shrdprodweb4 ~]# su - apache
Last login: Wed Apr  8 17:02:08 CEST 2020 on pts/0
apache@m7shrdprodweb4:[/shrd]$ /shrd/nore-prod-rep-web4/stop.sh
Passing arguments to httpd using apachectl is no longer supported.
You can only start/stop/restart httpd using this script.
If you want to pass extra arguments to httpd, edit the
/etc/sysconfig/httpd config file.
[Thu Apr 09 15:19:22.434518 2020] [core:warn] [pid 18830] AH00117: Ignoring deprecated use of DefaultType in line 409 of /shrd/nore-prod-rep-web4/config/httpd.conf.
apache@m7shrdprodweb4:[/shrd]$
apache@m7shrdprodweb4:[/shrd]$
apache@m7shrdprodweb4:[/shrd]$ ps -ef | grep nore-prod
apache   18890 18326  0 15:19 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb4:[/shrd]$
#####################################################################################################
{noformat}
{noformat}
#####################################################################################################
[root@m7shrdprodweb6 ~]# netstat -tanp | grep 62020
tcp        0      0 0.0.0.0:62020           0.0.0.0:*               LISTEN      18736/httpd
tcp        1      0 10.136.23.252:34392     10.139.53.250:62020     CLOSE_WAIT  18746/httpd
tcp        1      0 10.136.23.252:57150     10.139.53.250:62020     CLOSE_WAIT  18743/httpd
[root@m7shrdprodweb6 ~]# ps -ef | grep 18736
root      6466  6026  0 15:15 pts/0    00:00:00 grep --color=auto 18736
apache   18736     1  0  2019 ?        00:07:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   18739 18736  0  2019 ?        00:00:00 /usr/sbin/rotatelogs /shrd/logs/nore-prod-rep-web6/m7_nore_prod_web-rep-6_error_hau_%Y-%m-%d_%H.log 86400 100M
apache   18740 18736  0  2019 ?        00:00:00 /usr/sbin/rotatelogs /shrd/logs/nore-prod-rep-web6/m7_nore_prod_web-rep-6_access_hau_%Y-%m-%d_%H.log 86400 100M
apache   18742 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   18743 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   18744 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   18746 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   18747 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
apache   21921 18736  0  2019 ?        00:00:00 /usr/sbin/httpd -f /shrd/nore-prod-rep-web6/config/httpd.conf -k start
[root@m7shrdprodweb6 ~]# su - apache
Last login: Wed Apr  8 17:02:08 CEST 2020 on pts/0
apache@m7shrdprodweb6:[/shrd]$ /shrd/nore-prod-rep-web6/stop.sh
Passing arguments to httpd using apachectl is no longer supported.
You can only start/stop/restart httpd using this script.
If you want to pass extra arguments to httpd, edit the
/etc/sysconfig/httpd config file.
[Thu Apr 09 15:20:15.801913 2020] [core:warn] [pid 7533] AH00117: Ignoring deprecated use of DefaultType in line 409 of /shrd/nore-prod-rep-web6/config/httpd.conf.
apache@m7shrdprodweb6:[/shrd]$ ps -ef | grep nore-prod
apache    7567  7234  0 15:20 pts/0    00:00:00 grep --color=auto nore-prod
apache@m7shrdprodweb6:[/shrd]$
#####################################################################################################
{noformat}","09/Apr/20 15:26;cv524;Thursday 09.04.2020 15:24
Repeated run Jenkins job with deployment of ""M7 PLPX PROD REP WEB"" instance.
Jenkins job completed with result: SUCCESS
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/8384/console
 [^M7_PLPX_PROD_REP_WEB_20200409_SUCCESS_01.txt] ","09/Apr/20 15:55;cv524;Thursday 09.04.2020 15:53
Repeated run Jenkins job with deployment of ""M7 PLPX PROD REP2"" instance.
Jenkins job completed with result: SUCCESS
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/8387/console
 [^M7_PLPX_PROD_REP2_20200409_SUCCESS_01.txt] ","09/Apr/20 16:22;cv524;Thursday 09.04.2020 16:19
Even after redeployment of ""M7 PLPX PROD REP2"" instance and repeated restart the service is not listening on port ""62020""

{noformat}
#####################################################################################################
[root@m7shrdprodrep2 ~]# ps -ef | grep plpx-prod
tomcat   11702     1  1 15:53 ?        00:00:26 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/shrd/plpx-prod-rep2/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Xms256m -Xmx2048m -XX:MaxPermSize=768m -Dfile.encoding=UTF-8 -Duser.timezone=UTC -Dignore.endorsed.dirs= -classpath /shrd/plpx-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/plpx-prod-rep2/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/shrd/plpx-prod-rep2/tomcat -Dcatalina.home=/shrd/plpx-prod-rep2/tomcat -Djava.io.tmpdir=/shrd/temp/plpx-prod-rep2 org.apache.catalina.startup.Bootstrap start
root     14327 30675  0 16:19 pts/0    00:00:00 grep --color=auto plpx-prod
[root@m7shrdprodrep2 ~]# netstat -tanp | grep 11702
tcp        0      0 127.0.0.1:62021         0.0.0.0:*               LISTEN      11702/java
tcp        0      0 10.139.53.250:37782     10.139.53.173:20010     ESTABLISHED 11702/java
tcp        0      0 10.139.53.250:38884     10.139.53.176:20010     ESTABLISHED 11702/java
tcp        0      0 10.139.53.250:38894     10.139.53.176:20010     ESTABLISHED 11702/java
tcp        0      0 10.139.53.250:38890     10.139.53.176:20010     ESTABLISHED 11702/java
[root@m7shrdprodrep2 ~]#
#####################################################################################################
{noformat}
""catalina.out"" file of mentioned java process provided to [~dp007] to check the reason of issue
","09/Apr/20 16:36;cv524;Thursday 09.04.2020 16:28
[~dp007] discovered already utilized port ""62020"".
The port was occupied by abandoned ""M7 NORE PROD REP2"" instance. Instance was stopped and restarted demanded ""M7 PLPX PROD REP2"" instance.
It started properly and service is available.

{noformat}
#####################################################################################################
[root@m7shrdprodrep2 ~]# netstat -tanp | grep 62020
tcp        0      0 0.0.0.0:62020           0.0.0.0:*               LISTEN      17380/java
[root@m7shrdprodrep2 ~]# ps -ef | grep 17380
root     15063 30675  0 16:26 pts/0    00:00:00 grep --color=auto 17380
tomcat   17380     1  0 Apr08 ?        00:01:04 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/shrd/nore-prod-rep2/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms256m -Xmx2048m -XX:MaxPermSize=768m -Dfile.encoding=UTF-8 -Duser.timezone=UTC -Djava.endorsed.dirs=/shrd/nore-prod-rep2/tomcat/endorsed -classpath /shrd/nore-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/nore-prod-rep2/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/shrd/nore-prod-rep2/tomcat -Dcatalina.home=/shrd/nore-prod-rep2/tomcat -Djava.io.tmpdir=/tmp org.apache.catalina.startup.Bootstrap start
[root@m7shrdprodrep2 ~]# su - tomcat
Last login: Thu Apr  9 15:56:59 CEST 2020 on pts/0
tomcat@m7shrdprodrep2:[/shrd]$ /shrd/plpx-prod-rep2/tomcat/bin/stop.sh
Using CATALINA_BASE:   /shrd/plpx-prod-rep2/tomcat
Using CATALINA_HOME:   /shrd/plpx-prod-rep2/tomcat
Using CATALINA_TMPDIR: /shrd/plpx-prod-rep2/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /shrd/plpx-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/plpx-prod-rep2/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /shrd/plpx-prod-rep2/tomcat/pid
Tomcat stopped.
tomcat@m7shrdprodrep2:[/shrd]$ /shrd/nore-prod-rep2/tomcat/bin/stop.sh
Using CATALINA_BASE:   /shrd/nore-prod-rep2/tomcat
Using CATALINA_HOME:   /shrd/nore-prod-rep2/tomcat
Using CATALINA_TMPDIR: /shrd/nore-prod-rep2/tomcat/temp
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /shrd/nore-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/nore-prod-rep2/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /shrd/nore-prod-rep2/tomcat/pid
Tomcat stopped.
tomcat@m7shrdprodrep2:[/shrd]$ ps -ef | grep nore-prod-re
tomcat   15309 15114  0 16:27 pts/0    00:00:00 grep --color=auto nore-prod-re
tomcat@m7shrdprodrep2:[/shrd]$ /shrd/plpx-prod-rep2/tomcat/bin/start.sh
Using CATALINA_BASE:   /shrd/plpx-prod-rep2/tomcat
Using CATALINA_HOME:   /shrd/plpx-prod-rep2/tomcat
Using CATALINA_TMPDIR: /shrd/temp/plpx-prod-rep2
Using JRE_HOME:        /opt/java/default/jre
Using CLASSPATH:       /shrd/plpx-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/plpx-prod-rep2/tomcat/bin/tomcat-juli.jar
Using CATALINA_PID:    /shrd/plpx-prod-rep2/tomcat/pid
Tomcat started.
tomcat@m7shrdprodrep2:[/shrd]$ ps -ef | grep plpx-prod-rep
tomcat   15336     1 99 16:28 pts/0    00:00:24 /opt/java/default/jre/bin/java -Djava.util.logging.config.file=/shrd/plpx-prod-rep2/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 -Xms256m -Xmx2048m -XX:MaxPermSize=768m -Dfile.encoding=UTF-8 -Duser.timezone=UTC -Dignore.endorsed.dirs= -classpath /shrd/plpx-prod-rep2/tomcat/bin/bootstrap.jar:/shrd/plpx-prod-rep2/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/shrd/plpx-prod-rep2/tomcat -Dcatalina.home=/shrd/plpx-prod-rep2/tomcat -Djava.io.tmpdir=/shrd/temp/plpx-prod-rep2 org.apache.catalina.startup.Bootstrap start
tomcat   15392 15114  0 16:28 pts/0    00:00:00 grep --color=auto plpx-prod-rep
tomcat@m7shrdprodrep2:[/shrd]$
tomcat@m7shrdprodrep2:[/shrd]$ logout
[root@m7shrdprodrep2 ~]# netstat -tanp | grep 15336
tcp        0      0 0.0.0.0:62020           0.0.0.0:*               LISTEN      15336/java
tcp        0      0 127.0.0.1:62021         0.0.0.0:*               LISTEN      15336/java
tcp        0      0 10.139.53.250:38140     10.139.53.173:20010     ESTABLISHED 15336/java
tcp        0      0 10.139.53.250:39248     10.139.53.176:20010     ESTABLISHED 15336/java
tcp        0      0 10.139.53.250:39242     10.139.53.176:20010     ESTABLISHED 15336/java
tcp        0      0 10.139.53.250:39250     10.139.53.176:20010     ESTABLISHED 15336/java
[root@m7shrdprodrep2 ~]#
#####################################################################################################
{noformat}
","09/Apr/20 16:38;dp007;_Address already in use_ error because there was old NORE PROD REP running on port 62020. [~cv524] stopped that process and started PLPX again and it worked.",,,,,,,,,,,,,,,,,
Fix M7C ansible deployment jobs,M7P-5940,94396,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,ax460,ax460,08/Apr/20 16:17,30/Jul/20 14:19,16/Sep/21 14:11,27/Jul/20 08:49,,6.8.137,7tops_sprint12,,,,,,,7tops,7tops_comm,DEVOPS,M7PRODOPS,TechOps,,,"*Design suitable way how to deploy both m7t and m7c products*

There are two different jobs for deploying M7C (ICS)
 # [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7C%20Ansible/]
 ** Does not read rabbitmq version from components.yml eg [https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/m7capacity/m7-product/m7p-reports/6.8.120/]
 ** i you try to deploy only rabbitmq component version m7c_version is not propagated and default version is deployed
 # [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/dev-trigger/]
 ## is designed for m7t so it look for rabbitmq version in artifactory tree m7t not m7c",,ax460,cs687,cv179,,,,,,,,,,,,,,,M7P-6443,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"PR merged, no further complaints. Please get in touch with me if there is still any open issue or create a ticket if we need to change some parameters or design...",,,,,,,,,,,,,,,,,,,,,,,,38102400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3073,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxi1j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,7tops Sprint 10,7tops Sprint 11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94396,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,5940-2,M7P-5940,true,"08/Apr/20 16:18;ax460;Just to have a full picture note there is also another m7t job [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/] ","16/Apr/20 13:51;ax460;as agreed on 7tops refinement use [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/Jenkinsfile_deploy_custom] as template (ideally rename to m7t) and create similar jenkins file for m7c","27/May/20 11:36;ax460;[~cs687]please rename target job in *m7t* deployment config [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7T%20Ansible%20-%20Deployment/] and merge [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/909]

 

Also new *m7c* deployment job created [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/908]","04/Jun/20 13:34;cv179;having 4 products, 3 scenarios and 3 teams makes 36 jenkins files. No way we can just start with copy and paste to later adjust them!


I added some feedback to this:
|I don't see the need to copy the job file just for removal of components. If those components are not used, they won't get deployed anyways.
Potential reason to create a dedicated jenkins file would be a combined job to deploy capacity and trading part! So it can be done using just this one job for core, enq, cmi, cmm including all respective haproxy, rabbitmq and apache instances.
In that case, the ""shared library"" approach should be used as much as possible.
Naming would be better this way:
Jenkinsfile_deploy__
Product is clear.
Scenario could be ""full"", ""custom"", ""upgrade"" - depending on the different scenarios.|
 
 
|If the ansible implementation of cor and enq works well for m7c, please just extend the customer/env list of the existing job.|

as well as to the m7t suffix:
the name part ""custom"" must still be in there.
Rename must be in line with reconfiguring the jenkins job. And it should be done also for ""full"" and ""upgrade"" and also for all upstream jobs for bizops and dev. and also their respective upstream jobs. to be checked in jenkins and please add them in the comment.




Proposal for proceeding:

First essential task part is to optimize existing jobs, move out shared implementations to the library, add parameters if needed to get m7c deployable - but don't touch m7t jobs as they're part of pipelines and must not break.

Then, create an overview of which actual jobs/scenarios/teams are needed for what products.

Is there maybe a better way to create the restricted upstream jobs? ","04/Jun/20 13:36;cv179;If you like, let's have a quick conference call - maybe i'm not aware of all the facts. ","09/Jun/20 18:13;cs687;[~ax460] can you please give us a update on that? Thanks in Advance 
","01/Jul/20 11:29;cs687;Just had a quick meeting with [~cv179] 
he explained me the way how to implement/add the M7C to the Pipeline. 

Roman will start working on it and keep updating us about the status. ","02/Jul/20 10:10;cv179;[~ax460] please check [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/975/files]

That's essentially what I thought of",,,,,,,,,,,,,,,,,,,,
BSP SIMU M7 connection to XBID SIMU env,M7P-5937,94392,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,08/Apr/20 15:58,22/Apr/20 15:06,16/Sep/21 14:11,09/Apr/20 14:33,,6.10.14,7tops_Sprint5,,,,,,13/Apr/20 00:00,M7PRODOPS,,,,,,,"Dear all,

I would kindly ask you to check if our M7 SIMU is connected to XBID SIMU env as we cannot access the WebGui.

If it is not connected the exchange username is XBBSP001 and password is itEDvNbg!r70.

Thank you and best regards,
Matej",,cs687,,,,,,,,,,,,,,,,,SERVICE-6037,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,Southpool,,,,,,,,,,,,,,,,45273600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxgaf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94392,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"09/Apr/20 07:03;cs687;*Certificate issue found these log-entries on m7xsopsimum7b1 -> /xsop/logs/xsop-simu-cor1/rollover/transferred/m7_xsop_simu_cor-1_standard_ixe_1_2020-04-08.log.gz*

{code:java}
2020-04-08T15:16:46.295Z [ResultTransform] ERROR c.r.c.i.SocketFrameHandler - TLS connection failed: sun.security.validator.ValidatorException: No trusted certificate found
2020-04-08T15:16:46.301Z [ResultTransform] ERROR c.r.c.i.SocketFrameHandler - TLS connection failed: sun.security.validator.ValidatorException: No trusted certificate found
2020-04-08T15:16:46.313Z [ResultTransform] ERROR c.r.c.i.SocketFrameHandler - TLS connection failed: sun.security.validator.ValidatorException: No trusted certificate found
2020-04-08T15:16:46.324Z [ResultTransform] ERROR c.r.c.i.SocketFrameHandler - TLS connection failed: sun.security.validator.ValidatorException: No trusted certificate found
2020-04-08T15:16:46.325Z [ResultTransform] INFO  o.s.a.r.l.SimpleMessageListenerContainer - Shutdown ignored - container is not active already
2020-04-08T15:16:46.325Z [ResultTransform] INFO  o.s.a.r.l.SimpleMessageListenerContainer - Shutdown ignored - container is not active already
2020-04-08T15:16:46.325Z [ResultTransform] INFO  sob-gateway - Connection to SOB closed
2020-04-08T15:16:46.325Z [ResultTransform] ERROR c.d.e.m.c.o.t.s.AbstractSobConnectionResultTransformer - Unable to connect to SOB

Caused by: org.springframework.amqp.AmqpIOException: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: No trusted certificate found
        at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:71)
        at org.springframework.amqp.rabbit.connection.AbstractConnectionFactory.createBareConnection(AbstractConnectionFactory.java:530)
        at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:702)
        at org.springframework.amqp.rabbit.connection.ConnectionFactoryUtils.createConnection(ConnectionFactoryUtils.java:215)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:2068)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2042)
        at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:2022)
        at org.springframework.amqp.rabbit.core.RabbitAdmin.declareQueue(RabbitAdmin.java:303)
        at com.deutscheboerse.energy.m7.sobgateway.SpringQueueFactory.responseQueue(SpringQueueFactory.java:46)
        at com.deutscheboerse.energy.m7.sobgateway.SobConnector.startResponseListenerContainer(SobConnector.java:114)
{code}

Certificate is reagrding SSL handhake to XBID, will check the current vault-settings. 
We need an update for: *m7t/xsop/simu/m7core/sob_truststore* in vault and re-deploy cor 
like it is currently setup for hupx-simu and plpx-simu both of them are also connecting successful to xbid-simu

","09/Apr/20 09:29;cs687;with the current sob_truststore we are using the old *COMODO*

*[root@m7xsopsimum7b1 lib]# keytool -list -v -keystore trustStore.jks*
{code:java}
*******************************************
*******************************************


Alias name: comodo
Creation date: May 27, 2016
Entry type: trustedCertEntry

Owner: CN=COMODO RSA Organization Validation Secure Server CA, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Issuer: CN=COMODO RSA Certification Authority, O=COMODO CA Limited, L=Salford, ST=Greater Manchester, C=GB
Serial number: 36825e7fb5a481937ef6d1736bb93ca6
Valid from: Wed Feb 12 01:00:00 CET 2014 until: Mon Feb 12 00:59:59 CET 2029
{code}

Hupx-Simu and Plpx-simu having the new CN
{code:java}
Owner: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
Issuer: CN=AddTrust External CA Root, OU=AddTrust External TTP Network, O=AddTrust AB, C=SE
{code}

","09/Apr/20 09:36;cs687;Re-deployment of cor will be handled with that Ticket: 
https://jira.deutsche-boerse.com/browse/SERVICE-6037","09/Apr/20 09:39;cs687;also updated the user/password in vault with the mentioned one in the description
m7t/xsop/simu/m7core/sob_user","09/Apr/20 14:33;cs687;done. XSOP-Simu is now connecting to XBID SIMU",,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: BSP SIMU M7 connection to XBID SIMU env,M7P-5934,94387,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,wn626,wn626,08/Apr/20 15:42,22/Apr/20 10:46,16/Sep/21 14:11,22/Apr/20 09:08,,6.10.15,7tops_sprint4,,,,,,,M7PRODOPS,,,,,,,"Dear all,

I would kindly ask you to check if our M7 SIMU is connected to XBID SIMU env as we cannot access the WebGui.

If it is not connected the exchange username is XBBSP001 and password is itEDvNbg!r70.

Thank you and best regards,
Matej",,wn626,,,,,,,,,,,,,,,,,,,SERVICE-6020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,Southpool,,,,,,Information Request,,,,,,,,,,45360000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxg87:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94387,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sizing analysis for Data storage,M7P-5933,94382,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,dp007,dp007,08/Apr/20 14:43,23/Feb/21 12:02,16/Sep/21 14:11,14/May/20 18:56,,6.10.51,7tops_sprint7,,,EBSM,,,,M7PRODOPS,,,,,,,"Goal:
 * estimate disk space needs
 * breakdown current situation (in terms of disk space needs) into meaningful level

h1. Current situation

total numbers:
 *3600 GB* total
 * 1600G logs (m7+xbid zipped and unzipped)
 * 1900G db dumps (xbid only)

numbers per day:
 *112 GB* total
 * 88GB logs (unzipped)
 ** 53G/71% M7T
 ** 24G/28% XBID
 ** 1G/1% OTHERS

 * 24GB db dumps
 ** 3.1GB xbid_ctpa
 ** 1.1GB xbid_cbtp
 ** 0.2GB xbid_ctpc
 ** 0.6GB xbid_ctpd
 ** 0.3GB xbid_ctpe
 ** 0.1GB xbid_ctpf
 ** 0.1GB xbid_ctpg
 ** 0.9GB xbid_ctph
 ** 0.1GB xbid_ctpi
 ** 0.1GB xbid_ctpj
 ** 0.1GB xbid_ctpk
 ** 0.2GB xbid_ctpl
 ** 1.5GB xbid_ctso
 ** 0.7GB xbid_cute
 ** 1.6GB xbid_lipa
 ** 1.9GB xbid_lipb
 ** 8.8GB xbid_prod
 ** 2.5GB xbid_simu

There are no journal files transfers on daily basis, just some old relics at /opt/data/transfer/journals/. but one day journal for xbid prod needs 400MB (=5% of the db size).
h1. Requirements:

M7T

_for the team trouble shooting purpose is used just 6 months of logs. so NO DB Dumps, NO Journals_
 https://jira.deutsche-boerse.com/browse/M7P-5534

XBID
 ·        PROD (DB Dump, Logs, Journals) - 15 month
 ·        xSIMU+CUTEx+CTPx (DB Dump, Logs, Journals) - 6 months
 keep backup frequency - last month each day, older per week (DB Dump, Journals) for usage of DB Dump SSH/SCP needed 

M7A – not using 
h1. Conclusion:

M7 a day = 53GB:
 * logs (unzipped): 53GB

XBID PROD a day = 19.2GB:
 * logs (unzipped): 10GB
 * db dumps: 8.8GB
 * journals: 0.4GB

XBID all non-prod a day = 30GB:
 * logs (unzipped): 14GB
 * db dumps: 15.2GB
 * journals: 0.8GB

 
||growth||2020||2021||2022||2023||2024||2025||2026||2027||2028||2029||2030||
|00%|24|24|24|24|24|24|24|24|24|24|24|
|10%|24|27|29|32|36|39|43|47|52|57|63|
|15%|24|28|32|37|42|49|56|64|74|85|97|
|20%|24|29|35|42|50|60|72|86|104|124|149|
|25%|24|30|38|47|59|73|92|114|143|179|224|

* 24 = 183 days x 83 (53+30) + 455 days x 19.2 = 23.925 => 24TB

Please note the table here above doesn't count with any kind of buffer - please include a buffer of your choice into calculation",,dm700,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-545,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45360000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-1396,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxg73:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94382,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Apr/20 11:30;dp007;[~wm282] please let me know if the calculation is the one you expected or, if not, what do you want me to amend.",,,,,,,,,,,,,,,,,,,,,,,,,,,
ICS CuTE - Replace EMFIP certificate in java keystore,M7P-5929,94373,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,qz412,qz412,08/Apr/20 13:18,22/Apr/20 15:06,16/Sep/21 14:11,08/Apr/20 15:17,,6.8.124,7tops_Sprint5,,,ICS,,,,M7PRODOPS,,,,,,,"Please change the certificate in ICS CuTE java keystore as described in the PR below.

1) merge following PR

[https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/629]

 

2) Redeploy CMI in ICS CuTE.

The CuTE is currently available for our testing activities for AT-CH border setup. This change is needed for investigation of EMFIP related problems: M7P-5873 and M7P-5783.

 ",,cs687,qz412,,,,,,,,,,,,,,,,,,M7P-5923,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45360000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxg5j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94373,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"08/Apr/20 15:09;cs687;Ticket was solved in 
https://jira.deutsche-boerse.com/browse/SERVICE-6027
",,,,,,,,,,,,,,,,,,,,,,,,,,,
ICS CuTE - redeploy CMI with EMFIP file sending enabled,M7P-5923,94339,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,qz412,qz412,08/Apr/20 08:40,28/Apr/20 23:39,16/Sep/21 14:11,08/Apr/20 11:28,,6.8.124,6.8.126,7tops_Sprint5,,ICS,,,,M7PRODOPS,,,,,,,"Please

1) merge following PR:

[https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/626]

2) Redeploy CMI in ICS CuTE.

Coordinated with the customers, the CuTE is currently available for our testing activities for AT-CH border setup. This change is needed for investigation of EMFIP related problems: M7P-5873 and M7P-5783.

 ",,cs687,qz412,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45446400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxfxj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94339,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,CUTE,,,,"08/Apr/20 09:35;rehapav;approved for today 11:00 - or anytime later this day, announced maintenance window max 15 minutes","08/Apr/20 11:28;cs687;Ticket was handled in https://jira.deutsche-boerse.com/browse/SERVICE-6025
Can be closed, result was confirmed by [~qz412]",,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD MTT startup test,M7P-5922,94317,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,oy574,rehapav,rehapav,07/Apr/20 16:18,30/Jul/20 14:19,16/Sep/21 14:11,09/Apr/20 16:44,,7tops_sprint12,,,,,,,,7tops,,,,,,,"9/4 on ELTS PROD
 * create two technical users on ELTS PROD (SYSMTT01/02) with the correct roles/rights/groups/password (looking at HUPX PROD or ELTS LIPA  would be a good example)
 * provide the password to TECHOPS
 * TechOps please Make sure that we have the password entries in Vault and that it matches what we just set in WebGUI (and would end up in LDAP)
 * Merge for MTT: [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1651]
 * start MTT
 ** watch for errors in log, in case of errors immediately shut it down
 * stop MTT",,oy574,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5476,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44928000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxft3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 90,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94317,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 16:25;oy574;Explanation for the startup: only possible (low) impact I see could be caused by MTT's backoff policy that re-starts itself in case of errors - so e.g. if the login with the MTT user would fail, it would restart and try again. If we would have wrong password or non existing user, this would be useless - hence just stop the instance for extra safety not to send these login requests.","14/Apr/20 07:23;rehapav;Test sucesfully",,,,,,,,,,,,,,,,,,,,,,,,,,
Remove password policy from ATE4,M7P-5921,94308,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,nn236,nn236,07/Apr/20 15:45,05/Jan/21 14:00,16/Sep/21 14:11,28/May/20 16:02,,6.10.69,7tops Sprint8,,,,,,,7tops_comm,M7PRODOPS,,,,,,"Within M7P-5835, password policy was set up for ATE4 (there was one policy for technical users - those were not supposed to expire, and second policy for all other users - those were expiring after 3 days). 

In this ticket, please return the ATE4 environment to its previous state, i.e. the users shall not expire after x days, all the existing users shall be re-activated in LDAP and their passwords should be set a common password Test0101 or test01.",,nn236,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"- ATE4 specific password policy removed

- password reset for all accounts",,,,,,,,,,,,,,,,,,,,,,,,41040000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxi1b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 6,7tops Sprint 7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94308,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 15:48;nn236;Assigning as per our agreement","20/May/20 11:41;pd122;existing policy related objects in ate4 tree:
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
cn: cn=nsPwPolicyEntry,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
passwordMustChange: off
passwordMinAge: 0
passwordChange: on
passwordLockout: on
passwordMaxRepeats: 0
passwordMaxAge: 259200
passwordMinLength: 8
passwordMinAlphas: 0
passwordExp: on
passwordMinDigits: 1
passwordMinSpecials: 1
passwordMinLowers: 1
passwordInHistory: 5
passwordMinCategories: 1
passwordMinUppers: 1
passwordMinTokenLength: 3
passwordMin8bit: 0
passwordCheckSyntax: on
passwordGraceLimit: 0
passwordStorageScheme: sha256
passwordResetFailureCount: 3600
passwordMaxFailure: 3
passwordWarning: 0{code}
{code:java}
dn: cn=cn\3DnsPwTemplateEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
cn: cn=nsPwTemplateEntry,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
cosPriority: 1
objectClass: extensibleObject
objectClass: costemplate
objectClass: ldapsubentry
objectClass: top{code}
{code:java}
dn: cn=nsPwPolicy_CoS,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
cn: nsPwPolicy_CoS
cosAttribute: pwdpolicysubentry default operational-default
costemplatedn: cn=cn\3DnsPwTemplateEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: cosSuperDefinition
objectClass: cosPointerDefinition
objectClass: top{code}","20/May/20 11:48;pd122;Policies set up for admin users (first 3 specified in -M7P-5835):-
{code:java}
dn: uid=M7CODA02,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubEntry: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test{code}
{code:java}
dn: uid=SADMIN01,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubEntry: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test{code}
{code:java}
dn: uid=SYSOPS01,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubEntry: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test{code}
{code:java}
dn: uid=shrd-apa-ate4-adm,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdPolicySubEntry: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test{code}","20/May/20 11:55;pd122;Details of password policy used for ATE4 admin accounts (among others I would expect):
{code:java}
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
passwordMinAge: 0
passwordLockout: off
passwordMaxAge: 259200
passwordUnlock: off
passwordMaxFailure: 3
passwordChange: on
passwordLockoutDuration: 900
passwordStorageScheme: ssha
passwordExp: off
passwordWarning: 432000
objectClass: top
objectClass: passwordpolicy
objectClass: ldapsubentry
passwordResetFailureCount: 60
cn: cn=nsNoExpPwPolicyEntry,o=M7,dc=energy,dc=test
passwordMustChange: off
passwordInHistory: 0
passwordGraceLimit: 0{code}
Keeping the policy and the admin accounts' policy setup intact.","20/May/20 17:25;pd122;[~nn236] do I understand it correctly you would like ATE4 (non-admin) passwords to not expire at all (like SYT1, and ATE2,5 at this moment)?  Or would you like it to  be 90 days as on SYT2,3 and ATE3  or 1 day as on ATE1?","20/May/20 17:40;nn236;[~pd122] Actually, it'd be ideal if passwords of all users (not just non-Admin ones) would not expire on ATE4 at all.

Before the password policy test on ATE4, there was no password policy applied (to my knowledge at least) and there was no distinction for treating passwords based on user roles. This is what I wanted to achieve with this ticket, together with the passwords of all users (Admins, non-Admins, and others) being set to something simple like 'Test0101' or 'test01'. Because since the password policy test on ATE4, everybody from MAG7 is asking me for passwords of users which are all different and mostly randomly generated by M7 during the test.

Please let me know if my expectations are not making sense or are not achievable. Thanks!","28/May/20 16:01;pd122;ATE4 specific password policy has been removed, default M7 password policy applies now (no password expiration) for non-admin accounts:
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
cn: cn=nsPwPolicyEntry,o=M7,dc=energy,dc=test
passwordMustChange: off
passwordExp: off
passwordMinAge: 0
passwordChange: on
passwordStorageScheme: ssha
passwordLockout: on
passwordResetFailureCount: 600
passwordMaxFailure: 5{code}
 

Passwords were updated for all accounts (but _uid=shrd-apa-ate4-adm,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test_) to '_Test0101_'.",,,,,,,,,,,,,,,,,,,,,
Investigate deployment of 3.8.3 rabbit,M7P-5920,94298,91430,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,ax460,ax460,07/Apr/20 14:36,22/Apr/20 15:06,16/Sep/21 14:11,08/Apr/20 15:20,,7tops_Sprint5,,,,,,,,M7PRODOPS,,,,,,,"Added *3.8.3* as current version [https://github.deutsche-boerse.de/dev/m7.capacity-product/pull/15] and default version [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1738]

 

And I have deployed 6.8.121 (rmq 3.8.3 is placed in pom) to ate5 but 3.8.0 is deployed ([http://10.136.148.37:52500/])
  

Does [M7C Ansible|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7C%20Ansible/] job also deploy Rabbit? Based on components.yml in  [https://artifactory.dbgcloud.io/artifactory/eex-dev-local/com/deutscheboerse/energy/m7capacity/m7-product/m7p-reports/6.8.121/]",,ax460,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45360000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxfpz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 89,Schmetterling Sprint 90 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94298,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/20 11:55;cs687;Normally it should work, in case the erlang-version is properly upgraded. 
It should work to upgrade the rabbitmq version from 3.8.1 to 3.8.3, in that case we are upgrading 3.8.0 to 3.8.3 which can be harder. 

The erlang-version is running to proper one 22.1 
{code:java}
Installed Packages
Name        : XBID-erlang
Arch        : x86_64
Version     : 22.1
Release     : 1.el7
Size        : 96 M
Repo        : installed
From repo   : DBG_Energy_Global_XBID-7_XBID-7
Summary     : Erlang programming language
URL         : http://www.erlang.org/
License     : Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0)
Description : Erlang is a programming language used to build massively
            : scalable soft rt systems with requirements on high
            : availability.
{code}

Recommend steps:
* should stop the Environemnt
* check if erlang version is upgraded
* https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/dev-trigger/job/deploy_full/ deploy it with that jenkins job 

with your pure ansible job [~ax460] it is not possible to upgrade rabbitmq  


Update:
the pipeline job is not suitable for m7c - i'll need to create a dedicated one for capacity","08/Apr/20 15:20;cs687;Rabbitmq 3.8.3 is deployed we need to make some pipeline changes to make it suitable for m7c as well. 
[~ax460] please create a ticket for that. ",,,,,,,,,,,,,,,,,,,,,,,,,,
Option to shutdown/restart M7 components programatically,M7P-5914,94264,90712,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,jv861,jv861,06/Apr/20 18:43,11/Mar/21 13:48,16/Sep/21 14:11,07/Apr/20 13:10,,7tops_sprint4,,,,,,,,M7PRODOPS,,,,,,,"As discussed few weeks ago on DevOps CoP, we'd like to have a programmatic approach to shutdown M7 components on SYT3 (or any internal test env).

The idea is a load runner application running on m7shrdsyt3ldr1, and allow this application (based on it's own decision) to trigger following events:
 * stop/start cor/enq
 * stop/restart individual rabbit nodes
 * cut connection to xbid (preferable using iptables - it better models the problems we had)
 * cut connection to Xbid
 * cut connection to internal rabbitmq (if possible)
 * cut connection to database (if possible)

Maybe we would expand this later, but this would be a nice start.",,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45532800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmr9r:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 84,Magnificent 7 Sprint 85,Magnificent 7 Sprint 86 (PS),Magnificent 7 Sprint 87,M7 Development,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94264,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 13:11;jv861;Moved to M7P-5780",,,,,,,,,,,,,,,,,,,,,,,,,,,
Configure ATE1 and ATE5 environments for ICS Portal,M7P-5911,94254,91045,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,ef759,ef759,06/Apr/20 15:10,06/May/20 11:08,16/Sep/21 14:11,04/May/20 09:10,,7tops Sprint6,,,,,,,,M7PRODOPS,,,,,,,"Please configure Load Balancers to be able to communicate with Portal apache servers on ATE1 and ATE5 (host m7shrdinteweb1). Protocol HTTPS
ATE1 => port 60103 (Portal configuration was already done in past but for incorrect port 60666)
ATE5 => port 60503 (New config must be done)

Also create certificates for m7shrdinteweb1 hosts.
*Certificates:
ATE1 certificates: energy-mkt-shared/templates/php-portal/certificate/ate1/(ca.pem, priv.pem, pub.pem)
ATE5 certificates: not present

",,ef759,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-6079,,,,,,"22/Apr/20 13:58;iu252;pub.pem;https://jira.deutsche-boerse.com/secure/attachment/82922/pub.pem",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43545600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxfcn:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,Schmetterling Sprint 89,Schmetterling Sprint 90 (PS),Schmetterling Sprint 91,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94254,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Apr/20 13:00;iu252;I asked CCI-Team (Networks) to provide existing LoadBalancer configuration for ATE1 and ATE5. Waiting for the answer.

Meanwhile checking the situation with certificates.","21/Apr/20 07:23;iu252;Here is the actual LB config for ATE1 and ATE5:


{noformat}

Virtual server: M7-shrdate1              Status: enabled  IP: 10.136.148.29
                                         symmetric VIP state: Owner
       50100 ------->   m7shrdintessl1: 10.136.149.254, 50100 (Active)
       52100 ------->   m7shrdate1amq1: 10.139.59.163, 52100 (remote) (Active)
       60100 ------->   m7shrdinteweb1: 10.136.149.248, 60100 (Active)
       51100 ------->   m7shrdate1amq1: 10.139.59.163, 51100 (remote) (Failed)
       60101 ------->   m7shrdinteweb1: 10.136.149.248, 60101 (Active)
       60102 ------->   m7shrdinteweb1: 10.136.149.248, 60102 (Active)
{noformat}

{noformat}

Virtual server: M7-shrdate5              Status: enabled  IP: 10.136.148.37
                                         symmetric VIP state: Owner
       50500 ------->   m7shrdintessl1: 10.136.149.254, 50500 (Active)
       52500 ------->   m7shrdate5amq1: 10.139.59.132, 52500 (remote) (Active)
       60500 ------->   m7shrdinteweb1: 10.136.149.248, 60500 (Active)
       60501 ------->   m7shrdinteweb1: 10.136.149.248, 60501 (Active)
       60502 ------->   m7shrdinteweb1: 10.136.149.248, 60502 (Active)
{noformat}
","21/Apr/20 10:44;iu252;[~tj898] and me are in contact with LUX PKI-Team to get a new certificate.","22/Apr/20 09:54;iu252;LB was configured by Ioana:

{noformat}

Hi Alexander,
I have configured your request:

Virtual server: M7-shrdate1              Status: enabled  IP: 10.136.148.29
                                         symmetric VIP state: Owner
       50100 ------->   m7shrdintessl1: 10.136.149.254, 50100 (Active)
       52100 ------->   m7shrdate1amq1: 10.139.59.163, 52100 (remote) (Active)
       60100 ------->   m7shrdinteweb1: 10.136.149.248, 60100 (Active)
       51100 ------->   m7shrdate1amq1: 10.139.59.163, 51100 (remote) (Failed)
       60101 ------->   m7shrdinteweb1: 10.136.149.248, 60101 (Active)
       60102 ------->   m7shrdinteweb1: 10.136.149.248, 60102 (Active)
       60103 ------->   m7shrdinteweb1: 10.136.149.248, 60103 (Active)

Virtual server: M7-shrdate5              Status: enabled  IP: 10.136.148.37
                                         symmetric VIP state: Owner
       50500 ------->   m7shrdintessl1: 10.136.149.254, 50500 (Active)
       52500 ------->   m7shrdate5amq1: 10.139.59.132, 52500 (remote) (Active)
       60500 ------->   m7shrdinteweb1: 10.136.149.248, 60500 (Active)
       60501 ------->   m7shrdinteweb1: 10.136.149.248, 60501 (Active)
       60502 ------->   m7shrdinteweb1: 10.136.149.248, 60502 (Active)
       60503 ------->   m7shrdinteweb1: 10.136.149.248, 60503 (Active)
Regards,
Ioana
{noformat}
","22/Apr/20 12:45;iu252;This Client certificate is expired:
{noformat}
[root@m7shrdinteweb1 ssl]# openssl x509 -in /shrd/m7-php-portal/www/php/ssl/pub.pem  -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 75468 (0x126cc)
    Signature Algorithm: sha1WithRSAEncryption
        Issuer: C=DE, O=Exchange, OU=PKI Entity, CN=Gruppe Deutsche Boerse CA
        Validity
            Not Before: Jul 28 07:28:22 2015 GMT
            Not After : Jul 28 07:28:22 2018 GMT
        Subject: C=DE, O=Deutsche Boerse, OU=Energy, OU=M7, OU=shrd-apa, OU=AllNonProd, CN=COMTRADER
        Subject Public Key Info:
{noformat}

Contacted Luk PKI-Team.
Here is the answer:

{noformat}

Hi Alexander,

 

This is much clearer now.

We can now proceed and look into what we have.

 

The certificate that Hugo mentioned is a very very old one that was issued by 

     Issuer: C=DE, O=Exchange, OU=PKI Entity, CN=Gruppe Deutsche Boerse CA

The above Issuer has not been used by the M7 applications since many years now.

 

The M7 certificates have been moved to the new DBAG PKI since a long time and since then a lot of new client certificates have been issued for your application.

 

Can you please confirm that you need a new certificate for the existing client test certificate with :

DN :      cn=COMTRADER|ou=shrd-apa|ou=M7|ou=Energy|o=Deutsche Boerse|c=DE""

Issuer :   CN=TEST Deutsche Boerse AG CA,O=Deutsche Boerse AG,C=DE

 

This is what I found existing in our test dbag pki system : 

 
""cn=COMTRADER|ou=shrd-apa|ou=M7|ou=Energy|o=Deutsche Boerse|c=DE"",""2018-07-13"",""2021-07-13"","""",""557124283861098339656937300059077900323858202304"",""1012"",""M7 shrd-app TEST - 3 Years SSL Client v1.1""
{noformat}

It looks like we should have a valid cert.","22/Apr/20 13:56;iu252;Contacted [~fh971].
He gave me valid CT cert.","22/Apr/20 13:57;iu252;Converted CT cert:

{noformat}
[iu252@enprodauto1 ~/M7C]$ openssl pkcs12 -in certificate.p12 -out pub.pem -nodes
Enter Import Password:
MAC verified OK
[iu252@enprodauto1 ~/M7C]$
{noformat}


{noformat}
[iu252@enprodauto1 ~/M7C]$ openssl x509 -in pub.pem  -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            4d:ba:a5:01:72:9e:20:b3:de:c4:cb:bc:d1:69:2e:30:df:01:36:1c
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=DE, O=Deutsche Boerse AG, CN=TEST Deutsche Boerse AG CA
        Validity
            Not Before: Jul 13 09:36:36 2018 GMT
            Not After : Jul 13 09:36:36 2021 GMT
        Subject: C=DE, O=Deutsche Boerse, OU=Energy, OU=M7, OU=shrd-apa, CN=COMTRADER
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                Modulus:
                    00:99:6f:f2:89:cc:5b:63:8c:22:ff:de:db:19:81:
                    5a:b7:09:08:90:8c:e8:60:2c:12:f0:61:7e:4d:76:
                    ab:b9:2a:6b:2e:00:2c:b8:f9:46:a4:28:4a:71:56:
{noformat}
","22/Apr/20 13:58;iu252; [^pub.pem] ","30/Apr/20 12:46;ef759;Hi Alex,
I tested the certificates for ATE5 and Portal is now running properly with HA Proxy.",,,,,,,,,,,,,,,,,,,
insert admin report subscriptions into flex prod db,M7P-5910,94220,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,dp007,dp007,06/Apr/20 09:29,08/Apr/20 09:54,16/Sep/21 14:11,06/Apr/20 13:55,,6.10.7,6.9.98,7tops_sprint4,,,,,,M7PRODOPS,Reporting_Engine,,,,,,"Please insert the following records into cx_820_subscriber_x_report table:
{code:java}
insert into cx_820_subscriber_x_report values (1,'TC540');
insert into cx_820_subscriber_x_report values (1,'TC810');
insert into cx_820_subscriber_x_report values (1,'TC820');
insert into cx_820_subscriber_x_report values (1,'TC840'); {code}",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,45619200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxf5j:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94220,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,FPROD,,,,"06/Apr/20 09:56;cs687;[~dp007] inserted these 4 lines.

{code:java}
m7tflexprodm7b=# select * from cx_800_subscriber s join cx_820_subscriber_x_report r on s.subscriber_id=r.subscriber_id;
 subscriber_id |    last_update_time     |    last_update_user    | mod_type_code | subscriber_char_id | subscriber_type | subscriber_id | report_type_id
---------------+-------------------------+------------------------+---------------+--------------------+-----------------+---------------+----------------
             2 | 2019-01-09 14:52:33.578 | 9999999999999999SADMIN | SADD          | TEST1              | M               |             2 | TC540
             2 | 2019-01-09 14:52:33.578 | 9999999999999999SADMIN | SADD          | TEST1              | M               |             2 | TC810
             2 | 2019-01-09 14:52:33.578 | 9999999999999999SADMIN | SADD          | TEST1              | M               |             2 | TC820
             2 | 2019-01-09 14:52:33.578 | 9999999999999999SADMIN | SADD          | TEST1              | M               |             2 | TC840
             1 | 2020-04-06 07:29:47.502 | 9999999999999999REPORT | ACTI          | ADMIN              | MS              |             1 | TC540
             1 | 2020-04-06 07:29:47.502 | 9999999999999999REPORT | ACTI          | ADMIN              | MS              |             1 | TC810
             1 | 2020-04-06 07:29:47.502 | 9999999999999999REPORT | ACTI          | ADMIN              | MS              |             1 | TC820
             1 | 2020-04-06 07:29:47.502 | 9999999999999999REPORT | ACTI          | ADMIN              | MS              |             1 | TC840
{code}
","06/Apr/20 10:14;cs687;[~dp007] also confirmed that the subscriptions are still available and the reports are imp lace. 
Just wired that it was somehow resetting before without any changes on our side. 

Our subspition is that epex-admins are maybe using some old webbrowser which is resetting the subscriptions. ","06/Apr/20 11:45;cs687;trying to solve the issue with that deployment: 
https://jira.deutsche-boerse.com/browse/SERVICE-6005","06/Apr/20 13:55;cs687;can be closed SERVICE-6005 solved the issue. ",,,,,,,,,,,,,,,,,,,,,,,,
Reboot Host M7SIMUPDB3,M7P-5897,94149,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,03/Apr/20 07:21,08/Apr/20 09:54,16/Sep/21 14:11,06/Apr/20 19:38,,6.8.121,7tops_sprint4,,,,,,03/Apr/20 00:00,M7PRODOPS,,,,,,,"In the morning i noticed that i can not ssh the host m7simupdb3 anymore. It still seems like in an healthy mode, from the point of database view. 


{color:#DE350B}[cs687@enprodauto1 {db_scan L | +1} ~/ansible/energy.automation.deployments]$ ssh m7simupdb3
ssh_exchange_identification: read: Connection reset by peer{color}



[~cv524] checked the console, but it responds very unreliably.
So we recommend to do a reboot of the host *m7simupdb3*, what is possible without failovering because the Master-Role is for no Environment on the third host. 

for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done
{code:java}
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb3 | 10.139.58.174:24038 |              | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerasimsync | m7simupdb1 | 10.139.58.176:24042 |    Leader    | running |  3 |         0 |
| m7axeerasimsync | m7simupdb2 | 10.139.58.175:24042 | Sync standby | running |  3 |         0 |
| m7axeerasimsync | m7simupdb3 | 10.139.58.174:24042 |              | running |  3 |         0 |
| m7axeerasimsync | m7simupdb4 | 10.139.58.173:24042 |              | running |  3 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeercutesync | m7simupdb1 | 10.139.58.176:24044 |    Leader    | running |  1 |         0 |
| m7axeercutesync | m7simupdb2 | 10.139.58.175:24044 |              | running |  1 |         0 |
| m7axeercutesync | m7simupdb3 | 10.139.58.174:24044 | Sync standby | running |  1 |         0 |
| m7axeercutesync | m7simupdb4 | 10.139.58.173:24044 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeersimusync | m7simupdb1 | 10.139.58.176:24046 |    Leader    | running |  1 |         0 |
| m7axeersimusync | m7simupdb2 | 10.139.58.175:24046 | Sync standby | running |  1 |         0 |
| m7axeersimusync | m7simupdb3 | 10.139.58.174:24046 |              | running |  1 |         0 |
| m7axeersimusync | m7simupdb4 | 10.139.58.173:24046 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsacutasync | m7simupdb1 | 10.139.58.176:24002 | Leader | running |  2 |         0 |
| m7teltsacutasync | m7simupdb2 | 10.139.58.175:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb3 | 10.139.58.174:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb4 | 10.139.58.173:24002 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |           |
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |           |
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltscuteasync | m7simupdb1 | 10.139.58.176:24052 | Leader | running |  2 |         0 |
| m7teltscuteasync | m7simupdb2 | 10.139.58.175:24052 |        | running |  2 |           |
| m7teltscuteasync | m7simupdb3 | 10.139.58.174:24052 |        | running |  2 |           |
| m7teltscuteasync | m7simupdb4 | 10.139.58.173:24052 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltslipaasync | m7simupdb1 | 10.139.58.176:24054 | Leader | running |  3 |         0 |
| m7teltslipaasync | m7simupdb2 | 10.139.58.175:24054 |        | running |  3 |           |
| m7teltslipaasync | m7simupdb3 | 10.139.58.174:24054 |        | running |  3 |           |
| m7teltslipaasync | m7simupdb4 | 10.139.58.173:24054 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010 | Leader | running |  7 |         0 |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010 |        | running |  7 |           |
| m7teltssimuasync | m7simupdb3 | 10.139.58.174:24010 |        | running |  7 |           |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010 |        | running |  7 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | running |  1 |         0 |
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | running |  1 |           |
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader | running |  1 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        | running |  1 |           |
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012  |        | running |  1 |           |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        | running |  1 |           |
+------------------+------------+----------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexsimuasync | m7simupdb1 | 10.139.58.176:24016 | Leader | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb2 | 10.139.58.175:24016 |        | running |  2 |           |
| m7tflexsimuasync | m7simupdb3 | 10.139.58.174:24016 |        | running |  2 |           |
| m7tflexsimuasync | m7simupdb4 | 10.139.58.173:24016 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018 | Leader | running |  2 |         0 |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018 |        | running |  2 |           |
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018 |        | running |  2 |           |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxcuteasync | m7simupdb1 | 10.139.58.176:24020 | Leader | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb2 | 10.139.58.175:24020 |        | running |  3 |           |
| m7thupxcuteasync | m7simupdb3 | 10.139.58.174:24020 |        | running |  3 |           |
| m7thupxcuteasync | m7simupdb4 | 10.139.58.173:24020 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022 | Leader | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022 |        | running |  3 |           |
| m7thupxsimuasync | m7simupdb3 | 10.139.58.174:24022 |        | running |  3 |           |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxlipaasync | m7simupdb1 | 10.139.58.176:24024 | Leader | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb2 | 10.139.58.175:24024 |        | running |  1 |           |
| m7tplpxlipaasync | m7simupdb3 | 10.139.58.174:24024 |        | running |  1 |           |
| m7tplpxlipaasync | m7simupdb4 | 10.139.58.173:24024 |        | running |  1 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026 | Leader | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026 |        | running |  5 |           |
| m7tplpxsimuasync | m7simupdb3 | 10.139.58.174:24026 |        | running |  5 |           |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026 |        | running |  5 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrddst1async | m7simupdb1 | 10.139.58.176:24056 | Leader | running |  2 |         0 |
| m7tshrddst1async | m7simupdb2 | 10.139.58.175:24056 |        | running |  2 |           |
| m7tshrddst1async | m7simupdb3 | 10.139.58.174:24056 |        | running |  2 |           |
| m7tshrddst1async | m7simupdb4 | 10.139.58.173:24056 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdexteasync | m7simupdb1 | 10.139.58.176:24000 | Leader | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb2 | 10.139.58.175:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb3 | 10.139.58.174:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb4 | 10.139.58.173:24000 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmlipaasync | m7simupdb1 | 10.139.58.176:24034 |        | running |  2 |           |
| m7txrpmlipaasync | m7simupdb2 | 10.139.58.175:24034 | Leader | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb3 | 10.139.58.174:24034 |        | running |  2 |           |
| m7txrpmlipaasync | m7simupdb4 | 10.139.58.173:24034 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036 | Leader | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036 |        | running |  4 |           |
| m7txrpmsimuasync | m7simupdb3 | 10.139.58.174:24036 |        | running |  4 |           |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036 |        | running |  4 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028 | Leader | running |  3 |         0 |
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028 |        | running |  3 |           |
| m7txsopasimasync | m7simupdb3 | 10.139.58.174:24028 |        | running |  3 |           |
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopcuteasync | m7simupdb1 | 10.139.58.176:24030 | Leader | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb2 | 10.139.58.175:24030 |        | running |  1 |           |
| m7txsopcuteasync | m7simupdb3 | 10.139.58.174:24030 |        | running |  1 |           |
| m7txsopcuteasync | m7simupdb4 | 10.139.58.173:24030 |        | running |  1 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032 | Leader | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032 |        | running |  4 |           |
| m7txsopsimuasync | m7simupdb3 | 10.139.58.174:24032 |        | running |  4 |           |
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032 |        | running |  4 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
{code}
",,cs687,cv524,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Apr/20 07:31;cv524;m7simupdb3-ilo_console_20200403.png;https://jira.deutsche-boerse.com/secure/attachment/82215/m7simupdb3-ilo_console_20200403.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45532800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzxerr:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94149,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"03/Apr/20 07:31;cv524;Opened console session in ""https://m7simupdb3-ilo"" interface.
Console did not respond to keyboard  inputs

 !m7simupdb3-ilo_console_20200403.png! ","03/Apr/20 10:30;rehapav;Reboot approved.","03/Apr/20 11:00;cs687;Activated Maintenance mode on all the cluster
{code:java}
[root@m7simupdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
{code}

{code:java}
[root@m7simupdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb3 | 10.139.58.174:24038 |              | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerasimsync | m7simupdb1 | 10.139.58.176:24042 |    Leader    | running |  3 |         0 |
| m7axeerasimsync | m7simupdb2 | 10.139.58.175:24042 | Sync standby | running |  3 |         0 |
| m7axeerasimsync | m7simupdb3 | 10.139.58.174:24042 |              | running |  3 |         0 |
| m7axeerasimsync | m7simupdb4 | 10.139.58.173:24042 |              | running |  3 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeercutesync | m7simupdb1 | 10.139.58.176:24044 |    Leader    | running |  1 |         0 |
| m7axeercutesync | m7simupdb2 | 10.139.58.175:24044 |              | running |  1 |         0 |
| m7axeercutesync | m7simupdb3 | 10.139.58.174:24044 | Sync standby | running |  1 |         0 |
| m7axeercutesync | m7simupdb4 | 10.139.58.173:24044 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeersimusync | m7simupdb1 | 10.139.58.176:24046 |    Leader    | running |  1 |         0 |
| m7axeersimusync | m7simupdb2 | 10.139.58.175:24046 | Sync standby | running |  1 |         0 |
| m7axeersimusync | m7simupdb3 | 10.139.58.174:24046 |              | running |  1 |         0 |
| m7axeersimusync | m7simupdb4 | 10.139.58.173:24046 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsacutasync | m7simupdb1 | 10.139.58.176:24002 | Leader | running |  2 |         0 |
| m7teltsacutasync | m7simupdb2 | 10.139.58.175:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb3 | 10.139.58.174:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb4 | 10.139.58.173:24002 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |         0 |
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltscuteasync | m7simupdb1 | 10.139.58.176:24052 | Leader | running |  2 |         0 |
| m7teltscuteasync | m7simupdb2 | 10.139.58.175:24052 |        | running |  2 |         0 |
| m7teltscuteasync | m7simupdb3 | 10.139.58.174:24052 |        | running |  2 |         0 |
| m7teltscuteasync | m7simupdb4 | 10.139.58.173:24052 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltslipaasync | m7simupdb1 | 10.139.58.176:24054 | Leader | running |  3 |         0 |
| m7teltslipaasync | m7simupdb2 | 10.139.58.175:24054 |        | running |  3 |         0 |
| m7teltslipaasync | m7simupdb3 | 10.139.58.174:24054 |        | running |  3 |         0 |
| m7teltslipaasync | m7simupdb4 | 10.139.58.173:24054 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010 | Leader | running |  7 |         0 |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010 |        | running |  7 |         0 |
| m7teltssimuasync | m7simupdb3 | 10.139.58.174:24010 |        | running |  7 |         0 |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010 |        | running |  7 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | running |  1 |         0 |
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | running |  1 |         0 |
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader | running |  1 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        | running |  1 |         0 |
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012  |        | running |  1 |         0 |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        | running |  1 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexsimuasync | m7simupdb1 | 10.139.58.176:24016 | Leader | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb2 | 10.139.58.175:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb3 | 10.139.58.174:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb4 | 10.139.58.173:24016 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018 | Leader | running |  2 |         0 |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxcuteasync | m7simupdb1 | 10.139.58.176:24020 | Leader | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb2 | 10.139.58.175:24020 |        | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb3 | 10.139.58.174:24020 |        | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb4 | 10.139.58.173:24020 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022 | Leader | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb3 | 10.139.58.174:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxlipaasync | m7simupdb1 | 10.139.58.176:24024 | Leader | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb2 | 10.139.58.175:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb3 | 10.139.58.174:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb4 | 10.139.58.173:24024 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026 | Leader | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb3 | 10.139.58.174:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026 |        | running |  5 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrddst1async | m7simupdb1 | 10.139.58.176:24056 | Leader | running |  2 |         0 |
| m7tshrddst1async | m7simupdb2 | 10.139.58.175:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb3 | 10.139.58.174:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb4 | 10.139.58.173:24056 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdexteasync | m7simupdb1 | 10.139.58.176:24000 | Leader | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb2 | 10.139.58.175:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb3 | 10.139.58.174:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb4 | 10.139.58.173:24000 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmlipaasync | m7simupdb1 | 10.139.58.176:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb2 | 10.139.58.175:24034 | Leader | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb3 | 10.139.58.174:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb4 | 10.139.58.173:24034 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036 | Leader | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb3 | 10.139.58.174:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028 | Leader | running |  3 |         0 |
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb3 | 10.139.58.174:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopcuteasync | m7simupdb1 | 10.139.58.176:24030 | Leader | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb2 | 10.139.58.175:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb3 | 10.139.58.174:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb4 | 10.139.58.173:24030 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032 | Leader | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb3 | 10.139.58.174:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
{code}
","03/Apr/20 11:04;cs687;After reboot we have running cluster with 3 nodes (m7simupdb1/2/4)
{code:java}
[root@m7simupdb1 ~]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerasimsync | m7simupdb1 | 10.139.58.176:24042 |    Leader    | running |  3 |         0 |
| m7axeerasimsync | m7simupdb2 | 10.139.58.175:24042 | Sync standby | running |  3 |         0 |
| m7axeerasimsync | m7simupdb4 | 10.139.58.173:24042 |              | running |  3 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeercutesync | m7simupdb1 | 10.139.58.176:24044 |    Leader    | running |  1 |         0 |
| m7axeercutesync | m7simupdb2 | 10.139.58.175:24044 |              | running |  1 |         0 |
| m7axeercutesync | m7simupdb4 | 10.139.58.173:24044 | Sync standby | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeersimusync | m7simupdb1 | 10.139.58.176:24046 |    Leader    | running |  1 |         0 |
| m7axeersimusync | m7simupdb2 | 10.139.58.175:24046 | Sync standby | running |  1 |         0 |
| m7axeersimusync | m7simupdb4 | 10.139.58.173:24046 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsacutasync | m7simupdb1 | 10.139.58.176:24002 | Leader | running |  2 |         0 |
| m7teltsacutasync | m7simupdb2 | 10.139.58.175:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb4 | 10.139.58.173:24002 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |         0 |
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltscuteasync | m7simupdb1 | 10.139.58.176:24052 | Leader | running |  2 |         0 |
| m7teltscuteasync | m7simupdb2 | 10.139.58.175:24052 |        | running |  2 |         0 |
| m7teltscuteasync | m7simupdb4 | 10.139.58.173:24052 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltslipaasync | m7simupdb1 | 10.139.58.176:24054 | Leader | running |  3 |         0 |
| m7teltslipaasync | m7simupdb2 | 10.139.58.175:24054 |        | running |  3 |         0 |
| m7teltslipaasync | m7simupdb4 | 10.139.58.173:24054 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010 | Leader | running |  7 |         0 |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010 |        | running |  7 |         0 |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010 |        | running |  7 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | running |  1 |         0 |
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | running |  1 |         0 |
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader | running |  1 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        | running |  1 |         0 |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        | running |  1 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexsimuasync | m7simupdb1 | 10.139.58.176:24016 | Leader | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb2 | 10.139.58.175:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb4 | 10.139.58.173:24016 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018 | Leader | running |  2 |         0 |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxcuteasync | m7simupdb1 | 10.139.58.176:24020 | Leader | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb2 | 10.139.58.175:24020 |        | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb4 | 10.139.58.173:24020 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022 | Leader | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxlipaasync | m7simupdb1 | 10.139.58.176:24024 | Leader | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb2 | 10.139.58.175:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb4 | 10.139.58.173:24024 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026 | Leader | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026 |        | running |  5 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrddst1async | m7simupdb1 | 10.139.58.176:24056 | Leader | running |  2 |         0 |
| m7tshrddst1async | m7simupdb2 | 10.139.58.175:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb4 | 10.139.58.173:24056 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdexteasync | m7simupdb1 | 10.139.58.176:24000 | Leader | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb2 | 10.139.58.175:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb4 | 10.139.58.173:24000 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmlipaasync | m7simupdb1 | 10.139.58.176:24034 |        | running |  2 |           |
| m7txrpmlipaasync | m7simupdb2 | 10.139.58.175:24034 | Leader | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb4 | 10.139.58.173:24034 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036 | Leader | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036 |        | running |  4 |           |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036 |        | running |  4 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028 | Leader | running |  3 |         0 |
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028 |        | running |  3 |           |
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopcuteasync | m7simupdb1 | 10.139.58.176:24030 | Leader | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb2 | 10.139.58.175:24030 |        | running |  1 |           |
| m7txsopcuteasync | m7simupdb4 | 10.139.58.173:24030 |        | running |  1 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032 | Leader | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032 |        | running |  4 |           |
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032 |        | running |  4 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
{code}
","03/Apr/20 11:47;cv524;Friday 03.04.2020 11:01
Initiated reset of ""m7simupdb3"" physical host

System refused to boot in regular condition and was forced to switch into ""Maintenace Mode""
System declared ""Invalid superblock magic number"" on block device ""md-81"".
This block device corresponds to ""logical volume"" - ""/dev/datavg/lv_journal_m7epexasimm7b""
Mentioned logical volume is used as ""brick"" of ""GlusterFS"" volume ""journal_m7epexasimm7b""
""GlusterFS"" service was stopped and disabled mounting of mentioned logical volume into filesystem structure.

Friday 03.04.2020 11:36
Reboot process was repeated and system started to run.
System is reachable by ""SSH"" and major services are available.","03/Apr/20 11:51;cv524;Due to fact
* the ""GlusterFS"" brick """"/dev/datavg/lv_journal_m7epexasimm7b"" is corrupt, fixing operations are needed to restore the ""GlusterFS"" service.
* it was discovered one of physical disks is corrupt and requires replacement, relevant ""HP Support"" ticket will be created.","03/Apr/20 15:14;cv524;The e-mail request to HP Support was created and acceptance for support assistance was confirmed

HP Support ticket number: 5346345175  
{quote}==============================================================================
From: Support Center <support.center@hpe.com> 
Sent: Friday, April 3, 2020 2:08 PM
To: Lambert Neky <lambert.neky@deutsche-boerse.com>
Cc: Steffen Englert <steffen.englert@deutsche-boerse.com>; Support Center <support.center@hpe.com>
Subject: RE: Disk failure on HP ProLiant DL380 G10 (cefdxcl1) / 5346345175 

Dear Lambert Neky,
Thank you for contacting Hewlett Packard Enterprise. 
I would like to inform you that case 5346345175  has been created and forwarded to our technical department. A team representative will contact you in order to start technical analysis. 
Please contact us in case of any further questions.
 
Best Regards
 
Iglika Rizova

Support Agent

Customer Solution Center
HPE Pointnext Services

Technical Support Phone Numbers

Sofia, Bulgaria
hpe.com/pointnext
 
 
From: Lambert Neky [mailto:lambert.neky@deutsche-boerse.com] 
Sent: Friday, April 3, 2020 1:50 PM
To: Support Center <support.center@hpe.com>
Cc: Steffen Englert <steffen.englert@deutsche-boerse.com>
Subject: Disk failure on HP ProLiant DL380 G10 (cefdxcl1)
 
The below email is classified: Internal
 
Hello,
 
please, provide us new disks delivery. Failed disk replacement will be executed by on-site HP technicians. 
 
Disk replacement can be executed after granting permission to access the cabinet only.
 
 
Priority: high               
 
\*\*\* Call opened by: \*\*\*\*
Deutsche Börse employee: Lambert Neky
Phone Number: +49 (0)69 211 - 12607
 
\*\*\* ADDRESS INFO \*\*\* 
Company Name: Deutsche Boerse AG
Location: Campus Equinix/Floor F00/Room Mod4.3/Cabinet AW30/HU 33
Street: Kruppstr. 121
Zip code: 60388
City: Frankfurt
Country: Germany
 
\*\*\* PRODUCT INFO \*\*\*
Product Type: HP, ProLiant DL380 G10
Serial Number: CZ29130H3X
Hostname: m7simupdb3
 
 
\*\*\* PROBLEM DESCRIPTION \*\*\*
########################################
\-  Physical Drive in Port 1I Box 3 Bay 1 
Status  Failed  
Serial Number 190520830335 
Model VK000240GWEZB 
Media Type SSD 
Capacity 240 GB 
Location Port 1I Box 3 Bay 1 
Firmware Version HPGB 
Drive Configuration Configured 
Encryption Status Not Encrypted
##########################################
 
 
 
Thanks in advance.
 
 
 
 
 
Rgds.,

Lambert Neky
Deutsche Börse Group
Mergenthalerallee 61
D-65760 Frankfurt am Main

Phone  +49 69 211 12607
E-Mail  lambert.neky@deutsche-boerse.com
=============================================================================={quote}","03/Apr/20 15:21;cv524;""GlusterFS"" brick was fixed and relevant volume was restored into full health condition

{noformat}
################################################################################################
[root@m7simupdb3 ~]# gluster volume status journal_m7epexasimm7b
Status of volume: journal_m7epexasimm7b
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick m7simupdb1:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       26939
Brick m7simupdb2:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       19799
Brick m7simupdb3:/opt/gluster_volumes/journ
al/m7epexasimm7b                            N/A       N/A        N       N/A
Brick m7simupdb4:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       13479
NFS Server on localhost                     2049      0          Y       36423
Self-heal Daemon on localhost               N/A       N/A        Y       36433
NFS Server on m7simupdb1.deutsche-boerse.de 2049      0          Y       30199
Self-heal Daemon on m7simupdb1.deutsche-boe
rse.de                                      N/A       N/A        Y       30215
NFS Server on m7simupdb2                    2049      0          Y       14460
Self-heal Daemon on m7simupdb2              N/A       N/A        Y       14521
NFS Server on m7simupdb4                    2049      0          Y       42746
Self-heal Daemon on m7simupdb4              N/A       N/A        Y       42755

Task Status of Volume journal_m7epexasimm7b
------------------------------------------------------------------------------
There are no active volume tasks

[root@m7simupdb3 ~]#[root@m7simupdb3 ~]# gluster volume remove-brick journal_m7epexasimm7b replica 3 m7simupdb3:/opt/gluster_volumes/journal/m7epexasimm7b force
Removing brick(s) can result in data loss. Do you want to Continue? (y/n) y
volume remove-brick commit force: success
[root@m7simupdb3 ~]# gluster volume status journal_m7epexasimm7b
Status of volume: journal_m7epexasimm7b
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick m7simupdb1:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       26939
Brick m7simupdb2:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       19799
Brick m7simupdb4:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       13479
NFS Server on localhost                     2049      0          Y       38070
Self-heal Daemon on localhost               N/A       N/A        Y       38080
NFS Server on m7simupdb2                    2049      0          Y       16172
Self-heal Daemon on m7simupdb2              N/A       N/A        Y       16181
NFS Server on m7simupdb1.deutsche-boerse.de 2049      0          Y       32641
Self-heal Daemon on m7simupdb1.deutsche-boe
rse.de                                      N/A       N/A        Y       32653
NFS Server on m7simupdb4                    2049      0          Y       44197
Self-heal Daemon on m7simupdb4              N/A       N/A        Y       44207

Task Status of Volume journal_m7epexasimm7b
------------------------------------------------------------------------------
There are no active volume tasks

[root@m7simupdb3 ~]# umount /opt/gluster_volumes/journal/m7epexasimm7b
[root@m7simupdb3 ~]# mkfs.xfs -f /dev/datavg/lv_journal_m7epexasimm7b
meta-data=/dev/datavg/lv_journal_m7epexasimm7b isize=512    agcount=4, agsize=327680 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0, sparse=0
data     =                       bsize=4096   blocks=1310720, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
[root@m7simupdb3 ~]# mount /opt/gluster_volumes/journal/m7epexasimm7b
[root@m7simupdb3 ~]# gluster volume add-brick journal_m7epexasimm7b replica 4 m7simupdb3:/opt/gluster_volumes/journal/m7epexasimm7b force
volume add-brick: success
[root@m7simupdb3 ~]# gluster volume status journal_m7epexasimm7b
Status of volume: journal_m7epexasimm7b
Gluster process                             TCP Port  RDMA Port  Online  Pid
------------------------------------------------------------------------------
Brick m7simupdb1:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       26939
Brick m7simupdb2:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       19799
Brick m7simupdb4:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49170     0          Y       13479
Brick m7simupdb3:/opt/gluster_volumes/journ
al/m7epexasimm7b                            49172     0          Y       39289
NFS Server on localhost                     2049      0          Y       39311
Self-heal Daemon on localhost               N/A       N/A        Y       39320
NFS Server on m7simupdb2                    2049      0          Y       17214
Self-heal Daemon on m7simupdb2              N/A       N/A        Y       17225
NFS Server on m7simupdb1.deutsche-boerse.de 2049      0          Y       34487
Self-heal Daemon on m7simupdb1.deutsche-boe
rse.de                                      N/A       N/A        Y       34502
NFS Server on m7simupdb4                    2049      0          Y       45214
Self-heal Daemon on m7simupdb4              N/A       N/A        Y       45224

Task Status of Volume journal_m7epexasimm7b
------------------------------------------------------------------------------
There are no active volume tasks

[root@m7simupdb3 ~]#
################################################################################################
{noformat}
","06/Apr/20 11:10;cv524;Consultation HP technician Dietmar Schaefer and agreed the disk replacement instructions. According to reply, Jakub Skowronski, HP technician will execute requested operation.
{quote}==============================================================================
From: Carsten Boehm EXT <carsten.boehm.ext@deutsche-boerse.com> 
Sent: Monday, April 6, 2020 10:56 AM
To: Lambert Neky <lambert.neky@deutsche-boerse.com>; &HP-Engineer <&HP-Engineer@deutsche-boerse.com>
Cc: Steffen Englert <steffen.englert@deutsche-boerse.com>
Subject: RE: HP Support ticket 5346345175 - ""m7simupdb3"" failed disk replacement

The below email is classified: Internal

Hello,

The late shift will do this today: Jakub Skowronski

Best regards

Carsten Boehm

From: Lambert Neky <lambert.neky@deutsche-boerse.com> 
Sent: Monday, April 6, 2020 10:53 AM
To: &HP-Engineer <&HP-Engineer@deutsche-boerse.com>
Cc: Steffen Englert <steffen.englert@deutsche-boerse.com>
Subject: HP Support ticket 5346345175 - ""m7simupdb3"" failed disk replacement

The below email is classified: Internal

Hello everybody,


according to discussion with Dietmar Schaefer following instructions were agreed

Date of replacement: 06.04.2020
Time of replacement: 19:30
Device name : m7simupdb3 (Indicator LED is “SWITCHED ON”)
Location: Campus Equinix/Floor F00/Room Mod4.3/Cabinet AW30/HU 33
The disk definition: physicaldrive 1I:3:1 (port 1I:box 3:bay 1, SATA SSD, 240 GB
Energy TechOps contact person: Steffen Englert
Contact telephone number : 13077

Please inform us in reply to this e-mail, who will actually run the replacement operation.

In case of additional questions, please contact me, or colleague Steffen Englert.

Thank you in advance

Rgds.,

Lambert Neky
Deutsche Börse Group
Mergenthalerallee 61
D-65760 Frankfurt am Main

Phone  +49 69 211 12607
E-Mail  lambert.neky@deutsche-boerse.com
=============================================================================={quote}","06/Apr/20 19:34;cs687;1.) Before HP Technician Support replaced the disks, i paused the cluster ""maintaining mode"" 

2.) checking with the command *ssacli ctrl slot=0 pd 1I:3:1 show detail*
disk-replace started 7:30pm
{code:java}
[root@m7simupdb3 ~]# ssacli ctrl slot=0 pd 1I:3:1 show detail
HPE Smart Array P408i-a SR Gen10 in Slot 0 (Embedded)

   Array A

      physicaldrive 1I:3:1
         Port: 1I
         Box: 3
         Bay: 1
         Status: Rebuilding
         Drive Type: Data Drive
         Interface Type: Solid State SATA
         Size: 480 GB
         Drive exposed to OS: False
         Logical/Physical Block Size: 512/4096
         Firmware Revision: HPG2
         Serial Number: 200926BE71A7
         WWID: 31402EC012A337D3
         Model: ATA     VK000480GWSXF
         SATA NCQ Capable: True
         SATA NCQ Enabled: True
         Current Temperature (C): 29
         Maximum Temperature (C): 29
         Usage remaining: 100.00%
         Power On Hours: 0
         SSD Smart Trip Wearout: False
         PHY Count: 1
         PHY Transfer Rate: 6.0Gbps
         Drive Authentication Status: OK
         Carrier Application Version: 11
         Carrier Bootloader Version: 6
         Sanitize Erase Supported: True
         Sanitize Freeze Lock Supported: True
         Sanitize Anti-Freeze Lock Supported: True
         Sanitize Lock: None
         Sanitize Estimated Max Erase Time: 0 minute(s), 55 second(s)
         Unrestricted Sanitize Supported: True
         Shingled Magnetic Recording Support: None
         Drive Unique ID: CC3159EDFC30D940AE91B424434AB004
{code}

 ","06/Apr/20 19:35;cs687;rebuilding finished -> {color:#00875A}status ok{color}

{code:java}
[root@m7simupdb3 ~]# ssacli ctrl slot=0 pd 1I:3:1 show detail

HPE Smart Array P408i-a SR Gen10 in Slot 0 (Embedded)

   Array A

      physicaldrive 1I:3:1
         Port: 1I
         Box: 3
         Bay: 1
         Status: OK
         Drive Type: Data Drive
         Interface Type: Solid State SATA
         Size: 480 GB
         Drive exposed to OS: False
         Logical/Physical Block Size: 512/4096
         Firmware Revision: HPG2
         Serial Number: 200926BE71A7
         WWID: 31402EC012A337D3
         Model: ATA     VK000480GWSXF
         SATA NCQ Capable: True
         SATA NCQ Enabled: True
         Current Temperature (C): 28
         Maximum Temperature (C): 30
         Usage remaining: 100.00%
         Power On Hours: 0
         SSD Smart Trip Wearout: False
         PHY Count: 1
         PHY Transfer Rate: 6.0Gbps
         Drive Authentication Status: OK
         Carrier Application Version: 11
         Carrier Bootloader Version: 6
         Sanitize Erase Supported: True
         Sanitize Freeze Lock Supported: True
         Sanitize Anti-Freeze Lock Supported: True
         Sanitize Lock: None
         Sanitize Estimated Max Erase Time: 0 minute(s), 55 second(s)
         Unrestricted Sanitize Supported: True
         Shingled Magnetic Recording Support: None
         Drive Unique ID: CC3159EDFC30D940AE91B424434AB004
{code}
","06/Apr/20 19:38;cs687;deactivating maintenance mode 
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume; done","06/Apr/20 19:38;cs687;done",,,,,,,,,,,,,,,
Clean up old instances on shrd-test env´s,M7P-5895,94134,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,02/Apr/20 15:40,28/Apr/20 23:40,16/Sep/21 14:11,20/Apr/20 10:49,,6.8.126,7tops_Sprint5,,,,,,,M7PRODOPS,,,,,,,"During Upgrading-Process of test(syt/ate) machines it come to confusion because there several instance dir´s existing. 

so to prevent future confusion we should clean up the older instance-dirs when they are still existing. 

Just for example: *ate5* m7shrdate5amq1
{code:java}
[root@m7shrdate5amq1 shrd]# ll
total 36
drwxr-x--- 11 rabbitmq rabbitmq  4096 Mar  6 15:39 m7-shrd-ate5-amq1
drwxr-x--- 10 rabbitmq rabbitmq  4096 Mar  6 15:32 m7-shrd-ate5-amq1.bkp
drwxr-xr-x 11 rabbitmq rabbitmq  4096 Mar 23 14:15 shrd-ate5-amq1
{code}

has 2 different amq instances (shrd-ate5-amq1, m7-shrd-ate5-amq1), but only ""shrd-ate5-amq1"" is running and used: 

we should go through our Hosts and check such of this scenarios for amq, tomcat, web, ssl hosts and clean them up if necessary. ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44409600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzwvgv:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94134,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Apr/20 10:22;cs687;Cleaned up:
* m7shrdate1ap
* m7shrdate1amq1
* m7shrdate2apa1
* m7shrdate2amq1
* m7shrdate4amq1
* m7shrdate5apa1
* m7shrdate5amq1
* m7shrdsyt1amq1
* m7shrdsyt1amq9
* m7shrdsyt3apa1

",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: implement https cert on ComTrader download page SIMU,M7P-5892,94110,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Duplicate,dp007,dp007,dp007,02/Apr/20 13:21,07/Oct/20 11:37,16/Sep/21 14:11,05/Oct/20 15:24,,7tops_sprint102,,,,ComTrader,Customer Portal,,03/Apr/20 00:00,ComTrader,M7PRODOPS,,,,,,"Dear all,

as discussed earlier, we would like to update the ComTrader download pages from http to https. Firstly we would like to try this with SIMU environment. Therefore please find attached the issued certificate to implement here please: [http://comtrader-simu.epexspot.com/]

Furthermore: Can you please create an automatic forwarding, so that when someone opens http-page, it will automatically forwarded to https-page. Will that be possible?

If it works successfully, we would like to extend it to other environments as well.
 Please let me know if this requires any further information.

BR, Kaja

 

*TODO:*

*1) Apply attached certificate - 7TOPS*

*2) update ComTrader's pom file in 6.8 and 6.9*",,dp007,,,,,,,,,,,,,,,,,,,SERVICE-5981,,,,,,,,,,,,,,,,,,,,"02/Apr/20 13:21;dp007;comtrader-simu.epexspot.com.key.txt;https://jira.deutsche-boerse.com/secure/attachment/82170/comtrader-simu.epexspot.com.key.txt","02/Apr/20 13:21;dp007;comtrader-simu.epexspot.com.pem.txt;https://jira.deutsche-boerse.com/secure/attachment/82171/comtrader-simu.epexspot.com.pem.txt",,,,,,,,,,,,,,sw455,,,,,,,,problem solved by Customer Portal which by its nature (as AWS S3 bucket) contains HTTPS.,,,,,,,,ELTS,,,,,,Other Service Request,,,,,,,,,,29808000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxecf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,7tops Sprint 10,7tops Sprint 11,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,7tops Sprint 15,7tops Sprint 102,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94110,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"02/Apr/20 13:52;dp007;Ad 1) webadmin team notified, waiting for their timeline proposal.

Ad 2) [~fh971]: could you please implement the change in comtrader's pom file?","05/Oct/20 15:23;dp007;Problem solved by Customer Portal.",,,,,,,,,,,,,,,,,,,,,,,,,,
Consul Cert Renewal for M7-Product Family ,M7P-5890,94108,,Epic,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,02/Apr/20 12:37,16/Dec/20 11:16,16/Sep/21 14:11,14/Dec/20 15:23,,7tops_sprint107,,,,,,,30/Apr/20 00:00,M7PRODOPS,,,,,,,"our Consul certificates are running for 1 year than it will expire and the database will not be reachable during that time because consul is required for patroni-setup. 

Just checked for *M7-Simu* & *M7-Prod* the current situation: 

*openssl x509 -in /etc/consul/ssl/server.crt -noout -text*

{color:#DE350B}*Validity for Production until January next year*{color}
    Not Before: Jan 13 22:08:33 2020 GMT
    Not After : Jan 12 22:08:33 2021 GMT

hosts:
* {color:#DE350B}enprodcons1{color}
* {color:#DE350B}enprodcons2{color}
* {color:#DE350B}enprodcons3{color}
* {color:#DE350B}enprodcons4{color}
* {color:#DE350B}enprodcons5{color}
* {color:#DE350B}enprodcons6{color}

{color:#DE350B}*Validity for Simulation until end of this year*{color}
    Not Before: Dec 19 23:47:10 2019 GMT
    Not After : Dec 18 23:47:10 2020 GMT

* {color:#DE350B}ensimucons1{color}
* {color:#DE350B}ensimucons2{color}
* {color:#DE350B}ensimucons3{color}
* {color:#DE350B}ensimucons4{color}
* {color:#DE350B}ensimucons5{color}
* {color:#DE350B}ensimucons6{color}

*Validity for Test*
    Not Before: Mar 10 11:59:09 2020 GMT
    Not After : Mar 10 11:59:09 2021 GMT

+Which steps are to do:+
1.) clone repository energy.automation.deployment
https://github.deutsche-boerse.de/dev/energy.automation.deployments

2.) ""pause"" patroni cluster to activate maintenance mode, that failover is deactivated  
*for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done*
and check with list command, if the maintenance mode is activated.
*example*:
{code:java}
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt1async | m7testpdb1 | 10.139.58.178:26002 | Leader | running |  3 |         0 |
| m7tshrdsyt1async | m7testpdb2 | 10.139.58.177:26002 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml pause
Success: cluster management is paused
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt1async | m7testpdb1 | 10.139.58.178:26002 | Leader | running |  3 |         0 |
| m7tshrdsyt1async | m7testpdb2 | 10.139.58.177:26002 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
{code}


3.) go to vault where certs are located */secret/global/consul/energy-shrd-prod*
and backup the secrets for example on enprodauto1:
* ca_cert
* ca_key
* client_cert
* client_key
* server_cert
* server_key

https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/global/consul/energy-shrd-prod/?redirect_to=%2Fvault%2Fsecrets
renaming ca_cert to consul-agent-ca.pem and ca_key to consul-agent-ca-key.pem

4.) set the proper environment variables
export CONSUL_DC=energy-shrd-prod && \
export CONSUL_BINARY=/usr/local/bin/consul && \

check if the consul binary is existing on the host enprodauto1
[cs687@enprodauto1 {db_scan L | +2} ~/ansible/energy.automation.deployments]$ ls -all /usr/local/bin/consul
-rwxr-xr-x 1 root root 118511318 Nov 13 22:45 /usr/local/bin/consul

5.) remove from vault the mentioned secrets above

6.) execute script, which will generate new certs, afterwards check if vault has updated secrets
roles/consul_instance/create-consul-cluster.sh

7.) run the deployment 
ansible-playbook -e consul_group_name=consul-energy-shrd-prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass --list-hosts
ansible-playbook -e consul_group_name=consul-energy-shrd-prod playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass

8.) Check consul logs on server and client nodes if all is running fine
journalctl -u consul

9.) deactivate the maintenance mode again
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume; done
{code:java}
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml resume
Success: cluster management is resumed
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7tshrdsyt1async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdsyt1async | m7testpdb1 | 10.139.58.178:26002 | Leader | running |  3 |         0 |
| m7tshrdsyt1async | m7testpdb2 | 10.139.58.177:26002 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+

{code}

10.) Check patroni logs for any consul related problems, example
journalctl -u patroni_m7teltsprodasync.service

mentioned steps can be confirmed with [~hw120] to be on the safe side. These steps has to be done only once for all the M7-Simu and M7-Prod Database-Env´s. 
I would suggest to plan some maintenance window time for all the M7 Customers (maybe out of business hour) to renew the cert properly. 

Already checked with [~iv732] that the certificates checks for M7 PROD and SIMU are already in-place of the monitoring cert check. We should be reminded 30 days before the expiring-date!",,cs687,hw120,zv517,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44841600,,,dm700,lw641,ox626,rehapav,sw455,,,,,Consul Cert Renewal,To Do,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzn2wn:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94108,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/20 16:50;hw120;Updated the process, it should be fine now. Also extended validity of created certs and checked if monitoring is set properly.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Please restart cor and enq on ELTS LIPA,M7P-5889,94102,93929,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,jv861,jv861,02/Apr/20 10:58,08/Apr/20 09:54,16/Sep/21 14:11,02/Apr/20 11:19,,7tops_sprint4,,,,,,,,M7PRODOPS,,,,,,,"After Rabbitmq restart ([M7P-5883]), enqs can't connect to the core, so noone can login. Please restart both cor and enq, so we are sure M7 is in heathy state",,jv861,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45964800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxebb:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 89 (PS),Schmetterling Sprint 90 (PS),Schmetterling Sprint 91,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94102,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"02/Apr/20 11:19;pd122;restarted: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/CD-Pipeline/job/deploy_custom/217/console",,,,,,,,,,,,,,,,,,,,,,,,,,,
Broken Rabbitmq cluster on ELTS LIPA,M7P-5883,94083,93929,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,pd122,jv861,jv861,01/Apr/20 17:29,22/Apr/20 15:06,16/Sep/21 14:11,14/Apr/20 09:45,,7tops_Sprint5,,,,,,,,M7PRODOPS,,,,,,,"When opening Rabbitq console on m7eltsliparmq1: http://10.136.148.39:52760/#/ it seems like nodes 3 and 5 are down (or not connected to cluster). Could you please make sure cluster is up and running?

Also finding a root cause of the problem could help prevent similar problem in PROD, currently two thirds of the users can't connect to the environemnt",,jv861,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44841600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxe6n:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 89 (PS),Schmetterling Sprint 90 (PS),Schmetterling Sprint 91,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94083,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/20 18:34;pd122;Console showed nodes 3 and 5 down.  No obvious issue on node3, restarted it, all 3 nodes appear online afterwards.","02/Apr/20 11:29;pd122;Trying to find something interesting in the log, this was the last message before the restart at 2020-04-01 18:30:16.430:
{code:java}
2020-04-01 12:48:02.191 [warning] <0.1095.0> rabbit_sysmon_handler busy_dist_port <0.1449.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.27>,unknown}{code}
 

before it, nothing for a almost 2 days, just this:
{code:java}
2020-03-30 15:45:19.441 [info] <0.26516.383> Mirrored queue 'm7.response.M7USRDAN' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.15039.501>
2020-03-30 15:45:19.449 [info] <0.26516.383> Mirrored queue 'm7.response.M7USRDAN' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 15:45:19.449 [info] <0.26516.383> Mirrored queue 'm7.response.M7USRDAN' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 15:45:19.454 [info] <0.26478.383> Mirrored queue 'm7.response.M7USRDAN' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 15:45:19.636 [info] <0.26683.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.15110.501>
2020-03-30 15:45:19.645 [info] <0.26683.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 15:45:19.645 [info] <0.26683.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 15:45:19.652 [info] <0.26631.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 15:58:43.259 [info] <0.28877.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.17776.501>
2020-03-30 15:58:43.267 [info] <0.28877.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 15:58:43.267 [info] <0.28877.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 15:58:43.271 [info] <0.28875.383> Mirrored queue 'm7.response.M7USREDF' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 16:00:02.817 [info] <0.1436.0> webmachine_log_handler: closing log file: ""/elts/logs/elts-lipa-amq3/access.log""
2020-03-30 16:00:02.817 [info] <0.1436.0> opening log file: ""/elts/logs/elts-lipa-amq3/access.log.2020_03_30_14""
2020-03-30 16:01:46.702 [info] <0.29456.383> Mirrored queue 'm7.broadcastQueue.CXSTLM01' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.18435.501>
2020-03-30 16:01:46.709 [info] <0.29456.383> Mirrored queue 'm7.broadcastQueue.CXSTLM01' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 16:01:46.709 [info] <0.29456.383> Mirrored queue 'm7.broadcastQueue.CXSTLM01' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 16:01:46.713 [info] <0.29458.383> Mirrored queue 'm7.broadcastQueue.CXSTLM01' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 16:05:33.270 [info] <0.30107.383> Mirrored queue 'm7.broadcastQueue.M7USRDAN' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.19257.501>
2020-03-30 16:05:33.277 [info] <0.30107.383> Mirrored queue 'm7.broadcastQueue.M7USRDAN' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 16:05:33.277 [info] <0.30107.383> Mirrored queue 'm7.broadcastQueue.M7USRDAN' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 16:05:33.283 [info] <0.30073.383> Mirrored queue 'm7.broadcastQueue.M7USRDAN' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 16:05:33.468 [info] <0.30243.383> Mirrored queue 'm7.broadcastQueue.M7USREDF' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.19316.501>
2020-03-30 16:05:33.476 [info] <0.30243.383> Mirrored queue 'm7.broadcastQueue.M7USREDF' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 16:05:33.476 [info] <0.30243.383> Mirrored queue 'm7.broadcastQueue.M7USREDF' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 16:05:33.481 [info] <0.30275.383> Mirrored queue 'm7.broadcastQueue.M7USREDF' in vhost 'app': Synchronising: all slaves already synced
2020-03-30 16:06:46.024 [info] <0.30488.383> Mirrored queue 'm7.broadcastQueue.M7ADM001' in vhost 'app': Adding mirror on node 'elts-lipa-amq5@m7eltslipaamq5': <40348.19471.501>
2020-03-30 16:06:46.032 [info] <0.30488.383> Mirrored queue 'm7.broadcastQueue.M7ADM001' in vhost 'app': Synchronising: 0 messages to synchronise
2020-03-30 16:06:46.032 [info] <0.30488.383> Mirrored queue 'm7.broadcastQueue.M7ADM001' in vhost 'app': Synchronising: batch size: 4096
2020-03-30 16:06:46.036 [info] <0.30491.383> Mirrored queue 'm7.broadcastQueue.M7ADM001' in vhost 'app': Synchronising: all slaves already synced{code}","06/Apr/20 13:40;pd122;A bunch of busy_dist_port warning messages in log on nodes 3 and 5:
{code:java}
2020-02-20 23:16:04.223 [warning] <0.1095.0> rabbit_sysmon_handler busy_dist_port <0.1449.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.27>,unknown}
2020-04-01 12:48:02.191 [warning] <0.1095.0> rabbit_sysmon_handler busy_dist_port <0.1449.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.27>,unknown}{code}
{code:java}
2020-01-31 11:12:31.662 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,drain,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-01 12:19:03.665 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{proplists,get_value,3},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-04 03:42:32.217 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-04 08:11:34.445 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,retention_policy,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-05 03:55:30.333 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-07 02:29:00.105 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,drain,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-08 04:12:32.141 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,'-select_smaller_sample/1-lc$^0/1-0-',1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-15 11:02:31.185 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-23 00:35:00.668 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-25 05:15:31.110 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-27 04:36:30.837 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-02-29 13:40:30.164 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-07 07:21:33.813 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,maybe_convert_for_compatibility,2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-09 13:08:01.606 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{lists,sublist_2,2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-13 23:14:04.958 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-18 03:24:03.675 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-23 02:01:34.596 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-25 03:28:32.316 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{ets,lookup,2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-25 07:22:31.723 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-26 17:05:34.197 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,exchange_raw_detail_stats_data,2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-27 23:16:34.276 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-28 17:18:33.437 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-29 01:56:34.509 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,raw_message_data,3},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-29 10:36:33.102 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{ets,lookup,2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-30 01:23:34.429 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-03-30 14:57:04.724 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{rabbit_mgmt_data,'-all_exchange_data/3-lc$^0/1-0-',2},{message_queue_len,0}] {#Port<0.26>,unknown}
2020-04-01 04:23:35.372 [warning] <0.1090.0> rabbit_sysmon_handler busy_dist_port <0.1442.0> [{name,delegate_management_2},{initial_call,{delegate,init,1}},{gen_server2,process_next_msg,1},{message_queue_len,0}] {#Port<0.26>,unknown}{code}","08/Apr/20 16:35;pd122;*busy_dist_port* is likely caused by RABBITMQ_DISTRIBUTION_BUFFER_SIZE nearing its full capacity. Current setting (default) is 128000K:
{code:java}
/elts/elts-lipa-amqX/sbin/rabbitmq-env:DEFAULT_DISTRIBUTION_BUFFER_SIZE=128000
/elts/elts-lipa-amqX/sbin/rabbitmq-env:[ -n ""$RABBITMQ_DISTRIBUTION_BUFFER_SIZE"" ] || RABBITMQ_DISTRIBUTION_BUFFER_SIZE=""$DISTRIBUTION_BUFFER_SIZE""{code}
Perhaps that value could be (slightly) increased (e.g. to 192000K) , however I would not think it is the cause.","08/Apr/20 16:43;pd122;The AMQ VMs were migrated to our new ESX cluster on March 26th around 11am.  While unlikely, I would not completely rule out the possibility of it having such an undesired impact.  We would need to be sure the problems started to occur around the specified date though, which I understand we are not.","08/Apr/20 17:28;pd122;File descriptor limits differ wildly across the cluster:
 * soft limit:
 ** amq1: 1024
 ** amq3,5: 65000
 * hard limit:
 ** amq1: 4096
 ** amq3,5: 65000

While not sure this had caused the cluster disintegration, it is definitely not desirable for the nodes to differ so substantially.  I have modified the setup on amq1 to be the same as on nodes 2 and 3. RMQ restart on node 1 required for it to take effect.","14/Apr/20 14:48;pd122;elts-lipa-amq1 has been restarted, all cluster nodes now report 65000 available file descriptors",,,,,,,,,,,,,,,,,,,,,
"Decommission old VM ""M7TGEX""",M7P-5874,94055,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,01/Apr/20 11:29,29/Jun/20 12:56,16/Sep/21 14:11,09/Apr/20 11:14,,6.10.14,7tops_Sprint5,,,,,,30/Apr/20 00:00,M7PRODOPS,,,,,,,"We should decommission the old VM´s 
M7TGEXSIMUAMQ1
M7TGEXSIMUAMQ2
M7TGEXSIMUM7B1
M7TGEXSIMUM7B2",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45360000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx9uf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":94055,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"09/Apr/20 11:14;cs687;Deletion of the VM´s will be handled by [~wm282]
He is anyways creating Deletion NSR Request for more VMS and will just include them.

It was a part of ""general spring cleaning""  :) 

Done! Thanks [~wm282]",,,,,,,,,,,,,,,,,,,,,,,,,,,
Kibana access for Ondra Strba,M7P-5871,93969,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,qz412,qz412,31/Mar/20 14:39,17/Dec/20 15:26,16/Sep/21 14:11,01/Apr/20 08:37,,6.10.4,6.9.91,7tops_sprint4,,,,,,M7PRODOPS,,,,,,,"Please grant access rights to Kibana to Ondra Strba.

If there is any more specific access right setup with regards to projects / spaces / etc., please use an X-Men developer (e.g. P. Ceska) as a template. Thank you.",,cs687,qz412,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46051200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxdjb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93969,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"01/Apr/20 08:37;cs687;Good Morning [~qz412], 

is not possible to create dedicated user-accounts in kibana. 
We have just user accounts for each group/team, so like for dev we have the following one

*user-name:* dev
*assigned email:* EnergyTeam_Dev_ALL@deutsche-boerse.com
*role*: kibana_user, energy_user, watcher_admin

Please check that with your colleagues who are using already kibana, they should provide you the proper password. 

thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,
BizOps: Create a Read-Only on ICS PROD with access to all borders,M7P-5861,93922,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,qz412,qz412,30/Mar/20 14:26,08/Apr/20 09:54,16/Sep/21 14:11,30/Mar/20 14:54,,6.8.115,7tops_sprint4,,,ICS,,,,M7PRODOPS,,,,,,,"Please create a Read-Only User on ICS PROD so that ENTSO-E EMFIP data files can be checked.

The user shall be the exact copy of currently existing DB0TEST1 user with the only difference being in the BG used - the new user shall be assigned to following BG:
 * 01-ADMIN-ALL—L

For your convenience I am listing also all other configuration parameters.
 * LoginID: Anything that suits your naming conventions
 * Suspended: NO
 * EIC Code: 01-ADMIN-ALL—L
 * User Code: Anything the application forces
 * E-mail address: [ondrej.strba@deutsche-boerse.com|mailto:ondrej.strba@deutsche-boerse.com]
 * Certificate: None

!image-2020-03-30-14-34-07-457.png|width=334,height=142!

User Roles to be applied:

!image-2020-03-30-14-34-37-632.png|width=333,height=241!

Thank you, Ondra",,dp007,qz412,,,,,,,,,,,,,,,,,,M7P-5783,,,,,,,,,,,,,,,,,,,,"30/Mar/20 14:33;qz412;image-2020-03-30-14-33-38-123.png;https://jira.deutsche-boerse.com/secure/attachment/82041/image-2020-03-30-14-33-38-123.png","30/Mar/20 14:34;qz412;image-2020-03-30-14-34-07-457.png;https://jira.deutsche-boerse.com/secure/attachment/82042/image-2020-03-30-14-34-07-457.png","30/Mar/20 14:34;qz412;image-2020-03-30-14-34-37-632.png;https://jira.deutsche-boerse.com/secure/attachment/82043/image-2020-03-30-14-34-37-632.png",,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46137600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzxda7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93922,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Mar/20 14:43;dp007;DB0TEST2 user created",,,,,,,,,,,,,,,,,,,,,,,,,,,
RE does not send statsd,M7P-5845,93770,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,dp007,dp007,dp007,26/Mar/20 08:59,08/Apr/20 09:54,16/Sep/21 14:11,26/Mar/20 11:16,,6.10.4,6.9.91,7tops_sprint4,,RE,,,,M7PRODOPS,Monitoring,,,,,,"New customers (plpx+xrpm+enera) do not send statsd metrics, only our old envs (hupx+xsop+epex).

[https://github.deutsche-boerse.de/dev/energy.automation.inventory/search?q=re_statsd_enabled&unscoped_q=re_statsd_enabled
]

this variable makes the difference: it tells repengine to send statsd about newly created reports:
{code:java}
re_statsd_enabled: true {code}
re_statsd_enabled variable has to be enabled also on:
 * PLPX PROD
 * XRPM PROD
 * FLEX PROD

No need to have a special deployment window - just correct it and by next deployment it will be applied.",,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"variable introduced for PLPX, XRPM and FLEX PROD",,,,,,,,OPCOM,TGE,,,,,,,,,,,,,,,46569600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,26/Mar/20 08:59,,[],,,,,,,,,,,M7T,,,,"2|hzxcdb:",9223372036854775807,,,,No,,,,,,,,,,re_statsd_enable not set,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,do not set re_statsd_enable to true,1.0,,,,,,,,,"{""issueId"":93770,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"26/Mar/20 10:59;dp007;[https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1687/files]",,,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD DB dump request,M7P-5830,93678,93315,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,nn481,nn481,24/Mar/20 07:46,08/Apr/20 09:54,16/Sep/21 14:11,24/Mar/20 08:20,,7tops_sprint4,,,,,,,,7tops,,,,,,,We would need ELTS PROD DB dump to be able to solve [M7P-5773].,,cs687,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46742400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxbtr:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,X-Men Sprint 89,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93678,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Mar/20 08:16;cs687;Used the dump from yesterday starting by 9pm ""hotfix-copyshrd db-dump job""

{code:java}
[umgrcopy@m7ppg1 ~]$ ls -all /elts/data/
-rw------- 1 umgrcopy umgrcopy 6545282321 Mar 23 21:55 m7eltsprodm7b.dmp
{code}

Will upload it to ebsm 
{code:java}
[umgrcopy@m7ppg1 ~]$ scp /elts/data/m7eltsprodm7b.dmp logmover@m7shrdebsm1.deutsche-boerse.de:/opt/data/transfer/dbdumps/elts_prod/
logmover@m7shrdebsm1.deutsche-boerse.de's password:
m7eltsprodm7b.dmp  
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,
Consul Deployment for M7 Simu replica Hosts ,M7P-5829,93649,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,23/Mar/20 13:32,08/Apr/20 09:54,16/Sep/21 14:11,24/Mar/20 10:31,,7tops_sprint4,,,,,,,27/Mar/20 00:00,M7PRODOPS,,,,,,,"For Ticket M7P-5432 - Imp-lacing the M7 Simu Replica Hosts *m7simudbr1 & m7simudbr2"" 
https://jira.deutsche-boerse.com/browse/M7P-5432

we need to redeploy Consul Simulation. 
To not impact the current simulation patroni clusters we have to set the patroni-cluster which are still active running in an maintaining mode, handled by this command:
https://patroni.readthedocs.io/en/latest/pause.html
{code:java}
for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
{code}

then the consul redeployment can be run 
{code:java}
(venv3) [hw120@enprodauto1 {master L | ?6} ~/git/energy.automation.deployments]$ 
export CONSUL_DC=energy-shrd-simu && export CONSUL_BINARY=/usr/local/bin/consul
ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass
{code}

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1671/files
",,cs687,hw120,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46742400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzx9tr:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93649,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,SIMU,,,,"24/Mar/20 09:48;hw120;First I tried to pause 2 clusters manually,
{code:bash}
[root@m7simupdb1 etc]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml pause
Success: cluster management is paused
[root@m7simupdb1 etc]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml list
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
[root@m7simupdb1 etc]#  patronictl -c /etc/patroni_m7aamprcutesync/config.yml pause
Success: cluster management is paused
[root@m7simupdb1 etc]#  patronictl -c /etc/patroni_m7aamprcutesync/config.yml list
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 |              | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb3 | 10.139.58.174:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
{code}
All seems fine, continue with the rest of them at once.
{code:bash}
[root@m7simupdb1 etc]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i pause; done
Error: Cluster is already paused
Error: Cluster is already paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
Success: cluster management is paused
[root@m7simupdb1 etc]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 |              | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb3 | 10.139.58.174:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerasimsync | m7simupdb1 | 10.139.58.176:24042 |    Leader    | running |  3 |         0 |
| m7axeerasimsync | m7simupdb2 | 10.139.58.175:24042 | Sync standby | running |  3 |         0 |
| m7axeerasimsync | m7simupdb3 | 10.139.58.174:24042 |              | running |  3 |         0 |
| m7axeerasimsync | m7simupdb4 | 10.139.58.173:24042 |              | running |  3 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeercutesync | m7simupdb1 | 10.139.58.176:24044 |    Leader    | running |  1 |         0 |
| m7axeercutesync | m7simupdb2 | 10.139.58.175:24044 | Sync standby | running |  1 |         0 |
| m7axeercutesync | m7simupdb3 | 10.139.58.174:24044 |              | running |  1 |         0 |
| m7axeercutesync | m7simupdb4 | 10.139.58.173:24044 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeersimusync | m7simupdb1 | 10.139.58.176:24046 |    Leader    | running |  1 |         0 |
| m7axeersimusync | m7simupdb2 | 10.139.58.175:24046 | Sync standby | running |  1 |         0 |
| m7axeersimusync | m7simupdb3 | 10.139.58.174:24046 |              | running |  1 |         0 |
| m7axeersimusync | m7simupdb4 | 10.139.58.173:24046 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsacutasync | m7simupdb1 | 10.139.58.176:24002 | Leader | running |  2 |         0 |
| m7teltsacutasync | m7simupdb2 | 10.139.58.175:24002 |        | running |  2 |           |
| m7teltsacutasync | m7simupdb3 | 10.139.58.174:24002 |        | running |  2 |           |
| m7teltsacutasync | m7simupdb4 | 10.139.58.173:24002 |        | running |  2 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004 | Leader | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004 |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004 |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltscuteasync | m7simupdb1 | 10.139.58.176:24052 | Leader | running |  2 |         0 |
| m7teltscuteasync | m7simupdb2 | 10.139.58.175:24052 |        | running |  2 |           |
| m7teltscuteasync | m7simupdb3 | 10.139.58.174:24052 |        | running |  2 |           |
| m7teltscuteasync | m7simupdb4 | 10.139.58.173:24052 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltslipaasync | m7simupdb1 | 10.139.58.176:24054 | Leader | running |  3 |         0 |
| m7teltslipaasync | m7simupdb2 | 10.139.58.175:24054 |        | running |  3 |           |
| m7teltslipaasync | m7simupdb3 | 10.139.58.174:24054 |        | running |  3 |           |
| m7teltslipaasync | m7simupdb4 | 10.139.58.173:24054 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010 | Leader | running |  7 |         0 |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010 |        | running |  7 |           |
| m7teltssimuasync | m7simupdb3 | 10.139.58.174:24010 |        | running |  7 |           |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010 |        | running |  7 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012 | Leader | running |  1 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012 |        | running |  1 |           |
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012 |        | running |  1 |           |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012 |        | running |  1 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexsimuasync | m7simupdb1 | 10.139.58.176:24016 | Leader | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb2 | 10.139.58.175:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb3 | 10.139.58.174:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb4 | 10.139.58.173:24016 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018 | Leader | running |  2 |         0 |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxcuteasync | m7simupdb1 | 10.139.58.176:24020 | Leader | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb2 | 10.139.58.175:24020 |        | running |  3 |           |
| m7thupxcuteasync | m7simupdb3 | 10.139.58.174:24020 |        | running |  3 |           |
| m7thupxcuteasync | m7simupdb4 | 10.139.58.173:24020 |        | running |  3 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022 | Leader | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb3 | 10.139.58.174:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxlipaasync | m7simupdb1 | 10.139.58.176:24024 | Leader | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb2 | 10.139.58.175:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb3 | 10.139.58.174:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb4 | 10.139.58.173:24024 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026 | Leader | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb3 | 10.139.58.174:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026 |        | running |  5 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrddst1async | m7simupdb1 | 10.139.58.176:24056 | Leader | running |  2 |         0 |
| m7tshrddst1async | m7simupdb2 | 10.139.58.175:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb3 | 10.139.58.174:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb4 | 10.139.58.173:24056 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdexteasync | m7simupdb1 | 10.139.58.176:24000 | Leader | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb2 | 10.139.58.175:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb3 | 10.139.58.174:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb4 | 10.139.58.173:24000 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmlipaasync | m7simupdb1 | 10.139.58.176:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb2 | 10.139.58.175:24034 | Leader | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb3 | 10.139.58.174:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb4 | 10.139.58.173:24034 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036 | Leader | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb3 | 10.139.58.174:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036 |        | running |  4 |           |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028 | Leader | running |  3 |         0 |
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb3 | 10.139.58.174:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopcuteasync | m7simupdb1 | 10.139.58.176:24030 | Leader | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb2 | 10.139.58.175:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb3 | 10.139.58.174:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb4 | 10.139.58.173:24030 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032 | Leader | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb3 | 10.139.58.174:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
{code}
","24/Mar/20 10:19;hw120;Deploying consul to all instances
{code:bash}
(venv3) [hw120@enprodauto1 {master L | ?6} ~/git/energy.automation.deployments]$ ansible-playbook -e consul_group_name=consul_energy_shrd_simu playbooks/deploy_consul_instances.yml -e ansible_python_interpreter=/usr/bin/python --ask-become-pass
{code}

Checking consul cluster status
{code:bash}
[root@ensimucons1 ~]# export CONSUL_HTTP_TOKEN=XXXXXXXXXXX (see vault)
[root@ensimucons1 ~]# consul members
Node                       Address              Status  Type    Build      Protocol  DC                Segment
energy-shrd-simu-cons1     10.136.159.246:8301  alive   server  1.6.2+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons2     10.136.31.246:8301   alive   server  1.6.2+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons3     10.136.159.245:8301  alive   server  1.6.2+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons4     10.136.31.245:8301   alive   server  1.6.2+ent  2         energy-shrd-simu  <all>
energy-shrd-simu-cons5     10.136.159.244:8301  alive   server  1.6.2+ent  2         energy-shrd-simu  <all>
m7t-shrd-simu-consul-dbr1  10.136.161.121:8301  alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-dbr2  10.136.33.123:8301   alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb1  10.139.58.176:8301   alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb2  10.139.58.175:8301   alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb3  10.139.58.174:8301   alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
m7t-shrd-simu-consul-pdb4  10.139.58.173:8301   alive   client  1.6.2+ent  2         energy-shrd-simu  m7-simu-patroni-cluster
{code}

and checking the logs on server and client
journalctl -u consul
","24/Mar/20 10:25;hw120;Resuming patroni instances, trying on one first

{code:bash}
[root@m7simupdb1 etc]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml list
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
 Maintenance mode: on
[root@m7simupdb1 etc]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml resume
Success: cluster management is resumed
[root@m7simupdb1 etc]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml list
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
{code}

Checking patroni logs
{code:bash}
[root@m7simupdb1 etc]# journalctl -u patroni_enshrdebsmasync.service
Mar 24 10:20:14 m7simupdb1 patroni[36967]: 2020-03-24 10:20:14,140 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:14 m7simupdb1 patroni[36967]: 2020-03-24 10:20:14,144 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:20:24 m7simupdb1 patroni[36967]: 2020-03-24 10:20:24,154 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:24 m7simupdb1 patroni[36967]: 2020-03-24 10:20:24,174 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:20:34 m7simupdb1 patroni[36967]: 2020-03-24 10:20:34,149 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:34 m7simupdb1 patroni[36967]: 2020-03-24 10:20:34,164 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:20:35 m7simupdb1 patroni[36967]: 2020-03-24 10:20:35,386 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:35 m7simupdb1 patroni[36967]: 2020-03-24 10:20:35,425 INFO: no action.  i am the leader with the lock
Mar 24 10:20:35 m7simupdb1 patroni[36967]: 2020-03-24 10:20:35,428 INFO: No PostgreSQL configuration items changed, nothing to reload.
Mar 24 10:20:45 m7simupdb1 patroni[36967]: 2020-03-24 10:20:45,382 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:45 m7simupdb1 patroni[36967]: 2020-03-24 10:20:45,399 INFO: no action.  i am the leader with the lock
Mar 24 10:20:55 m7simupdb1 patroni[36967]: 2020-03-24 10:20:55,397 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:20:55 m7simupdb1 patroni[36967]: 2020-03-24 10:20:55,428 INFO: no action.  i am the leader with the lock
Mar 24 10:21:05 m7simupdb1 patroni[36967]: 2020-03-24 10:21:05,386 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:21:05 m7simupdb1 patroni[36967]: 2020-03-24 10:21:05,400 INFO: no action.  i am the leader with the lock
Mar 24 10:21:15 m7simupdb1 patroni[36967]: 2020-03-24 10:21:15,368 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:21:15 m7simupdb1 patroni[36967]: 2020-03-24 10:21:15,371 INFO: no action.  i am the leader with the lock
{code}","24/Mar/20 10:29;hw120;Resuming all patroni instances
{code:bash}
[root@m7simupdb1 etc]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i resume; done
Error: Cluster is not paused
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed
Success: cluster management is resumed

[root@m7simupdb1 etc]# for i in `ls /etc/patroni_*/config.yml`;do patronictl -c $i list; done
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7aamprcutesync | m7simupdb1 | 10.139.58.176:24038 | Sync standby | running |  2 |         0 |
| m7aamprcutesync | m7simupdb2 | 10.139.58.175:24038 |    Leader    | running |  2 |         0 |
| m7aamprcutesync | m7simupdb3 | 10.139.58.174:24038 |              | running |  2 |         0 |
| m7aamprcutesync | m7simupdb4 | 10.139.58.173:24038 |              | running |  2 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeerasimsync | m7simupdb1 | 10.139.58.176:24042 |    Leader    | running |  3 |         0 |
| m7axeerasimsync | m7simupdb2 | 10.139.58.175:24042 | Sync standby | running |  3 |         0 |
| m7axeerasimsync | m7simupdb3 | 10.139.58.174:24042 |              | running |  3 |         0 |
| m7axeerasimsync | m7simupdb4 | 10.139.58.173:24042 |              | running |  3 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeercutesync | m7simupdb1 | 10.139.58.176:24044 |    Leader    | running |  1 |         0 |
| m7axeercutesync | m7simupdb2 | 10.139.58.175:24044 |              | running |  1 |         0 |
| m7axeercutesync | m7simupdb3 | 10.139.58.174:24044 | Sync standby | running |  1 |         0 |
| m7axeercutesync | m7simupdb4 | 10.139.58.173:24044 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+-----------------+------------+---------------------+--------------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |     Role     |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
| m7axeersimusync | m7simupdb1 | 10.139.58.176:24046 |    Leader    | running |  1 |         0 |
| m7axeersimusync | m7simupdb2 | 10.139.58.175:24046 | Sync standby | running |  1 |         0 |
| m7axeersimusync | m7simupdb3 | 10.139.58.174:24046 |              | running |  1 |         0 |
| m7axeersimusync | m7simupdb4 | 10.139.58.173:24046 |              | running |  1 |         0 |
+-----------------+------------+---------------------+--------------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltsacutasync | m7simupdb1 | 10.139.58.176:24002 | Leader | running |  2 |         0 |
| m7teltsacutasync | m7simupdb2 | 10.139.58.175:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb3 | 10.139.58.174:24002 |        | running |  2 |         0 |
| m7teltsacutasync | m7simupdb4 | 10.139.58.173:24002 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+----------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |
+------------------+------------+----------------------+--------+---------+----+-----------+
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |         0 |
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004  |        | running |  3 |         0 |
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |
+------------------+------------+----------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltscuteasync | m7simupdb1 | 10.139.58.176:24052 | Leader | running |  2 |         0 |
| m7teltscuteasync | m7simupdb2 | 10.139.58.175:24052 |        | running |  2 |         0 |
| m7teltscuteasync | m7simupdb3 | 10.139.58.174:24052 |        | running |  2 |         0 |
| m7teltscuteasync | m7simupdb4 | 10.139.58.173:24052 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltslipaasync | m7simupdb1 | 10.139.58.176:24054 | Leader | running |  3 |         0 |
| m7teltslipaasync | m7simupdb2 | 10.139.58.175:24054 |        | running |  3 |         0 |
| m7teltslipaasync | m7simupdb3 | 10.139.58.174:24054 |        | running |  3 |         0 |
| m7teltslipaasync | m7simupdb4 | 10.139.58.173:24054 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7teltssimuasync | m7simupdb1 | 10.139.58.176:24010 | Leader | running |  7 |         0 |
| m7teltssimuasync | m7simupdb2 | 10.139.58.175:24010 |        | running |  7 |         0 |
| m7teltssimuasync | m7simupdb3 | 10.139.58.174:24010 |        | running |  7 |         0 |
| m7teltssimuasync | m7simupdb4 | 10.139.58.173:24010 |        | running |  7 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+----------------------+--------+------------------+----+-----------+
|     Cluster      |   Member   |         Host         |  Role  |      State       | TL | Lag in MB |
+------------------+------------+----------------------+--------+------------------+----+-----------+
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | creating replica |    |   unknown |
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | creating replica |    |   unknown |
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader |     running      |  1 |         0 |
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        |     running      |  1 |         0 |
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012  |        |     running      |  1 |         0 |
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        |     running      |  1 |         0 |
+------------------+------------+----------------------+--------+------------------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tflexsimuasync | m7simupdb1 | 10.139.58.176:24016 | Leader | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb2 | 10.139.58.175:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb3 | 10.139.58.174:24016 |        | running |  2 |         0 |
| m7tflexsimuasync | m7simupdb4 | 10.139.58.173:24016 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxasimasync | m7simupdb1 | 10.139.58.176:24018 | Leader | running |  2 |         0 |
| m7thupxasimasync | m7simupdb2 | 10.139.58.175:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb3 | 10.139.58.174:24018 |        | running |  2 |         0 |
| m7thupxasimasync | m7simupdb4 | 10.139.58.173:24018 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxcuteasync | m7simupdb1 | 10.139.58.176:24020 | Leader | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb2 | 10.139.58.175:24020 |        | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb3 | 10.139.58.174:24020 |        | running |  3 |         0 |
| m7thupxcuteasync | m7simupdb4 | 10.139.58.173:24020 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7thupxsimuasync | m7simupdb1 | 10.139.58.176:24022 | Leader | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb2 | 10.139.58.175:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb3 | 10.139.58.174:24022 |        | running |  3 |         0 |
| m7thupxsimuasync | m7simupdb4 | 10.139.58.173:24022 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxlipaasync | m7simupdb1 | 10.139.58.176:24024 | Leader | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb2 | 10.139.58.175:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb3 | 10.139.58.174:24024 |        | running |  1 |         0 |
| m7tplpxlipaasync | m7simupdb4 | 10.139.58.173:24024 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tplpxsimuasync | m7simupdb1 | 10.139.58.176:24026 | Leader | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb2 | 10.139.58.175:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb3 | 10.139.58.174:24026 |        | running |  5 |         0 |
| m7tplpxsimuasync | m7simupdb4 | 10.139.58.173:24026 |        | running |  5 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrddst1async | m7simupdb1 | 10.139.58.176:24056 | Leader | running |  2 |         0 |
| m7tshrddst1async | m7simupdb2 | 10.139.58.175:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb3 | 10.139.58.174:24056 |        | running |  2 |         0 |
| m7tshrddst1async | m7simupdb4 | 10.139.58.173:24056 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7tshrdexteasync | m7simupdb1 | 10.139.58.176:24000 | Leader | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb2 | 10.139.58.175:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb3 | 10.139.58.174:24000 |        | running |  1 |         0 |
| m7tshrdexteasync | m7simupdb4 | 10.139.58.173:24000 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmlipaasync | m7simupdb1 | 10.139.58.176:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb2 | 10.139.58.175:24034 | Leader | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb3 | 10.139.58.174:24034 |        | running |  2 |         0 |
| m7txrpmlipaasync | m7simupdb4 | 10.139.58.173:24034 |        | running |  2 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txrpmsimuasync | m7simupdb1 | 10.139.58.176:24036 | Leader | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb2 | 10.139.58.175:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb3 | 10.139.58.174:24036 |        | running |  4 |         0 |
| m7txrpmsimuasync | m7simupdb4 | 10.139.58.173:24036 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopasimasync | m7simupdb1 | 10.139.58.176:24028 | Leader | running |  3 |         0 |
| m7txsopasimasync | m7simupdb2 | 10.139.58.175:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb3 | 10.139.58.174:24028 |        | running |  3 |         0 |
| m7txsopasimasync | m7simupdb4 | 10.139.58.173:24028 |        | running |  3 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopcuteasync | m7simupdb1 | 10.139.58.176:24030 | Leader | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb2 | 10.139.58.175:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb3 | 10.139.58.174:24030 |        | running |  1 |         0 |
| m7txsopcuteasync | m7simupdb4 | 10.139.58.173:24030 |        | running |  1 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7txsopsimuasync | m7simupdb1 | 10.139.58.176:24032 | Leader | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb2 | 10.139.58.175:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb3 | 10.139.58.174:24032 |        | running |  4 |         0 |
| m7txsopsimuasync | m7simupdb4 | 10.139.58.173:24032 |        | running |  4 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
{code}

Checking logs of one of them
{code:bash}
[root@m7simupdb1 etc]# journalctl -u patroni_m7teltssimuasync.service
Mar 24 10:26:18 m7simupdb1 patroni[31187]: 2020-03-24 10:26:18,623 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:26:18 m7simupdb1 patroni[31187]: 2020-03-24 10:26:18,640 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:26:28 m7simupdb1 patroni[31187]: 2020-03-24 10:26:28,624 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:26:28 m7simupdb1 patroni[31187]: 2020-03-24 10:26:28,653 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:26:38 m7simupdb1 patroni[31187]: 2020-03-24 10:26:38,623 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:26:38 m7simupdb1 patroni[31187]: 2020-03-24 10:26:38,653 INFO: PAUSE: no action.  i am the leader with the lock
Mar 24 10:26:40 m7simupdb1 patroni[31187]: 2020-03-24 10:26:40,374 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:26:40 m7simupdb1 patroni[31187]: 2020-03-24 10:26:40,403 INFO: no action.  i am the leader with the lock
Mar 24 10:26:40 m7simupdb1 patroni[31187]: 2020-03-24 10:26:40,406 INFO: No PostgreSQL configuration items changed, nothing to reload.
Mar 24 10:26:50 m7simupdb1 patroni[31187]: 2020-03-24 10:26:50,378 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:26:50 m7simupdb1 patroni[31187]: 2020-03-24 10:26:50,424 INFO: no action.  i am the leader with the lock
Mar 24 10:27:00 m7simupdb1 patroni[31187]: 2020-03-24 10:27:00,372 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:27:00 m7simupdb1 patroni[31187]: 2020-03-24 10:27:00,395 INFO: no action.  i am the leader with the lock
Mar 24 10:27:10 m7simupdb1 patroni[31187]: 2020-03-24 10:27:10,371 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:27:10 m7simupdb1 patroni[31187]: 2020-03-24 10:27:10,391 INFO: no action.  i am the leader with the lock
Mar 24 10:27:20 m7simupdb1 patroni[31187]: 2020-03-24 10:27:20,370 INFO: Lock owner: m7simupdb1; I am m7simupdb1
Mar 24 10:27:20 m7simupdb1 patroni[31187]: 2020-03-24 10:27:20,388 INFO: no action.  i am the leader with the lock
{code}

All looks fine.","24/Mar/20 10:59;cs687;additional Cluster-nodes are up and running. Consul-Deployment worked fine!
{code:java}
[root@m7simupdb1 ~]# patronictl -c /etc/patroni_m7teltsctpbasync/config.yml list              
+------------------+------------+----------------------+--------+---------+----+-----------+  
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
{code}
",,,,,,,,,,,,,,,,,,,,,,,
Upgrading Zulu Version for M7T SHRD,M7P-5813,93564,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,19/Mar/20 12:49,08/Apr/20 09:54,16/Sep/21 14:11,20/Mar/20 07:16,,6.10.4,6.9.91,7tops_sprint4,,,,,20/Mar/20 00:00,7tops,M7PRODOPS,,,,,,"We need to upgrade the zulu-version to
* jdk 1.8.0_242 (Zulu is likely 8.44.0.213)*

for the following hosts: 
* m7shrdsyt3apa1
* m7shrdsyt3apa2
* m7shrdsyt1apa1
* m7shrdsyt1apa2
* m7shrdate3apa1

The Upgrade is necessary for the coming release 6.9 ",,cs687,cv524,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TECHLOG-3218,M7P-5812,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47088000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxb7b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93564,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/20 13:35;cv524;Related activities are tracked in TECHLOG-3218",,,,,,,,,,,,,,,,,,,,,,,,,,,
Insert missing part of session_history table,M7P-5811,93501,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Won't Do,cs687,HO764,HO764,18/Mar/20 12:50,08/Apr/20 09:54,16/Sep/21 14:11,18/Mar/20 13:47,,7tops_sprint4,,,,,,,,M7PRODOPS,,,,,,,"Please execute the attached sql script on ELTS PROD - inserting missing entries into session_history table, accidentally deteled during last history cleanup.",,cs687,HO764,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5871,,,,,,"18/Mar/20 12:50;HO764;missing.sql;https://jira.deutsche-boerse.com/secure/attachment/81664/missing.sql",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,47174400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxatr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93501,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"18/Mar/20 13:47;cs687;[~HO764] please create for that an SERVICE Ticket with the necessary Approvals, like for normal deployments. 

I already tested it in copyshrd hotfix db copy successfully.

{code:java}
edb=# \c m7eltsprodm7b
You are now connected to database ""m7eltsprodm7b"" as user ""enterprisedb"".
m7eltsprodm7b=#
m7eltsprodm7b=#
m7eltsprodm7b=#
m7eltsprodm7b=#
m7eltsprodm7b=# \i /tmp/M7P-5811.sql
m7eltsprodm7b=#
{code}
","18/Mar/20 14:09;HO764;Thank you for testing. I'll report a SERVICE jira.",,,,,,,,,,,,,,,,,,,,,,,,,,
"Send slack ERROR message based on m7-core log ""UNKNOWN ORDER""",M7P-5807,93471,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,ef759,ef759,17/Mar/20 16:20,01/Jul/20 11:27,16/Sep/21 14:11,29/Jun/20 08:15,M7 6.8,6.10.123,7tops_sprint9_,,,,,,,7tops_comm,MONITORING,S,,,,,"Based on error log in m7-core with pattern ""UNKNOWN ORDER"" we would need to send error message to slack.",,ef759,iu252,oy574,sJ194,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Watcher created, tested and implemented on all envs.",,,,,,,,,,,,,,,,,,,,,,,,38361600,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxmxr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93471,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"28/May/20 13:42;sJ194;[~iu252] to discuss details with [~ef759] like which message etc. ","28/May/20 14:39;iu252;[~ef759] there 2 points we need to discuss:
# send slack error message: should it be similar to watcher-warnings ""Tomcat Failover"" in m7_alerts channel?
# pattern ""UNKNOWN ORDER"": i've checked Kibana for the last 7 days and i can see 2 different Messages: 
    - ""txt=""Received trade with unknown order from XBID: externalTradeId""
    - ""UNKNOWN ORDER [OrderId: 3105, ExternalOrderId: 126390737, ExternalTradeId: 12942516]""
which one should be monitored?","08/Jun/20 11:28;ef759;1. Yes it should be similar like for watcher-warnings ""Tomcat failover"". When log will be written to file, alert message needs to be sent to slack channel.
2.  The second pattern is the right one: ""UNKNOWN ORDER [OrderId: 3105, ExternalOrderId: 126390737, ExternalTradeId: 12942516]"". So filter it please according to ""UNKNOWN ORDER"" text written with capitals.","24/Jun/20 10:06;iu252;Created https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1195

Waiting for review.","24/Jun/20 13:17;iu252;Merged PR after review from [~hw120].","24/Jun/20 14:04;iu252;Deployed watcher:

{noformat}
 2020-06-24 13:57:29 ⌚  ip-10-115-77-197 in ~/git/energy.monitoring/ansible
± |master ✓| → ANSIBLE_CONFIG=ansible_aws.cfg ansible-playbook playbooks/elasticsearch-setup.yml -i inventory/aws/svc -t watcher

PLAY [API calls to setup elasticsearch cluster] ************************************************************************************************************************

TASK [elasticsearch-setup : Get credentials for users from Vault] ******************************************************************************************************
ok: [10.115.92.195]

TASK [elasticsearch-setup : Reload secure settings] ********************************************************************************************************************
ok: [10.115.92.195]

TASK [elasticsearch-setup : Watcher alert for Tomcat Failover] *********************************************************************************************************
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
ok: [10.115.92.195] => (item=['xbid', 'prod'])
ok: [10.115.92.195] => (item=['xbid', 'nonprod'])

TASK [elasticsearch-setup : Watcher alert for rabbitmq network-restored] ***********************************************************************************************
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
ok: [10.115.92.195] => (item=['xbid', 'prod'])
ok: [10.115.92.195] => (item=['xbid', 'nonprod'])

TASK [elasticsearch-setup : Watcher alert for rabbitmq ldap-error] *****************************************************************************************************
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
ok: [10.115.92.195] => (item=['xbid', 'prod'])
ok: [10.115.92.195] => (item=['xbid', 'nonprod'])

TASK [elasticsearch-setup : Watcher alert for tomcat out of memory] ****************************************************************************************************
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
ok: [10.115.92.195] => (item=['xbid', 'prod'])
ok: [10.115.92.195] => (item=['xbid', 'nonprod'])

TASK [elasticsearch-setup : Watcher alert for tomcat unknown order] ****************************************************************************************************
ok: [10.115.92.195] => (item=['m7', 'prod'])
ok: [10.115.92.195] => (item=['m7', 'nonprod'])
.......
{noformat}
","24/Jun/20 15:27;iu252;Merged https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1197.

Activated nonprod watcher.","25/Jun/20 11:52;iu252;Changed time range for the watcher to see the error Messages from yesterday.

Watcher alert in m7_alerts:
{noformat}
watcherAPP  11:25 AMTomcat UNKNOWN ORDER alert
Encountered 2 Tomcat error(s) in the last 5 minutes.
m7eltsctpbm7b1 - 2020-06-24T10:55:04.821Z
UNKNOWN ORDER [OrderId: 181139, ExternalOrderId: 860652, ExternalTradeId: 431830]
com.deutscheboerse.energy.m7.core.out.exception.UnknownOrderIdException: UNKNOWN ORDER [OrderId: 181139, ExternalOrderId: 860652, ExternalTradeId: 431830]
    at com.deutscheboerse.energy.m7.trade.sync.RemoteSynchronizationServiceImpl.throwUnknownOrderIdException(RemoteSynchronizationServiceImpl.java:1115)
{noformat}
","25/Jun/20 11:53;iu252;Waiting for feedback from [~oy574].","25/Jun/20 13:22;oy574;I confirm that the watcher works as expected.","29/Jun/20 08:09;iu252;Redeployed watcher with additional term:

{noformat}
 ""term"": {
                    ""log_level"": ""ERROR""
{noformat}
","29/Jun/20 08:09;iu252;Watcher is active für prod and nonprod environments.

Ticket can be closed.",,,,,,,,,,,,,,,,
Run query on PLPX PROD CORE database ,M7P-5805,93442,93405,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,cf948,cf948,17/Mar/20 11:38,08/Apr/20 09:54,16/Sep/21 14:11,23/Mar/20 10:37,,7tops_sprint4,,,,,,,,7tops,M7PRODOPS,,,,,,"{code:sql}
select * from CX_284_USER_X_BALANCING_GROUP x join CX_270_BALANCING_GROUP bg on x.BALANCING_GROUP_EIC = bg.BALANCING_GROUP_EIC where bg.NAME = 'CEZ-LAF-TA'
{code}",,cf948,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47088000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxaif:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 88 (PS),Magnificent 7 Sprint 89 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93442,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/20 14:58;qo288;m7tplpxprodm7b=# select * from CX_284_USER_X_BALANCING_GROUP x join CX_270_BALANCING_GROUP bg on x.BALANCING_GROUP_EIC = bg.BALANCING_GROUP_EIC where bg.NAME = 'CEZ-LAF-TA';
 user_id | balancing_group_eic | balancing_group_eic |    last_update_time     |    last_update_user    | mod_type_
code | version |    name    | otc_trading | suspended_flag | technical | visible | member_id
---------+---------------------+---------------------+-------------------------+------------------------+----------
-----+---------+------------+-------------+----------------+-----------+---------+-----------
     316 | CEZ-LAF-TA          | CEZ-LAF-TA          | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP
     |       2 | CEZ-LAF-TA | N           | Y              | N         | Y       | M0008
     317 | CEZ-LAF-TA          | CEZ-LAF-TA          | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP
     |       2 | CEZ-LAF-TA | N           | Y              | N         | Y       | M0008
     318 | CEZ-LAF-TA          | CEZ-LAF-TA          | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP
     |       2 | CEZ-LAF-TA | N           | Y              | N         | Y       | M0008
(3 rows)
","19/Mar/20 15:14;cf948;user_id | balancing_group_eic | balancing_group_eic | last_update_time | last_update_user | mod_type_code | version | name | otc_trading | suspended_flag | technical | visible | member_id
 ---------+++------------------------------------------++-----------------------------------------------------------
 -----+++---------------------++-----------------------------++-------------------------------
 316 | CEZ-LAF-TA | CEZ-LAF-TA | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP | 2 | CEZ-LAF-TA | N | Y | N | Y | M0008
 317 | CEZ-LAF-TA | CEZ-LAF-TA | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP | 2 | CEZ-LAF-TA | N | Y | N | Y | M0008
 318 | CEZ-LAF-TA | CEZ-LAF-TA | 2020-02-27 14:42:51.525 | 9999999999999999TRD011 | SUSP | 2 | CEZ-LAF-TA | N | Y | N | Y | M0008",,,,,,,,,,,,,,,,,,,,,,,,,,
DST tests impact analysis,M7P-5789,93400,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,16/Mar/20 13:23,22/Sep/20 13:47,16/Sep/21 14:11,06/Apr/20 09:31,,6.10.7,6.9.98,7tops_sprint4,,,,,,M7PRODOPS,,,,,,,"2 times per year comes a repetitive task from XBID to perform XBID DST test.

As we have now 5 different M7 clients connected to XBID, they do want to participate as well.

Scheduling looks like that
 # XBID requests to perform on XBID CUTE DST time travel and DBAG has 1 working day T for it
 # on day T+1 official DST tests start

That means that DBAG must additionally perform DST time travel on all M7 environments (up to 5) connected to XBID CUTE

todo:
 * list steps that are done for M7 environment to time travel
 * list steps in case additional M7 environment must be linked from another XBID to XBID CUTE environmnent
 * provide efforts to perform M7 time travel per environment
 * can time travel be don in parael?
 * any suggestions for improvements to speed up the process or remove some manual steps?",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45619200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx9tj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93400,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Apr/20 07:52;cs687;* *list steps that are done for M7 environment to time travel*

1.) stopping the instances (*cor*, *enq*, *amq*, *h2h4u*, *rep*) for the DST-Time shifted M7 Envioronment
2.) change the same time like it is shifted for the XBID Environment. (Ansible-Playbook is prepared/available for that) 
     Afterwards you can validate the time with the linux command ""date""
3.) deleting journal files on one of the tomcat hosts ""*/<env>/journal/m7-msgs/""
4.) run the deployment in that way:
* starting amq-cluster 
  confirming the health-status with the rabbit-management WEBGUI
* deploying cor with *db_clean* (
   in that case truncating ""m7_999_revision_index""-table is not necessary
   let it also confirm from Bizops that the clean-up was running successful 
* starting the rest of the ""backend instances"" like ""*h2h4u*, *rep*, *enq*""
* check with health-check command if the instances cor, enq, h2h4u and rep are running properly
5.) Create User ""XB-USER"" in WEBGUI, User should be with Admin Rights and with ""Reference Data GUI"" additional rights (to be done by Bizops) 
6.) Run sql on cor database like the following command and restart ""cor, enq""
INSERT INTO cx_312_user_role (user_id, user_role) VALUES ((SELECT user_id FROM cx_282_user WHERE login_id = 'XB-USER), 'ROLE_EXCHANGE');
7.) Post-checks from Bizops-Side and handing over to customer again. 

In the past, it was confirmed that step 5 and 6 were handled automatically during the deployment, so these steps were not necessary at all. 



 ","06/Apr/20 08:59;cs687;* *list steps in case additional M7 environment must be linked from another XBID to XBID CUTE environmnent*

steps are mostly the similar like steps mentioned above. 
We just and only have to check which proxy host is used to connect this specific M7-Environment to XBID Cute Environment. 
For that we can connect to the m7b tomcat host and check the current settings in the application.properties file.

*Here is an example from the Environment TGE SIMU:*
/plpx/plpx-simu-cor1/tomcat/lib/application-env.properties

In the parameter sob.amqp.addresses you can see which proxies are currently in use. In that case we have a dedicated proxy-hosts *m7plpxsimumpls1* and *m7plpxsimumpls2*
When you connect to one of these hosts you can enter the directory */etc/xinetd.d* and you will find two xinetd config files:
{code:java}
-rw-r--r--  1 root root  189 Jul 19  2019 plpx-simu-mpls-ixe1
-rw-r--r--  1 root root  189 Jul 19  2019 plpx-simu-mpls-ixe2
{code}
there it is configured to which XBID Environment it is currently connected/redirected *(redirect = 10.103.128.23 50100)*
To get more details about the connection - open the newest ""XBID_Environments_2020-xx-xx.xlsx"" file and check the Tab *""Conn. <Environment>*""
In the Example above we have the COLT MPLS Address ""*AMQPS SOB Simulation IXE (Colt)* with the IP ""10.103.128.23"" with Loadbalancer Port ""50100""
In case you need to change this redirection address you have to change it in the proxy configuration file and reload the changes with that command handled by user root
*systemctl reload xinetd.service*
and you could proceed with the steps above!

{code:java}
###########################################
# SOB Setup
###########################################
sob.exchangeId=XSOB
sob.amqp.addresses=m7plpxsimumpls1:55120,m7plpxsimumpls1:55121,m7plpxsimumpls2:55120,m7plpxsimumpls2:55121
sob.amqp.vhost=ext
sob.amqp.username=XBTGEX01
sob.amqp.password=PASSWORD

sob.amqp.useSSL=True
sob.amqp.ssl.keyStore=classpath:XBID_PMI_SOB.p12
sob.amqp.ssl.keyStorePassword=PASSWORD
sob.amqp.ssl.trustStore=classpath:trustStore.jks
sob.amqp.ssl.trustStorePassword=PASSWORD

sobConnectionApplicationId=TGELTS
{code}

","06/Apr/20 09:04;cs687;* *provide efforts to perform M7 time travel per environment*

In the past it was shown that this type of deployment requires approx. *1 hour* per each environment including the post-checks from BO-side. ","06/Apr/20 09:06;cs687;* *can time travel be done in parallel?*

As far i know the  time-shifting of M7-Environments can be done in parallel! 
The only requirement is that the XBID Environment which will be used for this scenario should be finished before we start with the M7 Part.
","06/Apr/20 09:23;cs687;* *any suggestions for improvements to speed up the process or remove some manual steps?*

to remove some manual steps will not work, as far we have no automatic replacement for it. 
anyways i wouldn't change that now. 

*two things* come to my mind, what costed us some time in the past!
*1.) check the XBID-USER password on XBID LDAP-Side*
In that case we have to connect to XBID LDAP and confirm if the mentioned password in the ticket is matching with the password which is configured in LDAP for that specific user, 
before we are setting it in the vault-secret. 
{code:java}
Login: XBTGEX01
Password: PASSWORD
{code}

*2.) checking if some firewall-requests are still necessary on proxy-side, which can be a show-blocker for this kind of deployments*
{code:java}
service plpx-simu-mpls-ixe1                    
{                                              
        disable = no                           
        type = UNLISTED                        
        socket_type = stream                   
        protocol = tcp                         
        wait = no                              
        redirect = 10.103.128.23 50100         
        bind = 0.0.0.0                         
        port = 55120                           
        user = nobody                          
}                                              
{code}

So we have to check if the M7 tomcat-host can reach the proxy hosts with port ""55120"" and also the proxy host can reach the xbid Environment with the redirection address.

{code:java}
[cs687@m7plpxsimum7b1 ~]$ telnet m7plpxsimumpls1 55120
Trying 10.136.163.62...
Connected to m7plpxsimumpls1.
Escape character is '^]'.

[cs687@m7plpxsimum7b1 ~]$ telnet m7plpxsimumpls2 55120
Trying 10.136.35.62...
Connected to m7plpxsimumpls2.
Escape character is '^]'.
{code}

... and

{code:java}
[root@m7plpxsimumpls1 xinetd.d]# telnet 10.103.128.23 50100     
Trying 10.103.128.23...                                         
Connected to 10.103.128.23.                                     
Escape character is '^]'.

[root@m7plpxsimumpls2 ~]# telnet 10.103.128.23 50100     
Trying 10.103.128.23...                                  
Connected to 10.103.128.23.                              
Escape character is '^]'.
{code}




",,,,,,,,,,,,,,,,,,,,,,,
Create access to copyshrd dataabse,M7P-5782,93358,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,HO764,HO764,13/Mar/20 11:37,18/Mar/20 13:26,16/Sep/21 14:11,13/Mar/20 12:20,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,,Please provide me access to copyshrd database - user ho764.,,cs687,HO764,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47692800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzxa47:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93358,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 12:20;cs687;Configured the user to have access to copyhsrd DB. 
Will provide [~HO764] an email with the credentials. ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Technical solution for shutting down components,M7P-5780,93355,90712,Sub-task,To Do,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,qo288,jv861,jv861,13/Mar/20 10:34,08/Sep/21 15:21,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,Our original proposed solution ta call jenkins from m7shrdsyt3apa1 is no possible. Let's explore other options,,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45532800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmr8f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 84,Magnificent 7 Sprint 85,Magnificent 7 Sprint 86 (PS),Magnificent 7 Sprint 87,M7 Development,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93355,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 13:11;jv861;As discussed few weeks ago on DevOps CoP, we'd like to have a programmatic approach to shutdown M7 components on SYT3 (or any internal test env).

The idea is a load runner application running on m7shrdsyt3ldr1, and allow this application (based on it's own decision) to trigger following events:
 * stop/start cor/enq
 * stop/restart individual rabbit nodes
 * cut connection to xbid (preferable using iptables - it better models the problems we had)
 * cut connection to Xbid
 * cut connection to internal rabbitmq (if possible)
 * cut connection to database (if possible)

Maybe we would expand this later, but this would be a nice start.",,,,,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: prepare for M7 BSP XSOP CUTE deliver latest 6.8 & Kafka,M7P-5771,93273,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,12/Mar/20 09:35,08/Apr/20 09:54,16/Sep/21 14:11,19/Mar/20 09:30,,6.10.4,6.9.91,7tops_sprint4,,,,,17/Mar/20 00:00,M7PRODOPS,,,,,,,"Prepare all necessery steps / PRs in order to deliver Kafka for BSP CUTE

(see linked ticket)

 ",,cs687,fp407,rehapav,sJ194,,,,,,,,,,,,,,,,SERVICE-5831,,,,,,,,,,,,,,,,,,,,"17/Mar/20 13:35;cs687;Kafka_Dry_run.txt;https://jira.deutsche-boerse.com/secure/attachment/81630/Kafka_Dry_run.txt",,,,,,,,,,,,,,,rehapav,sw455,,,,,,,,,,,,,,,Southpool,,,,,,Internal Deployment Request,ax460,cf948,oy574,pw231,tf093,xt853,,,Yes,47260800,,CUTE,dm700,lw641,ox626,rehapav,sw455,,19/Mar/20 13:00,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzpr93:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 88,Schmetterling Sprint 89,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93273,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"12/Mar/20 13:41;sJ194;[~fp407] will help if needed.","12/Mar/20 15:16;rehapav;If not ready until due date 17/Mar/20 - i will cancel the deployment","17/Mar/20 08:20;fp407;BST CUTE environment configuration: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1652","17/Mar/20 13:09;cs687;merged pull-request above!","17/Mar/20 13:35;cs687;And tested the coming kafka deployment 
 [^Kafka_Dry_run.txt] ",,,,,,,,,,,,,,,,,,,,,,,
Content of MTT truststores for ELTS PORD and HUPX PROD,M7P-5770,93272,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cv179,fj021,fj021,12/Mar/20 09:33,18/Mar/20 13:26,16/Sep/21 14:11,12/Mar/20 11:33,,6.9.85,7tops_sprint2,,,MTT,,,,M7PRODOPS,,,,,,,"h2. What ?

Could you get us the content of MTT truststores for ELTS PROD and HUPX PROD

 
h2. Why ?

To help with M7P-5758.

It works for HUPX PROD but for ELTS PROD we get an error signaling that we are trying to create a certificate that already exists.

 
h2. Additional information

{color:#d4d4d4}- {color}{color:#569cd6}mtt1{color}{color:#d4d4d4}:{color}
 {color:#d4d4d4}    {color}{color:#569cd6}ansible_host{color}{color:#d4d4d4}: {color}{color:#ce9178}m7hupxprodm7b1{color}
  
 {color:#d4d4d4}- {color}{color:#569cd6}mtt1{color}{color:#d4d4d4}:{color}
 {color:#d4d4d4}    {color}{color:#569cd6}ansible_host{color}{color:#d4d4d4}: {color}{color:#ce9178}m7eltsprodm7b1{color}",,cs687,cv179,fj021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/20 10:17;cv179;image-2020-03-12-10-17-06-451.png;https://jira.deutsche-boerse.com/secure/attachment/81427/image-2020-03-12-10-17-06-451.png","12/Mar/20 10:18;cv179;image-2020-03-12-10-18-46-193.png;https://jira.deutsche-boerse.com/secure/attachment/81428/image-2020-03-12-10-18-46-193.png",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47779200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzpr7z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93272,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/20 10:17;cv179;on elts prod it looks like this:

 

!image-2020-03-12-10-17-06-451.png!","12/Mar/20 10:18;cv179;HUPX PROD shows this contents:

!image-2020-03-12-10-18-46-193.png!","12/Mar/20 10:52;fj021;[~cv179]Thanks. This looks fine. *This ticket can be closed !*",,,,,,,,,,,,,,,,,,,,,,,,,
CyberArk for M7T & ICS,M7P-5769,93266,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pn508,pn508,12/Mar/20 08:11,08/Apr/20 09:54,16/Sep/21 14:11,19/Mar/20 12:58,,6.8.114,7tops_sprint4,,,,,,,7tops_comm,,,,,,,"GIS finding regarding PAM onboarding:

The applications underlying infrastructure is not completely onboarded to *CyberArk*. Further, the DB used by the application is not yet onboarded to HP Guardium.
Insufficient protection and monitoring of operator logs can lead to malicious actions going undetected, which can result in confidential data leak / loss and the application not being able to provide the service.",,cs687,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47174400,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzx7pj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93266,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Mar/20 07:47;cs687;Asked the PAM-Team if the hosts are on-boarded to Cyberark. 

{code:java}
    m7cicsccuteapp1
    m7cicsccuteapp2
    m7cicsccuteamq1
    m7cicsccuteamq2
    m7cicsccuteamq3
    m7cicsccuteamq4
    m7cicsccuteamq5
    m7cicsccuteamq6
    m7cicscasimapp1
    m7cicscasimapp2
    m7cicscasimamq1
    m7cicscasimamq2
    m7cicscasimamq3
    m7cicscasimamq4
    m7cicscasimamq5
    m7cicscasimamq6
    m7cicscprodapp1
    m7cicscprodapp2
    m7cicscprodamq1
    m7cicscprodamq2
{code}
","19/Mar/20 08:35;cs687;The following hosts are on-boarded:

{code:java}
server	cyberark safe	cpmstatus	error message
m7cicsccuteapp1	Energy - root	success	0
m7cicsccuteapp2	Energy - root	success	0
m7cicsccuteamq1	Energy - root	success	0
m7cicsccuteamq2	Energy - root	success	0
m7cicsccuteamq3	Energy - root	success	0
m7cicsccuteamq4	Energy - root	success	0
m7cicsccuteamq6	Energy - root	success	0
m7cicscasimapp1	Energy - root	failure	Invalid username or bad password. code: 2114
m7cicscasimapp2	Energy - root	success	0
m7cicscasimamq1	Energy - root	success	0
m7cicscasimamq2	Energy - root	success	0
m7cicscasimamq3	Energy - root	success	0
m7cicscasimamq4	Energy - root	success	0
m7cicscasimamq5	Energy - root	success	0
m7cicscasimamq6	Energy - root	success	0
m7cicscprodapp1	Energy - root	success	0
m7cicscprodapp2	Energy - root	success	0
m7cicscprodamq1	Energy - root	success	0
m7cicscprodamq2	Energy - root	success	0

{code}

{color:#DE350B}m7cicsccuteamq5	#N/A	#N/A	#N/A
host m7cicsccuteamq5 is currently not on-boarded. {color}
*Will start the on-boarding process for that.*","19/Mar/20 12:58;cs687;Ticket: closed 

Onboarded the missing machine
{code:java}
The below email is classified: Internal

Hello Steffen,

The accounts are onboarded.

Best regards,
Vasileios Nikolaidis

{code}
",,,,,,,,,,,,,,,,,,,,,,,,,
CCS for ICS,M7P-5767,93264,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pn508,pn508,12/Mar/20 08:03,08/Apr/20 09:54,16/Sep/21 14:11,23/Mar/20 06:41,,6.8.114,7tops_sprint4,,,,,,,7tops_comm,,,,,,,"GIS finding in ICS Risk Assessment regarding Vulnerability scanning:

The infrastructure underlying the applications has not been completely onboarded to the security scanning tools. Most servers are missing Rapid7 vulnerability scan and significant number is missing *CCS compliance scanner.*
This can cause undetected misconfiguration or vulnerabilities being present in the network that can be taken advantage of by persistent threat acting in DBG network, or may result in in unexpected behavior. Both these risk may cause data loss or unavailability of application services.

CCS might have been already onboarded for both M7T & ICS, therefore *once confirmed please close the ticket*

_Last info from Steffen & Alex: CCS should be finished at least i on boarded today M7T/C Production and Simulation some weeks ago. So on Monday we should see all our hosts on-boarded for CCS (can double check that with Michael B.)_",,cs687,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46828800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzx7p3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93264,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/20 13:57;sw455;Remaining task: check if all ICS environements are onboarded to CCS - onboard to any envs still not covered","18/Mar/20 11:07;cs687;M7T is finalized since last week. 
For ICS i will check it let confirm Symantec CCS-Team. ","18/Mar/20 11:12;cs687;These Hosts: 

need to be checked

{code:java}
ansible all -l ""m7c*"" --list-hosts -k -K
    m7cicsccuteapp1
    m7cicsccuteapp2
    m7cicsccuteamq1
    m7cicsccuteamq2
    m7cicsccuteamq3
    m7cicsccuteamq4
    m7cicsccuteamq5
    m7cicsccuteamq6
    m7cicscasimapp1
    m7cicscasimapp2
    m7cicscasimamq1
    m7cicscasimamq2
    m7cicscasimamq3
    m7cicscasimamq4
    m7cicscasimamq5
    m7cicscasimamq6
    m7cicscprodapp1
    m7cicscprodapp2
    m7cicscprodamq1
    m7cicscprodamq2
{code}
","19/Mar/20 07:22;cs687;Waiting for an feedback - ticket is in waiting
{code:java}
Good Morning Symantec-Team, 
could you please check the current Situation, if these Hosts have “ccs” onboarded. 
If not I will immediately start with the on-boarding process. 

    m7cicsccuteapp1
    m7cicsccuteapp2
    m7cicsccuteamq1
    m7cicsccuteamq2
    m7cicsccuteamq3
    m7cicsccuteamq4
    m7cicsccuteamq5
    m7cicsccuteamq6
    m7cicscasimapp1
    m7cicscasimapp2
    m7cicscasimamq1
    m7cicscasimamq2
    m7cicscasimamq3
    m7cicscasimamq4
    m7cicscasimamq5
    m7cicscasimamq6
    m7cicscprodapp1
    m7cicscprodapp2
    m7cicscprodamq1
    m7cicscprodamq2

Thanks in Advance!

Cheers, 
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main
{code}

*UPDATE*
{code:java}
Hello Steffen,

These are currently not in CCS:
    m7cicsccuteapp1
    m7cicsccuteapp2
    m7cicsccuteamq1
    m7cicsccuteamq2
The rest of the list is in CCS.

Kind regards,
Matic Lukas
Security Linux & PKI (INH)
Phone: +420 29 64-2 80 25
Email: lukas.matic@deutsche-boerse.com
Deutsche Boerse Group
{code}

{color:#DE350B}Will on-board the missing one{color}","19/Mar/20 10:29;cs687;{code:java}
[cs687@enprodauto1 {master L | ?1} ~/ansible/energy.automation.deployments]$ ansible m7c-icsc-cute-app-amq1:m7c-icsc-cute-app-amq2:m7c-icsc-cute-cmi1:m7c-icsc-cute-cmi2 -m shell -b -a ""ls -all /opt/esm/system/*/agtcert.dat"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7c-icsc-cute-app-amq2 | FAILED | rc=2 >>
ls: cannot access /opt/esm/system/*/agtcert.dat: No such file or directorynon-zero return code

m7c-icsc-cute-cmi2 | FAILED | rc=2 >>
ls: cannot access /opt/esm/system/*/agtcert.dat: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq1 | FAILED | rc=2 >>
ls: cannot access /opt/esm/system/*/agtcert.dat: No such file or directorynon-zero return code

m7c-icsc-cute-cmi1 | FAILED | rc=2 >>
ls: cannot access /opt/esm/system/*/agtcert.dat: No such file or directorynon-zero return code
{code}

Registered:
{code:java}
[cs687@enprodauto1 {master L | ?1} ~/ansible/energy.automation.deployments]$ ansible m7c-icsc-cute-app-amq1:m7c-icsc-cute-app-amq2:m7c-icsc-cute-cmi1:m7c-icsc-cute-cmi2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7c-icsc-cute-app-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... Ok.

m7c-icsc-cute-cmi2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... Ok.

m7c-icsc-cute-cmi1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... Ok.

m7c-icsc-cute-app-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... Ok.
{code}
","23/Mar/20 06:41;cs687;Can be closed!
{code:java}
Hello Steffen,

Yes, I can see them in CCS now.

Have a nice weekend.

Kind regards,
Matic Lukas
Security Linux & PKI (INH)
Phone: +420 29 64-2 80 25
Email: matic.lukas@deutsche-boerse.com
Deutsche Boerse Group

{code}
",,,,,,,,,,,,,,,,,,,,,,
Rapid7 for ICS,M7P-5766,93263,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,pn508,pn508,12/Mar/20 07:59,08/Apr/20 09:54,16/Sep/21 14:11,20/Mar/20 10:53,,6.8.114,7tops_sprint4,,,,,,,7tops_comm,,,,,,,"GIS finding in ICS Risk Assessment regarding Vulnerability scanning:

The infrastructure underlying the applications has not been completely onboarded to the security scanning tools. Most servers are missing Rapid7 vulnerability scan and significant number is missing CCS compliance scanner.
This can cause undetected misconfiguration or vulnerabilities being present in the network that can be taken advantage of by persistent threat acting in DBG network, or may result in in unexpected behavior. Both these risk may cause data loss or unavailability of application services.

Rapid7 should have been already onboarded for M7T, therefore the task is to onboard M7 Capacity as well",,cs687,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Mar/20 07:48;cs687;on-boarded_rapid7.txt;https://jira.deutsche-boerse.com/secure/attachment/81725/on-boarded_rapid7.txt",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47088000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx7pb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93263,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/20 13:54;sw455;from refinement today:
 * most ICS VMs should already be including in Rapid7 reports
 * Task is then to check whether additional machines on ICS are still not covered in rapid7 reporting (see [~qo288] for details before starting work)","20/Mar/20 07:34;cs687;From the moment right now, it´s just seems that it is missing for *ICSC-CUTE*. For ASIM and PROD it is on-boarded

Checked the steps how it will be on-boarded with that repository https://github.deutsche-boerse.de/dev/energy.automation.os.install/blob/master/roles/os_agents/tasks/rapid7agent.yml
{code:java}

[cs687@enprodauto1 {master L | ?1} ~/ansible/energy.automation.deployments]$ ansible m7c-icsc-cute-app-amq*:m7c-icsc-cute-cmi1:m7c-icsc-cute-cmi2 -m shell
-b -a ""ls -all /home/scanmgr"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7c-icsc-cute-app-amq3 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq5 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq2 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq4 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq1 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-app-amq6 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-cmi2 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code

m7c-icsc-cute-cmi1 | FAILED | rc=2 >>
ls: cannot access /home/scanmgr: No such file or directorynon-zero return code
{code}
","20/Mar/20 07:48;cs687;When i am checking that current report for rapid7 i see an onboarded status of 99.75% 
https://csansp01.deutsche-boerse.de/dev/my342/sectools/

Just and only host *M7EPEXSIMUAMQ3* is missing, which is already decommissioned and not in use anymore. 
Besides that only ""*SIMU, ASIM and PROD* ENV´s have onboarded Rapid7. 

Hosts which tagged as on-boarded are the following ones:
 [^on-boarded_rapid7.txt] ","20/Mar/20 10:53;cs687;Can be closed, the report says that:

* ICS ASIM 
* ICS PROD

are onboarded. ",,,,,,,,,,,,,,,,,,,,,,,,
Coordinate installation of Java 11 and update Cardio config to use it,M7P-5762,93212,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,jv861,jv861,11/Mar/20 12:36,08/Sep/21 15:21,16/Sep/21 14:11,,,,,,,,,,,7tops,M7PRODOPS,,,,,,"* Install Java 11 to {{englobmon2}} (keeping Java 8 too) and updating cardio instances there touse it
 * Install Java 11 to customer envs and update existing instances
 * Install Java 11 to production (currently only ELTS PROD) and upgrade cardio there",,jv861,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47865600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx37b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Technical Debt/Improvements,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93212,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
CODA logs from ELTS PROD ,M7P-5746,93020,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,09/Mar/20 12:26,18/Mar/20 13:26,16/Sep/21 14:11,09/Mar/20 12:57,,6.9.81,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,,"h2. What ?

Could we get the CODA logs on ELTS PROD ?
h2. Why ?

We're not seeing any logs from CODA on Kibana, we want to know if it's still running on ELTS PROD and if not why.
h2. Additional information

From inventory : 
{color:#d4d4d4}- {color}{color:#569cd6}coda1{color}{color:#d4d4d4}:{color}
{color:#d4d4d4}    {color}{color:#569cd6}ansible_host{color}{color:#d4d4d4}: {color}{color:#ce9178}englobmon2{color}",,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48038400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx89z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":93020,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Mar/20 12:51;iu252;Started coda on englobmon2:

{noformat}
[tomcat@englobmon2 elts-prod-coda1]$ ./start.sh
[tomcat@englobmon2 elts-prod-coda1]$ nohup: redirecting stderr to stdout

[tomcat@englobmon2 elts-prod-coda1]$
[tomcat@englobmon2 elts-prod-coda1]$
[tomcat@englobmon2 elts-prod-coda1]$
[tomcat@englobmon2 elts-prod-coda1]$ ps -ef | grep coda
tomcat    83832      1 99 12:50 pts/0    00:00:27 /opt/java/default/bin/java -Xms256M -Xmx256M -jar /elts/elts-prod-coda1/crossed-orderbook-detector-app.jar --spring.config.additional-location=file:/elts/elts-prod-coda1/application.yml --logging.config=file:/elts/elts-prod-coda1/logback.xml --spring.profiles.active=epex
tomcat    84017  66345  0 12:50 pts/0    00:00:00 grep --color=auto coda
[tomcat@englobmon2 elts-prod-coda1]$
{noformat}
","09/Mar/20 12:57;iu252;Logs are now available in Kibana.",,,,,,,,,,,,,,,,,,,,,,,,,,
Deploy newest ICS and Rabbit on ATE5,M7P-5740,92952,91430,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,MG726,MG726,06/Mar/20 10:47,18/Mar/20 13:26,16/Sep/21 14:11,13/Mar/20 10:19,,7tops_sprint2,,,,,,,,M7PRODOPS,,,,,,,Fix deployment to ATE5 - deploy with newest ICS (v6.8.99) and Rabbit 3.8.1.,,MG726,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48038400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7wf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 89,Schmetterling Sprint 90 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92952,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"09/Mar/20 10:26;qo288;Deployment passes now after switch to patroni and newer flyway. also, created cmi schema in the new DB",,,,,,,,,,,,,,,,,,,,,,,,,,,
CATRINA: Onboarding of MFT Energy to ICS CuTe,M7P-5737,92936,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,tj898,qm925,qm925,06/Mar/20 08:35,08/Apr/20 09:54,16/Sep/21 14:11,19/Mar/20 12:40,,6.8.114,7tops_sprint4,,,,,,,7tops_comm,,,,,,,"MFT Energy are in the process of developing their SW for connecting to CATRINA. 

Please:
* grant MFT Energy with access to ICS CuTe
* provide them with the roll-on package (test client, specs, etc.)
* Balancing Group EIC/EAN/GLN Code: 23X--161129-ME-L

Please provide the details to the clients only after confirmation from Account Management (Simona).",,qm925,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-985,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47174400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx9tb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92936,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"17/Mar/20 09:52;qm925;Hi [~tj898],

The roll-on package can be already provided to the clients. The email address is jg@mft-energy.com
Could you please also update the Communication Matrix on Confluence?

Thank you.

Best  regards,
Simona
","19/Mar/20 12:39;tj898;Details and onboarding package sent to customer though the mentioned email address",,,,,,,,,,,,,,,,,,,,,,,,,,
EPEXMT CLONE: Issue Retest for 6.8.118,M7P-5736,92926,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,vp223,vp223,05/Mar/20 15:28,18/Mar/20 13:26,16/Sep/21 14:11,06/Mar/20 10:21,,6.9.81,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,," 

Member to be used: AETEX

User to be used: M7USE140

I suppose scope would be
 * EPEX to login somehow to cluster
 * DBAG to identify to which RabbitMQ node they are connected
 * DBAG to simulate that node crash
 * EPEX relogin to the system while node is crashed

 * Expected result: with 6.8.102 (PROD software) EPEX cannot relogin
 * Expected result: with 6.8.118 (PROD software) EPEX can relogin",,cs687,vp223,,,,,,,,,,,,,,,,,,EPEXMT-2490,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,48297600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7qv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":92926,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/20 10:16;cs687;found out in webgui ->  https://ctpb1.epex-lts.m7.deutsche-boerse.com:60460/intraday/faces/jsp/admin/admin.xhtml
the LOGINID on amq side. Clicked to ""Users Overview"" and searched for user ""AETEX"" and found out the *LOGINID* M7USE140


{code:java}
ComTraderConnection
 elts-ctpb-amq1@m7eltsctpbamq1 M7USE140 
running ○ AMQP 0-9-1 3 0iB/s 0iB/s 
{code}

in CT it is connected since 10:01 and connected to amq1

which i stopped afterwards. 

","06/Mar/20 10:17;cs687;UPDATE: Customer receiving heartbeat loss","06/Mar/20 10:19;cs687;Customer confirmed Test were successful!
Starting the amq1 again 

{code:java}
rabbitmq@m7eltsctpbamq1:[/elts/elts-ctpb-amq1]$ ./start.sh
{code}

","06/Mar/20 10:21;cs687;Cluster is in an active healthy state again!

{code:java}

Cluster name: elts-ctpb-amq1@m7eltsctpbamq1.deutsche-boerse.de

Disk Nodes

elts-ctpb-amq1@m7eltsctpbamq1
elts-ctpb-amq3@m7eltsctpbamq3
elts-ctpb-amq5@m7eltsctpbamq5

Running Nodes

elts-ctpb-amq1@m7eltsctpbamq1
elts-ctpb-amq3@m7eltsctpbamq3
elts-ctpb-amq5@m7eltsctpbamq5

Versions

elts-ctpb-amq1@m7eltsctpbamq1: RabbitMQ 3.8.1 on Erlang 22.1
elts-ctpb-amq3@m7eltsctpbamq3: RabbitMQ 3.8.1 on Erlang 22.1
elts-ctpb-amq5@m7eltsctpbamq5: RabbitMQ 3.8.1 on Erlang 22.1

{code}
","06/Mar/20 10:21;cs687;.",,,,,,,,,,,,,,,,,,,,,,,
CATRINA: Grant TrailStone Renewables with access to ICS CuTe,M7P-5728,92891,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,tj898,qm925,qm925,05/Mar/20 10:20,24/Mar/20 23:40,16/Sep/21 14:11,16/Mar/20 11:56,,6.8.114,7tops_sprint2,,,,,,,7tops_comm,,,,,,,"Please:
* grant TrailStone Renewables with access to ICS CuTe
* provide them with the roll-on package (test client, specs, etc.)
* Balancing Group EIC/EAN/GLN Code: 11X0-0000-0518-U

Please provide the details to the clients only after confirmation from Account Management (Simona).",,qm925,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-958,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47433600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx9t3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92891,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 14:27;tj898;Hello, [~qm925] .

We'll proceed with this request. One thing we will need is the Balancing Group to be assigned? Could you please mention it here in the ticket?

Thanks,

Hugo","05/Mar/20 14:29;qm925;Hi [~tj898],

Balancing Group EIC/EAN/GLN Code: 11X0-0000-0518-U

I have updated the description as well.
","12/Mar/20 17:56;qm925;Please provide the information to the clients to help@trailstonegroup.com ","16/Mar/20 11:56;tj898;Onboarding package and account details sent to the email address.",,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Disable HA Policy on all EPEX Non Production environments,M7P-5725,92874,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cf948,rehapav,rehapav,04/Mar/20 17:00,02/Dec/20 12:45,16/Sep/21 14:11,05/Mar/20 09:25,,7tops_sprint106,,,,,,,,7tops,minor,,,,,,"Hello,

in order tTo disable HA Policy in below envt but keep HA Policy enabled for DTT users & all M7 queues in following environments
 EPEX ASIM
ELTS SIMU
 ELTS CTPB
 ELTS CUTE
 ELTS LIPA
 ELTS ACUT

 

please provide commands for TechOps how to disable it:- similar to what has been done in SERVICE-5594",,cf948,rehapav,,,,,,,,,,,,,,,,,,SERVICE-5607,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,As a consequence of global disabling of HA Policy on ELTS Non production envt,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,48384000,,,dm700,lw641,ox626,rehapav,sw455,,24/Feb/20 11:00,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7hj:",9223372036854775807,,,,No,,,,,,N/A,,,,,,,,,,,,X-Men Sprint 88 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,"{""issueId"":92874,""testStatuses"":[]}",,,,Successfully implemented in production SERVICE-5605,,,,,,,,,,,,,,,,,,SIMU,,,,"05/Mar/20 09:19;cf948;{code}
rabbitmqctl set_policy --apply-to queues HA '^(?!amq\..*)(?!m7\.deadLetter.*)(?!m7\.broadcast.*)(?!m7\.private\.responseQueue.*)' '{""ha-mode"": ""exactly"", ""ha-sync-mode"": ""automatic"", ""ha-params"": 2}' -p $AMQP_ADMIN_INST
rabbitmqctl set_policy --apply-to queues HA-system-queues '^(m7\.broadcastQueue\.(tm-admingui|CXEPEX).*)' '{""ha-mode"": ""exactly"", ""ha-sync-mode"": ""automatic"", ""ha-params"": 2}' -p $AMQP_ADMIN_INST
{code}

After you run this you can check if it was applied:
{code}
rabbitmqctl list_policies -p $AMQP_ADMIN_INST
{code}

If the property $AMQP_ADMIN_INST is not defined replace it with app",,,,,,,,,,,,,,,,,,,,,,,,,,,
Access to ELTS PROD COPY DB,M7P-5721,92857,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,04/Mar/20 14:23,01/Apr/20 11:06,16/Sep/21 14:11,23/Mar/20 09:23,,6.10.4,6.9.81,6.9.91,7tops_sprint2,,,,,M7PRODOPS,,,,,,,"h2. Context

I've been told that I need to create a Jira ticket to Techops if I want access to the DB Copy of ELTS PROD through Citrix.
h2. What

Can someone grant me access to the ELTS PROD DB Copy ?

My credential : *fj021*
h2. Additional information

Server : m7spg12-copyshrd
 Port : 29900
 Db name : m7eltsprodm7b

 

Thanks !

Cheers",,dm700,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Mar/20 15:24;fj021;image-2020-03-20-15-24-27-397.png;https://jira.deutsche-boerse.com/secure/attachment/81761/image-2020-03-20-15-24-27-397.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46828800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7en:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92857,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"04/Mar/20 17:01;dm700;[~dm700] approved","05/Mar/20 08:31;iu252;Grant access to ELTS PROD COPY DB.
Send email with the password.


[~fj021], please check and confirm.","05/Mar/20 08:38;fj021;[~iu252] : I can confirm that I now have access, thanks Alex !","20/Mar/20 15:27;fj021;Like discussed here's the details about the situation : 

When I was first given access, I had no issue querrying tables from m7eltsprodm7b.

But all of a sudden, (I started noticing last week, I don't use it everyday so I'm not sure when it started) I can't anymore and get ""ERROR: permission denied for schema m7eltsprodm7b"".

I'm using the following to connect, didn't change anything in between : 
!image-2020-03-20-15-24-27-397.png!

Here's the detailed error stack from DBAnalyzer when trying to see the content of a table : 
{code:java}
An error occurred while executing the database request for:
PostgreSQL
9.3.6.19
PostgreSQL JDBC Driver
42.0.0.jre7

Short message:
An error occurred while performing the operation:
ERROR: permission denied for schema m7eltsprodm7b
Position: 15

The command that caused the problem:
SELECT * FROM ""m7eltsprodm7b"".""cx_110_trade""

Long Message:
ERROR: permission denied for schema m7eltsprodm7b
Position: 15

Details:
   Type: org.postgresql.util.PSQLException
   SQL State: 42501

System Information:
Product: DbVisualizer Free 9.5.7 [Build #2611]
OS: Windows Server 2012 R2
OS Version: 6.3
OS Arch: amd64
Java Version: 1.8.0_171
Java VM: Java HotSpot(TM) 64-Bit Server VM
Java Vendor: Oracle Corporation
Java Home: m:\winprog\javasoft\jre\8x64
DbVis Home: M:\WINPROG\DBVisualizer9.5.7
User Home: C:\Users\fj021
PrefsDir: P:\Winprog\DBVisualizer
SessionId: 358
BindDir: null
{code}","23/Mar/20 09:23;iu252;User ID fj021 was missing in 000_VARIABLES.INP (Thank you, [~cs687]!).",,,,,,,,,,,,,,,,,,,,,,,
measure persistor performance during daily db backup ,M7P-5717,92842,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,04/Mar/20 10:36,18/Mar/20 13:26,16/Sep/21 14:11,12/Mar/20 12:09,,6.9.85,7tops_sprint2,,,,,,11/Mar/20 00:00,M7PRODOPS,,,,,,,"On 10/3 we will execute final version of dbcleanup script in ELTS PROD

On 11/3 please trigger dialy backup (assuming that db is pretty small now, cca 20 gb)

and observe persistor behaviour during the dump.

 

Based on the performance decide if we should enable

- daily db backups",,ax460,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,47692800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7br:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92842,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"12/Mar/20 11:18;cs687;Started the job by Alex Orlov 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Hotfix-DB/job/_Automatically-M7-Trigger-Hotfix-DB.ELTS/222/console
","12/Mar/20 11:51;cs687;* start time of the postgres process is 12-MAR-20 11:16:58
* dump finished 2020-03-12 11:44:27

","12/Mar/20 12:09;cs687;Complete job runs round about 45 minutes with dumping/copying and restoring.","12/Mar/20 12:32;ax460;[~rehapav] [~pw231] shall we than reintroduce daily copy do ELTS PROD COPY DB? ","12/Mar/20 14:51;rehapav;From my perspective and understanding of test results I suggest to enable daily backup until we have PatroniDB in place.

[~pw231]?",,,,,,,,,,,,,,,,,,,,,,,
Kafka takeover & future feature plan,M7P-5716,92831,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fp407,fp407,04/Mar/20 09:30,18/Mar/20 13:26,16/Sep/21 14:11,12/Mar/20 11:11,,6.9.85,7tops_sprint2,,,infrastructure,,,,7tops_comm,,,,,,,"# Get familiar with current Kafka deployment procedure
 # Collect necessary features from devs, infrastructure team
 # Prepare plan for implementation of these new and/or missing feature",,cs687,fp407,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47779200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx74n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 2,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92831,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 11:07;cs687;Scheduled a meeting with [~qo288] and [~fp407] on Wednesday 11.03.2020 ","11/Mar/20 13:05;cs687;https://github.deutsche-boerse.de/dev/energy.kafka.cluster/blob/master/docs/training/NOTES_FOR_TAKEOVER.md","11/Mar/20 14:34;cs687;Setup Kafaka cluster with test application: 
{code:java}
[‎3/‎11/‎2020 2:32 PM]  Michal Jancok:  
1. https://github.deutsche-boerse.de/dev/energy.kafka.cluster/blob/master/vault/vault_clean.sh 
 
[‎3/‎11/‎2020 2:32 PM]  Michal Jancok:  
2. https://github.deutsche-boerse.de/dev/energy.kafka.cluster/blob/master/docs/guides/CLUSTER_DEPLOYMENT_GUIDE.md 
 
[‎3/‎11/‎2020 2:33 PM]  Michal Jancok:  
3. https://github.deutsche-boerse.de/dev/energy.kafka.cluster/blob/master/docs/guides/APPLICATION_SETUP_AND_CONNECTION_GUIDE.md#the-setup-procedure 

4. check here: https://confluence.energy.svc.dbgcloud.io/login.action?os_destination=%2Fpages%2Fviewpage.action%3FspaceKey%3DET%26title%3DKafka&permissionViolation=true  (from CITRIX!)
{code}

Next step is, to setup a Kafka cluster with m7-test application together with [~qo288]
and collect all the necessary topics, like 
* merging kafka deployment repository to our energy.automation.deployments repo etc. 
* adding kafka monitorring to our monitoring 
","12/Mar/20 11:10;cs687;Ticket https://jira.deutsche-boerse.com/browse/M7P-5771
will proceed with [~qo288] and me to collect some few first experiences. 

Ticket here can be closed. first Takeover was done during the meeting on wednesday 12.03.2020",,,,,,,,,,,,,,,,,,,,,,,,
Remove SADMIN password access & Personalize OPS accounts,M7P-5712,92787,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,dp007,sw455,sw455,03/Mar/20 12:48,06/May/20 11:08,16/Sep/21 14:11,13/Mar/20 11:15,,7tops Sprint6,,,,,,,03/Mar/20 00:00,M7PRODOPS,,,,,,,"Per GIS request, SADMIN access needs closer control than the current approach of sharing its password on a restricted confluence page.


Steps 1)
 * Create DBGADM00-06 users for BizOps personnel
 ** Users have admin but not super admin acess
 ** passwords will be personalized - used only by owner of account

Step 2)
 * SADMIN password to be reset and:
 ** initially kept with Management escalation team only
 ** will be eventually moved to CyberArk Vaukt",,dp007,lw641,ne232,tj898,ub113,wn626,yn731,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,ESO-259,,,,,,"03/Mar/20 15:52;sw455;image-2020-03-03-15-52-27-677.png;https://jira.deutsche-boerse.com/secure/attachment/81025/image-2020-03-03-15-52-27-677.png","04/Mar/20 17:30;tj898;image-2020-03-04-17-30-26-957.png;https://jira.deutsche-boerse.com/secure/attachment/81095/image-2020-03-04-17-30-26-957.png",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,EPEX,HUPX,OPCOM,Southpool,TGE,,,,,,,,,,,43718400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx72v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 1,7tops Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92787,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"03/Mar/20 13:04;sw455;XSOP Production:
 * Created users under Member: ADMIN
 ** Role: Admin (*non* super admin)
 ** Rights:
 *** Reference Data GUI
 *** Capacity Info

 # DBGADM00 | [alexander.thorne@deutsche-boerse.com|mailto:alexander.thorne@deutsche-boerse.com]
 # DBGADM01 | [hugo.correia@deutsche-boerse.com|mailto:hugo.correia@deutsche-boerse.com%C2%A0]
 # DBGADM02 | [ana.kovacevic@deutsche-boerse.com|mailto:ana.kovacevic@deutsche-boerse.com]

 # DBGADM03 | [iaroslav.kuchugurnyi@deutsche-boerse.com|mailto:iaroslav.kuchugurnyi@deutsche-boerse.com]

 # DBGADM04 | [ramiro.gabriel.fafian.sala@deutsche-boerse.com|mailto:ramiro.gabriel.fafian.sala@deutsche-boerse.com]

 # DBGADM05 | [martin.komberec@deutsche-boerse.com|mailto:martin.komberec@deutsche-boerse.com]
 # DBGADM06 | serhii.botulinskyi@deutsche-boerse.com
 # DBGADM07 | [sharadkumar.kariya.bangera@clearstream.com|mailto:sharadkumar.kariya.bangera@clearstream.com]

 ","03/Mar/20 13:07;tj898;*ELTS PROD:*

DONE (with same parameters as XSOP)

 ","03/Mar/20 13:29;tj898;*OPCOM PROD:*

DONE","03/Mar/20 13:35;sw455;*HUPX PROD:*

DONE (with same parameters as XSOP)","03/Mar/20 13:40;tj898;*TGE PROD:*

DONE","03/Mar/20 15:52;sw455;SADMIN01 password modified for all PROD envs

 ","03/Mar/20 15:52;sw455;[~tj898] - can you create personalized ref data admin users for BO team for ICS Prod? You can copy the details below
!image-2020-03-03-15-52-27-677.png!","04/Mar/20 17:29;tj898;*ICS PROD:*

DONE","04/Mar/20 17:30;tj898;!image-2020-03-04-17-30-26-957.png!","04/Mar/20 18:04;tj898;|| ||ELTS ||HUPX||XSOP||TGE  ||OPCOM||ICS  ||FLEX||EPEX 6.0||
|DBGADM00|(/)|(/)|(/)|(/)|(/)|(/)| | |
|DBGADM01|(/)|(/)|(/)|(/)|(/)|(/)| (/)| |
|DBGADM02| (/)| (/)| (/)| (/)| (/)| (/)| (/)| |
|DBGADM03|(/) | (/)| (/)| (/)| (/)| (/)| (/)| |
|DBGADM04| (/)| (/)| (/)| (/)| (/)| (/)| (/)| |
|DBGADM05| (/)|  (/)|  (/)|  (/)|  (/)| (/) |  (/)| |
|DBGADM06| (/)| (/)| (/)| (/)| (/)| (/)| (/)| |
|DBGADM07| (/) | (/) | (/) | (/) | (/) | (/) |(/)| |","13/Mar/20 11:14;sw455;Flex Prod done as well","16/Mar/20 15:00;ub113;Hi [~tj898]

Could you, please, reset password for DBGADM02 in XSOP PROD?

You might have to unlosck that account too.

Thank you,

 

Ana","16/Mar/20 16:14;sw455;Reset DBGADM02 in XSOP PROD - please check again","07/Apr/20 10:47;yq577;Granted superadmin access to all users DBGADM00-06 in all production envt
","28/Apr/20 11:39;dp007;|| ||ELTS ||HUPX||XSOP||TGE  ||OPCOM||ICS  ||FLEX||EPEX 6.0||
|DBGADM00|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM01|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM02|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM03|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM04|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM05|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM06|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|
|DBGADM07|(/)|(/)|(/)|(/)|(/)|(/)|(/)|(/)|",,,,,,,,,,,,,
Test new version of dbcleanup script (elts-prod) ,M7P-5703,92756,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,03/Mar/20 09:26,18/Mar/20 13:26,16/Sep/21 14:11,05/Mar/20 07:57,,6.9.81,7tops_sprint2,,,MTT,,,06/Mar/20 00:00,M7PRODOPS,,,,,,,"For the elts-prod deployment next week
https://jira.deutsche-boerse.com/browse/SERVICE-5478

We should validate the script behavior (refer pull-151) on the current database elts-prod.
https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/152

For that Dry-Run we restore the fullbackup and newest incremental backup on host m7spg2
copyId: 1 - 1583183378 - /ampgsql-data-0 - 2020-03-02 22:09:38
and analyse the update and execution time.
Once it is done we should give the proper feedback/result to Pavel Rehak (dbg ops)

",,cs687,dp007,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 07:56;cs687;pg_stat_all_tables;https://jira.deutsche-boerse.com/secure/attachment/81096/pg_stat_all_tables",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,48384000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx6uf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92756,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"03/Mar/20 14:39;cs687;Starting requesting the full-backup 

{code:java}
[root@m7spg2 restore]# ~/restore_eltsprod.sh /ampgsql-data-0 ""2020-03-02 22:09:38""
Check copyId: 1 - 1583183378 - /ampgsql-data-0 - 2020-03-02 22:09:38
Retrieving copyId: 1 - 1583183378 - /ampgsql-data-0 - 2020-03-02 22:09:38
......
{code}
","04/Mar/20 08:26;cs687;Starting requesting the incremental-backup
{code:java}
[root@m7spg2 restore]#  ~/restore_eltsprod.sh /ampgsql-data-1 ""2020-03-02 23:38:11""
Check copyId: 1 - 1583188691 - /ampgsql-data-1 - 2020-03-02 23:38:11
Retrieving copyId: 1 - 1583188691 - /ampgsql-data-1 - 2020-03-02 23:38:11
v[0] = /usr/bin/ampgsql
{code}
","04/Mar/20 09:17;cs687;{color:#DE350B}*Before running the scripts:*{color}

* the indices are in place
{code:java}
  schemaname   |       tablename        |         indexname         | tablespace |                                                                  indexdef
---------------+------------------------+---------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------
 m7eltsprodm7b | cx_101_order_history   | idx101_002                |            | CREATE INDEX idx101_002 ON cx_101_order_history USING btree (last_update_time)
 m7eltsprodm7b | cx_101_order_history   | idx101_001                |            | CREATE INDEX idx101_001 ON cx_101_order_history USING btree (rev, revtype, last_update_time, balancing_group_eic, order_type_code, action)
 m7eltsprodm7b | cx_101_order_history   | cx_101_order_history_pkey |            | CREATE UNIQUE INDEX cx_101_order_history_pkey ON cx_101_order_history USING btree (order_id, rev)
 m7eltsprodm7b | cx_111_trade_history   | idx111_002                |            | CREATE INDEX idx111_002 ON cx_111_trade_history USING btree (contract_id, order_id_buy, order_id_sell, action)
 m7eltsprodm7b | cx_111_trade_history   | idx111_001                |            | CREATE INDEX idx111_001 ON cx_111_trade_history USING btree (last_update_time)
 m7eltsprodm7b | cx_111_trade_history   | cx_111_trade_history_pkey |            | CREATE UNIQUE INDEX cx_111_trade_history_pkey ON cx_111_trade_history USING btree (trade_id, rev)
 m7eltsprodm7b | cx_296_session_history | idx296_001                |            | CREATE INDEX idx296_001 ON cx_296_session_history USING btree (session_id)
(7 rows)
{code}


* there are records in all those table
{code:java}
m7eltsprodm7b=# \dt+ cx_151_messages_history
                                   List of relations
    Schema     |          Name           | Type  |     Owner     | Size  | Description
---------------+-------------------------+-------+---------------+-------+-------------
 m7eltsprodm7b | cx_151_messages_history | table | m7eltsprodm7b | 15 GB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_120_remote_public_trade_history
                                        List of relations
    Schema     |                Name                | Type  |     Owner     | Size  | Description
---------------+------------------------------------+-------+---------------+-------+-------------
 m7eltsprodm7b | cx_120_remote_public_trade_history | table | m7eltsprodm7b | 12 GB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_441_contract_delivery_area_state_history
                                              List of relations
    Schema     |                    Name                     | Type  |     Owner     |  Size   | Description
---------------+---------------------------------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_441_contract_delivery_area_state_history | table | m7eltsprodm7b | 1211 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_211_contract_history
                                    List of relations
    Schema     |          Name           | Type  |     Owner     |  Size   | Description
---------------+-------------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_211_contract_history | table | m7eltsprodm7b | 3041 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_215_contract_closing_price_history
                                          List of relations
    Schema     |                 Name                  | Type  |     Owner     |  Size  | Description
---------------+---------------------------------------+-------+---------------+--------+-------------
 m7eltsprodm7b | cx_215_contract_closing_price_history | table | m7eltsprodm7b | 587 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_296_session_history
                                   List of relations
    Schema     |          Name          | Type  |     Owner     |  Size  | Description
---------------+------------------------+-------+---------------+--------+-------------
 m7eltsprodm7b | cx_296_session_history | table | m7eltsprodm7b | 431 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ m7_999_revision_index
                                  List of relations
    Schema     |         Name          | Type  |     Owner     | Size  | Description
---------------+-----------------------+-------+---------------+-------+-------------
 m7eltsprodm7b | m7_999_revision_index | table | m7eltsprodm7b | 11 GB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_101_order_history
                                 List of relations
    Schema     |         Name         | Type  |     Owner     | Size  | Description
---------------+----------------------+-------+---------------+-------+-------------
 m7eltsprodm7b | cx_101_order_history | table | m7eltsprodm7b | 22 GB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_262_limit_history
                                  List of relations
    Schema     |         Name         | Type  |     Owner     |  Size   | Description
---------------+----------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_262_limit_history | table | m7eltsprodm7b | 2474 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_119_settlement_history
                                     List of relations
    Schema     |           Name            | Type  |     Owner     |  Size   | Description
---------------+---------------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_119_settlement_history | table | m7eltsprodm7b | 1543 MB |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_673_trade_flow_history
                                     List of relations
    Schema     |           Name            | Type  |     Owner     |  Size   | Description
---------------+---------------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_673_trade_flow_history | table | m7eltsprodm7b | 0 bytes |
{code}
{code:java}
m7eltsprodm7b=# \dt+ cx_111_trade_history
                                  List of relations
    Schema     |         Name         | Type  |     Owner     |  Size   | Description
---------------+----------------------+-------+---------------+---------+-------------
 m7eltsprodm7b | cx_111_trade_history | table | m7eltsprodm7b | 1936 MB |
{code}

* there is a sequence in settlement history
{code:java}
m7eltsprodm7b=# select * from information_schema.sequences;
 sequence_catalog | sequence_schema |               sequence_name                | data_type | numeric_precision | numeric_precision_radix | numeric_scale | start_value | minimum_value |    maximum_value    | increment | cycle_option
------------------+-----------------+--------------------------------------------+-----------+-------------------+-------------------------+---------------+-------------+---------------+---------------------+-----------+--------------
 m7eltsprodm7b    | sys             | plsql_profiler_runid                       | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | sys             | snapshot_num_seq                           | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_119_settlement_history_seq              | bigint    |                64 |                       2 |             0 | 191097814   | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_213_contract_name_format_history_id_seq | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_410_trading_phase_trading_phase_id_seq  | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | hibernate_sequence                         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | hibernate_sequence_v42                     | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_268_risk_management_id_seq              | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_212_contract_name_format_id_seq         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_103_quote_request_id_seq                | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | envers_sequence                            | bigint    |                64 |                       2 |             0 | 1           | -2147483648   | 9223372036854775807 | 1         | NO
(11 rows)
{code}



","04/Mar/20 13:55;cs687;{color:#DE350B}*executed the scripts:*{color}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V002__M7P-5664_cleanup_messages_history.sql -A -F "","" -o /copyshrd/data/restore/script/V002__M7P-5664_cleanup_messages_history.csv*
*executed round about 1-2 Minutes*

shrink down from 15GB
{code:java}
m7eltsprodm7b=# \dt+ cx_151_messages_history
                                   List of relations
    Schema     |          Name           | Type  |    Owner     |  Size   | Description
---------------+-------------------------+-------+--------------+---------+-------------
 m7eltsprodm7b | cx_151_messages_history | table | enterprisedb | 9216 kB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V003__M7P-5664_cleanup_remote_public_trade_history.sql -A -F "","" -o /copyshrd/data/restore/script/V003__M7P-5664_cleanup_remote_public_trade_history.csv*

stayed the same
{code:java}
m7eltsprodm7b=# \dt+ cx_120_remote_public_trade_history
                                        List of relations
    Schema     |                Name                | Type  |     Owner     | Size  | Description
---------------+------------------------------------+-------+---------------+-------+-------------
 m7eltsprodm7b | cx_120_remote_public_trade_history | table | m7eltsprodm7b | 12 GB |
(1 row)
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V004__M7P-5664_cleanup_contract_delivery_area_state_history.sql -A -F "","" -o /copyshrd/data/restore/script/V004__M7P-5664_cleanup_contract_delivery_area_state_history.csv*
*executed under 1 minute*

shrink down from 1211 MB 
{code:java}
m7eltsprodm7b=# \dt+ cx_441_contract_delivery_area_state_history
                                            List of relations
    Schema     |                    Name                     | Type  |    Owner     | Size  | Description
---------------+---------------------------------------------+-------+--------------+-------+-------------
 m7eltsprodm7b | cx_441_contract_delivery_area_state_history | table | enterprisedb | 29 MB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V005__M7P-5664_cleanup_contract_history.sql -A -F "","" -o /copyshrd/data/restore/script/V005__M7P-5664_cleanup_contract_history.csv*
*executed under 1 minute*
shrink down from 3041 MB 

{code:java}
You are now connected to database ""m7eltsprodm7b"" as user ""enterprisedb"".
m7eltsprodm7b=# \dt+ cx_211_contract_history
                                  List of relations
    Schema     |          Name           | Type  |    Owner     | Size  | Description
---------------+-------------------------+-------+--------------+-------+-------------
 m7eltsprodm7b | cx_211_contract_history | table | enterprisedb | 30 MB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V006__M7P-5664_cleanup_contract_closing_price_history.sql -A -F "","" -o /copyshrd/data/restore/script/V006__M7P-5664_cleanup_contract_closing_price_history.csv*
*executed under 1 minute*

shrink down from 587 MB
{code:java}
m7eltsprodm7b=# \dt+ cx_215_contract_closing_price_history
                                          List of relations
    Schema     |                 Name                  | Type  |    Owner     |  Size   | Description
---------------+---------------------------------------+-------+--------------+---------+-------------
 m7eltsprodm7b | cx_215_contract_closing_price_history | table | enterprisedb | 4000 kB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V007__M7P-5664_cleanup_session_history.sql -A -F "","" -o /copyshrd/data/restore/script/V007__M7P-5664_cleanup_session_history.csv*
*executed under 1 minute*

shrink down from 431 MB

{code:java}

m7eltsprodm7b=# \dt+ cx_296_session_history
                                   List of relations
    Schema     |          Name          | Type  |    Owner     |  Size   | Description
---------------+------------------------+-------+--------------+---------+-------------
 m7eltsprodm7b | cx_296_session_history | table | enterprisedb | 5312 kB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V008__M7P-5664_cleanup_revision_index.sql -A -F "","" -o /copyshrd/data/restore/script/V008__M7P-5664_cleanup_revision_index.csv*
*executed under 1 minute*

shrink down from 11 GB

{code:java}
m7eltsprodm7b=# \dt+ m7_999_revision_index
                                    List of relations
    Schema     |         Name          | Type  |    Owner     |    Size    | Description
---------------+-----------------------+-------+--------------+------------+-------------
 m7eltsprodm7b | m7_999_revision_index | table | enterprisedb | 8192 bytes |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V009__M7P-5664_cleanup_order_history.sql -A -F "","" -o /copyshrd/data/restore/script/V009__M7P-5664_cleanup_order_history.csv*
{color:#DE350B}*executed round about 6 Minutes*{color}

shrink down from 22 GB
{code:java}
m7eltsprodm7b=# \dt+ cx_101_order_history
                                 List of relations
    Schema     |         Name         | Type  |    Owner     | Size  | Description
---------------+----------------------+-------+--------------+-------+-------------
 m7eltsprodm7b | cx_101_order_history | table | enterprisedb | 10 GB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V010__M7P-5664_cleanup_limit_history.sql -A -F "","" -o /copyshrd/data/restore/script/V010__M7P-5664_cleanup_limit_history.csv*
executed round about 2-3 minutes

shrink down from 2474 MB
{code:java}
m7eltsprodm7b=# \dt+ cx_262_limit_history
                                  List of relations
    Schema     |         Name         | Type  |    Owner     |  Size   | Description
---------------+----------------------+-------+--------------+---------+-------------
 m7eltsprodm7b | cx_262_limit_history | table | enterprisedb | 1423 MB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V011__M7P-5664_cleanup_settlement_history.sql -A -F "","" -o /copyshrd/data/restore/script/V011__M7P-5664_cleanup_settlement_history.csv*
*executed under 1 minute*

shrink down from 1543 MB

{code:java}
m7eltsprodm7b=# \dt+ cx_119_settlement_history
                                    List of relations
    Schema     |           Name            | Type  |    Owner     |  Size  | Description
---------------+---------------------------+-------+--------------+--------+-------------
 m7eltsprodm7b | cx_119_settlement_history | table | enterprisedb | 726 MB |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V012__M7P-5664_cleanup_trade_flow_history.sql -A -F "","" -o /copyshrd/data/restore/script/V012__M7P-5664_cleanup_trade_flow_history.csv*

stayed the same - was already empty
{code:java}
m7eltsprodm7b=# \dt+ cx_673_trade_flow_history
                                    List of relations
    Schema     |           Name            | Type  |    Owner     |  Size   | Description
---------------+---------------------------+-------+--------------+---------+-------------
 m7eltsprodm7b | cx_673_trade_flow_history | table | enterprisedb | 0 bytes |
{code}

*enterprisedb@m7spg2:/copyshrd/data/restore > psql -p 22222 -d m7eltsprodm7b -f /copyshrd/data/restore/script/V013__M7P-5664_cleanup_trade_history.sql -A -F "","" -o /copyshrd/data/restore/script/V013__M7P-5664_cleanup_trade_history.csv*
executed under 1 minute

shrink down from 1936 MB
{code:java}
m7eltsprodm7b=# \dt+ cx_111_trade_history
                                 List of relations
    Schema     |         Name         | Type  |    Owner     |  Size  | Description
---------------+----------------------+-------+--------------+--------+-------------
 m7eltsprodm7b | cx_111_trade_history | table | enterprisedb | 784 MB |
{code}




","04/Mar/20 14:35;cs687;I found also no differences with the indices after executing the script, it´s looking the same like it was before.
{code:java}
m7eltsprodm7b=# select * from pg_indexes where tablename in ('cx_101_order_history', 'cx_111_trade_history', 'cx_296_session_history');
  schemaname   |       tablename        |         indexname         | tablespace |                                                               indexdef
---------------+------------------------+---------------------------+------------+---------------------------------------------------------------------------------------------------------------------------------------
 m7eltsprodm7b | cx_111_trade_history   | idx111_002                |            | CREATE INDEX idx111_002 ON cx_111_trade_history USING btree (contract_id, order_id_buy, order_id_sell, action)
 m7eltsprodm7b | cx_111_trade_history   | idx111_001                |            | CREATE INDEX idx111_001 ON cx_111_trade_history USING btree (last_update_time)
 m7eltsprodm7b | cx_111_trade_history   | cx_111_trade_history_pkey |            | CREATE UNIQUE INDEX cx_111_trade_history_pkey ON cx_111_trade_history USING btree (trade_id, rev)
 m7eltsprodm7b | cx_296_session_history | idx296_001                |            | CREATE INDEX idx296_001 ON cx_296_session_history USING btree (last_modified_date)
 m7eltsprodm7b | cx_101_order_history   | idx101_002                |            | CREATE INDEX idx101_002 ON cx_101_order_history USING btree (last_update_time)
 m7eltsprodm7b | cx_101_order_history   | idx101_001                |            | CREATE INDEX idx101_001 ON cx_101_order_history USING btree (revtype, last_update_time, balancing_group_eic, order_type_code, action)
 m7eltsprodm7b | cx_101_order_history   | cx_101_order_history_pkey |            | CREATE UNIQUE INDEX cx_101_order_history_pkey ON cx_101_order_history USING btree (order_id, rev)
(7 rows)
{code}

The same for sequences
{code:java}
m7eltsprodm7b=# select * from information_schema.sequences;
 sequence_catalog | sequence_schema |               sequence_name                | data_type | numeric_precision | numeric_precision_radix | numeric_scale | start_value | minimum_value |    maximum_value    | increment | cycle_option
------------------+-----------------+--------------------------------------------+-----------+-------------------+-------------------------+---------------+-------------+---------------+---------------------+-----------+--------------
 m7eltsprodm7b    | sys             | plsql_profiler_runid                       | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | sys             | snapshot_num_seq                           | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_213_contract_name_format_history_id_seq | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_119_settlement_history_seq              | bigint    |                64 |                       2 |             0 | 193530258   | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_410_trading_phase_trading_phase_id_seq  | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | hibernate_sequence                         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | hibernate_sequence_v42                     | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_268_risk_management_id_seq              | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_212_contract_name_format_id_seq         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | cx_103_quote_request_id_seq                | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7eltsprodm7b    | m7eltsprodm7b   | envers_sequence                            | bigint    |                64 |                       2 |             0 | 1           | -2147483648   | 9223372036854775807 | 1         | NO
(11 rows)

{code}

","04/Mar/20 14:36;cs687;[~oy574] and [~dp007] can please also validate it? from my point of view its looking fine. 

Database has a size of *44 GB*
{code:java}                                                                             List of databases
       Name       |      Owner       | Encoding |   Collate   |    Ctype    |             Access privileges             |  Size   | Tablespace |                Description
------------------+------------------+----------+-------------+-------------+-------------------------------------------+---------+------------+--------------------------------------------
 edb              | enterprisedb     | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/enterprisedb                         +| 9210 kB | pg_default |
                  |                  |          |             |             | enterprisedb=CTc/enterprisedb            +|         |            |
                  |                  |          |             |             | pg_watch2=c/enterprisedb                  |         |            |
 m7eltsprodm7b    | m7eltsprodm7b    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7eltsprodm7b=CTc/m7eltsprodm7b          +| 44 GB   | pg_default |
{code}
","04/Mar/20 16:32;oy574;From my point of view this is looking good, thanks for the tests and thorough and detailed info Steffen!","05/Mar/20 07:57;cs687;[~dp007] also run your wished command *select * from pg_stat_all_tables;*
see attached file. 

I will close the ticket. ","05/Mar/20 09:37;dp007;Thanks Steff,

There are no _n_dead_tup, n_tup_upd, n_tup_del_ so vacuum would be useless.

I don't see a room for further improvements - keep the ticket closed.",,,,,,,,,,,,,,,,,,,
CATRINA: Onboarding of Groupe E SA to ICS CuTe,M7P-5702,92752,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,tj898,qm925,qm925,03/Mar/20 09:08,24/Mar/20 23:40,16/Sep/21 14:11,16/Mar/20 11:52,,6.8.114,7tops_sprint2,,,,,,,7tops_comm,,,,,,,"Groupe E SA are in the process of developing their SW for connecting to CATRINA. 

Please:
* grant Groupe E SA with access to ICS CuTe
* provide them with the roll-on package (test client, specs, etc.)
* Balancing Group EIC/EAN/GLN Code: 12XGROUPE-E----V

Please provide the details to the clients only after confirmation from Account Management (Simona).",,qm925,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-962,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47433600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx74f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 2,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92752,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 14:27;tj898;Hello, [~qm925] .

We'll proceed with this request. One thing we will need is the Balancing Group to be assigned? Could you please mention it here in the ticket?

Thanks,

Hugo","05/Mar/20 14:32;qm925;Hi [~tj898],

I am still waiting the clients to confirm the BG. I will update it asap.

Best regards,
Simona","10/Mar/20 09:03;qm925;Hi [~tj898], 

I updated the BG in the description.
The contract has been sign so when you complete the setup, we can provide the information to the clients.

Let me know if you need something else.

Thanks.

Best regards,
Simona","16/Mar/20 09:26;qm925;Hi [~tj898],

Please provide the roll-om package to alexandre.gal@groupe-e.ch

Thank you.

Best regards,
Simona","16/Mar/20 11:52;tj898;Onboarding package and user details sent to the mentioned email address.

 ",,,,,,,,,,,,,,,,,,,,,,,
ICS: Upgrade of ICS CuTe for DST Tests ,M7P-5700,92749,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,qm925,qm925,03/Mar/20 08:49,18/Mar/20 13:26,16/Sep/21 14:11,09/Mar/20 09:05,,6.8.110,7tops_sprint2,,,,,,,7tops_comm,,,,,,,"Please provide information:
* what is necessary to be done so ICS CuTe is suitable for performing DST tests
* what will be the related efforts on our side",,iu252,qm925,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7ACM-983,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48211200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx747:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92749,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/20 12:18;iu252;Steps for DST test (EPEX CUTE and ICSC CUTE):


1. stop RabbitMQ
2. stop applications
3. run db dump on epex and ocsc db's ( to be able to to restore the data condition before the DST tests)
4. configure ntp server on one node (e.g. m7epexcutem7b1)

                - [root@m7epexcutem7b1 ~]# timedatectl set-ntp no

                - vi /etc/ntp.conf

                                
{noformat}
                                restrict default kod nomodify notrap nopeer noquery

                                restrict -6 default kod nomodify notrap nopeer noquery 

                                restrict 127.0.0.1

                                restrict -6 ::1
 

                                #server 193.29.68.12

                                #server 193.29.68.32

                                server 10.139.59.200

 

                                server  127.127.1.0     # local clock

                                #fudge   127.127.1.0 stratum 10

                                fudge   127.127.1.0 stratum 1

 

                                driftfile /var/lib/ntp/drift

 

                                keys /etc/ntp/keys

{noformat}

 

[root@m7epexcutem7b1 ~]#

                - [root@m7epexcutem7b1 ~]# timedatectl set-time ""2020-03-12 01:16""

                - [root@m7epexcutem7b1 ~]# timedatectl set-ntp yes

                - [root@m7epexcutem7b1 ~]# date

                - Thu Mar 12 01:16:11 CET 2020

5. configure ntp-clients

                [root@m7epexcutem7b2 ~]# systemctl stop ntpd

                vi /etc/ntp.conf

                                
{noformat}
restrict default kod nomodify notrap nopeer noquery

                                restrict -6 default kod nomodify notrap nopeer noquery

 

                                restrict 127.0.0.1

                                restrict -6 ::1

 

                                #server 193.29.68.12

                                #server 193.29.68.32

                                server 10.139.59.200
 

                                server  127.127.1.0     # local clock

                                fudge   127.127.1.0 stratum 10

 

                                driftfile /var/lib/ntp/drift

 

                                keys /etc/ntp/keys

{noformat}

                [root@m7epexcutem7b2 ~]# ntpdate 10.139.59.200 (ip-addres of ntp server)

                12 Mar 01:18:59 ntpdate[22102]: step time server 10.139.59.200 offset 647891.302981 sec

                [root@m7epexcutem7b2 ~]# systemctl start ntpd

                [root@m7epexcutem7b2 ~]# date

                Thu Mar 12 01:19:09 CET 2020

                [root@m7epexcutem7b2 ~]# ntpq -p

                                remote           refid      st t when poll reach   delay   offset  jitter

                ==============================================================================

                m7epexcutem7b2 LOCAL(0)         2 u   10   64    1    0.460    0.020   0.000

                *LOCAL(0)        .LOCL.          10 l    9   64    1    0.000    0.000   0.000

                

6. rm journalfiles
7. truncate index table
8. start envs","06/Mar/20 12:18;iu252;Time estimation: 2 hours","06/Mar/20 12:32;iu252;[~qm925] please claarify with the customer when DST test should be done and create a SERVICE ticket for DST test.","06/Mar/20 13:03;qm925;[~iu252] could you please tell me if with the current infrastructure the ICS CuTe is capable to carry out DST tests or do we need to upgrade/change the infrastructure?

Thanks ","06/Mar/20 13:32;iu252;[~qm925], DST test is just time shifting into the future.
From my point of view we don't need to change/upgrade the infrastructure.
","06/Mar/20 13:44;qm925;Thank you, [~iu252], this is what I needed to know.
The ticket can be closed.",,,,,,,,,,,,,,,,,,,,,,
Huge Journal times during stability tests (glusterFS) 2nd round,M7P-5687,92721,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pw231,rehapav,rehapav,02/Mar/20 14:48,19/May/21 14:32,16/Sep/21 14:11,12/Mar/20 14:55,,6.9.85,7tops_sprint2,,,,,,31/Jan/20 00:00,M7PRODOPS,,,,,,,"h4. Original Problem

while monitoring our stability tests on shrd/SYT1, we spotted some huge processing times (>1s).
 Further analyses showed that some events are spending in journal quite some time.
 It looks like appending a file on glusterFS is blocked every 10-20 minutes.
h5. Examples of problematic events :
 - 2020-01-28 13:26:55.233 - OrdrModify - 1194 ms in journaler
 - 2020-01-28 13:47:31.357 - OrdrModify - 962ms in journaler
 - 2020-01-28 14:04:40.985 - OrdrModify - 989ms in journaler

h5. Normal Processing Times

Normally, max processing times are around 70ms so these are big peaks. See 
 [https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1580214198946&to=1580216778725&var-host=m7shrdsyt1apa1%20-%20tomcat%20-%20m7_shrd_syt1&var-client=shrd&var-client_env=syt1&var-group=All&var-interval=$__auto_interval_interval&var-exchangeId=EPEX&fullscreen&panelId=3]
h4. Acceptance Criteria

Our SLA for 99.5% is 500ms. We should make sure that the processing times are below that if nothing extraordinary is going on.
 Please,
 - ""remove peaks"" option to be discussed with [~pn508]
 - find the root cause (and fix) or
 - suggest an ""improvement that might help"". It is easy for dev team to test any configuration change shrd/syt1.

TODO:
* test lowering size to 32MB and 16 MB or smaller
* create ticket to Redhat 
* create ticket to the network guys
* test the results if processing times are bellow 500 ms

 

*Outcome of techops analysis* TECHLOG-3149:

The final opinion based on executed experiments:
 * currently set up of GlusterFS server used in ""ENERGY"" infrastructure gives reasonable performance
 * after checking the possible modifications of GlusterFS server parameters, there was no huge difference in discovered reaction time in test operations
 * there were created additional types of network disk resources to run comparison in disk operation reactions
 * native NFS server model presented except only one result comparable values of tested reaction times. The only big difference was recognized for reading data from such a type of network disk. It is necessary to admit, this parameter is not so important due the object of our interest in matter of disk operations reaction time.
 * GlusterFS based network disk resource created from fast ""NVME"" disks also did not provide improvement in time of reaction tests
 * all test presented the fact, decreasing the size of processed block of data has relevant impact on the value of reaction time
 * according to previous points, it is very obvious, we are unable to reach better reaction times on site of network disk resources. It can be (without guaranty) consequence of used network infrastructure, hypervisor management, or the file creation method, etc.
 * currently the best and fast implementable solution looks like resizing the ""journal"" files size to value of 32MB, or even less
 * it is of course possible, there is another technological solution to solve this problem, but in that case, it is necessary to decide to dedicate necessary personal, time and financial resources

 

 

 ",,fp407,op211,pw231,rehapav,,,,,,,,,,,,,,,,TECHLOG-3149,,,,,,,,,,,,,,,,,,,,"11/Mar/20 10:14;pw231;image-2020-03-11-10-14-16-360.png;https://jira.deutsche-boerse.com/secure/attachment/81340/image-2020-03-11-10-14-16-360.png","11/Mar/20 10:39;pw231;image-2020-03-11-10-39-14-497.png;https://jira.deutsche-boerse.com/secure/attachment/81343/image-2020-03-11-10-39-14-497.png","06/Mar/20 10:59;pw231;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/81171/screenshot-1.png",,,,,,,,,,,,,sw455,,,,,,,,"- no changes, only analyses and tests",,,,,,,,,,,,,,,,,,,,,,,,47692800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5430,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx127:",9223372036854775807,,,,Yes,,,,,,,,,,,,,,,,,,Schmetterling Sprint 88,Schmetterling Sprint 89,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,"{""issueId"":92721,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,develop,master,true,"04/Mar/20 14:19;fp407;Just an explicit reminder:
 * Do not forget to create a subtask for 7tops regarding update of settings & entring those tickets to redhat & network team.
 * The investment in this task also accounts for an investigation to find the reason for glusterfs (new) having worse performance than nfs (old). Kamil (Mag7) can provide more details.","04/Mar/20 16:51;rehapav;And from a pure delivery perspective, I need a decision

Are we ready to go as it is with 6.8.118 on ELTS PROD with PatroniDB or not?","06/Mar/20 11:01;pw231;h4. Problem
- journal times are still  too high on syt1 (see the attached screenshot)
- journal times are ok when load is lower
- it looks like GlusterFs cannot handle the expected load

 !image-2020-03-11-10-39-14-497.png! 

h4. Possible Solutions
we should try :
- smaller data files; if not succesfull then
- to improve journaler to improve batching 
- to reconfigure glusterfs 

h4. Workaround
until then, we might consider not to use glsuter fs in elts prod and stick with journal without replication.
this has risks

h4. Risk
Patroni uses async replication which means when the DB dies, some transactions can be lost.
And if also the journal is lost (e.g. DC disaster), we have broadcasted some events that will not be part of the state after failover. ","09/Mar/20 09:55;pw231;h4. Changes
- dataBlockSize configurable and reduced to 32MB  : https://github.deutsche-boerse.de/dev/m7.m7/pull/6068
-* *STATUS*: not deployed yet (blokced by other tests)
- syt1 VMs migrated to new (faster) ESX cluster.
-* *STATUS*: after that - massive journal-time improvement
 !image-2020-03-11-10-14-16-360.png! ","10/Mar/20 10:03;pw231;idea : we might not need to journal XBID events. This should massivly reduce amount of events to journal and ergo solve the problem...","11/Mar/20 11:07;op211;As discussed with Milos on the phone and proposed by [~cv179]: One option would be, to start with synchronous replication and NFS. This could be the starting point for a step-wise approach towards the final setup:

* Step 1: Change to Patroni; Sync replication + NFS; prepare GlusterFS in PROD but not use it
* Step 2: Sync replication + GlusterFS
* Step 3: Async replication + GlusterFS

All the steps above should be tested in SysTest1, with the *same software version* and *no other infrastructure* change in between.","11/Mar/20 11:52;pw231;h3. Root cause
current hypothesis is that it is the network between the VM and the patroni SSDs.

h3. Facts
h4. SYT1
- *on old syt1* ESX cluster, the network cards was:
-* shared by MANY vms (possibly including amqp-borkers and/or load-runners) and 
-* it is *1Gb only*
-* LOAD: 2500 events/min (elts prod like)
-* RESULT: journal time peaks up to *2secs*
- after we migrated syt1 to new ESX server,
-* there is much less VMs on the server
-* HW is more powerful
-* and networkd card is *10Gb*
-* core's VM shares HW with loadrunner and amq3 VM
-* LOAD: 5k events/min (2x elts prod like)
-* *RESULT*: only small peaks of *200ms*
- after failover (master now in HAU):
-* core's master is on a machine that is NOT shared with load-runners or rabbitmq server
-* LOAD: 5k events/min (2x elts prod like)
-* *RESULT*: journal times even lower - peaks only around *25ms*


NO other changes made: same m7 version, same journal configuration.

h4. ELTS Prod
- it has 10Gb card
- HW is less occupied (fewer VMs)
- HW is as fast as the old SYT1's ","12/Mar/20 14:43;pw231;h3. Conclusion
- replicated journals via GlusterFS are fast enough 
-* even on doubled production load
- the reason for the journal delays/slow peaks was the NETWORK 
-* after migrating to 10Gb/s (like in ELTS PROD) - no issues
- there is no need to change the patroni setup
-* with GlusterFS - we have the required consistency, and we are fast enough
-* with full async replication, we have a fast persistence

h4. Follow ups
- it seems that VM distribution (across individiaul ESX servers) has significant impact on persister/journal/message latencies
-* [~wm282] to come up with suggestions
- [~cv179] wanted to perform extra test
-* compare network speed between elts-prod and syt1
-* e.g. by transfer few files between cor-slave and patroni-db
- don't journal data that are not required for reply - [~pw231] to discuss on Dev CoP

All of these followups shall be handled outside this jira.",,,,,,,,,,,,,,,,,,,,
Consider validating Host header (parent issue),M7P-5686,92707,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,HO764,HO764,02/Mar/20 13:11,08/Sep/21 13:47,16/Sep/21 14:11,07/Sep/21 16:27,,6.12.132,7tops_sprint125,,,apache,,,,7tops,XL,,,,,,"Currently, we do not validate Host header and use it often for redirects. Consider allowing only correct Host header and reject the request otherwise.

This behavior has been reported on M7T, -M7C,- and profile server.

 *M7C part moved to XBID (XP-4568)*

Pen test report references:

Security assessment report of M7 EPEX V8 (6.2) [https://vmt.deutsche-boerse.de/browse/PT-1459] - *Priority* None
Security assessment report of ComTrader, the profile server and the Trading Module PMI V12 (7.2) [https://vmt.deutsche-boerse.de/browse/PT-1514] *Priority* Medium",,HO764,pd122,sJ194,vp223,,,,,,,,,,,,,,ICS-43,,,ICS-37,ICS-32,M7P-5030,M7P-5067,,M7P-6434,M7P-6576,M7P-6575,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,changes deployed to all M7T envs,,,,,,,,,,,,,,,,,,,,,,,,691200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-8368,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmwvz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92707,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-5686,,true,"11/Mar/20 11:04;vp223;TBD with CIROSEC","24/Mar/20 15:09;HO764;Result: we should probably implement this whitelisting, just to be sure.","15/Jun/20 16:15;sJ194;the task needs to be split into smaller pieces ","15/Jul/20 13:57;pd122;work to be traced in 3 tasks this one has been split into","07/Sep/21 16:26;pd122;this has been completed - changes (default catch-all and monitoring virtual hosts) deployed to all M7T environments",,,,,,,,,,,,,,,,,,,,,,,
"Decommission old VM ""m7intepg1""",M7P-5685,92705,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,02/Mar/20 12:46,08/Apr/20 09:54,16/Sep/21 14:11,07/Apr/20 14:39,,6.10.7,6.9.98,7tops_sprint4,,,,,,M7PRODOPS,,,,,,,"the virtual machine ""m7intepg1"" is not used anymore. 
During the VM migration to our own ESX Cluster [~wm282] detected this machine.

[~fh971] checked also the situation and we agreed on that, that this old machine is not used anymore and can be decommissioned ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45446400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx4dz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92705,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/20 14:39;cs687;can be closed [~wm282] will handle that ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove some default tomcat / apache content,M7P-5684,92704,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,op211,HO764,HO764,02/Mar/20 12:37,01/Jun/21 17:15,16/Sep/21 14:11,15/Feb/21 14:38,,7tops_sprint111,,,,uknown,,,,7tops,XL,,,,,,"Some default content is available.

 

For M7C:

[https://cute1.ics.m7c.deutsche-boerse.com/icons/] (probably already restricted, but check anyway, maybe only listing is disabled)

Standard error pages, e.g.: [https://cute1.ics.m7c.deutsche-boerse.com/error/HTTP_NOT_FOUND.html.var] 

[https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/] (requires auth)

[https://cute1.ics.m7c.deutsche-boerse.com/m7c/..;/examples/] 

 

For profile server (requires auth):

Standard error pages, e.g.: [https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/ssss] (already done in M7P-5060)

[https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/examples/]

[https://exte1.profiles.m7.deutsche-boerse.com:60100/shrd-apa-dst1/..;/docs/]

 

We should restrict the access to these resources.

 

Pen test report reference:

Security assessment report of M7C V8+V9 (5.2.6, 5.2.7)
 Security assessment report of ComTrader, the profile server and the Trading Module PMI P4 V4+V6 (5.1.2, 5.1.4)",,cs687,HO764,ne232,op211,sJ194,vp223,,,,,,,,,,,,,,,M7P-5062,M7P-4969,M7P-5060,M7P-4970,M7P-5071,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,See below.,,,,,,,,,,,,,,,,,,,,,,,,18316800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5259,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzmwwf:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92704,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/20 07:11;vp223;https://vmt.deutsche-boerse.de/browse/PT-1492 - medium
https://vmt.deutsche-boerse.de/browse/PT-1493 - medium
https://vmt.deutsche-boerse.de/browse/PT-1490 - medium
https://vmt.deutsche-boerse.de/browse/PT-1512 - medium
https://vmt.deutsche-boerse.de/browse/PT-1510 - medium
","15/Jun/20 16:10;sJ194;[~pd122] and [~cs687] pls discuss this topic and try to break it to smaller tasks. ","30/Jun/20 13:47;cs687;[~pd122] [~sJ194] created SPIKE tickets to break it down in smaller tasks. ","15/Feb/21 14:38;op211;Done.",,,,,,,,,,,,,,,,,,,,,,,,
Install Prometheus Plugin on SYT1,M7P-5671,92643,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,sw455,sw455,27/Feb/20 13:11,22/Apr/20 15:06,16/Sep/21 14:11,21/Apr/20 10:35,,6.10.15,7tops_Sprint5,,,,,,,7tops_comm,,,,,,,"Task:
 * Install and configure Prometheus rabbitmq plug-in in SYT1
 * Share in next product review that Prometheus is ready in SYT1 and next steps for analysis of Prometheus as a replacement for RabbitMQ Management Plug in will be refined in next 7TOPS refinement

 ",,hw120,iu252,pw231,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Mar/20 01:27;hw120;InfluxDB_ingestion_rate.PNG;https://jira.deutsche-boerse.com/secure/attachment/81151/InfluxDB_ingestion_rate.PNG","10/Mar/20 15:23;iu252;promethius1.txt;https://jira.deutsche-boerse.com/secure/attachment/81309/promethius1.txt","19/Mar/20 13:07;iu252;promethius5.txt;https://jira.deutsche-boerse.com/secure/attachment/81700/promethius5.txt",,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44323200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5343,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx73z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 2,7tops Sprint 3,7tops Sprint 4,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92643,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"04/Mar/20 15:29;hw120;Prometheus rabbitmq plug-in was designed to be used by Prometheus monitoring, while we are using TICK stack. Main difference is in metric data format and pull vs push based monitoring system.

I believe it might be doable, but we will need to use one plugin/service in between to do the translation.

Probably this plugin could consume metrics provided by prometheus rabbitmq plugin and then translate it to influxdb format...

https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus

Question is if it is worth the effort, is it collecting metrics which existing plugin isn't?

 

 ","05/Mar/20 13:25;iu252;Enabled Prometheus on amq1:

{noformat}
[rabbitmq@m7shrdsyt1amq1 shrd]$ rabbitmq-plugins enable rabbitmq_prometheus
Enabling plugins on node shrd-syt1-apa-amq1@m7shrdsyt1amq1:
rabbitmq_prometheus
The following plugins have been configured:
  rabbitmq_auth_backend_cache
  rabbitmq_auth_backend_ldap
  rabbitmq_event_exchange
  rabbitmq_management
  rabbitmq_management_agent
  rabbitmq_prometheus
  rabbitmq_tracing
  rabbitmq_web_dispatch
Applying plugin configuration to shrd-syt1-apa-amq1@m7shrdsyt1amq1...
The following plugins have been enabled:
  rabbitmq_prometheusstarted 1 plugins.
[rabbitmq@m7shrdsyt1amq1 shrd]$
{noformat}



{noformat}
Notice that RabbitMQ exposes the metrics on a dedicated TCP port, 15692 by Default.

[rabbitmq@m7shrdsyt1amq1 include]$ curl -s localhost:15692/metrics | head -n 3
# TYPE erlang_mnesia_held_locks gauge
# HELP erlang_mnesia_held_locks Number of held locks.
erlang_mnesia_held_locks 0
[rabbitmq@m7shrdsyt1amq1 include]$
{noformat}
","05/Mar/20 16:25;iu252;Changed telegraf config /etc/telegraf/telegraf.conf:

{noformat}
# Read metrics from one or many prometheus clients
[[inputs.prometheus]]
#   ## An array of urls to scrape metrics from.
 urls = [""http://localhost:15692/metrics""]
{noformat}


Restarted telegraf (systemctl restart telegraf).
Logs Output ([root@m7shrdsyt1amq1 bin]# journalctl -u telegraf)

{noformat}
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Starting Telegraf 1.13.2
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Loaded inputs: mem diskio net processes dns_query cpu system kernel swap ping prometheus disk rabbitmq
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Loaded aggregators:
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Loaded processors:
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Loaded outputs: influxdb
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! Tags enabled: client=shrd client_environment=syt1 datacenter=equinix group=rabbitmq host=m7shrdsyt1amq1 host_grou
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z I! [agent] Config: Interval:30s, Quiet:false, Hostname:""m7shrdsyt1amq1"", Flush Interval:30s
Mar 05 14:57:39 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:57:39Z W! [inputs.prometheus] Use of deprecated configuration: 'metric_version = 1'; please update to 'metric_version = 2'
Mar 05 14:58:02 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:58:02Z W! [outputs.influxdb] Metric buffer overflow; 3451 metrics have been dropped
Mar 05 14:58:31 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:58:31Z W! [outputs.influxdb] Metric buffer overflow; 7043 metrics have been dropped
Mar 05 14:58:31 m7shrdsyt1amq1 telegraf[127697]: 2020-03-05T13:58:31Z W! [outputs.influxdb] Metric buffer overflow; 424 metrics have been dropped
{noformat}
","05/Mar/20 16:28;iu252;There are to many metrics

{noformat}
[root@m7shrdsyt1amq1 ~]# curl http://localhost:15692/metrics |wc -l
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  816k  100  816k    0     0  1420k      0 --:--:-- --:--:-- --:--:-- 1426k
9271

{noformat}

We have to contact developers to identify all metrics we need.
Here is the list of Prometheus metrics:
https://github.com/rabbitmq/rabbitmq-prometheus/blob/master/metrics.md","05/Mar/20 16:37;pw231;[~hw120]: there should be lot of new metrics, e.g. erlang vm details or (hopefully) some extra queue data.
But mainly, using Prometheus (plugin) is currently THE recommended way and might be soon enough the only supported way of monitoring the cluster.

[~iu252] : once telegraf has the prometheus plugin installed (and the metrics flow to influxdb), we might want to try some of the cool predefined dashboards. see this article : https://www.rabbitmq.com/prometheus.html","05/Mar/20 21:42;hw120;[~pw231] We must discuss the possibilities. Yes, the new plugin looks nice, but we must test the performance impact on rabbitmq and also on influxdb.

Just a few points to consider before we continue.

Deploying it on all rabbitmq instances would exponentially increase the number of metrics we collect, see attached screenshot what did only one rabbitmq host.

But what would be the number of metrics from elts prod during peak load or non-standard situations like are being solved by auto-healing?

Would you like to use Prometheus monitoring also? This would be a huge change and it would require a lot of man-days.

Do you know the difference between push vs pull based monitoring? It would mean opening a lot of firewall connections which are not even allowed in this company.

 ","09/Mar/20 11:35;pw231;[~hw120], [~iu252]:

h4. Problem
syt1: too much data sent from rabbitmq vms to influx

h4. Solution
do not include metrics for individual connections/channels/queues.
i.e. exclude:
- rabbitmq_connection_*
- rabbitmq_channel_*
- rabbitmq_queue_*

After that, the size of data sent to influx should be similar to current Rabbitmq moitoring....","10/Mar/20 13:07;iu252;Did some tests with/without Prometheus plugin:

1. disable Prometheus plugin  and check the metrics

{noformat}
# Read metrics from one or many prometheus clients
#[[inputs.prometheus]]
#   ## An array of urls to scrape metrics from.
# urls = [""http://localhost:15692/metrics""]
 # Don't collect prometheus data for
 #namedrop = [""rabbitmq_queue_*"",""rabbitmq_channel_*"",""rabbitmq_connection_*""]
{noformat}
Run telegraf with --test Parameter:
{noformat}
 /usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --test > /tmp/promethius3.txt
2020-03-10T11:39:36Z I! Starting Telegraf 1.13.2
[root@m7shrdsyt1amq1 ~]# ls -l /tmp/promethius*
-rw-r--r-- 1 root root   25475 Mar 10 12:39 /tmp/promethius3.txt
{noformat}

2. enable Prometheus plugin without drop metrics:

{noformat}
# Read metrics from one or many prometheus clients
[[inputs.prometheus]]
#   ## An array of urls to scrape metrics from.
 urls = [""http://localhost:15692/metrics""]
 # Don't collect prometheus data for
 #namedrop = [""rabbitmq_queue_*"",""rabbitmq_channel_*"",""rabbitmq_connection_*""]
{noformat}
Run telegraf with --test Parameter:

{noformat}
/usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --test > /tmp/promethius2.txt
2020-03-10T11:39:36Z I! Starting Telegraf 1.13.2
[root@m7shrdsyt1amq1 ~]# ls -l /tmp/promethius*
-rw-r--r-- 1 root root 2734718 Mar 10 12:25 /tmp/promethius2.txt
{noformat}

3. enable Prometheus plugin with drop metrics:

{noformat}
# Read metrics from one or many prometheus clients
[[inputs.prometheus]]
#   ## An array of urls to scrape metrics from.
 urls = [""http://localhost:15692/metrics""]
 # Don't collect prometheus data for
 namedrop = [""rabbitmq_queue_*"",""rabbitmq_channel_*"",""rabbitmq_connection_*""]
{noformat}
Run telegraf with --test Parameter:

{noformat}
/usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --test > /tmp/promethius1.txt
2020-03-10T11:39:36Z I! Starting Telegraf 1.13.2
[root@m7shrdsyt1amq1 ~]# ls -l /tmp/promethius*
-rw-r--r-- 1 root root  632146 Mar 10 12:19 /tmp/promethius1.txt
{noformat}

Summary: 
{noformat}
[root@m7shrdsyt1amq1 ~]# ls -l /tmp/promethius*
-rw-r--r-- 1 root root  632146 Mar 10 12:19 /tmp/promethius1.txt     - with Prometheus pulgin and with drop metric for chanel-, queue- and Connection-metrics
-rw-r--r-- 1 root root 2734718 Mar 10 12:25 /tmp/promethius2.txt    - with Prometheus plugin, without any drops
-rw-r--r-- 1 root root   25475 Mar 10 12:39 /tmp/promethius3.txt      - without Prometheus plugin
[root@m7shrdsyt1amq1 ~]#
{noformat}
","10/Mar/20 15:24;iu252;[~pw231] after we dropped rabbitmq_queue_*, rabbitmq_channel_* ,""rabbitmq_connection_* metrics, there are still too much.
Here is a dump of metrics:  [^promethius1.txt] .
Imagine sending that much from all rabbits in all environments every 30s!

We need to reduce more metrics.","12/Mar/20 10:02;iu252;[~pw231] any idea which metrics we can drop?","18/Mar/20 11:24;pw231;[~iu252]: I see lot's of data from these metrics:
- rabbitmq_consumer_prefetch - seems like data for individual consumers - too much consumers, CAN BE OMITTED
-  erlang_vm_allocators - seems like detailed info about erlang vm allocation - NOT NEEDED

Both of the metrics above can be filtered out and we should be fine afterwards.","19/Mar/20 13:07;iu252;Disabled rabbitmq in telegraf:

{noformat}
[root@m7shrdsyt1amq1 telegraf.d]# more m7t-shrd-syt1-apa-amq1.conf
#############################################################################
#   Group RabbitMQ                                                          #
#############################################################################
#[[inputs.rabbitmq]]
#  url=""http://127.0.0.1:52700""
#  username = ""monitor""
#  password = ""test01""
#  client_timeout = ""15s""
#  header_timeout = ""15s""

#  queues = [""m7.request""]
#  exchanges = [""m7.broadcastExchange""]
#  [inputs.rabbitmq.tagdrop]
#    queue = [""amq.gen-*""]
#  [inputs.rabbitmq.tags]
#    module = ""m7_shrd_syt1""
#    product = ""m7t""
#    client = ""shrd""
#    client_environment = ""syt1""
#    host_group_module=""m7shrdsyt1amq1 - rabbitmq - m7_shrd_syt1""
#    instance = ""apa-amq1""
#    datacenter = ""equinix""
#############################################################################
#   End of Group RabbitMQ                                                   #
#############################################################################
[root@m7shrdsyt1amq1 telegraf.d]#
{noformat}

Enabled Prometheus with additional filters:

{noformat}
[root@m7shrdsyt1amq1 telegraf]# more telegraf.conf
.......
# Read metrics from one or many prometheus clients
[[inputs.prometheus]]
#   ## An array of urls to scrape metrics from.
 urls = [""http://localhost:15692/metrics""]
 # Don't collect prometheus data for
 namedrop = [""rabbitmq_queue_*"",""rabbitmq_channel_*"",""rabbitmq_connection_*"",""rabbitmq_consumer_prefetch"",""erlang_vm_allocators""]
 #      queue = [""rabbitmq_queue_*""]
 #      connection = [""rabbitmq_connection_*""]
 #      chanel = [""rabbitmq_channel_*""]
[root@m7shrdsyt1amq1 telegraf]#
{noformat}

Did additional test:

{noformat}
[root@m7shrdsyt1amq1 telegraf.d]#  /usr/bin/telegraf -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --test > /tmp/promethius5.txt
2020-03-19T09:10:02Z I! Starting Telegraf 1.13.2
2020-03-19T09:10:02Z W! [inputs.prometheus] Use of deprecated configuration: 'metric_version = 1'; please update to 'metric_version = 2'
[root@m7shrdsyt1amq1 telegraf.d]# ll /tmp/promethius*
-rw-r--r-- 1 root root  632146 Mar 10 12:19 /tmp/promethius1.txt
-rw-r--r-- 1 root root 2734718 Mar 10 12:25 /tmp/promethius2.txt
-rw-r--r-- 1 root root   25475 Mar 10 12:39 /tmp/promethius3.txt
-rw-r--r-- 1 root root   90499 Mar 19 09:48 /tmp/promethius4.txt
-rw-r--r-- 1 root root   81018 Mar 19 10:10 /tmp/promethius5.txt
[root@m7shrdsyt1amq1 telegraf.d]#
{noformat}

There are a lot of erlang metrics:

{noformat}
[root@m7shrdsyt1amq1 tmp]# grep rabbitmq_ promethius5.txt |wc -l
46
[root@m7shrdsyt1amq1 tmp]# grep erlang_ promethius5.txt |wc -l
157
{noformat}

[~pw231] can you please review erlang metrics. Tahnks.
 [^promethius5.txt] ","19/Mar/20 13:25;pw231;The file has 80kB, we should be able to coop with that amount of data per 30secs and environment ... right [~hw120], [~iu252] ?
Most of the data is generated by the many tags we have ... maybe we could reduce it somehow.","19/Mar/20 14:59;hw120;[~pw231] If you consider remaining metrics as necessary, we should be able to handle that much. I would just have to attach and allocate more space to influxdb instances. We will see in time when we start collecting from more environments, how much additional load will it produce.

The main question now is about the preparation of grafana dashboards, we tried to import prepared one, but it is not possible as it requires prometheus data source which we don't have.

Would you be fine with creating one from the provided metrics? We can possibly prepare it for you if you can specify which graphs would make sense for you.","24/Mar/20 08:26;iu252;[~pw231] I created a new grafana Dashboard (https://grafana.energy.svc.dbgcloud.io/d/0tsoVdIiy/rabbitmq-prometheus). It's a copy from our RabbitMQ.
I modified some graphs (Queues, Consumer, Chanels) for m7shrdsyt1amq1, which show metrics from prometheus plugin.
Unfortunately prometheus plugin collects different metrics as telegraf. It's not possible to create the same graphs using prometheus metrics.
We need your feedback which graphs we should create.
Here again the list of available prometheus metrics: https://github.com/rabbitmq/rabbitmq-prometheus/blob/master/metrics.md
","24/Mar/20 09:31;pw231;[~iu252] : we need at least the graphs we have now. The aim for all this exercise are two:
- less impact on running cluster while collecting metrics (currently the mgmt-plugin seems to be too invasive)
- gather more data, especially, the erlang vm insides... (currently this is not available at all)

I would recommend to try to rewrite the prometheus-fit-dashboards from prometheaus datasource to influx db. it might be easier...","24/Mar/20 14:52;iu252;Created PR: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1683","24/Mar/20 15:30;iu252;Due to the fact that SYT1 is used for stability tests, we switched to ATE3.

Changed https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1683 and merged it after approval.","31/Mar/20 12:25;iu252;I need support from [~hw120].
Unfortunately, he is on vacation for the rest of this week.
","07/Apr/20 08:45;iu252;Limited some duplicates metrics for erlang:

{noformat}
......
 # Don't collect prometheus data for
    namedrop = [""rabbitmq_queue_*"",""rabbitmq_channel_*"",""rabbitmq_connection_*"",""rabbitmq_consumer_prefetch"",""erlang_vm_allocators"",""erlang_vm_msacc_aux_seconds_total"",""erlang_vm_msacc_check_io_seconds_total"",""erlang_vm_msacc_emulator_seconds_total"",""erlang_vm_msacc_gc_seconds_total"",""erlang_vm_msacc_other_seconds_total"",""erlang_vm_msacc_port_seconds_total"",""erlang_vm_msacc_sleep_seconds_total""]
......
{noformat}



{noformat}
[root@m7shrdate3amq1 ~]# grep erlang  v1.out |wc -l
650
[root@m7shrdate3amq1 ~]# grep erlang  v3.out |wc -l
61
{noformat}
","21/Apr/20 09:07;iu252;Created following dashboard with metrics from prometheus plugin:
https://grafana.energy.svc.dbgcloud.io/d/0tsoVdIiy/rabbitmq-prometheus.

Unfortunately prometheus does not provide any metrics for exchanges!!!


With graph ""Queues Details"" i need your support [~pw231]. For me it's not clear which Prometheus metric should be used.


Generaly speaking, i see this task as completed. Prometheus plugin is installed, graphs with new metrics created.","21/Apr/20 10:25;pw231;I agree this jira, as PoC, is completed. 
Now the dev team needs to evaluate if the new plugin can be used everywhere.

I personally would wait for influxb to provide support for the prometheus QL and maybe then the fancy prometheus dashboards could be easily implemented. Only this would provide us with the extra data about erlang VMs. Without that, we would only stress influx db with huge amount of data and not use them.",,,,,,
Slower Report generation on ELTS PROD compared to 6.7,M7P-5670,92640,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,cf948,dp007,dp007,27/Feb/20 12:04,18/Mar/20 13:26,16/Sep/21 14:11,09/Mar/20 14:50,,6.9.81,7tops_sprint2,,,,,,,M7PRODOPS,Reporting_Engine,,,,,,"Admin report generation times comparison:
||Report||6.7 (Tue 25/02)||6.8 (Thu 27/02)||difference||
|TC540|00:16:24|02:55:51|+2h 39m|
|TC810|00:09:44|00:12:05|+2m|
|TC820|00:02:40|00:17:27|+14m|
|TC840|00:00:26|00:00:28|+2s|

For more details I attached the log files.

TC810 6.7: 01:15:00 - 01:24:44 = 00:09:44

TC810 6.8: 01:05:12 - 01:17:17 = 00:12:05

TC820 6.7: 01:24:44 - 01:27:24 = 00:02:40

TC820 6.8: 01:17:17 - 01:34:41 = 00:17:24

TC840 6.7: 01:27:24 - 01:27:50 = 00:00:26

TC840 6.8: 01:34:41 - 01:35:09 = 00:00:28

TC540 6.7: 01:27:50 - 01:44:14 = 00:16:24

TC540 6.8: 01:35:09 - 04:31:00 = 02:55:51",,ax460,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5757,SERVICE-5705,,,,,"27/Feb/20 12:08;dp007;m7t_elts_prod_rep-1_standard_ixe.log;https://jira.deutsche-boerse.com/secure/attachment/80872/m7t_elts_prod_rep-1_standard_ixe.log","27/Feb/20 12:06;dp007;m7t_elts_prod_rep-1_standard_ixe_0_2020-02-25.log;https://jira.deutsche-boerse.com/secure/attachment/80871/m7t_elts_prod_rep-1_standard_ixe_0_2020-02-25.log",,,,,,,,,,,,,,sw455,,,,,,,,"Tested on ELST PROD COPY idx101_001 is not applied unless REV is used in where clause (in proper order https://devcenter.heroku.com/articles/postgresql-indexes#multi-column-indexes ) When rev column introduced into query it starts using index and gets faster.

Martin Komberec (dbg ops) is preparing new version of maintenance SQL with correct index creation, which will run on 10/3/2020 (previous test is not needed we will wait till 10/3 anyway)",,,,,,,,ELTS,,,,,,,,,,,,,,,,48470400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,27/Feb/20 12:04,,[],,,,,,,,,,,M7T,,,,"2|hzn2kv:",9223372036854775807,,,,No,,,,,,,,,,The issue is caused by wring index idx101_001 which contains also column rev. Rev column is not used in reporting engine query. ,,,,,,,,Schmetterling Sprint 87 (PS),X-Men Sprint 88 (PS),,,,,,,,,,,,,,,,,,,,,,,,,--,1.0,,,,,,,,,"{""issueId"":92640,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"27/Feb/20 15:32;ax460;History tables in DB were recreated during deployment on 25/2 see [https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/140/files] I would expect that some of indexes are missing.

 

Note
 # in PROD COPY DB there is index cx_101_order_history in columns (revtype, last_update_time, balancing_group_eic, order_type_code, action) while in [elts/prod/6.8.x/V001__M7P-4658_clanup_history_tables.sql#L30|https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/blob/master/m7coredb/elts/prod/6.8.x/V001__M7P-4658_clanup_history_tables.sql#L30] there is also *rev* column
 # There are columns CX_296_SESSION_HISTORY.disconnected, contractHistory.EXTERNAL_REVISION, contractHistory.PRODUCT_LONG_NAME, orderHistory.USER_CODE, orderHistory.CONTRACT_ID, orderHistory.VERSION used in WHERE or ORDER BY clause but not having an index.

 ","27/Feb/20 16:01;dp007;ELTS PROD:

select * from pg_indexes where tablename in ('cx_101_order_history', 'cx_111_trade_history');
 schemaname | tablename | indexname | tablespace | indexdef
 ---------------++++---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 m7eltsprodm7b | cx_101_order_history | idx101_002 | | CREATE INDEX idx101_002 ON cx_101_order_history USING btree (last_update_time)
 m7eltsprodm7b | cx_101_order_history | idx101_001 | | CREATE INDEX idx101_001 ON cx_101_order_history USING btree (rev, revtype, last_update_time, balancing_group_eic, order_type_code, action)
 m7eltsprodm7b | cx_101_order_history | cx_101_order_history_pkey | | CREATE UNIQUE INDEX cx_101_order_history_pkey ON cx_101_order_history USING btree (order_id, rev)
 m7eltsprodm7b | cx_111_trade_history | idx111_002 | | CREATE INDEX idx111_002 ON cx_111_trade_history USING btree (contract_id, order_id_buy, order_id_sell, action)
 m7eltsprodm7b | cx_111_trade_history | idx111_001 | | CREATE INDEX idx111_001 ON cx_111_trade_history USING btree (last_update_time)
 m7eltsprodm7b | cx_111_trade_history | cx_111_trade_history_pkey | | CREATE UNIQUE INDEX cx_111_trade_history_pkey ON cx_111_trade_history USING btree (trade_id, rev)
 (6 rows)

 

PROD-COPY:

schemaname | tablename | indexname | tablespace | indexdef
 ---------------++++---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
m7eltsprodm7b cx_101_order_history idx101_001 (null) CREATE INDEX idx101_001 ON cx_101_order_history USING btree (revtype, last_update_time, balancing_group_eic, order_type_code, action);
 m7eltsprodm7b cx_101_order_history idx101_002 (null) CREATE INDEX idx101_002 ON cx_101_order_history USING btree (last_update_time)
 m7eltsprodm7b cx_101_order_history cx_101_order_history_pkey (null) CREATE UNIQUE INDEX cx_101_order_history_pkey ON cx_101_order_history USING btree (order_id, rev)
 m7eltsprodm7b cx_111_trade_history idx111_002 (null) CREATE INDEX idx111_002 ON cx_111_trade_history USING btree (contract_id, order_id_buy, order_id_sell, action)
 m7eltsprodm7b cx_111_trade_history idx111_001 (null) CREATE INDEX idx111_001 ON cx_111_trade_history USING btree (last_update_time)
 m7eltsprodm7b cx_111_trade_history cx_111_trade_history_pkey (null) CREATE UNIQUE INDEX cx_111_trade_history_pkey ON cx_111_trade_history USING btree (trade_id, rev)","28/Feb/20 08:44;dp007;The generation times are worse and worse every single day:

20200225 - 26.02. 03:57:41 UTC 
20200226 - 27.02. 04:30:59 UTC
20200227 - 28.02. 05:07:25 UTC","28/Feb/20 11:06;ax460;Discussed with [~dp007], we will wait till monday (on Sunday DB dump will be created) and [~cs687] will deploy this dump to SYT1 and after environment will be up and running
 * stop market
 * drop index idx101_001
 * create index idx101_001
 ** 
{code:java}
CREATE INDEX idx101_001 ON cx_101_order_history USING btree (revtype, last_update_time, balancing_group_eic, order_type_code, action);{code}

 * and messure how long recreation took","02/Mar/20 12:31;ax460;The issue is caused by wring index idx101_001 which contains also column rev. Rev column is not used in reporting engine query. Tested on ELST PROD COPY idx101_001 is not applied unless REV is used in where clause (in proper order [https://devcenter.heroku.com/articles/postgresql-indexes#multi-column-indexes] ) When rev column introduced into query it starts using index and gets faster.

[~dp007] is preparing new version of maintenance SQL with correct index creation, which will run on 10/3/2020 (previous test is not needed we will wait till 10/3 anyway)

 

 ","04/Mar/20 09:13;dp007;Pull request prepared: [https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/152]
Index _idx101_001_ fixed in [https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/blob/c9f1533d9bc56383df323deb6cecf0ec6f03ce66/m7coredb/elts/prod/6.8.x/V009__M7P-5664_cleanup_order_history.sql]",,,,,,,,,,,,,,,,,,,,,,
RabbitMQ Cluster Management Procedures,M7P-5669,92637,,Epic,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,sw455,sw455,sw455,27/Feb/20 11:48,30/Jul/20 14:19,16/Sep/21 14:11,28/Jul/20 10:42,,7tops_sprint12,,,,ansible,infrastructure,,,M7PRODOPS,,,,,,,"*User story:* DEVOPS needs to have an idempotent way of making all potentially required rabbitMQ cluster changes

 

""Enhance Ansible Playbooks for RabbitMQ Cluster Changes""
""Ensure idempotent results for automated deployment, tear down, and all other cluster modifications""

 

*Task:*
 * Create and Operational Playbook for RabbitMQ cluster changes (M7P Backlog). The playbook should consider all potential rabbitmq cluster actions we expect we might need (set up of full cluster from scratch, removing single/multiple node(s), adding single/multiple node(s), tearing down full cluster, etc. etc.)
 * Review playbook with development
 * Test all playbook actions several times in multiple pre-prod and prod environments to ensure we are confident to make rmq changes with clear results",,,,,,,,,,,,,,,,,,,,,M7P-5489,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,35856000,,,dm700,lw641,ox626,rehapav,sw455,,,,,RMQ Cluster Automation,To Do,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx6bb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92637,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"28/Jul/20 10:42;sw455;The only subtask in this 'epic' was completed - see M7P-5489",,,,,,,,,,,,,,,,,,,,,,,,,,,
DBVisualizer credentials,M7P-5665,92627,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,wn626,wn626,27/Feb/20 10:24,30/Jul/20 14:19,16/Sep/21 14:11,28/Jul/20 15:08,,6.10.157,7tops_sprint12,,,,,,,M7PRODOPS,,,,,,,"We are using DBVisualizer for connection to databases, but recently connection details for some of the DBs have changed. We need to create new connections in DBVisualizer and share it with the team",,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5649,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,DB connections sent to all team members via email,,,,,,,,,,,,,,,,,,,,,,,,47692800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwz8n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92627,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 10:59;wn626;Attached file with all connection details. Missing connections are XBID PROD copy and M7T PROD DBs",,,,,,,,,,,,,,,,,,,,,,,,,,,
ELTS PROD 25/2 - dbcleanup script update & execution time analysis,M7P-5664,92618,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Cannot Reproduce,cs687,rehapav,rehapav,27/Feb/20 09:22,04/Mar/20 15:12,16/Sep/21 14:11,03/Mar/20 14:17,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,"During ELTS PROD deployment on 25/2 we had to interrupt dbcleanup script due to long duration

 

Todo:
 * get proddb backup from prior of 25/2 (prior the date when we migrated to 6.8)
 * let BIZOPs gather trade and order history data for last 30 days (was erased by cleanup script in actual prod) in order to be able generate SLA reports for 02/2020
 * run following  tests
 ** test 1 - run same command as was used during ELTS PROD deployment
 ***  psql -p 20106 -d m7eltsprodm7b -f /tmp/SERVICE-5092/V001__M7P-4658_clanup_history_tables.sql -A -F "","" -o /tmp/SERVICE-5092/V001__M7P-4658_clanup_history_tables.csv 
 *** measure execution time, confirm that this was the reason for huge execuiton time 
 ** test 2 - run correct script with expected command 
 *** psql -p 20106 -U m7eltsprodm7b -d m7eltsprodm7b -W -f /tmp/cleanup_6.8.sql
 *** measure execution time and confirm it finished within 10 minutes
 * alter the script in order to keep order and trade history in the dump for 40 days & also split the cleanup script into several small scripts for each individual table 
 ** run the altered script and measure time of execution
 ** perform dbdump to check size of dumped datbaase (with original cleanup history of 10 days, size was cca 15 GB)
 *** expected is that altered script will generate bigger database
 *** provide patronidb migration time with database created by altered script

 ",,cs687,rehapav,,,,,,,,,,,,,,,,,,M7P-5655,,,,,,,,,,,,,,SERVICE-5478,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,48470400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,26/Feb/20 09:35,,[],,,,,,,,,,,M7T,,,,"2|hzwrrz:",9223372036854775807,,,,No,,,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":92618,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/20 10:27;cs687;The Current Database of ELTS-PROD restored with netbackup is running on the Host m7spg2 with the listener port 2222 

During the maintenance period, we planned to clear out some historic data (deleting all rows that are older than X-Days) 
Before we did it on production we tested in advance on a restored backup somewhere else and measured the time. 
For the test we took about 10 minutes while the actual operation needed to be aborted after over 90 minutes. 

For testing we also did dump/restore in between, that might have caused some way of optimized data layout on the disk, we want to proof if that is really the case. 

Current Plan: 
to create a dump of the current running database elts-prod port 2222 on host m7spg2, which was restored by netbackup agent 
After successful dump we are going to start the cleanup script on the database and measure the time. Afterwards we restore the dump and compare the time after running the script on the fresh restored database. 

*enterprisedb@m7spg2:~ > pg_dump --port=22222 -d m7eltsprodm7b -n m7eltsprodm7b | gzip > /copyshrd/data/backup/m7eltsprodm7b.sql.gz*

","28/Feb/20 15:27;cs687;Run sql-script */tmp/cleanup_6.8.sql*
with activating timing and putting commands to a transaction BEGIN; ... ROLLBACK;

Started 13:56
{code:java}
enterprisedb@m7spg2:~ > time psql -p 22222 -U m7eltsprodm7b -d m7eltsprodm7b -f /tmp/cleanup_6.8.sql          
Timing is on.                                                                                                 
BEGIN                                                                                                         
Time: 0.109 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 16.504 ms                                                                                               
CREATE TABLE                                                                                                  
Time: 71.329 ms                                                                                               
ALTER TABLE                                                                                                   
Time: 9.418 ms                                                                                                
INSERT 0 0                                                                                                    
Time: 42.807 ms                                                                                               
TRUNCATE TABLE                                                                                                
Time: 10.400 ms                                                                                               
DROP TABLE                                                                                                    
Time: 7.050 ms                                                                                                
SET                                                                                                           
Time: 0.707 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 6.879 ms                                                                                                
CREATE INDEX                                                                                                  
Time: 2.875 ms                                                                                                
CREATE INDEX                                                                                                  
Time: 2.524 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 1.068 ms                                                                                                
CREATE TABLE                                                                                                  
Time: 1.561 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 0.761 ms                                                                                                
INSERT 0 0                                                                                                    
Time: 211209.765 ms                                                                                           
TRUNCATE TABLE                                                                                                
Time: 9.800 ms                                                                                                
DROP TABLE                                                                                                    
Time: 17.140 ms                                                                                               
SET                                                                                                           
Time: 0.289 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 12.528 ms                                                                                               
ALTER TABLE                                                                                                   
Time: 0.370 ms                                                                                                
CREATE TABLE                                                                                                  
Time: 6.663 ms                                                                                                
ALTER TABLE                                                                                                   
Time: 4.364 ms                                                                                                
INSERT 0 0                                                                                                    
Time: 130413.783 ms                                                                                           
TRUNCATE TABLE                                                                                                
Time: 3.608 ms                                                                                                
DROP TABLE                                                                                                    
Time: 6.286 ms                                                                                                                                                
SET
Time: 0.047 ms                                                                                                                                                                                                                                                                                                   
ALTER TABLE
Time: 2.293 ms
ALTER TABLE
Time: 0.236 ms
CREATE TABLE
Time: 0.719 ms
ALTER TABLE
Time: 0.827 ms
INSERT 0 0
Time: 18.022 ms
TRUNCATE TABLE
Time: 3.124 ms
DROP TABLE
Time: 1.195 ms
SET
Time: 0.033 ms
ALTER TABLE
Time: 2.461 ms
ALTER TABLE
Time: 0.169 ms
CREATE TABLE
Time: 7.065 ms
ALTER TABLE
Time: 5.025 ms
INSERT 0 0
Time: 22.404 ms
TRUNCATE TABLE
Time: 10.054 ms
DROP TABLE
Time: 12.719 ms
SET
Time: 0.032 ms
ALTER TABLE
Time: 2.983 ms
CREATE INDEX
Time: 1.919 ms
CREATE INDEX
Time: 2.564 ms
ALTER TABLE
Time: 9.292 ms
ALTER TABLE
Time: 1.599 ms
ALTER TABLE
Time: 2.425 ms
ALTER TABLE
Time: 0.225 ms
CREATE TABLE
Time: 4.092 ms
ALTER TABLE
Time: 5.635 ms
INSERT 0 0
Time: 38596.130 ms
TRUNCATE TABLE
Time: 3.484 ms
DROP TABLE
Time: 0.810 ms
SET
Time: 0.034 ms
ALTER TABLE
Time: 2.075 ms
ALTER TABLE
Time: 0.189 ms
CREATE TABLE
Time: 0.725 ms
ALTER TABLE
Time: 0.869 ms
INSERT 0 0
Time: 35140.446 ms
TRUNCATE TABLE
Time: 2.176 ms
DROP TABLE
Time: 2.648 ms
SET
Time: 0.036 ms
ALTER TABLE
Time: 1.796 ms
ALTER TABLE
Time: 0.233 ms
CREATE TABLE
Time: 0.659 ms
ALTER TABLE
Time: 3.879 ms
{code}

Still running!

{code:java}
real    7m13.021s                                                                            
user    0m0.004s                                                                             
sys     0m0.005s                                                                             
enterprisedb@m7spg2:~ > packet_write_wait: Connection to 10.139.59.253 port 22: Broken pipe  
{code}

Script ended after round about 7 mintues. 

Also tested the script by executing it via Enterprisedb-User
{code:java}
enterprisedb@m7spg2:~ > time psql -p 22222 -d m7eltsprodm7b -f /tmp/cleanup_6.8.sql -A -F "","" -o /tmp/clean_history_tables_edb.csv
{code}

{code:java}
real    7m13.170s          
user    0m0.007s           
sys     0m0.003s           
{code}


Also the output csv files having exactly the same output. 
enterprisedb@m7spg2:/tmp > diff clean_history_tables.csv clean_history_tables_edb.csv

","02/Mar/20 09:06;cs687;enterprisedb@m7spg2:~ > time psql -p 22222 -U m7eltsprodm7b -d m7eltsprodm7b -f /tmp/cleanup_6.8.sql -A -F "","" -o /tmp/clean_history_tables.csv
{code:java}
real    7m15.215s
user    0m0.006s
sys     0m0.004s
{code}

after executing the script with a final Commit, it was run with the same amount of time like before. 
Database-Size is reduced to 

{code:java}
                                                                                     List of databases
       Name       |      Owner       | Encoding |   Collate   |    Ctype    |             Access privileges             |  Size   | Tablespace |                Description
------------------+------------------+----------+-------------+-------------+-------------------------------------------+---------+------------+--------------------------------------------
 m7eltsprodm7b    | m7eltsprodm7b    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | m7eltsprodm7b=CTc/m7eltsprodm7b          +| 146 GB  | pg_default |

{code}
","02/Mar/20 09:22;cs687;Roman recommend to stop the database process on veritas cluster before running the deployment with executing the sql-script to have a cleaned up new process. 
hares -stop prodeltsSGdb -sys m7ppg1

... 
and starting it again 
hares -start prodeltsSGdb -sys m7ppg1



","02/Mar/20 09:53;rehapav;[~cs687] & [~dp007] please make sure that you (as part of this ticket) fix final version of dbcleanup script that fixes INDEX for reporting engine problem","03/Mar/20 07:37;cs687;Started the script ""*V001__M7P-4658_clanup_history_tables.sql""* how it was started during the ELTS-PROD Deployment ""SERVICE-5092""
*Starting at 07:35am*

That was the command what [~iu252] used during the deployment: 

{code:java}
[root@m7spg2 tmp]# su - enterprisedb
enterprisedb@m7spg2:~ > psql -p 22222 -d m7eltsprodm7b -f /tmp/V001__M7P-4658_clanup_history_tables.sql -A -F "","" -o /tmp/V001__M7P-4658_clanup_history_tables.csv
{code}

Script ended 7:46:41
{code:java}
enterprisedb@m7spg2:~ > psql -p 22222 -d m7eltsprodm7b -f /tmp/V001__M7P-4658_clanup_history_tables.sql -A -F "","" -o /tmp/V001__M7P-4658_clanup_history_tables.csv
enterprisedb@m7spg2:~ > date
Tue Mar  3 07:46:41 CET 2020
{code}

round about 11 Minutes it was finished!!

","03/Mar/20 08:07;cs687;Achieved the following results:
* script m7spg2:/tmp/cleanup_6.8.sql what Niklas was recommending was running 7-8 Minutes. I started the script with enterprisedb and m7eltsprodm7b user
* script m7spg2:/tmp/V001__M7P-4658_clanup_history_tables.sql what @Alex O executed during the deployment of ELTS-PROD as enterprisedb-user were running 11 Minutes. we shrink down the DB-Size from over 700GB to 150GB 
* During the deployment we stopped the script because it was running over 90 minutes. 
* For test-mode we also did a dump/restore in between to check if we have with that kind of restoring, some way of optimized data layout on the disk. After investigating we noticed that there are no huge differences if we restore the Database with dump/restore in between or requesting the transaction files (point in time recovery) from netbackup-server.

For testing i used the DB-Status before the deployment at 25.02.2020 7pm.
We recommend to stop the database process with veritas cluster command and start it again, that we have from beginning on cleaned new started process.
That´s also how we do it for testing, before we restore the database we have to stop the db-instance and starting it afterwards.
Any idea how we can continue on that. Or should we close it, test the coming db-script(s) with the current database and hope everything is going fine during Deployment.
Obviously i can not reproduce the behavior what occurred during the deployment.","03/Mar/20 14:17;cs687;Can be closed, [~rehapav] and [~oy574] also confirmed this final step. 
We couldn´t reproduce the behavior. We will prepare a new script for next Tuesday deployment and test it tomorrow to be prepared. ",,,,,,,,,,,,,,,,,,,,
Clean-Up Inventory and Vault settings for patroni-deployment,M7P-5662,92608,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,27/Feb/20 08:14,21/May/20 10:23,16/Sep/21 14:11,08/May/20 09:11,,6.8.128,7tops_sprint7,,,,,,,M7PRODOPS,,,,,,,"Some parameters are still listed for each Product-Family in the inventory. 
For a right clean-up we could put some variables to default.yml in patroni role itself. 
some of this settings can be moved to defaults.yml, same for xbid and m7a --> https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/postgres.yml

We also have to cleanup the current Vault-settings. ",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42854400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzx4e7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92608,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"08/May/20 09:02;cs687;Cleaned up Vault settings for:

*xsop*:
 /secrets/secret/m7t/xsop/asim/db
 /secrets/secret/m7t/xsop/cute/db
 /secrets/secret/m7t/xsop/simu/db
 /secrets/secret/m7t/xsop/prod/db

*xrpm*:
 /secrets/secret/m7t/xrpm/lipa/db
 /secrets/secret/m7t/xrpm/simu/db
 /secrets/secret/m7t/xrpm/prod/db

*plpx*:
 /secrets/secret/m7t/plpx/lipa/db
 /secrets/secret/m7t/plpx/simu/db
 /secrets/secret/m7t/plpx/prod/db

*hupx*:
 /secrets/secret/m7t/hupx/asim/db
 /secrets/secret/m7t/hupx/cute/db
 /secrets/secret/m7t/hupx/simu/db
 /secrets/secret/m7t/hupx/prod/db

*flex*:
 /secrets/secret/m7t/flex/simu/db
 /secrets/secret/m7t/flex/prod/db

*epex-asim*:
 /secrets/secret/m7t/epex/asim/db

*elts*:
 /secrets/secret/m7t/elts/simu/db
 /secrets/secret/m7t/elts/prod/db
 /secrets/secret/m7t/elts/lipa/db
 /secrets/secret/m7t/elts/cute/db
 /secrets/secret/m7t/elts/ctpb/db
 /secrets/secret/m7t/elts/acut/db

*shrd*:
/secrets/secret/m7t/shrd/ate3/db
/secrets/secret/m7t/shrd/ate4/db
/secrets/secret/m7t/shrd/ate5/db
/secrets/secret/m7t/shrd/dst1/db
/secrets/secret/m7t/shrd/exte/db
/secrets/secret/m7t/shrd/inte/db
/secrets/secret/m7t/shrd/prod/db
/secrets/secret/m7t/shrd/show/db
/secrets/secret/m7t/shrd/syt1/db
/secrets/secret/m7t/shrd/syt3/db


",,,,,,,,,,,,,,,,,,,,,,,,,,,
"ELTS PROD: Inquiry tries to write into non-existing m7_revinfo table (25/2, upgrade from 6.7. to 6.8.)",M7P-5657,92563,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,fp407,rehapav,rehapav,26/Feb/20 09:40,18/Mar/20 13:26,16/Sep/21 14:11,13/Mar/20 20:38,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,,"As a conequence for interrupting dbcleanup script in ETLS PROD 25/2


one thing we should investigate tomorrow is what database tables have triggers on {{m7_revinfo}} table. There shouldn't be any, but apparently there still are some.
After we remove the triggers, we can drop the table {{m7_revinfo}} (edited) 
 

I suspect {{cx_150_message}} , but we'll have to see
 ",,cs687,fp407,pn508,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5784,M7P-5655,,,,,"28/Feb/20 11:16;cs687;triggers.txt;https://jira.deutsche-boerse.com/secure/attachment/80925/triggers.txt",,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,47779200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,26/Feb/20 09:40,,[],,,,,,,,,,,M7T,,,,"2|hzn2nz:",9223372036854775807,,,,No,,,,,,,,,,"Resolved by M7P-5300, improvements suggested in M7P-5784",,,,,,,,Schmetterling Sprint 87 (PS),Schmetterling Sprint 88,Schmetterling Sprint 89,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":92563,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Feb/20 09:20;rehapav;techops to list all actual triggers on PROD databasse (maintenance team does not have access)

(we need to find problematic trigger)

hand over ticket to maintenance shift for further analysis","28/Feb/20 11:16;cs687;attached file triggers.txt is uploaded, includes the list of all the triggers. 
In case you need some more information´s, feel free to reach me out [~oy574]

Output was generated with that command -> *m7eltsprodm7b=# select * from information_schema.triggers;* 

[^triggers.txt] ","28/Feb/20 11:17;cs687;.","28/Feb/20 15:17;rehapav;Thansk for the list of triggers.

Now its task for dev team to analyse if there is an issue.","03/Mar/20 10:07;fp407;[~cs687]could you please run the following query on _*m7eltsprodm7b*? Thx :)_
{code:java}
select class.relname, trig.tgname, fun.proname, fun.prosrc from pg_class class, pg_trigger trig, pg_proc fun where class.oid = trig.tgrelid and fun.oid = trig.tgfoid and (fun.prosrc like '%m7_revinfo%' or fun.prosrc like '%M7_REVINFO%');
{code}","03/Mar/20 11:28;cs687;sure thing, output of the select command, [~fp407]
{code:java}
m7eltsprodm7b=# select class.relname, trig.tgname, fun.proname, fun.prosrc from pg_class class, pg_trigger trig, pg_proc fun where class.oid = trig.tgrelid and fun.oid = trig.tgfoid and (fun.prosrc like '%m7_revinfo%' or fun.prosrc like '%M7_REVINFO%');
 relname | tgname | proname | prosrc
---------+--------+---------+--------
(0 rows)

{code}
","03/Mar/20 12:30;fp407;Kibana logs from the event:

[https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:'2020-02-25T19:00:00.000Z',mode:absolute,to:'2020-02-26T00:59:59.999Z'))&_a=(columns:!(log_level,log.file.path,logline),index:m7-tomcat,interval:auto,query:(language:lucene,query:'client:+elts+AND+client_environment:+prod+%2Blog_level:+ERROR+%2Blogline:+%22does+not+exist%22'),sort:!('@timestamp',desc))]

*February 26th 2020, 00:45:48.000*
{code:java}
Unexpected error when calling isNewMessagesAvailableSince()
org.hibernate.AssertionFailure: Unable to perform beforeTransactionCompletion callback
	at org.hibernate.engine.spi.ActionQueue$BeforeTransactionCompletionProcessQueue.beforeTransactionCompletion(ActionQueue.java:960)
	at org.hibernate.engine.spi.ActionQueue.beforeTransactionCompletion(ActionQueue.java:525)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2518)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:447)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:626)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:534)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:305)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy188.isNewMessagesAvailableSince(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor832.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:205)
	at com.sun.proxy.$Proxy189.isNewMessagesAvailableSince(Unknown Source)
	at com.deutscheboerse.comxerv.power.controller.AbstractMessagesController.isNewMessagesAvailable(AbstractMessagesController.java:72)
	at com.deutscheboerse.comxerv.power.controller.AbstractMessagesController.getMessages(AbstractMessagesController.java:53)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController.getMessages(PrivateMessagesController.java:55)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$FastClassBySpringCGLIB$$12b4cda6.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$EnhancerBySpringCGLIB$$1d38aa20.getMessages(<generated>)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$FastClassBySpringCGLIB$$12b4cda6.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:750)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:136)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:124)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$EnhancerBySpringCGLIB$$41183477.getMessages(<generated>)
	at sun.reflect.GeneratedMethodAccessor1068.invoke(Unknown Source)
Caused by: javax.persistence.PersistenceException: org.hibernate.exception.SQLGrammarException: could not execute batch
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:154)
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:181)
	at org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:188)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1489)
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1469)
	at org.hibernate.envers.internal.synchronization.AuditProcess.doBeforeTransactionCompletion(AuditProcess.java:177)
	at org.hibernate.envers.internal.synchronization.AuditProcessManager$1.doBeforeTransactionCompletion(AuditProcessManager.java:47)
	at org.hibernate.engine.spi.ActionQueue$BeforeTransactionCompletionProcessQueue.beforeTransactionCompletion(ActionQueue.java:954)
	at org.hibernate.engine.spi.ActionQueue.beforeTransactionCompletion(ActionQueue.java:525)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2518)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:447)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:626)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:534)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:305)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy188.isNewMessagesAvailableSince(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor832.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:205)
	at com.sun.proxy.$Proxy189.isNewMessagesAvailableSince(Unknown Source)
	at com.deutscheboerse.comxerv.power.controller.AbstractMessagesController.isNewMessagesAvailable(AbstractMessagesController.java:72)
	at com.deutscheboerse.comxerv.power.controller.AbstractMessagesController.getMessages(AbstractMessagesController.java:53)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController.getMessages(PrivateMessagesController.java:55)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$FastClassBySpringCGLIB$$12b4cda6.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:685)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$EnhancerBySpringCGLIB$$1d38aa20.getMessages(<generated>)
	at com.deutscheboerse.comxerv.power.controller.PrivateMessagesController$$FastClassBySpringCGLIB$$12b4cda6.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:750)
Caused by: org.hibernate.exception.SQLGrammarException: could not execute batch
	at org.hibernate.exception.internal.SQLStateConversionDelegate.convert(SQLStateConversionDelegate.java:106)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:42)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:129)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:105)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:148)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.getBatch(JdbcCoordinatorImpl.java:187)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3166)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3706)
	at org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:90)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:604)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1483)
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1469)
	at org.hibernate.envers.internal.synchronization.AuditProcess.doBeforeTransactionCompletion(AuditProcess.java:177)
	at org.hibernate.envers.internal.synchronization.AuditProcessManager$1.doBeforeTransactionCompletion(AuditProcessManager.java:47)
	at org.hibernate.engine.spi.ActionQueue$BeforeTransactionCompletionProcessQueue.beforeTransactionCompletion(ActionQueue.java:954)
	at org.hibernate.engine.spi.ActionQueue.beforeTransactionCompletion(ActionQueue.java:525)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2518)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:447)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:626)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:534)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:305)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy188.isNewMessagesAvailableSince(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor832.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:205)
Caused by: java.sql.BatchUpdateException: Batch entry 0 insert into m7eltsprodm7b.REVINFO (REVTSTMP, REV) values (1582674348621, 86608008) was aborted: ERROR: relation ""m7eltsprodm7b.revinfo"" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:148)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2234)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:510)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:853)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1546)
	at org.apache.tomcat.dbcp.dbcp2.DelegatingStatement.executeBatch(DelegatingStatement.java:223)
	at org.apache.tomcat.dbcp.dbcp2.DelegatingStatement.executeBatch(DelegatingStatement.java:223)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:119)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:105)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:148)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.getBatch(JdbcCoordinatorImpl.java:187)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3166)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3706)
	at org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:90)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:604)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1483)
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1469)
	at org.hibernate.envers.internal.synchronization.AuditProcess.doBeforeTransactionCompletion(AuditProcess.java:177)
	at org.hibernate.envers.internal.synchronization.AuditProcessManager$1.doBeforeTransactionCompletion(AuditProcessManager.java:47)
	at org.hibernate.engine.spi.ActionQueue$BeforeTransactionCompletionProcessQueue.beforeTransactionCompletion(ActionQueue.java:954)
	at org.hibernate.engine.spi.ActionQueue.beforeTransactionCompletion(ActionQueue.java:525)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2518)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:447)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:626)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:534)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:305)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy188.isNewMessagesAvailableSince(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor832.invoke(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: relation ""m7eltsprodm7b.revinfo"" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2497)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2233)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:510)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:853)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1546)
	at org.apache.tomcat.dbcp.dbcp2.DelegatingStatement.executeBatch(DelegatingStatement.java:223)
	at org.apache.tomcat.dbcp.dbcp2.DelegatingStatement.executeBatch(DelegatingStatement.java:223)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.performExecution(BatchingBatch.java:119)
	at org.hibernate.engine.jdbc.batch.internal.BatchingBatch.doExecuteBatch(BatchingBatch.java:105)
	at org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.execute(AbstractBatchImpl.java:148)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.getBatch(JdbcCoordinatorImpl.java:187)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3166)
	at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:3706)
	at org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:90)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:604)
	at org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:478)
	at org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:356)
	at org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)
	at org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1483)
	at org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1469)
	at org.hibernate.envers.internal.synchronization.AuditProcess.doBeforeTransactionCompletion(AuditProcess.java:177)
	at org.hibernate.envers.internal.synchronization.AuditProcessManager$1.doBeforeTransactionCompletion(AuditProcessManager.java:47)
	at org.hibernate.engine.spi.ActionQueue$BeforeTransactionCompletionProcessQueue.beforeTransactionCompletion(ActionQueue.java:954)
	at org.hibernate.engine.spi.ActionQueue.beforeTransactionCompletion(ActionQueue.java:525)
	at org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2518)
	at org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:447)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:178)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$300(JdbcResourceLocalTransactionCoordinatorImpl.java:39)
	at org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:271)
	at org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)
	at org.springframework.orm.hibernate5.HibernateTransactionManager.doCommit(HibernateTransactionManager.java:626)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:746)
	at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:714)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:534)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:305)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:212)
	at com.sun.proxy.$Proxy188.isNewMessagesAvailableSince(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor832.invoke(Unknown Source)
{code}","05/Mar/20 16:11;fp407;This problem happened when upgrading from 6.7.111 to 6.8.90.

Writing in the m7_revinfo table is a functionality which we decomissioned in 6.8.90. Based on the available logs we currently believe that this problem happened due to inconsistent state during the upgrade procedure. This problem could happen again, but can be fixed by temporarily introducing the m7_revinfo table. In such case, it would be beneficial to check what is the status of m7 software (i.e. which processes are running and what is the actual DB setup).

Currently on ELTS PROD, no process seems to be trying to write into to the m7_revinfo table introduced as a workaround and there are is no evidence of inquiry trying to perform any updates on cx_151_status_messages table (which was the crash scenario). See selects below.

Regardless of the m7_revinfo issue, logs show that inquiry is trying to write into the DB. This should never happen as inquiry is not supposed to change any data in the core database. We were not able to identify which process breaks this rule.

As a fix to that we suggest introducing a read-only DB user for inquiry in 6.9. This change would affect:
 * automation inventory ([https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/elts/prod/m7tenq/vars.yml])
 * automation deployments ([https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/m7tenq/defaults/main.yml])
 * vault (new user secret storage)
 * docker deployment scripts (m7.m7/m7-docker)

This of course does not solve the underlying issue, but would help us identify processing which triggers these DB writes.

*This issue is not critical, as a workaround exists and the fact that we're writing in the DB from inquiry should only have a minor performance impact.*

Estimated cost of introducing the read-only user -> 4 SPs (dev + test).

Excerpts from production DB backup taken on 1.3.2020:
{code:java}
m7eltsprodm7b=# select * from cx_151_messages_history where revtype <> 0 order by last_update_time desc limit 20; message_id |     rev     | revtype | mod_type_code |    last_update_time    |    last_update_user    |            text             |         
------------+-------------+---------+---------------+------------------------+------------------------+-----------------------------+---------
  380279739 | -1524217210 |       2 | ACTI          | 23-FEB-20 19:10:00.439 | 7777777777777777SYSTEM | 20Q2 closed for APG         | Contract
  380279740 | -1524217209 |       2 | ACTI          | 23-FEB-20 19:10:00.439 | 7777777777777777SYSTEM | 20Q2 closed for TTG         | Contract
  380279738 | -1524217211 |       2 | ACTI          | 23-FEB-20 19:10:00.439 | 7777777777777777SYSTEM | 20Q2 closed for AMP         | Contract
  380279737 | -1524217212 |       2 | ACTI          | 23-FEB-20 19:10:00.439 | 7777777777777777SYSTEM | 20Q2 closed for TNG         | Contract
  380279736 | -1524217213 |       2 | ACTI          | 23-FEB-20 19:10:00.439 | 7777777777777777SYSTEM | 20Q2 closed for 50HzT       | Contract
  380279707 | -1524217214 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20Q1 closed for 50HzT       | Contract
  380279703 | -1524217219 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20Q1 closed for TNG         | Contract
  380279706 | -1524217215 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20Q1 closed for TTG         | Contract
  380279705 | -1524217217 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20Q1 closed for APG         | Contract
  380279696 | -1524217220 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20H1 closed for RTE         | Contract
  380279704 | -1524217218 |       2 | ACTI          | 23-FEB-20 18:55:00.405 | 7777777777777777SYSTEM | 20Q1 closed for AMP         | Contract
  380279677 | -1524217216 |       2 | ACTI          | 23-FEB-20 18:45:00.439 | 7777777777777777SYSTEM | HH200223-39 closed for NGET | Contract
  380279666 | -1524322975 |       2 | ACTI          | 23-FEB-20 18:40:00.407 | 7777777777777777SYSTEM | 19Q4 closed for 50HzT       | Contract
  380279665 | -1524322976 |       2 | ACTI          | 23-FEB-20 18:40:00.407 | 7777777777777777SYSTEM | 19Q4 closed for TTG         | Contract
  380279663 | -1524322978 |       2 | ACTI          | 23-FEB-20 18:40:00.407 | 7777777777777777SYSTEM | 19Q4 closed for AMP         | Contract
  380279664 | -1524322977 |       2 | ACTI          | 23-FEB-20 18:40:00.407 | 7777777777777777SYSTEM | 19Q4 closed for APG         | Contract
  380279662 | -1524322979 |       2 | ACTI          | 23-FEB-20 18:40:00.407 | 7777777777777777SYSTEM | 19Q4 closed for TNG         | Contract
  380279640 | -1524322981 |       2 | ACTI          | 23-FEB-20 18:25:00.386 | 7777777777777777SYSTEM | 19Q3 closed for APG         | Contract
  380279641 | -1524322980 |       2 | ACTI          | 23-FEB-20 18:25:00.386 | 7777777777777777SYSTEM | 19Q3 closed for TNG         | Contract
  380279638 | -1524322983 |       2 | ACTI          | 23-FEB-20 18:25:00.386 | 7777777777777777SYSTEM | 19Q3 closed for TTG         | Contract
(20 rows)

select * from cx_151_messages_history where revtype = 1 order by last_update_time desc limit 20;
 message_id | rev | revtype | mod_type_code | last_update_time | last_update_user | text | message_text | external_timestamp | priority | mess
------------+-----+---------+---------------+------------------+------------------+------+--------------+--------------------+----------+-----
(0 rows)
{code}
 ","11/Mar/20 16:36;fp407;*Please take again for re-planning. Scope & priority have changed. See comment above for details.*","12/Mar/20 10:53;fp407;After discussion with PO, we want to implement the read only user. As this can result in inquiry module failures, planned for m7 version 6.10.

XBID has also implemented the read-only user for inquiry. They managed to identify some problem because of it (inquiry doing unexpected db writes). Get in touch with them when implementing to get advice/hints.","12/Mar/20 10:55;pn508;Approved",,,,,,,,,,,,,,,,,
Verify MTT keystore Vault configuration,M7P-5656,92562,92555,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,rehapav,ax460,ax460,26/Feb/20 09:37,04/Mar/20 15:12,16/Sep/21 14:11,03/Mar/20 14:38,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,"please check [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/elts/prod/mtt2/]

value are loaded from vault see [https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/roles/mtt2/defaults/main.yml#L94]

 

Also note elts production is only env using different alias [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/elts/prod/mtt2/vars.yml#L18] even epex prod has different [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/hupx/prod/mtt2/vars.yml#L17]",,ax460,cs687,dp007,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5478,,,,,,"26/Feb/20 11:43;dp007;ecc.png;https://jira.deutsche-boerse.com/secure/attachment/80781/ecc.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48470400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx5xz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92562,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Feb/20 11:44;dp007;
Hi,

the first test was NOT succesful:
!ecc.png!

I cannot connect to the server:

 {code}

wget https://prod1.epex-lts.m7.deutsche-boerse.com:60064/mtt/as2

--2020-02-25 22:55:08--  https://prod1.epex-lts.m7.deutsche-boerse.com:60064/mtt/as2

Auflösen des Hostnamens »prod1.epex-lts.m7.deutsche-boerse.com (prod1.epex-lts.m7.deutsche-boerse.com)« … 193.29.81.67

Verbindungsaufbau zu prod1.epex-lts.m7.deutsche-boerse.com (prod1.epex-lts.m7.deutsche-boerse.com)|193.29.81.67|:60064 … fehlgeschlagen: Verbindungsaufbau abgelehnt.
 {code}
 

Please check on your side and try to send a message to us.

Best regards,

Gunar 
","26/Feb/20 13:15;cs687;Based on that error:  *Caused by: java.security.KeyStoreException: Unsupported Key type*

I checked the certificate Situation and found out that we have some password issues with ""keystore_key_password"" to proper encrypt the private key. 
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/elts/prod/mtt2/keystore_key_password

When i run the following command to validate the password of the private key and use the current vault-password ""*keystore_key_password*"" we can see that the password is not matching. 
{code:java}
tomcat@m7eltsprodm7b1:[/tmp]$ openssl pkcs12 -in /elts/elts-prod-mtt1/keystore.p12 -nodes -nocerts -out /tmp/prvkey.pem
*{color:#DE350B}Enter Import Password:
Mac verify error: invalid password?{color}*
{code}

After using the password which is stored in secret ""*keystore_password*"" its working out and i can encrypt the private-key!
{code:java}
tomcat@m7eltsprodm7b1:[/tmp]$ openssl pkcs12 -in /elts/elts-prod-mtt1/keystore.p12 -nodes -nocerts -out /tmp/prvkey.pem
Enter Import Password:
MAC verified OK
{code}


So easiest try would be to change the current application.yml properties with the correct keyPassword the application. Once it is working out we can change Vault and are prepared for the future or run an additional re-deployment of mtt. 
{code:java}
 # AS2 keystore settings for receiving/sending
  keystoreConfiguration:
    url: /elts/elts-prod-mtt1/keystore.p12
    password: PASSWORD_IN_VAULT
    keyAlias: AS20004
    keyPassword: PASSWORD_IN_VAULT
{code}

FYI: [~ax460], [~rehapav]


UPDATE: 
i also compared it with hupx-prod and here we have the same setup, so root cause wrong password in vault for keystore_key_password. 

","26/Feb/20 13:41;cs687;[~rehapav] please schedule a redeployment and we can validate if MTT is running afterwards. ","27/Feb/20 10:30;pd122;[~cs687], also key alias mismatch (*AS20004* vs 1):

 
{code:java}
tomcat@m7eltsprodm7b1:[/home/tomcat]$ grep -i alias /elts/elts-prod-mtt1/application.yml 
 keyAlias: AS20004
{code}
 
{code:java}
tomcat@m7eltsprodm7b1:[/home/tomcat]$ keytool -list -keystore /elts/elts-prod-mtt1/keystore.p12 
Enter keystore password: 
Keystore type: PKCS12
Keystore provider: SUN
Your keystore contains 1 entry
1, Feb 27, 2020, PrivateKeyEntry, 
Certificate fingerprint (SHA1): 50:88:59:58:8C:CB:17:AD:EC:6E:C8:D4:47:1D:F4:EF:3C:A9:B5:30
{code}
 

 ","28/Feb/20 11:36;pd122;key alias updated in the vault keystore, ready for the deployment now:
{code:java}
$ vault read -field=value secret/m7t/elts/prod/mtt2/keystore | base64 -d >/tmp/keystore.p12 && keytool -list -keystore /tmp/keystore.p12

Keystore type: jks
Keystore provider: SUN
Your keystore contains 1 entry
as20004, Feb 28, 2020, PrivateKeyEntry, 
Certificate fingerprint (SHA1): 50:88:59:58:8C:CB:17:AD:EC:6E:C8:D4:47:1D:F4:EF:3C:A9:B5:30
{code}
 ","28/Feb/20 11:38;pd122;please, schedule the ELTS PROD MTT deployment with the customer","03/Mar/20 14:19;rehapav;Scheduled for execution in SERVICE-5478 for 10/3 at 15:00 - 17:00",,,,,,,,,,,,,,,,,,,,,
ELTS PROD 25/2 - dbcleanup script interrupted,M7P-5655,92560,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Cannot Reproduce,qo288,rehapav,rehapav,26/Feb/20 09:35,08/Apr/20 09:54,16/Sep/21 14:11,19/Mar/20 08:29,,7tops_sprint4,,,,,,,,M7PRODOPS,,,,,,,"During ELTS PROD deployment on 25/2 we had to interrupt 

dbcleanup script after 67 minutes
|it run for 69 minutes:
 the final cleanup script status:
 cx_101_order_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/2714-fe0f.png!
 cx_262_limit_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/2714-fe0f.png!
 cx_119_settlement_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/2714-fe0f.png!
 cx_673_trade_flow_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/2714-fe0f.png!
 cx_111_trade_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/2714-fe0f.png!
 cx_151_messages_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 cx_120_remote_public_trade_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 cx_441_contract_delivery_area_state_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 cx_211_contract_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 cx_215_contract_closing_price_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 cx_296_session_history   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!
 m7_999_revision_index   !https://a.slack-edge.com/production-standard-emoji-assets/10.2/google-medium/274c.png!|

 

Todo:
 * review the script in the actual ELTS PROD db state and prepare new version if needed for next deployment
 * measure how much time we will need for executing this new (or same) script with next deployment
 * we measured 30 minutes execution time during tests on ELTS PROD db backup in M7P-5201, analyze why script didnt finish in time

Additional question:
 * DB cleanup script test took internally 30 minutes, would it make sense to have the same environment as ELTS PROD with the same amount of data and test the execution of the script in real-world scenario? Potentially the whole deployment playbook as well.
 * Can we also split the cleanup script into several small scripts for each individual table?",,cs687,dp007,rehapav,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5765,,,,,,"26/Feb/20 13:05;yo218;cleanup_6.8.sql;https://jira.deutsche-boerse.com/secure/attachment/80794/cleanup_6.8.sql",,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,47174400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,26/Feb/20 09:35,,[],,,,,,,,,,,M7T,,,,"2|hzx5xj:",9223372036854775807,,,,No,,,,,,,,,,.,,,,,,,,7tops Sprint 1,7tops Sprint 2,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":92560,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Feb/20 09:45;yo218;""we measured 30 minutes execution time during tests on ELTS PROD db backup in M7P-5201, analyze why script didnt finish in time""

actually it was just 10 minutes:
{noformat}
enterprisedb@m7spg2:/var/lib/ppas_syt3shrd_20800/ADMIN/INSTALL > date && psql -p 20800 -U m7shrdsyt3m7b -d m7shrdsyt3m7b -W -f /tmp/cleanup_6.8.sql && date
Tue Feb 11 10:52:45 CET 2020
Password for user m7shrdsyt3m7b:
ALTER TABLE
CREATE TABLE
(...)
ALTER TABLE
DO
Tue Feb 11 11:02:16 CET 2020{noformat}","26/Feb/20 11:29;yo218;The script has not been executed in the same way as tested on prod db and on all prior 6.8 deployments (not even the same script).

It was tested and documented as follows:
{noformat}
psql -p 20106 -U m7eltsprodm7b -d m7eltsprodm7b -W -f /tmp/cleanup_6.8.sql{noformat}
Executed was the following command:
{noformat}
psql -p 20106 -d m7eltsprodm7b -f /tmp/SERVICE-5092/V001__M7P-4658_clanup_history_tables.sql -A -F "","" -o /tmp/SERVICE-5092/V001__M7P-4658_clanup_history_tables.csv {noformat}
 * different script (it doesn't contain the adding of the missing sequence and the int8 changes)
 * not executed as db owner (missing -U m7eltsprodm7b)
 * output written into csv file

It should be tested whether this makes really a difference though","26/Feb/20 13:01;dp007;[~yo218] could you please give us link to _cleanup_6.8.sql_ file?","26/Feb/20 13:05;yo218;attached it to the ticket","03/Mar/20 08:15;cs687;Put my results in M7P-5664","03/Mar/20 15:49;dp007;New version of the cleanup scripts: [https://github.deutsche-boerse.de/dev/energy.automation.inventory-sql/pull/152]","18/Mar/20 10:58;rehapav;[~yo218] Do we still plan to use this during PatroniDB migration on 14/4 ? Or size is good enought to be migrated in 2 hours","19/Mar/20 08:29;cs687;can be closed,like we confirmed last time in the 7tops-meeting
[~rehapav] also confirmed it. ",,,,,,,,,,,,,,,,,,,,
ELTS CTPB: shared network storage not mounted to journal dir on core 1,M7P-5654,92558,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,fp407,fp407,fp407,26/Feb/20 09:24,04/Mar/20 15:12,16/Sep/21 14:11,26/Feb/20 14:26,,6.9.76,7Tops_Sprint1,,,cor,,,,M7PRODOPS,,,,,,,"core1:
{code:java}
[root@m7eltsctpbm7b1 ~]# df -h
Filesystem                            Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root            3,8G  2,0G  1,7G  54% /
devtmpfs                              9,8G     0  9,8G   0% /dev
tmpfs                                 9,8G     0  9,8G   0% /dev/shm
tmpfs                                 9,8G  628M  9,2G   7% /run
tmpfs                                 9,8G     0  9,8G   0% /sys/fs/cgroup
/dev/sda1                             190M  140M   40M  78% /boot
/dev/mapper/rootvg-lv_tmp             969M  2,6M  900M   1% /tmp
/dev/mapper/rootvg-lv_patrol          976M  436M  474M  48% /opt/patrol
/dev/mapper/rootvg-lv_elts            3,9G  1,2G  2,6G  32% /elts
/dev/mapper/rootvg-lv_var             2,5G  1,1G  1,3G  45% /var
/dev/mapper/rootvg-lv_logs            2,0G  834M 1000M  46% /elts/logs
/dev/mapper/rootvg-lv_uc4bin_opt_uc4  488M   46M  407M  11% /elts/opt/uc4
/dev/mapper/rootvg-lv_uc4bin_uc4      2,0G  6,0M  1,8G   1% /elts/uc4
/dev/mapper/rootvg-lv_varlog          969M  113M  790M  13% /var/log
tmpfs                                 2,0G     0  2,0G   0% /run/user/1984
tmpfs                                 2,0G     0  2,0G   0% /run/user/496
tmpfs                                 2,0G     0  2,0G   0% /run/user/1983
tmpfs                                 2,0G     0  2,0G   0% /run/user/509666
{code}
core2:
{code:java}
[root@m7eltsctpbm7b2 ~]# df -h
Filesystem                         Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root         3,8G  1,9G  1,8G  52% /
devtmpfs                           9,8G     0  9,8G   0% /dev
tmpfs                              9,8G     0  9,8G   0% /dev/shm
tmpfs                              9,8G  476M  9,3G   5% /run
tmpfs                              9,8G     0  9,8G   0% /sys/fs/cgroup
/dev/sda1                          190M  144M   47M  76% /boot
/dev/mapper/rootvg-lv_tmp          969M  2,6M  900M   1% /tmp
/dev/mapper/rootvg-lv_var          2,5G  975M  1,4G  42% /var
/dev/mapper/rootvg-lv_elts         3,0G  852M  2,0G  30% /elts
/dev/mapper/rootvg-lv_elts_logs    2,0G   76M  1,8G   5% /elts/logs
/dev/mapper/rootvg-lv_varlog       969M   99M  805M  11% /var/log
tmpfs                              2,0G     0  2,0G   0% /run/user/1984
m7simupdb2:/journal_m7eltsctpbm7b  5,0G 1014M  4,0G  20% /elts/journal
tmpfs                              2,0G     0  2,0G   0% /run/user/496
tmpfs                              2,0G     0  2,0G   0% /run/user/1983
tmpfs                              2,0G     0  2,0G   0% /run/user/509666
{code}
try to perform e.g. ""touch /elts/journal/somefile"" whether it appears on both nodes",,fp407,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"* both nodes shat down (core only)
 * remote journal mounted on m7eltsctpbm7b1 (/etc/fstab entry existed already)
 * local journal files copied over to it
 * both nodes started",,,,,,,,,,,,,,,,,,,,,,,,48988800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,26/Feb/20 09:24,,[],,,,,,,,,,,M7T,,,,"2|hzx5x3:",9223372036854775807,,,,No,,,,,,,,,,journal FS is remote on m7eltsctpbm7b2 but local on m7eltsctpbm7b1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,N/A,,,,,,,,,,"{""issueId"":92558,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Feb/20 14:22;pd122;Journal is now shared between the 2  nodes:
{code:java}
[pd122@m7eltsctpbm7b1 ~]$ df /elts/journal
Filesystem 1K-blocks Used Available Use% Mounted on
m7simupdb1:/journal_m7eltsctpbm7b 5232640 2067456 3165184 40% /elts/journal{code}
{code:java}
[pd122@m7eltsctpbm7b2 ~]$ df /elts/journal/
Filesystem 1K-blocks Used Available Use% Mounted on
m7simupdb2:/journal_m7eltsctpbm7b 5232640 2067456 3165184 40% /elts/journal{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,
Release fails on missing docker image osixia/openldap:1.1.9,M7P-5650,92543,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,qo288,ax460,ax460,25/Feb/20 16:23,18/Mar/20 13:26,16/Sep/21 14:11,05/Mar/20 10:10,,6.9.81,7tops_sprint2,,,M7 BE,,,,M7PRODOPS,,,,,,,"Release of m7.m7 in [develop branch|https://englobjci1.deutsche-boerse.de/job/Energy/view/M7%20Trading/job/m7-core-ci/job/develop/] fails on pulling osixia/openldap:1.1.9

 

Note it works from [acceptance branch|https://englobjci1.deutsche-boerse.de/job/Energy/view/M7%20Trading/job/m7-core-ci/job/acceptance/]",,ax460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48384000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx5u7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92543,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 12:12;ax460;Was there any resolution/fix or it is not occurring anymore",,,,,,,,,,,,,,,,,,,,,,,,,,,
DBVisualizer connection details,M7P-5649,92532,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,wn626,wn626,25/Feb/20 14:07,04/Mar/20 15:12,16/Sep/21 14:11,27/Feb/20 10:02,,6.9.76,7Tops_Sprint1,,,,,,,M7PRODOPS,,,,,,,"We are using DBVisualizer for connection to databases, but recently connection details for some of the DBs have changed. We need to go through all of them and make it up to date.

 

For example: XRPM LIPA",,cs687,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48988800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwz87:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92532,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Feb/20 10:00;cs687;First i give you the proper answer to your question: 
XRPM-LIPA is running:

*with the port*: 24034
*on the hosts*: m7simupdb1.deutsche-boerse.de, m7simupdb2.deutsche-boerse.de, m7simupdb3.deutsche-boerse.de and m7simupdb4.deutsche-boerse.de (Patroni-Cluster, thats why these amount of machines) 


In the past we had the excel environment sheet which were updated but this sheet is totally outdated and we are not using the tab env-details anymore. 
Actually you can get all the necessary information's from *github inventory:*

https://github.deutsche-boerse.de/dev/energy.automation.inventory

Ports ""-pdb-async|sync"" will be found here: 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/ports.yml

On which hosts the database is running you will find it in the postgres-folder like for flex-simu. Every environment is setup with the same folders in the inventory. 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/flex/simu/postgres/main.yml

Be aware our schemas-names changed: 
in the past we had just the naming of schema/users starting with m7 now we changed it for each m7-product family like m7*t* for trading, m7*c* for capacity and m7*a* for auction. 

------------------------------------------------------------------------------------------------------------------------------------------------------------

HERE an example with elts-ctpb -> how to get the database informations:

port: m7t-elts-ctpb-*pdb-async:* 24004
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/ports.yml

hosts: m7simupdb1-m7simupdb4 (reachable from cyberark) 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/elts/ctpb/postgres/main.yml

Schema-Names: 
instead of m7eltsctpbm7b, m7eltsctpbmtt and m7eltsctpbrep we are now using!!! *m7teltsctpbm7b, m7teltsctpbmtt and m7teltsctpbrep*

User-Names: 
the same for the usernames -> udev01m7teltsctpbm7b, udev01m7teltsctpbmtt and udev01m7teltsctpbrep

","27/Feb/20 10:02;cs687;As far i can see all the current changes are updated in the bizops confluence page: 

--> https://confluence.energy.svc.dbgcloud.io/pages/viewpage.action?pageId=10470502
",,,,,,,,,,,,,,,,,,,,,,,,,,
Investigate strategies for backups and archiving of data in Kafka cluster,M7P-5634,92402,,Task,Waiting,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,,,HO764,HO764,21/Feb/20 16:44,03/Sep/21 09:37,16/Sep/21 14:11,,,,,,,,,,,7tops_comm,M,M7PRODOPS,,,,,"In a clean design, all components should be able to start just from Kafka (i.e., snapshots / local databases are mainly for improving startup times, but not for keeping any data not available in Kafka). In some cases, we need to perform backup/restore of Kafka cluster (or just some topics). The examples of such cases include:
 * software error (something wrong published to a topic)
 * admin error (e.g., incorrect setup leads to deletion of some data)
 * performing and experiment (e.g., dst test) and later restore to the state before
 * data has to be archived for 10 years (contractual requirement), involve techops for technical solution (data storage), how quickly should historical data be accessible to be defined by business (e.g. delivery time when someone requests a report based on historical data)

Investigate the possible solutions, maybe also test the solutions, and propose the best one. Some info available here: [https://medium.com/@anatolyz/introducing-kafka-backup-9dc0677ea7ee]

*Contractual obligations/requirements from the CR:*
 * We must archive Production data for 10 years period (e.g. an order entered now is archived for 10 years as of now)
 * We must archive log files (including API and M7 log files) for a 6-month period, starting with the creation of any such log file.
 * We must store daily backups of Production data.
 ** Production data is DATA defined as reference data, orders, trades, delivery areas and log files.
 * Archived production data must be retrievable within 4 weeks time frame (internal assumption of ACM)
 * We must be able to easily re-generate reports for the last 6 trading days.

*Current ""technical"" backup for disaster recovery (state as of 17/4/2020):*
 * currently we are running our backups with netbackup (dedicated team of DBAG nbu-admins).
 * we are running once a day a backup which contains (important FS) on our VM´s and physical machines.
 * On db-side we are running at least for the simu/prod db-clusters every hour an incremental backup and once a day an full-backup to realize proper Point-In-Time recoveries.
 * db backup is performed using usr/bin/postgres-backup, we have for each cluster-env separated zmanda backup-scripts where the necessary infos are included (like data-dir, listener port etc), on each database machine is a netbackup-agent running which is communicating with the server.",,cs687,fp407,HO764,nn236,nz893,op211,rehapav,,,,,,,,,,,M7P-6036,M7P-4103,,,,,,,,,,,,,,,,,,,,,"17/Apr/20 14:11;sw455;Energy JIRA 2020-04-17T14_09_45+0200.csv;https://jira.deutsche-boerse.com/secure/attachment/82756/Energy+JIRA+2020-04-17T14_09_45%2B0200.csv",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-3944,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzzoxr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 102,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,7tops Sprint 106,7tops Sprint 107,7tops Sprint 108,7tops Sprint 110,7tops Sprint 111,7tops Sprint 112,7tops Sprint 113,7tops Sprint 116,7tops Sprint 117,7tops Sprint 118,7tops Sprint 119,7tops Sprint 120,7tops Sprint 121,7tops Sprint 122,7tops Sprint 123,7tops Sprint 124,OPS backlog,,,,,,,,,,,,,,,,"{""issueId"":92402,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Mar/20 13:17;fp407;more details on market data backup for 10 years","17/Apr/20 14:06;sw455;As requested in the meeting, here is a quick search showing at least 15 request in the last 12 months for retrieving archived or historical data (mostly TC report regen.) 

[Jira Search Result|https://jira.deutsche-boerse.com/issues/?jql=%22Customer%20Request%20Type%22%20%3D%20%22Request%20for%20Historical%20or%20Archival%20Data%20(SERVICE)%22%20%20and%20createdDate%20%3C%3D%20now()%20and%20createdDate%20%3E%20-365d]
And csv -  [^Energy JIRA 2020-04-17T14_09_45+0200.csv] 

Based on time logged values I assume ~1.5 hrs average per request fulfillment.

So we might estimate some ~25 hours per year for such requests. ","17/Apr/20 14:38;nn236;Another link from Alex for (older) EPEX data:

[https://jira.deutsche-boerse.com/issues/?jql=%22Customer%20Request%20Type%22%20%3D%20%22Request%20for%20Historical%20or%20Archival%20Data%20(SERVICE)%22%20%20and%20Organizations%20%3D%20EPEX]","17/Apr/20 16:14;nn236;The re-generated TC540 reports for EPEX can be found here:

https://jira.deutsche-boerse.com/browse/SERVICE-4645

 ","20/Apr/20 12:34;cs687;Hey just a small update from our meeting with internal NBU-Admins (netbackup) today. 
*Participants were*: [~qo288], [~fp407], Michael Lievens and Alain Nokel

Netbackup confirmed that we can backup our data´s for 10 years, like it is already in use for our Filesystem-Backup and Database Backup procedure. 
For the future we could easily use a similar setup how we are doing backups for our databases at the moment. 
So we have a netbackup-agent running on the source host which is connecting to the netbackup-server where the backups will be stored/received.
NBU-Admins will provide us a script with proper parameters to execute backups, this could be easily automated via Jenkins later on. For requesting older backups we have two possibilities.
On the one hand we could also solve that via a provided nbu-script and automate that properly, on the other hand we have the option to use a Web-GUI ""https://opscenter/opscenter/"" which might be not a proper solution for me, because it is not really user-friendly and the performance to restore file(s) is not the optimal one. 

As first steps that our proper backup solution is working we will try the following, maybe in the next Sprint(s):
* install netbackup agent on the kafka machines (enprodkbrX - maybe only one machine is enough) (handled by 7tops)
* provide NBU-Admins the hosts where we want to proceed backups (handled by 7tops) 
* roll out the scripts which will be provided by netbackup (handled by 7tops)
* execute some dummy files/topics on kafka side (handled by dev)
* testing the backup behavior for these files and also try to restore them.  
","14/Sep/20 11:57;cs687;Update: had a small meeting with [~wm282] and [~fp407]

we talked about putting kafka to openshift and using with that technology some backup strategy´s. 
Will put the ticket to waiting.","28/Sep/20 09:13;cs687;Will have a meeting with netbackup Team on wednesday 30.09.2020

 +UPDATE from 30.09.2020+

Just talked to [~fp407] we could imagine the following for doing kafka backups.



fist of all we have several kafka-clusters accross one physical cluster, so for example for test we have 4 hosts which are building a cluster 
 * entestkfk1
 * entestkfk2
 * entestkfk3
 * entestkfk4

Backup´s can be only taken when the kafka cluster/node is down, that´s why we would add additional to the real clusters (test,simu,prod) a dedicated virtual machine which will be mirrored from each kafka cluster. In that case we can daily shutdown the kafka-node which is running on virtual machine and proceed with archiving the kafka topic-files. On the Virtual Machine there would run the netbackup agent, therefore we need to open the ports  [nbuonline2.deutsche-boerse.de|http://nbuonline2.deutsche-boerse.de/] 13724 and 1556 to the netbackup-server

Netbackup-Team would provide us some scripts to trigger the backup and restore the proper files. 

That all the communication between the kafka-broker, kafka-zookeeper and the additional VM can work properly we would recommend to open a port range between these hosts 

for example: 13000-17000, in that case we should also think about a proper port-convention? how we are using it currently for application´s and databases? will have a chat with [~wm282] about it. 

[~fp407] will provide me a list until tomorrow, how many ports we will need for each kafka-setup 

 

 ","14/Jan/21 09:47;fp407;To perform a consistent backup, there seem to be only 2 options:

*1. Cluster shutdown*
Complete shutdown of the kafka cluster, which we cannot afford in the long run, when kafka becomes centre of component communications.

*2. ""scraping method""* 
We would use a process which would connect to kafka periodically (e.g. in 60 min periods) to request data, stored these data in a file and back it up.

Data would be requested based on either
- timestamps: timestamps are ""fuzzy"", which means, that data in ""the beggining"" and ""the end"" of the interval would be repeated), but Kafka should be able to cope with that if records keys are defined properly
- last backed-up offset - kafka stores this information internally (we must trust kafka here not to lose this info) - this is probably the better way

*Data store format and restore*

Since data in the topics is in ""google protocol buffers"", it should be stored in the same way in the files (serialized). 
We will need another mechanism for restored which is able to read the data from files and feed them into kafka.","25/Jan/21 12:48;rehapav;Implement proof of concept for the backup based on the proposal from [~fp407]14/1 at 9:47.

Waiting for VMs

Waiting for deployment scripts","28/Apr/21 22:01;nz893;Agree, the first option is nonsense due Kafka use case is real time solution. 

2. For the 'scrapping method' we can
a) Write custom consumer which will get data from a topic an save them into file(s).
b) Install Schema Registry with Kafka Connect to do same as above (but automated way with more possibilities to do future). With Kafka Connect we can save data to AWS S3 or files. 

Both solutions has its own drawbacks. I prefer choice b since it's easier to manage it and in the end it's more reliable solution. Also, Schema Registry and Kafka Connect can increase Kafka usability.  The drawback is Schema Registry needs to upgrade, because *Protobuf *is supported from version Confluent Kafka 5.5.0 [https://www.confluent.io/blog/confluent-platform-now-supports-protobuf-json-schema-custom-formats/]. 

For the Kafka upgrade I created another ticket - https://jira.deutsche-boerse.com/browse/M7P-8187 and https://jira.deutsche-boerse.com/browse/SYSENGINT-640. 

In another words, first should be done Kafka Upgrade and then Kafka Backup strategy implemented.","03/Sep/21 09:37;op211;Taken out of current sprint. Need to be put into new sprint again later on.",,,,,,,,,,,,,,,,,
VM request for Stalker application,M7P-5621,92351,92671,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,nn481,nn481,nn481,20/Feb/20 14:16,22/Apr/20 15:06,16/Sep/21 14:11,20/Apr/20 11:16,,7tops_Sprint5,,,,,,,,M7PRODOPS,,,,,,,"I would like to ask for VM for SYT1 env for Stalker app:
Parameters it should have:
1) 1CPU
2) 2GB RAM (1G RAM for application + RAM for system)
3) 40GB disk space on separate partition for Stalker's output
4) 20GB disk space for system/apps
5) OS: RHEL 7.6
6) software: AZUL-JRE8
7) tomcat user as usual
8) possible AMQP network connection to m7shrdintebha1:50700,m7shrdintebha3:50700
9) possible HTTPS connection to elasticsearch-ingest.energy.svc.dbgcloud.io:443
5) hostname: m7shrdsyt1stlkr1
 ",,fj021,iu252,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Feb/20 09:41;iu252;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/80856/screenshot-1.png",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48038400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx50v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92351,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,true,"20/Feb/20 14:35;iu252;[~nn481] in which network should we install/request this new VM?
Same as m7shrdsyt1apa1?","20/Feb/20 17:31;iu252;[~nn481], can you please provide more details regarding this new tool.
Will this app stay in syt1 only or is it going to propagate to prod one day?
Why it has to be on a dedicated VM and can't go together with ENQ?","21/Feb/20 08:57;nn481;[~iu252] I think that m7shrdsyt1apa1 network is fine.

One day this app should run on prod as well. The app is connected to RMQ and collects (in/out) messages to disk and Elastic so one day we can disable this logging in Core.
We don't want this app to interfere with ENQ or other SW component, that is the reason why I have requested a dedicated VM.","21/Feb/20 12:09;iu252;[~nn481] we (TechOps) decided to provide a new shared VM for systemtest:

hostname: m7shrdintestk1 
disk: 100GB

I'll request it.","21/Feb/20 12:29;iu252;Requested VM:


{noformat}
Hello everybody,


@VM_Approval: please, approve these VM´s creation for M7P-5621

Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/Shared Test Internal(Systest 1++2 Acc)	M7shrdintestk1	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	1	2 GB	100 GB	Clustdmzlxeq	RHEL7	M7P-5621	TEST	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Please also enable hotplug for vCPU and vRAM.

In case of additional questions, please contact me.


Thank you in advance.
Kind regards,
Alexander 

{noformat}
","27/Feb/20 09:41;iu252;Requested ip-address (NSR: 7031107)
 !screenshot-1.png! ","27/Feb/20 09:42;iu252;I'll start with os installation.","02/Mar/20 14:53;iu252;os installed.","02/Mar/20 14:59;iu252;[~nn481], to install tomcat server software and setup tomcat user i need Stalker-role in our automation deployment repository.
Do you have something already prepared?
Do you have already information about RabbitMQ connectivity, to which host/which port? I'd like to test the connectivity, maybe we need a firewall request (which can take few days).
","03/Mar/20 12:43;fj021;Hello [~iu252] ,

 

I added you to [~nn481] pending PRs about Stalker. ( [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/561] [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1417] )

As far as I know that should be enough ?

 

For the RMQ connectivity with Syt1, it should be :
||Protocol||Node||Bound to||Port||
|amqp|shrd-syt1-apa-amq1@m7shrdsyt1amq1|0.0.0.0|50700|
|amqp|shrd-syt1-apa-amq3@m7shrdsyt1amq3|0.0.0.0|50700|
|amqp|shrd-syt1-apa-amq5@m7shrdsyt1amq5|0.0.0.0|50700|
|amqp|shrd-syt1-apa-amq7@m7shrdsyt1amq7|0.0.0.0|50700|
|amqp|shrd-syt1-apa-amq9@m7shrdsyt1amq9|0.0.0.0|50700|

 

Or at least, that would be my guess since that's the RMQ set up used on SYT1.

 

Hope this helps !","03/Mar/20 14:20;iu252;Thanks, [~fj021]!

I've checked the connectivity from stalker-vm to rabbit server:


{noformat}
[root@m7shrdintestk1 ~]# telnet m7shrdsyt1amq1 50700
Trying 10.139.59.222...
Connected to m7shrdsyt1amq1.
Escape character is '^]'.



[root@m7shrdintestk1 ~]# telnet m7shrdsyt1amq3 50700
Trying 10.139.59.71...
Connected to m7shrdsyt1amq3.
Escape character is '^]'.



[root@m7shrdintestk1 ~]# telnet m7shrdsyt1amq5 50700
Trying 10.139.58.167...
Connected to m7shrdsyt1amq5.
Escape character is '^]'.



[root@m7shrdintestk1 ~]# telnet m7shrdsyt1amq7 50700
Trying 10.139.58.166...
Connected to m7shrdsyt1amq7.
Escape character is '^]'.
AMQP    Connection closed by foreign host.



[root@m7shrdintestk1 ~]# telnet m7shrdsyt1amq9 50700
Trying 10.139.58.165...
Connected to m7shrdsyt1amq9.
Escape character is '^]'.

[root@m7shrdintestk1 ~]
{noformat}
","03/Mar/20 15:00;iu252;
User tomcat created, java installed:

{noformat}
[tomcat@m7shrdintestk1 ~]$ ls -l /shrd/
total 20
drwxr-xr-x 3 tomcat tomcat  4096 Mar  2 08:01 logs
drwx------ 2 tomcat tomcat 16384 Mar  2 08:01 lost+found
[tomcat@m7shrdintestk1 ~]$ java -version
openjdk version ""1.8.0_202""
OpenJDK Runtime Environment (Zulu 8.36.0.2-SA-linux64) (build 1.8.0_202-b05)
OpenJDK 64-Bit Server VM (Zulu 8.36.0.2-SA-linux64) (build 25.202-b05, mixed mode)
[tomcat@m7shrdintestk1 ~]$

{noformat}
","03/Mar/20 15:03;iu252;Connection to elasticsearch:

{noformat}
[tomcat@m7shrdintestk1 ~]$ telnet elasticsearch-ingest.energy.svc.dbgcloud.io 443
Trying 10.115.103.231...
Connected to elasticsearch-ingest.energy.svc.dbgcloud.io.
Escape character is '^]'.

^C^C^CConnection closed by foreign host.
[tomcat@m7shrdintestk1 ~]$
{noformat}
","03/Mar/20 15:05;iu252;[~nn481], [~fj021] pls check if something is missing. Thanks.","03/Mar/20 15:09;iu252;Extended file system for /shrd:


{noformat}
[root@m7shrdintestk1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   9   0 wz--n- <99.51g <73.93g
[root@m7shrdintestk1 ~]# lvextend -r -L +40g /dev/mapper/rootvg-lv_shrd
  Size of logical volume rootvg/lv_shrd changed from 1.00 GiB (256 extents) to 41.00 GiB (10496 extents).
  Logical volume rootvg/lv_shrd successfully resized.
resize2fs 1.42.9 (28-Dec-2013)
Filesystem at /dev/mapper/rootvg-lv_shrd is mounted on /shrd; on-line resizing required
old_desc_blocks = 1, new_desc_blocks = 6
The filesystem on /dev/mapper/rootvg-lv_shrd is now 10747904 blocks long.

[root@m7shrdintestk1 ~]# vgs
  VG     #PV #LV #SN Attr   VSize   VFree
  rootvg   1   9   0 wz--n- <99.51g <33.93g
[root@m7shrdintestk1 ~]# df -h
Filesystem                              Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-lv_root              7.6G  1.7G  5.5G  24% /
devtmpfs                                899M     0  899M   0% /dev
tmpfs                                   910M     0  910M   0% /dev/shm
tmpfs                                   910M   34M  877M   4% /run
tmpfs                                   910M     0  910M   0% /sys/fs/cgroup
/dev/sda1                               477M  154M  298M  35% /boot
/dev/mapper/rootvg-lv_var               1.9G  849M  973M  47% /var
/dev/mapper/rootvg-lv_tmp               1.9G   14M  1.8G   1% /tmp
/dev/mapper/rootvg-lv_varlog            1.9G   21M  1.8G   2% /var/log
tmpfs                                   182M     0  182M   0% /run/user/1984
/dev/mapper/rootvg-lv_opt_ds_agent      2.0G   18M  1.8G   1% /opt/ds_agent
/dev/mapper/rootvg-lv_var_opt_ds_agent  3.9G   17M  3.6G   1% /var/opt/ds_agent
/dev/mapper/rootvg-lv_shrd               41G  5.8M   39G   1% /shrd
/dev/mapper/rootvg-lv_shrd_logs         976M  2.6M  907M   1% /shrd/logs
tmpfs                                   182M     0  182M   0% /run/user/501864
[root@m7shrdintestk1 ~]#
{noformat}
","09/Mar/20 11:01;iu252;[~nn481], can we close this ticket?",,,,,,,,,,,,
Flex SIMU reporting-engine - reporting-security.xml,M7P-5620,92348,92285,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,iu252,ef759,ef759,20/Feb/20 13:32,04/Mar/20 15:12,16/Sep/21 14:11,20/Feb/20 14:57,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,Can you please provide me reporting-security.xml file used in reporting-engine for Flex SIMU.,,ef759,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Feb/20 14:03;iu252;reporting-security - Copy.xml;https://jira.deutsche-boerse.com/secure/attachment/80591/reporting-security+-+Copy.xml","20/Feb/20 14:57;cs687;reporting-security.xml.xml;https://jira.deutsche-boerse.com/secure/attachment/80594/reporting-security.xml.xml",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49507200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx507:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92348,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Feb/20 14:03;iu252;[~ef759], here is the requested file from FLEX SIMU REP.

I changed the passwords [^reporting-security - Copy.xml]  in the file.",,,,,,,,,,,,,,,,,,,,,,,,,,,
Flex SIMU comxerv_env.properties,M7P-5617,92322,92285,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,pd122,ef759,ef759,19/Feb/20 17:03,04/Mar/20 15:12,16/Sep/21 14:11,19/Feb/20 17:32,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,Can you please provide me property file comxerv_env.properties with the configuration for Flex SIMU.,,ef759,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49593600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx4v3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92322,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/20 17:27;pd122; 

deployed 9 Jan 2020 15:51, (passwords edited out just in case)
{code:java}
tomcat@m7flexsimum7b1:[/flex]$ cat flex-simu-enq1/tomcat/lib/comxerv_env.properties 
##########################################
# Exchange setup
##########################################
platform=epex
comxerv.exchangeId=EPEX
comxerv.remote.exchangeId=XSOB
#####################################################
# Master-Slave node id configuration
#####################################################
node_id=flex-simu-enq1
#####################################################
# timezone configuration for gui time interpretation
#####################################################
configured_time_zone=CET
#####################################################
# JNDI resources configuration
#####################################################
jndi.resource.ref=true
#####################################################
# Session Factory configuration
#####################################################
hibernate.show_sql=false
hibernate.default_schema=m7tflexsimum7b
hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
#####################################################
# Timers configuration
#####################################################
timer.refDataActivation=30 0 15 * * ?
timer.createFile=10 */5 * * * ? 2099
timer.createOrderHistoryFile=15 */5 * * * ? 2099
###########################################
# Reporting configuration
###########################################
reporting.url=http://m7shrdexterep1:62110/reporting-engine-app/remoting-flex/RemoteService,http://m7shrdexterep2:62110/reporting-engine-app/remoting-flex/RemoteService
reporting.username=remoteuser
reporting.password=...
reporting.platform=flex
###########################################
# Mail Setup
###########################################
mail.host=englobmail1,englobmail2
mail.port=25,25
mail.from.address=flexsimu@m7-test.deutsche-boerse.com
mail.sms.from.address=
mail.imap.host=
mail.user.name=flexsimu@m7-test.deutsche-boerse.com
mail.user.password=...
#####################################################
# LDAP configuration
####################################################
ldap.hostname=m7testldap2,m7testldap1
ldap.port=636,636
ldap.useSsl=true
ldap.trustStorePath=ldapkeystore.jks
ldap.bindDn=uid\=flex-app-simu-adm,ou\=simu,ou\=flex-app,o=M7,dc\=energy,dc\=test
ldap.bindPassword=...
ldap.userIdentityTemplate=uid\=%s,ou\=simu,ou\=flex-app,o=M7,dc\=energy,dc\=test
#####################################################
# Admin GUI user / pass
####################################################
inquiry.amqp.request.username=tm-admingui1
inquiry.amqp.request.password=...
############################################
# AMQP Setup - Both same inst SOB, two users
############################################
# User = tech user created broker
m7.core.amqp.adresses=m7shrdextebha1:50110,m7shrdextebha3:50110
m7.core.amqp.vhost=app
# User = admin (comxerv) user
amqp.admin.user=comxerv
amqp.admin.password=...
amqp.vhost=app
# TODO: fix duplicities in app source code (amqp.admin.user always == amqp.user)
amqp.username=${amqp.admin.user}
amqp.password=${amqp.admin.password}
amqp.uri=amqp://${amqp.username}:${amqp.password}@m7shrdextebha1:50110/app,amqp://${amqp.username}:${amqp.password}@m7shrdextebha3:50110/app
amqp.admin.addresses=m7shrdextebha1:52110,m7shrdextebha3:52110
amqp.adminUri=http://comxerv:${amqp.admin.password}@m7shrdextebha1:52110/app,http://comxerv:${amqp.admin.password}@m7shrdextebha3:52110/app
amqp.queue.expiration.timeout=360000
amqp.message.expiration.timeout=180000
############################################
# General items
############################################
#spring.profiles.active=default,remote-sob
###########################################
# Host Setup
###########################################
m7.trading.faces.url=https://flexsimu1.epex.m7.deutsche-boerse.com:60110/intraday/faces/
mailReplyTo=no-reply@deutsche-boerse.de
# This endpoint is used for inquiry versions up to 6.6.92
m7.h2h4u.endpoint=http://m7flexsimum7b1:8123/hub-to-hub
# This endpoint is used for inquiry versions from 6.6.93
m7.h2h4u.api.endpoint=http://m7flexsimum7b1:8123
# Environment name - used in change password emails
environment=SIMU
# Logo
primaryLogo=/static/logo.png
secondaryLogo=/static/logo.png
# feature config
m7.tradingSchedule.sameDeliveryAreaTradingEnabled=true
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,
Setup password policy in LDAP,M7P-5609,92278,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Not a Bug,pd122,ax460,ax460,19/Feb/20 09:57,13/Jan/21 11:31,16/Sep/21 14:11,17/Dec/20 13:38,,7tops_sprint108,,,,uknown,,,,7tops,M7PRODOPS,,,,,,Setup password policy (remmeber last 6 password) in LDAP in all M7T environments (except M7C EPEX),,ax460,dp007,ne232,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23500800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzyobr:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92278,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Feb/20 16:44;pd122;Unfortunatelly M7T and M7C share the LDAP tree.  These are all M7 test environments (except M7A):
{code:java}
ou=acct,ou=cltx-cob,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-cob,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-cob,o=M7,dc=energy,dc=test

ou=acct,ou=cltx-clt,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-clt,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-clt,o=M7,dc=energy,dc=test

ou=acct,ou=cltx-fis,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-fis,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-fis,o=M7,dc=energy,dc=test

ou=acut,ou=elts-app,o=M7,dc=energy,dc=test
ou=cute,ou=elts-app,o=M7,dc=energy,dc=test
ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
ou=lipa,ou=elts-app,o=M7,dc=energy,dc=test
ou=simu,ou=elts-app,o=M7,dc=energy,dc=test

ou=simu,ou=flex-app,o=M7,dc=energy,dc=test

ou=cute,ou=hupx-app,o=M7,dc=energy,dc=test
ou=asim,ou=hupx-app,o=M7,dc=energy,dc=test
ou=simu,ou=hupx-app,o=M7,dc=energy,dc=test

ou=simu,ou=nore-app,o=M7,dc=energy,dc=test

ou=lipa,ou=plpx-app,o=M7,dc=energy,dc=test
ou=simu,ou=plpx-app,o=M7,dc=energy,dc=test

ou=cute,ou=xsop-app,o=M7,dc=energy,dc=test
ou=asim,ou=xsop-app,o=M7,dc=energy,dc=test
ou=simu,ou=xsop-app,o=M7,dc=energy,dc=test

ou=lipa,ou=xrpm-app,o=M7,dc=energy,dc=test
ou=simu,ou=xrpm-app,o=M7,dc=energy,dc=test

ou=dst1,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=ate1,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=ate2,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=ate5,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=show,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=syt2,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
ou=syt4,ou=shrd-apa,o=M7,dc=energy,dc=test

ou=syt1,ou=shrd-apb,o=M7,dc=energy,dc=test
ou=syt2,ou=shrd-apb,o=M7,dc=energy,dc=test

ou=syt2,ou=shrd-apc,o=M7,dc=energy,dc=test
ou=syt1,ou=shrd-apc,o=M7,dc=energy,dc=test{code}
 

These are EPEX envs:
{code:java}
ou=cute,ou=epex-app,o=M7,dc=energy,dc=test
ou=tsim,ou=epex-app,o=M7,dc=energy,dc=test
ou=asim,ou=epex-app,o=M7,dc=energy,dc=test 
{code}
 My understanding is that those should not have the new policy applied to them.  [~ax460], can you confirm, pls?","25/Feb/20 10:01;ax460;[~pd122] yes exactly, epex environments should not have this policy since Capacity M7 is not ready to support that. ","25/Feb/20 11:05;dp007;[~pd122]: Please delete:
ou=acct,ou=cltx-cob,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-cob,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-cob,o=M7,dc=energy,dc=test

ou=acct,ou=cltx-clt,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-clt,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-clt,o=M7,dc=energy,dc=test

ou=acct,ou=cltx-fis,o=M7,dc=energy,dc=test
ou=cute,ou=cltx-fis,o=M7,dc=energy,dc=test
ou=simu,ou=cltx-fis,o=M7,dc=energy,dc=test

ou=simu,ou=nore-app,o=M7,dc=energy,dc=test","25/Feb/20 12:07;pd122;[~dp007] specified LDAP sub-trees were removed.","25/Feb/20 12:12;pd122;Currently existing password policies for *o=M7,dc=energy,dc=test* sub-tree including password history setting if present:
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt2\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt2,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt1\2Cou\3Dshrd-apb\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt1,ou=shrd-apb,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt2\2Cou\3Dshrd-apb\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt2,ou=shrd-apb,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt1\2Cou\3Dshrd-apc\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt1,ou=shrd-apc,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt2\2Cou\3Dshrd-apc\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt2,ou=shrd-apc,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 3
dn: cn=cn\3DnsNoPwPolicyEntry\2Cou\3Dsyt3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=syt3,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Dctpb\2Cou\3Delts-app\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ctpb,ou=elts-app,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 6
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date1\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate1,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 10
dn: cn=cn\3DnsExpTestPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
passwordInHistory: 5
dn: cn=cn\3DnsNoExpPwPolicyEntry\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,o=M7,dc=energy,dc=test
passwordInHistory: 0
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordInHistory: 5
dn: cn=cn\3DnsNoPwPolicyEntry\2Cou\3Date3\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate3,ou=shrd-apa,o=M7,dc=energy,dc=test
{code}
 

 ","29/May/20 16:44;pd122;New PP objects created in ou=shrd-apc,o=M7,dc=energy,dc=test:
{code:java}
dn: cn=nsPwPolicyContainer,ou=shrd-apc,o=M7,dc=energy,dc=test
objectClass: top
objectClass: nsContainer
cn: nsPwPolicyContainer{code}
{code:java}
dn: cn=""cn=nsPwPolicyEntry,ou=shrd-apc,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=shrd-apc,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: ldapsubentry
objectclass: passwordpolicy
passwordHistory: on
passwordInHistory: 6{code}
{code:java}
dn: cn=""cn=nsPwTemplateEntry,ou=shrd-apc,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=shrd-apc,o=M7,dc=energy,dc=test
objectclass: top
objectclass: extensibleObject
objectclass: costemplate
objectclass: ldapsubentry
cosPriority: 1
pwdpolicysubentry: cn=""cn=nsPwPolicyEntry,ou=shrd-apc,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=shrd-apc,o=M7,dc=energy,dc=test{code}
{code:java}
dn: cn=m7tpwdpolicy_cos,ou=shrd-apc,o=M7,dc=energy,dc=test
objectclass: top
objectclass: LDAPsubentry
objectclass: cosSuperDefinition
objectclass: cosPointerDefinition
cosTemplateDn: cn=""cn=nsPwTemplateEntry,ou=shrd-apc,o=M7,dc=energy,dc=test"",cn=nsPwPolicyContainer,ou=shrd-apc,o=M7,dc=energy,dc=test
cosAttribute: pwdpolicysubentry default operational-default{code}","29/May/20 16:51;pd122;Same objects (policy) were now set up for:
 - ou=shrd-apa,o=M7,dc=energy,dc=test
 - ou=shrd-apb,o=M7,dc=energy,dc=test","01/Jul/20 14:58;pd122;ou=shrd-apb,o=M7,dc=energy,dc=test

ou=shrd-apc,o=M7,dc=energy,dc=test

were removed during LDAP migration, and new policy objects removed from ou=shrd-apa,o=M7,dc=energy,dc=test

New policy was recreated at o=M7,dc=energy,dc=test level","11/Aug/20 11:48;ne232;Requirement unchanged in new access control standard.","17/Dec/20 13:36;pd122;The setting is included in the approved password policy (in -M7P-7052-) and will be rolled out on all external test and production environments gradually after the customer (EPEX) completes testing.",,,,,,,,,,,,,,,,,,
ICS User Set Up (New BG & User for Catrina user),M7P-5607,92269,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,tj898,qm925,qm925,19/Feb/20 08:19,17/Dec/20 15:21,16/Sep/21 14:11,02/Mar/20 13:35,,6.9.76,7Tops_Sprint1,,,,,,02/Mar/20 00:00,M7PRODOPS,,,,,,,"Request for a set-up of one (1) Production user for CATRINA

Participant Name/Company: Trailstone Renewables GmbH 

Balancing Group EIC/EAN/GLN Code: 11X0-0000-0518-U

Email address to be added to account: help@trailstonegroup.com

Assignment of Products/Borders: CH-DE; CH-FR

Additional Note: Please provide the details to the clients (user, certificate, etc.) only after confirmation from Account Management. *The foreseen go-live in Prod is 02.03.2020, however it needs to be confirmed.*",,qm925,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5715,M7ACM-958,,,,,"26/Feb/20 15:40;tj898;M7P-5607.zip;https://jira.deutsche-boerse.com/secure/attachment/80824/M7P-5607.zip","27/Feb/20 10:57;tj898;M7P-5607_ACCOUNTDETAILS.txt;https://jira.deutsche-boerse.com/secure/attachment/80865/M7P-5607_ACCOUNTDETAILS.txt","26/Feb/20 15:40;tj898;PASSWORD.txt;https://jira.deutsche-boerse.com/secure/attachment/80825/PASSWORD.txt","27/Feb/20 10:55;tj898;image-2020-02-27-10-55-20-540.png;https://jira.deutsche-boerse.com/secure/attachment/80862/image-2020-02-27-10-55-20-540.png",,,,,,,,,,,,sw455,,,,,,,,,,,,,4.4778948887E11,,,,,,,,,Capacity Service (ICS) User Set Up or Modification,,,,,,,,,,47433600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx27r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,"{""issueId"":92269,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"24/Feb/20 17:00;tj898;Certificate/Password in zip file and encrypted password","25/Feb/20 10:21;tj898;Status:
 * BG created
 * User created
 * Certificate attached

To be finalized today.","26/Feb/20 15:50;tj898;email defined as our m7-si mailbox for testing with test client. to be changed in the final stage before delivery","27/Feb/20 10:55;tj898;Connectivity test performed successfully (using Leased Line IP, since it's ran in DBAG network):

!image-2020-02-27-10-55-20-540.png!","27/Feb/20 10:57;tj898;Attached file with the account details:

[^M7P-5607_ACCOUNTDETAILS.txt]","27/Feb/20 10:59;tj898;Reverted the email for the account to the final setting.

User account disabled until go live date.","27/Feb/20 12:01;tj898;As discussed with Simona, we will wait now until the contractual document is signed. Will set the ticket to Waiting state,","12/Mar/20 17:56;qm925;Please provide the information to the clients to help@trailstonegroup.com ","16/Mar/20 12:24;tj898;Contact phone:

0044 7789 488870",,,,,,,,,,,,,,,,,,,
"Add ""Confidential"" label to the SLA reports",M7P-5603,92239,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,dp007,pn508,pn508,18/Feb/20 12:42,03/Nov/20 11:06,16/Sep/21 14:11,14/Oct/20 11:59,,7tops_sprint103,,,,,,,,7tops_comm,,,,,,,"As a Part of Information security standard, we have to label physical documents. Please add Confidential label to SLA reports in:

[file:///S:/Energie/Prod_DEVELOP/003%20Business%20Operations/Applications/M7/]

for all customers

Discuss the classification with [~ne232] or [~rl336]",,dp007,pn508,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,label placed on the bottom of the frontpage,,,,,,,,,,,,,,,,,,,,,,,,29116800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-4014,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzygqv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 103,7tops Sprint 104,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92239,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Oct/20 11:23;dp007;ACM (Jutta) confirmed the label: _Hi Martin, yes, you have to label it and the label should be confidential._","14/Oct/20 11:58;dp007;Label applied on the bottom of the frontpage.",,,,,,,,,,,,,,,,,,,,,,,,,,
Login of a user on the expiry date shifts the passwordExpirationTime in LDAP by 24 hours since the login time,M7P-5598,92219,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Fixed,pd122,nn236,nn236,17/Feb/20 15:18,05/Jan/21 14:01,16/Sep/21 14:11,12/Mar/20 17:54,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,,"Login of a user on the expiry date shifts the passwordExpirationTime in LDAP by 24 hour since the login time.

Steps and actual results:
 # Create new user M7USRJD3 (14/02/2020 18:03 CET) - ok
 # On expiry date (17/02/2020), check the passwordExpirationTime in LDAP - ok
 !screenshot-1.png!
 # On expiry date, log in into CT (17/02/2020 10:34 CET) - ok
 # Check if passwordExpirationTime in LDAP has changed - it was changed to the login date + 24 hours - *not ok*
 !screenshot-2.png!

 

Please investigate why this is happening and correct the LDAP settings so that a login does not postpone the passwordExpirationTime in LDAP.

*Note*: the shift did not happen when a newly created user logged in on the date when he was created.",,jv861,nn236,pd122,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5076,M7P-5234,,,,,"03/Mar/20 17:14;nn236;image-2020-03-03-17-13-58-711.png;https://jira.deutsche-boerse.com/secure/attachment/81027/image-2020-03-03-17-13-58-711.png","09/Mar/20 12:03;nn236;image-2020-03-09-12-02-58-183.png;https://jira.deutsche-boerse.com/secure/attachment/81235/image-2020-03-09-12-02-58-183.png","12/Mar/20 09:38;nn236;image-2020-03-12-09-38-23-363.png;https://jira.deutsche-boerse.com/secure/attachment/81425/image-2020-03-12-09-38-23-363.png","17/Feb/20 15:29;nn236;screenshot-1.png;https://jira.deutsche-boerse.com/secure/attachment/80483/screenshot-1.png","17/Feb/20 15:29;nn236;screenshot-2.png;https://jira.deutsche-boerse.com/secure/attachment/80484/screenshot-2.png",,,,,,,,,,,sw455,,,,,,,,"By disabling *passwordWarning* (setting it to 0), all authentication attempts after *passwordExpirationTime* will fail regardless of the time of the previous successful authentication.  No password expiry warning will be ever sent.",,,,,,,,,,,,,,,,,,,,,,,,47692800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-7507,,,,,,,,,,,,,17/Feb/20 15:18,,[],,,,,,,,,,,M7T,,,,"2|hzpr87:",9223372036854775807,,,,No,,,,,,,,,,"When user tries to authenticates after its password has expired and had not authenticated at least *passwordWarning* seconds before that, to ensure the warning is sent the *passwordExpirationTime* will be extended by *passwordWarning*, the user with be successfully authenticated and the warning sent. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,passwordWarning set to default (86400s) - 1 day,,,,,,,,,,"{""issueId"":92219,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/20 14:51;pd122;{code:java}
dn: uid=M7USRJD3,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
pwdpolicysubentry: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test{code}
{code:java}
dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordMaxFailure: 3
passwordResetFailureCount: 3600
passwordStorageScheme: sha256
passwordGraceLimit: 0
passwordCheckSyntax: on
passwordMin8bit: 0
passwordMinTokenLength: 3
passwordMinUppers: 1
passwordMinCategories: 1
passwordInHistory: 5
passwordMinLowers: 1
passwordWarning: 86400
passwordMinSpecials: 1
passwordMinDigits: 1
passwordExp: on
passwordMinAlphas: 0
passwordMinLength: 8
passwordMaxAge: 259200
passwordMaxRepeats: 0
passwordLockout: on
passwordChange: on
passwordMinAge: 0
passwordMustChange: off
objectClass: ldapsubentry
objectClass: passwordpolicy
objectClass: top
cn: cn=nsPwPolicyEntry,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test{code}
That would mean the password expires 3 days after its last modified.","18/Feb/20 15:39;pd122;{code:java}
[17/Feb/2020:10:34:26 +0100] conn=1369166 fd=135 slot=135 SSL connection from 10.136.149.248 to 10.136.140.252
[17/Feb/2020:10:34:26 +0100] conn=1369166 TLS1.2 128-bit AES-GCM
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=0 BIND dn="""" method=128 version=3
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=0 RESULT err=0 tag=97 nentries=0 etime=0 dn=""""
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=1 SRCH base=""ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test"" scope=2 filter=""(&(objectClass=*)(uid=M7USRJD3))"" attrs=""uid""
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=1 RESULT err=0 tag=101 nentries=1 etime=0 notes=U
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=2 BIND dn=""uid=M7USRJD3,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test"" method=128 version=3
[17/Feb/2020:10:34:26 +0100] conn=1369166 op=2 RESULT err=0 tag=97 nentries=0 etime=0 dn=""uid=m7usrjd3,ou=ate4,ou=shrd-apa,o=m7,dc=energy,dc=test""{code}
{code:java}
time: 20200217103426
dn: uid=M7USRJD3,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
changetype: modify
replace: passwordExpirationTime
passwordExpirationTime: 20200218093426Z
-
replace: passwordExpWarned
passwordExpWarned: 1{code}
Looks like there was a connection from *m7shrdinteweb1* with bind dn  *uid=M7USRJD3,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test*  at 17/Feb/2020:10:34:26 CET that triggered 2 changes:
 * - passwordExpirationTime modification (to 20200218093426Z)
 * - passwordExpWarned set to 1","26/Feb/20 15:43;pd122;Verified with Juergen Schneider: *passwordExpirationTime* is not native LDAP attribute, neither is there any LDAP mechanism (e.g. hook/plugin) that would inject it into the individual entries during the app access.","26/Feb/20 15:56;pd122;Interesting bits:

*passwordWarning*
 * specifies in the number of seconds before a password is to expire that the server will start sending a warning(EXPIRING CONTROL) on their next LDAP operation . If a password is expired but the warning was not sent, the server will “send the warning”, then it will add the warning value to the current expiration time
 * current setting of 86400 (1 day) is the default
 * it cannot be disabled

This would explain observed behavior, wouldn't it?","27/Feb/20 10:11;pd122;Tried to disable *passwordWarning* for ate4 (set it to 0):
{code:java}
[pd122@m7testldap1 ~]$ ldapsearch -LLL -o ldif-wrap=no -x -h m7testldap1 -D ""cn=Directory Manager"" -W -b ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test ""(&(objectclass=ldapsubentry)(objectclass=passwordpolicy))"" passwordWarning

dn: cn=cn\3DnsPwPolicyEntry\2Cou\3Date4\2Cou\3Dshrd-apa\2Co\3DM7\2Cdc\3Denergy\2Cdc\3Dtest,cn=nsPwPolicyContainer,ou=ate4,ou=shrd-apa,o=M7,dc=energy,dc=test
passwordWarning: 0{code}
[~nn236] can you test, please?","03/Mar/20 17:16;nn236;Retest:

Steps and actual results:
 # Create new user M7USRJD6 (09/03/2020 12:01:520 PM CET) - ok
 !image-2020-03-09-12-02-58-183.png!
 # Configured x days (i.e. 1 day) before expiry check if password reminder email was received - it was - OK
 # On expiry date *before* the expiry time (12/03/2020 12:01:52 PM CET), check the passwordExpirationTime in LDAP
 # Check if password expiry email was received - the email wasn't received (checked at 12/03/2020 9:35 CET). *Update:* According to [~pd122] the mailserver was down yesterday and today which was the reason for the expiry email not being received on time. The email was received later on today after the mailserver restart, see below. - OK
 # Log in into CT (12/03/2020 09:37 CET) - ok
 # Check if passwordExpirationTime in LDAP has changed - the time has not changed - ok
 !image-2020-03-12-09-38-23-363.png!

Password reminder email:
{quote}-----Original Message-----
 From: tomcat@m7shrdate4apa1.deutsche-boerse.de <tomcat@m7shrdate4apa1.deutsche-boerse.de> 
 Sent: 11 March 2020 04:20
 To: Jana Dullova <jana.dullova@clearstream.com>
 Subject: Your password will expire in 1 days

Login ID: M7USRJD6
 Password Expiration Date: 2020-03-12
 This notice has been sent to you because your password will expire soon.
 Please change your password at your earliest convenience or reset your password [https://10.136.148.36:60400/intraday/faces/public/forgotPasswdReq.xhtml] .{quote}

Password expiry email:
{quote}
-----Original Message-----
 From: tomcat@m7shrdate4apa1.deutsche-boerse.de <tomcat@m7shrdate4apa1.deutsche-boerse.de>
 Sent: 12 March 2020 04:20
 To: Jana Dullova <jana.dullova@clearstream.com>
 Subject: Your password expires today

Login ID: M7USRJD6
 Password Expiration Date: 2020-03-12
 This notice has been sent to you because your password expires today.
 Please change your password at your earliest convenience or reset your password [https://10.136.148.36:60400/intraday/faces/public/forgotPasswdReq.xhtml] .
{quote}

Retest on ATE4, backend version 6.9.29;
ComTrader 6.8.50 2020-01-17T13:05:40Z
ENV: EPEX acceptance4
JRE: 1.8.0_201-b09, Webstart: N/A
JVM: Java HotSpot(TM) 64-Bit Server VM by Oracle Corporation
OS: Linux 4.4.0-169-generic amd64
196MB / 7125MB
EPEX m7-core-6.9.29-b0073bfee691e3232c08ebd5a7deed958450d6c7","12/Mar/20 10:23;jv861;Emails were sent by M7 according to logs:
https://kibana.energy.svc.dbgcloud.io/goto/4664de8a76ba968ec31b35cf060d1e25","12/Mar/20 16:46;nn236;Hi [~pd122] , the change in the configuration worked. I believe we can close this task :). Thanks for your help! J.

Note: I added a note for config to the ticket M7P-5235.","12/Mar/20 17:54;pd122;N/A",,,,,,,,,,,,,,,,,,,
Creating missing M7C DB for ATE1,M7P-5597,92216,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,17/Feb/20 14:45,04/Mar/20 15:12,16/Sep/21 14:11,27/Feb/20 08:46,,6.9.76,7Tops_Sprint1,,,,,,,M7PRODOPS,,,,,,,"h2. What ?

We need M7C DB instance to be created, and ports allocated to it ([~pd122] / [~iu252] as discussed, probably 26030) on m7testpdb1.deutsche-boerse.de and m7testpdb2.deutsche-boerse.de
h2. Why ?

We want to make M7C deployable by Ansible on ATE1. Right now it cannot connect to the DB.
h2. Additional information

Environment info : m7c-shrd-ate1-pdb-async

Schemas : m7shrdate1apa

Users :
 * m7shrdate1apa
 * uapp01m7shrdate1apa
 * (passwords in vault : [https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate1/db/m7shrdate1apa|https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate1/db/m7shrdate1apa)] )

Inventory PR for M7C ATE1 : [https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1578]

 

 ",,cs687,fj021,iu252,,,,,,,,,,,,,,,M7P-5117,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48988800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx49b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92216,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,true,"18/Feb/20 09:12;cs687;Be aware that the schema names changed for all M7-Env´s [~iu252], [~pd122], [~fj021]
So the right one would be:

{code:java}
Schemas : 
- m7cshrdate1m7b

Users:
- m7cshrdate1m7b
- uapp01m7cshrdate1m7b
 {code}

So we have unique identifier. 
M7 Trading starting with *m7t*
M7 Auction starting with *m7a*
M7 Capacity starting with *m7c*

We are using no apa´s anymore. For the cor-database we are ending with *m7b*
","18/Feb/20 09:34;iu252;Created vault-entries:
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7c/shrd/ate1/db/m7cshrdate1m7b1","18/Feb/20 09:42;iu252;PR request for the db-ports:

https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1593","19/Feb/20 08:31;iu252;created pull request:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1595","27/Feb/20 08:45;iu252;Cluster is up and running:


{noformat}
[root@m7testpdb1 ~]# patronictl -c /etc/patroni_m7cshrdate1async/config.yml list
+------------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster      |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+------------------+------------+---------------------+--------+---------+----+-----------+
| m7cshrdate1async | m7testpdb1 | 10.139.58.178:26030 | Leader | running |  8 |         0 |
| m7cshrdate1async | m7testpdb2 | 10.139.58.177:26030 |        | running |  8 |         0 |
+------------------+------------+---------------------+--------+---------+----+-----------+
[root@m7testpdb1 ~]#
{noformat}



{noformat}
-bash-4.2$ psql -p 26030
psql (11.5)
Type ""help"" for help.
postgres=# \l
                                               List of databases
      Name      |     Owner      | Encoding |   Collate   |    Ctype    |           Access privileges
----------------+----------------+----------+-------------+-------------+---------------------------------------
 m7cshrdate1cmi | m7cshrdate1cmi | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7cshrdate1cmi                   +
                |                |          |             |             | m7cshrdate1cmi=CTc/m7cshrdate1cmi    +
                |                |          |             |             | uapp01m7cshrdate1cmi=c/m7cshrdate1cmi+
                |                |          |             |             | udev01m7cshrdate1cmi=c/m7cshrdate1cmi
 m7cshrdate1m7b | m7cshrdate1m7b | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7cshrdate1m7b                   +
                |                |          |             |             | m7cshrdate1m7b=CTc/m7cshrdate1m7b    +
                |                |          |             |             | uapp01m7cshrdate1m7b=c/m7cshrdate1m7b+
                |                |          |             |             | uapp01m7cshrdate1rep=c/m7cshrdate1m7b+
                |                |          |             |             | udev01m7cshrdate1m7b=c/m7cshrdate1m7b
 m7cshrdate1rep | m7cshrdate1rep | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =Tc/m7cshrdate1rep                   +
                |                |          |             |             | m7cshrdate1rep=CTc/m7cshrdate1rep    +
                |                |          |             |             | uapp01m7cshrdate1rep=c/m7cshrdate1rep+
                |                |          |             |             | udev01m7cshrdate1rep=c/m7cshrdate1rep
 postgres       | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
 template1      | postgres       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres                          +
                |                |          |             |             | postgres=CTc/postgres
(6 rows)
postgres=#
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,
Broken SSL certificate chain for profile server exte1,M7P-5596,92213,90740,Sub-task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,rehapav,fp407,fp407,17/Feb/20 14:12,08/Jul/20 12:20,16/Sep/21 14:11,03/Mar/20 10:10,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,"Profile server exte1.profiles.m7.deutsche-boerse.com has a broken certificate chain:
{code:java}
michal@lusi-energy:~/git/forks/m7.comtrader$ openssl s_client -connect exte1.profiles.m7.deutsche-boerse.com:60100 -proxy webproxy.deutsche-boerse.de:8080
CONNECTED(00000005)
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktiengesellschaft, OU = Multi-Domain SSL, CN = exte1.profiles.m7.deutsche-boerse.com
verify error:num=20:unable to get local issuer certificate
verify return:1
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktiengesellschaft, OU = Multi-Domain SSL, CN = exte1.profiles.m7.deutsche-boerse.com
verify error:num=21:unable to verify the first certificate
verify return:1
---
Certificate chain
 0 s:C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktiengesellschaft, OU = Multi-Domain SSL, CN = exte1.profiles.m7.deutsche-boerse.com
   i:C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Organization Validation Secure Server CA
 1 s:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
   i:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
 2 s:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
 3 s:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
{code}
It should look like this (exte2):
{code:java}
michal@lusi-energy:~/git/forks/m7.comtrader$ openssl s_client -connect exte2.profiles.m7.deutsche-boerse.com:60100 -proxy webproxy.deutsche-boerse.de:8080
CONNECTED(00000005)
depth=2 C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
verify return:1
depth=1 C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
verify return:1
depth=0 C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktiengesellschaft, OU = Enterprise SSL Pro, CN = exte2.profiles.m7.deutsche-boerse.com
verify return:1
---
Certificate chain
 0 s:C = DE, postalCode = 65760, ST = Hessen, L = Eschborn, street = Mergenthalerallee 61, O = Deutsche Boerse AG, OU = Cash & Derivatives IT Operations, OU = Hosted by Deutsche Borse Aktiengesellschaft, OU = Enterprise SSL Pro, CN = exte2.profiles.m7.deutsche-boerse.com
   i:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
 1 s:C = GB, ST = Greater Manchester, L = Salford, O = Sectigo Limited, CN = Sectigo RSA Organization Validation Secure Server CA
   i:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
 2 s:C = US, ST = New Jersey, L = Jersey City, O = The USERTRUST Network, CN = USERTrust RSA Certification Authority
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
 3 s:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
   i:C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
{code}
 

 ",,fp407,pd122,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5476,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,37584000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx48n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Schmetterling Sprint 86,Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92213,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,M7P-5596,master,true,"17/Feb/20 14:16;fp407;Please re-check chain correctness of all profile servers (to avoid nasty surprises when server identity validation is activated in comtrader):
{code:java}
test:
profile-storage-primary=http://10.136.148.16:61400/shin-apa-ate1/services/
profile-storage-secondary=http://10.136.20.16:61400/shin-apa-ate1/services/

simu:
profile-storage-primary=https://exte1.profiles.m7.deutsche-boerse.com:60100/epex-app-asim/services/
profile-storage-secondary=https://exte2.profiles.m7.deutsche-boerse.com:60100/epex-app-asim/services/

prod:
profile-storage-primary=https://prod1.profiles.m7.deutsche-boerse.com:60000/epex-app-prod/services/
profile-storage-secondary=https://prod2.profiles.m7.deutsche-boerse.com:60000/epex-app-prod/services/
{code}
 ","17/Feb/20 17:17;pd122;Cause: m7shrdexteweb1:/shrd/ssl/sectigo_chain.pem (deployed Oct 21 2019 10:24) contains incorrect intermediate cert (SECTIGO, no COMODO)","17/Feb/20 18:29;pd122;The chain cert file is shared with other sites, it is not possible to change it without negative consequences.  New server certificate has been requested instead (ITSR #5B0108)","21/Feb/20 15:45;pd122;I have added previous (COMODO) intermediates
{code:java}
subject=C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Certification Authority
issuer=C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
notBefore=May 30 10:48:38 2000 GMT
notAfter=May 30 10:48:38 2020 GMT
{code}
{code:java}
subject=C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Organization Validation Secure Server CA
issuer=C = GB, ST = Greater Manchester, L = Salford, O = COMODO CA Limited, CN = COMODO RSA Certification Authority
notBefore=Feb 12 00:00:00 2014 GMT
notAfter=Feb 11 23:59:59 2029 GMT{code}
into the chain (on _m7shrdexteweb1:/shrd/ssl/sectigo_chain.pem_) and restarted the server. Looks good to me now.","21/Feb/20 17:02;pd122;Re production systems there seems to be no chain file installed at all.  Created it on all 6 nodes as well as PR [https://github.deutsche-boerse.de/dev/energy-mkt-shared/pull/593]  to update the config.  Needs re-deployment [~rehapav]. ","25/Feb/20 11:49;rehapav;registered into SERVICE-5476 ELTS PROD PatroniDB migration - there is a syngergy with Profile CT deployment","08/Jul/20 12:20;pd122;PROD CTP WEB servers (m7-prod-ctp-web[1-6) re-deployed), new chain is in place now",,,,,,,,,,,,,,,,,,,,,
Journal is not cleaned up on SYT1,M7P-5589,92173,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,cs687,oy574,oy574,14/Feb/20 14:56,04/Mar/20 15:12,16/Sep/21 14:11,27/Feb/20 09:35,,6.9.76,7Tops_Sprint1,,,,,,,M7PRODOPS,,,,,,,"The journal cleanup script on SYT1 is probably not working - it should be cleaning up journal files older than 3 days, but we have already journal for last 5 days - which lead to {{No space left on device.}}

*Additional remark:*

Please consider broader impact of this issue. Pls check all environments (M7T related)",,cs687,oy574,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"i command that line out and made some changes with mindepth and maxdepth
find /${BASEDIR}/journal/m7-msgs -mindepth 2 -maxdepth 2 -daystart -mtime +2 -exec rm -f {} \; -ls
",,,,,,,,,,,,,,,,,,,,,,,,48988800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,14/Feb/20 14:56,,[],,,,,,,,,,,M7T,,,,"2|hzx27j:",9223372036854775807,,,,No,,,,,,,,,,"not the proper parameters are used in the find command 
#find /${BASEDIR}/journal/m7-msgs -type f -mtime +3 -exec rm -f {} \; -ls
",,,,,,,,7tops Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,,,"tested the script for few days and it´s working fine. 
only journal files are kept which are 3 days old and not older and empty dirs will be deleted. 
",,,,,,,,,,"{""issueId"":92173,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"20/Feb/20 09:23;cs687;for me its looking fine we have files from 17.02 16:21 so its looking fine for me and in the cronjob we have these commands in-place

{code:java}
#Ansible: clean_journal.ksh
0 6 * * * /shrd/prodscripts/clean_journal.ksh
tomcat@m7shrdsyt1apa1:[/shrd]$ less /shrd/prodscripts/clean_journal.ksh
#!/bin/bash
BASEDIR=shrd
if [ -d /${BASEDIR}/journal/m7-msgs ]
 then
  find /${BASEDIR}/journal/m7-msgs -type f -mtime +3 -exec rm -f {} \; -ls
  find /${BASEDIR}/journal/m7-msgs -type d -empty -delete
fi
{code}

so actually there are no files there which are older than 3 days
should i check all env´s for that or just test env´s.

Please come back to me [~oy574]","25/Feb/20 08:18;cs687;{code:java}
tomcat@m7shrdsyt1apa1:[/shrd]$ ls -all /shrd/journal/m7-msgs/                                                                                 
drwxr-x--- 7 tomcat tomcat 4096 Feb 25 06:00 .                              
drwxr-xr-x 4 tomcat tomcat 4096 Feb 20 13:06 ..                             
drwxr-x--- 2 tomcat tomcat 4096 Feb 25 06:00 20200221                       
drwxr-x--- 2 tomcat tomcat 4096 Feb 22 03:03 20200222                       
drwxr-x--- 2 tomcat tomcat 4096 Feb 23 03:03 20200223                       
drwxr-x--- 2 tomcat tomcat 4096 Feb 24 03:03 20200224                       
drwxr-x--- 2 tomcat tomcat 4096 Feb 25 03:03 20200225                       
{code}                                            
{code:java}
tomcat@m7shrdsyt1apa1:[/shrd]$ ls -all /shrd/journal/m7-msgs/20200221/                                                                 
drwxr-x--- 2 tomcat tomcat     4096 Feb 25 06:00 .                          
drwxr-x--- 7 tomcat tomcat     4096 Feb 25 06:00 ..                         
-rw-r----- 1 tomcat tomcat 67108864 Feb 22 00:59 data-16399-1               
-rw-r----- 1 tomcat tomcat 16777216 Feb 22 00:59 index-0                    
{code}
{code:java}
tomcat@m7shrdsyt1apa1:[/shrd]$ ls -all /shrd/journal/m7-msgs/20200222/                                                                  
drwxr-x--- 2 tomcat tomcat     4096 Feb 22 03:03 .                          
drwxr-x--- 7 tomcat tomcat     4096 Feb 25 06:00 ..                         
-rw-r----- 1 tomcat tomcat 67108864 Feb 22 03:03 data-16399-0               
-rw-r----- 1 tomcat tomcat 67108864 Feb 23 00:59 data-16399-1               
-rw-r----- 1 tomcat tomcat 16777216 Feb 23 00:59 index-0        
{code}    
{code:java}        
tomcat@m7shrdsyt1apa1:[/shrd]$ ls -all /shrd/journal/m7-msgs/20200223/                                                                
drwxr-x--- 2 tomcat tomcat     4096 Feb 23 03:03 .                          
drwxr-x--- 7 tomcat tomcat     4096 Feb 25 06:00 ..                         
-rw-r----- 1 tomcat tomcat 67108864 Feb 23 03:02 data-16399-0               
-rw-r----- 1 tomcat tomcat 67108864 Feb 24 00:59 data-16399-1               
-rw-r----- 1 tomcat tomcat 16777216 Feb 24 00:59 index-0                    
{code}

made the following {color:#DE350B}*changes*{color}
{code:java}
#!/bin/bash                                                                                                     
BASEDIR=shrd                                                                                                    
                                                                                                               
if [ -d /${BASEDIR}/journal/m7-msgs ]                                                                           
 then                                                                                                           
  #find /${BASEDIR}/journal/m7-msgs -type f -mtime +3 -exec rm -f {} \; -ls                                     
  find /${BASEDIR}/journal/m7-msgs -mindepth 2 -maxdepth 2 -daystart -mtime +2 -exec rm -f {} \; -ls            
  find /${BASEDIR}/journal/m7-msgs -type d -empty -delete                                                       
fi                                                                                                              
{code}

","25/Feb/20 08:46;cs687;*+End-Result after running the script:+*
Folder 20200221 was deleted because after deleting the older files+{color:#DE350B} it was an empty directory!{color}+

{code:java}
tomcat@m7shrdsyt1apa1:[/shrd]$ /shrd/prodscripts/clean_journal.ksh                                                                           
11498819526689650299 1216 -rw-r-----   1 tomcat   tomcat   16777216 Feb 22 00:59 /shrd/journal/m7-msgs/20200221/index-0                      
10737383883547757413 28860 -rw-r-----   1 tomcat   tomcat   67108864 Feb 22 00:59 /shrd/journal/m7-msgs/20200221/data-16399-1                
13554374755917570765 2720 -rw-r-----   1 tomcat   tomcat   67108864 Feb 22 03:03 /shrd/journal/m7-msgs/20200222/data-16399-0                                                                                                           
                                                                                                                               
drwxr-x--- 2 tomcat tomcat 4096 Feb 25 08:43 20200222                                                                                        
drwxr-x--- 2 tomcat tomcat 4096 Feb 23 03:03 20200223                                                                                        
drwxr-x--- 2 tomcat tomcat 4096 Feb 24 03:03 20200224                                                                                        
drwxr-x--- 2 tomcat tomcat 4096 Feb 25 03:03 20200225 
                                                                                       
tomcat@m7shrdsyt1apa1:[/shrd/journal/m7-msgs]$ ls -all  *                                                                                    
20200222:                                                                                                                                                                                                                                                                 
drwxr-x--- 2 tomcat tomcat     4096 Feb 25 08:43 .                                                                                           
drwxr-x--- 6 tomcat tomcat     4096 Feb 25 08:43 ..                                                                                          
-rw-r----- 1 tomcat tomcat 67108864 Feb 23 00:59 data-16399-1                                                                                
-rw-r----- 1 tomcat tomcat 16777216 Feb 23 00:59 index-0                                                                                     
                                                                                                                                             
20200223:                                                                                                                                                                                                                                                                    
drwxr-x--- 2 tomcat tomcat     4096 Feb 23 03:03 .                                                                                           
drwxr-x--- 6 tomcat tomcat     4096 Feb 25 08:43 ..                                                                                          
-rw-r----- 1 tomcat tomcat 67108864 Feb 23 03:02 data-16399-0                                                                                
-rw-r----- 1 tomcat tomcat 67108864 Feb 24 00:59 data-16399-1                                                                                
-rw-r----- 1 tomcat tomcat 16777216 Feb 24 00:59 index-0                                                                                     
                                                                                                                                             
20200224:                                                                                                                                                                                                                                                                     
drwxr-x--- 2 tomcat tomcat     4096 Feb 24 03:03 .                                                                                           
drwxr-x--- 6 tomcat tomcat     4096 Feb 25 08:43 ..                                                                                          
-rw-r----- 1 tomcat tomcat 67108864 Feb 24 03:03 data-16399-0                                                                                
-rw-r----- 1 tomcat tomcat 67108864 Feb 25 00:59 data-16399-1                                                                                
-rw-r----- 1 tomcat tomcat 16777216 Feb 25 00:59 index-0                                                                                     
                                                                                                                                             
20200225:                                                                                                                                                                                                                                                                     
drwxr-x--- 2 tomcat tomcat     4096 Feb 25 03:03 .                                                                                           
drwxr-x--- 6 tomcat tomcat     4096 Feb 25 08:43 ..                                                                                          
-rw-r----- 1 tomcat tomcat 67108864 Feb 25 03:02 data-16399-0                                                                                
-rw-r----- 1 tomcat tomcat 67108864 Feb 25 08:43 data-16399-1                                                                                
-rw-r----- 1 tomcat tomcat 16777216 Feb 25 08:43 index-0                                                                                     
{code}

Will observe that the next days. 
","26/Feb/20 07:37;cs687;Changes seems like to working out [~oy574]
{code:java}
tomcat@m7shrdsyt1apa1:[/shrd]$ ls -all /shrd/journal/m7-msgs/
drwxr-x--- 2 tomcat tomcat 4096 Feb 26 06:00 20200223
drwxr-x--- 2 tomcat tomcat 4096 Feb 24 03:03 20200224
drwxr-x--- 2 tomcat tomcat 4096 Feb 25 03:03 20200225
drwxr-x--- 2 tomcat tomcat 4096 Feb 26 03:03 20200226

/shrd/journal/m7-msgs/20200223:
-rw-r----- 1 tomcat tomcat 67108864 Feb 24 00:59 data-16399-1
-rw-r----- 1 tomcat tomcat 16777216 Feb 24 00:59 index-0

/shrd/journal/m7-msgs/20200224:
-rw-r----- 1 tomcat tomcat 67108864 Feb 24 03:03 data-16399-0
-rw-r----- 1 tomcat tomcat 67108864 Feb 25 00:59 data-16399-1
-rw-r----- 1 tomcat tomcat 16777216 Feb 25 00:59 index-0

/shrd/journal/m7-msgs/20200225:
-rw-r----- 1 tomcat tomcat 67108864 Feb 25 03:02 data-16399-0
-rw-r----- 1 tomcat tomcat 67108864 Feb 26 00:59 data-16399-1
-rw-r----- 1 tomcat tomcat 16777216 Feb 26 00:59 index-0

/shrd/journal/m7-msgs/20200226:
-rw-r----- 1 tomcat tomcat 67108864 Feb 26 03:02 data-16399-0
-rw-r----- 1 tomcat tomcat 67108864 Feb 26 07:35 data-16399-1
-rw-r----- 1 tomcat tomcat 16777216 Feb 26 07:35 index-0
{code}

Will check the situation on the other machines. ","27/Feb/20 09:18;cs687;+Updated the changes also for the following Hosts:+

- m7shrdate1apa1
- m7shrdate3apa1
- m7shrdate4apa1
- m7shrddst1m7b1
- m7shrdshowm7b1
- m7shrdsyt2apa1
- m7shrdsyt3apa1
","27/Feb/20 09:20;cs687;Will close the ticket, once it is proofed that this changes are the proper solution we can go on with the other higher top env´s. 
[~oy574]","27/Feb/20 09:35;cs687;can be closed. ",,,,,,,,,,,,,,,,,,,,,
ICS Prod is not receiving Swissgrid's ACKs for the sent CRDs,M7P-5588,92167,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,jv861,qm925,qm925,14/Feb/20 12:29,25/Feb/20 23:39,16/Sep/21 14:11,18/Feb/20 10:59,,6.8.109,7tops_sprint0,,,,,,14/Feb/20 00:00,M7PRODOPS,,,,,,,ICS Prod is not receiving Swissgrid's ACKs for the sent CRDs yet. Which e-mail address is to be used? Can you confirm that ACKs for CRDs are to be sent to icsprod@m7c.deutsche-boerse.com,,jv861,pd122,qm925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49766400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,14/Feb/20 12:29,,[],,,,,,,,,,,M7C,,,,"2|hzx14n:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 86 (PS),Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92167,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Feb/20 18:13;jv861;I need help from techops here (I added label to Jira). I didn't find anything suspicious in the logs or in the code, so I'd like to verify IMAP connection to the mailbox used for acks. So for need, i need someone to check the following:
On the {{m7cicscprodapp1}}, there should be cmi's tomcat lib directory (probably {{/icsc/icsc-prod-cmi1/tomcat/lib}}?), there should be {{cmi_env.properties}} file with keys {{mail.imap.url1}} and {{mail.imap.url2}}. I'd like to know if these urls are correct, accessible, what email address are they pointing to and if there are some messages in the inbox.","17/Feb/20 11:28;pd122;{code:java}
tomcat@m7cicscprodapp1:[/home/tomcat]$ grep imap /icsc/icsc-prod-cmi1/tomcat/lib/cmi_env.properties 
mail.imap.url1=imap://icsprod%40m7c.deutsche-boerse.com:<password>@m7prodmail1:143/INBOX
mail.imap.url2=imap://icsprod%40m7c.deutsche-boerse.com:<password>@m7prodmail2:143/INBOX{code}
{code:java}
tomcat@m7cicscprodapp1:[/home/tomcat]$ telnet m7prodmail1 143
Trying 10.136.140.248...
Connected to m7prodmail1.
Escape character is '^]'.
* OK [CAPABILITY IMAP4rev1 LITERAL+ SASL-IR LOGIN-REFERRALS ID ENABLE IDLE AUTH=PLAIN] Dovecot ready.

tomcat@m7cicscprodapp1:[/home/tomcat]$ telnet m7prodmail2 143
Trying 10.136.12.250...
Connected to m7prodmail2.
Escape character is '^]'.
* OK [CAPABILITY IMAP4rev1 LITERAL+ SASL-IR LOGIN-REFERRALS ID ENABLE IDLE AUTH=PLAIN] Dovecot ready.{code}","17/Feb/20 11:31;jv861;[~qm925] Do we know the address they are sending the confirmations from? Is it {{ca.scheduling@chtso.ch}}, or something else?","17/Feb/20 11:34;qm925;It should be ca.scheduling@chtso.ch but I will check with Swissgrid for confirmation.","17/Feb/20 11:41;pd122;The mailbox is empty, but timestamps are being updated regularly and there are no access errors, meaning the app connects successfully to the IMAP.","17/Feb/20 11:43;pd122;Sadly, have not found any trace of messages sent to (or received from) [ca.scheduling@chtso.ch.|mailto:ca.scheduling@chtso.ch.] ","17/Feb/20 11:48;pd122;Also, [icsprod@m7c.deutsche-boerse.com|mailto:icsprod@m7c.deutsche-boerse.com] is the correct address.","18/Feb/20 10:59;jv861;So as agreed with [~qm925] in person, Swissgrid was just asking where to send the ACKs. The correct address is the one Urban specified in a comment above:  icsprod@m7c.deutsche-boerse.com",,,,,,,,,,,,,,,,,,,,
CTP deployment with ansible - multiple instances per host ,M7P-5583,92130,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,yo218,yo218,13/Feb/20 15:47,10/Apr/20 14:58,16/Sep/21 14:11,09/Mar/20 08:07,,6.9.81,7tops_sprint2,,,PS,,,,M7PRODOPS,Patroni,,,,,,"It should be possible to run two instances of CTP on one host (for example on m7shrdextectp1)

 

Pavel Rehak:

Required in order to be able to start 4 instances of CTP>

 

At the moment after migration to PatroniDB we have
 * internal test ?
 * external test only 2/4 instances
 * production not yet migrated

 

Before we migrate PROD this needs to be fixed.

PROD to be migrated 10/3 by SERVICE-5476",,cs687,rehapav,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5518,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48038400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx3tb:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92130,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Feb/20 09:07;rehapav;Required in order to be able to start 4 instances of CTP>

 

At the moment after migration to PatroniDB we have
 * internal test ?
 * external test only 2/4 instances
 * production not yet migrated

 

Before we migrate PROD this needs to be fixed.

PROD to be migrated 10/3 by SERVICE-5476","14/Feb/20 09:56;fh971;I guess we could close, please see https://jira.deutsche-boerse.com/browse/SERVICE-5520?focusedCommentId=264606&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-264606","09/Mar/20 08:07;cs687;can be closed. ",,,,,,,,,,,,,,,,,,,,,,,,,
Ansible Jenkins Job - New job with parameterized branch for Inventory,M7P-5575,92094,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,qo288,fj021,fj021,12/Feb/20 12:06,04/Mar/20 15:12,16/Sep/21 14:11,20/Feb/20 09:23,,6.8.109,7Tops_Sprint1,,,,,,,M7PRODOPS,,,,,,,"h2. What ?

We would like to have an Ansible Deployment job that allows us to parametrized both Inventory and Deployment branches (right now, only Deployment branch).
h2. Why ?

It would allow us to be able to test our current progress with creating new Ansible deployment without having to merge to master for each small fixes. 
 That way *we only merge to master tested set ups*.
h2. Additional information

It was discussed with [~qo288], it already exists for M7A and should be doable for us. ([https://github.deutsche-boerse.de/dev/energy.automation.deployments/blob/master/jenkins/selfservice/Jenkinsfile_m7a_ansible])
h2. Acceptance criteria

New Jenkins Job similar to [existing Deployment job|https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/]. Plus the option to parametrized the Inventory branch/commit",,fj021,qo288,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Job is in place, I think this can be closed.",,,,,,,,,,,,,,,,,,,,,,,,50198400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,M7T,,,"2|hzx3iv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92094,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/20 15:17;qo288;Created pipeline at [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/681] , wtiting to be merged

Jenkins project is ready: https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/M7C%20Ansible/",,,,,,,,,,,,,,,,,,,,,,,,,,,
DB migration failed on REP instance,M7P-5573,92092,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,pd122,pd122,12/Feb/20 11:30,07/Jan/21 08:41,16/Sep/21 14:11,,,,,,,ansible,,,14/Feb/20 00:00,7tops,IceBox,M7PRODOPS,,,,,"DB Migration failed recently on EPEX ASIM REP instance:

 
{code:java}
TASK [reporting_engine : Migrate db] *********************************************************************************************************
skipping: [m7t-epex-asim-rep2]
fatal: [m7t-epex-asim-rep1 -> localhost]: FAILED! => {
 ""changed"": true,
 ""cmd"": [
 ""flyway_role/flyway-6.0.4/flyway"",
 ""-user=m7tepexasimrep"",
 ""-url=jdbc:postgresql://m7simupdb1.deutsche-boerse.de:24012,m7simupdb2.deutsche-boerse.de:24012,m7simupdb3.deutsche-boerse.de:24012,m7simupdb4.deutsche-boerse.de:24012/m7tepexasimrep?targetServerType=master"",
 ""-schemas=m7tepexasimrep"",
 ""-password=..."",
 ""-locations=filesystem:/home/pd122/Sources/energy.automation.deployments/playbooks/flyway_role/epex-6.4.19-clean-database-setup"",
 ""-group=true"",
 ""migrate""
 ],
 ""delta"": ""0:00:40.238179"",
 ""end"": ""2020-02-11 17:46:11.027010"",
 ""rc"": 1,
 ""start"": ""2020-02-11 17:45:30.788831""
}
STDOUT:
Flyway Community Edition 6.0.4 by Redgate

STDERR:
ERROR: 
Unable to obtain connection from database (jdbc:postgresql://m7simupdb1.deutsche-boerse.de:24012,m7simupdb2.deutsche-boerse.de:24012,m7simupdb3.deutsche-boerse.de:24012,m7simupdb4.deutsche-boerse.de:24012/m7tepexasimrep?targetServerType=master) for user 'm7tepexasimrep': The connection attempt failed.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL State : 08001
Error Code : 0
Message : The connection attempt failed.

MSG:
non-zero return code
{code}
 ",,pd122,yo218,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,50284800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzz0xj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92092,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jenkins Job for temp. Access to Database ,M7P-5572,92090,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,12/Feb/20 11:12,19/Feb/20 10:25,16/Sep/21 14:11,12/Feb/20 15:23,,6.9.68,7tops_sprint0,,,,,,29/Feb/20 00:00,M7PRODOPS,,,,,,,"https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Temporary%20DB%20access%20(M7)/

make jenkins job workable for giving access to m7 database",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50198400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzvamn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92090,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"12/Feb/20 15:23;cs687;Jenkins Job is working 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/Temporary%20DB%20access%20(M7)/",,,,,,,,,,,,,,,,,,,,,,,,,,,
install monitoring clients on elts-prod-amq7-10,M7P-5568,92064,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,iu252,iu252,12/Feb/20 09:49,21/Oct/20 11:21,16/Sep/21 14:11,13/Oct/20 10:17,,6.11.44,7tops_sprint103,,,,,,28/Feb/20 00:00,M7PRODOPS,Monitoring,,,,,,"After roll out 5 node cluster please install monitoring agents:
* telegraf
* filebeat
* CheckMK",,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"We don't use amq5-am0.
Ticket can be closed.",,,,,,,,ELTS,,,,,,,,,,,,,,,,50284800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx3kn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92064,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fire self-healing script on warning for user with too many queues,M7P-5559,92040,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cv179,sw455,sw455,11/Feb/20 14:30,19/Feb/20 10:25,16/Sep/21 14:11,12/Feb/20 15:24,,7tops_sprint0,,,,,,,,M7PRODOPS,,,,,,,"Automate the firing of the self-healing script which deletes queues of a user.

 

When the warning fires because a single user has more than X amount of response queues, a self-healing script should be automatically executed to clean up the queues created by that user, disconnect the user, and send report of the action to Ops team/customer",,cv179,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50198400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwtrz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92040,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"12/Feb/20 13:09;sw455;[~cv179] may have completed this task already:
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/679 
","12/Feb/20 15:04;cv179;updated the script to use rabbitmqctl: [https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/683/files]","12/Feb/20 15:08;cv179;One more improvement to reduce the WARN level is covered with this PR: [https://github.deutsche-boerse.de/dev/energy.monitoring/pull/1160]","12/Feb/20 15:24;cv179;changes are all done and tested",,,,,,,,,,,,,,,,,,,,,,,,
SERVICE CLONE: Recall function not working properly,M7P-5553,92013,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,,dp007,dp007,10/Feb/20 14:56,27/Nov/20 08:47,16/Sep/21 14:11,25/Feb/20 15:28,,6.9.71,7Tops_Sprint1,,,ansible,M7T BE,,,configuration,M7PRODOPS,minor,,,,,"Dear DBAG,

In SIMU and ASIM environments the recall is not working properly for product Quarterly_local. However, in CUTE it is fine. All test environments have 6.8. 

Current behaviour:
After clicking the recall button with a trader user, the recall gets immediately accepted, and first the ""recall accepted"" popup message appears then the attached ""call the market operations"" message.

Expected behaviour: 
After clicking the recall button the ""call the market operations"" message appears, then the recall needs to be accepted/rejected by an admin user.

How to reproduce:
Simply recall a Quarterly_local trade. 

Please investigate as soon as possible and check if it exists on PROD environment as well or not or would it after 6.8 2020.02.20. deployment or not.

Thanks a lot!

Best regards,
N.Tomi",,dp007,MG726,rehapav,tf093,tj898,,,,,,,,,,,,,,,SERVICE-5517,,,,,,,,,,,,,,SERVICE-5421,,,,,,"10/Feb/20 14:56;dp007;recall message.PNG;https://jira.deutsche-boerse.com/secure/attachment/80254/recall+message.PNG",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,HUPX,,,,,,Report a Non-Critical Incident,,,,,,,,,,49075200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,Communication -> Customer,,,[],,,,,,,,,,,M7T,,,,"2|hzx17b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,Magnificent 7 Sprint 86 (PS),Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":92013,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"10/Feb/20 15:01;dp007;TODO:

In order to disable auto trade recalls for local products on *ALL HUPX ENVs* move the line *auto_trade_recall_for_local_products: ""false""*

from [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/hupx/cute/m7tcor/vars.yml]

to [https://github.deutsche-boerse.de/dev/energy.automation.inventory/blob/master/inventory/m7t/hupx/vars.yml]

Please add it right above the line: _recall_time_limit_max_after_execution: 15_

This has to be done before 2020-02-20 when 6.8 goes to Production!","10/Feb/20 15:16;tf093;PR: https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1562
[~rehapav] [~dp007] please make sure it is attached to the relevant deployment requests","10/Feb/20 15:56;rehapav;Included into https://jira.deutsche-boerse.com/browse/SERVICE-5421","20/Feb/20 14:53;MG726;Hi [~tj898], deployment was successfully processed today. Could you please confirm with customer that the problem is solved now? Thank you.","24/Feb/20 12:06;tj898;Hi, [~MG726].

We informed the customer. However, they cannot test in Production, so they are waiting for the same fix to be applied in SIMU/CUTE - to be done automatically - and if the result is satisfactory they will inform us and we can close this,

Cheers,

Hugo","25/Feb/20 11:18;rehapav;This ticket can be closed.

Already applied in HUPX PROD during 20/2 deployment.

HUPX CUTE and SIMU deployment is scheduled.","25/Feb/20 15:28;MG726;Disable auto trade recalls for local products applied in HUPX PROD during 20/2 deployment.",,,,,,,,,,,,,,,,,,,,,
request and install VMs for 5 node RabbitMQ cluster ELTS PROD,M7P-5545,91941,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,iu252,iu252,07/Feb/20 13:59,19/Feb/20 10:25,16/Sep/21 14:11,12/Feb/20 09:47,,6.9.68,7tops_sprint0,,,,,,14/Feb/20 00:00,M7PRODOPS,,,,,,,request and install VMs for 5 node RabbitMQ cluster ELTS PROD,,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,50371200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx2pj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91941,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"10/Feb/20 11:38;iu252;Requested new VMs:


{noformat}
Hello everybody,

@VM_Approval: please, approve these VM´s creation for M7P-5545


Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/PROD/ELTS/	M7eltsprodamq7	394 (M7CLOUD-PRD-BE-FF-H1) (10.139.52.0/23)	12	16 GB	40 GB	CLUST-M7-EQ	RHEL7	M7P-5545	Prod	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/PROD/ELTS/	M7eltsprodamq8	394 (M7CLOUD-PRD-BE-FF-H1) (10.139.52.0/23)	12	16 GB	40 GB	CLUST-M7-HA	RHEL7	M7P-5545	Prod	Energy TechOps (Energy_TechOps@deutsche-boerse.com )



Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/PROD/ELTS/	M7eltsprodamq9	394 (M7CLOUD-PRD-BE-FF-H1) (10.139.52.0/23)	12	16 GB	40 GB	CLUST-M7-EQ	RHEL7	M7P-5545	Prod	Energy TechOps (Energy_TechOps@deutsche-boerse.com )



Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/PROD/ELTS/	M7eltsprodamq10	394 (M7CLOUD-PRD-BE-FF-H1) (10.139.52.0/23)	12	16 GB	40 GB	CLUST-M7-HA	RHEL7	M7P-5545	Prod	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Please also enable hotplug for vCPU and vRAM.

In case of additional questions, please contact me.


Thank you in advance.

Kind regards,
Alexander

{noformat}
","11/Feb/20 09:20;iu252;@Lambert requested ip-addresses:
m7eltsprodamq7: Device Request: 7030832
m7eltsprodamq8: Device Request: 7030833
m7eltsprodamq9: Device Request: 7030834
m7eltsprodamq10: Device Request: 7030835","11/Feb/20 09:22;iu252;duplicate ticket.

https://jira.deutsche-boerse.com/browse/M7P-5507",,,,,,,,,,,,,,,,,,,,,,,,,
Check version of PHP on shared servers with ICS portal,M7P-5539,91922,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,HO764,HO764,07/Feb/20 10:39,18/Mar/20 13:26,16/Sep/21 14:11,09/Mar/20 12:04,,6.8.110,7tops_sprint2,,,,,,,M7PRODOPS,,,,,,,"Please check whether we have the latest available version of php installed on the machines m7shrdinteweb[number], m7shrdexteweb[number], and m7shrdprodweb[number]. By latest version, I mean the latest errata version from RHEL (5.4.x); from the information I have, it seems that at least on production, this is not the case.

In case we find outdated version, let's find a way how to upgrade it.",,HO764,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48038400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzx2lz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91922,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/20 12:00;iu252;
{noformat}
[root@m7shrdinteweb1 ~]# php --version
PHP 5.4.16 (cli) (built: Jun 19 2018 13:09:01)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdinteweb1 ~]#


[root@m7shrdinteweb2 ~]# php --version
-bash: php: command not found
[root@m7shrdinteweb2 ~]# rpm -qa | grep php
[root@m7shrdinteweb2 ~]#
php is not installed on m7shrdinteweb2 
{noformat}




{noformat}
[root@m7shrdexteweb1 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdexteweb1 ~]#

[root@m7shrdexteweb2 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdexteweb2 ~]#
{noformat}



{noformat}
[root@m7shrdprodweb1 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb1 ~]#

[root@m7shrdprodweb2 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb2 ~]#

[root@m7shrdprodweb3 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb3 ~]#

[root@m7shrdprodweb4 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb4 ~]#


[root@m7shrdprodweb5 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb5 ~]#

[root@m7shrdprodweb6 ~]# php --version
PHP 5.4.16 (cli) (built: Aug  5 2016 07:50:38)
Copyright (c) 1997-2013 The PHP Group
Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies
[root@m7shrdprodweb6 ~]#
{noformat}
","07/Feb/20 12:16;HO764;Thanks for the version dump. Can you please also determine whether the version installed in inteweb1 is the latest one available in RHEL?","07/Feb/20 12:43;iu252;[~HO764], we are able to provide php 7.3 if necessary.
But don't forget the web server are shared between different environments.
","07/Feb/20 12:59;HO764;No, we don't want php 7. We want the latest php 5.4, as per [https://access.redhat.com/solutions/3321431,] it is enough to be secure.","07/Feb/20 13:54;iu252;The latest version of php 5.4 which is available on our RHEL-repository is:

php-5.4.16-46.1.el7_7.x86_64

This version is installed on m7shrdinteweb1:


{noformat}
[root@m7shrdinteweb1 ~]# rpm -qa | grep php
.......
php-5.4.16-46.el7.x86_64
..........
{noformat}


Keep in mind that different version is installed in PROD and also in EXTE:


{noformat}
[root@m7shrdexteweb1 ~]# rpm -qa | grep php-5.4
php-5.4.16-42.el7.x86_64
[root@m7shrdexteweb1 ~]#


[root@m7shrdprodweb4 ~]# rpm -qa | grep php-5.4
php-5.4.16-42.el7.x86_64
[root@m7shrdprodweb4 ~]#
{noformat}

","07/Feb/20 14:14;HO764;Thank you for the investigation. We'd need to upgrade php on the EXTE and PROD eventually. I don't know what can be affected by this upgrade. I'll communicate this information with [~rehapav] to decide on the next steps.","09/Mar/20 11:01;iu252;[~HO764] can we close this ticket?
In case we will upgrade php, there will be a new ticket, right?","09/Mar/20 12:03;HO764;[~iu252] yes, we can close it. Confirmed by [~rehapav] that he has a note about it and will report it in the future.",,,,,,,,,,,,,,,,,,,,
Migrate inte shrd ctp database,M7P-5538,91911,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,fh971,fh971,06/Feb/20 16:52,19/Feb/20 10:25,16/Sep/21 14:11,10/Feb/20 12:11,,7tops_sprint0,,,,PS,,,,M7PRODOPS,,,,,,,Please migrate {{m7shrdintectp}} database from {{m7spg12-inteshrd}}  to {{m7testpdb1/2}}.,,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/20 13:34;cs687;M7P-5538.txt;https://jira.deutsche-boerse.com/secure/attachment/80210/M7P-5538.txt",,,,,,,,,,,,,,,sw455,,,,,,,,"Set it back to offline on the old veritas hosts. 

{code:java}
[root@m7spg2 tmp]# hagrp -offline inteshrdSG -sys m7spg2

[root@m7spg2 tmp]# hares -state | grep inte
inteshrdSGbackupmnt  State                 m7spg1     OFFLINE
inteshrdSGbackupmnt  State                 m7spg2     OFFLINE
inteshrdSGbackupvol  State                 m7spg1     OFFLINE
inteshrdSGbackupvol  State                 m7spg2     OFFLINE
inteshrdSGdatamnt    State                 m7spg1     OFFLINE
inteshrdSGdatamnt    State                 m7spg2     OFFLINE
inteshrdSGdatavol    State                 m7spg1     OFFLINE
inteshrdSGdatavol    State                 m7spg2     OFFLINE
inteshrdSGdb         State                 m7spg1     OFFLINE
inteshrdSGdb         State                 m7spg2     OFFLINE
inteshrdSGdg         State                 m7spg1     OFFLINE
inteshrdSGdg         State                 m7spg2     OFFLINE
inteshrdSGdlogvol    State                 m7spg1     OFFLINE
inteshrdSGdlogvol    State                 m7spg2     OFFLINE
inteshrdSGip         State                 m7spg1     OFFLINE
inteshrdSGip         State                 m7spg2     OFFLINE
inteshrdSGlogmnt     State                 m7spg1     OFFLINE
inteshrdSGlogmnt     State                 m7spg2     OFFLINE
inteshrdSGnic_prx    State                 m7spg1     ONLINE
inteshrdSGnic_prx    State                 m7spg2     ONLINE

[root@m7spg2 tmp]# hagrp -freeze inteshrdSG
{code}
",,,,,,,,,,,,,,,,,,,,,,,,50457600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx2jj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91911,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,netbackup-role,master,true,"07/Feb/20 12:22;cs687;Prepared the pull-request:
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1552
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/664

Need to deploy m7ctp","07/Feb/20 13:34;cs687;After adding the necessary vault-settings...
Jenkins Job end up with an SQL ERROR 
{code:java}
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/show/m7t/shrd/inte/db/m7tshrdintectp

ERROR: 
Unable to obtain Jdbc connection from DataSource (jdbc:postgresql://['m7testpdb1.deutsche-boerse.de', 'm7testpdb2.deutsche-boerse.de']:26028/m7tshrdintectp) for user 'm7tshrdintectp': The connection attempt failed.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SQL State  : 08001
Error Code : 0
Message    : The connection attempt failed.
{code}

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/7030/console
","07/Feb/20 14:58;cs687;https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1553
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/665/
https://github.deutsche-boerse.de/dev/energy.automation.deployments/pull/671

after that pull-requests the jenkins job were running successfully 
","10/Feb/20 08:46;cs687;Main root cause for the issue above was the following 

Script *034_GRANT_AND_ALTER_DEFAULT_PRIVILEGES.sq* 
didnt work because the schemas were still existing. 


{code:java}
GRANT SELECT,INSERT,UPDATE,DELETE on all tables in schema m7tshrdintectp TO uapp01m7tshrdintectp;
GRANT USAGE on all sequences in schema m7tshrdintectp to uapp01m7tshrdintectp;
GRANT EXECUTE on all functions in schema m7tshrdintectp to uapp01m7tshrdintectp;

GRANT SELECT on ALL TABLES IN SCHEMA m7tshrdintectp to udev01m7tshrdintectp;
GRANT USAGE on all sequences in schema m7tshrdintectp to udev01m7tshrdintectp;
GRANT EXECUTE on all functions in schema m7tshrdintectp to udev01m7tshrdintectp;
{code}

Afterwards it was working. 
Next step migrate the database from the old veritas cluster. 
","10/Feb/20 11:50;cs687;Unfreeze the old veritas cluster and put the cluster in an online-mode:
{code:java}
hagrp -unfreeze inteshrdSG
hagrp -online inteshrdSG -sys m7spg2
{code}

dumped the last Database state as Enterprisedb User:
{code:java}
for comp in ctp; do pg_dump --port=21100 -d m7shrdinte$comp -n m7shrdinte$comp | gzip > /tmpppas/dump/m7shrdinte$comp.sql.gz; done
{code}

Changing the schema-names from m7shrdintectp to *m7tshrdintectp*
{code:java}
for comp in ctp; do zcat m7shrdinte${comp}.sql.gz | sed 's/m7shrdinte/m7tshrdinte/g' | gzip > m7tshrdinte${comp}.sql.gz; done
{code}

restore the data dump:
{code:java}
zcat m7tshrdintectp.sql.gz | psql -p 26028 -d m7tshrdintectp
{code}


","10/Feb/20 12:11;cs687;Ticket can be closed. ",,,,,,,,,,,,,,,,,,,,,,
install monitoring clients on epex-asim-amq7-10,M7P-5533,91903,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,iu252,iu252,06/Feb/20 16:05,19/Feb/20 10:25,16/Sep/21 14:11,13/Feb/20 12:51,,6.9.68,7tops_sprint0,,,,,,28/Feb/20 00:00,M7PRODOPS,Monitoring,,,,,,"After roll out of RabbitMQ 5-node cluster in EPEX ASIM deploy monitoring clients to m7epexasimamq7-10:

-filebeat
-telegraf
- CheckMK",,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,EPEX,,,,,,,,,,,,,,,,50198400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx2m7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91903,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"13/Feb/20 09:22;iu252;Deployed filebeat and telegraf:

https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Monitoring%20Clients/646/console

Deployed CheckMK:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Monitoring/job/Deploy%20Check_MK%20Client/10/console


Checked Kibana, the logs of new rabbitmq server are there!",,,,,,,,,,,,,,,,,,,,,,,,,,,
Huge Journal times during stability tests (glusterFS),M7P-5528,91856,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,yo218,yo218,06/Feb/20 07:35,17/Dec/20 15:26,16/Sep/21 14:11,28/Feb/20 13:14,,6.9.76,7Tops_Sprint1,,,,,,31/Jan/20 00:00,M7PRODOPS,,,,,,,"h4. Problem
while monitoring our stability tests on shrd/SYT1, we spotted some huge processing times (>1s).
Further analyses showed that some events are spending in journal quite some time.
It looks like appending a file on glusterFS is blocked every 10-20 minutes.

h5. Examples of problematic events :
- 2020-01-28 13:26:55.233 - OrdrModify - 1194 ms in journaler
- 2020-01-28 13:47:31.357 - OrdrModify - 962ms in journaler
- 2020-01-28 14:04:40.985 - OrdrModify - 989ms in journaler

h5. Normal Processing Times
Normally, max processing times are around 70ms so these are big peaks. See 
https://grafana.energy.svc.dbgcloud.io/d/Ng45cU4mz/java-statsd?orgId=2&from=1580214198946&to=1580216778725&var-host=m7shrdsyt1apa1%20-%20tomcat%20-%20m7_shrd_syt1&var-client=shrd&var-client_env=syt1&var-group=All&var-interval=$__auto_interval_interval&var-exchangeId=EPEX&fullscreen&panelId=3

h4. Acceptance Criteria
Our SLA for 99.5% is 500ms. We should make sure that the processing times are below that if nothing extraordinary is going on.
Please, 
- find the root cause (and fix) or 
- suggest an ""improvement that might help"". It is easy for dev team to test any configuration change shrd/syt1.

",,cs687,pw231,yo218,,,,,,,,,,,,,,,,,TECHLOG-3149,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,48816000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-2995,,,,,,,,,,,,Monitoring -> Grafana,,,[],,,,,,,,,,,M7T,,,,"2|hzx27z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 1,,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":91856,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Feb/20 11:42;pw231;we have options: please, see the comments in the TECHLOG-3149 .","28/Feb/20 13:14;cs687;Detailed Information will be found in TICKET TECHLOG-3149",,,,,,,,,,,,,,,,,,,,,,,,,,
Create empty Patroni Postgres DB for EBSM,M7P-5526,91841,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,dp007,dp007,05/Feb/20 15:41,02/Jun/20 23:21,16/Sep/21 14:11,02/Jun/20 09:45,,6.10.69,6.9.81,7tops_sprint2,,EBSM,,,31/Mar/20 00:00,7tops_comm,DB,EBSM,M7PRODOPS,Patroni,,,"In order to switch EBSM to PostgreSQL I need an empty db where I can dump the current DB2 tables/views/...

Please do the following:
 # prepare the db,
 # enable FW from EBSM,
 # send me user:password.

Thanks,
Kombi",,cs687,dp007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5988,INIT-491,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,40694400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx27b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 0,7tops Sprint 1,7tops Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,"{""issueId"":91841,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"11/Feb/20 10:30;cs687;Just communicated with [~op211] and [~dp007] about that topic. 

So the main idea is to setup a new cluster on the hosts *m7simupdb1, m7simupdb2, m7simupdb3 and m7simupdb4*
at the moment with the current java code we are just connecting to one *Database DB2*
Java-Code -> https://github.deutsche-boerse.de/dev/energy.ebsm/blob/master/src/main/java/com/deutscheboerse/energy/ebsm/util/db/dao/DAOFactoryDB2.java

In that code we have to put some more logic, the application should have mechanism to determine which node is currently running as MASTER.

{code:java}
public class DAOFactoryDB2 extends DAOFactory {
	private static final String driver = ""com.ibm.db2.jcc.DB2Driver"";
	private static final String dbms   = ""db2"";
	private static Logger log;
	private LogFormatter lf = new LogFormatter();
	private String host;
	private String port;
	private String sid;
	private String schema;
	private String user;
	private String password;
	private Connection jdbcConnection;

	static {
		log = Logger.getLogger(CommonConstants.LOGGER_INSTANCE_NAME);
		loadDriver();
	}
	public DAOFactoryDB2 (String host, String port, String sid, String schema, String user, String password) throws Exception {
		this.host     = host;
		this.port     = port;
		this.sid      = sid;
		this.schema   = schema;
		this.user     = user;
		if (password.length()>20) this.password = decrypt(password);
		                     else this.password = password;
		createConnection();
	}
{code}

I guess we have to change something in that lines. 
For example creating a function ""determine_master-node()""
which could properly run an sql-command * SELECT pg_is_in_recovery();*

It will give you a flag ""true"" or ""false"" 
- true if it is running as slave 
- flase if it is running as master. 

[~dp007] we should figure that out. 

As my first point, i will setup a cluster on the hosts above with an empty database. 
[~dp007] you will give me an database-username which i will configure as superuser. 


 ","03/Mar/20 15:08;cs687;Pull-Request for preparing the Inventory to create a new empty patroni database. 
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1635

proper inventory path would be m7t-shrd-simu-postgres in main.yml/vars.yml

added the necessary vault-settings:
* postgres_db_password
* replication_db_password
https://englobvault.deutsche-boerse.de/ui/vault/secrets/secret/list/m7t/shrd/simu/db/?redirect_to=%2Fvault%2Fsecrets

run the playbook for deploying patroni
*[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*shrd*simu*pdb*"" -K -k -b --tags deploy*

","05/Mar/20 11:22;cs687;Port is up and listening 
{code:java}
[cs687@m7simupdb1 ~]$ netstat -tulpn | grep 24059
(No info could be read for ""-p"": geteuid()=519105 but you should be root.)
tcp        0      0 0.0.0.0:24059           0.0.0.0:*               LISTEN      -
{code}

{code:java}
-bash-4.2$ psql -p 24059

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(3 rows)
{code}

The empty Database is up and running. 
next step:
* preparing a database-username 
*ebsmadmin* who can do everything (SUPERUSER), 

{code:java}
postgres=# CREATE ROLE ebsmadmin LOGIN SUPERUSER PASSWORD 'EMAIL';
CREATE ROLE
postgres=# \du
                                                               List of roles
         Role name         |                   Attributes                   |                          Member of
---------------------------+------------------------------------------------+--------------------------------------------------------------
 ebsmadmin                 | Superuser                                      | {}
{code}

*ebsm* who only can read and insert/update/delete in tables.
{code:java}
                                                              List of roles
        Role name         |                   Attributes                   |                          Member of
--------------------------+------------------------------------------------+--------------------------------------------------------------
ebsm                      |                                                | {}
{code}


* give the right rights in pg_hba.conf 
* handover to [~dp007]

The deal is to add the users, prepare necessary firewall-settings that the database can be connected via Cyberark and handing over to martin. He can setup the DB and set the necessary credentials. 

","06/Mar/20 08:49;cs687;Database is accessible via CYBERARK 
tested with DBVisualizer

PORT: 24059
HOST: M7SIMUPDB1 (current LEADER-Node) 
OTHER HOSTS: M7SIMUPDB2, M7SIMUPDB3 and M7SIMUPDB4

{code:java}
[root@m7simupdb1 ~]# patronictl -c /etc/patroni_enshrdebsmasync/config.yml list
+-----------------+------------+---------------------+--------+---------+----+-----------+
|     Cluster     |   Member   |         Host        |  Role  |  State  | TL | Lag in MB |
+-----------------+------------+---------------------+--------+---------+----+-----------+
| enshrdebsmasync | m7simupdb1 | 10.139.58.176:24059 | Leader | running |  1 |         0 |
| enshrdebsmasync | m7simupdb2 | 10.139.58.175:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb3 | 10.139.58.174:24059 |        | running |  1 |         0 |
| enshrdebsmasync | m7simupdb4 | 10.139.58.173:24059 |        | running |  1 |         0 |
+-----------------+------------+---------------------+--------+---------+----+-----------+
{code}
","06/Mar/20 08:55;cs687;[~dp007] confirmed that everything is working fine. 
Ticket is closed. ","02/Jun/20 08:38;cs687;Additional Firewall-Request is necessary. 
EBSM connection: 

*m7shrdebsm1* -> m7simupdb1/2/3/4 with port 24059

ID: 504369",,,,,,,,,,,,,,,,,,,,,,
Action recurring AMQ alerts for HUPX/XSOP,M7P-5521,91818,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,wn626,sw455,sw455,05/Feb/20 11:29,19/Feb/20 10:25,16/Sep/21 14:11,06/Feb/20 12:00,,6.9.65,7tops_sprint0,,,Monitoring,,,,M7PRODOPS,,,,,,,"There are recurring alerts in m7p_prod_alerts channel notifying that rabbitmq message thresholds for unack messages are being reached for HUPX and XSOP production.

The cause of the threshold breach is assumed to be a single slow consumer.

Please find out which API users on HUPX are regularly slow to consume their queues, and message the customer and speak with them about addressing the issue.

 

 

Last messages:
[01:59|https://dbg-devops.slack.com/archives/C941CV942/p1580864375114300] 05.02.2020
WARNING on *m7hupxprodamq1* | RabbitMQ Messages Unacked: 100041 
[23:12 |https://dbg-devops.slack.com/archives/C941CV942/p1580767954111700]03.02.2020
WARNING on *m7xsopprodamq3* | RabbitMQ Messages Unacked: 100063 
 

 

!image-2020-02-05-11-24-47-742.png!",,wn626,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Feb/20 11:24;sw455;image-2020-02-05-11-24-47-742.png;https://jira.deutsche-boerse.com/secure/attachment/80120/image-2020-02-05-11-24-47-742.png","05/Feb/20 11:32;sw455;image-2020-02-05-11-32-58-222.png;https://jira.deutsche-boerse.com/secure/attachment/80121/image-2020-02-05-11-32-58-222.png",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,HUPX,Southpool,,,,,,,,,,,,,,,49680000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzn5xz:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91818,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"05/Feb/20 11:33;sw455;[~wn626] - you were correct, I don't see any mails with information on individual queue termination in our mailbox:

!image-2020-02-05-11-32-58-222.png!","05/Feb/20 11:35;sw455;Also - could this actually be the cause of HUPX's constant session terminations? 
https://jira.deutsche-boerse.com/browse/SERVICE-4858","06/Feb/20 12:00;wn626;I informed HUPX and Southpool regarding this issue. They are looking into it, hopefully, it will not re-occur.","19/Feb/20 08:59;sw455;Flagging for Product review - this was a retro item from last sprint and might need to be reported done.
[~wn626]",,,,,,,,,,,,,,,,,,,,,,,,
VM hypervisor check on EPEX ASIM,M7P-5519,91796,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Done,cs687,nn481,nn481,05/Feb/20 09:17,19/Feb/20 10:25,16/Sep/21 14:11,07/Feb/20 10:48,,7tops_sprint0,,,,,,,,M7PRODOPS,,,,,,,"One of our hypothesis is that problems on EPEX ASIM [M7P-5393] are caused by misbehaving VM hypervisor. 
 
We would like to as to check it to disprove this hypothesis.

Last occurrence was at 01-25-2020-07:29:17 up to 01-25-2020-16:35:37 CET.",,cs687,nn481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50716800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,,,,,"2|hzpr8f:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91796,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"05/Feb/20 12:46;cs687;After checking the Monitoring of these two hosts ""*m7epexasimm7b1 and m7epexasimm7b2*"" in the vSphere Client, we can see the following results. 
For m7epexasimm7b1 and m7epexasimm7b2 there completely missing the events from 25.01.2020 and also after checking some other hosts like m7hupxcutem7b1, m7plpxlipam7b2, etc. its the same!

To be sure i will talk to the ESX-Team and ask them why we have such of this events behavior on our side. ","05/Feb/20 14:49;cs687;Update from ESX-TEAM:

{code:java}
Hi,


[issues on two machines, m7epexasimm7b1 & m7epexasimm7b2, on Saturday, 2020-01-25 between  07:29:17 and 16:35:37. High load without reasonable cause within the VM, no events recorded in vCenter]

Impacted VMs:

m7epexasimm7b1
CLUST-DMZLX-EQ
fresxdmzi001
san.clustdmzlxeq.eq.2
VLAN 389
10 Cores (5x2)
20GB RAM

m7epexasimm7b2
CLUST-DMZLX-HA
fresxdmzh002
san.clustdmzlxha.ha.1
VLAN 389
10 Cores (5x2)
20GB RAM

We were unable to identify any issue/possible cause on the ESX side. Nothing showing up in the logs, we didn't perform any maintenance on the environments hosting the two given VMs that weekend (and only minor stuff to some other clusters), and also aren't aware of any general issue.

For the ""empty"" eventlog: If nothing happens, nothing is logged. The only event showing up on a regular base for most of the VMs is the NetBackup backup with its snapshot operations and updates to the ""NB_LAST_BACKUP"" attribute. But if no backup is taken, these events also aren't created. Was the same the Saturday before (2020-01-18) - no backups, no events at all.

So we don't see any obvious issue on VMware side which may have caused the high load within these two VMs, sorry. Maybe changes implemented by other teams may have had an impact (networking, firewalls, low level infrastructure like DNS, whatever).

Regards,
Bernd
{code}

They found no issues on there side. 
","05/Feb/20 14:58;cs687;ESX Guys found no issues on their side. 
I will close the ticket. ","05/Feb/20 15:21;sw455;Reopening real quick so I can release prior work

 ","07/Feb/20 10:49;sw455;Set to done - check of VM realted issues causing ASIM failures is completed - investigation ongoing elsehwere on application level (db/core)",,,,,,,,,,,,,,,,,,,,,,,
request and install VMs for 5 node RabbitMQ cluster ELTS PROD,M7P-5507,91725,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,rehapav,rehapav,03/Feb/20 11:26,04/Nov/20 13:01,16/Sep/21 14:11,23/Oct/20 09:44,,6.11.66,7tops_sprint104,,,,,,13/Feb/20 00:00,M7PRODOPS,,,,,,,"request and install VMs for 5 node RabbitMQ cluster ELTS PROD

*tbd: product team* to fill all the needed details for techops

 

 *tbd product team: based on* M7P-5485 System validation script for new VMs M7P-5487

please also make sure that we manually run through a checklist to validated all system resources and connectivity (see parent ticket for details) whenever changes or deployments require us to establish new VM's. 

Please check
 * # Cores
 * Amount ram
 * ulimit
 * Disk space
 * Connection to expected end-points (eg db, xbid, etc)
 * Etc etc etc
 * Firewalls required?

 

techops then will
 * request machines
 * install machines
 * and via separate deployment ticekt will deploy it ",,iu252,rehapav,,,,,,,,,,,,,,,,,,M7P-5506,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"m7eltsprodamq7|8|9|10 are not needed anymore.",,,,,,,,ELTS,,,,,,,,,,,,,,,,29203200,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx1l3:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91725,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,master,,true,"03/Feb/20 12:12;rehapav;Decided to put on hold until we get completed results from ELTS SIMU/ASIM","11/Feb/20 08:53;rehapav;You can proceed with request once ELTS ASIM is deployed on 13/2","11/Feb/20 09:43;iu252;New VMs already requested:
https://jira.deutsche-boerse.com/browse/M7P-5545","12/Feb/20 08:38;iu252;OS installed on m7eltsprodamq7|8|9|10.

os_selinux:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1076/console

os_update:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1077/console

os_ntp:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1079/console

os_network:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1080/console

os_accounts:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1082/console

os_agents:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1084/console

os_authentication:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1085/console

os_filesystem:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/1086/console","12/Feb/20 08:54;iu252;Deployed RabbitMQ server software and erlang:
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/7105/console
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/M7-Deploy-Playbook/7107/console","12/Feb/20 08:54;iu252;m7eltsprodamq7-10 are ready for 5 nodes rabbitmq cluster.","13/Oct/20 10:18;iu252;[~rehapav], I guess we can close this ticket. ",,,,,,,,,,,,,,,,,,,,,
request and install VMs for 5 node RabbitMQ cluster ELTS ASIM,M7P-5506,91724,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,rehapav,rehapav,03/Feb/20 11:26,27/Oct/20 23:20,16/Sep/21 14:11,06/Feb/20 16:01,,6.11.66,7tops_sprint0,,,,,,07/Feb/20 00:00,M7PRODOPS,,,,,,,"request and install VMs for 5 node RabbitMQ cluster ELTS ASIM {color:#de350b}( ASIM decided by EPEX 14:30 on 3/2){color}

*tbd: product team* to fill all the needed details for techops

 *tbd product team: based on* M7P-5485 System validation script for new VMs M7P-5487

please also make sure that we manually run through a checklist to validated all system resources and connectivity (see parent ticket for details) whenever changes or deployments require us to establish new VM's. 

Please check
 * # Cores
 * Amount ram
 * ulimit
 * Disk space
 * Connection to expected end-points (eg db, xbid, etc)
 * Etc etc etc
 * Firewalls required?

techops then will
 * request machines
 * install machines
 * and via separate deployment ticekt will deploy it ",,cs687,nn481,qz412,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Feb/20 09:56;cs687;iso_image_m7epexasimamq10.txt;https://jira.deutsche-boerse.com/secure/attachment/80160/iso_image_m7epexasimamq10.txt","06/Feb/20 09:46;cs687;iso_image_m7epexasimamq7.txt;https://jira.deutsche-boerse.com/secure/attachment/80157/iso_image_m7epexasimamq7.txt","06/Feb/20 09:51;cs687;iso_image_m7epexasimamq8.txt;https://jira.deutsche-boerse.com/secure/attachment/80158/iso_image_m7epexasimamq8.txt","06/Feb/20 09:56;cs687;iso_image_m7epexasimamq9.txt;https://jira.deutsche-boerse.com/secure/attachment/80159/iso_image_m7epexasimamq9.txt",,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,50716800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzvamv:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 85 (PS),Magnificent 7 Sprint 86 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91724,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,ASIM,,,,"03/Feb/20 12:18;cs687;[~pw231] that is the current setup for the existing amq-machines 
When we should request 2 more virtual machines (m7eltssimuamq7/9 and m7eltssimu8/10) for each DC how should we manage the CPU/RAM Resources and also for the existing machines. 
Maybe also interested for [~oy574] and [~tf093]

In the end we talk about the asim-env we have the following setup:
*m7epexasimamq1*
CPU: 8
RAM: 10 GB

*m7epexasimamq2*
CPU: 8
RAM: 10 GB

*m7epexasimamq3*
CPU: 8
RAM: 10 GB

*m7epexasimamq4*
CPU: 8
RAM: 10 GB

*m7epexasimamq5*
CPU: 8
RAM: 10 GB

*m7epexasimamq6*
CPU: 8
RAM: 10 GB ","03/Feb/20 15:12;qz412;^^^ The ASIM (bottom) part only is now relevant","03/Feb/20 15:37;qz412;Info from [~tf093] - the configuration of the additional machines should be the same as the machines currently in use.

[~cs687]: How about firewalls?","04/Feb/20 08:56;cs687;Hi [~qz412] thank you for your feedback. 
That means i will create 4 more Virtual Machines with the same Setting of Resources. (amq1+2 have 2x35GB diskspace, the rest has 40GB single disk) 
CPU: 8 and RAM: 10 GB

- m7epexasimamq7
- m7epexasimamq8
- m7epexasimamq9
- m7epexasimamq10

[~qz412] about firewalls we should expect any issues. Nothing will changed for the infrastructure just and only 4 more rabbitmq-nodes will be in the cluster, 2 for each DC. 
Waiting for your final GO to request the machines. You can assign the ticket than to me. 
","04/Feb/20 09:17;nn481;[~cs687] I suppose versions of operating system and erlang and other SW components will be same, right?

[~cs687] GO.","04/Feb/20 09:52;cs687;They will be the same yes :) 
Alright i will request 4 new Virtual Machines and will update everything in the ticket. 


{code:java}
Hello everybody,

@VM_Approval: please, approve these VM´s creation for M7P-5506

Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/ASIM/EPEX/	M7epexasimamq7	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	8	10 GB	40 GB	Clustdmzlxeq	RHEL7	M7P-5506	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/ASIM/EPEX	M7epexasimamq8	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	8	10 GB	40 GB	Clustdmzlxha	RHEL7	M7P-5506	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/ASIM/EPEX/	M7epexasimamq9	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	8	10 GB	40 GB	Clustdmzlxeq	RHEL7	M7P-5506	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/ASIM/EPEX	M7epexasimamq10	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	8	10 GB	40 GB	Clustdmzlxha	RHEL7	M7P-5506	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


In case of additional questions, please contact me.


Thank you in advance.

Cheers,
{code}
","05/Feb/20 12:09;cs687;*Created necessary IP-Addresses and DNS-Record via NSR:*

m7epexasimamq7:
{code:java}
Product 1304521 successfully created!
Request 7030721 successfully created!
{code}
*10.139.58.157*

m7epexasimamq8:
{code:java}
Product 1304522 successfully created!
Request 7030722 successfully created! 
{code}
*10.139.58.158*

m7epexasimamq9:
{code:java}
Product 1304523 successfully created!
Request 7030723 successfully created!
{code}
*10.139.58.159*

m7epexasimamq10:
{code:java}
Product 1304524 successfully created!
Request 7030724 successfully created!
{code}
*10.139.58.160*","06/Feb/20 09:55;cs687;Created the iso-images with Jenkins Job (see attached files) 
iso-images are stored -> http://syspmon1.deutsche-boerse.de/energy/

m7epexasimamq7-genoa-rh7-VM-ext4-energy.iso
m7epexasimamq8-genoa-rh7-VM-ext4-energy.iso
m7epexasimamq9-genoa-rh7-VM-ext4-energy.iso
m7epexasimamq10-genoa-rh7-VM-ext4-energy.iso","06/Feb/20 12:39;cs687;Installed the virtual machines with mentioned iso-image above. 
Afterwards i will run the os_playbooks with rabbitmq-playbook to finalize the OS-Installation. 
Once we will go for the deployment we also need to deploy monitoring tools on the machines, for that i will create a separated ticket [~iu252] when you dont mind.  

Lambert registered the machines in RHS. 

Run for 4 Virtual Machines the following playbooks:
- os_selinux.yml
- os_update.yml
- os_ntp.yml
- os_network.yml
- os_filesystem.yml
- os_authentication.yml
- os_account.yml
- os_agents.yml","06/Feb/20 16:01;cs687;Run the OS-Playbook M7-Deploy-Playbook *rabbitmq*
for all 4 new hosts with tag: configure 

rabbitmq user is installed. Will close the ticket. 
Preparation is done. 

Next steps will be deploying the rabbitmq cluster as 5-node changing necessary inventory settings with pull-requests and deploying monitoring. ",,,,,,,,,,,,,,,,,,
"SERVICE CLONE: [ PKI - Deutsche Boerse AG Test CA ] - M7 certificates: 2 certificates with ""ou=m7"" in the DN and expiring in the next 28 days",M7P-5499,91698,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,lw641,lw641,lw641,31/Jan/20 11:41,27/Nov/20 08:50,16/Sep/21 14:11,25/Feb/20 08:59,,6.9.71,7Tops_Sprint1,,,,,,,Certificates,M7PRODOPS,minor,,,,,"Hi Dev team,

Could you please help to check if those test certificates are in use and which env(s)?

Regards, Serhii

—
{code:java}
Certificate                                                Serial                                              Policy ID  Issue date  Expiry date   Revocation date   Remaining days
cn=AS20001,ou=AS2,ou=M7,ou=Energy,o=Deutsche Boerse,c=DE   433721431090388347743661732026097554590713192719    469        17/02/2017   17/02/2020                      21
cn=AS20002,ou=AS2,ou=M7,ou=Energy,o=Deutsche Boerse,c=DE   558212720724741627619613335598445889940371631556    469        17/02/2017   17/02/2020                      21
{code}",,cf948,iu252,lw641,nn236,wn626,,,,,,,,,,,,,,,SERVICE-5467,,,,,,,,,SERVICE-5619,SERVICE-5618,,,,,,,,,,"19/Feb/20 10:08;lw641;as20001.p12;https://jira.deutsche-boerse.com/secure/attachment/80537/as20001.p12","17/Feb/20 07:32;iu252;as20001.zip;https://jira.deutsche-boerse.com/secure/attachment/80404/as20001.zip","19/Feb/20 10:08;lw641;as20002.p12;https://jira.deutsche-boerse.com/secure/attachment/80538/as20002.p12","27/Feb/20 11:43;iu252;publicCert.pem;https://jira.deutsche-boerse.com/secure/attachment/80869/publicCert.pem",,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48988800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx13z:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 85 (PS),Magnificent 7 Sprint 86 (PS),Schmetterling Sprint 87 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91698,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"04/Feb/20 16:29;cf948;Dear [~lw641] this task is more for techops as they can look at machines if certificates are there. This certificate is probably for MTT as there is ou=AS2.","06/Feb/20 16:41;nn236;This needs to be checked in vaults for EPEX and HUPX testing environments whether the serial number is listed there. These vaults are accessible only for OPS team, as it's customer facing envs. It is a client certificate and seems like external one (so ECC).","14/Feb/20 11:50;iu252;HUPX CUTE:

{noformat}
[root@m7hupxcutem7b1 hupx-cute-mtt1]# keytool -list -v -keystore keystore.p12 | more
Enter keystore password:  Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: Feb 14, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
{noformat}
","14/Feb/20 11:52;iu252;ELTS LIPA:


{noformat}
[root@m7eltslipam7b1 elts-lipa-mtt1]# keytool -list -v -keystore keystore.p12 | more
Enter keystore password:  Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: Feb 14, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
{noformat}
","14/Feb/20 11:56;iu252;HUPX ASIM:


{noformat}
[root@m7hupxasimm7b1 hupx-asim-mtt1]# keytool -list -v -keystore keystore.p12 | more
Enter keystore password:  Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: Feb 14, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
{noformat}
","14/Feb/20 11:58;iu252;HUPX SIMU:


{noformat}
[root@m7hupxsimum7b1 hupx-simu-mtt1]# keytool -list -v -keystore keystore.p12 | more
Enter keystore password:  Keystore type: PKCS12
Keystore provider: SUN

Your keystore contains 1 entry

Alias name: as20001 - ds, ke
Creation date: Feb 14, 2020
Entry type: PrivateKeyEntry
Certificate chain length: 3
Certificate[1]:
Owner: CN=AS20001, OU=AS2, OU=M7, OU=Energy, O=Deutsche Boerse, C=DE
Issuer: CN=TEST Deutsche Boerse AG CA, O=Deutsche Boerse AG, C=DE
Serial number: 4bf8bdda317a65d556484eac51f0208c8453210f
Valid from: Fri Feb 17 14:56:29 CET 2017 until: Mon Feb 17 14:56:29 CET 2020
{noformat}
","14/Feb/20 13:43;nn236;The certificate used by ELTS LIPA, HUPX CUTE and HUPX SIMU is expiring also on Feb 17 2020.

Therefore, a new certificate needs to be requested to be generated. After that, it needs to be installed by TechOps in all these environments. ECC needs to be given the new certificate and requested to install it on their server, ideally at the same time. after the installation, a restart of MTT needs to be performed.

Note: it's not needed to take care of HUPX ASIM as MTT is not supposed to work there.","14/Feb/20 14:28;lw641;I've requested PKI team to renew mentioned certificates.","14/Feb/20 14:30;nn236;[~iu252] could you please also check the MTT certificates in ELTS CUTE, ELTS CTPB and ELTS ACUT? I do not know with certainty whether MTT was deployed there in the past. Thank you, J.","14/Feb/20 14:48;lw641;[~iu252] as I wrote in slack, PKI team needs copies of expiring certificates to find them and renew. Could you please export those and attach here? Thanks!","17/Feb/20 07:19;iu252;[~nn236], Hello Jana, we don't have any mtt-entries  in vault for these 3 environment (ELTS CUTE, ELTS CTPB and ELTS ACUT).
I also checked the severs, mtt is not installed there.","17/Feb/20 07:29;iu252;[~lw641], certificate attached.
 ","17/Feb/20 13:39;nn236;We agreed with [~lw641] that he will arrange a new certificate /extension of the validity of the attached AS20001 certificate. We decided to disregard the expiry of the AS20002 certificate, as it does not seem to be used in any environment. ","19/Feb/20 10:09;lw641;Hi [~iu252] ,

Please find renewed certificates attached.

[^as20001.p12][^as20002.p12]

I will fwd you password separately.

Do you need a deployment request to install them?

Regards, Serhii","19/Feb/20 13:39;iu252;I'll update the keystore in vault.
Then we need to redeploy mtt.

For deployment we need a request.","19/Feb/20 15:00;iu252;[~lw641], certificate renewed in vault for
HUPX ASIM
HUPX CUTE
HUPX SIMU
ELTS LIPA

Now we can deploy.....","21/Feb/20 11:15;lw641;Opened SERVICE-5618 for deployment to HUPX CUTE / SIMU. No need to deploy on HUPX ASIM.

[~tj898] [~wn626]  should MTT be working on ELTS LIPA?","21/Feb/20 11:25;wn626;MTT should be working on ELTS LIPA

[https://lipa1.epex-lts.m7.deutsche-boerse.com:60764/mtt/admin]","24/Feb/20 14:40;lw641;[~wn626] pls confirm it is completed on ELTS LIPA (SERVICE-5619), then this ticket can be closed.

 ","25/Feb/20 08:57;wn626;ELTS LIPA deployment is done","27/Feb/20 11:43;iu252;I've extracted the public certificate from AS20001.p12:


{noformat}
[enprodauto1 ~/mtt]$ openssl pkcs12 -in as20001.p12  -clcerts -nokeys -out publicCert.pem
Enter Import Password:
MAC verified OK
[enprodauto1 ~/mtt]$ ll
total 12
-rw-r--r-- 1 iu252 users 5772 Feb 27 10:36 as20001.p12
-rw-r--r-- 1 iu252 users 1560 Feb 27 11:07 publicCert.pem
{noformat}


{noformat}
[enprodauto1 ~/mtt]$ openssl x509 -in publicCert.pem -noout -text
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            46:0b:cb:46:55:d5:91:d1:28:73:2d:c3:ff:ea:03:d9:c4:82:cf:fc
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=DE, O=Deutsche Boerse AG, CN=TEST Deutsche Boerse AG CA
        Validity
            Not Before: Feb 18 15:04:16 2020 GMT
            Not After : Feb 18 15:04:16 2023 GMT
        Subject: C=DE, O=Deutsche Boerse, OU=Energy, OU=M7, OU=AS2, CN=as20001
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                Modulus:
                    00:bb:b9:ec:9d:a1:c1:d0:af:f6:1b:9e:9e:e3:f0:
                    eb:2e:00:8c:2e:6b:d7:8d:6f:7b:58:31:5f:ef:96:
                    87:5e:35:3a:43:d7:9b:45:60:82:86:64:ff:0b:6a:
                    a6:c6:bd:af:3e:ca:fd:3b:88:cf:bf:5f:a6:29:8f:
                    d1:ec:61:c8:20:db:f0:57:f4:8f:23:10:dc:5f:5a:
                    1e:e2:e4:74:44:9b:fb:13:d6:80:2e:84:03:f3:a6:
                    e1:13:91:c6:41:5c:3f:90:85:1f:cc:fa:86:06:6d:
                    e7:5b:49:70:71:15:d3:0a:37:dc:51:a9:a2:05:cf:
                    4f:bd:14:e9:f3:90:62:1b:f2:60:f9:50:05:5e:4d:
                    38:0f:81:f3:83:f4:e2:22:a8:41:92:60:8e:9b:a2:
                    2a:5e:95:ef:69:2a:8a:5e:e6:a1:1e:16:73:87:ec:
                    1f:1d:ca:b0:59:83:c5:06:75:19:a1:50:11:98:dd:
                    83:e3:56:8c:1d:e2:8e:1c:97:c0:ab:9b:4e:e2:2c:
                    01:83:a9:d2:ca:64:a6:0f:16:be:67:31:10:82:e7:
                    79:08:81:dd:83:56:66:92:93:3e:85:f4:a2:70:70:
                    dd:c2:0e:88:be:0b:03:ec:bc:c5:40:46:df:e7:b9:
                    3f:79:4d:74:55:fd:23:4e:8b:4d:f8:8c:e2:c7:a4:
                    6e:7f
                Exponent: 65537 (0x10001)
        X509v3 extensions:
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Certificate Policies:
                Policy: 1.3.6.1.4.1.22557.10.2.2.14
                  User Notice:
                    Explicit Text: Test Use Only

            X509v3 Key Usage:
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage:
                TLS Web Client Authentication
    Signature Algorithm: sha256WithRSAEncryption
         54:05:67:bd:f3:a3:cb:85:f2:ae:d8:f4:eb:7d:de:9e:80:b7:
         10:ec:00:e0:81:83:56:84:2c:23:bf:be:a5:07:d8:7a:28:fb:
         52:70:f7:c6:46:f2:85:3f:f0:52:22:a8:a0:e8:46:76:c6:4f:
         dd:cb:65:e9:6d:e6:a6:61:58:14:f3:79:d3:b1:c3:66:63:eb:
         77:f0:d2:58:27:ac:fd:36:d7:c1:58:f0:a6:a6:6a:1c:da:d2:
         b2:21:0a:32:71:bc:60:a5:97:a9:ed:31:a1:9f:62:86:67:4e:
         5d:9a:7f:9e:37:2b:83:7b:b2:50:3c:8b:be:60:54:e4:3d:b8:
         de:40:48:19:0a:99:ab:c3:27:09:51:35:51:2d:61:76:b1:d9:
         d3:9e:46:77:05:99:66:53:17:32:5f:f2:78:38:66:4f:56:18:
         2f:80:0f:3a:e1:15:fd:e6:27:0b:d9:b8:a9:19:9d:4c:16:c9:
         57:89:08:c6:13:d0:ee:9c:b2:3f:a6:92:78:f2:77:2c:76:bd:
         46:0f:e6:9c:c5:4b:b7:60:41:e0:9b:33:1e:df:50:52:ff:51:
         c4:55:d9:8b:ab:8f:b6:69:a7:01:96:7d:ce:de:4a:f6:80:1c:
         3c:d8:01:f5:77:12:83:8f:62:1c:2b:db:e5:3e:ad:cd:62:45:
         75:2e:56:0e
enprodauto1 ~/mtt]$
{noformat}

 [^publicCert.pem] ",,,,,,,
SERVICE CLONE: Matching bug in LIP A,M7P-5498,91695,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Fixed,cs687,ub113,ub113,31/Jan/20 10:45,27/Nov/20 08:50,16/Sep/21 14:11,31/Jan/20 11:37,,7tops_pre-sprint0_cleanup,,,,,,,,M7PRODOPS,minor,,,,,,"There is a strange behaviour in LIP A:

I've used the TRDOPC01 user to conclude some trades
when i've introduced orders, were displayed in own orders (correct)
when i've matched the orders, those were disappeared from own orders (correct), messages that orders were matched were received (correct), Own trade panel remained empty (NOK), starting receiving heartbeat alerts wich seemed to be triggered by the matching (NOK- strange behaviour) but finally the system was automatically reconnected (i've not received disconnection message)
i've tried to repeat the steps. the result was the same as the first time, but second time i was disconnected, and i was asked to re-login, but when i've tried to re-login i've received the message: ' the core is down or busy.

I've experienced this behaviour (both steps) twice during today. First time when the core was down, i don't know if you did something to solve the issue or the core was setted up again automaticaly. 
Anyway i was able to test this twice, the behaviour is the same.  In this moment the the core is down .

You can find attached the application logs from the second time.

can you, please take a look on this ?

Thank you,

Marius Tone",,cs687,ub113,,,,,,,,,,,,,,,,,,SERVICE-5461,,,,,,,,,,,,,,,,,,,,"31/Jan/20 10:45;ub113;2020-01-29_16-25-56-202_comtrader_logfile.0.log;https://jira.deutsche-boerse.com/secure/attachment/79943/2020-01-29_16-25-56-202_comtrader_logfile.0.log","31/Jan/20 10:45;ub113;image-2.png;https://jira.deutsche-boerse.com/secure/attachment/79944/image-2.png",,,,,,,,,,,,,,sw455,,,,,,,,added the sequence like described above. ,,,,,,,,OPCOM,,,,,,Report a problem or bug,,,,,,,,,,51321600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,31/Jan/20 10:45,,[],,,,,,,,,,,M7T,,,,"2|hzx1fj:",9223372036854775807,,,,No,,,,,,,,,,"missing sequence in the database during the migration of patroni. 
properly the sequence was missing in the flyway script. 


{code:java}
org.postgresql.util.PSQLException: ERROR: relation ""cx_119_settlement_history_seq"" does not exist
{code}
entry from cor log file
",,,,,,,,X-Men Sprint 85 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,Ana will handle that with the customer. ,1.0,,,,,,,,,"{""issueId"":91695,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,LIPA,,,,"31/Jan/20 10:46;ub113;Connection issues were resolved by [~cs687]

I asked the customer to reproduce his steps once again, to verify that he, indeed, caused unresponsiveness of the environment.","31/Jan/20 11:01;cs687;Both cor´s were running as *SLAVE* node and were disconnected from XBID 

{code:java}
[root@m7xrpmlipam7b1 xrpm-lipa-cor1]# curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[root@m7xrpmlipam7b1 xrpm-lipa-cor1]

[tomcat@m7xrpmlipam7b2 xrpm-lipa-cor2]$ curl http://localhost:8079/m7core/health
{""status"":""DOWN"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""DOWN"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[tomcat@m7xrpmlipam7b2 xrpm-lipa-cor2]$
{code}

stopped both cor´s and started only cor1 which were later on running as MASTER and were connected to XBID

*root cause* was a missing sequence in the cor/m7b Database.
I added the sequence on the leader host m7simupdb2. 

{code:java}
org.postgresql.util.PSQLException: ERROR: relation ""cx_119_settlement_history_seq"" does not exist

postgres=# \c m7txrpmlipam7b
psql (9.2.24, server 11.5)
WARNING: psql version 9.2, server version 11.0.
         Some psql features might not work.
You are now connected to database ""m7txrpmlipam7b"" as user ""postgres"".
m7txrpmlipam7b=# SELECT * FROM information_schema.sequences;
 sequence_catalog | sequence_schema |               sequence_name                | data_type | numeric_precision | numeric_precision_radix | numeric_scale | start_value | minimum_value |    maximum_value    | increment | cycle_option
------------------+-----------------+--------------------------------------------+-----------+-------------------+-------------------------+---------------+-------------+---------------+---------------------+-----------+--------------
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_213_contract_name_format_history_id_seq | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | envers_sequence                            | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | hibernate_sequence                         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_103_quote_request_id_seq                | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_212_contract_name_format_id_seq         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_410_trading_phase_trading_phase_id_seq  | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_268_risk_management_id_seq              | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
{code}


added the sequence 
{code:java}
do $SEQ_CX_119_SETTLEMENT_HISTORY$
  declare start_id int;
begin
    select coalesce(max(history_id)+1,1) from CX_119_SETTLEMENT_HISTORY into start_id;
    execute 'CREATE SEQUENCE CX_119_SETTLEMENT_HISTORY_SEQ
                START WITH ' || start_id || ' INCREMENT BY 1
                OWNED BY CX_119_SETTLEMENT_HISTORY.HISTORY_ID' ;
end $SEQ_CX_119_SETTLEMENT_HISTORY$;

m7txrpmlipam7b=> SELECT * FROM information_schema.sequences;
 sequence_catalog | sequence_schema |               sequence_name                | data_type | numeric_precision | numeric_precision_radix | numeric_scale | start_value | minimum_value |    maximum_value    | increment | cycle_option
------------------+-----------------+--------------------------------------------+-----------+-------------------+-------------------------+---------------+-------------+---------------+---------------------+-----------+--------------
 m7txrpmlipam7b   | m7txrpmlipam7b  | cx_119_settlement_history_seq              | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,
EPEXMT CLONE: Core is down or busy in LIPA ,M7P-5495,91691,,Bug,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Critical,Cannot Reproduce,qo288,qz412,qz412,31/Jan/20 09:09,04/Mar/20 15:12,16/Sep/21 14:11,27/Feb/20 10:24,,7Tops_Sprint1,,,,,,,,M7PRODOPS,,,,,,,Core is down or busy in LIPA,,fj021,lw641,qo288,qz412,,,,,,,,,,,,,,,,EPEXMT-2474,,,,,,,,,,,,,,,,,,,,"31/Jan/20 09:09;qz412;core is down or busy in LIPA.PNG;https://jira.deutsche-boerse.com/secure/attachment/79941/core+is+down+or+busy+in+LIPA.PNG",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,48556800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,30/Jan/20 10:47,M7ADM001/Test0101,[],,,,,,,,,,,M7T,,,,"2|hzwvgn:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,X-Men Sprint 85 (PS),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91691,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,LIPA,,,,"31/Jan/20 11:52;fj021;Both core seems to be running just fine : 
{code:java}
[fj021@m7eltslipam7b2 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""CONNECTED""}}}}

[fj021@m7eltslipam7b1 ~]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""sob"":""DISCONNECTED""}}}}[
{code}
We can notice a big decrease in activity and increase of Exceptions right after what seems to be a DNS issue (UnknowHostException) 29th morning for ENQ1. ENQ2 seems fine. 

[https://kibana.energy.svc.dbgcloud.io/app/kibana#/discover?_g=h@5575c8f&_a=h@b915d65]

 

Gonna try restarting ENQ1 with Techops, it seems to be in an unhealthy state.","31/Jan/20 14:00;fj021;[~cs687]restarted ENQ1 and everything seems to be back to normal.

We're working on clarifying the root cause .","31/Jan/20 15:35;fj021;Waiting on Techops contacting Network team for DNS issues on 29th.

edit: Network team contacted by [~qo288]","10/Feb/20 17:55;qo288;SAP 20730759 in progress","14/Feb/20 12:11;qo288;We had a chat with Andreas Sedler from CCI team was interested to see the IPs, routing tables, /etc/resolv.conf and /etc/nsswitch.conf on some VMs and we didnt find anything obviously wrong
 
 
He said that he will do some troubleshooting on his part and I also made a query to Kibana to get all UnknownHostExceptions from this week and I got a 240M text file that I will format and see if this still occurs
 
 
Now the plan is to leave tcpdump running on port 53/udp on some host for a longer time, so I will be asking the dev team which environment we could use, but this is probably for the beginning of next week","20/Feb/20 09:33;qo288;Hi [~fj021] [~cs687] [~qz412] ,

We discussed this problem during a call with Andreas Sedler from CCI Team.

We checked the config in /etc/resolv.conf and /etc/nsswitch.conf on the affected hosts and all seemed OK.

Andreas stated that there is no visible issue in DNS monitoring.

Final agreement was to monitor the problem and in case of any further issues - to run tcpdump for a longer time on 53/udp to see exactly where its failing.

Now, with the extracted logs for ALL environments, I cant see this error message anymore and everything seems stable. Is this enough to close this issue then? I literally see no other direction to troubleshoot it...

Could you please comment?","20/Feb/20 10:23;fj021;Hello [~qo288] ,

 

Technically this task should now go to the new ProdShift (Schmetterling) but for some reason this ticket wasn't shifted (twice ^^''') and no one can see it in their current sprint.

I chatted with [~MG726] and [~qz412] , basically if we can close it, let's. But if customer really want more analysis and a defenite answer as to ""why?"" then will shift this task to current ProdShift to work on it more.

 

[~lw641]: Based on Piotr last response, do you think we can close this ticket ? Even without any satisfactory root cause. 

 

Regards,

Aurélien","21/Feb/20 16:14;lw641;I think we shouldn't invest more time in the issue, knowing it is difficult to get any details from the CCI team. It is also not worth the effort cause it's LIPA env. However, taking into account situation with EPEX, I would like [~sJ194] or [~pn508] to help with explanation why LIPA was down for half of the day on Jan 30th 2020 and what kind of root cause we wanna share to EPEX.

Cheers

Regards, Serhii","02/Mar/20 15:01;qz412;Response to the customers, aligned with [~pn508]:

Dear Alaa,

we have put significant effort into investigation of this issue but were unable to narrow down the reason. It seems the issue was caused by a technical / network glitch isolated to the LIPA environment but we have no certain proof in any logs or broad range of monitoring tools' outputs we have investigated. All environments have been analyzed for the symptoms similar to this issue but none were found. We have also enhanced monitoring of the environment to catch the issue in case it repeats but there was no other occurence.We are not able to continue the investigation in any meaningful way and suggest we keep monitoring the occurence and react propmply should it occur again.

Best regards,

M7Product Team","03/Mar/20 12:33;sw455;Ondra posted comment to customers in linked EPEXMT-2474 - no further investigation planned on this issue - closing ticket",,,,,,,,,,,,,,,,,,
Update Ops Procedures: Setting up NEW VM's when adding components instead of modifying existing VM,M7P-5493,91679,,Task,Open,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,,,sw455,sw455,30/Jan/20 15:38,08/Sep/21 15:20,16/Sep/21 14:11,,,,,,,ansible,infrastructure,,,7tops,M7PRODOPS,,,,,,"*Story*: development suggests that it would be less risky to set up a VM with all required components and resources when performing changes like adding an additional rabbitMQ node to a cluster, and then redirecting traffic or failing-over to that node

 

 ",,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51321600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzymbj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,OPS backlog,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91679,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Jan/20 15:39;sw455; [~jv861] [~pw231] [~cf948] [~oy574] [~op211]  [~wm282] - this is one of the tasks we discussed in yesterday's meeting. Please feel free to add details.

*This one definitely needs refinement.*",,,,,,,,,,,,,,,,,,,,,,,,,,,
Ops Playbook: Migrate Slave COR VM,M7P-5492,91678,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,sw455,sw455,30/Jan/20 15:15,07/Oct/20 11:37,16/Sep/21 14:11,30/Sep/20 15:57,,6.11.36,7tops_sprint102,,,ansible,infrastructure,,,M7PRODOPS,XL,,,,,,"*Story:* DEVOPS needs a playbook to migrate the virtual machine hosting an M7T core node from one data-center to another in preparation for DC wide maintenance, or in response to DC wide disaster.

 

*Task:*
 * Create a playbook to shutdown Slave COR node and migrate its VM from one data center or physical host to another
 ** the playbook should somehow ensure that the migrated VM is distributed between physical hosts when migrating a slave cor's VM to the same DC as the master is running in (Per [~wm282]  this should be possible.)
 * Validate playbook by exercising it several times in a Production-like environment (e.g. SYT1)
 ** i.e. monitor for any disruption at time of migration, exercise technical testing after migration (e.g. do fail-over scenarios still work as expected?)",,ed812,pn508,qo288,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"closed nothing to do 

confirmed by Piotr",,,,,,,,,,,,,,,,,,,,,,,,43632000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzmx9b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91678,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Jan/20 15:16;sw455;[~matemar] [~jv861] [~pw231] [~cf948] [~oy574] [~op211]  [~wm282] - this is one of the tasks we discussed in yesterday's meeting. Please feel free to add details.","13/Feb/20 12:00;sw455;Notes from refinement 13.02:
 * Goal of task seems clear to team, but there are questions about the solution:
 ** Should we, Energy, work on this before we can fully do it ourselves? Currently we think it still requires requests to Cloud Team
 ** How is this affected with the expected future infra team? How should we collaborate on this task's solution?","14/Feb/20 14:49;qo288;I had a chance to discuss the idea with [~wm282]

At the moment it looks like there are some blocking points before we can start with implementation and the major points are:
 * Access to ESXi API. There is idea to run a workshop for TechOps team to understand the architecture and current processes before we can get access to the API to automate teska with Ansible.
 * Major changes required to Ansible inventory. Such playbook would need to have tasks that refer to a running application instance name (to check if master/slave) and also tasks that need to be ran on VM hostnames (to migrate VM and storege to the other DC...)

I will also write down here some other technical points that I think need to be adressed (later in the implementation phase)
 * How do we handle VMs with multiple instances of them? Or for example H2H4U that is currently running along with cor1?
 * Do we worry about possible FW requests? Is IP addressing similar in both DCs?","27/Feb/20 13:36;sw455;Will call short meeting with [~cv179] and [~qo288] and [~wm282]  to clarify implementation steps and decide whether this can and should be done now or whether it should be done later","29/Apr/20 13:05;pn508;To be done after ESX migration",,,,,,,,,,,,,,,,,,,,,,,
Operational Playbook for RabbitMQ cluster changes,M7P-5489,91672,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,sw455,sw455,30/Jan/20 14:59,14/Jan/21 14:20,16/Sep/21 14:11,28/Jul/20 10:18,,6.10.157,7tops_sprint12,,,ansible,infrastructure,,,M7PRODOPS,,,,,,,"*Part of EPIC: M7P-5669* Ansible Playbooks for RabbitMQ Cluster Changes

Refined description:
Current RabbitMQ cluster management procedures are fine as is. Our quick-reference documentation needs some revision to make it easier to use by operations (examples and parameters should be better described), and needs to be extended to cover several use cases that are not yet there (remove, reset, -forget_cluster_node-, -update policy-, ...)


 
??Original description:??
{quote}
*Tasks:*
 * Create and Operational Playbook for RabbitMQ cluster changes (M7P Backlog). The playbook should consider all potential rabbitmq cluster actions we expect we might need (set up of full cluster from scratch, removing single/multiple node(s), adding single/multiple node(s), tearing down full cluster, etc. etc.)
 * Review playbook with development
 * Test all playbook actions several times in multiple pre-prod and prod environments to ensure we are confident to make rmq changes with clear results
{quote}",,cs687,cv179,ed812,pn508,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"added new Chapters to the confluence page 
https://confluence.energy.svc.dbgcloud.io/display/ET/RabbitMQ+Maintenance+and+troubleshooting#RabbitMQMaintenanceandtroubleshooting-Prepareforaction

reviewed by Roman K. ",,,,,,,,,,,,,,,,,,,,,,,,35856000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5669,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx9un:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"new chapters:
* 3.7 Remove Cluster-Node (forget_cluster_node)
* 3.8. Stop Cluster-Node (stop_app)
* 3.9. Reset Cluster-Node (reset)
* 3.10. List Policies (list_policies)
* 3.11. Update Policies (set_policy)
* 3.12. Clear Policies (clear_policy)",,,,,,,,,,"{""issueId"":91672,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Jan/20 15:00;sw455;[~matemar] [~jv861] [~pw231] [~cf948] [~oy574] [~op211]  [~wm282] - this is one of the tasks we discussed in yesterday's meeting. Please feel free to add details.","13/Feb/20 11:41;sw455;Notes from refinement:

Needs to be split into an Epic with multiple tasks

Solution proposal still needs further discussion with stakeholders.","27/Feb/20 13:39;cv179;current documentation: [https://confluence.energy.svc.dbgcloud.io/display/ET/RabbitMQ+Maintenance+and+troubleshooting]

... deserves a major make up - examples and parameters need a better description. Missing activities should be added (remove, reset, forget node, update policy, ...)","29/Apr/20 13:04;pn508;[~sw455] will update already existing documentation","28/Jul/20 09:02;cs687;UPDATE: 
Added new Chapter: *Remove Cluster-Node (forget_cluster_node)*
Added new Chapter: *List Policies (list_policies)*
Added new Chapter: *Update Policies (set_policy)*
Added new Chapter: *Clear Policies (clear_policy)*
Added new Chapter: *Stop Cluster-Node (stop_app)*
Added new Chapter: *Reset Cluster-Node (reset)*","28/Jul/20 10:18;cs687;done","28/Jul/20 10:19;cv179;I reviewed and confirm, all commands are provided with proper examples. More details can be obtained by simply visiting the rabbitmq website with detailed documentation, but for our operational tasks, those very concise descriptions and examples are exactly what we need.

Nevertheless, about once a year, the docs deserve a review, e.g. for parameter changes in the commands...","28/Jul/20 13:24;sw455;Thanks guys! Closed the epic and thinked INIT ticket as well",,,,,,,,,,,,,,,,,,,,
"Create ansible playbook: ""Stop Slave""",M7P-5488,91671,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,qo288,sw455,sw455,30/Jan/20 14:47,01/Sep/20 23:21,16/Sep/21 14:11,26/Aug/20 09:18,,6.10.212,7tops_sprint13,,,ansible,infrastructure,,,7tops_comm,M7PRODOPS,,,,,,"_Item from 'M7T 2020 Stabilization Measures' Meeting 29.01_

*Background*: In preparation for the 2019 HAU PWR Mtc, we checked to ensure that all M7T Core nodes were running master in IXE before the weekend. After we finished this check, we had a failover occur on ELTS production. The failover was successful and did cause any noticeable disruption. On Saturday, just before the maintance, we followed the instructions to stop the core running in HAU - which we did not catch was master at that time. This cause another failover back to IXE, which was not as smooth as it should have been.

 

*User story*: Ops needs a script/playbook to gracefully stop an m7t SLAVE core node. If the node the playbook is run against is NOT running as 'slave' at that time, the script should stop, and report back ""Node X not SLAVE"".

 

PS: I don't know if we should extend this to other components beyond just core.

 

 ",,ed812,qo288,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Jenkins job and playbook/role in place, needs some more testing before going to production mode which will be part of another ticket",,,,,,,,,,,,,,,,,,,,,,,,48556800,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzpr8v:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 0,7tops Sprint 1,7tops Sprint 2,7tops Sprint 3,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,7tops Sprint 10,7tops Sprint 11,7tops Sprint 12,7tops Sprint 13,7tops Sprint 14,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91671,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"30/Jan/20 14:47;sw455;[~matemar] [~jv861] [~pw231] [~cf948] [~oy574] [~op211]  [~wm282] - this is one of the tasks we discussed in yesterday's meeting. Please feel free to add details.","10/Feb/20 18:21;qo288;[~sw455] Its easily doable as 'run anything on any module working as slave' and I would proceed that way just to keep it extendable in the future. Also, do we care about slave-slave scenario?","11/Feb/20 09:34;sw455;Hi [~qo288]  -

We had this in mind for executing changes, like deploying to a module or stopping services on a module - it should just be a safety so we don't shut down a running master accidentally.

So yes - I agree with your proposal:
{quote} 'run anything on any module working as slave'
{quote}
If you want to refine the requirement further, the guys I pinged above would all be able to give some more input.","03/Mar/20 10:53;sw455;[~qo288] [~iu252]  - can Alex help finish this task before end of this sprint?",,,,,,,,,,,,,,,,,,,,,,,,
System validation script for new VMs,M7P-5485,91667,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,sw455,sw455,sw455,30/Jan/20 12:05,18/Mar/20 13:26,16/Sep/21 14:11,16/Mar/20 16:07,,7tops_sprint2,,,,infrastructure,,,,M7PRODOPS,,,,,,,"_Item from 'M7T 2020 Stabilization Measures' Meeting 29.01_

*WHY:* When setting up a new VM for new components or migrating existing components, we need to be sure we have the expected system resources and configuration in the VM prior to executing the change.

 

*Task:* Create a script that will inspect a virtual machine and report back results compared to expect values for system resources and connectivity: 

Script should check:
 * Number of Cores
 * Amount of RAM
 * ulimit setting
 * Disk space
 * Connection to expected end-points (eg db, xbid, etc)

 

Notes:
 * Roman has already built a script which checks the Number of Cores and Amount of Ram. This could be extended to to use for the rest of this purpose
 * Would be nice to have as self-service task
 * Some documentation is needed (process how and when to use)",,cv179,ed812,pw231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,INIT-494,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47347200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx733:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91667,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"30/Jan/20 12:08;sw455;[~matemar] [~jv861] [~pw231] [~cf948] [~oy574] [~op211]  [~wm282] - this is one of the tasks we discussed in yesterday's meeting. Please feel free to add details.","28/Feb/20 15:49;cv179;find the current output and self service here: [https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/Self-Service/job/VM%20report/9/console]

 

the output looks like this for a rabbitmq instance:

Hostname 
--------

m7eltssimuamq2 (IP: 10.139.59.174)

OS
---

RedHat 7.6

Memory
------

7817 MB

CPUs
----

1

ulimit settings
---------------

core file size (blocks, -c) 0
data seg size (kbytes, -d) unlimited
scheduling priority (-e) 0
file size (blocks, -f) unlimited
pending signals (-i) 31177
max locked memory (kbytes, -l) 64
max memory size (kbytes, -m) unlimited
open files (-n) 65000
pipe size (512 bytes, -p) 8
POSIX message queues (bytes, -q) 819200
real-time priority (-r) 0
stack size (kbytes, -s) 8192
cpu time (seconds, -t) unlimited
max user processes (-u) 4096
virtual memory (kbytes, -v) unlimited
file locks (-x) unlimited

filesystem utilization
----------------------

/dev/mapper/rootvg-lv_root ext4 3.8G 1.9G 1.8G 51% /
/dev/sda1 ext3 190M 140M 40M 78% /boot
/dev/mapper/rootvg-lv_patrol ext4 976M 435M 475M 48% /opt/patrol
/dev/mapper/rootvg-lv_elts ext4 2.0G 101M 1.7G 6% /elts
/dev/mapper/rootvg-lv_tmp ext4 969M 2.6M 900M 1% /tmp
/dev/mapper/rootvg-lv_logs ext4 2.0G 902M 933M 50% /elts/logs
/dev/mapper/rootvg-lv_var ext4 2.0G 985M 888M 53% /var
/dev/mapper/rootvg-lv_varlog ext4 969M 111M 792M 13% /var/log

connectivity
------------

ldap:
- host: m7testldap2
 port: 389
 state: started
- host: m7testldap1
 port: 389
 state: started

 

 

Now I have a huge issue:

At which point in time we want to verify the VM?
From the discussion I understood, it should be done when the VM is ready but not yet introduced to the inventory. But in this case, we just don't have any idea about connectivity details required.

So I assume, we need the instance to be introduced to the inventory. But then, this whole feature overlaps with the version info table. And maybe we want to find a way to merge functionality in some way.

 

If I should continue with connectivity, please provide exact list for each group (module / component), just like:
 * Rabbitmq: connection to LDAP
 * M7tcor: ???
 * m7tenq: ???
 * h2h4u: ???

And for sure, in case of a NEW environment, this connectivity might still not tell us anything, as the remote service could not be set up at all. Is this acceptable? In this case, the connection test must be repeated manually.

 

 ","13/Mar/20 11:50;pw231;Me and [~cv179] reviewed the report and agreed to add two things:
- note to the job that the report is in console and your mailbox
- connectivity check to DB

Otherwise it perfectly suits the purpose and we shall use it with every new VM as part of the review ([~rehapav] ) .","16/Mar/20 16:07;sw455;Discussed with Business Operations team and [~rehapav]

We will add validating VM sizing/capacity as apart of validation/planning process as needed.

Thanks!",,,,,,,,,,,,,,,,,,,,,,,,
Add monitoring for missing/delayed ADMIN TC540 report,M7P-5484,91666,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,hw120,dp007,dp007,30/Jan/20 12:00,06/May/20 11:08,16/Sep/21 14:11,28/Apr/20 16:24,,7tops Sprint6,,,,Monitoring,RE,,,M7PRODOPS,Monitoring,MONITORING,Reporting_Engine,,,,"Add ADMIN TC540 report generation to monitoring. Send alert if expect ADMIN TC540 report is not generated at expected time.

 

m7_rep_generation_time under metrics_m7

tags:
 * client=elts
 * client_environment=prod
 * report=TC540
 * subscriber=ADMIN

 

If at 03:00 the gauge/value have not been increased in last 3 hours (=that day) we need to add a kapacitor message in m7_prod_alerts + kapacitor (critical/prio p1) to opsgenie (triggering the bizops oncall shift)",,dp007,hw120,,,,,,,,,,,,,,,,M7P-5715,,,,,,,,,,,,,,,,SERVICE-6108,M7P-5348,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,ELTS,,,,,,,,,,,,,,,,43632000,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5582,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx7on:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 3,7tops Sprint 4,7tops Sprint 5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91666,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,PROD,,,,"21/Apr/20 11:21;hw120;- Created kapacitor tick script alert
 - Using cron scheduler [https://docs.influxdata.com/kapacitor/v1.5/nodes/query_node/#cron]
 - Check/alert runs every 30 min. from 4:00am till 8:00am and it queries 10h window of data
 - Metrics
 m7_rep_generation_time under metrics_m7
 tags:
 client=*
 client_environment=*
 report=TC540
 subscriber=ADMIN
 - Condition:
 - OK: if incremented by 1 in last 10 hours window
 - Critical: if not incremented by 1 in last 10 hours window

To test in influx/chronograf query from kapacitor
{code:java}
SELECT mean(""value"") AS ""mean"" FROM ""metrics_m7"".""autogen"".""m7_rep_generation_time"" WHERE time > now() - 24h AND ""client""='elts' AND ""client_environment""='prod' AND ""report""='TC540' AND ""subscriber""='ADMIN' GROUP BY time(15m), ""client_environment"", ""client"", ""product"", ""report"", ""subscriber"" FILL(null){code}
 ","21/Apr/20 11:23;hw120;What remains is to connect alerting to call-alert service like alarmtilt or opsgenie and call bizops hotline number.","28/Apr/20 16:24;hw120;Together with Hugo we managed to test kapacitor alert call notification and create alert in opsgenie to call when this alert is triggered.

Call alert will be triggered only from prod environments.

[https://deutsche-boerse.app.eu.opsgenie.com/settings/integration/edit/Kapacitor/f2a2f468-ffc6-4de9-91e9-6ac5a3997b24]

Done.",,,,,,,,,,,,,,,,,,,,,,,,,
Add alerting for MTT trades stuck in 'INIT' status,M7P-5473,90948,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Won't Do,sw455,sw455,sw455,10/Jan/20 11:01,14/Jan/21 14:20,16/Sep/21 14:11,06/Nov/20 10:38,,7tops_sprint105,,,,Monitoring,MTT,,,7tops_comm,M7PRODOPS,MONITORING,,,,,"Based on the problem: Service-4362. See the incident report there.

 

Basically, MTT should never have trades in 'INIT' status for longer than a minute or two in Production. For HUPX, failure to report trades via MTT to ECC is a critical failure. It will always result in an emergency.

 

I propose to find a way to detect these situations early, but looking at MTT data and triggering an alarm if trade status is stuck in an incorrect state for too long. I would start with HUPX production for this alerting.",,cs687,hw120,jv861,sJ194,,,,,,86400,86400,,0%,86400,86400,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,"Won't do: Alerting is more difficult than originally expected. Would be possible, but because MTT is now much more stable, and we haven't had any issues like this since September 2019, we do not need to spend time making this alert anymore.",,,,,,,,,,,,,,,,,,,,,,,,41731200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-176,,,,,,,,,,,,,,,[],,,,,,,,,,,,,,,"2|hzygrb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 103,7tops Sprint 104,7tops Sprint 105,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":90948,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"26/Mar/20 13:32;sJ194;[~sw455] to discuss with Dev and bring it to DevOps CoP","06/Apr/20 17:31;sw455;Added to DevOps CoP:

I want to add alerts to our alerting jobs that trigger when matched trades stay in INIT state for an extended period (~5 minutes)

I need M7 Trading Development to propose how we can identify this state to add the aler","06/Apr/20 18:37;jv861;The state is held by M7, so there are several options on how to check it:
* Directly in database, table {{cx_118_settlement}}
* Watch logs for settlement messages
** This means monitoring has to watch for all INIT states, store id of the trade and check later, if some state update was sent with the same id
* Reuse current alerting system
** If alerts are set up on Trade Acknowledgement page and triggered, M7 logs message like this: ""{{Sending alarms for those settlements (count: 1): [Settlement{id=2068, st=INIT, trade {id=1730234, v=2, st=CNCL}}]}}""
** Disadvantage is, that we get the alert at the same time as a client

We could also write a little monitoring app, that would query settlement state using M7 API, but I'd like to use this approach only if absolutely necessary and no other approach works.

Also keep in mind, that EPEX uses only a subset of settlement states when compared with HUPX.","07/Apr/20 14:27;sw455;We should also consider way to trigger auto-healing (e.g. restart of MTT process) on alert, not only alerting.","18/May/20 12:00;cs687;Like discussed with [~hw120] today, we can solve the it by log-monitoring 
what [~jv861] supposed as a solution as well 

{code:java}
Watch logs for settlement messages
This means monitoring has to watch for all INIT states, store id of the trade and check later, if some state update was sent with the same id
{code}

Ticket can be handled as refined. 
","18/May/20 17:30;hw120;I gave it a bit of time to think about it and log alerting would not be possible as described here.

The problem is that elasticsearch watcher alerts can base their alerts only on queries, can't store values somewhere and then use those variables in the next eval condition.

 

Possible options
 * first option, from the database, it would require to create script to extract the data and transform them into form of metrics, but the question would be where(on which host) we would run such script
 ** if it could be done in form of single sql select, we could possibly try to implement it into our pg_watch2 postgres instance monitoring
 * send monitoring data from mtt instance to statsd daemon, for example send trade id and status 1 if INIT state is present, 0 if it isn't. Then we can setup alert on specified condition
 ** with group by influxql query it should be possible to group tradeid with state, thou it would be wise to test it first

 ","20/May/20 17:08;jv861;Just for the record, if we want to go the simple query way in the future, the qurey could look like this (not tested, exact values to be discussed):

{code:sql}
SELECT id, trade_id FROM cx_118_settlement WHERE mod_type_code = 'INIT' AND last_update_time < now() - 10 minutes
{code}

Alert should be raised if this query returns anything, either with number of results or if posible even with the actual returned IDs.",,,,,,,,,,,,,,,,,,,,,
Capture m7-si mails via OpsGenie,M7P-5471,90947,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,tj898,sw455,sw455,10/Jan/20 10:57,17/Dec/20 15:26,16/Sep/21 14:11,17/Jun/20 09:55,,6.10.105,7tops_sprint8,,,,,,,M7PRODOPS,Monitoring,,,,,,"We have had some issues where critical incidents were reported via mail (See for example SERVICE-4362.

Now that the amount of mails coming to [m7-si@deutsche-boerse.com|mailto:m7-si@deutsche-boerse.com] is extremely low, I propose that all mails that come there are automatically forwarded to OpsGenie.

 

I would add some logic to parse the mails, and for this initial integration:

1) add a list of emergency subject lines, like the automated ""Missing Trade Acknowledgement"" alerts

2) Ignore certificate and logparser mails (+ any other recurring mails that are known 'non emergencies')

3) add a list of 'VIP' senders, like the M7T market ops addresses maybe, that always trigger at least a warning to Biz Ops",,lw641,tj898,,,,,,,,115200,115200,,0%,115200,115200,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jun/20 09:27;lw641;FW Please forward ALL incoming emails.;from m7-si@deutsche-boerse.com;to m7-si@deutsche-boerse.eu.opsgenie.net;Thanks;Regards Serhii.msg;https://jira.deutsche-boerse.com/secure/attachment/84915/FW+Please+forward+ALL+incoming+emails.%3Bfrom+m7-si%40deutsche-boerse.com%3Bto+m7-si%40deutsche-boerse.eu.opsgenie.net%3BThanks%3BRegards+Serhii.msg",,,,,,,,,,,,,,,sw455,,,,,,,,Feature implemented,,,,,,,,,,,,,,,,,,,,,,,,39398400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwxon:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":90947,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jan/20 12:54;tj898;Hi, [~sw455]

What would be the priority that should be assigned to those?

We already have the Unacknowledged Trades email arriving to Opsgenie, Just need to know how to process them, and if Oncall should triggered by them.

Cheers,

HUgo","30/Jan/20 16:30;sw455;[~tj898] - good question. Let's ask during refinement for this issue - that way we can decide together between OPs+Dev what level of alert we should get for these notifications","03/Feb/20 08:59;tj898;Integration set up in Opsgenie.

Forwarding of the emails arriving to the shared mailbox requested to Exchange team.

Setting the ticket to Waiting.","17/Jun/20 09:28;lw641;[^FW Please forward ALL incoming emails.;from m7-si@deutsche-boerse.com;to m7-si@deutsche-boerse.eu.opsgenie.net;Thanks;Regards Serhii.msg]

This item is outstanding, see attached msg from security team.","17/Jun/20 09:37;tj898;Hello, [~sw455] / [~lw641] .

From the point of view of the Opsgenie integration, everything was done. The tool is ready to parse the emails whenever they will reach the dedicated address. Further filtering is applicable according to our needs (adjusting priority and possible alerting.

Regards,

Hugo","17/Jun/20 09:55;tj898;Feature implemented",,,,,,,,,,,,,,,,,,,,,,
M7T SIMU - CCS not onboarded,M7P-5469,91225,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Jan/20 13:49,17/Dec/20 15:26,16/Sep/21 14:11,19/Feb/20 06:58,,6.9.71,7tops_sprint0,,,,,,,M7PRODOPS,TechOpsBoard,,,,,,"On board CCS tool for M7 Simulation level environments (list of envs below) 
 [^CCS on-boarding process.docx]

 

 
|-M7SIMUPDB1-|
|-M7SIMUPDB2-|
|-M7SIMUPDB3-|
|-M7SIMUPDB4-|
|-M7HUPXSIMUM7B1-|
|-M7HUPXSIMUAMQ1-|
|-M7XSOPSIMUM7B1-|
|-M7XSOPSIMUAMQ1-|
|-M7EPEXASIMAMQ2-|
|-M7EPEXASIMM7B1-|
|-M7EPEXASIMM7B2-|
|-M7EPEXASIMAMQ1-|",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/20 10:11;sw455;CCS on-boarding process.docx;https://jira.deutsche-boerse.com/secure/attachment/80194/CCS+on-boarding+process.docx",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49680000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwz7j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91225,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"14/Feb/20 07:20;cs687;*+checked the situation for all the mentioned hosts above:+*

*M7SIMUPDB1*
{code:java}
[root@m7simupdb1 ~]# yum search esmrc
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
====================================================================================================================================================== Matched: esmrc =======================================================================================================================================================
ccsagent.x86_64 : Symantec CCS Agent for Red Hat Linux
[root@m7simupdb1 ~]# yum info ccsagent.x86_64
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.6
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7simupdb1 ~]# ls -all /opt/esm/system/m7simupdb1/db/agtcert.dat
-rw-rw----. 1 root root 258 Jul 12  2019 /opt/esm/system/m7simupdb1/db/agtcert.dat
{code}

Last Run: Service was started 7 of Feb and was stopping at 10 of Feb
{code:java}
[root@m7simupdb1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 07 21:00:02 m7simupdb1 esmrc[15835]: Starting ESM...
Feb 07 21:00:02 m7simupdb1 esmrc[15835]: Starting ESM network server: [  OK  ]
Feb 07 21:00:02 m7simupdb1 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 08 14:04:50 m7simupdb1 su[15705]: (to root) root on none
Feb 08 14:04:50 m7simupdb1 su[15785]: (to ansible) root on none
Feb 08 14:04:50 m7simupdb1 su[15815]: (to scanmgr) root on none
Feb 10 05:00:01 m7simupdb1 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:01 m7simupdb1 esmrc[36818]: Stopping ESM...
Feb 10 05:00:08 m7simupdb1 esmrc[36818]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:08 m7simupdb1 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
{code}




","14/Feb/20 07:25;cs687;*M7SIMUPDB2*

{code:java}
[root@m7simupdb2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.6
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7simupdb2 ~]# ls -all /opt/esm/system/m7simupdb2/db/agtcert.dat
-rw-rw----. 1 root root 258 Jul 12  2019 /opt/esm/system/m7simupdb2/db/agtcert.dat
{code}

Last Run: Service was started 7 of Feb and was stopping at 10 Feb
{code:java}
[root@m7simupdb2 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 07 21:00:01 m7simupdb2 esmrc[4734]: Starting ESM...
Feb 07 21:00:01 m7simupdb2 esmrc[4734]: Starting ESM network server: [  OK  ]
Feb 07 21:00:01 m7simupdb2 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 08 14:04:39 m7simupdb2 su[27752]: (to root) root on none
Feb 08 14:04:39 m7simupdb2 su[27843]: (to ansible) root on none
Feb 08 14:04:39 m7simupdb2 su[27873]: (to scanmgr) root on none
Feb 10 05:00:01 m7simupdb2 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:01 m7simupdb2 esmrc[34907]: Stopping ESM...
Feb 10 05:00:07 m7simupdb2 esmrc[34907]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:07 m7simupdb2 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
{code}


","14/Feb/20 07:35;cs687;*M7SIMUPDB3*

{code:java}
[root@m7simupdb3 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.6
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7simupdb3 ~]# ls -all /opt/esm/system/m7simupdb3/db/agtcert.dat
-rw-rw----. 1 root root 258 Jul 12  2019 /opt/esm/system/m7simupdb3/db/agtcert.dat
{code}

Last Run:  Service was started 7 of Feb and was stopping at 10 Feb
{code:java}
[root@m7simupdb3 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 07 21:00:01 m7simupdb3 esmrc[32030]: Starting ESM...
Feb 07 21:00:01 m7simupdb3 esmrc[32030]: Starting ESM network server: [  OK  ]
Feb 07 21:00:01 m7simupdb3 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 08 14:04:59 m7simupdb3 su[16119]: (to root) root on none
Feb 08 14:04:59 m7simupdb3 su[16199]: (to ansible) root on none
Feb 08 14:04:59 m7simupdb3 su[16228]: (to scanmgr) root on none
Feb 10 05:00:01 m7simupdb3 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:01 m7simupdb3 esmrc[34526]: Stopping ESM...
Feb 10 05:00:08 m7simupdb3 esmrc[34526]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:08 m7simupdb3 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
{code}




","14/Feb/20 07:44;cs687;*M7SIMUPDB4*

{code:java}
[root@m7simupdb4 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.6
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration: 
{code:java}
[root@m7simupdb4 ~]# ls -all /opt/esm/system/m7simupdb4/db/agtcert.dat
-rw-rw----. 1 root root 258 Jul 12  2019 /opt/esm/system/m7simupdb4/db/agtcert.dat
{code}

Last Run: Service was started 7 of Feb and was stopping at 10 Feb
{code:java}
[root@m7simupdb4 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 07 21:00:01 m7simupdb4 esmrc[40075]: Starting ESM...
Feb 07 21:00:01 m7simupdb4 esmrc[40075]: Starting ESM network server: [  OK  ]
Feb 07 21:00:01 m7simupdb4 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 08 14:05:05 m7simupdb4 su[23827]: (to root) root on none
Feb 08 14:05:06 m7simupdb4 su[23916]: (to ansible) root on none
Feb 08 14:05:06 m7simupdb4 su[23973]: (to scanmgr) root on none
Feb 10 05:00:01 m7simupdb4 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:01 m7simupdb4 esmrc[40631]: Stopping ESM...
Feb 10 05:00:07 m7simupdb4 esmrc[40631]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:07 m7simupdb4 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
{code}
","14/Feb/20 09:32;cs687;*M7HUPXSIMUM7B1*

{code:java}
[root@m7hupxsimum7b1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration: 
{code:java}
[root@m7hupxsimum7b1 ~]# ls -all /opt/esm/system/m7hupxsimum7b1/db/agtcert.dat
-rw-rw---- 1 root root 258 Nov  9  2017 /opt/esm/system/m7hupxsimum7b1/db/agtcert.dat
{code}

*{color:#DE350B}Last Run: Service is started without any scheduling!{color}*
{code:java}
[root@m7hupxsimum7b1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Wed 2020-01-29 09:34:01 CET; 2 weeks 1 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─12659 /esm/bin/lnx-x64/esmd -fv
{code}

","14/Feb/20 09:34;cs687;*M7HUPXSIMUAMQ1*

{code:java}
[root@m7hupxsimuamq1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7hupxsimuamq1 ~]# ls -all /opt/esm/system/m7hupxsimuamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Nov  9  2017 /opt/esm/system/m7hupxsimuamq1/db/agtcert.dat
{code}

*{color:#DE350B}Last Run: Service is started without any scheduling!{color}*
{code:java}
[root@m7hupxsimuamq1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Wed 2020-01-29 09:35:18 CET; 2 weeks 1 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─8625 /esm/bin/lnx-x64/esmd -fv

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
{code}




","14/Feb/20 09:36;cs687;*M7XSOPSIMUM7B1*

{code:java}
[root@m7xsopsimum7b1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7xsopsimum7b1 ~]# ls -all /opt/esm/system/m7xsopsimum7b1/db/agtcert.dat
-rw-rw---- 1 root root 258 Oct 30  2017 /opt/esm/system/m7xsopsimum7b1/db/agtcert.dat
{code}

Last Run: Service was started 7 of Feb and was stopping at 10 Feb
{code:java}
[root@m7xsopsimum7b1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 03 05:00:07 m7xsopsimum7b1 esmrc[28066]: Stopping ESM services:                                        [  OK  ]
Feb 03 05:00:07 m7xsopsimum7b1 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 07 21:00:01 m7xsopsimum7b1 systemd[1]: Starting SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 07 21:00:01 m7xsopsimum7b1 esmrc[28675]: Starting ESM...
Feb 07 21:00:01 m7xsopsimum7b1 esmrc[28675]: Starting ESM network server: [  OK  ]
Feb 07 21:00:01 m7xsopsimum7b1 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 10 05:00:01 m7xsopsimum7b1 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:01 m7xsopsimum7b1 esmrc[17112]: Stopping ESM...
Feb 10 05:00:07 m7xsopsimum7b1 esmrc[17112]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:07 m7xsopsimum7b1 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..

{code}



","14/Feb/20 09:40;cs687;*M7XSOPSIMUAMQ1*

{code:java}
[root@m7xsopsimuamq1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7xsopsimuamq1 ~]# ls -all /opt/esm/system/m7xsopsimuamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Oct 30  2017 /opt/esm/system/m7xsopsimuamq1/db/agtcert.dat
{code}

Last Run: Service was started 7 of Feb and was stopping at 10 Feb
{code:java}
[root@m7xsopsimuamq1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)

Feb 07 21:00:01 m7xsopsimuamq1 systemd[1]: Starting SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 07 21:00:01 m7xsopsimuamq1 esmrc[15538]: Starting ESM...
Feb 07 21:00:01 m7xsopsimuamq1 systemd[1]: Started SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
Feb 07 21:00:01 m7xsopsimuamq1 esmrc[15538]: Starting ESM network server: [  OK  ]
Feb 10 05:00:01 m7xsopsimuamq1 systemd[1]: Stopping SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy....
Feb 10 05:00:02 m7xsopsimuamq1 esmrc[13179]: Stopping ESM...
Feb 10 05:00:08 m7xsopsimuamq1 esmrc[13179]: Stopping ESM services:                                        [  OK  ]
Feb 10 05:00:08 m7xsopsimuamq1 systemd[1]: Stopped SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy..
{code}


","14/Feb/20 09:42;cs687;*M7EPEXASIMAMQ2*

{code:java}
[root@m7epexasimamq2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7epexasimamq2 ~]# ls -all /opt/esm/system/m7epexasimamq2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jan 12  2018 /opt/esm/system/m7epexasimamq2/db/agtcert.dat
{code}

*{color:#DE350B}Last Run: Service is started without any scheduling!{color}*
{code:java}
[root@m7epexasimamq2 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Fri 2020-01-03 13:15:45 CET; 1 months 11 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─9553 /esm/bin/lnx-x64/esmd -fv

{code}



","18/Feb/20 07:05;cs687;*M7EPEXASIMM7B1*

{code:java}
[root@m7epexasimm7b1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7epexasimm7b1 ~]# ls -all /opt/esm/system/m7epexasimm7b1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jan 12  2018 /opt/esm/system/m7epexasimm7b1/db/agtcert.dat
{code}

*{color:#DE350B}Last Run: Service is started without any scheduling!{color}*
{code:java}
[root@m7epexasimm7b1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Wed 2019-12-11 09:47:41 CET; 2 months 8 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─13148 /esm/bin/lnx-x64/esmd -fv

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
{code}
","18/Feb/20 07:08;cs687;*M7EPEXASIMM7B2*

{code:java}
[root@m7epexasimm7b2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration:
{code:java}
[root@m7epexasimm7b2 ~]# ls -all /opt/esm/system/m7epexasimm7b2/db/agtcert.dat
-rw-rw---- 1 root root 258 Jan 12  2018 /opt/esm/system/m7epexasimm7b2/db/agtcert.dat
{code}

{color:#DE350B}*Last Run: Service is started without any scheduling!*{color}
{code:java}
[root@m7epexasimm7b2 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Wed 2019-12-11 09:47:28 CET; 2 months 8 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─12994 /esm/bin/lnx-x64/esmd -fv

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
You have new mail in /var/spool/mail/root*strong text*
{code}

","18/Feb/20 07:11;cs687;*M7EPEXASIMAMQ1*

{code:java}
[root@m7epexasimamq1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

Validation of the registration: 
{code:java}
[root@m7epexasimamq1 ~]# ls -all /opt/esm/system/m7epexasimamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jan 12  2018 /opt/esm/system/m7epexasimamq1/db/agtcert.dat
{code}

*{color:#DE350B}Last Run: Service is started without any scheduling!{color}*
{code:java}
[root@m7epexasimamq1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Fri 2020-01-03 13:14:04 CET; 1 months 15 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─9551 /esm/bin/lnx-x64/esmd -fv

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
{code}

","18/Feb/20 07:20;cs687;After Consulting with [~iO924] i will contact Jan Papai or Christian Stössel
and talk with that Engineer about the steps how to continue on that. 

At least from our point of view everything is prepared and installed on our hosts. 

","18/Feb/20 08:35;cs687;Email is out, waiting for Response of Security Team.
{code:java}
Good Morning Everybody,

I have a question to the onboarding CCS-Process for our Environments in M7T Simulation. 
The following Hosts are marked as “not onboarded”, in the last report from yesterday 17.02.2020.
 
-	M7SIMUPDB1
-	M7SIMUPDB2
-	M7SIMUPDB3
-	M7SIMUPDB4
-	M7HUPXSIMUM7B1
-	M7HUPXSIMUAMQ1
-	M7XSOPSIMUM7B1
-	M7XSOPSIMUAMQ1
-	M7EPEXASIMAMQ2
-	M7EPEXASIMM7B1
-	M7EPEXASIMM7B2
-	M7EPEXASIMAMQ1

At least from our point of view everything is prepared and installed on our Hosts. 
One of the machines are running the agent via cronjob, starting on Friday at 9pm and stopping it on Monday 5am. 
Few other machines are constantly running the agent “esmrc”.

For example Host: M7EPEXASIMAMQ1

[root@m7epexasimamq1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink

Validation of the registration:
[root@m7epexasimamq1 ~]# ls -all /opt/esm/system/m7epexasimamq1/db/agtcert.dat
-rw-rw---- 1 root root 258 Jan 12  2018 /opt/esm/system/m7epexasimamq1/db/agtcert.dat

Status of the agent:
[root@m7epexasimamq1 ~]# systemctl status esmrc
● esmrc.service - SYSV: Enterprise Security Manager (ESM) allows a computer to be monitored for compliance with security policy.
   Loaded: loaded (/etc/rc.d/init.d/esmrc; bad; vendor preset: disabled)
   Active: active (running) since Fri 2020-01-03 13:14:04 CET; 1 months 15 days ago
     Docs: man:systemd-sysv-generator(8)
   CGroup: /system.slice/esmrc.service
           └─9551 /esm/bin/lnx-x64/esmd -fv

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.

Please find also the attached registration file “agtcert.dat” of the Host M7EPEXASIMAMQ1 in the Email. 

How should we continue with the onboarding process, do you need some further Information´s?
Please feel free to contact me.
 
Thank you very much!

Cheers, 
Steffen 
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43

E-Mail  steffen.englert@deutsche-boerse.com
http://www.deutsche-boerse.com
{code}
","18/Feb/20 12:41;cs687;Response from Security Team:
I will try it with one of the hosts and waiting for the feedback from them 
{code:java}
Hi Steffen,

Looping in @Symantec CCS Contacts

I couldn’t find the m7simupdb* machines in the report but I could find them in CCS:

 

The rest of the machines are indeed not in CCS. The sample timestamp of the agtcert file in your command output (Jan 12  2018 /opt/esm/system/m7epexasimamq1/db/agtcert.dat) indicates the machines were registered 2 years ago. I suggest re-registering them by running /opt/esm/re-register.sh to see if this works. Or even better, but this requires a bit of manual work, find out which IPs from re-register.sh are reachable on port 5600 and then run the following:

rm -f /opt/esm/system/$(hostname)/db/agtcert.dat
/opt/esm/bin/lnx-x64/register -m $IPAddress -p 5600 -E -v -u

This command would give us more insight in case the registration does not succeed. In either case (re-register.sh or the second option), would you please provide commands output so I can check on the respective CCS servers? Thank you!

Regards,
Jan
{code}


###############################################################

Hello @Jan Papai, 

I have followed up your suggestion by 
-	Deleting the existing agtcert.dat file 
-	And registering the host M7HUPXSIMUM7B1

And re-registering [root@m7hupxsimum7b1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.

Could you please the Situation in CCS or CMS, to proof that the re-registering was working successfully. 
Thanks in Advance!

Cheers
Steffen 


{color:#00875A}*Update from Jan Papai*{color}
After the commands above, hosts is visible in CCS. Solved. 
Will do it for the rest of the machines as well and close the ticket. 
","18/Feb/20 14:15;cs687;*M7HUPXSIMUAMQ1*
{code:java}
[root@m7hupxsimuamq1 ~]# cp /opt/esm/system/m7hupxsimuamq1/db/agtcert.dat /tmp
[root@m7hupxsimuamq1 ~]# rm -rf /opt/esm/system/m7hupxsimuamq1/db/agtcert.dat
[root@m7hupxsimuamq1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7XSOPSIMUM7B1*
{code:java}
[root@m7xsopsimum7b1 ~]# cp /opt/esm/system/m7xsopsimum7b1/db/agtcert.dat /tmp
[root@m7xsopsimum7b1 ~]# rm -rf /opt/esm/system/m7xsopsimum7b1/db/agtcert.dat
[root@m7xsopsimum7b1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7XSOPSIMUAMQ1*
{code:java}
[root@m7xsopsimuamq1 ~]# cp /opt/esm/system/m7xsopsimuamq1/db/agtcert.dat /tmp
[root@m7xsopsimuamq1 ~]# rm -rf /opt/esm/system/m7xsopsimuamq1/db/agtcert.dat
[root@m7xsopsimuamq1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7EPEXASIMAMQ2*
{code:java}
[root@m7epexasimamq2 ~]# cp /opt/esm/system/m7epexasimamq2/db/agtcert.dat /tmp
[root@m7epexasimamq2 ~]# rm -rf /opt/esm/system/m7epexasimamq2/db/agtcert.dat
[root@m7epexasimamq2 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7EPEXASIMM7B1*
{code:java}
[root@m7epexasimm7b1 ~]# cp /opt/esm/system/m7epexasimm7b1/db/agtcert.dat /tmp
[root@m7epexasimm7b1 ~]# rm -rf /opt/esm/system/m7epexasimm7b1/db/agtcert.dat
[root@m7epexasimm7b1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7EPEXASIMM7B2*
{code:java}
[root@m7epexasimm7b2 ~]# cp /opt/esm/system/m7epexasimm7b2/db/agtcert.dat /tmp
[root@m7epexasimm7b2 ~]# rm -rf /opt/esm/system/m7epexasimm7b2/db/agtcert.dat
[root@m7epexasimm7b2 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7EPEXASIMAMQ1*
{code:java}
[root@m7epexasimamq1 ~]# cp /opt/esm/system/m7epexasimamq1/db/agtcert.dat /tmp
[root@m7epexasimamq1 ~]# rm -rf /opt/esm/system/m7epexasimamq1/db/agtcert.dat
[root@m7epexasimamq1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7SIMUPDB1*
{code:java}
[root@m7simupdb1 ~]# cp /opt/esm/system/m7simupdb1/db/agtcert.dat /tmp
[root@m7simupdb1 ~]# rm -rf /opt/esm/system/m7simupdb1/db/agtcert.dat
[root@m7simupdb1 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7SIMUPDB2*
{code:java}
[root@m7simupdb2 ~]# cp /opt/esm/system/m7simupdb2/db/agtcert.dat /tmp
[root@m7simupdb2 ~]# rm -rf /opt/esm/system/m7simupdb2/db/agtcert.dat
[root@m7simupdb2 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7SIMUPDB3*
{code:java}
[root@m7simupdb3 ~]# cp /opt/esm/system/m7simupdb3/db/agtcert.dat /tmp
[root@m7simupdb3 ~]# rm -rf /opt/esm/system/m7simupdb3/db/agtcert.dat
[root@m7simupdb3 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}

*M7SIMUPDB4*
{code:java}
[root@m7simupdb4 ~]# cp /opt/esm/system/m7simupdb4/db/agtcert.dat /tmp
[root@m7simupdb4 ~]# rm -rf /opt/esm/system/m7simupdb4/db/agtcert.dat
[root@m7simupdb4 ~]# /opt/esm/re-register.sh
Registering to 10.129.119.254... Ok.
{code}



","19/Feb/20 06:58;cs687;It´s done and proofed by Security Team. ",,,,,,,,,,,
M7T PROD - CCS not onboarded,M7P-5468,91226,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Jan/20 14:00,17/Dec/20 15:26,16/Sep/21 14:11,11/Mar/20 12:54,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,TechOpsBoard,,,,,,"On board CCS tool for M7 Production level environments (list of envs below)
 [^CCS on-boarding process.docx]

 

 
-|M7HUPXPRODAMQ1|-
-|M7HUPXPRODAMQ2|-
-|M7HUPXPRODM7B2|-
-|M7HUPXPRODM7B1|-
-|M7XSOPPRODM7B1|-
-|M7XSOPPRODM7B2|-
-|M7XSOPPRODAMQ2|-
-|M7XSOPPRODAMQ1|-
-|M7EPEXPRODM7B1|-
-|M7EPEXPRODAMQ1|-
-|M7EPEXPRODM7B2|-
-|M7EPEXPRODAMQ2|-
-|M7CICSCPRODAMQ1|-
-|M7CICSCPRODAPP2|-
-|M7CICSCPRODAPP1|-
-|M7CICSCPRODAMQ2|-
-|M7ELTSPRODAMQ2|-
-|M7ELTSPRODM7B1|-
-|M7ELTSPRODM7B2|-
-|M7ELTSPRODAMQ1|-
-|M7HUPXPRODAMQ3|-
-|M7EPEXPRODAMQ3|-
-|M7XSOPPRODAMQ3|-
-|M7EPEXPRODNET2|-
-|M7EPEXPRODNET1|-
-|M7FLEXPRODAMQ2|-
-|M7FLEXPRODM7B2|-
-|M7FLEXPRODM7B1|-
-|M7FLEXPRODAMQ1|-
-|M7ELTSPRODM7C1|-
-|M7ELTSPRODM7C2|-",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Feb/20 10:12;sw455;CCS on-boarding process.docx;https://jira.deutsche-boerse.com/secure/attachment/80195/CCS+on-boarding+process.docx",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47865600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwz7r:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91226,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"10/Mar/20 08:40;cs687;*Starting with HUPX-PROD*
ansible m7t-hupx-prod-amq1:m7t-hupx-prod-amq2:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2 -m shell -b -a ""yum info ccsagent"" -k -K

+Checking if the rpm is installed:+

*M7HUPXPRODAMQ1*
{code:java}
m7t-hupx-prod-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7HUPXPRODAMQ2*
{code:java}
m7t-hupx-prod-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7HUPXPRODAMQ3*
{code:java}
m7t-hupx-prod-amq3 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7HUPXPRODM7B1*
{code:java}
m7t-hupx-prod-cor1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7HUPXPRODM7B2""*
{code:java}
m7t-hupx-prod-cor2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing:+

*M7HUPXPRODAMQ1*
{code:java}
m7t-hupx-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7hupxprodamq1/db/agtcert.dat
{code}

*M7HUPXPRODAMQ2*
{code:java}
m7t-hupx-prod-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7hupxprodamq2/db/agtcert.dat
{code}

*M7HUPXPRODAMQ3*
{code:java}
m7t-hupx-prod-amq3 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 19  2017 /opt/esm/system/m7hupxprodamq3/db/agtcert.dat
{code}

*M7HUPXPRODM7B1*
{code:java}
m7t-hupx-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7hupxprodm7b1/db/agtcert.dat
{code}

*M7HUPXPRODM7B2*
{code:java}
m7t-hupx-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7hupxprodm7b2/db/agtcert.dat
{code}

Service: *esmrc.service* is running via crontab ""esmrc""


#####################################################################
re-registering service:
1.) *ansible m7t-hupx-prod-amq1:m7t-hupx-prod-amq2:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K*
2.) *ansible m7t-hupx-prod-amq1:m7t-hupx-prod-amq2:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7t-hupx-prod-amq1:m7t-hupx-prod-amq2:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*

{code:java}
m7t-hupx-prod-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-hupx-prod-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-hupx-prod-amq3 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-hupx-prod-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-hupx-prod-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}
","10/Mar/20 09:23;cs687;*Starting with XSOP-PROD*

+Checking if the rpm is installed:+
*M7XSOPPRODAMQ1*
{code:java}
m7t-xsop-prod-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7XSOPPRODAMQ2*
{code:java}
m7t-xsop-prod-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7XSOPPRODAMQ3*
{code:java}
m7t-xsop-prod-amq3 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7XSOPPRODCOR1*
{code:java}
m7t-xsop-prod-cor1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7XSOPPRODCOR2*
{code:java}
m7t-xsop-prod-cor2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing+
*M7XSOPPRODAMQ1*
{code:java}
m7t-xsop-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7xsopprodamq1/db/agtcert.dat
{code}

*M7XSOPPRODAMQ2*
{code:java}
m7t-xsop-prod-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7xsopprodamq2/db/agtcert.dat
{code}

*M7XSOPPRODAMQ3*
{code:java}
m7t-xsop-prod-amq3 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 19  2017 /opt/esm/system/m7xsopprodamq3/db/agtcert.dat
{code}

*M7XSOPPRODCOR1*
{code:java}
m7t-xsop-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7xsopprodm7b1/db/agtcert.dat
{code}

*M7XSOPPRODCOR2*
{code:java}
m7t-xsop-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Oct 17  2017 /opt/esm/system/m7xsopprodm7b2/db/agtcert.dat
{code}

Service: *esmrc.service* is running via crontab ""esmrc""

#####################################################################
re-registering service:
1.) *ansible m7t-xsop-prod-amq1:m7t-xsop-prod-amq2:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K*
2.) *ansible m7t-xsop-prod-amq1:m7t-xsop-prod-amq2:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7t-xsop-prod-amq1:m7t-xsop-prod-amq2:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*
{code:java}
m7t-xsop-prod-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-xsop-prod-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-xsop-prod-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-xsop-prod-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-xsop-prod-amq3 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}

","10/Mar/20 09:45;cs687;*Starting with EPEX-PROD*

+Checking if the rpm is installed+

*M7EPEXPRODAMQ1*
{code:java}
m7t-epex-prod-app-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODAMQ2*
{code:java}
m7t-epex-prod-app-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODAMQ3*
{code:java}
m7t-epex-prod-app-amq3 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODCOR1*
{code:java}
m7t-epex-prod-cor1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODCOR2*
{code:java}
m7t-epex-prod-cor2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODNET2*
{code:java}
[root@m7epexprodnet2 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7EPEXPRODNET1*
{code:java}
[root@m7epexprodnet1 ~]# yum info ccsagent
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent for Linux.
            : FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing+
*M7EPEXPRODAMQ1*
{code:java}
m7t-epex-prod-app-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 20  2017 /opt/esm/system/m7epexprodamq1/db/agtcert.dat
{code}

*M7EPEXPRODAMQ2*
{code:java}
m7t-epex-prod-app-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 20  2017 /opt/esm/system/m7epexprodamq2/db/agtcert.dat
{code}

*M7EPEXPRODAMQ3*
{code:java}
m7t-epex-prod-app-amq3 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 20  2017 /opt/esm/system/m7epexprodamq3/db/agtcert.dat
{code}

*M7EPEXPRODCOR1*
{code:java}
m7t-epex-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 20  2017 /opt/esm/system/m7epexprodm7b1/db/agtcert.dat
{code}

*M7EPEXPRODCOR2*
{code:java}
m7t-epex-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 20  2017 /opt/esm/system/m7epexprodm7b2/db/agtcert.dat
{code}

*M7EPEXPRODNET2*
{code:java}
[root@m7epexprodnet2 ~]# ls -all /opt/esm/system/m7epexprodnet2/db/agtcert.dat
-rw-rw---- 1 root root 258 Nov 16  2017 /opt/esm/system/m7epexprodnet2/db/agtcert.dat
{code}

*M7EPEXPRODNET1*
{code:java}
[root@m7epexprodnet1 ~]# ls -all /opt/esm/system/m7epexprodnet1/db/agtcert.dat
-rw-rw---- 1 root root 258 Nov 16  2017 /opt/esm/system/m7epexprodnet1/db/agtcert.dat
{code}

Service: *esmrc.service* is running via crontab ""esmrc""

#####################################################################
re-registering serivce:
1.) *ansible m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-app-amq3:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K* 
2.) *ansible m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-app-amq3:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-app-amq3-:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*
{code:java}
m7t-epex-prod-app-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-epex-prod-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-epex-prod-app-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-epex-prod-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7epexprodnet2
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7epexprodnet1
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}
","10/Mar/20 13:02;cs687;*Starting with ICSC-PROD*

+Checking if the rpm is installed:+
*M7CICSCPRODAMQ1*
{code:java}
m7c-icsc-prod-app-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7CICSCPRODAPP2*
{code:java}
m7c-icsc-prod-cmi2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7CICSCPRODAPP1*
{code:java}
m7c-icsc-prod-cmi1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7CICSCPRODAMQ2*
{code:java}
m7c-icsc-prod-app-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing:+
*M7CICSCPRODAMQ1*
{code:java}
m7c-icsc-prod-app-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 May 11  2017 /opt/esm/system/m7cicscprodamq1/db/agtcert.dat
{code}

*M7CICSCPRODAPP2*
{code:java}
m7c-icsc-prod-cmi2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 May 11  2017 /opt/esm/system/m7cicscprodapp2/db/agtcert.dat
{code}

*M7CICSCPRODAPP1*
{code:java}
m7c-icsc-prod-cmi1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 May 11  2017 /opt/esm/system/m7cicscprodapp1/db/agtcert.dat
{code}

*M7CICSCPRODAMQ2*
{code:java}
m7c-icsc-prod-app-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 May 11  2017 /opt/esm/system/m7cicscprodamq2/db/agtcert.dat
{code}

Service: esmrc.service is running via crontab ""esmrc""

#####################################################################
re-registering service:
1.) *ansible m7c-icsc-prod-app-amq1:m7c-icsc-prod-app-amq2:m7c-icsc-prod-cmi1:m7c-icsc-prod-cmi2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K*
2.) *ansible m7c-icsc-prod-app-amq1:m7c-icsc-prod-app-amq2:m7c-icsc-prod-cmi1:m7c-icsc-prod-cmi2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7c-icsc-prod-app-amq1:m7c-icsc-prod-app-amq2:m7c-icsc-prod-cmi1:m7c-icsc-prod-cmi2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*

{code:java}
m7c-icsc-prod-app-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7c-icsc-prod-cmi1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7c-icsc-prod-app-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7c-icsc-prod-cmi2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}
","10/Mar/20 13:05;cs687;*Starting with FLEX-PROD*

+Checking if the rpm is installed+

*M7FLEXPRODAMQ1*
{code:java}
m7t-flex-prod-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7FLEXPRODAMQ2*
{code:java}
m7t-flex-prod-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7FLEXPRODM7B1*
{code:java}
m7t-flex-prod-cor1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7FLEXPRODM7B2*
{code:java}
m7t-flex-prod-cor2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing+
*M7FLEXPRODAMQ1*
{code:java}
m7t-flex-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 28  2018 /opt/esm/system/m7flexprodamq1/db/agtcert.dat
{code}

*M7FLEXPRODAMQ2*
{code:java}
m7t-flex-prod-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 28  2018 /opt/esm/system/m7flexprodamq2/db/agtcert.dat
{code}

*M7FLEXPRODM7B1*
{code:java}
m7t-flex-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 28  2018 /opt/esm/system/m7flexprodm7b1/db/agtcert.dat
{code}

*M7FLEXPRODM7B2*
{code:java}
m7t-flex-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Nov 28  2018 /opt/esm/system/m7flexprodm7b2/db/agtcert.dat
{code}

Service: esmrc.service is running via crontab ""esmrc""

#####################################################################
re-registration service 
1.) *ansible m7t-flex-prod-amq1:m7t-flex-prod-amq2:m7t-flex-prod-cor1:m7t-flex-prod-cor2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K*
2.) *ansible m7t-flex-prod-amq1:m7t-flex-prod-amq2:m7t-flex-prod-cor1:m7t-flex-prod-cor2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7t-flex-prod-amq1:m7t-flex-prod-amq2:m7t-flex-prod-cor1:m7t-flex-prod-cor2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*

{code:java}
m7t-flex-prod-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-flex-prod-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-flex-prod-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-flex-prod-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}
","10/Mar/20 13:28;cs687;*Starting with ELTS-PROD*

+Checking if the rpm is installed+

*M7ELTSPRODAMQ1*
{code:java}
m7t-elts-prod-amq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7ELTSPRODAMQ2*
{code:java}
m7t-elts-prod-amq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7ELTSPRODM7B1*
{code:java}
m7t-elts-prod-enq1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7ELTSPRODM7B2*
{code:java}
m7t-elts-prod-enq2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.3
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7ELTSPRODM7C1*
{code:java}
m7t-elts-prod-cor1 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

*M7ELTSPRODM7C2*
{code:java}
m7t-elts-prod-cor2 | SUCCESS | rc=0 >>
Loaded plugins: langpacks, product-id, rhnplugin, search-disabled-repos
This system is receiving updates from RHN Classic or Red Hat Satellite.
Installed Packages
Name        : ccsagent
Arch        : x86_64
Version     : 11.1
Release     : 11
Size        : 186 M
Repo        : installed
From repo   : server-ops-genoa-rh7.5
Summary     : Symantec CCS Agent for Red Hat Linux
License     : (C) Symantec
Description : This package installs the Symantec Control Compliance Suite Agent
            : for Linux. FSH modifications on the system are:
            : /opt/esm: distribution tree
            : /etc/rc.d: installation of the esmrc service (235 S69 K10)
            : /usr/share/regid.1992-12.com.symantec: software Idtag
            : /esm: symlink
{code}

+Checking if the registration file is existing:+
*M7ELTSPRODAMQ1*
{code:java}
m7t-elts-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 20  2017 /opt/esm/system/m7eltsprodamq1/db/agtcert.dat
{code}

*M7ELTSPRODAMQ2*
{code:java}
m7t-elts-prod-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 20  2017 /opt/esm/system/m7eltsprodamq2/db/agtcert.dat
{code}

*M7ELTSPRODM7B1*
{code:java}
m7t-elts-prod-enq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 20  2017 /opt/esm/system/m7eltsprodm7b1/db/agtcert.dat
{code}

*M7ELTSPRODM7B2*
{code:java}
m7t-elts-prod-enq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Jul 20  2017 /opt/esm/system/m7eltsprodm7b2/db/agtcert.dat
{code}

*M7ELTSPRODM7C1*
{code:java}
m7t-elts-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 21  2019 /opt/esm/system/m7eltsprodm7c1/db/agtcert.da
{code}

*M7ELTSPRODM7C2*
{code:java}
m7t-elts-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 21  2019 /opt/esm/system/m7eltsprodm7c2/db/agtcert.dat
{code}


Service: esmrc.service is running via crontab ""esmrc""

#####################################################################
re-registering service:
1.) *ansible m7t-elts-prod-amq1:m7t-elts-prod-amq2:m7t-elts-prod-cor1:m7t-elts-prod-cor2:m7t-elts-prod-enq1:m7t-elts-prod-enq2 -m shell -b -a ""cp /opt/esm/system/*/db/agtcert.dat /tmp"" -k -K* 
2.) *ansible m7t-elts-prod-amq1:m7t-elts-prod-amq2:m7t-elts-prod-cor1:m7t-elts-prod-cor2:m7t-elts-prod-enq1:m7t-elts-prod-enq2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K*
3.) *ansible m7t-elts-prod-amq1:m7t-elts-prod-amq2:m7t-elts-prod-cor1:m7t-elts-prod-cor2:m7t-elts-prod-enq1:m7t-elts-prod-enq2 -m shell -b -a ""/opt/esm/re-register.sh"" -k -K*

{code:java}
m7t-elts-prod-enq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-elts-prod-cor2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-elts-prod-cor1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-elts-prod-amq1 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-elts-prod-amq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.

m7t-elts-prod-enq2 | SUCCESS | rc=0 >>
Registering to 10.129.119.254... failed.
Registering to 10.250.0.142... failed.
Registering to 10.246.0.16... Ok.
{code}
","10/Mar/20 13:53;cs687;Informed the *Symantec CCS Contacts <SymantecCCSContacts@deutsche-boerse.com>* People about the change. 
Ticket is in waiting until i get a positive response, than we could close it. 


{code:java}
Hello Steffen,

I checked CCS and found the following hosts onboarded: (True meaning the host is present in CCS, False meaning the host is not present in CCS)

m7hupxprodamq2  False
m7hupxprodamq1  False
m7hupxprodamq3  True
m7hupxprodm7b1  False
m7hupxprodm7b2  False
m7xsopprodamq2  False
m7xsopprodm7b2  False
m7xsopprodm7b1  False
m7xsopprodamq1  False
m7xsopprodamq3  True
m7epexprodamq1  False
m7epexprodm7b2  False
m7epexprodamq2  False
m7epexprodm7b1  False
m7epexprodnet1  True
m7epexprodnet2  True
m7cicscprodamq1 True
m7cicscprodamq2 True
m7cicscprodapp1 True
m7cicscprodapp2 True
m7flexprodamq2  True
m7flexprodamq1  True
m7flexprodm7b1  True
m7flexprodm7b2  True
m7eltsprodm7b1  True
m7eltsprodm7b2  True
m7eltsprodm7c1  True
m7eltsprodm7c2  True
m7eltsprodamq1  True
m7eltsprodamq2  True

Unfortunately, we are unable to see what went wrong with the hosts that are not present. Could you please register them again with the following commands which provides a more verbose output, that might help us to identify the issue? 

rm -f /opt/esm/system/$(hostname)/db/agtcert.dat
/opt/esm/bin/lnx-x64/register -m 10.246.0.16 -p 5600 -E -v -u

Please run the commands above for each host that is not present and send us the output. 

Thank you for your help and time.
{code}

UPDATE:
After running this special command with the proper parameters its working and the host is on boarded. Will run it for all the other machines which are not on-boarded yet as well  
{code:java}
Good morning Steffen,

Thank you for running the commands and providing us with the output. 

The host “M7HUPXPRODAMQ2” is now present in CCS. Could you please do the same for all the other hosts that are not present in CCS currently? 

Also, you are correct about the error message regarding the agent service, that won’t cause any issues. However, if you see anything else other than what you saw below for any other host, please let us know and send us the output of that command. In case all hosts are re-registered with the same outputs, everything should be fine and I will verify it for you.

Thank you for your help. 
{code}

","11/Mar/20 11:31;cs687;*1.) List registration file*
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible m7t-hupx-prod-amq1:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2:m7t-xsop-prod-amq2:m7t-xsop-prod-amq1:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2:m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""ls -all /opt/esm/system/*/db/agtcert.dat"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
m7t-xsop-prod-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:31 /opt/esm/system/m7xsopprodamq2/db/agtcert.dat

m7t-xsop-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:31 /opt/esm/system/m7xsopprodamq1/db/agtcert.dat

m7t-hupx-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:15 /opt/esm/system/m7hupxprodm7b1/db/agtcert.dat

m7t-hupx-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:15 /opt/esm/system/m7hupxprodm7b2/db/agtcert.dat

m7t-xsop-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:31 /opt/esm/system/m7xsopprodm7b2/db/agtcert.dat

m7t-hupx-prod-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:15 /opt/esm/system/m7hupxprodamq1/db/agtcert.dat

m7t-xsop-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:31 /opt/esm/system/m7xsopprodm7b1/db/agtcert.dat

m7t-epex-prod-app-amq1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:58 /opt/esm/system/m7epexprodamq1/db/agtcert.dat

m7t-epex-prod-app-amq2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:58 /opt/esm/system/m7epexprodamq2/db/agtcert.dat

m7t-epex-prod-cor2 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:58 /opt/esm/system/m7epexprodm7b2/db/agtcert.dat

m7t-epex-prod-cor1 | SUCCESS | rc=0 >>
-rw-rw---- 1 root root 258 Mar 10 09:58 /opt/esm/system/m7epexprodm7b1/db/agtcert.dat
{code}

*2.) Deleting the current registration file*
{code:java}
[cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible m7t-hupx-prod-amq1:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2:m7t-xsop-prod-amq2:m7t-xsop-prod-amq1:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2:m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""rm -rf /opt/esm/system/*/db/agtcert.dat"" -k -K
SSH password:
SUDO password[defaults to SSH password]:
 [WARNING]: Consider using the file module with state=absent rather than running rm.  If you need to use command because file is insufficient you can add warn=False to this command task or set command_warnings=False in ansible.cfg to get rid of this message.

m7t-xsop-prod-amq1 | SUCCESS | rc=0 >>


m7t-xsop-prod-amq2 | SUCCESS | rc=0 >>


m7t-hupx-prod-cor1 | SUCCESS | rc=0 >>


m7t-hupx-prod-amq1 | SUCCESS | rc=0 >>


m7t-hupx-prod-cor2 | SUCCESS | rc=0 >>


m7t-xsop-prod-cor2 | SUCCESS | rc=0 >>


m7t-xsop-prod-cor1 | SUCCESS | rc=0 >>


m7t-epex-prod-app-amq1 | SUCCESS | rc=0 >>


m7t-epex-prod-cor1 | SUCCESS | rc=0 >>


m7t-epex-prod-app-amq2 | SUCCESS | rc=0 >>


m7t-epex-prod-cor2 | SUCCESS | rc=0 >>
{code}

*3.) [cs687@enprodauto1 {master L | ✔} ~/ansible/energy.automation.deployments]$ ansible m7t-hupx-prod-amq1:m7t-hupx-prod-cor1:m7t-hupx-prod-cor2:m7t-xsop-prod-amq2:m7t-xsop-prod-amq1:m7t-xsop-prod-cor1:m7t-xsop-prod-cor2:m7t-epex-prod-app-amq1:m7t-epex-prod-app-amq2:m7t-epex-prod-cor1:m7t-epex-prod-cor2 -m shell -b -a ""
/opt/esm/bin/lnx-x64/register -m 10.246.0.16 -p 5600 -E -v -u"" -k -K
*
","11/Mar/20 12:55;cs687;ALL the Hosts are on-boarded in cms",,,,,,,,,,,,,,,,,,,
Renewal of Certificate [CTPB],M7P-5463,91180,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iv732,tj898,tj898,17/Jan/20 13:19,17/Dec/20 15:26,16/Sep/21 14:11,05/Feb/20 10:57,,6.9.65,7tops_pre-sprint0_cleanup,,,,,,31/Jan/20 00:00,Certificates,M7PRODOPS,,,,,,"Hello. We'll need to renew this certificate below. We got the alert from new alerting system regarding certificates in the Vault.

Alert:
{code:java}
secret/m7t/elts/ctpb/cert/;CN=ctpb2.epex-lts.m7.deutsche-boerse.com - expires at Feb 15 23:59:59 2020 GMT{code}
Thanks. Regards,

Hugo Correia",,iv732,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50889600,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwyzb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91180,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/20 10:00;iv732;ITSR: 4B8142","28/Jan/20 14:07;iv732;[~tj898] the cert is there. When can we deploy it (need to restart haproxy and web service)","03/Feb/20 14:22;iv732;cert & key is imported to vault","04/Feb/20 11:41;tj898;Customer asked to be executed tomorrow at 10am.","05/Feb/20 10:49;iv732;- Found out that elts ctpb apache is not yet migrated.

- therefore migrated it and deploy certs",,,,,,,,,,,,,,,,,,,,,,,
Log retention rules - Analysis ,M7P-5461,91457,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iu252,fj021,fj021,27/Jan/20 10:38,17/Dec/20 15:26,16/Sep/21 14:11,29/Jan/20 11:56,,6.9.64,7tops_pre-sprint0_cleanup,,,,,,,M7PRODOPS,TO4M7,,,,,,"The log retention rules don't seem very clear or uniform. Can we have some clarification ?

 

On Kibana for example, as of today (27.01.20) the logs before 25.12.19 for *ELTS* on *PRODUCTION* are not available anymore : 
 * [https://kibana.energy.svc.dbgcloud.io/goto/9e7018c4c487159b2d20c628e61e7486]

Now if I change client to *XPRM*, I can see logs but only *AMQ** logs :
 * [https://kibana.energy.svc.dbgcloud.io/goto/8bdaab04f2b285acff271146b7c135eb]

Already we have a different set up between two clients.

 

Now, sure we can go to EBSM if we really need those logs, right ?

Well, not entirely. I've noticed that we *don't* have RabbitMQ logs in the archived-logs on EBSM. (Checked for ELTS, PROD). Why ?

 

So what I think is important to know is :
 * Are there any rules ?
 * If there are rules, what are they ?
 * If we know what they are, are we OK with those rules ?

 

Because it's not a rare occurrence to have to analyze an issue from ELTS (critical client) that happened a month ago. And I don't think ""Tell us when it happens again, we don't have the logs anymore"" is an answer that they enjoy hearing too much.

 

Thanks !",,fj021,iu252,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51494400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx09z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91457,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/20 11:32;iu252;So what I think is important to know is :

* Are there any rules ?    *Yes, there are rules.*
* If there are rules, what are they ? *We have data in Kibana for the last 30 days, the rest is stored in AWS. In case we need older data, we can restore it. If you search for the logs in Kibana you will see the last 500 entries: ""These are the first 500 documents matching your search, refine your search to see others.""*","28/Jan/20 11:57;fj021;[~iu252],

Alright, so the rules are clear. The fact that some stay longer than 30days doesn't infer that there is multiple rules, simply that some slip trough the net.

*About the EBSM part : Is there a reason for not having RMQ logs ?*

??[...] I've noticed that we *don't* have RabbitMQ logs in the archived-logs on EBSM. (Checked for ELTS, PROD). Why???

Thanks. 
 Aurélien","29/Jan/20 10:42;iu252;[~fj021],
The rules are valid for all logs!!!
The fact that you see logs for XRPM has different reason.
If you look closer into the logs from 22nd December you will see that filebeat (which collect logs) created an index which points to 27.01.2020:  to _index"": ""m7-rabbitmq-2020.01.27"".
From filebeat configuration we can see how index was created: index: ""m7-rabbitmq-%{+yyyy.MM.dd}""
It means that we had some issues with the time on that date. 


*About the EBSM part : Is there a reason for not having RMQ logs ?*
Yes, there is one.
Yesterday we found the reason why we don't have RMQ logs.
With ansible deployment we changed the name of RMQ log files. In the past it was m7_elts_prod_*rmq*-1_standard_hau.log and now  m7_elts_prod_*rabbitmq*-2_standard_hau.log.
From our cor-servers we sent every 4 hours logs from cor, enq, rabbit to EBSM. On EBSM there is logmover installed which checks and sorts the incoming files using special pattern. In case the file name doesn't fit  the pattern logmover moves the files into /tmp directory and some when the files will be deleted. In the pattern list we still had only ""rmq"" and not ""rabbitmq"".
The issue is fixed now and we have RMQ logs on EBSM:

{noformat}
[root@m7shrdebsm1 m7_elts]# pwd
/opt/data/home/logmover/2currentDay/prod/m7_elts
[root@m7shrdebsm1 m7_elts]# ls -l *rabbit*
-rw-r--r-- 1 logmover logmover 1301489 Jan 29 05:31 m7_elts_prod_rabbitmq-1_standard_ixe.log
-rw-r--r-- 1 logmover logmover     702 Jan 29 05:00 m7_elts_prod_rabbitmq-2_standard_hau.log
{noformat}


","29/Jan/20 11:43;fj021;[~iu252], 

 

Thanks for the explanation, glad to know that the RMQ logs issue on EBSM is now fixed !

I think it's all clear on my part now. We can consider this ticket as Resolved (y)

 

Thanks again,

Aurélien",,,,,,,,,,,,,,,,,,,,,,,,
Renewal of Certificate [ELTS CUTE],M7P-5460,91181,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,iv732,tj898,tj898,17/Jan/20 13:20,17/Dec/20 15:26,16/Sep/21 14:11,05/Feb/20 10:48,,6.9.65,7tops_pre-sprint0_cleanup,,,,,,31/Jan/20 00:00,Certificates,M7PRODOPS,,,,,,"Hello. We'll need to renew this certificate below. We got the alert from new alerting system regarding certificates in the Vault.

Alert:
{code:java}
secret/m7t/elts/cute/cert/;CN=cute2.epex-lts.m7.deutsche-boerse.com - expires at Feb 15 23:59:59 2020 GMT
{code}
Thanks. Regards,

Hugo Correia",,iv732,tj898,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50976000,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwyzj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91181,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/20 09:59;iv732;ITSR: 4B8142","28/Jan/20 14:07;iv732;[~tj898] the cert is there. When can we deploy it (need to restart haproxy and web service)","03/Feb/20 14:23;iv732;cert & key is imported to vault","04/Feb/20 11:40;tj898;Asked customer for a slot. Waiting for their reply.",,,,,,,,,,,,,,,,,,,,,,,,
Enhance SYT1 to support 5 node cluster setup for Rabbit,M7P-5457,91117,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,nn236,nn236,nn236,15/Jan/20 17:07,17/Dec/20 15:26,16/Sep/21 14:11,27/Jan/20 13:52,,6.9.54,7tops_pre-sprint0_cleanup,,,,,,24/Jan/20 00:00,M7PRODOPS,TO4M7,,,,,,"On ELTS Production, the customer experiences performance issues during high load periods. There is a suspicion that the high delays are caused by the Rabbit.

A possible solution could be to add node clusters to Rabbit.

We would like to test this solution on SYT1.

For this purpose, *please enhance the SYT1 environment to support 5 node cluster on Rabbit*.",,cs687,cv179,cv524,nn236,pw231,,,,,,,,,,,,,M7P-5248,,,,,,,,,,,,,,,,,,,,,,"24/Jan/20 08:06;cs687;os_accounts.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79503/os_accounts.yml.txt","24/Jan/20 08:06;cs687;os_agents.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79504/os_agents.yml.txt","24/Jan/20 08:33;cs687;os_authentication.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79506/os_authentication.yml.txt","24/Jan/20 08:33;cs687;os_filesystem.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79507/os_filesystem.yml.txt","24/Jan/20 08:01;cs687;os_network.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79501/os_network.yml.txt","24/Jan/20 07:58;cs687;os_ntp.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79500/os_ntp.yml.txt","23/Jan/20 13:53;cs687;os_selinux.output.txt;https://jira.deutsche-boerse.com/secure/attachment/79479/os_selinux.output.txt","24/Jan/20 07:54;cs687;os_update.yml.txt;https://jira.deutsche-boerse.com/secure/attachment/79499/os_update.yml.txt",,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51580800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwylr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91117,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/20 09:41;cv179;[~pw231] please review following approach:

We will create 2 additional VMs: amq4 and amq5 for syt1.

First 3 and new 2 vms will get updated OS to rhel 7.6. It would also make sense to update erlang (if not already done)

Please note, the 5 VMs are distributed across both DCs. This will not falsify the test results in a positive direction so I think it's fine. Otherwiese we would need to order 7 additional VMs to reflect real double sided cold-standby 5+5 setup. But as far as I remember we agreed on 5+0.

Also make sure, haproxy gets redeployed and is configured properly - this might be a bit challenging - we might need to manually override the computed connection schema so all frontend and backend haproxy instances distribute their connections to all rabbitmq nodes (and not just to the DC-local ones determined by the even/odd flag.","16/Jan/20 15:49;pw231;[~cv179]: 5+0 zero is enough. But it should be production sized (in CPUs) and all nodes in EQ. So:
- 5 nodes in one DC (e.g. amq1. amq3 ,...,amq9)
- all have CPU prod like, i.e. *12 CPUs* (This is *important* since elts prod has very high CPU usage and we want to achieve the same)
- RAM can be smaller, since we are not using it much in elts prod : *8 GB* should do.

having all nodes in EQ, we should solve the config problem for HA proxies...","16/Jan/20 16:46;cv179;Plan:
*m7shrdsyt1amq1*: 
shutdown, reduce memory to 8GB, increase CPU to 12, clear deployed instance folders

*m7shrdsyt1amq2*: 
shutdown, reduce memory to 8GB, increase CPU to 12, request DNS change to m7shrdsyt1amq9, request DC-prefer-option to be IXE and migrate VM to ixe, clear deployment instance folders

*m7shrdsyt1amq3*:
shutdown, increase memory to 8GB, increase CPU to 12, clear deployed instance folders

*m7shrdsyt1amq5* & *m7shrdsyt1amq7*:
request as new VMs, setup OS RHEL 7.6 with Erlang 22.1.



Update inventory to reflect new situation - dismiss ""instance_oldname"" variable and set OTHER_NODE for all instances to 'shrd-syt1-amq1@m7shrdsyt1amq1`

 

Redeploy all rabbitmq

Redeploy all backend haproxys","17/Jan/20 11:12;cs687;Requested new Virtual Machines and Changes for Resources of the existing virtual Machines:

{code:java}
Hello everybody,

please reduce/increase memory to 8-GB RAM and increase CPU to 12 for the existing Virtual Machines
-	M7shrdsyt1amq1
-	M7shrdsyt1amq2 
-	M7shrdsyt1amq3

@VM_Approval: please, approve these VM´s creation for TECHLOG-3111

Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/Systemtest1	M7shrdsyt1amq5	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	12	8	45 GB	Clustdmzlxeq	RHEL7	ENERGY TECHLOG 3111	TEST	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/Systemtest1	M7shrdsyt1amq7	389 (M7CLOUD-SIM-BE-DATA-H1-FF) (10.139.56.0/22)	12	8	45 GB	Clustdmzlxeq	RHEL7	ENERGY TECHLOG 3111	TEST	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


In case of additional questions, please contact me.


Thank you in advance.


Cheers,
--------------------
Steffen Englert
Deutsche Börse AG
D-60485 Frankfurt am Main

Phone  +49 69 2 11-1 67 43

E-Mail  steffen.englert@deutsche-boerse.com
http://www.deutsche-boerse.com

{code}

We need to do a shutdown, for adding and deleting RAM/CPU on the existing VM´s
Waiting for dev to give us green light for that and coordinate it with cloud-admins. 
___________________________________________________________________________________________
Maintenance is done: 

*m7shrdsyt1amq1, m7shrdsyt1amq2 and m7shrdsyt1amq3 has 8GB RAM and 12 CPU´s*","17/Jan/20 12:53;cs687;Pull-Request for the 5-node Rabbitmq-Cluster
https://github.deutsche-boerse.de/dev/energy.automation.inventory/pull/1451
[~tf093] please review it. Thanks","20/Jan/20 10:08;cs687;Next To-Do´s: (i)

1.) Installing 2 VM´s 
- m7shrdsyt1amq5
- m7shrdsyt1amq7
- Necessary NSR´s

2.) Creating NSR for DNS-Request for m7shrdsyt1amq2 to m7shrdsyt1amq9 

3.) Merging pull-request

4.) Deploying rabbitmq-cluster 

Waiting for the GO from DEV-Team to start with this points. ","22/Jan/20 08:05;cs687;*NSR-Request for m7shrdsyt1amq5:*
Product 1302878 successfully created!
Request 7030456 successfully created!

IP-Address 10.149.58.167

*NSR-Request for m7shrdsyt1amq7*
Product 1302879 successfully created!
Request 7030457 successfully created!

IP-Address: 10.139.58.166

*NSR-Request for DNS Change from m7shrdsyt1amq2 to m7shrdsyt1amq9*
 
Product 1302880 successfully changed!
Request 7030458 successfully changed! 

IP-Address: 10.139.58.165","23/Jan/20 08:22;cs687;m7shrdsyt1amq5 was handled by [~iu252]

Created ISO-Image for m7shrdsyt1amq7 with the following Jenkins Job 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/System-Setup/job/generate-iso/61/console

Going to install the basic installation with the generated ISO-Image. 

Run Jenkins Job:
os_selinux.yml 
os_update.yml
os_ntp.yml
os_network.yml
os_agents.yml
os_accounts.yml
os_authentication.yml
os_filesystem.yml","24/Jan/20 10:08;cs687;+*Last Status: *+

m7shrdsyt1amq2 is changed to *m7shrdsyt1amq9*
*m7shrdsyt1amq5* and *m7shrdsytamq7* is installed and setup

m7shrdintebh1/3 are not in the right VLAN. Currently they are in the VLAN 387 and supposed to be in 389 like the amq-hosts, which i mentioned above. 

{color:#DE350B}*DMZ-387M7CLOUD-SIM-LB-FF10.136.149.0 /24  -> DMZ-389M7CLOUD-SIM-BE-FF-H110.139.56.0 /22*{color}
We also double-checked with M7 SIMU and M7 PROD Infrastructure which covers exactly this behavior.

When we are going to proceed this changes, Systemtest3 will be also touched and has to be deployed again.

[~nn236] please check that with Product Owner, that we can continue with that ticket. 
https://confluence.energy.svc.dbgcloud.io/display/ET/Energy+Networks?preview=/10460279/10717849/M7_network_design_v1.0.pdf

*+Update:+*
Feedback from CloudAdmins:
To change the VLAN can be done anytime and costs only few clicks. 
[~xx256] will check today to create DNS-Records and new IPs with ISR.
","24/Jan/20 14:06;cs687;1.) First step 

ESX Team ""Bernd Giegerich"" changed the Interface of the virtual machines from VLAN 387 to VLAN 389
- m7shrdintebha1
- m7shrdintebha2
- m7shrdintebha3
- m7shrdintebha4

2.) 

changed the following files for all 4 machines:
/etc/sysconfig/network-scripts/ifcfg-eth0
-> ip address and subnetmask

/etc/sysconfig/network
-> standard gateway to 10.139.56.3

3.) 

run the Jenkins job to update static route tables 
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/ 
playbook -> os_network.yml

4.) 

after all the changes we restarted ""cor"" and ""enq"" for systemtest1 and systemtest3 
and also restarted the backend ha-proxies after changing the haproxy.cfg
with the new host-ip address. 

*frontend amqp_ssl_public*
        *bind ...*","27/Jan/20 08:50;cv524;Monday 27.01.2020 
New IP addresses and DNS record modification was requested by NSR tickets: 7030541-7030544
10.139.58.164 m7shrdintebha1 m7shrdintebha1.deutsche-boerse.de
10.139.58.163 m7shrdintebha2 m7shrdintebha2.deutsche-boerse.de
10.139.58.162 m7shrdintebha3 m7shrdintebha3.deutsche-boerse.de
10.139.58.161 m7shrdintebha4 m7shrdintebha4.deutsche-boerse.de
","27/Jan/20 13:50;cs687;[~tf093] confirmed that systemtest1 and systemtest3 is running fine for developers. ","27/Jan/20 13:52;cs687;5 node cluster is prepared/configured and running. Ticket is closed. ",,,,,,,,,,,,,,,
reflect 3 node cluster installed in FLEX PROD in M7_environments sheet,M7P-5456,90709,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,rehapav,rehapav,06/Jan/20 12:58,17/Dec/20 15:26,16/Sep/21 14:11,18/Feb/20 07:30,,6.9.68,7tops_sprint0,,,,,,24/Jan/20 00:00,M7PRODOPS,TechOpsBoard,,,,,,"Looking into document

S:\Energie\Prod_DEVELOP\001 M7\Infrastructure

M7_Environments_2019-11-19

 
|FLEX Production| | | | | |FLEX Production| | | | | |
|Env.|Description|VM hostname|IP|OS Version|Software|Type|ESX Host|VLAN|vCPU|RAM (GB)|Disk total| |
|Flex Production|M7 backend|M7FLEXPRODM7B1|10.139.53.191|RHEL 7.x|Java 8 latest|Master|Production Equinix|394|4|20|20|/flex(2GB);/flex/logs(2GB)|
|Flex Production|RabbitMQ Broker|M7FLEXPRODAMQ1|10.139.53.189|RHEL 7.x|RabbitMQ/Erlang|Master|Production Equinix|394|4|16|15|/flex(2GB);/flex/logs(2GB)|
|Flex Production|M7 backend|M7FLEXPRODM7B2|10.139.53.190|RHEL 7.x|Java 8 latest|Master|Production Hausen|394|4|20|20|/flex(2GB);/flex/logs(2GB)|
|Flex Production|RabbitMQ Broker|M7FLEXPRODAMQ2|10.139.53.188|RHEL 7.x|RabbitMQ/Erlang|Master|Production Hausen|394|4|16|15|/flex(2GB);/flex/logs(2GB)|

It seems that there is only 2node RabbitMQ cluster in FLEX PROD.

 

However Niklas confirmed that we have installed with 6.7 deployment 3 node cluster.

*Todo1*: update the document

S:\Energie\Prod_DEVELOP\001 M7\Infrastructure

M7_Environments_2019-11-19

 

*Todo2*: is it worth of review the document to check if its up to date?

 

 

 ",,cs687,rehapav,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49766400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwhrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":90709,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"18/Feb/20 07:29;cs687;The Excel Sheet ""Env-Details"" is *outdated* and will *not be updated* anymore. We are only keeping/updating the sheets for the connections!
So the new source of Truth is the inventory in github repository 

https://github.deutsche-boerse.de/dev/energy.automation.inventory

For the excel sheet we make it visible in *Env-details* that this page is outdated and will be not updated anymore.
I will close the ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,
M7T PROD - Server to be onboaraded with Cyberark,M7P-5449,91227,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Jan/20 14:22,17/Dec/20 15:26,16/Sep/21 14:11,13/Mar/20 13:51,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,TechOpsBoard,,,,,,"-|M7EPEXPRODAMQ3|-
|M7EPEXPRODNET2|
|M7EPEXPRODNET1|",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 10:58;cs687;new_onboarded_HOSTS_M7.csv;https://jira.deutsche-boerse.com/secure/attachment/81466/new_onboarded_HOSTS_M7.csv",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47606400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwxo7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91227,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 09:13;cs687;*Current status:*

*Server on-boarded but with error/warnings*
{code:java}
Server onboarded m7epexprodamq3  | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001
{code}

*Server not on-boarded:*
{code:java}
Server not onboarded M7EPEXPRODNET2
Server not onboarded M7EPEXPRODNET1 
{code}
","13/Mar/20 09:18;cs687;Contact persons were: Pavel Tajanovsky or Vasileios Nikolaidis","13/Mar/20 10:58;cs687;requested that the hosts will be onboarded.
{code:java}
Hi Steffen,
We are currently in the phase of changing the onboarding process, but for now I think it’s alright to do it the old way.
Simply fill in the attached csv file (and rename it) with the simple and fqdn names of the servers to be onboarded. Also either set the same password everywhere or include a different password for each new servers in the csv file. I will update my onboarding scripts accordingly.
Please add servers in attachment to Safe ""ENERGY - root"", with policy ""Unixviassh7dayreset_OTP"". 
Password for the server is “CHANGEme“
Kind regards,
-pt-
{code}
","13/Mar/20 13:51;cs687;Can be closed!
{code:java}
The below email is classified: Strictly Confidential

Hello Steffen,

The servers are onboarded.

Best regards,
Vasileios Nikolaidis

{code}
",,,,,,,,,,,,,,,,,,,,,,,,
ADV Simu not working,M7P-5446,91337,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,yq577,yq577,22/Jan/20 15:58,17/Dec/20 15:26,16/Sep/21 14:11,23/Jan/20 10:24,,6.9.54,7tops_pre-sprint0_cleanup,,,,,,22/Jan/20 00:00,M7PRODOPS,,,,,,,"Hi,

ADV Simu is not working since this noon. Could you please check and advise? We just see a blanc, white page.

",,cs687,lw641,qo288,yq577,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SERVICE-5426,M7P-5368,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,52012800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwztz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91337,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/20 16:09;qo288;One core crashed and other core was left in slave mode

After both cor+amq restart application is back to normal","22/Jan/20 17:16;lw641;Seems like not working again - I'm not able to access WebGUI. Customer has also reported issues:
 
{code:java}
     Kaja Schülke added a comment - 22/Jan/20 16:39    
Hello all,
 unfortunately the system doesn´t seem stable. Customers cannot log in, and as soon as we wanna do things like a simple password reset, the ""core is down or busy, please try again later"" appears.
{code}
Ticket reopened.
 ","23/Jan/20 08:49;cs687;Stopped both cor´s at least cor2 was not runinng, so i stopped cor1 

and started just and only cor1 again. 

found the following error in the logfile 

{code:java}
---> 2020-01-23T07:42:03.653Z [CoreService] INFO  c.d.e.m.c.CoreServiceExceptionHandler - Validation error during Input:com.deutscheboerse.energy.m7.core.in.req.DeactivateRemoteOrdersByDisconnectionTask@6244fe90; ComxervException:java.lang.IllegalStateException: Journaler not started. Event : com.deutscheboerse.energy.m7.core.in.req.DeactivateRemoteOrdersByDisconnectionTask@6244fe90
{code}

*jornaler not started*

Provided [~nn481] the logfiles in ebsm. ","23/Jan/20 09:43;cs687;1.) backuped journal-files and truncate ""*m7_999_revision_index*""
2.) started cor1 again but it failed after some minutes again.

Than we noticed the following issue in the standard-logfile:

{code:java}
missing relation:  cx_119_settlement_history_seq

*Caused by: java.sql.BatchUpdateException: Batch entry 0 insert into m7tepexasimm7b.CX_118_SETTLEMENT (VERSION, INFO, TRADE_ID, TRADE_VERSION, TRADE_STATE, TRADE_ACTION, TRADE_TIME_STAMP, TRADE_BUY_ORDER_EIC, TRADE_SELL_ORDER_EIC, TRADE_BUY_CLIENT_ORDER_ID, TRADE_SELL_CLIENT_ORDER_ID, TRADE_EXTERNAL_ID, EXTERNAL_REVISION, ALARM_ATTEMPTS_LEFT, INIT_ALARMS, SNDG_ALARMS, SENT_ALARMS, MOD_TYPE_CODE, LAST_UPDATE_TIME, LAST_UPDATE_USER, ID) values (1, NULL, 16065220, 1, 'ACTI', 'SADD', '2020-01-23 08:04:46.444+00', 'TPCSP-----------', 'TMDBEX-BG1-----X', NULL, NULL, 3810972, 1, 3, 0, 0, 0, 'INIT', '2020-01-23 08:04:46.444+00', 'TMDBEX-BG1-----XOPEPE3', 3002836) was aborted: ERROR: relation ""cx_119_settlement_history_seq"" does not exist*
{code}

and we created the sequence and started cor1 again. 

{code:java}
do $SEQ_CX_119_SETTLEMENT_HISTORY$
  declare start_id int;
begin
    select coalesce(max(history_id)+1,1) from CX_119_SETTLEMENT_HISTORY into start_id;
    execute 'CREATE SEQUENCE CX_119_SETTLEMENT_HISTORY_SEQ
                START WITH ' || start_id || ' INCREMENT BY 1
                OWNED BY CX_119_SETTLEMENT_HISTORY.HISTORY_ID' ;
end $SEQ_CX_119_SETTLEMENT_HISTORY$;
{code}



*{color:#DE350B}The root-issue was not the error *Journaler not started, like expected before!{color}*


As last step we started cor2 again. 


HEALTHCHECK: 
{code:java}
tomcat@m7epexasimm7b1:[/epex/logs/epex-asim-cor1]$  curl http://localhost:8079/
m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""MASTER"",""consumer"":""CONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""status""tomcat@m7epexasimm7b1:[/epex/logs/epex-asim-cor1]$
{code}



HEALTHCHECK:
{code:java}
tomcat@m7epexasimm7b2:[/epex/epex-asim-cor2]$ curl http://localhost:8079/m7core/health
{""status"":""UP"",""details"":{""db"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP""},""m7"":{""type"":""org.springframework.boot.actuate.health.Health"",""status"":""UP"",""details"":{""masterStatus"":""SLAVE"",""consumer"":""DISCONNECTED""}},""sobGateway"":{""type"":""org.springframework.boot.actuate.health.Health"",""statutomcat@m7epexasimm7b2:[/epex/epex-asim-cor2]$
{code}

","23/Jan/20 09:50;cs687;Should be the expected sequences in cor database:
{code:java}
m7tepexasimm7b=# SELECT * FROM information_schema.sequences;
 sequence_catalog | sequence_schema |               sequence_name                | data_type | numeric_precision | numeric_precision_radix | numeric_scale | start_value | minimum_value |    maximum_value    | increment | cycle_option
------------------+-----------------+--------------------------------------------+-----------+-------------------+-------------------------+---------------+-------------+---------------+---------------------+-----------+--------------
 m7tepexasimm7b   | m7tepexasimm7b  | cx_119_settlement_history_seq              | bigint    |                64 |                       2 |             0 | 5903257     | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | cx_212_contract_name_format_id_seq         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | envers_sequence                            | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | hibernate_sequence                         | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | cx_103_quote_request_id_seq                | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | cx_213_contract_name_format_history_id_seq | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | cx_268_risk_management_id_seq              | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
 m7tepexasimm7b   | m7tepexasimm7b  | cx_410_trading_phase_trading_phase_id_seq  | bigint    |                64 |                       2 |             0 | 1           | 1             | 9223372036854775807 | 1         | NO
(8 rows)
{code}
","23/Jan/20 10:22;cs687;[~yq577] mentioned the following issue by opening the web-gui:

{code:java}
Service Unavailable
The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later.

https://advsimu1.epex.m7.deutsche-boerse.com:60240
https://advsimu2.epex.m7.deutsche-boerse.com:60240
{code}

after restarting the enq´s, its working fine!

I will close the ticket, and after 15 minutes passed in a healthy mode, [~yq577] will inform the customer. ","23/Jan/20 10:24;cs687;Closed. ",,,,,,,,,,,,,,,,,,,,,
M7T SIMU - Server to be onboaraded with Cyberark,M7P-5438,91229,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Minor,Done,cs687,cs687,cs687,20/Jan/20 14:32,17/Dec/20 15:26,16/Sep/21 14:11,13/Mar/20 13:51,,6.9.85,7tops_sprint2,,,,,,,M7PRODOPS,TechOpsBoard,,,,,,"-|M7HUPXSIMUAMQ1|-
-|M7XSOPSIMUM7B1|-
-|M7XSOPSIMUAMQ1|-
-|M7EPEXASIMAMQ2|-
-|M7EPEXASIMM7B2|-
-|M7ELTSSIMUM7B2|-
-|M7ELTSSIMUAMQ2|-
-|M7CICSCASIMAPP2|-
-|M7CICSCASIMAMQ2|-
-|M7CICSCASIMAPP1|-
-|M7HUPXSIMUAMQ2|-
|{color:#DE350B}M7HUPXSIMUAMQ3{color}|
-|M7HUPXSIMUM7B2|-
|{color:#DE350B}M7XSOPSIMUAMQ3{color}|
-|M7XSOPSIMUAMQ2|-
-|M7XSOPSIMUM7B2|-
-|M7HUPXASIMM7B2|-
-|M7HUPXASIMAMQ2|-
-|M7ELTSSIMUM7C2|-
-|M7PLPXSIMUM7B2|-
-|M7PLPXSIMUAMQ2|-
-|M7PLPXLIPAM7B2|-
-|M7PLPXLIPAAMQ2|-
-|M7XSOPASIMM7B2|-
-|M7XSOPASIMAMQ2|-
-|M7XRPMLIPAAMQ6|-
-|M7XRPMLIPAAMQ4|-
-|M7XRPMLIPAM7B2|-
-|M7XRPMSIMUAMQ4|-
-|M7XRPMSIMUAMQ6|-
-|M7XRPMSIMUM7B2|-
-|M7XRPMSIMUAMQ2|-

https://confluence.energy.svc.dbgcloud.io/display/PD/Review+Configuration+to+be+installed+on+each+host?preview=/25463610/25463611/CyberArk%20onboarding%20procedure_%20v1.2.pdf",,cs687,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 10:57;cs687;new_onboarded_HOSTS_M7.csv;https://jira.deutsche-boerse.com/secure/attachment/81465/new_onboarded_HOSTS_M7.csv",,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47606400,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwxof:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91229,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/20 08:48;cs687;Current on-boarded status:
{code:java}
Server onboarded m7epexasimm7b2 | 
Server onboarded m7epexasimamq2 | 
Server onboarded m7eltssimuamq2 | 
Server onboarded m7eltssimum7b2 | 
Server onboarded m7eltssimum7c2 | 
Server onboarded m7hupxasimamq2 | 
Server onboarded m7hupxasimm7b2 | 
Server onboarded m7hupxsimum7b2 | 
Server onboarded m7plpxlipaamq2 | 
Server onboarded m7plpxlipam7b2 | 
Server onboarded m7plpxsimuamq2 | 
Server onboarded m7xrpmlipaamq4 | 
Server onboarded m7xrpmlipaamq6 | 
Server onboarded m7xrpmlipam7b2 | 
Server onboarded m7xrpmsimuamq2 | 
Server onboarded m7xrpmsimuamq4 | 
Server onboarded m7xrpmsimuamq6 | 
Server onboarded m7xrpmsimum7b2 | 
Server onboarded m7xsopasimamq2 | 
Server onboarded m7xsopasimm7b2 | 
Server onboarded m7xsopsimuamq1 | 
Server onboarded m7xsopsimuamq2 | 
Server onboarded m7xsopsimum7b1 | 
Server onboarded m7xsopsimum7b2 | 
{code}
","13/Mar/20 09:06;cs687;Server on-boarded but with errors:

{code:java}
Server onboarded m7cicscasimamq2 | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001
Server onboarded m7cicscasimapp1 | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001
Server onboarded m7cicscasimapp2 | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001
Server onboarded m7hupxsimuamq1  | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001
Server onboarded m7hupxsimuamq2  | Execution error. Error: Invalid prompt or did not receive any prompt. State: ""ChangePass"". code: 7001

Server onboarded m7plpxsimum7b2 | Invalid username or bad password. code: 2114

{code}
","13/Mar/20 09:06;cs687;Server not on-boarded:
{code:java}
Server not onboarded M7HUPXSIMUAMQ3
Server not onboarded M7XSOPSIMUAMQ3
{code}
","13/Mar/20 09:18;cs687;Contact persons were: Pavel Tajanovsky or Vasileios Nikolaidis","13/Mar/20 10:57;cs687;requested that the hosts will be onboarded.
{code:java}
Hi Steffen,
We are currently in the phase of changing the onboarding process, but for now I think it’s alright to do it the old way.
Simply fill in the attached csv file (and rename it) with the simple and fqdn names of the servers to be onboarded. Also either set the same password everywhere or include a different password for each new servers in the csv file. I will update my onboarding scripts accordingly.
Please add servers in attachment to Safe ""ENERGY - root"", with policy ""Unixviassh7dayreset_OTP"". 
Password for the server is “CHANGEme“
Kind regards,
-pt-
{code}
","13/Mar/20 13:51;cs687;Can be closed!
{code:java}
The below email is classified: Strictly Confidential

Hello Steffen,

The servers are onboarded.

Best regards,
Vasileios Nikolaidis

{code}
",,,,,,,,,,,,,,,,,,,,,,
DATALAKE SIMU for creating monthly Reports,M7P-5432,91369,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,cs687,cs687,23/Jan/20 12:50,17/Dec/20 15:24,16/Sep/21 14:11,26/Mar/20 07:15,,6.10.4,6.9.91,7tops_sprint4,,,,,,M7PRODOPS,,,,,,,"For monthly reports Bizops need connectivity from M7shrdebsm1 to our Simu Database-Hosts for the databases 
- epex-asim
- elts-ctpb

For that we need to create 2 virtual-machines on our own comming ESX Cluster 
- m7simudbr1
- m7simudbr2

and configure the Machines as Replica-Nodes to patroni-databases which i mentioned above. 
Once we have that we should allow M7shrdebsm1 to connect to epex-asim/elts-ctpb port that bizops can run some report-jobs to generate the monthly reports on the Replica-Host. 

With that task we can start, once we have our own esx-cluster to start creating new virtual-machines. 
Until that time it is not done, [~dp007] confirmed that this process will be handled manually on the first day in the month.  
",,cs687,cv524,dp007,oy574,xt853,,,,,,,,,,,,,,,,,,,,,,,,,,,,,M7P-5435,,,,,,"14/Feb/20 08:04;cs687;iso_image-m7simudbr1.txt;https://jira.deutsche-boerse.com/secure/attachment/80363/iso_image-m7simudbr1.txt","14/Feb/20 08:06;cs687;iso_image-m7simudbr2.txt;https://jira.deutsche-boerse.com/secure/attachment/80364/iso_image-m7simudbr2.txt",,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,46483200,,,dm700,lw641,ox626,rehapav,sw455,,,,M7P-5430,,,,,Impediment,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzx73b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,7tops Sprint 2,7tops Sprint 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91369,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,master,,true,"11/Feb/20 11:51;cs687;To-Do´s:
1.) Requesting Virtual Machines *""m7simudbr1"" & ""m7simudbr2""*
2.) Create OS_Image and NSR-Request
3.) Install Virtual Machines with Postgres 11
4.) Request a bunch of Firewall-Request for patroni-deployment with consul + Firewall-Request from ebsm to vm´s
5.) Deploy Patroni for the Databases (epex-asim, elts-ctpb) to integrate these two nodes to the patroni-cluster
6.) Deploy Consul-Agent on the virtual machines","11/Feb/20 11:53;cs687;1.) Requested the virtual machines:

{code:java}
Hi CloudAdmins,
@VM_Approval: please, approve these VMs’ creation.
Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7/Simulation/DB/	M7SIMUDBR1	620 (DMZ-620 ENDW-TST-FF) (10.136.161.0/25)	2	8	80 GB	clustm7eq	RHEL7	M7P-5432	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com )


Please, create following VM resources:
Host group	Hostname	VLAN	vCPU	RAM	DISK	ESX	OS	Description	Environment	Contact
Energy (NEW)/M7 /Simulation/DB/	M7SIMUDBR2	622 (DMZ-622 ENDW-TST-H1) (10.136.33.0/25)	2	8	80 GB	clustm7ha	RHEL7	M7P-5432	Simu	Energy TechOps (Energy_TechOps@deutsche-boerse.com)



Thank you in Advance!
Cheers, 
Steffen
{code}
","13/Feb/20 09:55;cs687;2.) Created NSR-Request for the machines M7SIMUDBR1 & M7SIMUDBR2

*10.136.161.121 -> M7SIMUDBR1*
{code:java}
Product 1306110 successfully created!
Request 7030893 successfully created!
{code}

*10.136.33.123 -> M7SIMUDBR2*
{code:java}
Product 1306111 successfully changed!
Request 7030894 successfully changed!
{code}


Created the iso-images with Jenkins Job (see attached files)
iso-images are stored -> http://syspmon1.deutsche-boerse.de/energy/

*m7simudbr1-genoa-rh7-VM-ext4-energy.iso*
*m7simudbr2-genoa-rh7-VM-ext4-energy.iso*


","14/Feb/20 08:08;cs687;3.) Install Virtual Machine with Postgres 11

run for the two replica-hosts the following playbooks in energy.automation.os.install:
- os_selinux.yml
- os_upate.yml
- os_ntp.yml
- os_network.yml
- os_filesystem.yml
- os_authentication.yml
- os_accounts.yml
- os_agents.yml","14/Feb/20 13:01;cs687;4.) Requesting necessary Firewall-Requests ... still waiting until FW are implemented
ID 503214 with the new Tool Tufin.

UPDATE:

Firewall-Request is rejected from GIS invalid request 

{code:java}
Hello Steffen

Your request is violating the DBG connectivity rules by trying to connect from DEV to SIMU zone, which connection is strictly forbidden. 
Is there any way how to implement the functionality without violating the rules?
To consider the request, we would need answers to the following:
 
•	Business need / service 
•	Related Application 
•	Information types  (Transferred Data) 
•	Data criticality 
•	Self-identified security risk (Possible risk) 
•	Similar FW rules which were request in the past (ID)?
•	Security concept available for the application:
 
We might also need approval of application owner / information owner and a relevant risk being entered into the risk register for the impacted application.
 
Best regards,

Jan Beran
IS Governance & Risk
{code}

I talked to Jan Beran and told him that we had a similar Request in the past with the ID  319385
on XBID Side. 
He will double-check that and hopefully accept it the next days. I will check the process in the next days. 

update: 04.03.2020 
scheduling a meeting with andrei, jan on monday 09.03.2020
","17/Feb/20 13:45;cv524;Both involved hosts were assigned to required channels of RHN Satellite

{noformat}
#############################################################################################################
[root@m7simudbr1 ~]# rhn-channel -l
epel-genoa-rh7.6
genoa-rh7.6
postgresql-11-genoa-rh7.6
rhel-rhn-tools-genoa-rh7.6
rhel-server-extras-genoa-rh7.6
rhel-server-optional-genoa-rh7.6
rhel-server-supplementary-genoa-rh7.6
server-ops-genoa-rh7.6
xbid-genoa-rh7.6
[root@m7simudbr1 ~]#
#############################################################################################################
{noformat}
{noformat}
#############################################################################################################
[root@m7simudbr2 ~]# rhn-channel -l
epel-genoa-rh7.6
genoa-rh7.6
postgresql-11-genoa-rh7.6
rhel-rhn-tools-genoa-rh7.6
rhel-server-extras-genoa-rh7.6
rhel-server-optional-genoa-rh7.6
rhel-server-supplementary-genoa-rh7.6
server-ops-genoa-rh7.6
xbid-genoa-rh7.6
[root@m7simudbr2 ~]#
#############################################################################################################
{noformat}","09/Mar/20 13:23;cs687;UPDATE: we had a meeting with [~wm282] and Jan Beran from GIS and talked about the open firewall-request ID: 319385
It will be approved by Jan and we get it implemented. Ticket still in waiting. 

UPDATE: 
Firewall-Rules are implemented but still not working, reopened the ticket and get in contact with CCI-Team. 

#################################################################
Added the following routes to *m7simupdb1-4*
* ip route add 10.136.161.0/25 via 10.139.56.9
* ip route add 10.136.33.0/25 via 10.139.56.6

and also added these routes to 
/etc/sysconfig/network-scripts/route-bond-admin
#################################################################
Afterwards tests are working fine. ","23/Mar/20 12:48;cs687;5.) Deploying patroni replica for epex-asim and elts-ctpb on the hosts m7simudbr1/2 
{code:java}
[root@m7simudbr1 ~]# wget http://syspmon1/pub/RPM-GPG-KEY-PGDG-11.PUB                                                                        
--2020-03-23 12:45:00--  http://syspmon1/pub/RPM-GPG-KEY-PGDG-11.PUB                                                                         
Resolving syspmon1 (syspmon1)... 172.20.100.252                                                                                              
Connecting to syspmon1 (syspmon1)|172.20.100.252|:80... connected.                                                                           
HTTP request sent, awaiting response... 200 OK                                                                                               
Length: 1726 (1.7K) [text/plain]                                                                                                             
Saving to: ‘RPM-GPG-KEY-PGDG-11.PUB’                                                                                                         
                                                                                                                                             
100%[=======================================================================================================>] 1,726       --.-K/s   in 0s   
                                                                                                                                             
2020-03-23 12:45:00 (405 MB/s) - ‘RPM-GPG-KEY-PGDG-11.PUB’ saved [1726/1726]                                                                 
                                                                                                                                             
[root@m7simudbr1 ~]# rpm --import RPM-GPG-KEY-PGDG-11.PUB                                                                                    
{code}

and running the playbook:
{code:java}
[cs687@enprodauto1 {master L | ?1} ~/ansible/energy.automation.deployments]$ ansible-playbook playbooks/deploy_patroni.yml --limit ""m7t*epex*asim*dbr-async1"" -K -k -b --tags replica
SSH password:
SUDO password[defaults to SSH password]:

PLAY [deploy patroni resources to an environment] *********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************************************************
ok: [m7t-epex-asim-dbr-async1]

TASK [patroni : install patroni for RedHat] ***************************************************************************************************************
ok: [m7t-epex-asim-dbr-async1]

TASK [patroni : install postgresql package] ***************************************************************************************************************
ok: [m7t-epex-asim-dbr-async1] => (item=postgresql11)
ok: [m7t-epex-asim-dbr-async1] => (item=postgresql11-server)
ok: [m7t-epex-asim-dbr-async1] => (item=postgresql11-contrib)
ok: [m7t-epex-asim-dbr-async1] => (item=postgresql11-debuginfo)
ok: [m7t-epex-asim-dbr-async1] => (item=expect)

TASK [patroni : LVM Volumes creation data] ****************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item={'lv': 'data', 'size': '5g'})
changed: [m7t-epex-asim-dbr-async1] => (item={'lv': 'log', 'size': '5g'})
changed: [m7t-epex-asim-dbr-async1] => (item={'lv': 'backup', 'size': '5g'})

TASK [patroni : Filesystem creation] **********************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item=data)
changed: [m7t-epex-asim-dbr-async1] => (item=log)
changed: [m7t-epex-asim-dbr-async1] => (item=backup)

TASK [patroni : Mountpoint definition] ********************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item=data)
changed: [m7t-epex-asim-dbr-async1] => (item=log)
changed: [m7t-epex-asim-dbr-async1] => (item=backup)

TASK [patroni : Filesystem mount definition in ""/etc/fstab""] **********************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item=data)
changed: [m7t-epex-asim-dbr-async1] => (item=log)
changed: [m7t-epex-asim-dbr-async1] => (item=backup)

TASK [patroni : change fs permissions] ********************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item=data)
changed: [m7t-epex-asim-dbr-async1] => (item=log)
changed: [m7t-epex-asim-dbr-async1] => (item=backup)
 [WARNING]: Consider using the file module with owner rather than running chown.  If you need to use command because file is insufficient you can add
warn=False to this command task or set command_warnings=False in ansible.cfg to get rid of this message.


TASK [patroni : create patroni config folder] *************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1] => (item=/etc/patroni_m7tepexasimasync)

TASK [patroni : copy patroni.yml template] ****************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1]

TASK [patroni : copy patroni service file] ****************************************************************************************************************
changed: [m7t-epex-asim-dbr-async1]

TASK [patroni : enable and restart patroni service] *******************************************************************************************************
changed: [m7t-epex-asim-dbr-async1]

TASK [patroni : giving the process time to start] *********************************************************************************************************
ok: [m7t-epex-asim-dbr-async1]

TASK [patroni : allow postgres user to read journal] ******************************************************************************************************
changed: [m7t-epex-asim-dbr-async1]

PLAY RECAP ************************************************************************************************************************************************
m7t-epex-asim-dbr-async1   : ok=14   changed=10   unreachable=0    failed=0
{code}
","23/Mar/20 13:01;cs687;6.) Will be handled with separated M7P-Ticket. 
https://jira.deutsche-boerse.com/browse/M7P-5829

cluster is prepared and waiting for consul 
*2020-03-23 13:39:23,231 INFO: waiting on consul*
{code:java}
● patroni_m7tepexasimasync.service - Runners to orchestrate a high-availability PostgreSQL
   Loaded: loaded (/usr/lib/systemd/system/patroni_m7tepexasimasync.service; enabled; vendor preset: disabled)
   Active: active (running) since Mon 2020-03-23 13:37:37 CET; 1min 52s ago
  Process: 6452 ExecStartPre=/usr/bin/chmod 0700 /var/lib/pgsql_m7tepexasimasync/data/11/m7tepexasimasync (code=exited, status=1/FAILURE)
 Main PID: 6454 (python3.6)
   CGroup: /system.slice/patroni_m7tepexasimasync.service
           └─6454 python3.6 /usr/bin/patroni /etc/patroni_m7tepexasimasync/config.yml

Mar 23 13:39:23 m7simudbr1 patroni[6454]: During handling of the above exception, another exception occurred:
Mar 23 13:39:23 m7simudbr1 patroni[6454]: Traceback (most recent call last):
Mar 23 13:39:23 m7simudbr1 patroni[6454]: File ""/opt/app/patroni/lib/python3.6/site-packages/patroni/dcs/consul.py"", line 292, in refresh_session
Mar 23 13:39:23 m7simudbr1 patroni[6454]: return self.retry(self._do_refresh_session)
Mar 23 13:39:23 m7simudbr1 patroni[6454]: File ""/opt/app/patroni/lib/python3.6/site-packages/patroni/dcs/consul.py"", line 230, in retry
Mar 23 13:39:23 m7simudbr1 patroni[6454]: return self._retry.copy()(*args, **kwargs)
Mar 23 13:39:23 m7simudbr1 patroni[6454]: File ""/opt/app/patroni/lib/python3.6/site-packages/patroni/utils.py"", line 324, in __call__
Mar 23 13:39:23 m7simudbr1 patroni[6454]: raise RetryFailedError(""Exceeded retry deadline"")
Mar 23 13:39:23 m7simudbr1 patroni[6454]: patroni.utils.RetryFailedError: 'Exceeded retry deadline'
Mar 23 13:39:23 m7simudbr1 patroni[6454]: 2020-03-23 13:39:23,231 INFO: waiting on consul
Hint: Some lines were ellipsized, use -l to show in full.
{code}
","24/Mar/20 11:03;cs687;Patroni-Cluster for *epex-asim* and *elts-ctpb*
is up and running!

{code:java}
[root@m7simupdb1 ~]# patronictl -c /etc/patroni_m7teltsctpbasync/config.yml list              
+------------------+------------+----------------------+--------+---------+----+-----------+  
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
| m7teltsctpbasync | m7simudbr1 | 10.136.161.121:24004 |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simudbr2 | 10.136.33.123:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb1 | 10.139.58.176:24004  | Leader | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb2 | 10.139.58.175:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb3 | 10.139.58.174:24004  |        | running |  3 |         0 |  
| m7teltsctpbasync | m7simupdb4 | 10.139.58.173:24004  |        | running |  3 |         0 |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
{code}

{code:java}
[root@m7simupdb1 ~]# patronictl -c /etc/patroni_m7tepexasimasync/config.yml list              
+------------------+------------+----------------------+--------+---------+----+-----------+  
|     Cluster      |   Member   |         Host         |  Role  |  State  | TL | Lag in MB |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
| m7tepexasimasync | m7simudbr1 | 10.136.161.121:24012 |        | running |  1 |         0 |  
| m7tepexasimasync | m7simudbr2 | 10.136.33.123:24012  |        | running |  1 |         0 |  
| m7tepexasimasync | m7simupdb1 | 10.139.58.176:24012  | Leader | running |  1 |         0 |  
| m7tepexasimasync | m7simupdb2 | 10.139.58.175:24012  |        | running |  1 |         0 |  
| m7tepexasimasync | m7simupdb3 | 10.139.58.174:24012  |        | running |  1 |         0 |  
| m7tepexasimasync | m7simupdb4 | 10.139.58.173:24012  |        | running |  1 |         0 |  
+------------------+------------+----------------------+--------+---------+----+-----------+  
{code}

","24/Mar/20 11:09;cs687;pending firewall-requests necessary, creating a ticket for that, to allow the following connection:
{code:java}
[root@m7shrdebsm1 ~]# telnet m7simudbr1 24012
Trying 10.136.161.121...

[root@m7shrdebsm1 ~]# telnet m7simudbr2 24012
Trying 10.136.33.123...

[root@m7shrdebsm1 ~]# telnet m7simudbr1 24004
Trying 10.136.161.121...

[root@m7shrdebsm1 ~]# telnet m7simudbr2 24004
Trying 10.136.33.123...
{code}

ID: 	503602 -- waiting for implementation. 
","26/Mar/20 07:15;cs687;Firewall-Requests are implemented. Closing the ticket. 
Handing over to [~dp007]


{code:java}
[cs687@m7shrdebsm1 ~]$ telnet m7simudbr2 24004
Trying 10.136.33.123...
Connected to m7simudbr2.
Escape character is '^]'.

[cs687@m7shrdebsm1 ~]$ telnet m7simudbr2 24012
Trying 10.136.33.123...
Connected to m7simudbr2.
Escape character is '^]'.

[cs687@m7shrdebsm1 ~]$ telnet m7simudbr1 24004
Trying 10.136.161.121...
Connected to m7simudbr1.
Escape character is '^]'.

[cs687@m7shrdebsm1 ~]$ telnet m7simudbr1 24012
Trying 10.136.161.121...
Connected to m7simudbr1.
Escape character is '^]'.
{code}
","26/Mar/20 14:48;dp007;both connections do work.",,,,,,,,,,,,,,,
M7T DB-Refresh - Introduction of new DB Setup,M7P-5430,91550,,Epic,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,,yo218,sw455,28/Jan/20 10:54,27/May/21 10:46,16/Sep/21 14:11,27/May/21 10:46,,,,,,,,,29/Feb/20 00:00,M7PRODOPS,TechOpsBoard,,,,,,"Main ticket for the status of the discussion and the implementation of the new DB design with Patroni and Consul for M7T

Setup: The new DB setup contains of 4 DB Hosts per environment, 2 in each data center. All hosts are equipped with two very fast local NVMe SSD devices which will be used by the databases and by the journal files for the M7 Core module (to be clarified: is it required for M7, too?). 

A consul agent on each host connect to one node of a 5-node Consul cluster and is responsible for the election and detection of the master node. 

!image-2019-04-10-10-49-45-656.png!",,,,,,,,,,,,,,,,,,,,,TECHLOG-2212,,,,,,,,,,,,,,,,,,,,"28/Jan/20 10:54;sw455;image-2019-04-09-15-53-15-072.png;https://jira.deutsche-boerse.com/secure/attachment/79809/image-2019-04-09-15-53-15-072.png","28/Jan/20 10:54;sw455;image-2019-04-10-10-49-45-656.png;https://jira.deutsche-boerse.com/secure/attachment/79810/image-2019-04-10-10-49-45-656.png",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51580800,,,,,,,,,,,,DB Refresh,In Progress,,,,,,,,,,,,,[],,,,,,,,,,,,,,,"2|hzpr7b:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":91550,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kafka: Extend simu and prod routing tables to enable access,M7P-5398,91445,,Task,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,fp407,fp407,27/Jan/20 09:21,01/Jul/20 11:27,16/Sep/21 14:11,30/Jun/20 15:10,,6.10.123,7tops_sprint9_,,,,,,,DEVOPS,M7PRODOPS,,,,,,"Currently, a missing rule in routing tables on simu (including e.g. cute) and prod servers prevents M7 core from accessing the Kafka cluster.

Routing tables are handled by:

[https://github.deutsche-boerse.de/jancmic/energy.automation.os.install/blob/master/roles/os_network/]

Templates:
 * (prod) [https://github.deutsche-boerse.de/jancmic/energy.automation.os.install/blob/master/roles/os_network/templates/10.139.52.0_route_table.j2]
 * (simu) [https://github.deutsche-boerse.de/jancmic/energy.automation.os.install/blob/master/roles/os_network/templates/10.139.56.0_route_table.j2]

Must contain the rules:
 * prod: 10.136.32.0/25 -> 10.139.52.6, 10.136.160.0/25 -> 10.139.52.9
 * simu: 10.136.31.128/25 -> 10.139.56.6, 10.136.159.128/25 -> 10.139.56.9

This configuration is already present, but has not yet been applied to the servers.

This issue shall create/define a procedure how to apply the configuration to all machines either globally or when needed.

*Additional information:*
 * Once this ticket is resolved, configure Kafka in Syt1
 * Once this ticket is resolved, please contact [~rehapav] for further deployment activities",,cs687,fp407,,,,,,,,,,,,,,,,SERVICE-2486,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,38188800,,,dm700,lw641,ox626,rehapav,sw455,,,,,,,,,,,,,,,,,,,[],,,,,,,,,,,M7T,,,,"2|hzwtw7:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,7tops Sprint 4,7tops Sprint 5,7tops Sprint 6,7tops Sprint 7,7tops Sprint 8,7tops Sprint 9,,,,,,,,,,,,,,,,,,,,,.,2.0,,,,,,,,,"{""issueId"":91445,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"27/Jan/20 09:50;fp407;Create an ansible playbook which will add the route to the routing table (applying the changes immediately) and modify the network configuration file to match the changes made so that they are not lost on restart.

Modify the routing table:
{code:java}
“TEST/SIMU” (VLAN389- 10.139.56.0/22)
=========================
 [root@m7xsopcutem7b1 ~]# ip route add 10.136.31.128/25 via 10.139.56.6 dev eth0
 [root@m7xsopcutem7b1 ~]# ip route add 10.136.159.128/25 via 10.139.56.9 dev eth0
 =========================
“PROD” (VLAN394- 10.139.52.0/23)
=========================
 [root@m7xsopprodm7b1 ~]# ip route add 10.136.32.0/25 via 10.139.52.6 dev eth0
 [root@m7xsopprodm7b1 ~]# ip route add 10.136.160.0/25 via 10.139.52.9 dev eth0
 ========================={code}
 Update the config file:

[https://github.deutsche-boerse.de/jancmic/energy.automation.os.install/blob/master/roles/os_network/tasks/static_route.yml]
{code:java}
  template:
    src: ""templates/{{ ansible_default_ipv4.network }}_route_table.j2""
    dest: ""/etc/sysconfig/network-scripts/route-{{ ansible_default_ipv4.interface }}""
{code}","16/Jun/20 08:32;cs687;I would recommend to leave the ansible-playbook ""os_network"" like it is. 
https://github.deutsche-boerse.de/jancmic/energy.automation.os.install/blob/master/roles/os_network/

In case we want to introduce future KAFKA instances we have anyways to re-deploy cor-instances in that case we could also restart the network service to activate the added static routes. We just have to inform [~rehapav] about it, to put that part to the SERVICE Ticket as well. 
https://jira.deutsche-boerse.com/browse/SERVICE-5831

For now to activate the static-routes what [~fp407] mentioned above i would do the following:
Deploy os_network with the Jenkins Jobs -> *energy.automation.os.install* on necessary hosts to add the static rule to the network script with proper *tags: all*
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/

{code:java}
# Static route definitions

---
- name: Set static route table
  template:
    src: ""templates/{{ ansible_default_ipv4.network }}_route_table.j2""
    dest: ""/etc/sysconfig/network-scripts/route-{{ ansible_default_ipv4.interface }}""
    owner: ""root""
    group: ""root""
    mode: ""0644""
  ignore_errors: True
  register: static_route_configuration_status


- name: Restart network service if routing table changes
  service:
    name: network
    state: restarted
  when: static_route_configuration_status.changed
  tags: 
    - restart_network
    - never
{code}

With that tag we can avoid a restart of the network and we just have to trigger the ""ip route add"" commands manually. 
Otherwise when we want to execute it automatically we have to touch all the current static routes in the template and add it with ip route add... command. 

For this few Hosts i would not change the role, on the other hand it would be also more SYSENG Task to update it. 
In case we want to restart the network-agent we have to deploy it with *tag: restart_network"", what could be used in the future. 

{code:java}
+ ansible-playbook playbooks/os_network.yml --limit m7shrdsyt1apa1 -u ansible --tags all -C
 [WARNING]: While constructing a mapping from /usr/local/share/energy.automatio
n.inventory/inventory/m7t/shrd/syt3/m7_load_runner/vars.yml, line 1, column 1,
found a duplicate dict key (additional_params). Using last defined value only.

PLAY [all] *********************************************************************

TASK [Gathering Facts] *********************************************************
ok: [m7shrdsyt1apa1]

TASK [os_network : Network Manager stop and disable] ***************************
ok: [m7shrdsyt1apa1]

TASK [os_network : Standard network service enable and start] ******************
ok: [m7shrdsyt1apa1]

TASK [os_network : DNS resolving configuration] ********************************
ok: [m7shrdsyt1apa1]

TASK [os_network : Set static route table] *************************************
changed: [m7shrdsyt1apa1]

PLAY RECAP *********************************************************************
m7shrdsyt1apa1             : ok=5    changed=1    unreachable=0    failed=0   

Finished: SUCCESS
{code}","16/Jun/20 12:00;cs687;Just checked for all the xsop cor-machines and elts-simu the current setup of the static routes and can confirm that it is already im-place. 

Also talked to [~cv524] today and he confirmed there will be no planned changes on the os_network role itself, at least for the next future. 
So we will keep it like it is and once we are going to introduce Kafka to Env we have to check the following steps. [~rehapav] please add this steps to the SERVICE-Ticket once we are doing to deploy KAFKA to an Environment. 

*1.) Step:*
checking if the missing static routes are configured in the tomcat/cor-hosts 
{code:java}
/etc/sysconfig/network-scripts/route-eth0
{code}

SIMU&TEST:
{code:java}
10.136.31.128/25 -> 10.139.56.6
10.136.159.128/25 -> 10.139.56.9
{code}

PROD: 
{code:java}
10.136.32.0/25 -> 10.139.52.6
10.136.160.0/25 -> 10.139.52.9
{code}

In case it is not existing in network-scripts file we have to run the os_network playbook, *without* restarting network-service restart. 
When the deployment will touch the cor/tomcat instance we can also restart the network-service by adding the ""tag: *restart_network*"", if not we just leave it to ""tags: *all*""
https://englobjci1.deutsche-boerse.de/job/Energy-Operations/job/M7%20Ansible%20Jobs/job/energy.automation.os.install/

*2.) Step:* 
checking if the static routes are really im-place and activated with proper command.  
{code:java}
route -n 
{code}

There is nothing to do on ""7tops"" side, everything is working and static routes are configured properly.
For the future we just have to be aware of the missing steps or the role os_network itself has to changed from SYSENG-Team.
","16/Jun/20 12:14;cs687;It´s up to you [~fp407] how to continue with that ticket. 
its out of 7tops scope for now, i see it also more useless to keep it pending in the next sprints, like it is active running since sprint4.

Cheers. ","30/Jun/20 15:10;cs687;Ticket will be closed and handled with a separated SYSENG ticket.  ",,,,,,,,,,,,,,,,,,,,,,,
Remove php banner and server easter eggs,M7P-5268,90778,,Epic,Done,M7P,M7 Product,software,matemar,M7T Product main agile development project,,Major,Done,cs687,HO764,HO764,07/Jan/20 12:43,27/Jan/21 09:53,16/Sep/21 14:11,01/Dec/20 07:34,,7tops_sprint106,,,,,,,,7tops,M7PRODOPS,PenetrationTest,S,,,,"In ICS portal, set expose_php to Off to disable easter eggs, e.g.,

[https://cute1.ics.m7c.deutsche-boerse.com/php/main.php/?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000]

and also to disable X-Powered-By header.

 

Pen test report reference:

Security assessment report of M7C V3+V4 (sections 5.2.1, 5.2.2) [https://vmt.deutsche-boerse.de/browse/PT-1484] - *Priority* Medium + [https://vmt.deutsche-boerse.de/browse/PT-1488] *Priority* Medium",,cs687,dp007,HO764,rl336,,,,,,,,,,,,,,M7P-5684,,,M7P-4967,M7P-4968,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sw455,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,38707200,,,dm700,lw641,ox626,rehapav,sw455,,,,,pentest_php,To Do,,,,,,,,,,,,,[],,,,,,,,,,,M7C,,,,"2|hzn6bj:",9223372036854775807,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"{""issueId"":90778,""testStatuses"":[]}",,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jan/20 18:33;rl336;M7C V3: https://vmt.deutsche-boerse.de/browse/PT-1484
M7C V4: https://vmt.deutsche-boerse.de/browse/PT-1488","30/Apr/20 13:26;dp007;This article describes the problem: [https://perishablepress.com/expose-php/]","18/Jun/20 07:16;cs687;Proper Solution found, deployed it successfully in ATE1 env 
refer: https://jira.deutsche-boerse.com/browse/M7P-6354","19/Jun/20 07:18;cs687;Deployed WEB-Server for icsc-cute 
https://jira.deutsche-boerse.com/browse/M7P-6363","25/Jun/20 13:28;cs687;Ticket can be closed once TICKET M7P-6388 will be closed with the ICSC Production Deployment
Confirmed in last refinement meeting on 25.06.20

https://jira.deutsche-boerse.com/browse/SERVICE-2483

FYI: [~sJ194]",,,,,,,,,,,,,,,,,,,,,,,
